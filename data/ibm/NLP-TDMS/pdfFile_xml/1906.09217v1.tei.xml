<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Gating Networks for Sequential Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Ma</surname></persName>
							<email>chen.ma2@mail.mcgill.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Kang</surname></persName>
							<email>pengkang2022@u.northwestern.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Liu</surname></persName>
							<email>xueliu@cs.mcgill.ca</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Gating Networks for Sequential Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sequential Recommendation</term>
					<term>Feature Gating</term>
					<term>Instance Gating</term>
					<term>Item- item Product</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The chronological order of user-item interactions is a key feature in many recommender systems, where the items that users will interact may largely depend on those items that users just accessed recently. However, with the tremendous increase of users and items, sequential recommender systems still face several challenging problems: (1) the hardness of modeling the long-term user interests from sparse implicit feedback; (2) the difficulty of capturing the shortterm user interests given several items the user just accessed. To cope with these challenges, we propose a hierarchical gating network (HGN), integrated with the Bayesian Personalized Ranking (BPR) to capture both the long-term and short-term user interests. Our HGN consists of a feature gating module, an instance gating module, and an item-item product module. In particular, our feature gating and instance gating modules select what item features can be passed to the downstream layers from the feature and instance levels, respectively. Our item-item product module explicitly captures the item relations between the items that users accessed in the past and those items users will access in the future. We extensively evaluate our model with several state-of-the-art methods and different validation metrics on five real-world datasets. The experimental results demonstrate the effectiveness of our model on Top-N sequential recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As the Internet service and mobile device usages keep growing, Internet users can easily access a large number of online products and services. Although this growth provides users with more available choices, it is also difficult for users to pick up one of the most favorite items out of plenty of candidates. To reduce information overload and satisfy the diverse needs of users, personalized recommender systems come into being and play more and more important roles in modern society. These systems can provide personalized experiences, serve huge service demands, and bring significant benefits to at least two parties: <ref type="bibr" target="#b0">(1)</ref> help users easily discover products that they are interested in; <ref type="bibr" target="#b1">(2)</ref> create opportunities for product providers to increase the revenue.</p><p>In all kinds of Internet services, users access the products or items in a chronological order, where the items a user will interact may be closely relevant to those items she just accessed. This property facilitates a non-trivial recommendation task-sequential recommendation, which treats the user behavior history as an action sequence ordered by the operating timestamp. This task is challenging to address due to one major reason: the difficulty of inferring users' short-term interests and intentions. Indeed, both the longterm and short-term interests of users together determine the users' actions on items. With the large accumulated data, the long-term user interests can be effectively modeled. However, within a shortterm context, how to take advantage of the sequential dynamics for predicting user actions in the near future is non-trivial.</p><p>To capture the sequential dynamics in the user action history, effective models are proposed to learn the short-term user preference in the sequential user interactions, such as Markov Chains (MCs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs). MC-based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30]</ref> apply a K-order Markov chain to make recommendations based on the K previous actions. CNN-based methods <ref type="bibr" target="#b33">[34]</ref> utilize convolutional filters and sliding window strategies to capture the short-term contexts for future prediction. RNN-based methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b27">28]</ref> adopt gated recurrent (GRU) or long short-term memory (LSTM) units to learn the user-item sequence, where the short-term user interests are captured by the hidden states of RNNs.</p><p>Although existing methods have proposed effective models and achieved satisfactory results, we argue that there are still several factors to be considered for enhancing the performance. First, previous studies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> learn the user action sequence by CNN or RNN structures, which does not consider the specific parts of features of different items. Neglecting the representative features may fail to capture the true user interests in a short context. Second, these CNN or RNN based methods also do not discriminate the item importance based on users' preferences. Equally treating those informative items along with other items may lead to the incomplete understanding of user intentions. Third, it is also important to note that the relations between items are neglected in previous works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34]</ref>. It is very likely that closely related items may be interacted by users one after the other. As such, explicitly capturing the item-item relations will largely benefit predicting subsequent items users will interact.</p><p>To address the problems mentioned above, we propose a novel recommendation model, hierarchical gating network (HGN), for the sequential recommendation task without using complex recurrent or convolutional neural networks. HGN consists of a feature gating module, an instance gating module, and an item-item product module, integrated with the matrix factorization model and optimized by the Bayesian Personalized Ranking (BPR) objective. In particular, the feature gating module allows the adaptive selections of attractive latent features of items based on the user preference, where the selected user-specific features will be passed to the instance gating module. At the instance gating module, important items that reflect the short-term user interests will be distinguished and selected for future item prediction. Thus, the feature gating and instance gating modules form a hierarchical gating network to control what features or items can be passed to the downstream layers. On the other hand, item-item relations provide important auxiliary information to predict users' sequential behaviors, since closely related items may be interacted by users one after the other. Thus, we apply an item-item product module to explicitly capture the relations between the items users have interacted and those items user will interact in the future. We extensively evaluate our model with many state-of-the-art methods and different validation metrics on five real-world datasets. The experimental results not only demonstrate the improvements of our model over other baselines but also show the effectiveness of the gating and item-item product modules.</p><p>To summarize, the major contributions of this paper are listed as follows:</p><p>• To infer the user interests in a short-term context, we propose a hierarchical gating network to control what item latent features and which relevant item can be passed to the downstream layers. Our hierarchical gating network achieves better performance compared with complex recurrent or convolutional neural networks yet with fewer parameters and faster training speed. • To explicitly capture the item-item relations, we utilize an itemitem product module to learn the relationships between the items users have interacted and those items user will interact in the near future. • Experiments on five real-world datasets show that the proposed HGN model significantly outperforms the state-of-the-art methods for the sequential recommendation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we illustrate related work about the proposed model: personalized recommendation with user implicit feedback and the sequential recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Recommendation with Implicit Feedback</head><p>In many real-world recommendation scenarios, user implicit data <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b38">39]</ref>, e.g., browsing or clicking history, is more ubiquitous and common than the explicit feedback <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>, such as user ratings. The implicit feedback only provides positive samples, which is also called one-class collaborative filtering (OCCF) <ref type="bibr" target="#b25">[26]</ref>. Effective methods are proposed to tackle the OCCF problem. Early works either apply a uniform weighting scheme to treat all missing data as negative samples <ref type="bibr" target="#b14">[15]</ref>, or sample negative instances from missing data to learn the pair-wise user preference between positive and negative samples <ref type="bibr" target="#b28">[29]</ref>. Recently, several works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22]</ref> are proposed to weigh the missing data. In <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b35">36]</ref>, metric learning is applied to compute the distance between users and items. With the ability to represent non-linear and complex data, (deep) neural networks have been utilized in the domain of recommendation and bring more opportunities to reshape the conventional recommendation architectures. In <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40]</ref>, (denoising) autoencoders are proposed capture the user-item interaction from user implicit feedback. In <ref type="bibr" target="#b9">[10]</ref>, He et al. propose a neural network-based collaborative filtering model, where a multi-layer perceptron is utilized to learn the nonlinear user-item interactions. In <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b40">41]</ref>, conventional matrix factorization and factorization machine methods are also benefited by the representation ability of deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sequential Recommendation</head><p>Some early sequential recommendation methods rely on item-item transition matrices to capture the sequential patterns in the user interaction sequence. The Markov chain <ref type="bibr" target="#b1">[2]</ref> is a classical option to solve this problem. For example, Rendle et al. <ref type="bibr" target="#b29">[30]</ref> propose to factorize personalized Markov chains for capturing long-term preferences and short-term transitions. He et al. <ref type="bibr" target="#b7">[8]</ref> combines similarity-based models with high-order Markov chains to make personalized sequential recommendations. In <ref type="bibr" target="#b6">[7]</ref>, the translation-based method is proposed for sequential recommendation. Recently, benefited by the advantages of sequence learning in natural language processing, (deep) neural network based methods are proposed to learn the sequential dynamics. For instance, Tang et al. <ref type="bibr" target="#b33">[34]</ref> propose to apply the convolutional neural network (CNN) on item embedding sequence, where the short-term contexts can be captured by the convolutional operations. In <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28]</ref>, recurrent neural network (RNN), especially gated recurrent unit (GRU), based methods are utilized to model the sequential patterns for the session-based recommendation <ref type="bibr" target="#b12">[13]</ref>, where the hidden states of RNNs reflect the summary of the (sub)sequence. On the other hand, self-attention <ref type="bibr" target="#b36">[37]</ref> exhibits promising performance in sequence learning and is utilized in sequential recommendation. In <ref type="bibr" target="#b17">[18]</ref>, Kang et al. propose to leverage self-attention for adaptively considering interacted items. In <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16]</ref>, memory networks <ref type="bibr" target="#b32">[33]</ref> are adopted to memorize the important items that will play a role in predicting future user actions. However, our hierarchical gating network is different from the above studies. We apply feature-level and instance-level gating modules to adaptively control what item latent features and which relevant item can be passed to the downstream layers. While previous works either do not consider the representative items, or only consider the instance-level importance by the attention model but neglecting the feature-level ones. On the other hand, we adopt an item-item product to explicitly capture the relations between the items users have interacted and those items users will access in the near future, where the explicit modeling of item relations is rarely considered in previous works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM FORMULATION</head><p>The recommendation task considered in this paper takes sequential implicit feedback as training data. The user preference is presented by a user-item sequence in the chronological order S i = (S i 1 , S i 2 , ..., S i |S i | ), where S i j is an item index that user i has interacted with. Given the earlier subsequence S i 1:t (t &lt; |S i |) of M users, the problem is to recommend a list of items from N items to each user and evaluate whether the items in S i t :|S i | will appear in the recommended list.</p><p>Here, following common symbolic notation, upper case bold letters denote matrices, lower case bold letters denote column vectors without any specification, and non-bold letters represent scalars. The major symbols are listed in <ref type="table" target="#tab_0">Table 1</ref>.  <ref type="figure">Figure 1</ref>: An illustrative example of the feature gating, instance gating, and item-item product modules. In <ref type="figure">Figure 1a</ref>, the gray lines on items denote those latent features are masked off. In <ref type="figure">Figure 1b</ref>, the darker blue means the item is more important. In <ref type="figure">Figure 1c</ref>, the line linked between two items denotes the inner product, which captures the relations between the items users have accessed and the items users will access in the future. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGIES</head><p>To model the sequential recommendation task, for each user i, we extract every |L|, i.e. L = (S i j , S i j+1 , ..., S i j+|L |−1 ), successive items as input and their next |T | items as the targets to be predicted. The problem can be formulated as: in the user-item interaction sequence S i , given the |L| successive items, how likely other N items will be interacted subsequently.</p><p>In the sequential recommendation problem, the prediction of users' preferences on items can be modeled in two perspectives: long-term interests and short-term interests. The long-term user preference modeling has been widely investigated in the conventional Top-N recommendation methods, such as matrix factorization <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29]</ref>. On the other hand, how to capture the short-term user interests from the sequential data is the key point for performance improvement.</p><p>For the short-term interest modeling, we argue that there are two kinds of relationships existing between items users have interacted and items users will interact in the future: group-level and instancelevel relations. The group-level influence illustrates a phenomenon that several items in L together have an impact on the items user may interact in the future. For example, if a user has bought a bed frame and a mattress, a pillow is probably a more suitable recommendation than a table. On the other hand, the instance-level influence depicts the strong relation between a single item in L and a single item in T . For example, if a user bought a mobile phone, she may also need to buy a screen protector or a case. Thus, these two kinds of relations together determine users' short-term interests.</p><p>In this section, we introduce the proposed model to capture both the long-term interests and short-term interests of users for the sequential recommendation, which is shown in <ref type="figure">Figure 1</ref> and <ref type="figure">Figure  2</ref>. We first illustrate the hierarchical gating network for learning users' group-level preferences. Next, we present the inner product of item embeddings to model the item-item relations. Then we introduce the prediction layer for aggregating the long-term and short-term interests of users. Lastly, we go through the loss function and training process of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Hierarchical Gating for Group-level Influence</head><p>In the sequential recommendation, taking advantage of the properties of sequential data to learn the (sub)sequence representation is a critical point, where an item may be closely related to its previous or subsequent items, or a group of previous items will have an impact on the items in the near future. In previous works, researchers have utilized various methods to model the group-level sequential interactions, e.g., convolutional neural networks <ref type="bibr" target="#b33">[34]</ref>, recurrent neural networks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>, and the self-attention model <ref type="bibr" target="#b17">[18]</ref>. Different from previous works, we propose a hierarchical gating network for modeling group-level user-item interactions, which consists of two components: a feature gating module and an instance gating module. These two modules allow the selection of effective latent features and relevant items, respectively, for predicting the subsequent items. Our proposed gating network is both effective and efficient (section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Feature Gating</head><p>Unlike previous works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34]</ref> that only operate on the itemlevel, we provide a learnable feature gating module to select salient latent features of items from the feature-level. For a certain item, some parts of the latent features are more relevant to predict the subsequent items. For example, for a big fan of Robert Downey Jr., after watching Iron Man I and Iron Man II, it is better to recommend Iron Man III rather than Aquaman, although Aquaman is also a superhero movie. Thus, to capture the representative item features based on users' long-term preferences is a necessary point to capture.</p><p>Embedding Layer. In the proposed module, the input is a sequence of |L| items, where each item is represented by a unique index. At the embedding layer, the item index is converted into a low-dimensional real-valued dense vector representation by an item embedding matrix E ∈ R d ×N , where d is the dimension of the item embedding and N is the number of items. After converted by the embedding layer, the item subsequence embeddings are <ref type="figure">Figure 2</ref>: The architecture of HGN. HGN consists of three major components: the embedding layer, the hierarchical gating layer, and the prediction layer. Specifically, F Gating denotes the feature gating module, I Gating denotes the instance gating module, Aggregation denotes the aggregation layer, and ⊗ denotes the element-wise multiplication.</p><p>represented as:</p><formula xml:id="formula_0">S i,l =       | | | ... e j−1 e j e j+1 ... | | |       where S i,l ∈ R d × |L |</formula><p>indicates the embeddings of the l-th subsequence of user i, e j ∈ R d is the j-th column of the embedding matrix E.</p><p>Gated Linear Unit. Inspired by the gated linear unit (GLU) proposed by Dauphin et al. in <ref type="bibr" target="#b3">[4]</ref>, which is utilized to control what information should be propagated for predicting the next word in the language modeling task, we also adopt a similar model to select what features are relevant to predict future items. The GLU in the original paper is shown:</p><formula xml:id="formula_1">(X * W + b) ⊗ σ (X * V + c),</formula><p>where X is the input embeddings, W, V, b, c are learnable parameters, σ is the sigmoid function, * is the convolution operation, and ⊗ is the element-wise product between matrices.</p><p>Personalized Feature Gating. However, directly applying the GLU to select item features does not explicitly consider the user preference on items. For a certain item, a user may just focus a specific part of the item and neglect other unattractive parts. For example, a user may only care about whether the starring role is Tom Cruise rather than the movie content.</p><p>Therefore, to capture the item features that tailored to users' preferences, we need to modify the GLU to be user-specific. To reduce the number of learnable parameters, we apply the inner product instead of the convolution operation in the original GLU (the superscript F indicates the item sequence embeddings are learned from the feature gating module):</p><formula xml:id="formula_2">S F i,l = S i,l ⊗ σ (W д 1 · S i,l + W д 2 · u i + b д ),<label>(1)</label></formula><p>where u i ∈ R d is the embedding of user i, W д 1 , W д 2 ∈ R d ×d and b д ∈ R d are learnable parameters, and ⊗ is the element-wise product between matrices. By doing this, user-specific features of items can be passed to downstream layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Instance Gating</head><p>Personalized Instance Gating. Since our formulated problem is: given |L| successive items, how likely other items will appear after L in the near feature, we argue that there are some items are more relevant in L to predict the items users will interact. However, existing works either do not consider the representative items in L <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b33">34]</ref> or apply attention models to capture the representative items <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20]</ref>. Unlike previous works benefiting from attention models, we adopt an instance-level gating module to select the informative items that are helpful to predict items in the near future according to users' preferences:</p><formula xml:id="formula_3">S I i,l = S F i,l ⊗ σ (w ⊤ д 3 · S F i,l + u ⊤ i · W д 4 ),<label>(2)</label></formula><p>where S I i,l ∈ R d ×|L | is the sequence embedding after the instance gating, w д 3 ∈ R d , W д 4 ∈ R d ×|L | are learnable parameters. By applying the instance gating, the representative items will contribute more to make predictions about the future items and irrelevant items will be largely neglected.</p><p>Aggregation Layer. To make the item embeddings S I i,l into one group-level latent representation, we can either apply average pooling or max pooling on S I i,l :</p><formula xml:id="formula_4">s avд i,l = avд − poolinд(S I i,l ),<label>(3)</label></formula><formula xml:id="formula_5">s max i,l = max − poolinд(S I i,l ),<label>(4)</label></formula><p>where s avд i,l , s max i,l ∈ R d . Since the item embeddings have manipulated by the feature-level and instance-level gating modules, the informative features and items have been selected and irrelevant ones have been eliminated. Thus, the average pooling will accumulate the informative parts in these embeddings. On the other hand, max-pooling directly selects the most representative features from each embedding to form the group-level representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Item-item Product</head><p>The relation between two single items is an important factor to model in the recommendation task and has been widely studied in many years <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25]</ref>, e.g., item-based collaborative filtering methods utilizing the rating vectors of two items to calculate the similarity. However, most of the recent works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34]</ref> only consider the sequential recommendation from the group-level, but do not explicitly capture the item-item relations between the items in L and the items user will interact in the future. Since strongly related item pairs will appear in L and T simultaneously. Unlike previous works, we apply the inner product between the input item embeddings and the output item embeddings to capture the item relations between L and T :</p><formula xml:id="formula_6">e j ∈S i,l e ⊤ j · Q,</formula><p>where Q ∈ R d ×N is the output item embeddings, the sum of multiplication results captures the accumulated item-item relation scores from each item in L to all other items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prediction Layer</head><p>After applying the hierarchical gating network to capture the shortterm interests of users and item-item product to capture the relevant item pairs, we adopt the classical matrix factorization term to capture the global and long-time interests of users. Given the l-th subsequence to predict, the prediction score of user i on item j is:</p><formula xml:id="formula_7">r i, j = u ⊤ i · q j + s avд⊤ i,l · q j + e k ∈S i,l e ⊤ k · q j ,<label>(5)</label></formula><p>where q j ∈ R d is the j-th column of the output item embedding Q.</p><p>In the prediction layer, the first term captures the user long-term interests, the second term models the user short-term interests, and the third term reflects the relations between item pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Network Training</head><p>As the training data is from the user implicit feedback, we optimize the proposed model by the Bayesian Personalized Ranking objective <ref type="bibr" target="#b28">[29]</ref>: optimizing the pairwise ranking between the positive and nonobserving items:</p><formula xml:id="formula_8">arg min U,Q,E,Θ (i, L i , j,k )∈ D −loдσ (r i, j −r i,k )+λ(||U|| 2 +||Q|| 2 +||E|| 2 +||Θ|| 2 ),<label>(6)</label></formula><p>where L i denotes one of the |L| successive items of user i, j denotes the item that in T i , and k denotes the randomly sampled negative item, Θ is the parameters in the gating network, λ is the regularization parameter. By minimizing the objective function, the partial derivatives with respect to all the parameters can be computed by gradient descent with back-propagation. We apply Adam <ref type="bibr" target="#b18">[19]</ref> to automatically adapt the learning rate during the learning procedure.</p><p>Time complexity. The computational complexity of our model for each L is mainly due to the feature gating layer and item-item product module, which is O(|L|d 2 + |L|Nd) (|L| is the length of L, d is the dimension of embeddings, and N is the number of items). This computational complexity makes our model scalable on large datasets. We empirically test the training speed with other stateof-the-art methods and find that our model is faster than other methods (section 5.7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we evaluate the proposed model with the state-ofthe-art methods on five real-world datasets 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>The proposed model is evaluated on five real-world datasets from various domains with different sparsities: MovieLens-20M <ref type="bibr" target="#b5">[6]</ref>, Amazon-Books and Amazon-CDs <ref type="bibr" target="#b8">[9]</ref>, Goodreads-Children and Goodreads-Comics <ref type="bibr" target="#b37">[38]</ref>. MovieLens-20M is a user-movie dataset collected from the MovieLens website, where this dataset has 20 million usermovie interactions. The Amazon-Books and Amazon-CDs datasets are adopted from the Amazon review dataset 2 with different categories, i.e., CDs and Books, which cover a large amount of user-item interaction data, e.g., user ratings and reviews. Goodreads-Children and Goodreads-Comics datasets 3 are collected in late 2017 from goodreads website with different genres, and we use the genres of Children and Comics. In order to be consistent with the implicit feedback setting, we keep those with ratings no less than four (out of five) as positive feedback and treat all other ratings as missing entries on all datasets. To filter noisy data, we only keep the users with at least ten ratings and the items at least with five ratings. The data statistics after preprocessing are shown in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>For each user, we hold the 70% of interactions in the user sequence as the training set and use the next 10% of interactions as the validation set for hyper-parameter tuning. The remaining 20% constitutes the test set for reporting model performance. Note that during the testing procedure, the input sequences include the interactions in both the training set and validation set. The execution of all the models is carried out five times independently, and we report the average results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>We evaluate our model versus other methods in terms of Recall@k and NDCG@k. For each user, Recall@k (R@k) indicates what percentage of her rated items can emerge in the top k recommended items. NDCG@k (N@k) is the normalized discounted cumulative gain at k, which takes the position of correctly recommended items into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Methods Studied</head><p>To demonstrate the effectiveness of our model, we compare to the following recommendation methods. Classical methods for implicit feedback:</p><p>• BPRMF, the Bayesian Personalized Ranking based matrix factorization <ref type="bibr" target="#b28">[29]</ref>, which is a classic method for learning pairwise personalized rankings from user implicit feedback. Specifically, we use BPR-MF for model learning.</p><p>State-of-the-art session-based recommendation methods:</p><p>• GRU4Rec, gated recurrent unit for recommendation <ref type="bibr" target="#b12">[13]</ref>, which uses recurrent neural networks to model user-item interaction sequences for session-based recommendation. Each user sequence is treated as a session. • GRU4Rec+, an improved version of GRU4Rec <ref type="bibr" target="#b11">[12]</ref>, which adopts a different loss function and sampling strategy, and shows significant performance gains on Top-N recommendation. • NextItNet, the next item recommendation net <ref type="bibr" target="#b41">[42]</ref>, applies dilated convolutional neural networks to increase the receptive fields without relying on the pooling operation.</p><p>State-of-the-art sequential recommendation methods:</p><p>• Caser, convolutional sequence embedding model <ref type="bibr" target="#b33">[34]</ref>, which captures high-order Markov chains by applying convolution operations on the embeddings of the |L| recent items. • SASRec, self-attention based sequential model <ref type="bibr" target="#b17">[18]</ref>, which uses an attention mechanism to identify relevant items for predicting the next item.</p><p>The proposed method:</p><p>• HGN, the proposed model, applies a hierarchical gating network to learn the group-level representations of a sequence of items and adopts the item-item product to explicitly capture the item-item relations.</p><p>Given our extensive comparisons against the state-of-the-art methods, we omit comparisons with methods such as FMC and FPMC <ref type="bibr" target="#b29">[30]</ref>, Fossil <ref type="bibr" target="#b7">[8]</ref>, since they have been outperformed by the recently proposed Caser and SASRec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experiment Settings</head><p>In the experiments, the latent dimension of all the models is set to 50. For those session-based methods, we treat each user sequence as one session. For GRU4Rec and GRU4Rec+, we find that when the learning rate is 0.001, and batch size is 50 can achieve good performance. These two methods adopt Top1 loss and BPR-max loss, respectively. For NextItNet, we following the original settings in the paper to set the learning rate to 0.001, the kernel size to 3, the dilated levels to 1 and 2, the batch size to 32. For Caser, we follow the settings in the author-provided code to set |L| = 5, |T | = 3, the number of horizontal filters to 16, the number of vertical filters to 4, where Caser can achieve good results. For SASRec, we set the number of self-attention blocks to 2, the batch size to 128, and the maximum sequence length to 50. The network architectures of   above methods are also set the same with the original papers. The hyper-parameters are tuned using the validation set. For HGN, we follow the same setting in Caser to set |L| = 5 and |T | = 3, where the length effects are shown in the section 5.8. Hyper-parameters are tuned by grid search on the validation set. The network embedding size d is also set to 50. The learning learning rate and λ are set to 0.001 and 0.001, respectively. The batch size is set to 4096. Our experiments are conducted with PyTorch 4 running on GPU machines (Nvidia GeForce GTX 1080 Ti).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Performance Comparison</head><p>The performance comparison results are shown in <ref type="figure" target="#fig_1">Figure 3</ref>, 4, 5, 6, 7, and <ref type="table">Table 3</ref>.</p><p>Observations about our model. First, the proposed model-HGN, achieves the best performance on five datasets with all evaluation metrics, which illustrates the superiority of our model. Second, HGN achieves better performance than SASRec. The reasons are three-fold: (1) SASRec only applies the instance-level selection but neglecting the feature-level one, which plays an important role in learning short-term user interests (section 5.6); (2) SASRec adopts <ref type="table">Table 3</ref>: The performance comparison of all methods in terms of Recall@10 and NDCG@10. The best performing method is boldfaced. The underlined number is the second best performing method. * , * * , * * * indicate the statistical significance for p &lt;= 0.05, p &lt;= 0.01, and p &lt;= 0.001, respectively, compared to the best baseline method based on the paired t-test. Improv. denotes the improvement of our model over the best baseline method.</p><p>BPRMF GRU4Rec GRU4Rec+ NextItRec Caser SASRec HGN Improv.   a hyper-parameter-the maximum sequence length to reduce the computation burden, where only using part of the user data may lead to the insufficient understanding of long-term user interests; (3) SASRec does not explicitly model the item-item relations between two closely relevant items, which is captured by our item-item product module. Third, HGN outperforms Caser, one major reason is that Caser only applies CNNs to learn the group-level representation of several successive items without considering the item importance for different users. Fourth, HGN obtains better results than GRU4Rec, GRU4Rec+, and NextItNet. Two possible reasons are: (1) these models are session-based methods without explicitly modeling the long-term user interests; (2) these methods equally treat all the items in a short context, which may fail to capture the short-term user intentions. Fifth, HGN outperforms BPRMF. Since BPRMF only captures the long-term interests of users, which does not incorporate the sequential patterns of user-item interactions.</p><p>On the top of BPRMF, HGN adopts a hierarchical gating network to capture the sequential dynamics in the user actions and an itemitem product module to explicitly capture the item-item relations, which leads to better performance. Other observations. First, all the results reported on MovieLens-20M, GoodReads-Children and GoodReads-Comics are better than the results on other datasets, the major reason is that other datasets are more sparse and the data sparsity declines the recommendation performance. Second, SASRec outperforms Caser on most of the datasets. The main reason is that SASRec adaptively attends items that would reflect the short-term user interests. Third, SASRec and Caser achieve better performance than GRU4Rec, GRU4Rec+, and NextItNet in most cases. One possible reason is that SASRec and Caser both explicitly plug the user embeddings in their models, which allows the long-term user interests modeling. Fourth, GRU4Rec+ performs better than other methods on one dataset. The reason is that GRU4Rec+ not only captures the sequential patterns in the user-item sequence but also has a promising object function-BPR-max. Fifth, all the methods perform better than BPR. This illustrates that only effectively modeling the long-term user interests is not sufficient to capture the user sequential behaviors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Ablation Analysis</head><p>To verify the effectiveness of the proposed feature gating, instance gating, and item-item product modules, we conduct an ablation analysis in <ref type="table" target="#tab_3">Table 4</ref> to demonstrate the importance each module contributes to the HGN model. In <ref type="formula" target="#formula_2">(1)</ref>, we utilize only the BPR matrix factorization without any other components. In (2), we only incorporate the feature gating and apply the average pooling on the embeddings after the feature gating, on the top of (1). In <ref type="formula" target="#formula_4">(3)</ref>, we replace the average pooling in (2) with max pooling. In (4), we only include the instance gating and apply the average pooling on the top of (1). In <ref type="formula" target="#formula_7">(5)</ref>, we replace the average pooling in (4) with max-pooling.</p><p>In <ref type="formula" target="#formula_8">(6)</ref>, we adopt a recurrent neural network structure-gated recurrent unit (GRU) <ref type="bibr" target="#b2">[3]</ref> to learn the group-level representations of items. In <ref type="formula">(7)</ref>, we replace the GRU in (6) with a convolutional neural network (CNN), where the structure and hyper-parameters are set the same in Caser <ref type="bibr" target="#b33">[34]</ref>. In <ref type="bibr" target="#b7">(8)</ref>, we both apply the feature and instance gating with average pooling. In <ref type="formula">(9)</ref>, we replace the average pooling with max pooling. In <ref type="formula" target="#formula_2">(10)</ref>, we present the overall HGN model to show the significance of the item-item product module. From the results shown in <ref type="table" target="#tab_3">Table 4</ref>, we have some observations. First, from (1) and all others, we can observe that the conventional BPR matrix factorization to capture the long-term user interests cannot effectively model the short-term user interests. Second, from (2), (3), (4) and <ref type="formula" target="#formula_7">(5)</ref>, the feature gating seems to achieve slightly better results than the instance gating. And the average pooling is slightly better than the max pooling, one possible reason is that the average pooling makes the representative item features accumulated, which results in a more effective representation of a group of |L| successive items. Third, from (6), <ref type="bibr" target="#b6">(7)</ref>, and (8), we observe that our hierarchical gating network achieves better performance than GRU and CNN but with fewer learnable parameters 5 (if we set the item embedding size to 50 (d = 50), then the number of learnable parameters of our hierarchical gating network is 5,350, the number of parameters of the one-recurrent-layer GRU is 15,300, the number of parameters of the CNN in <ref type="bibr" target="#b33">[34]</ref> is <ref type="bibr" target="#b25">26,</ref><ref type="bibr">154)</ref>. This result demonstrates that the proposed hierarchical gating network can effectively capture the sequential patterns in the user-item interaction sequence. Lastly, from (1), <ref type="bibr" target="#b7">(8)</ref>, and (9), we observe that by incorporating the item-item product, the performance further improves. The results demonstrate that explicitly capturing the relations between the items users accessed and those items users may interact in the future can provide a significant supplementary to model the user sequential dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Training Efficiency</head><p>In this section, we evaluate the training efficiency with other stateof-the-art methods in terms of the training speed (time taken for one epoch of training). Since GRU4Rec+ has been compared with SAS-Rec in <ref type="bibr" target="#b17">[18]</ref>, we omit the training time comparison with GRU4Rec+. To make a fair comparison, we set the max sequence length of SASRec as 300 to cover more than 95% of the sequence. All the experiments are conducted on a single GPU of Nvidia GeForce GTX 1080 Ti. All the compared methods are executed 20 epochs and we report the average computation time, which is shown in Table <ref type="bibr" target="#b4">5</ref> We verified the number of parameters of all three models by the named_parameters() function provided by PyTorch.  From the results in <ref type="table" target="#tab_4">Table 5</ref>, we can observe that HGN yields the fastest training speed on all datasets. As we have discussed in section 4.4, our model has less item complexity than SASRec, which is O(N 2 d + Nd 2 ). Thus, our proposed model has better training efficiency both theoretically and practically.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">The Sensitivity of Hyper-parameters</head><p>We present the effect of two hyper-parameters: the dimension of the item embeddings d and the length of successive items |L| and |T |. The effects of these two parameters are shown in <ref type="figure">Figure 8</ref> and <ref type="table" target="#tab_5">Table 6</ref>. Due to the space limit, we only present the effects on two datasets, the parameter effects on other datasets have similar trends.</p><p>The variation of d is shown in <ref type="figure">Figure 8</ref>. We can observe that a small dimension of item embeddings is not sufficient to express the latent features of items. By increasing the dimension of item embeddings, the model has more capacity to model the complex features of items. With the increase of d, the model performance largely improves and becomes steady.</p><p>The variation of |L| and |T | is shown in <ref type="table" target="#tab_5">Table 6</ref>. We observe that when |L| is fixed, a larger value of |T |, i.e. 3, can achieve better performance. This may illustrate that a group of |L| items may determine several items that user will interact in the near future. We also observe that smaller |L| has better results than larger ones. One possible reason is that larger |L| may include too many irrelevant items for predicting future items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose a hierarchical gating network with an item-item product module for the sequential recommendation. The model adopts a feature gating module and an instance gating module to control what item features can be passed to downstream layers, where informative latent features and items can be selected. Moreover, we apply an item-item product module to capture the relations between closely relevant items. Experimental results on five real-world datasets clearly validate the performance of our model over many state-of-the-art methods and demonstrate the effectiveness of the gating and item-item product modules.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The performance comparison on MovieLens-20M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>The performance comparison on Amazon-Books.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>The performance comparison on Amazon-CDs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>The performance comparison on Children.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>The performance comparison on Comics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 : 5 .</head><label>85</label><figDesc>The dimension variations of embeddings. Note that the time reported only includes the training time of models without including the negative sampling time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>|=1 0.0260 0.0415 0.1202 0.1684 |L|=3, |T |=2 0.0291 0.0448 0.1275 0.1758 |L|=3, |T |=3 0.0289 0.0450 0.1296 0.1793 |L|=5, |T |=1 0.0254 0.0417 0.1155 0.1645 |L|=5, |T |=2 0.0261 0.0432 0.1215 0.1711 |L|=5, |T |=3 0.0290 0.0456 0.1238 0.1738 |L|=8, |T |=1 0.0220 0.0372 0.1083 0.1566 |L|=8, |T |=2 0.0248 0.0401 0.1142 0.1636 |L|=8, |T |=3 0.0260 0.0413 0.1160 0.1658</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>List of notations.</figDesc><table><row><cell>M, N</cell><cell>the number of users and items</cell></row><row><cell>S i</cell><cell>the item sequence of user i</cell></row><row><cell>S i,</cell><cell></cell></row></table><note>l the embeddings of the l-th subsequence of user i W д* , w д* the learnable parameters in the gating layers U the user embedding matrix E the input item embedding matrix Q the output item embedding matrix d the dimension of the embeddingŝ r i, j the prediction score of user i on item j λ the regularization term</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The statistics of datasets.</figDesc><table><row><cell cols="4">Dataset #Users #Items #Interactions Density</cell></row><row><cell cols="2">ML20M 129,797 13,649</cell><cell>9,921,393</cell><cell>0.560%</cell></row><row><cell>Books</cell><cell>52,406 41,264</cell><cell>1,856,747</cell><cell>0.086%</cell></row><row><cell>CDs</cell><cell>17,052 35,118</cell><cell>472,265</cell><cell>0.079%</cell></row><row><cell cols="2">Children 48,296 32,871</cell><cell>2,784,423</cell><cell>0.175%</cell></row><row><cell>Comics</cell><cell>34,445 33,121</cell><cell>2,411,314</cell><cell>0.211%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The ablation analysis on GoodReads-Comics and Amazon-Books datasets. F denotes the feature gating module, I denotes the instance gating module, avg denotes the average pooling, and max denotes the max pooling.</figDesc><table><row><cell>Architecture</cell><cell cols="2">Comics</cell><cell cols="2">Books</cell></row><row><cell></cell><cell>R@10</cell><cell>N@10</cell><cell>R@10</cell><cell>N@10</cell></row><row><cell>(1) BPR</cell><cell cols="4">0.0911 0.0802 0.0310 0.0177</cell></row><row><cell>(2) BPR+F+avg</cell><cell cols="4">0.1555 0.1624 0.0361 0.0266</cell></row><row><cell>(3) BPR+F+max</cell><cell cols="4">0.1456 0.1550 0.0355 0.0240</cell></row><row><cell>(4) BPR+I+avg</cell><cell cols="4">0.1538 0.1591 0.0351 0.0254</cell></row><row><cell>(5) BPR+I+max</cell><cell cols="4">0.1489 0.1585 0.0329 0.0241</cell></row><row><cell>(6) BPR+GRU</cell><cell cols="4">0.1456 0.1581 0.0289 0.0216</cell></row><row><cell>(7) BPR+CNN</cell><cell cols="4">0.1305 0.1387 0.0278 0.0207</cell></row><row><cell>(8) BPR+F+I+avg</cell><cell cols="4">0.1635 0.1791 0.0391 0.0250</cell></row><row><cell cols="5">(9) BPR+F+I+max 0.1569 0.1658 0.0355 0.0234</cell></row><row><cell>(10) HGN</cell><cell cols="4">0.1743 0.1927 0.0429 0.0298</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>The training time per epoch comparison on five datasets in terms of seconds.</figDesc><table><row><cell></cell><cell>CDs</cell><cell cols="3">Books ML20M Children Comics</cell></row><row><cell>HGN</cell><cell cols="2">0.957s 2.086s 28.304s</cell><cell>3.496s</cell><cell>2.228s</cell></row><row><cell cols="3">SASRec 2.242s 16.154s 39.937s</cell><cell>14.913s</cell><cell>10.468s</cell></row><row><cell>Caser</cell><cell cols="2">5.063s 17.577s 63.702s</cell><cell>28.593s</cell><cell>25.657s</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>The effect of the length |L| and |T |.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code is available on Github: https://github.com/allenjack/HGN 2 http://jmcauley.ucsd.edu/data/amazon/ 3 https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://pytorch.org/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sequential Recommendation with User Memory Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongteng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
	<note>Yixin Cao, Zheng Qin, and Hongyuan Zha</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Where You Like to Go Next: Successive Point-of-Interest Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. IJCAI/AAAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2605" to="2611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Çaglar</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language Modeling with Gated Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grangier</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML (Proceedings of Machine Learning Research)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. ijcai.org</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1725" to="1731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The MovieLens Datasets: History and Context. TiiS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Translation-based Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys. ACM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM. IEEE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Collaborative Filtering. In WWW. ACM</title>
		<imprint>
			<biblScope unit="page" from="173" to="182" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast Matrix Factorization for Online Recommendation with Implicit Feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR. ACM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="843" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Session-based Recommendations with Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno>abs/1511.06939</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Linas Baltrunas, and Domonkos Tikk</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Kang</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Collaborative Metric Learning. In WWW</title>
		<imprint>
			<biblScope unit="page" from="193" to="201" />
			<date type="published" when="2017" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collaborative Filtering for Implicit Feedback Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Jian</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="505" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">FISM: factored item similarity models for top-N recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Kabbur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD. ACM</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="659" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Self-Attentive Sequential Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural Attentive Session-based Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM. ACM</title>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Modeling User Exposure in Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="951" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gated Attentive-Autoencoder for Content-Aware Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM. ACM</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="519" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Point-of-Interest Recommendation: Exploiting Self-Attentive Autoencoders with Neighbor-Aware Influence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingxue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Comprehensive Survey of Neighborhood-Based Recommendation Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems Handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="37" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">One-Class Collaborative Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><forename type="middle">Nan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajan</forename><forename type="middle">M</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interacting Attention-gated Recurrent Networks for Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bozzon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M J</forename><surname>Tax</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM. ACM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys. ACM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">BPR: Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Factorizing personalized Markov chains for next-basket recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Restricted Boltzmann machines for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML (ACM International Conference Proceeding Series)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">227</biblScope>
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Badrul Munir Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">End-To-End Memory Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Regularizing Matrix Factorization with User and Item Embeddings for Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyumin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyumin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<title level="m">Signed Distancebased Deep Memory Recommender</title>
		<imprint/>
	</monogr>
	<note>n.d.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Attention is All you Need. In NIPS</title>
		<imprint>
			<biblScope unit="page" from="6000" to="6010" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Item recommendation on monotonic behavior chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengting</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys. ACM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="86" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Collaborative Deep Learning for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD. ACM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Collaborative Denoising Auto-Encoders for Top-N Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM. ACM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep Matrix Factorization Models for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Hong-Jian Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. ijcai.org</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3203" to="3209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A Simple Convolutional Generative Network for Next Item Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Arapakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM. ACM</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
