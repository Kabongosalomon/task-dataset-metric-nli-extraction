<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Solar Cell Surface Defect Inspection Based on Multispectral Convolutional Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyong</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The School of Artificial Intelligence</orgName>
								<orgName type="institution">Hebei University of Technology</orgName>
								<address>
									<postCode>300130</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Intelligent Rehabilitation Equipment and Detection Tech-nology Engineering Research Center of Ministry of Educa-tion</orgName>
								<address>
									<postCode>300130</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Pang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The School of Artificial Intelligence</orgName>
								<orgName type="institution">Hebei University of Technology</orgName>
								<address>
									<postCode>300130</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qidi</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The School of Artificial Intelligence</orgName>
								<orgName type="institution">Hebei University of Technology</orgName>
								<address>
									<postCode>300130</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Liu</surname></persName>
							<email>liukun@hebut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">The School of Artificial Intelligence</orgName>
								<orgName type="institution">Hebei University of Technology</orgName>
								<address>
									<postCode>300130</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Intelligent Rehabilitation Equipment and Detection Tech-nology Engineering Research Center of Ministry of Educa-tion</orgName>
								<address>
									<postCode>300130</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Liu</surname></persName>
						</author>
						<title level="a" type="main">Solar Cell Surface Defect Inspection Based on Multispectral Convolutional Neural Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1 / 14</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>machine vision</term>
					<term>solar cell</term>
					<term>deep learning</term>
					<term>defection inspection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Similar and indeterminate defect detection of solar cell surface with heterogeneous texture and complex background is a challenge of solar cell manufacturing. The traditional manufacturing process relies on human eye detection which requires a large number of workers without a stable and good detection effect. In order to solve the problem, a visual defect detection method based on multi-spectral deep convolutional neural network is designed in this paper. Firstly, a selected convolutional neural network (CNN)model is established. By adjusting the depth and width of the model, the influence of model depth and kernel size on the recognition result is evaluated. The optimal convolutional neural network model structure is selected. Secondly, the light spectrum features of solar cell color image are analyzed. It is found that a variety of defects exhibited different distinguishable characteristics in different spectral bands. Thus, a multi-spectral convolutional neural network model is constructed to enhance the discrimination ability of the model to distinguish between complex texture background features and defect features. Finally, some experimental results and K-fold cross validation show that the multi-spectral deep convolutional neural network model can effectively detect the solar cell surface defects with higher accuracy and greater adaptability. The accuracy of defect recognition reaches 94.30%. Applying such an algorithm can increase the efficiency of solar cell manufacturing and make the manufacturing process smarter.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As one of the most important renewable energy sources, solar energy is gaining more and more attention. However, in the manufacturing process, solar cells will have some surface defects, including broken gates, pasting spot, thick lines, dirty cells, missing corners, scratches, chromatic aberrations, etc. Solar cells with defects should be detected and eliminated in time to avoid the quality damage of solar cell module in the next step of production. Therefore, surface defect detection of solar cells plays a key role in controlling the quality of solar cell products during manufacturing process <ref type="bibr" target="#b0">[1]</ref> .</p><p>As machine vision develops rapidly, an image-based defect detection method has been employed for solar cell surface quality controlling in manufacturing industry. Solar cell surface quality inspection can not only improve the production quality of the solar cell module, but also increase the lifetime of the solar cell module. Generally, solar cells are divided into monocrystalline silicon and polysilicon by the production materials. The monocrystalline silicon solar cell has a uniform background texture.</p><p>The defect detection object of this paper is polycrystalline silicon solar cells. The surface of polycrystalline silicon solar cells contains a large number of lattice particles with random shapes and sizes, which are randomly distributed in different directions and locations. Moreover, the color features of surface defects in such complex background vary randomly. Thus, the non-uniform backgrounds and complex textures bring a huge challenge for visual inspection of multiple defects of solar cell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related works on solar cell surface detection</head><p>In order to reliably obtain the surface defect characteristics, some feature extraction methods are effective when image intensity consistency is satisfied. The existing surface defect detection methods based on machine vision can be classified into four categories in term of texture surface features: 1) non-textured surface; 2) repeated pattern surface; 3) homogeneouslytextured surface;4) non-homogeneously-textured surface. For non-textured surface images, such as sheet steel <ref type="bibr" target="#b1">[2]</ref> <ref type="bibr" target="#b2">[3]</ref>, glass screen <ref type="bibr" target="#b4">[5]</ref> or integrated circuit <ref type="bibr" target="#b4">[5]</ref> ,the commonly used texture features are statistical measures <ref type="bibr" target="#b5">[6]</ref>, for instance first-order statistics (i.e., mean and variance) and second-order statistics <ref type="bibr" target="#b6">[7]</ref>. For repeated pattern surface images, such as textile fabrics <ref type="bibr" target="#b7">[8]</ref>., semiconductor wafers <ref type="bibr" target="#b8">[9]</ref>.. The detection algorithms usually use template matching methods between current image and self-generating template. For homogeneously-textured surface images, the texture pattern shows high similarity everywhere in the image, such as wood inspection <ref type="bibr" target="#b9">[10]</ref>, there are two kinds of defect detection method, spatial and spectral approaches. In the spatial domain, defect can be effectively identified with statistics features derived from co-occurrence matrices <ref type="bibr" target="#b10">[11]</ref>. In the spectral domain, PJR Torres et.al <ref type="bibr" target="#b11">[12]</ref> proposes an algorithm for checking thermal fuses with machine vision to detect four different defects. For non-homogeneously-textured surface images, such as marble or granite, the Ref <ref type="bibr" target="#b12">[13]</ref>. constructed a feature extraction system for marble tile inspection by employing eight Gabor filters. Liu et.al <ref type="bibr" target="#b13">[14]</ref> proposed a texture edge detection method that includes encoding and prediction modules for texture inspection. Mirmehdizai <ref type="bibr" target="#b14">[15]</ref> presented an automatic defect detection method for random color texture surface. However, the detection of surface defects of solar cells is a multi-feature extraction and detection problem under a non-uniform texture background. The polycrystalline solar cell always shows the complex surface with inhomogeneous texture and non-Gaussian color distribution. One of typical features of these defects is that they have different characteristics in different spectral ranges.</p><p>Many existing solar cell defect detection methods focus on the analysis of electroluminescence (EL) infrared images under 1000nm-1200nm wave length. Chiou et al. <ref type="bibr" target="#b15">[16]</ref> developed a regional growth detection algorithm to extract cracks defect 2 / 14 from the captured images. Fu et al. <ref type="bibr" target="#b16">[17]</ref> proposed a method for detecting cracks in solar cells using machine vision. This method can only identify defects on the edge of the cell and has no significant effect on internal defects. Anwar <ref type="bibr" target="#b17">[18]</ref> proposed an improved anisotropic diffusion filter and image segmentation algorithm for the detection of micro-cracks in polycrystalline silicon solar cells with a detection result of 88%. This method is only applicable to micro-crack detection and cannot detect multiple defects. Tsai et al. <ref type="bibr" target="#b18">[19]</ref> proposed a method based on independent component analysis to evaluate the reconstruction error between the detected image and the reconstructed image to detect the defects. This method can cause erroneous detection of defects in non-uniform light areas. Tsai also proposed a clustering algorithm for solar cell surface defect detection. The algorithm uses binary tree clustering algorithm to cluster the distribution of multiple sets of training data and determines the defect type by calculating the distance between classes. Ordaz <ref type="bibr" target="#b19">[20]</ref> used the gray distribution histogram in the EL image of the cell for analysis. However, this method can only obtain the gray region distribution and statistical information of the image. It is unable to extract and distinguish the texture features, and it lacks the ability to recognize local small defects. Unfortunately, this method only has significant effect on linear features and performs poorly on other defections in the image with visible light spectrum. Qian et al. <ref type="bibr" target="#b20">[21]</ref>. reviewed the typical types of solar cell surface defects and evaluated current popular machine vision detection algorithms. For the four types of defects, the accuracy rate on the test data set reached about 95%. However, the features depend on manual selection and the number of experimental samples is small. The above shortcomings restrict the adaptability. Li et al. <ref type="bibr" target="#b21">[22]</ref> proposed a discriminant method based on wavelet transform for the detection of defects in polycrystalline silicon solar cells. The experimental results show that the method has good effects on fingerprints, dirty marks, etc. However, the effect of sharp edges on the edges is poor and it cannot be applied to all defects. Yao et al. <ref type="bibr" target="#b22">[23]</ref> used Robust Principal Component Analysis (RPCA) to separate the background information and defect information of the solar cell defect picture and judged the defect through the decomposed defect information. This method requires a template. If the production batch is inconsistent and the illumination of the light source is uneven, the template needs to be re-selected. Therefore, the adaptability is limited. The above-mentioned traditional feature extraction methods rely heavily on the selection of artificial features, resulting in limited adaptability of the defect detection of solar cells under complex backgrounds.</p><p>Solar cell surface defects under visible spectrum are various, including broken gates, paste spot, thick lines, dirty cell, missing corners, scratches, color differences, etc. The non-uniform background, complex textures and Non-Gaussian color distribution weaken defect discernable feature. The gaps of color and lattice between different polysilicon cells are also quite large. This leads to the existing manually image feature extracting methods are difficult to effectively perceive the multiple types of defect information in different light spectrum range. The reason lies in the fact that the defect features of the algorithms depend on manual selection, which is hard to represent some features in the multispectral images.</p><p>Deep learning uses a large amount of data to train deep learning models, including a large number of low and high-level features. Wang et al. <ref type="bibr" target="#b23">[24]</ref> applied deep confidence neural networks to the detection of cracks and missing corners of solar cells. The deep belief network is an unsupervised learning method that can reconstruct a defect-free model based on the current image. However, the number of data sets used in this method is small. Moreover, there have been no reports about surface defect detection of solar cells using deep learning.</p><p>In recent years, the CNN and its variants have been preliminary studied in the field of surface defects detection such as textiles, strip steel, and buildings <ref type="bibr" target="#b24">[25]</ref>. Weimer <ref type="bibr" target="#b25">[26]</ref> et al. used the deep convolutional neural networks to detect surface defect datasets such as textile and steel in 2016. This paper discussed the effect of depth and width of the CNN model on test results. Wang et al. <ref type="bibr" target="#b26">[27]</ref> proposed a new deep CNN model structure in 2017. The model uses all types of defect-free and defect samples together as input, and the output is a 12-class classifier: 6 non-defective and 6 defectives. However, the dataset is small and may have problems of overfitting. In order to solve the problem that there is not enough labelled data in the defect detection, Kim <ref type="bibr" target="#b27">[28]</ref> and others proposed a defect detection algorithm based on transfer learning. The paper transferred the weight parameters of other models to the current defect detection model to achieve sharing of weights and easing overfitting. Lin et al. <ref type="bibr" target="#b28">[29]</ref> first apply a convolutional neural network to the LED surface and realized the identification and positioning of various defects. And the accuracy reaches 94%. However, the datasets which are studied in the above several literatures are single-channel images and it is difficult to describe and deal with the multi-spectral characteristics of complex surface defects in solar cells. As to solar cell test, there are a few researches based on CNN. Pierdicca, R., et al. <ref type="bibr" target="#b29">[30]</ref>. used convolutional neural networks to detect remote sensing images of solar cells and identify broken cells in the solar cell module. The author successfully applies CNN to solar cell defect detection. The disadvantage is that the precision of CNN in this paper is about 70% due to the low-resolution remote sensing images of solar modules. S Deitsch et al. <ref type="bibr" target="#b30">[31]</ref> applied a convolutional neural network for EL image detection of solar cells and was able to detect various EL defects. Comparing with the traditional machine vision method, the algorithm in this paper achieves 88.36% accuracy on the dataset, which increase by 6 percentage points. At the same time, the detection speed of the algorithm meets the requirements of real-time production.</p><p>To achieve the defect inspection of solar cell surface, we have to deal with two major problems. One problem is to significantly highlight multiple defects characteristics by employing multiple spectrum information. The other is automatic multi-spectrum feature extraction and inspection of solar cell surface.</p><p>In this paper, focusing on the visual intelligent detection of surface defects in polycrystalline silicon cells based on deep learning, the high dynamic camera is used to collect the multispectral images of solar cells. Then the defect dataset of solar cells is established. Next, the optimized design of solar cell convolutional neural network model is achieved. Finally, a multi-spectral convolutional neural network model is proposed based on the CNN optimization model. The detection accuracy and feature extracting ability are significantly improved. The paper has the following research contributions.</p><p>1. The effects of model depth and convolution kernel size variation are evaluated and analyzed in this paper. The solar cell CNN model with optimized CNN model depth and convolution kernel size are established, which can better distinguish multi-defect features.</p><p>2. Based on the selected solar cells CNN model, a multi-spectral solar cell CNN network model is proposed so as to extract the multi-spectrum features of solar cell surface. The comparison of Multispectral solar cell CNN models and solar cell CNN models is experimentally analyzed. The cross-validation results prove that the model is robust and adapts to various types of random feature defects and has strong ability to resist over-fitting.</p><p>3.Experiments with multiple classifications are carried out. Experimental results show that error detection occurs more between positive and negative samples. Furtherly, the features of the middle layer are displayed to enhance the interpretability of the model.</p><p>To the best of our knowledge, this is the first paper which solves the solar cell surface defect inspection using a deep learning approach.</p><p>The rest of the paper is organized as follows. In Section 3, the defect dataset of solar cells is established then visual acquisition system of multi-exposure welding images is designed. Furthermore, a multi-spectral solar cell CNN network model is proposed. In Section 4, several comparative experiments including traditional machine learning algorithms, solar cells CNN and Multispectral solar cell CNN are performed, demonstrating the adaptability and robustness of Multispectral solar cell CNNs to complex non-uniform surfaces. Finally, concluding remarks are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>In this section, the multi-spectral characteristics of solar cell surface defects are analyzed, and defect datasets are established. Then the solar cell CNN model and the multi-spectral solar cell CNN model are designed. The effect of model depth and convolution kernel size variation on the detection performance is discussed. The solar cell CNN model structure with the best performance is selected. Furthermore, a multi-spectral solar cell CNN model is proposed to improve the proposed solar cell CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Defect feature analysis and dataset 3.1.1 Multispectral defect feature analysis</head><p>Solar cells appear a complex texture background including irregular lattice features, and grid line features. The shape and location of lattice are random, whose color is similar to background color of solar cell. The grid line is the energized current-conducting part of the cell, which is silver white. The surface defects of solar cells in the visible light spectrum range include chipping, broken gates, leaky paste, dirty sheets, scratches, thick lines, and chromatic aberrations. The shape, size and spectrum characteristics of each defect show a big difference. Some typical defects are shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. Broken gate refers to the breakage and loss of the printed finger lines on the surface of the cell. Paste spot is the dripping of the paste when the cell sheets are printed the grid. Dirty cell refers to large dust or dirt on the solar cell. The thick line indicates that the printed weight of the cell sheet is too heavy and the thickness of the gate line is uneven. Scratches are caused by a sharp object passing over the cell. Destruction refers to the collapse of the blue coating on the edge of the cell, which is generally white. Chromatic aberration is due to firing problems with rainbow colors. The characteristics of solar cell surface defects in different spectrum are shown in <ref type="figure">Fig. 2</ref>. It can be seen that different defects have different contrast in the same spectrum, and the same kind of defect also show different contrast in different spectra. For example, the broken gate, thick line, and dirty cell are more obvious in the red or green spectrum image, while the blue spectrum has poor contrast due to the interference of the lattice background. The paste spot, and color difference are all evident in the three spectra; The scratches are more pronounced in the green and blue spectrum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Multispectral defect dataset</head><p>The actual size of the solar cell used in this paper is 156mm×156mm. The images are collected by a 5 million color camera. After extracting the region of a solar cell, color images with a height and width of 1868×1868 pixels are obtained. During training process, the image needs to be chunked in order to ensure the speed of model training and retain defect information.</p><p>Using slide-splitting <ref type="bibr" target="#b25">[26]</ref> [27] to segment the images into smaller pictures can both expand the dataset and highlight the defect information. Sliding segmentation is widely used in the establishment of deep learning datasets and has a good effect for extending scale, reducing overfitting of data training. The sliding window has a size of 469×469 pixel and moves along the rows and columns over the whole image with a 235-pixel stride. The steps of the sliding-splitting division are as shown in <ref type="figure">Fig. 3</ref>, it takes image blocks of size 469×469 pixel extracted from the original 1828×1828-pixel images as the input. In this way, we can extract 49 small blocks from one original image. After splitting each segmented cell is manually screened and classified. Finally, 15330 undefective images and 5915 defective images are obtained. The types of defects include broken gates, paste spot, dirty cell, thick lines, scratches, and color differences. The specific number of each defect is given in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Solar cell CNN model structure</head><p>Based on the dataset, the three challenging problems about training and inspection of solar cell surface defect mainly include： 1) There are 6 types of defects in the dataset. The characteristics of each defect type are quite different in shape, scale and spectrum; 2) the lattice shape of the polycrystalline silicon cell is random. The background texture features of cells are relatively complex, and the defect features cannot easily be discerned; 3) the surface color of the solar cell is a random non-Gaussian distribution, which causes the random and non-uniform brightness of the solar. Next, solar cell convolutional neural network model will be designed. The convolutional layer (Conv) convolutes on the input image by moving the convolution kernel to extract image features. The convolution kernel is a square filter. The filter size is optional, usually 3x3, 5x5 or 7x7.</p><p>Pooling is also called down-sampling. The effect is to reduce the size of the feature map output by the intermediate process without changing the dimension of the image, so as to reduce the image size and reduce the complexity of the model training calculation. Generally, the calculating methods of the pooling layer include the average pooling, the max pooling, and the Gaussian pooling, among which the max pooling is more suitable for the extraction of image texture detail features.</p><p>Fully Connection: As the last part of the convolutional neural network model, Fully Connection is connected to the Softmax classifier. Each output of the fully connected layer can be considered as multiplying each node of the previous layer by a weight coefficient and finally adding a bias value. The last layer of the fully connection produces the output of entire network. The output has the same number of K neurons as the input label.</p><p>represents the input of the Softmax classifier while ( ) represents the output probability.</p><formula xml:id="formula_0">( ) = ( ) ∑ ( ) =1</formula><p>(1) The above layers are stacked together to form a complete CNN model. The optimal objective function is as follows * = 1 ∑ ( ∫ ( ( ) , ( ) ) + Ω( ))</p><p>(2) Where, * are the set of final parameters while λ represents learning rate. ( ) ( ) indicate the input data and corresponding labels of the network model. Input data ( ( ) , ( ) ) into the network for supervised training and decision making. θ = {w 1 , 1 , … , +1 , +1 } represents weights (network weights and ) of all layers in the network model. Ω(θ) represents regularization hyperparameter used to penalize excessively high network weights to prevent overfitting. CNN uses the difference between the output and the tag to control the change of weight and uses the stochastic gradient descent (SGD) to solve the optimal value of the back propagation of the network model. Activation: Since a linearly structured network cannot fit complex functions, the activation function layer must be a nonlinear function. Typical activation functions are sigmoid, tanh, ReLU and their variants. Among them, ReLU is selected as the activation function in the paper due to its best performance in the ImageNet recognition contest <ref type="bibr" target="#b31">[32]</ref>. It can speed up the random gradient dropping, and its function expression is as follows: are mostly edge-based, max-pooling is chosen as the pooling method of the model. Compared with average pooling, the maximum pooling can better preserve the texture features.</p><p>The solar cell CNN models can extract image features autonomously, but solar cell surface defects have a big difference in different spectra. Therefore, a new model structure is designed based on the Alexnet model. Adjusting the convolution kernel size and network depth to enhance the model's defect discrimination capabilities. The solar CNN model structure is shown in <ref type="figure">Fig. 4</ref>. The different convolution kernel size and feature output sizes of the two models are shown in <ref type="table">Table 2</ref>. <ref type="figure">Fig.4</ref> Structure of solar cell CNN <ref type="table">Table 2</ref> Different structure of solar cell CNN 1 th structure 2 th structure 3 th structure</p><formula xml:id="formula_1">Layer1 Conv1-3×3 Conv1-3×3 Conv1-7×7 Layer2 Conv2-3×3 Conv2-3×3 Conv2-5×5 Conv3-3×3 Conv3-5×5 Layer3 Conv3-3×3 Conv4-3×3 Conv4-3×3 Conv5-3×3 Conv5-3×3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">The depth and convolution kernel size selection of solar cell CNN</head><p>The depth and convolution kernel size of the CNN model have a significant influence on the test results <ref type="bibr" target="#b25">[26]</ref>. The depth of the model refers to the number of convolution layers in the model. Changes in the kernel size in the convolutional layers also affect the characteristics extracted from the image. The deeper CNN can be, the more advanced the features extracted; the larger the convolutional kernel is, the more surrounding information the extracted features contain. Referring to the literature on the use of CNN models to deal with surface defects in recent years <ref type="bibr" target="#b26">[27]</ref>[28]Error! Reference source not found., the influences of depth and width changes of CNN models on the final results are significant. According to the above literature, the following three model depths and convolution kernel sizes are compared. Finally, the best-performing model structure is determined for subsequent multi-spectral solar cell CNN model experiments. The three model structures are shown in <ref type="table">Table 2</ref>, in which Convi-j×j (i=1,2,3,4,5. j=3,5,7) represents the i -th convolution layer, and the convolution kernel size is j× j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The Multispectral solar cell CNN model structure</head><p>Some defects are prominent in some spectra while weak in others. Solar CNN models can extract features in the mixed spectrum. Some defect features of solar cells are located on the gate lines, such as thick lines, broken gates, etc., while the others are in the background, such as scratches, dirty cells, paste spots, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 5 Multispectral solar cell CNN structures Layer1</head><p>Layer2 Layer3 </p><formula xml:id="formula_2">Conv1 pooling1 Conv2 Relu Conv3 Relu pooling2 Conv5 Conv4 Relu pooling3 256×256×3 FC1 512 FC2 512 Dropout Softmax Layer1-R Layer2-R Layer3-R Conv1-R pooling1 Conv2-R Relu Conv3-R Relu pooling2 Conv5-R Conv4-R Relu pooling3 Conv1-G pooling1 Conv2-G Relu Conv3-G Relu pooling2 Conv5-G Conv4-G Relu pooling3 Conv1-B pooling1 Conv2-B Relu Conv3-B Relu pooling2 Conv5-B Conv4-B Relu pooling3 FC1 512 FC2 7 / 14</formula><formula xml:id="formula_3">Layer1 16@7×7 Conv1 256×256×16 Conv1-R Conv1-G Conv1-B 3@256×256×16 2×2 Pool1 128×128×16 Pooling1-R Pooling1-G Pooling1-B 3@128×128×16 Layer2 32@5×5 Conv2 128×128×32 Conv2-R Conv2-G Conv2-B 3@128×128×32 32@5×5 Conv3 128×128×32 Conv3-R Conv3-G Conv3-B 3@128×128×32 2×2 Pool2 64×64×32 Pooling2-R Pooling2-G Pooling2-B 3@64×64×32 Layer3 64@3×3 Conv4 64×64×64 Conv4-R Conv4-G Conv4-B 3@64×64×64 64@3×3 Conv5 64×64×64 Conv5-R Conv5-G Conv5-B 3@64×64×64 22 Pool3 32×32×64 Pooling3-R Pooling3-G Pooling3-B 32×32×192 FC1 512 FC1 FC1 FC2 512 FC2 FC2 Softmax 2 Softmax Softmax</formula><p>Therefore, aiming at the characteristics of distinguishing degree of solar cells surface defects in different spectra, a multi spectral solar cell CNN model is established by extracting three basic networks. The three spectra in the original image are separated and sent to different convolutional neural networks. The output characteristics of the three networks are then connected and fed into the fully connected layer, ultimately producing a predictive output. The multi-spectral solar cell CNN model structure is shown in <ref type="figure">Fig. 5</ref> and <ref type="table" target="#tab_1">Table 3</ref>. There are three parallel feature extraction layers. Conv-R, Conv-G and Conv-B represent convolutional layers of different spectra. ReLU is a nonlinear activation function; Pooling is the maximum pooling, that is, the features of multiple spectra of images. The Multispectral solar cell CNN is composed of maximum value of the feature points in the neighborhood is selected as the output. In the multispectral solar CNN model, mixed features of multiple spectra are extracted. The output dimension of the third convolutional layer is 32x32x64, which contains all the feature information extracted from multiple spectra and is then input to the fully connected layer. The multi-spectral solar cell CNN separates the three spectra of the color image into the convolution pool after inputting the image, and outputs the feature results Layer3_B, Layer3_R, and Layer3_G in the third convolutional layer of the model and combines the three feature results to obtain Layer3. The output feature size is 64×64×192. The output features' size is 64 x 64 x 192, which are then input into the fully connected layer and the final Softmax layer for inspection. Extracting the feature information of the images from the three spectra, since the features of each defect in the different spectra are very distinct, the finally obtained image features are more distinguishable and conducive for defect detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental results analysis and discussion</head><p>The experiment is completed on the Ubuntu 16.04 platform using the TensorFlow framework. The computer's CPU used for training is the Core i7 series, with 32GB memory and two GTX1080 graphics cards. The learning rate of the CNN model and the multi-spectral solar cell CNN model is both chosen as λ=0.0001, and the epochs of training is 10,000. The Dropout neuron ratio is 50%. The experiments in this article are mainly divided into the following three parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Selection of CNN depth, kernel size and stride step</head><p>The design of the CNN model is closely related to different defect datasets. Though the CNN models that detect different defects are similar, the model structures including the depth and the size of the convolution kernel vary. This paper designs three CNN models with different convolutional depths and kernel sizes and selects the best CNN model for solar cells. The training images are fed into the network. Then the trained network is loaded for the test. Each type of defect and non-defective images in the dataset are randomly selected as a test set by 20%, and the test set for the three experiments is the same.</p><p>To more accurately evaluate the vague scratches detection results, we use precision, recall rate and F-measure. Precision measures the exactness or fidelity of detection and segmentation and is calculated in Eq. (4). Recall describes the completeness of detection and segmentation and is defined in Eq. (5). Fmeasure combines precision and recall and is computed in Eq. <ref type="bibr" target="#b5">(6)</ref>. <ref type="table" target="#tab_2">Table 4</ref> shows the precision, recall, and F-measure for the solar cell CNN. (TP represents a true positive, that is, images labeled as defective are correctly detected; FP indicates false positives, that is, images labeled as good are erroneously detected as defective; FN means false negative, that is, images labeled as defective are erroneously detected as non-defective; TN represents a true negative, that is, images labeled as nondefect are correctly detected as non-defect)</p><formula xml:id="formula_4">8 / 14 = + (4) = + (5) − = 2 × × + (6)</formula><p>The experimental results for the three different structures of solar CNN are given in <ref type="table" target="#tab_2">Table 4</ref>, and each experimental result is the average of the 5-fold cross-validation. The experimental results show that the precision of the solar cell CNN model with 5-layer convolutional layer is 2% higher than that of a 3layer convolutional layer CNN model. When the kernel size is increased on the basis of the five-layer convolutional layer CNN model, both precision and recall are improved, but they are all within 0.6%, and the effect is not significantly improved. If the depth of the convolution layer and kernel size are increased the training time of the model will be prolonged and the training pressure will be increased. Therefore, the third model structure is selected as the solar cell CNN model and subsequent experiments are conducted.</p><p>It is considered that deeper network has better ability to extract high-level features and increasing the width of the network can also improve the performance of the network. At the same time, the larger convolution kernel in the low-level feature map has a larger receptive domain, which has a better effect on extracting large-area feature defects <ref type="bibr" target="#b25">[26]</ref>. After the network structure is selected, an experiment to determine the sliding window step size is performed. The size of the image in the dataset is 469x469, which contains exactly the main grid lines on either side, or one main grid line in the center. Therefore, to ensure the stability of all images in the dataset, we choose the quarter length of the original image as the size of the dataset image. In order to ensure the validity of dataset, three sets of images of different sizes are prepared and tested separately. <ref type="table" target="#tab_3">Table 5</ref> shows the results of three different strides based on five-fold cross-validation. The experiment is based on solar CNN. As can be seen from <ref type="table" target="#tab_3">Table 5</ref>, if the splitting stride is too long, many features will be lost, so the classification effect is relatively poor. As for the smaller image dataset, the detection result is also poorer than the middle one. Furtherly, a serious overfitting occurred on the test dataset. The reason is that defective solar cells account for only about 2% of the total production. If the original images are split too small, it will not only affect the recognition speed of the whole battery, but also lead to further imbalance of the proportion of defective samples, resulting in more serious over-fitting. Therefore, Therefore, too small images' segment are also not conducive to the detection of defects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison and Analysis between multispectral solar cell CNN model and solar cell CNN</head><p>The Multispectral solar cell CNN is based on the solar cell convolutional neural network model and analyzes the characteristics of different solar cell surface features defects under different spectra and improved the obtained network structure. To increase the credibility of the training results, this experiment firstly used K-fold cross-validation to traverse all the images to verify that the defect detection result of solar cell CNN has higher reliability <ref type="bibr" target="#b32">[33]</ref>. The K-fold cross-validation experimental procedure is as follows: The data set is divided into K sub-samples, a single sub-sample is reserved as a test set, and another (K-1) sample is used as a training set. The experiment is performed K times, and the average is taken as the final test result. This paper used a 5-fold cross validation.</p><p>By analyzing the performance characteristics of various defect types of the cell under different spectra, it is found that defects such as broken gate, paste spot, thick line, dirty cell, color difference, scratch, have different performance characteristics in different spectra. Some defects are more pronounced in a particular spectrum while they are reduced in other spectra. The multi-spectral solar cell CNN model separates the three spectra of the image to make the features extracted by the model more distinguishable and reduce the false detection rate of defects. In order to verify the effectiveness of the multi-spectral feature separating's extraction, we compared the experimental results of the solar cell CNN model and the multi-spectral solar cell CNN model and used a 5-fold cross validation to traverse all the images. <ref type="table" target="#tab_4">Table 6</ref> shows the 5-floder training and testing dataset. Then the statistics of the detection performance of each type of defect is used to evaluate the performance of various defects by using solar cell CNN and Multi-spectral solar cell CNN. Each time a certain type of defect in the dataset is used to test separately. In order to fully demonstrate the experimental process, <ref type="table" target="#tab_7">Table 7</ref> shows three indicators for each fold of each defect in the five-fold cross-validation, and the average of all the indicators after five experiments.</p><p>In <ref type="table" target="#tab_7">Table 7</ref>, it can be seen that the experiment results show that the multi-spectral solar cell CNN model has improved the detection rate of dirty cell, thick line, broken gate, color difference, and paste spot in the detection of cell defects. Among them, the dirty cell, and broken gate is increased by more than 1%, the scratch detection rate decreased by about 0.5%. The correct detection rate of the non-defective cells is increased by 1.3%. From the longitudinal comparison of five experiments, the correct detection rates of color difference, and dirty cell in the five experimental results of the multi-spectral solar cell CNN model are higher than that of the CNN model. The correct detection rate of five training non-defective images has increased by about 1% to 4%. The defects of thick lines, broken gates, and paste spot are higher than the CNN model's detection results three times in the five experimental results. At the same time the average detection rates are higher. It should be noted that for defect detection, high recall means fewer defects missing. As it can be seen from <ref type="table" target="#tab_7">Table 7</ref>, the recall of multispectral CNN is relatively higher. In addition, from the comparison of the data of the 5-fold cross-validation, it can be seen that there is no large fluctuation in results of each experiment. This also confirms that the multi-spectral CNN model avoids over-fitting well and has better generalization ability. The detection rate of scratches is also higher than the solar cell CNN model three times in the experiment, but the average detection rate is reduced by 0.5%, and the detection rate is lower than other defects. Based on the final test results, the multi-spectral convolutional neural network is better for detecting defects in solar cells.</p><p>All experimental results in <ref type="table" target="#tab_4">Table 6</ref> are counted and the average number of all samples was calculated. The confusion matrix for the multispectral CNN experimental average results is given in <ref type="table" target="#tab_5">Table 8</ref>. The convolutional neural network can autonomously extract low and high-level features of the image itself. The convolution output after the first layer is the low-level features of the image, and the output after the convolution of the last layer is the high-level feature. <ref type="figure">Fig.6</ref> shows the output of the low-level and high-level features of the solar cell CNN model and the multi-spectral solar cell CNN model. <ref type="figure">Fig.6 (a)</ref> is the defect image, <ref type="figure">Fig.6 (b)</ref> and <ref type="figure">Fig.6 (d)</ref> are the low-level features of the output of Layer1 of the two models, and <ref type="figure">Fig.6 (c)</ref> and <ref type="figure">Fig.6 (e)</ref> are the high-level features of the output of Layer3. It can be seen in <ref type="figure">Fig. 2</ref> that the characteristics of the dirty cell in the red and green spectrum are significant, but the performance in the blue spectrum is not obvious. As can be seen in <ref type="figure">Fig.6(d)</ref>, the multi-spectral solar cell CNN model has obvious defect features in low-level features extracted from the red and green spectra. Most of the features extracted in the blue spectrum are lattice features, the defect features are not obvious, and most of the output feature images are pure black. <ref type="figure">Fig.6 (e)</ref> shows the high-level features output of Multispectral solar cell CNN. The defect features extracted from red and green spectra are more accurate and the gray values are higher. The features of lattice and grating lines in the blue spectrum are obvious and there are few defect features.</p><p>Comprehending low and high-level features extracted by multi-spectral solar cell CNN, it can be found that the background texture feature and defect feature of the image are well separated. For dirty cell defects, the features in the red and green spectrums are more pronounced. The multi-spectral solar cell CNN separates the defect features and background features of the dirty cell. Compared with the hybrid spectral feature extraction of solar cell CNN model, the feature extraction ability of multi-spectral solar cell CNN model is strengthened, and the extracted feature is more distinguishable.</p><p>Thus, multi-spectral solar cell CNN model has better adaptability to the different characteristics of solar cell surface defects. And as to other defection like thick line, paste spot or scratches, their features are also more illustrate the adaptability of unknown multi-spectral solar cells samples in some extent.</p><p>Next, the ratio of the training and test sets is 8:2, 6:4, and 4:6 respectively, as is shown in <ref type="table" target="#tab_5">Table 8</ref>. This experiment is conducted to demonstrate that multispectral solar cell convolutional neural networks are still effective when the data set is still a small percentage of overall production data. <ref type="table" target="#tab_6">Table 9</ref> shows the results of three experiments. From <ref type="table" target="#tab_6">Table 9</ref> it can be obtained that as the ratio of the training and test sets increases, the precision, recall and F-measure of multi-spectral solar cell CNN increases slightly. When the ratio of test set to verification set is 4:6, precision is reduced by about five percentage points. The experimental results illustrate the adaptability of unknown multi-spectral solar cells samples in some extent.  <ref type="figure">Fig. 6</ref> The feature of solar cell CNN and multi-spectral solar cell CNN</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-Class Comparison and Analysis of Multispectral solar cell CNN Models and Some Typical Machine Learning Methods</head><p>To furtherly validate the stability of multispectral CNN for different defects, a multi-class experiment is performed the experimental results of solar CNN and multispectral solar cell CNN are shown in <ref type="table" target="#tab_0">Table 10</ref>. The data in <ref type="table" target="#tab_0">Table 10</ref> is the average of the five-fold cross-validation.</p><p>As can be seen from <ref type="table" target="#tab_0">Table 10</ref>, in the multi-classification task, the accuracy of the multi-spectral CNN is 2 to 6 percentage higher than solar cell CNN for each defect. At the same time, misidentification mainly occurs between positive and negative samples compared to defect classes. At the same time, misidentifications mainly occur between positive and negative samples compared to the types of defects. Moreover, compared with the accuracy rate of about 85 percent of the positive and negative samples of the two classifications, the precision of the multi-class is on average 8 percent lower. The accuracy of multi-class classification of defects is lower than binary classifications maybe because the dataset is not balanced. For the specific defect types like scratches or color difference, too few images of certain defective solar cells are an important cause of the decline in multi-classification effects. But in industrial manufacturing, different types of defective solar cells will be collected and reduced to the defective grade. Therefore, binary classification can improve the efficiency of manufacturing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison and Analysis of Multispectral solar cell CNN Models and Some Typical Machine Learning Methods</head><p>The surface defects of solar cells are various, the background is complex, and the features of manual extraction are more difficult. Before the large-scale application of convolutional neural networks, the method of manually extracting features for defect detection is widely used in machine vision. LBP+HOG-SVM and Gabor-SVM have good results in the field of surface defect detection <ref type="bibr" target="#b15">[16]</ref>[35], Among them, LBP stands for Local Binary Pattern, HOG stands for Histogram of Oriented Gradient, and SVM stands for Support Vector Machine. Like the Gabor feature, they are feature descriptors used in traditional machine vision methods. Therefore, the above two commonly used machine learning methods are selected as comparative experiments. <ref type="table" target="#tab_0">Table 11</ref> includes the recall and precision for the four methods of LBP+HOG-SVM, Gabor-SVM and traditional CNN models, Multispectral solar cell CNN models.</p><p>The parameters of LBP+HOG-SVM are as follows: the original images are splitting into 12×12 regions to calculate LBP features with a radius of 1 in 8 neighborhoods. As to Gabor, the cell size is 8×8 while the block size is 2×2 and the overlap is 1×1. The parameters of Gabor-SVM are as follows, the down-sample image' size is 10×10, the Gabor kernel size is 31×31, Gabor kernel's energy preserving ratio is 0.9. Gabor kernel's number is 40, which is in 5 scales and 8 orientations. <ref type="figure">Fig. 7</ref> The Receiver Operation Characteristic (ROC) curves The experimental results are gained by using a 5-fold cross validation experiment. <ref type="figure">Fig.7</ref> shows the receiver operation characteristic curves for the four detection methods. It can be seen from the experimental results that the detection of solar cell surface defects using LBP+HOG-SVM and Gabor-SVM is not very effective. It can be seen that typical machine learning methods like LBP or Gabor with SVM's precision are 10% lower than CNN methods, and the recall are also 8% lower. The reason is that the LBP+HOG and Gabor features are more pronounced for texture features of defects in uniform background. However, there are many surface texture features on the cell surface, including a large number of nondefect background texture features such as lattices and grid lines, which may interfere with training. For machine learning methods that extract features manually, it is too difficult to attempt to express all the surface defect features of solar cell using high level features. Moreover, the defects of the solar cell have the characteristics of random shape and complex background, which makes the traditional machine learning method that requires manual extraction of features to perform the detection method to be less adaptable.</p><p>It can be found for in <ref type="figure">Fig.7</ref> and <ref type="table" target="#tab_0">Table 11</ref> that the Solar CNN model shows stronger ability to distinguish multiple defect features, which helps to effectively solve the complex problem of irregular surface of cell surface defects and the random shape and color features of surface defects. Furthermore, from the experimental results, the multi-spectral solar cell CNN model has a higher accuracy and adaptability to the defect detection problem of random shape and complicated background on the surface of solar cells. It means that the ability of multi-spectral solar cell CNN model to extract features of different spectra is enhanced, and the defect features extracted by the model are more distinguishable.</p><p>The training and detection computation time for the two models are shown in <ref type="table" target="#tab_0">Table 12</ref>. The training time of the multispectral solar cell CNN model is 6771 seconds longer than solar CNN model. However, multi-spectral solar cell CNN can speed up training through multi-threading, the performance of the experimental platform will be further improved. The detection time of the two models was calculated by testing 100 images. The solar CNN model took 3.66s while the multi-spectral solar cell CNN model took 4.25s. The detection time of each picture is within 50 milliseconds, so both neural networks meet the requirements of real-time monitoring. It should be mentioned that the deep learning model can input multiple image tensors at the same time, while the traditional machine vision method needs to read and extract features cyclically, so the total processing time per hundred images is quite different.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Aiming at the wide variety of surface defects, various shapes, and severe background interference, the multi-spectral convolutional neural network model is proposed in this paper. Experimental results show that multi-spectral solar cell CNN model enhances the ability to extract multiple spectral information features, improves the ability to separate defects and background features, and improves the detection rate of most defects. The detection rate of non-defective pictures increased by about 1.4%. Therefore, the multi-spectral solar cell CNN model has higher accuracy and stronger adaptability in the detection of solar cell surface defects.</p><p>Although the multispectral convolutional neural network improves the detection results overall, the inadequacies can also be seen from the experimental data. In the experimental results, multi-spectral solar cell CNN models have relatively low detection rates for defects such as broken gates and scratches, and high detection rates for thick lines, dirty cell, paste spot, color difference. Analyzing the characteristics of these defects, it is found that the area of the broken gates and scratches with low detection efficiency is small and linear. However, the areas of defects such as color difference and dirty cell are relatively large and all had large area defects. The experimental results show that the multi-spectral solar cell CNN has weaker feature extraction ability for small area defects and linear defect defects.</p><p>The time consumed by multi-spectral solar cell CNN to detect 100 images is 3.66s, which only consumes 0.59s more than the 4.25s of the original CNN model. It still meets the processing needs of real-time detection. Subsequent preparations will further optimize the model's ability to identify linear and small-area defects, increase the training speed in a multithreaded training mode, and test the model's ability to recognize more types of surface defects. In the future research, we are going to use the deep learning model to display the features extracted by the convolutional neural network to achieve accurate detection of defect locations. And by using the updated model, like VGG or ResNet as the base network of the RGB model, we will furtherly reduce the training time and over-fitting of the network.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Various surface defects of solar cell Fig.2 Defection in different spectral</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>order to reduce computation time and memory consumption when training the model, solar cell images in dataset are resized to 256×256×3. During model training, L2 regularization and Dropout [33]. are used to prevent overfitting of model training. Dropout refers to the inactivation of some hidden layer nodes of the network at the time of model training. These deactivated nodes do not work in the current training. During convolution and pooling operations, extra padding is performed in the image boundary area to ensure the integrity of images. At the same time, because the features of the defects Training</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The type and number of defection dataset Convolutional neural network (CNN) is a learnable end-toend model that combines feature extraction and inspection. It captures the low and high-level features of images through multiple layers of convolution and pooling, then classifies through the full connection layer. A complete CNN model includes Input, Conv, Activation, Pool, and Fully Connection.</figDesc><table><row><cell>defect</cell><cell>Broken gate</cell><cell>Paste spot</cell><cell>Dirty cells</cell><cell>Thick lines</cell><cell>scratches</cell><cell>Color difference</cell></row><row><cell>amount</cell><cell>1330</cell><cell>1790</cell><cell>1830</cell><cell>361</cell><cell>350</cell><cell>254</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>The architecture and parameters of MS-CNN</figDesc><table><row><cell>Name</cell><cell>kernel</cell><cell cols="2">Solar cells CNN</cell><cell cols="2">Multispectral solar cell CNN</cell></row><row><cell></cell><cell></cell><cell>structures</cell><cell>output</cell><cell>Red-spectral</cell><cell>Green-spectral</cell><cell>Blue-spectral</cell><cell>Output</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Results of different structures of Solar Cell CNN</figDesc><table><row><cell></cell><cell>1 th structure</cell><cell>2 th structure</cell><cell>3 th structure</cell></row><row><cell>precision(%)</cell><cell>85.11</cell><cell>86.16</cell><cell>87.30</cell></row><row><cell>recall(%)</cell><cell>96.00</cell><cell>96.46</cell><cell>97.04</cell></row><row><cell>F-measure</cell><cell>0.9022</cell><cell>0.9041</cell><cell>0.9187</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Results of different strides of Solar Cell CNN</figDesc><table><row><cell></cell><cell>234×234</cell><cell>469×469</cell><cell>623×623</cell></row><row><cell>precision(%)</cell><cell>76.86</cell><cell>87.30</cell><cell>76.85</cell></row><row><cell>recall(%)</cell><cell>95.88</cell><cell>97.04</cell><cell>81.02</cell></row><row><cell>F-measure</cell><cell>0.8532</cell><cell>0.9187</cell><cell>0.7888</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>The division of each experiment</figDesc><table><row><cell>type</cell><cell>training set</cell><cell>test set</cell><cell>sum</cell></row><row><cell>good</cell><cell>12264</cell><cell>3066</cell><cell>15330</cell></row><row><cell>broken gate</cell><cell>1064</cell><cell>266</cell><cell>1330</cell></row><row><cell>paste spot</cell><cell>1432</cell><cell>358</cell><cell>1790</cell></row><row><cell>dirty cell</cell><cell>464</cell><cell>366</cell><cell>1830</cell></row><row><cell>thick line</cell><cell>289</cell><cell>72</cell><cell>361</cell></row><row><cell>scratches</cell><cell>280</cell><cell>70</cell><cell>350</cell></row><row><cell>color difference</cell><cell>203</cell><cell>51</cell><cell>254</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8</head><label>8</label><figDesc>Test sets' result of multi-spectral solar cell CNN</figDesc><table><row><cell></cell><cell>Non-defect</cell><cell>thick line</cell></row><row><cell>Non-defect</cell><cell>3017</cell><cell>49</cell></row><row><cell>thick line defect</cell><cell>10</cell><cell>62</cell></row><row><cell></cell><cell>Non-defect</cell><cell>broken gate</cell></row><row><cell>Non-defect</cell><cell>3015</cell><cell>51</cell></row><row><cell>broken gate</cell><cell>46</cell><cell>220</cell></row><row><cell></cell><cell>Non-defect</cell><cell>scratches</cell></row><row><cell>Non-defect</cell><cell>3006</cell><cell>60</cell></row><row><cell>scratches</cell><cell>20</cell><cell>50</cell></row><row><cell></cell><cell>Non-defect</cell><cell>paste spot</cell></row><row><cell>Non-defect</cell><cell>3032</cell><cell>34</cell></row><row><cell>paste spot</cell><cell>43</cell><cell>315</cell></row><row><cell></cell><cell>Non-defect</cell><cell>color difference</cell></row><row><cell>Non-defect</cell><cell>3023</cell><cell>43</cell></row><row><cell>color difference</cell><cell>1</cell><cell>50</cell></row><row><cell></cell><cell>Non-defect</cell><cell>dirty cells</cell></row><row><cell>Non-defect</cell><cell>2998</cell><cell>68</cell></row><row><cell>dirty cells</cell><cell>18</cell><cell>348</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 9</head><label>9</label><figDesc>Results for three different scale datasets</figDesc><table><row><cell></cell><cell>8:2</cell><cell>6:4</cell><cell>4:6</cell></row><row><cell>precision(%)</cell><cell>88.41</cell><cell>87.53</cell><cell>83.41</cell></row><row><cell>recall(%)</cell><cell>98.40</cell><cell>96.80</cell><cell>96.06</cell></row><row><cell>F-measure</cell><cell>0.9401</cell><cell cols="2">0.9193 0.8929</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc>The results of CNN experiment</figDesc><table><row><cell>Thick line</cell><cell>Broken gate</cell><cell>Scratches</cell><cell>Paste spot</cell><cell>Color differ-ence</cell><cell>Dirty cells</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10</head><label>10</label><figDesc>Multi-class experimental results of solar cell CNN and multi-spectral CNN</figDesc><table><row><cell></cell><cell></cell><cell>Thick line</cell><cell>Broken gate</cell><cell>Scratches</cell><cell>Paste spot</cell><cell>Color difference</cell><cell>Dirty cells</cell><cell>Right</cell></row><row><cell></cell><cell>Thick line</cell><cell>73.61</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>26.39</cell></row><row><cell></cell><cell>Broken gate</cell><cell>0.38</cell><cell>78.20</cell><cell>0</cell><cell>0.38</cell><cell>0</cell><cell>0</cell><cell>21.43</cell></row><row><cell>Solar</cell><cell>scratches</cell><cell>0</cell><cell>1.42</cell><cell>40.00</cell><cell>0</cell><cell>0</cell><cell>5.71</cell><cell>52.85</cell></row><row><cell>cell CNN</cell><cell>Paste spot</cell><cell>0</cell><cell>0</cell><cell>0.83</cell><cell>82.12</cell><cell>0.56</cell><cell>1.12</cell><cell>16.48</cell></row><row><cell></cell><cell>Color difference</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>100</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>Dirty cells</cell><cell>0</cell><cell>0.54</cell><cell>0.27</cell><cell>2.73</cell><cell>0</cell><cell>86.33</cell><cell>10.11</cell></row><row><cell></cell><cell>Right</cell><cell>0.32</cell><cell>0.96</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.64</cell><cell>98.06</cell></row><row><cell></cell><cell>Thick line</cell><cell>76.39</cell><cell>0</cell><cell>0</cell><cell>1.39</cell><cell>0</cell><cell>1.39</cell><cell>20.83</cell></row><row><cell></cell><cell>Broken gate</cell><cell>0</cell><cell>80.45</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.37</cell><cell>18.79</cell></row><row><cell>MS</cell><cell>scratches</cell><cell>0</cell><cell>0</cell><cell>48.57</cell><cell>0</cell><cell>0</cell><cell>4.29</cell><cell>47.14</cell></row><row><cell>Solar Cell</cell><cell>Paste spot</cell><cell>0</cell><cell>0</cell><cell>0.56</cell><cell>82.12</cell><cell>0.28</cell><cell>1.12</cell><cell>15.92</cell></row><row><cell>CNN</cell><cell>Color difference</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>100</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>Dirty cells</cell><cell>0.54</cell><cell>0.54</cell><cell>0</cell><cell>3.00</cell><cell>0</cell><cell>87.16</cell><cell>8.74</cell></row><row><cell></cell><cell>Right</cell><cell>0.32</cell><cell>0.96</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.64</cell><cell>98.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 11</head><label>11</label><figDesc>Different results of training method</figDesc><table><row><cell>Training meth-ods</cell><cell>precision (%)</cell><cell>recall (%)</cell><cell>F-measure</cell></row><row><cell>LBP+HOG-SVM</cell><cell>79.26</cell><cell>89.59</cell><cell>0.84</cell></row><row><cell>Gabor-SVM</cell><cell>74.55</cell><cell>89.26</cell><cell>0.81</cell></row><row><cell>Solar cell CNN</cell><cell>87.30</cell><cell>97.05</cell><cell>0.92</cell></row><row><cell>MS-CNN</cell><cell>88.41</cell><cell>98.40</cell><cell>0.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 12</head><label>12</label><figDesc>Training and detection time</figDesc><table><row><cell></cell><cell>Training time (s)</cell><cell>Detecting time (100 im-ages)</cell></row><row><cell>Solar cell CNN</cell><cell>4869</cell><cell>3.66</cell></row><row><cell>multispectral-CNN</cell><cell>11640</cell><cell>4.25</cell></row><row><cell>LBP+HOG-SVM</cell><cell>9785</cell><cell>42.20</cell></row><row><cell>Gabor-SVM</cell><cell>9670</cell><cell>35.70</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An efficient method for defect detection during the manufacturing of web materials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Bulnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Usamentiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Molleda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="431" to="445" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On line prediction of surface defects in hot bar rolling based on Bayesian hierarchical modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shivpuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="785" to="800" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic defect detection on hot-rolled flat steel products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghorai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gangadaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dutta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="612" to="621" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic surface defect detection for mobile phone screen glass based on machine vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="348" to="358" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic optical inspection system for IC molding surface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Perng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Support vector machines models for surface roughness prediction in cnc turning of aisi 304 austenitic stainless steel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Çaydaş</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ekici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="639" to="650" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A blind source separation technique using second-order statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Belouchrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Abed-Meraim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on signal processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="434" to="444" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The use of fuzzy logic and neural networks models for sensory properties prediction from process and structure parameters of knitted fabrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E G</forename><surname>Jeguirim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Dhouib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sahnoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheikhrouhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adolphe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="873" to="884" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Joint modeling of classification and regression for improving faulty wafer detection in semiconductor manufacturing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Wood inspection with non-supervised clustering. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Silvé N</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niskanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kauppinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="275" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An efficient method for texture defect detection: sub-band domain co-occurrence matrices. Image and Vision computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Latif-Amet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ertüzün</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Erç Il</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="543" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Probabilistic Boolean network modeling of an industrial machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J R</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Mercado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Rifón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="875" to="890" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic classification of granite tiles through colour and texture features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bianconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gonzá Lez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ferná Ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Saetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="11212" to="11218" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Just noticeable difference for images with decomposition model for separating edge and textured regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1648" to="1652" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Handbook of texture analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirmehdi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Imperial College Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Micro crack detection of multi-crystalline silicon solar wafer using machine vision techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">T</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensor Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="165" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Solar cell crack inspection by image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yanzheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qixin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mingbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Business of Electronic Product Reliability and Liability</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="77" to="80" />
		</imprint>
	</monogr>
	<note>International Conference on</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Micro-crack detection of multi crystalline solar cells featuring an improved anisotropic diffusion filter and image segmentation technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Abdullah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Image and Video Processing</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Machine vision for solar cell characterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ordaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Lush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision Applications in Industrial Inspection VIII</title>
		<imprint>
			<date type="published" when="2000-03" />
			<biblScope unit="volume">3966</biblScope>
			<biblScope unit="page" from="238" to="249" />
		</imprint>
	</monogr>
	<note>International Society for Optics and Photonics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Defect detection of solar cells in electroluminescence images using Fourier image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Solar Energy Materials and Solar Cells</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="250" to="262" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Solar Cell Surface Defects Detection based on Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Performability Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1048</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wavelet-based defect detection in solar wafer images with inhomogeneous texture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="742" to="756" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Solar cells surface defects detection using RPCA method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Journal of Computers</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1943" to="1952" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Solar cells surface defects detection based on deep learning. Pattern Recognition and Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xian-Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming-Hai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wen-Xiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yun-Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="517" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">NB-CNN: deep learning-based crack detection using convolutional neural network and naive Bayes data fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Jahanshahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4392" to="4400" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Design of deep convolutional neural network architectures for automated feature extraction in industrial inspection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholz-Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shpitalni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CIRP Annals</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="417" to="420" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A fast and robust convolutional neural network-based defect detection model in product quality control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Snoussi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Manufacturing Technology</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3465" to="3471" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Transfer learning for automated optical inspection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks (IJCNN), 2017 International Joint Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2517" to="2524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated defect inspection of LED chip using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DEEP CONVOLUTIONAL NEURAL NETWORK FOR AUTOMATIC DETECTION OF DAMAGED PHOTOVOLTAIC CELLS. International Archives of the Photogrammetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pierdicca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Malinverni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Piccinini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paolanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Felicetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zingaretti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing &amp; Spatial Information Sciences</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Automatic Classification of Defective Photovoltaic Module Cells in Electroluminescence Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Christlein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buerhop-Lutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gallwitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Riess</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02894</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automated defect classification in sewer closed circuit television inspections using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Jahanshahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Iseley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Starr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in Construction</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="273" to="283" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dominant local binary patterns for texture classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1107" to="1118" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
