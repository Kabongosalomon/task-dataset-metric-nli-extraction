<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Nathani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Hyderbad</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jatin</forename><surname>Chauhan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Hyderbad</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charu</forename><surname>Sharma</surname></persName>
							<email>charusharma1991@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Hyderbad</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Kaul</surname></persName>
							<email>mkaul@iith.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Hyderbad</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) represent knowledge bases (KBs) as a directed graph whose nodes and edges represent entities and relations between entities, respectively. For example, in <ref type="figure">Figure</ref> 1, a triple (London, capital of, United Kingdom) is represented as two entities: London and United Kingdom along with a relation (capital of) linking them. KGs find uses in a wide variety of applications such as semantic search <ref type="bibr" target="#b15">(Berant et al., 2013;</ref><ref type="bibr" target="#b17">Berant and Liang, 2014)</ref>, dialogue generation <ref type="bibr" target="#b21">(He et al., 2017;</ref><ref type="bibr" target="#b22">Keizer et al., 2017)</ref>, and question answering <ref type="bibr" target="#b43">(Zhang et al., 2016</ref>; * Equal Contribution <ref type="bibr" target="#b20">Diefenbach et al., 2018)</ref>, to name a few. However, KGs typically suffer from missing relations <ref type="bibr" target="#b33">(Socher et al., 2013a;</ref><ref type="bibr" target="#b40">West et al., 2014)</ref>. This problem gives rise to the task of knowledge base completion (also referred to as relation prediction), which entails predicting whether a given triple is valid or not.</p><p>State-of-the-art relation prediction methods are known to be primarily knowledge embedding based models.</p><p>They are broadly classified as translational models  and convolutional neural network (CNN)  based models. While translational models learn embeddings using simple operations and limited parameters, they produce low quality embeddings. In contrast, CNN based models learn more expressive embeddings due to their parameter efficiency and consideration of complex relations. However, both translational and CNN based models process each triple independently and hence fail to encapsulate the semantically rich and latent relations that are inherently present in the vicinity of a given entity in a KG.</p><p>Motivated by the aforementioned observations, we propose a generalized attention-based graph embedding for relation prediction. For node classification, graph attention networks (GATs) <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref> have been shown to focus on the most relevant portions of the graph, namely the node features in a 1-hop neighborhood. Given a KG and the task of relation prediction, our model generalizes and extends the attention mechanism by guiding attention to both entity (node) and relation (edge) features in a multi-hop neighborhood of a given entity / node. Our idea is: 1) to capture multi-hop relations <ref type="bibr" target="#b27">(Lin et al., 2015)</ref> surrounding a given node, 2) to encapsulate the diversity of roles played by an entity in various relations, and 3) to consolidate the existing knowledge present in semantically similar relation clusters (Valverde-Rebaza and de Andrade Lopes, 2012). Our model achieves these objectives by assigning different weight mass (attention) to nodes in a neighborhood and by propagating attention via layers in an iterative fashion. However, as the model depth increases, the contribution of distant entities decreases exponentially. To resolve this issue, we use relation composition as proposed by <ref type="bibr" target="#b27">(Lin et al., 2015)</ref> to introduce an auxiliary edge between n-hop neighbors, which then readily allows the flow of knowledge between entities. Our architecture is an encoder-decoder model where our generalized graph attention model and <ref type="bibr">Con-vKB (Nguyen et al., 2018)</ref> play the roles of an encoder and decoder, respectively. Moreover, this method can be extended for learning effective embeddings for Textual Entailment Graphs <ref type="bibr" target="#b25">(KOTLERMAN et al., 2015)</ref>, where global learning has proven effective in the past as shown by <ref type="bibr" target="#b14">(Berant et al., 2015)</ref> and <ref type="bibr" target="#b16">(Berant et al., 2010)</ref>.</p><p>Our contributions are as follows. To the best of our knowledge, we are the first to learn new graph attention based embeddings that specifically target relation prediction on KGs. Secondly, we generalize and extend graph attention mechanisms to capture both entity and relation features in a multi-hop neighborhood of a given entity. Finally, we evaluate our model on challenging relation prediction tasks for a wide variety of realworld datasets. Our experimental results indicate a clear and substantial improvement over stateof-the-art relation prediction methods. For instance, our attention-based embedding achieves an improvement of 104% over the state-of-the-art method for the Hits@1 metric on the popular Freebase (FB15K-237) dataset.</p><p>The rest of the paper is structured as follows. We first provide a review of related work in Section 2 and then our detailed approach in Section 3. Experimental results and dataset descriptions are reported in Section 4 followed by our conclusion and future research directions in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recently, several variants of KG embeddings have been proposed for relation prediction. These methods can be broadly classified as: (i) compositional, (ii) translational, (iii) CNN based, and (iv) graph based models. RESCAL <ref type="bibr" target="#b30">(Nickel et al., 2011)</ref>, NTN <ref type="bibr" target="#b34">(Socher et al., 2013b)</ref>, and the Holographic embedding model (HOLE) <ref type="bibr" target="#b29">(Nickel et al., 2016)</ref> are examples of compositional based models. Both RESCAL and NTN use tensor products which capture rich interactions, but require a large number of parameters to model relations and are thus cumbersome to compute. To combat these drawbacks, HOLE creates more efficient and scalable compositional representations using the circular correlation of entity embeddings.</p><p>In comparison, translational models like TransE , DIST-MULT  and ComplEx  propose arguably simpler models. TransE considers the translation operation between head and tail entities for relations. DIST-MULT  learns embeddings using a bilinear diagonal model which is a special case of the bilinear objective used in NTN and TransE. DISTMULT uses weighted elementwise dot products to model entity relations. ComplEx  generalizes DISTMULT  by using complex embeddings and Hermitian dot products instead. These translational models are faster, require fewer parameters and are relatively easier to train, but result in less expressive KG embeddings.</p><p>Recently, two CNN based models have been proposed for relation prediction, namely ConvE  and <ref type="bibr">Con-vKB (Nguyen et al., 2018)</ref>. ConvE uses 2-D convolution over embeddings to predict links. It comprises of a convolutional layer, a fully connected projection layer and an inner product layer for the final predictions. Different feature maps are generated using multiple filters to extract global relationships. Concatenation of these feature maps represents an input triple. These models are parameter efficient but consider each triple independently without taking into account the relationships between the triples.</p><p>A graph based neural network model called R-GCN  is an extension of applying graph convolutional networks (GCNs) (Kipf and Welling, 2017) to relational data. It applies a convolution operation to the neighborhood of each entity and assigns them equal weights. This graph based model does not outperform the CNN based models.</p><p>Existing methods either learn KG embeddings by solely focusing on entity features or by taking into account the features of entities and relations in a disjoint manner. Instead, our proposed graph attention model holistically captures multi-hop and semantically similar relations in the n-hop neighborhood of any given entity in the KG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>We begin this section by introducing the notations and definitions used in the rest of the paper, followed by a brief background on graph attention networks (GATs) <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref>. Finally, we describe our proposed attention architecture for knowledge graphs followed by our decoder network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background</head><p>A knowledge graph is denoted by G = (E, R), where E and R represent the set of entities (nodes) and relations (edges), respectively. A triple (e s , r, e o ) is represented as an edge r between nodes e s and e r in G 1 . Embedding models try to learn an effective representation of entities, relations, and a scoring function f , such that for a given input triple t = (e s , r, e o ), f (t) gives the likelihood of t being a valid triple. For example, <ref type="figure" target="#fig_0">Figure 1</ref> shows the subgraph from a KG which infers missing links represented by dashed lines using existing triples such as (London, captial of, United Kingdom).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Attention Networks (GATs)</head><p>Graph convolutional networks (GCNs) (Kipf and Welling, 2017) gather information from the entity's neighborhood and all neighbors contribute equally in the information passing. To address the shortcomings of GCNs, <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref> introduced graph attention networks (GATs). GATs learn to assign varying levels of importance to nodes in every node's neighborhood, rather than treating all neighboring nodes with equal importance, as is done in GCN.</p><p>The input feature set of nodes to a layer is x = { x 1 , x 2 , ..., x N }. A layer produces a transformed set of node feature vectors x = { x 1 , x 2 , ..., x N }, where x i and x i are input and output embeddings of the entity e i , and N is number of entities (nodes). A single GAT layer can be described as</p><formula xml:id="formula_0">e ij = a(W x i , W x j )<label>(1)</label></formula><p>where e ij is the attention value of the edge (e i , e j ) in G, W is a parametrized linear transformation matrix mapping the input features to a higher dimensional output feature space, and a is any attention function of our choosing. Attention values for each edge are the importance of the edge (e i , e j ) s features for a source node e i . Here, the relative attention α ij is computed using a softmax function over all the values in the neighborhood. Equation 2 shows the output of a layer. GAT employs multi-head attention to stabilize the learning process as credited to <ref type="bibr" target="#b38">(Vaswani et al., 2017)</ref>.</p><formula xml:id="formula_1">x i = σ j∈N i α ij W x j<label>(2)</label></formula><p>The multihead attention process of concatenating K attention heads is shown as follows in Equation 3.</p><formula xml:id="formula_2">x i = K k=1 σ j∈N i α k ij W k x j<label>(3)</label></formula><p>where represents concatenation, σ represents any non-linear function, α k ij are normalized attention coefficients of edge (e i , e j ) calculated by the k-th attention mechanism, and W k represents the corresponding linear transformation matrix of the k-th attention mechanism. The output embedding in the final layer is calculated using averaging, instead of the concatenation operation, to achieve multi-head attention, as is shown in the following Equation 4.</p><formula xml:id="formula_3">x i = σ 1 K K k=1 j∈N i α k ij W k x j<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Relations are Important</head><p>Despite the success of GATs, they are unsuitable for KGs as they ignore relation (edge) features, which are an integral part of KGs. In KGs, entities play different roles depending on the relation they are associated with. For example, in <ref type="figure" target="#fig_0">Figure  1</ref>, entity Christopher Nolan appears in two different triples assuming the roles of a brother and a director. To this end, we propose a novel embedding approach to incorporate relation and neighboring node features in the attention mechanism.</p><p>We define a single attentional layer, which is the building block of our model. Similar to GAT, our framework is agnostic to the particular choice of attention mechanism.</p><p>Each layer in our model takes two embedding matrices as input. Entity embeddings are represented by a matrix H ∈ R Ne×T , where the i-th row is the embedding of entity e i , N e is the total number of entities, and T is the feature dimension of each entity embedding. With a similar construction, the relation embeddings are represented by a matrix G ∈ R Nr×P . The layer then outputs the corresponding embedding matrices, H ∈ R Ne×T and G ∈ R Nr×P .</p><p>In order to obtain the new embedding for an entity e i , a representation of each triple associated with e i is learned. We learn these embeddings by performing a linear transformation over the concatenation of entity and relation feature vectors corresponding to a particular triple t k ij = (e i , r k , e j ), as is shown in Equation 5. This operation is also illustrated in the initial block of <ref type="figure" target="#fig_3">Figure 4</ref>.</p><formula xml:id="formula_4">c ijk = W 1 [ h i h j g k ]<label>(5)</label></formula><p>where c ijk is the vector representation of a triple t k ij . Vectors h i , h j , and g k denote embeddings of entities e i , e j and relation r k , respectively. Additionally, W 1 denotes the linear transformation matrix. Similar to <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref>, we learn  <ref type="figure">Figure 3</ref>: Attention Mechanism the importance of each triple t k ij denoted by b ijk . We perform a linear transformation parameterized by a weight matrix W 2 followed by application of the LeakyRelu non-linearity to get the absolute attention value of the triple (Equation 6).</p><formula xml:id="formula_5">b ijk = LeakyReLU W 2 c ijk<label>(6)</label></formula><p>To get the relative attention values softmax is applied over b ijk as shown in Equation 7. <ref type="figure">Figure 3</ref> shows the computation of relative attention values α ijk for a single triple.</p><formula xml:id="formula_6">α ijk = softmax jk (b ijk ) (7) = exp(b ijk ) n∈N i r∈R in exp(b inr )</formula><p>where N i denotes the neighborhood of entity e i and R ij denotes the set of relations connecting entities e i and e j . The new embedding of the entity e i is the sum of each triple representation weighted by their attention values as shown in Equation 8.</p><formula xml:id="formula_7">h i = σ j∈N i k∈R ij α ijk c ijk<label>(8)</label></formula><p>As suggested by <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref>, multihead attention which was first introduced by <ref type="bibr" target="#b38">(Vaswani et al., 2017)</ref>, is used to stabilize the learning process and encapsulate more information about the neighborhood. Essentially, M independent attention mechanisms calculate the embeddings, which are then concatenated, resulting in the following representation:  </p><formula xml:id="formula_8">h i = M m=1 σ j∈N i α m ijk c m ijk<label>(9)</label></formula><formula xml:id="formula_9">G = G.W R<label>(10)</label></formula><p>In the final layer of our model, instead of concatenating the embeddings from multiple heads we employ averaging to get final embedding vectors for entities as shown in Equation <ref type="formula" target="#formula_0">11</ref>.</p><formula xml:id="formula_10">h i = σ 1 M M m=1 j∈N i k∈R ij α m ijk c m ijk<label>(11)</label></formula><p>However, while learning new embeddings, entities lose their initial embedding information. To resolve this issue, we linearly transform H i to obtain H t using a weight matrix W E ∈ R T i ×T f , where H i represents the input entity embeddings to our model, H t represents the transformed entity embeddings, T i denotes the dimension of an initial entity embedding, and T f denotes the dimension of the final entity embedding. We add this initial entity embedding information to the entity embeddings obtained from the final attentional layer, H f ∈ R Ne×T f as shown in Equation 12.</p><formula xml:id="formula_11">H = W E H t + H f<label>(12)</label></formula><p>In our architecture, we extend the notion of an edge to a directed path by introducing an auxiliary relation for n-hop neighbors between two entities. The embedding of this auxiliary relation is the summation of embeddings of all the relations in the path. Our model iteratively accumulates knowledge from distant neighbors of an entity. As illustrated in figure 2, in the first layer of our model, all entities capture information from their direct in-flowing neighbors. In the second layer, U.S gathers information from entities Barack Obama, Ethan Horvath, Chevrolet, and Washington D.C, which already possess information about their neighbors Michelle Obama and Samuel L. Jackson, from a previous layer. In general, for a n layer model the incoming information is accumulated over a n-hop neighborhood.</p><p>The aggregation process to learn new entity embeddings and the introduction of an auxiliary edge between n-hop neighbors is also shown in <ref type="figure" target="#fig_1">Figure  2</ref>. We normalize the entity embeddings after every generalized GAT layer and prior to the first layer, for every main iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training Objective</head><p>Our model borrows the idea of a translational scoring function from , which learns embeddings such that for a given valid triple t k ij = (e i , r k , e j ), the condition h i + g k ≈ h j holds, i.e., e j is the nearest neighbor of e i connected via relation r k . Specifically, we try to learn entity and relation embeddings to minimize the L1-norm dissimilarity measure given by d t ij = h i + g k − h j 1 . We train our model using hinge-loss which is given by the following expression <ref type="formula" target="#formula_0">(13)</ref> where γ &gt; 0 is a margin hyper-parameter, S is the set of valid triples, and S denotes the set of invalid triples, given formally as</p><formula xml:id="formula_12">L(Ω) = t ij ∈S t ij ∈S max{d t ij − d t ij + γ, 0}</formula><formula xml:id="formula_13">S = {t k i j | e i ∈ E \ e i } replace head entity ∪ {t k ij | e j ∈ E \ e j }</formula><p>replace tail entity</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Decoder</head><p>Our model uses ConvKB <ref type="figure" target="#fig_0">(Nguyen et al., 2018)</ref> as a decoder. The aim of the convolutional layer is to analyze the global embedding properties of a triple t k ij across each dimension and to generalize the transitional characteristics in our model. The score function with multiple feature maps can be written formally as:</p><formula xml:id="formula_14">f (t k ij ) = Ω m=1 ReLU([ h i , g k , h j ] * ω m ) .W</formula><p>where ω m represents the m th convolutional filter, Ω is a hyper-parameter denoting number of filters used, * is a convolution operator, and W ∈ R Ωk×1 represents a linear transformation matrix used to compute the final score of the triple. The model is trained using soft-margin loss as</p><formula xml:id="formula_15">L = t k ij ∈{S∪S } log(1+exp(l t k ij .f (t k ij )))+ λ 2 W 2 2 where l t k ij = 1 for t k ij ∈ S −1 for t k ij ∈ S</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>To evaluate our proposed method, we use five benchmark datasets: WN18RR , FB15k-237 <ref type="bibr" target="#b35">(Toutanova et al., 2015)</ref>, NELL-995 <ref type="bibr" target="#b41">(Xiong et al., 2017)</ref>, Unified Medical Language Systems (UMLS) <ref type="bibr" target="#b24">(Kok and Domingos, 2007)</ref> and Alyawarra Kinship <ref type="bibr" target="#b26">(Lin et al., 2018)</ref>. Previous works <ref type="bibr" target="#b35">(Toutanova et al., 2015;</ref> suggest that the task of relation prediction in WN18 and FB15K suffers from the problem of inverse relations, whereby one can achieve state-of-the-art results using a simple reversal rule based model, as shown by . Therefore, corresponding subset datasets WN18RR and FB15k-237 were created to resolve the reversible relation problem in WN18 and FB15K. We used the data splits provided by . <ref type="table">Table 1</ref> provides statistics of all datasets used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Protocol</head><p>We create two sets of invalid triples, each time replacing either the head or tail entity in a triple by an invalid entity. We randomly sample equal number of invalid triples from both the sets to ensure robust performance on detecting both head and tail entity. Entity and relation embeddings produced by TransE  are used to initialize our embeddings. We follow a two-step training procedure, i.e., we first train our generalized GAT to encode information about the graph entities and relations and then train a decoder model like ConvKB  to perform the relation prediction task. The original GAT update Equation 3 only aggregates information passed from 1-hop neighborhood, while our generalized GAT uses information from the n-hop neighborhood. We use auxiliary relations to aggregate more information about the neighborhood in sparse graphs. We use Adam to optimize all the parameters with initial learning rate set at 0.001. Both the entity and relation embeddings of the final layer are set to 200. The optimal hyper-parameters set for each dataset are mentioned in our supplementary section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Protocol</head><p>In the relation prediction task, the aim is to predict a triple (e i , r k , e j ) with e i or e j missing, i.e., predict e i given (r k , e j ) or predict e j given (e i , r k ). We generate a set of (N − 1) corrupt triples for each entity e i by replacing it with every other entity e i ∈ E \ e i , then we assign a score to each such triple. Subsequently, we sort these scores in ascending order and get the rank of a correct triple (e i , r k , e j ). Similar to previous work (( , ), we evaluate all the models in a filtered setting, i.e, during ranking we remove corrupt triples which are already present in one of the training, validation, or test sets. This whole process is repeated by replacing the tail entity e j , and averaged metrics are reported. We report mean reciprocal rank (MRR), mean rank (MR) and the proportion of correct entities in the top N ranks (Hits@N) for N = 1, 3, and 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and Analysis</head><p>Tables 2 and 3 present the prediction results on the test sets of all the datasets. The results clearly demonstrate that our proposed method 2 2 Our work  significantly outperforms state-of-the-art results on five metrics for FB15k-237, and on two metrics for WN18RR. We downloaded publicly available source codes to reproduce results of the state-ofthe-art methods 345678 on all the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Values vs Epochs:</head><p>We study the distribution of attention with increasing epochs for a particular node. <ref type="figure">Figure 5</ref> shows this distribution on FB15k-237. In the initial stages of the learning process, the attention is distributed randomly. As the training progresses and our model gathers more information from the neighborhood, it assigns more attention to direct neighbors and takes minor information from the more distant neighbors. Once the model converges, it learns to gather multi-hop and clustered relation information from the n-hop neighborhood of the node. PageRank Analysis: We hypothesize that com-3 TransE 4 DistMult 5 ComplEx 6 R-GCN 7 ConvE 8 ConvKB plex and hidden multi-hop relations among entities are captured more succinctly in dense graphs as opposed to sparse graphs. To test this hypothesis, we perform an analysis similar to ConvE, where they study the correlation between mean PageRank and increase in MRR relative to Dist-Mult. We notice a strong correlation coefficient of r = 0.808. <ref type="table" target="#tab_4">Table 4</ref> indicates that when there is an increase in PageRank values, there is also a corresponding increase in MRR values. We observe an anomaly to our observed correlation in case of NELL-995 versus WN18RR and attribute this to the highly sparse and hierarchical structure of WN18RR which poses as a challenge to our method that does not capture information in a topdown recursive fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>We carry out an ablation study on our model, where we analyze the behavior of mean rank on a   test set when we omit path generalization (−PG), i.e., removing n-hop information, and omit relation Information (−Relations) from our model. <ref type="figure" target="#fig_5">Figure 7</ref> shows that our model performs better than the two ablated models and we see a significant drop in the results when using ablated models on NELL-995. Removing the relations from the proposed model has a huge impact on the results which suggests that the relation embeddings play a pivotal role in relation prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we propose a novel approach for relation prediction. Our approach improves over the state-of-the-art models by significant margins. Our proposed model learns new graph attention- based embeddings that specifically cater to relation prediction on KGs. Additionally, we generalize and extend graph attention mechanisms to capture both entity and relation features in a multihop neighborhood of a given entity. Our detailed and exhaustive empirical analysis gives more insight into our method's superiority for relation prediction on KGs. The proposed model can be extended to learn embeddings for various tasks us-ing KGs such as dialogue generation <ref type="bibr" target="#b21">(He et al., 2017;</ref><ref type="bibr" target="#b22">Keizer et al., 2017)</ref>, and question answering <ref type="bibr" target="#b43">(Zhang et al., 2016;</ref><ref type="bibr" target="#b20">Diefenbach et al., 2018)</ref>.</p><p>In the future, we intend to extend our method to better perform on hierarchical graphs and capture higher-order relations between entities (like motifs) in our graph attention model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Subgraph of a knowledge graph contains actual relations between entities (solid lines) and inferred relations that are initially hidden (dashed lines).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>This figure shows the aggregation process of our graph attentional layer. α ij represents relative attention values of the edge. The dashed lines represent an auxiliary edge from a n-hop neighbors, in this case n = 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>This figure shows end-to-end architecture of our model. Dashed arrows in the figure represent concatenation operation. Green circles represents initial entity embedding vectors and yellow circles represents initial relation embedding vectors. This is the graph attention layer shown in Figure 4. We perform a linear transformation on input relation embedding matrix G, parameterized by a weight matrix W R ∈ R T ×T , where T is the dimensionality of output relation embeddings (Equation 10).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Learning process of our model on FB15K-237 dataset. Y-axis represents attention values ×1e −5 . Learning process of our model on WN18RR dataset. Y-axis represents attention values ×1e −5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Epochs vs Mean Rank for our model and two ablated models on NELL-995. −PG (green) represents the model after removing n-hop auxiliary relations or path generalization, −Relations (blue) represents model without taking relations into account and Our model (red) represents the entire model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Experimental results on NELL-995 and Kinship test sets. Hits@N values are in percentage. The best score is in bold and second best score is underlined.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Mean PageRank ×10 −5 vs relative increase in MRR wrt. DistMult.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">From here onwards, the pairs "node / entity" and "edge / relation" will be used interchangeably</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Distmult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Complex (trouillon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Conve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dettmers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Transe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bordes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Convkb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R-Gcn (</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">6700</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Table 2: Experimental results on WN18RR and FB15K-237 test sets. Hits@N values are in percentage. The best score is in bold and second best score is underlined</title>
		<imprint>
			<biblScope unit="page">995</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<title level="m">Kinship Hits@N Hits@N MR MRR @1 @3 @10 MR MRR @1 @3 @10</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Distmult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Complex (trouillon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Conve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dettmers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Transe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bordes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Convkb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R-Gcn (</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">7600</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient global learning of entailment graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noga</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldberger</surname></persName>
		</author>
		<idno type="DOI">10.1162/COLI_a_00220</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="221" to="263" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Global learning of focused entailment graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1220" to="1229" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wdaqua-core1: a question answering service for rdf knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Diefenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Maret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion of the The Web Conference 2018 on The Web Conference (WWW)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1087" to="1091" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anusha</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating persuasion strategies and deep reinforcement learning methods for negotiation dialogue agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Guhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heriberto</forename><surname>Cuayahuitl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Efstathiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Peter</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Statistical predicate invention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning, (ICML)</title>
		<meeting>the 24th International Conference on Machine Learning, (ICML)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Textual entailment graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Kotlerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnini</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324915000108</idno>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">699724</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-hop knowledge graph reasoning with reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modeling relation paths for representation learning of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A novel embedding model for knowledge base completion based on convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="327" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tomaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference (ESWC)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26 (NIPS)</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1499" to="1509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Link prediction in complex networks based on cluster information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Carlos Valverde-Rebaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alneu</forename><surname>De Andrade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Brazilian Conference on Advances in Artificial Intelligence, (SBIA)</title>
		<meeting>the 21st Brazilian Conference on Advances in Artificial Intelligence, (SBIA)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph Attention Networks. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Knowledge base completion via search-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on World Wide Web</title>
		<meeting>the 23rd International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="515" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deeppath: A reinforcement learning method for knowledge graph reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thien</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Embedding Entities and Relations for Learning and Inference in Knowledge Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Question answering over knowledge base with neural attention combining global knowledge information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00979</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
