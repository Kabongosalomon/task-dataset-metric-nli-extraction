<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain-independent Extraction of Scientific Concepts from Research Articles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Brack</surname></persName>
							<email>arthur.brack|jennifer.dsouza|anett.hoppe|soeren.auer|ralph.ewerth@tib.eu</email>
							<affiliation key="aff0">
								<orgName type="department">Leibniz Information Centre for Science and Technology (TIB)</orgName>
								<address>
									<settlement>Hanover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Domain-independent Extraction of Scientific Concepts from Research Articles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>0000−0002−1428−5348]</term>
					<term>Jennifer D&apos;Souza [0000−0002−6616−9509]</term>
					<term>Anett Hoppe [0000−0002−1452−9509]</term>
					<term>Sören Auer [0000−0002−0698−2864]</term>
					<term>and Ralph Ewerth [0000−0003−0918−6297] Keywords: sequence labelling · information extraction · scientific articles · ac- tive learning · scholarly communication · research knowledge graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We examine the novel task of domain-independent scientific concept extraction from abstracts of scholarly articles and present two contributions. First, we suggest a set of generic scientific concepts that have been identified in a systematic annotation process. This set of concepts is utilised to annotate a corpus of scientific abstracts from 10 domains of Science, Technology and Medicine at the phrasal level in a joint effort with domain experts. The resulting dataset is used in a set of benchmark experiments to (a) provide baseline performance for this task, (b) examine the transferability of concepts between domains. Second, we present two deep learning systems as baselines. In particular, we propose active learning to deal with different domains in our task. The experimental results show that (1) a substantial agreement is achievable by non-experts after consultation with domain experts, (2) the baseline system achieves a fairly high F1 score, (3) active learning enables us to nearly halve the amount of required training data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scholarly communication as of today is a document-centric process. Research results are usually conveyed in written articles, as a PDF file with text, tables and figures. Automatic indexing of these texts is limited and generally does not access their semantic content. There are thus severe limitations how current research infrastructures can support scientists in their work: finding relevant research works, comparing them, and compiling summaries is still a tedious and error-prone manual work. The strong increase in the number of published research papers aggravates this situation <ref type="bibr" target="#b6">[7]</ref>.</p><p>Knowledge graphs are recognised as an effective approach to facilitate semantic search <ref type="bibr" target="#b2">[3]</ref>. For academic search engines, Xiong et al. <ref type="bibr" target="#b36">[42]</ref> have shown that exploiting knowledge bases like Freebase can improve search results. However, the introduction of new scientific concepts occurs at a faster pace than knowledge base curation, resulting in a large gap in knowledge base coverage of scientific entities <ref type="bibr" target="#b0">[1]</ref>, e.g. the task geolocation estimation of photos from the Computer Vision field is neither present in Wikipedia nor in more specialised knowledge bases like Computer Science Ontology (CSO) <ref type="bibr" target="#b31">[35]</ref> arXiv:2001.03067v1 [cs.IR] 9 Jan 2020 or "Papers with code" <ref type="bibr">[32]</ref>. Information extraction from text helps to identify emerging entities and to populate knowledge graphs <ref type="bibr" target="#b2">[3]</ref>. Thus, information extraction from scientific texts is a first vital step towards a fine-grained research knowledge graph in which research articles are described and interconnected through entities like tasks, materials, and methods. Our work is motivated by the idea of the automatic construction of a research knowledge graph.</p><p>Information extraction from scientific texts, obviously, differs from its general domain counterpart: Understanding a research paper and determining its most important statements demands certain expertise in the article's domain. Every domain is characterised by its specific terminology and phrasing which is hard to grasp for a non-expert reader. In consequence, extraction of scientific concepts from text would entail the involvement of domain experts and a specific design of an extraction methodology for each scientific discipline -both requirements are rather time-consuming and costly.</p><p>At present, a structured study of these assumptions is missing. We thus present the task of domain-independent scientific concept extraction. This article examines the intuition that most domain-specific articles share certain core concepts such as the mentions of research tasks, used materials, or data. If so, these would allow a domain-independent information extraction system, which does not reach all semantic depths of the analysed article, but still provides some science-specific structure.</p><p>In this paper, we introduce a set of science concepts that generalise well over the set of examined domains (10 disciplines from Science, Technology and Medicine (STM)). These concepts have been identified in a systematic, joint effort of domain experts and non-domain experts. The inter-coder agreement is measured to ensure the adequacy and quality of concepts. A set of research abstracts has been annotated using these concepts and the results are discussed with experts from the corresponding fields. The resulting dataset serves as a basis to train two baseline deep learning classifiers. In particular, we present an active learning approach to reduce the number of required training data. The systems are evaluated in different experimental setups.</p><p>Our main contributions can be summarised as follows: (1) We introduce the novel task domain-independent scientific concept extraction, which aims at automatically extracting scientific entities in a domain-independent manner. (2) We release a new corpus that comprises 110 abstracts of 10 STM domains annotated at the phrasal level. Additionally, we release a silver-labelled corpus with 62K automatically annotated abstracts of Elsevier with CCBY license and 1.2 Mio. extracted unique concepts comprising 24 domains. (3) We present two baseline deep learning systems for this task, including an active learning approach. To the best of our knowledge, this is the first approach that applies active learning to scholarly texts. We demonstrate that about half of the training data are sufficient to maintain the performance when using the entire training set. (4) We make our corpora and source code publicly available to facilitate further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This section gives a brief overview of existing annotated scientific corpora before some exemplary applications for domain-independent information extraction from scientific papers and the respective state of the art are introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Scientific corpora</head><p>Sentence level annotation. Early approaches for semantic structuring of research papers focused on sentences as the basic unit of analysis. This enables, for instance, automatic highlighting of relevant paper passages to enable efficient assessment regarding quality and relevance. Several ontologies have been created that focus on the rhetorical <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b10">11]</ref>, argumentative <ref type="bibr" target="#b35">[41,</ref><ref type="bibr" target="#b25">27]</ref> or activity-based <ref type="bibr" target="#b29">[33]</ref> structure of research papers.</p><p>Annotated datasets exist for several domains, e.g. PubMed200k <ref type="bibr" target="#b11">[12]</ref> from biomedical randomized controlled trials, NICTA-PIBOSO <ref type="bibr" target="#b20">[22]</ref> from evidence-based medicine, Dr. Inventor <ref type="bibr" target="#b13">[14]</ref> from Computer Graphics, Core Scientific Concepts (CoreSC) <ref type="bibr" target="#b25">[27]</ref> from Chemistry and Biochemistry, and Argumentative Zoning (AZ) <ref type="bibr" target="#b35">[41]</ref> from Chemistry and Computational Linguistics, Sentence Corpus <ref type="bibr" target="#b7">[8]</ref> from Biology, Machine Learning and Psychology. Most datasets cover only a single domain, while few other datasets cover three domains. Several machine learning methods have been proposed for scientific sentence classification <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b24">26]</ref>.</p><p>Phrase level annotation. More recent corpora have been annotated at phrasal level. SciCite <ref type="bibr" target="#b8">[9]</ref> and ACL ARC <ref type="bibr" target="#b19">[21]</ref> are datasets for citation intent classification from Computer Science, Medicine, and Computational Linguistics. ACL RD-TEC <ref type="bibr" target="#b16">[18]</ref> from Computational Linguistics aims at extracting scientific technology and non-technology terms. ScienceIE17 <ref type="bibr" target="#b1">[2]</ref> from Computer Science, Material Sciences, and Physics contains three concepts PROCESS, TASK and MATERIAL. SciERC <ref type="bibr" target="#b26">[28]</ref> from the machine learning domain contains six concepts TASK, METHOD, METRIC, MATERIAL, OTHER-SCIEN-TIFICTERM and GENERIC. Each corpus covers at most three domains.</p><p>Experts vs. non-experts. The aforementioned datasets were usually annotated by domain experts <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b25">27]</ref>. In contrast, Teufel et al. <ref type="bibr" target="#b35">[41]</ref> explicitly use nonexperts in their annotation tasks, arguing that text understanding systems can use general, rhetorical and logical aspects also when qualifying scientific text. According to this line of thought, more researchers used (presumably cheaper) non-expert annotation as an alternative <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Snow et. al. <ref type="bibr" target="#b34">[39]</ref> provide a study on expert versus non-expert performance for general, non-scientific annotation tasks. They state that about four non-experts (Mechanical Turk workers, in their case) were needed to rival the experts' annotation quality. However, systems trained on data generated by non-experts showed to benefit from annotation diversity and to suffer less from annotator bias. A recent study <ref type="bibr" target="#b30">[34]</ref> examines the agreement between experts and non-experts for visual concept classification and person recognition in historical video data. For the task of face recognition, training with expert annotations lead to an increase of only 1.5 % in classification accuracy.</p><p>Active learning in Natural Language Processing (NLP). To the best of our knowledge, active learning has not been applied to classification tasks for scientific text yet. Recent publications demonstrate the effectiveness of active learning for NLP tasks such as Named Entity Recognition (NER) <ref type="bibr" target="#b32">[37]</ref> and sentence classification <ref type="bibr" target="#b38">[44]</ref>. Siddhant and Lipton <ref type="bibr" target="#b33">[38]</ref> and Shen et. al. <ref type="bibr" target="#b32">[37]</ref> compare several sampling strategies on NLP tasks and show that Maximum Normalized Log-Probability (MNLP) based on uncertainty sampling performs well in NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Applications for domain-independent scientific information extraction</head><p>Academic search engines. Academic search engines such as Google Scholar [16], Microsoft Academic [30] and Semantic Scholar [36] specialise in search of scholarly literature. They exploit graph structures such as the Microsoft Academic Knowledge Graph <ref type="bibr" target="#b28">[31]</ref>, SciGraph [40], or the Semantic Scholar Corpus <ref type="bibr" target="#b0">[1]</ref>. These graphs interlink the papers through meta-data such as citations, authors, venues, and keywords, but not through deep semantic representation of the articles' content.</p><p>However, first attempts towards a more semantic representation of article content exist: Ammar et al. <ref type="bibr" target="#b0">[1]</ref> interlink the Semantic Scholar Corpus with DBpedia <ref type="bibr" target="#b23">[25]</ref> and Unified Medical Language System (UMLS) <ref type="bibr" target="#b5">[6]</ref> using entity linking techniques. Yaman et al. <ref type="bibr" target="#b37">[43]</ref> connect SciGraph with DBpedia person entities. Xiong et al. <ref type="bibr" target="#b36">[42]</ref> demonstrate that academic search engines can greatly benefit from exploiting general-purpose knowledge bases. However, the coverage of science-specific concepts is rather low <ref type="bibr" target="#b0">[1]</ref>.</p><p>Research paper recommendation systems. Beel et al. <ref type="bibr" target="#b3">[4]</ref> provide a comprehensive survey about research paper recommendation systems. Such systems usually employ different strategies (e.g. content-based and collaborative filtering) and several data sources (e.g. text in the documents, ratings, feedback, stereotyping). Graph-based systems, in particular, exploit citation graphs and genes mentioned in the papers <ref type="bibr" target="#b21">[23]</ref>. Beel et al. conclude that it is not possible to determine the most effective recommendation approach at the moment. However, we believe that a fine-grained research knowledge graph can improve such systems. Although "Papers with code" [32] is not a typical recommendation system, it allows researchers to browse easily for papers from the field of machine learning that address a certain task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Domain-independent scientific concept extraction: A corpus</head><p>In this section, we introduce the novel task of domain-independent extraction of scientific concepts and present an annotated corpus. As the discussion of related work reveals, the annotation of scientific resources is not a novel task. However, most researchers focus on at most three scientific disciplines and on expert-level annotations. In this work, we explore the domain-independent annotation of scientific concepts based on abstracts from ten different science domains. Since other studies have also shown that non-expert annotations are feasible for the general and scientific domain, we go for a cost-efficient middle course: annotations of non-experts experienced in the annotation task and consultation with domain-experts. Finally, we explore how well state-of-the-art machine learning approaches do perform on this novel, domain-independent information extraction task and whether active learning can save annotation costs. The base corpus, which we make publicly available, and the annotation process are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">OA STM Corpus</head><p>The OA STM corpus <ref type="bibr" target="#b12">[13]</ref> is a set of open access (OA) articles from various domains in Science, Technology and Medicine (STM). It was published in 2017 as a platform for benchmarking methods in scholarly article processing, amongst other scientific information extraction. The dataset contains a selection of 110 articles from 10 domains, namely Agriculture (Agr), Astronomy (Ast), Biology (Bio), Chemistry (Che), Computer Science (CS), Earth Science (ES), Engineering (Eng), Materials Science (MS), Mathematics (Mat), and Medicine (Med). While the original corpus contains full articles, this first annotation cycle focuses on the articles' abstracts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Annotation process</head><p>The OA STM Corpus is used as a base for (a) the identification of potential domainindependent concepts; (b) a first annotated corpus for baseline classification experiments. Main actors in the annotation process were two post-doctoral researchers with a background in computer science (acting as non-expert annotators); their basic annotation assumptions were checked by experts from the respective domains. <ref type="table">Table 1</ref>: The four core scientific concepts that were derived in this study PROCESS Natural phenomenon or activities, e.g. growing (Bio), reduction (Mat), flooding (ES). METHOD A commonly used procedure that acts on entities, e.g. powder X-ray (Che), the PRAM analysis (CS), magnetoencephalography (Med). MATERIAL A physical or abstract entity used in scientific experiments or proofs, e.g. soil (Agr), the moon (Ast), the carbonator (Che). DATA The data themselves, measurements, or quantitative or qualitative characteristics of entities, e.g. rotational energy (Eng), tensile strength (MS), 3D time-lapse seismic data (ES).</p><p>Pre-annotation. A literature review of annotation schemes <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b10">11]</ref> provided a seed set of potential candidate concepts. Both non-experts independently annotated a subset of the STM abstracts with these concepts and discussed the outcome. In a three-step process, the concept set was pruned to only contain those which seemed suitably transferable between domains. Our set of generic scientific concepts consists of PROCESS, METHOD, MATERIAL, and DATA (see <ref type="table">Table 1</ref> for their definitions). We also identified TASK <ref type="bibr" target="#b1">[2]</ref>, OBJECT <ref type="bibr" target="#b24">[26]</ref>, and RESULTS <ref type="bibr" target="#b10">[11]</ref>, however, in this study we do not consider nested span concepts, hence we leave them out since they were almost always nested with the other scientific entities (e.g. a RESULT may be nested with DATA).</p><p>Phase I. Five abstracts per domain (i.e. 50 abstracts) were annotated by both annotators and the inter-annotator agreement was computed using Cohen's κ <ref type="bibr" target="#b9">[10]</ref>. Results showed a moderate inter-annotator agreement of 0.52 κ.</p><p>Phase II. The annotations were then presented to subject specialists who each reviewed (a) the choice of concepts and (b) annotation decisions on the respective domain corpus. The interviews mostly confirmed the concept candidates as generally applicable. The experts' feedback on the annotation was even more valuable: The comments allowed for a more precise reformulation of the annotation guidelines, including illustrating examples from the corpus.</p><p>Consolidation. Finally, the 50 abstracts from phase I were reannotated by the nonexperts. Based on the revised annotation guidelines, a substantial agreement of 0.76 κ could be reached (see <ref type="table" target="#tab_0">Table 2</ref>). Subsequently, the remaining 60 abstracts (six per do-main) were annotated by one annotator. This last phase also involved reconciliation of the previously annotated 50 abstracts to obtain a gold standard corpus.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Corpus characteristics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental setup: Two baseline classifiers</head><p>The current state-of-the-art for scientific entity extraction is Beltagy et al.'s system <ref type="bibr" target="#b4">[5]</ref>. We use their NER task-specific deep learning architecture atop SciBERT embeddings with a Conditional Random Field (CRF) based sequence tag decoder <ref type="bibr" target="#b27">[29]</ref> and BILOU (beginning, inside, last, outside, unit) tagging scheme. The following classifiers are implemented in AllenNLP <ref type="bibr" target="#b14">[15]</ref>. We report span-based micro-averaged F1 scores and use the ScienceIE17 [2] evaluation script.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Traditionally trained classifiers</head><p>Using the above mentioned architecture, we train one model with data from all domains combined. We refer to this model as the domain-independent classifier. Similarly, we train 10 models for each domain in our corpus -the domain-specific classifier.</p><p>To obtain a robust evaluation of models, we perform five-fold cross-validation experiments. In each fold experiment, we train a model on 8 abstracts per domain (i.e. 80 abstracts), tune hyperparameters on 1 abstract per domain (i.e. 10 abstracts), and test on the remaining 2 abstracts per domain (i.e. 20 abstracts) ensuring that the data splits are not identical between the folds. All results reported in the paper are averaged over the five folds. Please note that 8 abstracts have about 445 concepts so that the training data should be sufficient for the domain-dependent classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Active learning trained classifier</head><p>Based on the results of the aforementioned comparison studies <ref type="bibr" target="#b33">[38,</ref><ref type="bibr" target="#b38">44]</ref>, we decide to use MNLP <ref type="bibr" target="#b32">[37]</ref> as the sampling strategy in the active learning setting. It is chosen over other possibly suitable candidates such as Bayesian Active Learning by Disagreement (BALD) <ref type="bibr" target="#b17">[19]</ref>, which is another powerful strategy, but has higher computational requirements. The objective involves strategically selecting sentences from the overall dataset in each iteration of the algorithm greedily, aiming at getting greater performance with a minimum number of sentences. In our experiments, we found that adding 4% of the data to be the most discriminative selection of classifier performance. Therefore, we run 25 iterations of active learning in each stage adding 4% training data. To obtain a robust evaluation of models, we repeat the experiment for five folds and average the results. The models use the same hyperparameters as for the domain-independent classifier. We retrain the model within each iteration and fold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental results and discussion</head><p>This section describes the results of the experimental setup and the correlation analysis between inter-annotator agreement and performance of the several classifiers. <ref type="table" target="#tab_3">Table 4</ref> shows an overview of the domain-independent classifier results. The system achieves an F 1 score of 65.5 (± 1.26) in the overall task. For this classifier, MATERIAL was the easiest concept with an F 1 of 71 (± 1.88), whereas METHOD was the hardest concept with an F 1 of 43 (± 6.30). The concept METHOD is also the most underrepresented one in our corpus, which partly explains the poor extraction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Traditionally trained classifiers</head><p>Next, we compare and contrast the 10 domain-specific classifiers according to their capability to extract the concepts from their own domains and in other domains. The results are shown as F 1 scores in <ref type="figure" target="#fig_0">Figure 1</ref> where the x-axis represents the 10 test domains. We discuss some observations in the sequel.   <ref type="figure" target="#fig_0">Figure 1</ref>) extracts scientific entities from its own domain at the same performance as the domain-independent classifier with an F 1 score of 71 (± 9.0) demonstrating a robust domain. It comprises only 11% of the overall data, yet the domain-independent classifier trained on all data does not outperform it.</p><p>Most generic domain. MS (the third last bar in each domain in <ref type="figure" target="#fig_0">Figure 1</ref>) exhibits a high degree of domain independence since it is among the top 3 classifiers for seven of the 10 domains (viz. ES, Che, CS, Ast, Agr, MS, and Bio).</p><p>Most specialised domain. Mat (the second last bar in each domain in <ref type="figure" target="#fig_0">Figure 1</ref>) shows the lowest performance in extracting scientific concepts from all domains except itself. Hence it shows to be the most specialised domain in our corpus. Notably, a characteristic feature of this domain is that it has short abstracts (nearly a third of the size of the longest abstracts), so it is also the most underrepresented in our corpus. Also, distinct from the other domains, Mat has triple the number of DATA entities compared to each of its other concepts, where in the other domains PROCESS and MATERIAL are consistently predominant. Domain-independent vs. domain-dependent classifier. Except for Bio the domainindependent classifier clearly outperforms the domain-dependent one extracting concepts from their respective domains. To analyse the reason, we investigate the improvements in CS domain. We have chosen CS exemplary as the size of the domain is slightly below the average and this domain strongly benefits from the domain-independent classifier and improves the F 1 score for the CS classifier from 49.5 (± 4.22) to 65.9 (± 1.21). The F 1 score for span-detection is improved from 73.4 (± 3.45) to 82.0 (± 3.98). Span-detection usually requires less domain-dependent signals, thus the domainindependent classifier can benefit from other domains. Accuracy on token-level also improves from 67.7 (± 5.35) to 77.5 (± 4.42) F 1, that is correct labelling of the tokens also benefits from other domains. This is also supported by the results in the confusion matrix depicted in <ref type="figure" target="#fig_1">Figure 2</ref> for the CS and the domain-independent classifier on token-level.</p><p>Scientific concept extraction. <ref type="figure" target="#fig_3">Figure 3</ref> depicts the 10 domain-specific classifier results for extracting each of the four scientific concepts. It can be observed that Agr, Med, Bio, and Ast classifiers are the best in extracting PROCESS, METHOD, MATERIAL, and DATA, respectively.   For SciERC <ref type="bibr" target="#b26">[28]</ref> and ScienceIE17 <ref type="bibr" target="#b1">[2]</ref> similar results are demonstrating that MNLP can significantly reduce the amount of labelled data.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Active learning trained classifier</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Correlations between inter-annotator agreement and performance</head><p>In this section, we analyse the correlations of inter-annotator agreement κ and the number of annotated concepts per domain (#) on the performance and variance of the classifiers employing Pearson's correlation coefficient (Pearson's R).   <ref type="table">Table 6</ref> summarises the results of our correlation analysis. The active learning classifier (AL-trained) has been trained with 52 % training data sampled by MNLP. For the domain-dependent, domain-independent and AL-trained classifier we observe a strong correlation between F1 and number of concepts per domain (R 0.70, 0.76, 0.68) and a weak correlation between κ and F1 (R 0.20, 0.28, 0.23). Thus, we can hypothesise that the number of annotated concepts in a particular domain has more influence on the performance than the inter-annotator agreement.</p><p>The correlation values for std is different between the classifier types. For the domaindependent classifier the correlation between κ and std (R 0.29), and the number of concepts per domain and std (R 0.28) is slightly positive. In other words: the higher the agreement and the size of the domain, the higher the variance of the domain-dependent classifier. This is different for the domain-independent classifier as there is no correlation anymore. For the AL-trained classifier there is, on the other hand, a moderate negative correlation between κ and std (R -0.41), and a strong negative correlation between number of concepts per domain and std (R -0.72), i.e. higher agreement and larger amount of training data in a domain lead to less variance for the AL-trained classifier. We hypothesise that more diversity through several domains in the domain-independent and the AL-trained classifier leads to better performance and lower variance by introducing an inductive bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we have introduced the novel task of domain-independent concept extraction from scientific texts. During a systematic annotation procedure involving domain experts, we have identified four general core concepts that are relevant across the domains of Science, Technology and Medicine. To enable and foster research on these topics, we have annotated a corpus for the domains. We have verified the adequacy of the concepts by evaluating the human annotator agreement for our broad STM domain corpus. The results indicate that the identification of the generic concepts in a corpus covering 10 different scholarly domains is feasible by non-experts with moderate agreement and after consultation of domain experts with substantial agreement (0.76 κ).</p><p>We have presented two deep learning systems which achieved a fairly high F1 score (65.5% overall). The domain-independent system noticeably outperforms the domaindependent systems, which indicates that the model can generalise well across domains. We also observed a strong correlation between the number of annotated concepts per domain and classifier performance, and only a weak correlation between inter-annotator agreement per domain and the performance. We can hypothesise that more annotated data positively influence the performance in the respective domain.</p><p>Furthermore, we have suggested active learning for our novel task. We have shown that only approx. 5 annotated abstracts per domain serving as training data are sufficient to build a performant model. Our active learning results for SciERC <ref type="bibr" target="#b26">[28]</ref> and ScienceIE17 <ref type="bibr" target="#b1">[2]</ref> datasets were similar. The promising results suggest that we do not need a large annotated dataset for scientific information extraction. Active learning can significantly save annotation costs and enable fast adaptation to new domains.</p><p>We make our annotated corpus, a silver-labelled corpus with 62K abstracts comprising 24 domains, and source code publicly available 1 . We hope to facilitate the research on that task and several applications, e.g. academic search engines or research paper recommendation systems.</p><p>In the future, we plan to extend and refine the concepts for certain domains. Besides, we want to apply and evaluate the information extraction system to populate a research knowledge graph. For that we plan to extend the corpus with co-reference annotations <ref type="bibr" target="#b22">[24]</ref> so that mentions referring to the same concept can be collapsed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>F 1 per domain of the 10 domain-specific classifiers (as bar plots) and of the domain-independent classifier (as scatter plots) for scientific concept extraction; the xaxis represents the 10 test domains Most robust domain. Bio (third bar in each domain in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Confusion matrix for (a) the CS classifier and (b) domain-independent classifier on CS domain predicting concept-type of tokens Medical and Life Science domains. The Med, Agr, and Bio domains show strong domain relatedness. Their respective domain-specific classifiers show top five system performances among the three domains, when applied to another domain. For instance, the Med domain shows the strongest domain relatedness and is classified best by Med (last bar), followed by Bio (third bar) and Agr (first bar).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4</head><label>4</label><figDesc>shows the results of the active learning experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>F 1 of the 10 domain-specific classifier (as bar plots) and the domain-independent classifier (as scatter plots) for extracting each scientific concept; the x-axis represents the evaluated concept of the training data, the best result of the domain-independent classifier trained with all training data is surpassed with an F 1 score of 65.5 (± 1.0). For comparison: the random baseline achieves an F 1 score of 62.5 (± 2.6) with 52 % of the training data. When 76 % of the data are sampled by MNLP, the best active learning performance across all steps is achieved with an F 1 score of 69.0 on the validation set, having the best F 1 of 66.4 (± 2.0) on the test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Progress of active learning with MNLP and random sampling strategy; the areas represent the standard deviation (std) of the F1 score across 5 folds for MNLP and random sampling strategy, respectively by MNLP. When using 52 % of the training data, 65.4% of Math, 66.2% of CS sentences were sampled, but only 41.6% of Eng and 37.3% of MS. Thereby all domains are present, that is a heterogeneous mix of sentences sampled by MNLP yields the most generic model with less training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>6 :</head><label>6</label><figDesc>Inter-annotator agreement (κ) and the number of concept phrases (#) per domain; F1 and std of domain-dependent classifiers on their domains; F1 and std of domain-independent and AL-trained classifier on each domain; the right side depicts correlation coefficients (R) of each row with κ and the number of concept phrases Agr Ast Bio Che CS ES Eng MS Mat Med R κ R # inter-annotator agreement (κ) 0.6 0.57 0.75 0.77 0.85 0.81 0.79 0.9 0.58 0.94 1.00 -0.02 # concept phrases (#) 741 791 649 483 553 698 741 574 297 600 -0.02 1.00 domain-dependent (F1) 0.58 0.61 0.71 0.54 0.49 0.46 0.64 0.61 0.31 0.55 0.20 0.70 domain-independent (F1) 0.68 0.66 0.71 0.64 0.65 0.63 0.71 0.69 0.48 0.61 0.28 0.76 AL-trained (F1) 0.65 0.67 0.74 0.65 0.62 0.63 0.72 0.69 0.50 0.60 0.23 0.68 domain-dependent (std) 0.06 0.06 0.09 0.08 0.05 0.06 0.04 0.11 0.06 0.07 0.29 0.28 domain-independent (std) 0.04 0.04 0.11 0.08 0.07 0.05 0.03 0.04 0.06 0.03 -0.11 -0.05 AL-trained (std) 0.04 0.04 0.09 0.08 0.07 0.04 0.07 0.05 0.15 0.02 -0.41 -0.72</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Per-domain and overall inter-annotator agreement (Cohen's Kappa κ) for PRO-CESS, METHOD, MATERIAL, and METHOD scientific concept annotation</figDesc><table><row><cell cols="2">Med MS CS ES Eng Che Bio Agr Mat Ast Overall</cell></row><row><cell>κ 0.94 0.90 0.85 0.81 0.79 0.77 0.75 0.60 0.58 0.57</cell><cell>0.76</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 shows</head><label>3</label><figDesc></figDesc><table /><note>some characteristics of the resulting corpus. The corpus has a total of 6,127 scientific entities, including 2,112 PROCESS, 258 METHOD, 2,099 MATERIAL, and 1,658 DATA concept entities. The number of entities per abstract in our corpus directly correlates with the length of the abstracts (Pearson's R 0.97). Among the con- cepts, PROCESS and MATERIAL directly correlate with abstract length (R 0.8 and 0.83, respectively), while DATA has only a slight correlation (R 0.35) and METHOD has no correlation (R 0.02). The domains Bio, CS, Ast, and Eng contain the most of PROCESS, METHOD, MATERIAL, and DATA concepts, respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>The annotated corpus characteristics in terms of size and the number of scientific concept phrases</figDesc><table><row><cell></cell><cell>Ast Agr Eng ES Bio Med MS CS Che Mat</cell></row><row><cell>Avg. # Tokens/Abstract</cell><cell>382 333 303 321 273 274 282 253 217 140</cell></row><row><cell># Gold scientific concept phrases</cell><cell>791 741 741 698 649 600 574 553 483 297</cell></row><row><cell cols="2"># Unique gold scientific concept phrases 663 631 618 633 511 518 493 482 444 287</cell></row><row><cell># PROCESS</cell><cell>241 252 248 243 281 244 178 220 149 56</cell></row><row><cell># METHOD</cell><cell>19 28 27 9 15 33 27 66 27 7</cell></row><row><cell># MATERIAL</cell><cell>296 292 208 249 291 191 231 102 188 51</cell></row><row><cell># DATA</cell><cell>235 169 258 197 62 132 138 165 119 183</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The domain-independent classifier results in terms of Precision (P ), Recall (R), and F1-score on scientific concepts, respectively, and Overall</figDesc><table><row><cell></cell><cell>PROCESS</cell><cell cols="3">METHOD</cell><cell cols="2">MATERIAL</cell><cell cols="2">DATA</cell><cell></cell><cell>Overall</cell><cell></cell></row><row><cell>P</cell><cell cols="11">65.5 (± 4.22) 45.8 (± 13.50) 69.2 (± 3.55) 60.3 (±4.14) 64.3 (± 1.73)</cell></row><row><cell cols="12">R 68.3 (± 1.93) 44.1 (± 8.73) 73.2 (± 4.27) 60.0 (± 4.84) 66.7 (± 0.92)</cell></row><row><cell cols="12">F 1 66.8 (± 2.07) 43.0 (± 6.30) 71.0 (± 1.88) 59.8 (± 1.75) 65.5 (± 1.26)</cell></row><row><cell></cell><cell>0.8</cell><cell>Agr</cell><cell>Ast</cell><cell>Bio</cell><cell>Che</cell><cell>CS</cell><cell>ES</cell><cell>Eng</cell><cell>MS</cell><cell>Mat</cell><cell>Med</cell><cell>Overall</cell></row><row><cell></cell><cell>0.6 0.7</cell><cell>0.61</cell><cell></cell><cell>0.63</cell><cell>0.64</cell><cell>0.65</cell><cell>0.66</cell><cell></cell><cell>0.68</cell><cell>0.69</cell><cell>0.71</cell><cell>0.71</cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1</cell><cell>0.48</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Test</cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mat</cell><cell>Med</cell><cell></cell><cell>ES</cell><cell>Che</cell><cell>CS</cell><cell>Ast</cell><cell></cell><cell>Agr</cell><cell>MS</cell><cell>Bio</cell><cell>Eng</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>depicts the results for the fraction of training data when the performance using the entire training dataset is achieved. MNLP clearly outperforms the random baseline. While using only 52 %</figDesc><table><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Agr</cell><cell>Ast</cell><cell>Bio</cell><cell>Che</cell><cell>CS</cell><cell>ES</cell><cell>Eng</cell><cell>MS</cell><cell>Mat</cell><cell>Med</cell><cell>Overall</cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.71</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.67</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Test</cell><cell>0.4</cell><cell>0.43</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Method</cell><cell></cell><cell>Data</cell><cell></cell><cell></cell><cell></cell><cell>Process</cell><cell></cell><cell></cell><cell>Material</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Performance of active learning with MNLP and random sampling strategy for the fraction of training data when the performance with entire training dataset is achieved, for SciERC and ScienceIE17 results are reported across 5 random restarts To find out which mix of training data produces the most generic model, we analyse the distribution of sentences in the training data sampled by MNLP. As expected, the random sampling strategy uniformly samples sentences from all domains in each iteration. However, (Math, CS) are the most and (Eng, MS) the least preferred domains</figDesc><table><row><cell></cell><cell>training data</cell><cell>F1 (MNLP)</cell><cell>F1 (random)</cell><cell>F1 (full data)</cell></row><row><cell>STM (our corpus)</cell><cell>52 %</cell><cell>65.5 (± 1.0)</cell><cell>62.5 (± 2.6)</cell><cell>65.5 (± 1.3)</cell></row><row><cell>SciERC [28]</cell><cell>62 %</cell><cell>65.3 (± 1.5)</cell><cell>62.3 (± 1.5)</cell><cell>65.6 (± 1.0)</cell></row><row><cell>ScienceIE17 [2]</cell><cell>38 %</cell><cell>43.9 (± 1.2)</cell><cell>42.2 (± 1.8)</cell><cell>43.8 (± 1.0)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://gitlab.com/TIBHannover/orkg/orkg-nlp/tree/master/STM-corpus</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Construction of the literature graph in semantic scholar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dunkelberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kohlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skjonsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="NAACL" to="HLT" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vikraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<title level="m">Semeval 2017 task 10: Scienceie -extracting keyphrases and relations from scientific publications</title>
		<imprint>
			<publisher>SemEval@ACL</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Entity-oriented search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Information Retrieval Series</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Research-paper recommender systems: a literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Breitinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="305" to="338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scibert: Pretrained language model for scientific text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The unified medical language system (umls): integrating biomedical terminology. Nucleic acids research 32 Database issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="267" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bornmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Statistical Models for Text Classification and Clustering: Applications and Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>UNIVERSITY OF CALIFORNIA, IRVINE</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Structural scaffolds for citation intent classification in scientific publications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cady</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The document components ontology (doco)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pettifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vitali</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="167" to="181" />
		</imprint>
	</monogr>
	<note>Semantic Web 7</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Pubmed 200k rct: a dataset for sequential sentence classification in medical abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IJCNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Elsevier oa stm corpus</title>
		<ptr target="https://github.com/elsevierlabs/OA-STM-Corpus" />
		<imprint>
			<biblScope unit="page" from="2019" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">On the discoursive structure of computer graphics research papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ronzano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="LAW@NAACL" to="HLT" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07640</idno>
		<title level="m">Allennlp: A deep semantic natural language processing platform</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Salt: Semantically annotated latex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Groza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Handschuh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>SAAW@ISWC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The acl rd-tec: a dataset for benchmarking terminology extraction and classification in computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Handschuh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qasemizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2014: 4th international workshop on computational terminology</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bayesian active learning for classification and preference learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lengyel</surname></persName>
		</author>
		<idno>abs/1112.5745</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Hierarchical neural networks for sequential sentence classification in medical scientific abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Measuring the evolution of a scientific field through citation frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="391" to="406" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic classification of sentences to support evidence based medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cavedon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yencken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relational retrieval using a combination of path-constrained random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="53" to="67" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dbpedia -a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic recognition of conceptualization zones in scientific articles and two life science applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dobnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Batchelor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="991" to="1000" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Corpora for the conceptualisation and zoning of scientific papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Batchelor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>LREC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<idno>abs/1603.01354</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
				<idno>accessed: 2019-09-12 32</idno>
		<ptr target="https://paperswithcode.com/" />
	</analytic>
	<monogr>
		<title level="m">Microsoft academic knowledge graph</title>
		<imprint>
			<biblScope unit="page" from="2019" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scholarly ontology: modelling scholarly practices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pertsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Constantopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="173" to="190" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Investigating correlations of inter-coder agreement and machine annotation performance for historical video data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pustu-Iren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mühling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Korfhage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bernhöft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hörth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freisleben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ewerth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TPDL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The computer science ontology: A large-scale taxonomy of research areas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Salatino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Thanapalasingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mannocci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Motta</surname></persName>
		</author>
		<ptr target="https://www.semanticscholar.org/" />
	</analytic>
	<monogr>
		<title level="m">International Semantic Web Conference</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2019" to="2028" />
		</imprint>
	</monogr>
	<note>Semantic scholar</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Deep active learning for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kronrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Deep bayesian active learning for natural language processing: Results of a large-scale empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cheap and fast -but is it good? evaluating non-expert annotations for natural language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="https://www.springernature.com/gp/researchers/scigraph" />
	</analytic>
	<monogr>
		<title level="m">Springer nature scigraph</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2019" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards discipline-independent argumentative zoning: evidence from chemistry and computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Batchelor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1493" to="1502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Explicit semantic ranking for academic search via knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Interlinking scigraph and dbpedia datasets using link discovery and named entity recognition techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Freudenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>LDK</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Active discriminative text representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
