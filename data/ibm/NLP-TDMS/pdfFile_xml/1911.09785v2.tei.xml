<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring REMIXMATCH: SEMI-SUPERVISED LEARNING WITH DISTRIBUTION ALIGNMENT AND AUGMENTATION ANCHORING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
							<email>ncarlini@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
							<email>cubuk@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kurakin</surname></persName>
							<email>kurakin@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
							<email>zhanghan@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
							<email>craffel@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
							<email>kihyuks@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Cloud</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename></persName>
						</author>
						<title level="a" type="main">ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring REMIXMATCH: SEMI-SUPERVISED LEARNING WITH DISTRIBUTION ALIGNMENT AND AUGMENTATION ANCHORING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We improve the recently-proposed "MixMatch" semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of groundtruth labels. Augmentation anchoring feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMix-Match, is significantly more data-efficient than prior work, requiring between 5× and 16× less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to Mix-Match's accuracy of 93.58% with 4,000 examples) and a median accuracy of 84.92% with just four labels per class. We make our code and data open-source at https://github.com/google-research/remixmatch.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Semi-supervised learning (SSL) provides a means of leveraging unlabeled data to improve a model's performance when only limited labeled data is available. This can enable the use of large, powerful models when labeling data is expensive or inconvenient. Research on SSL has produced a diverse collection of approaches, including consistency regularization <ref type="bibr" target="#b24">(Sajjadi et al., 2016;</ref><ref type="bibr" target="#b16">Laine &amp; Aila, 2017</ref>) which encourages a model to produce the same prediction when the input is perturbed and entropy minimization <ref type="bibr" target="#b11">(Grandvalet &amp; Bengio, 2005</ref>) which encourages the model to output highconfidence predictions. The recently proposed "MixMatch" algorithm <ref type="bibr" target="#b2">(Berthelot et al., 2019)</ref> combines these techniques in a unified loss function and achieves strong performance on a variety of image classification benchmarks. In this paper, we propose two improvements which can be readily integrated into MixMatch's framework.</p><p>First, we introduce "distribution alignment", which encourages the distribution of a model's aggregated class predictions to match the marginal distribution of ground-truth class labels. This concept was introduced as a "fair" objective by <ref type="bibr" target="#b3">Bridle et al. (1992)</ref>, where a related loss term was shown to arise from the maximization of mutual information between model inputs and outputs. After reviewing this theoretical framework, we show how distribution alignment can be straightforwardly added to MixMatch by modifying the "guessed labels" using a running average of model predictions.</p><p>Second, we introduce "augmentation anchoring", which replaces the consistency regularization component of MixMatch. For each given unlabeled input, augmentation anchoring first generates a weakly augmented version (e.g. using only a flip and a crop) and then generates multiple strongly augmented versions. The model's prediction for the weakly-augmented input is treated as the basis Figure 2: Augmentation anchoring. We use the prediction for a weakly augmented image (green, middle) as the target for predictions on strong augmentations of the same image (blue). of the guessed label for all of the strongly augmented versions. To generate strong augmentations, we introduce a variant of AutoAugment  based on control theory which we dub "CTAugment". Unlike AutoAugment, CTAugment learns an augmentation policy alongside model training, making it particularly convenient in SSL settings.</p><p>We call our improved algorithm "ReMixMatch" and experimentally validate it on a suite of standard SSL image benchmarks. ReMixMatch achieves state-of-the-art accuracy across all labeled data amounts, for example achieving an accuracy of 93.73% with 250 labels on CIFAR-10 compared to the previous state-of-the-art of 88.92% (and compared to 96.09% for fully-supervised classification with 50,000 labels). We also push the limited-data setting further than ever before, ultimately achieving a median of 84.92% accuracy with only 40 labels (just 4 labels per class) on CIFAR-10. To quantify the impact of our proposed improvements, we carry out an extensive ablation study to measure the impact of our improvements to MixMatch. Finally, we release all of our models and code to facilitate future work on semi-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>The goal of a semi-supervised learning algorithm is to learn from unlabeled data in a way that improves performance on labeled data. Typical ways of achieving this include training against "guessed" labels for unlabeled data or optimizing a heuristically-motivated objective that does not rely on labels. This section reviews the semi-supervised learning methods relevant to ReMixMatch, with a particular focus on the components of the MixMatch algorithm upon which we base our work.</p><p>Consistency Regularization Many SSL methods rely on consistency regularization to enforce that the model output remains unchanged when the input is perturbed. First proposed in <ref type="bibr" target="#b0">(Bachman et al., 2014)</ref>, <ref type="bibr" target="#b24">(Sajjadi et al., 2016)</ref> and <ref type="bibr" target="#b16">(Laine &amp; Aila, 2017)</ref>, this approach was referred to as "Regularization With Stochastic Transformations and Perturbations" and the "Π-Model" respectively. While some work perturbs adversarially <ref type="bibr" target="#b21">(Miyato et al., 2018)</ref> or using dropout <ref type="bibr" target="#b16">(Laine &amp; Aila, 2017;</ref><ref type="bibr" target="#b25">Tarvainen &amp; Valpola, 2017)</ref>, the most common perturbation is to apply domain-specific data augmentation <ref type="bibr" target="#b16">(Laine &amp; Aila, 2017;</ref><ref type="bibr" target="#b24">Sajjadi et al., 2016;</ref><ref type="bibr" target="#b2">Berthelot et al., 2019;</ref><ref type="bibr" target="#b27">Xie et al., 2019)</ref>. The loss function used to measure consistency is typically either the mean-squared error <ref type="bibr" target="#b16">(Laine &amp; Aila, 2017;</ref><ref type="bibr" target="#b25">Tarvainen &amp; Valpola, 2017;</ref><ref type="bibr" target="#b24">Sajjadi et al., 2016)</ref> or cross-entropy <ref type="bibr" target="#b21">(Miyato et al., 2018;</ref><ref type="bibr" target="#b27">Xie et al., 2019)</ref> between the model's output for a perturbed and non-perturbed input. <ref type="bibr" target="#b11">Grandvalet &amp; Bengio (2005)</ref> argues that unlabeled data should be used to ensure that classes are well-separated. This can be achieved by encouraging the model's output distribution to have low entropy (i.e., to make "high-confidence" predictions) on unlabeled data. For example, one can explicitly add a loss term to minimize the entropy of the model's predicted class distribution on unlabeled data <ref type="bibr" target="#b11">(Grandvalet &amp; Bengio, 2005;</ref><ref type="bibr" target="#b21">Miyato et al., 2018)</ref>. Related to this idea are "self-training" methods <ref type="bibr" target="#b20">(McLachlan, 1975;</ref><ref type="bibr" target="#b23">Rosenberg et al., 2005)</ref> such as Pseudo-Label <ref type="bibr" target="#b17">(Lee, 2013)</ref> that use the predicted class on an unlabeled input as a hard target for the same input, which implicitly minimizes the entropy of the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entropy Minimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard Regularization</head><p>Outside of the setting of SSL, it is often useful to regularize models in the over-parameterized regime. This regularization can often be applied both when training on labeled and unlabeled data. For example, standard "weight decay" <ref type="bibr" target="#b12">(Hinton &amp; van Camp, 1993)</ref> where the L 2 norm of parameters is minimized is often used alongside SSL techniques. Similarly, powerful MixUp regularization <ref type="bibr" target="#b31">(Zhang et al., 2017</ref>) which trains a model on linear interpolants of inputs and labels has recently been applied to SSL <ref type="bibr" target="#b2">(Berthelot et al., 2019;</ref><ref type="bibr" target="#b26">Verma et al., 2019)</ref>.</p><p>Other Approaches The three aforementioned categories of SSL techniques does not cover the full literature on semi-supervised learning. For example, there is a significant body of research on "transductive" or graph-based semi-supervised learning techniques which leverage the idea that unlabeled datapoints should be assigned the label of a labeled datapoint if they are sufficiently similar <ref type="bibr" target="#b9">(Gammerman et al., 1998;</ref><ref type="bibr" target="#b14">Joachims, 2003;</ref><ref type="bibr" target="#b13">1999;</ref><ref type="bibr" target="#b1">Bengio et al., 2006;</ref><ref type="bibr" target="#b19">Liu et al., 2018)</ref>. Since our work does not involve these (or other) approaches to SSL, we will not discuss them further. A more substantial overview of SSL methods is available in <ref type="bibr" target="#b5">(Chapelle et al., 2006)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">MIXMATCH</head><p>MixMatch <ref type="bibr" target="#b2">(Berthelot et al., 2019)</ref> unifies several of the previously mentioned SSL techniques. The algorithm works by generating "guessed labels" for each unlabeled example, and then using fullysupervised techniques to train on the original labeled data along with the guessed labels for the unlabeled data. This section reviews the necessary details of MixMatch; see <ref type="bibr" target="#b2">(Berthelot et al., 2019)</ref> for a full definition. MixMatch first produces K weakly augmented versions of each unlabeled datapointû b,k for k ∈ {1, . . . , K}. Then, it generates a "guessed label" q b for each u b by computing the average predictionq b across the K augmented versions:q b = 1 K k p model (y |û b,k ; θ). The guessed label distribution is then sharpened by adjusting its temperature (i.e. raising all probabilities to a power of 1 ⁄T and renormalizing). Finally, pairs of examples (x 1 , p 1 ), (x 2 , p 2 ) from the combined set of labeled examples and unlabeled examples with label guesses are fed into the MixUp <ref type="bibr" target="#b31">(Zhang et al., 2017)</ref> algorithm to compute examples (x , p ) where x = λx 1 + (1 − λ)x 2 for λ ∼ Beta(α, α), and similarly for p . Given these mixed-up examples, MixMatch performs standard fully-supervised training with minor modifications. A standard cross-entropy loss is used for labeled data, whereas the loss for unlabeled data is computed using a mean square error (i.e. the Brier score <ref type="bibr" target="#b4">(Brier, 1950)</ref>) and is weighted with a hyperparameter λ U . The terms K (number of augmentations), T (sharpening temperature), α (MixUp Beta parameter), and λ U (unlabeled loss weight) are MixMatch's hyperparameters. For augmentation, shifting and flipping was used for the CIFAR-10, CIFAR-100, and STL-10 datasets, and shifting alone was used for SVHN.</p><formula xml:id="formula_0">Let X = (x b , p b ) : b ∈ (1, . . . , B) be</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">REMIXMATCH</head><p>Having introduced MixMatch, we now turn to the two improvements we propose in this paper: Distribution alignment and augmentation anchoring. For clarity, we describe how we integrate them into the base MixMatch algorithm; the full algorithm for ReMixMatch is shown in algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DISTRIBUTION ALIGNMENT</head><p>Our first contribution is distribution alignment, which enforces that the aggregate of predictions on unlabeled data matches the distribution of the provided labeled data. This general idea was first introduced over 25 years ago <ref type="bibr" target="#b3">(Bridle et al., 1992)</ref>, but to the best of our knowledge is not used in modern SSL techniques. A schematic of distribution alignment can be seen in <ref type="figure" target="#fig_0">fig. 1</ref>. After reviewing and extending the theory, we describe how it can be straightforwardly included in ReMixMatch. </p><formula xml:id="formula_1">X = (x b , p b ) : b ∈ (1, . . . , B) , batch of unlabeled examples U = u b : b ∈ (1, . . . , B) , sharpening temperature T , number of augmentations K, Beta distribution parameter α for MixUp. 2: for b = 1 to B do 3:x b = StrongAugment(x b ) // Apply strong data augmentation to x b 4:û b,k = StrongAugment(u b ); k ∈ {1, . . . , K} // Apply strong data augmentation K times to u b 5:ũ b = WeakAugment(u b ) // Apply weak data augmentation to u b 6: q b = p model (y |ũ b ; θ) // Compute prediction for weak augmentation of u b 7: q b = Normalize(q b × p(y) p(y)) // Apply distribution alignment 8: q b = Normalize q 1/T b</formula><p>// Apply temperature sharpening to label guess 9: end for 10:</p><formula xml:id="formula_2">X = (x b , p b ); b ∈ (1, . . . , B) //</formula><p>Augmented labeled examples and their labels</p><formula xml:id="formula_3">11:Û1 = (û b,1 , q b ); b ∈ (1, . . . , B)</formula><p>// First strongly augmented unlabeled example and guessed label 12: </p><formula xml:id="formula_4">Û = (û b,k , q b ); b ∈ (1, . . . , B), k ∈ (1, . . . , K) // All strongly augmented unlabeled examples 13:Û =Û ∪ (ũ b , q b ); b ∈ (1, . . . , B) //</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">INPUT-OUTPUT MUTUAL INFORMATION</head><p>As previously mentioned, the primary goal of an SSL algorithm is to incorporate unlabeled data in a way which improves a model's performance. One way to formalize this intuition, first proposed by <ref type="bibr" target="#b3">Bridle et al. (1992)</ref>, is to maximize the mutual information between the model's input and output for unlabeled data. Intuitively, a good classifier's prediction should depend as much as possible on the input. Following the analysis from <ref type="bibr" target="#b3">Bridle et al. (1992)</ref>, we can formalize this objective as</p><formula xml:id="formula_5">I(y; x) = p(y, x) log p(y, x) p(y)p(x) dy dx (1) = H(E x [p model (y|x; θ)]) − E x [H(p model (y|x; θ))]<label>(2)</label></formula><p>where H(·) refers to the entropy. See Appendix A for a proof. To interpret this result, observe that the second term in eq. (2) is the familiar entropy minimization objective <ref type="bibr" target="#b11">(Grandvalet &amp; Bengio, 2005)</ref>, which simply encourages each individual model output to have low entropy (suggesting high confidence in a class label). The first term, however, is not widely used in modern SSL techniques. This term (roughly speaking) encourages that on average, across the entire training set, the model predicts each class with equal frequency. <ref type="bibr" target="#b3">Bridle et al. (1992)</ref> refer to this as the model being "fair".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">DISTRIBUTION ALIGNMENT IN REMIXMATCH</head><p>MixMatch already includes a form of entropy minimization via the "sharpening" operation which makes the guessed labels (synthetic targets) for unlabeled data have lower entropy. We are therefore interested in also incorporating a form of "fairness" in ReMixMatch. However, note that the objective H(E x [p model (y|x; θ)]) on its own essentially implies that the model should predict each class with equal frequency. This is not necessarily a useful objective if the dataset's marginal class distribution p(y) is not uniform. Furthermore, while it would in principle be possible to directly minimize this objective on a per-batch basis, we are instead interested in integrating it into MixMatch in a way which does not introduce an additional loss term or any sensitive hyperparameters.</p><p>To address these issues, we incorporate a form of fairness we call "distribution alignment" which proceeds as follows: over the course of training, we maintain a running average of the model's predictions on unlabeled data, which we refer to asp(y). Given the model's prediction q = p model (y|u; θ) on an unlabeled example u, we scale q by the ratio p(y)/p(y) and then renormalize the result to form a valid probability distribution:q = Normalize(q × p(y)/p(y)) where</p><p>Normalize(x) i = x i / j x j . We then useq as the label guess for u, and proceed as usual with sharpening and other processing. In practice, we computep(y) as the moving average of the model's predictions on unlabeled examples over the last 128 batches. We also estimate the marginal class distribution p(y) based on the labeled examples seen during training. Note that a better estimate for p(y) could be used if it is known a priori; in this work we do not explore this direction further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">IMPROVED CONSISTENCY REGULARIZATION</head><p>Consistency regularization underlies most SSL methods <ref type="bibr" target="#b21">(Miyato et al., 2018;</ref><ref type="bibr" target="#b25">Tarvainen &amp; Valpola, 2017;</ref><ref type="bibr" target="#b2">Berthelot et al., 2019;</ref><ref type="bibr" target="#b27">Xie et al., 2019)</ref>. For image classification tasks, consistency is typically enforced between two augmented versions of the same unlabeled image. In order to enforce a form of consistency regularization, MixMatch generates K (in practice, K = 2) augmentations of each unlabeled example u and averages them together to produce a "guessed label" for u.</p><p>Recent work <ref type="bibr" target="#b27">(Xie et al., 2019)</ref> found that applying stronger forms of augmentation can significantly improve the performance of consistency regularization. In particular, for image classification tasks it was shown that using variants of AutoAugment (Cubuk et al., 2018) produced substantial gains.</p><p>Since MixMatch uses a simple flip-and-crop augmentation strategy, we were interested to see if replacing the weak augmentation in MixMatch with AutoAugment would improve performance but found that training would not converge. To circumvent this issue, we propose a new method for consistency regularization in MixMatch called "Augmentation Anchoring". The basic idea is to use the model's prediction for a weakly augmented unlabeled image as the guessed label for many strongly augmented versions of the same image.</p><p>A further logistical concern with using AutoAugment is that it uses reinforcement learning to learn a policy which requires many trials of supervised model training. This poses issues in the SSL setting where we often have limited labeled data. To address this, we propose a variant of Au-toAugment called "CTAugment" which adapts itself online using ideas from control theory without requiring any form of reinforcement learning-based training. We describe Augmentation Anchoring and CTAugment in the following two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">AUGMENTATION ANCHORING</head><p>We hypothesize the reason MixMatch with AutoAugment is unstable is that MixMatch averages the prediction across K augmentations. Stronger augmentation can result in disparate predictions, so their average may not be a meaningful target. Instead, given an unlabeled input we first generate an "anchor" by applying weak augmentation to it. Then, we generate K strongly-augmented versions of the same unlabeled input using CTAugment (described below). We use the guessed label (after applying distribution alignment and sharpening) as the target for all of the K strongly-augmented versions of the image. This process is visualized in <ref type="figure">fig. 2</ref>.</p><p>While experimenting with Augmentation Anchoring, we found it enabled us to replace MixMatch's unlabeled-data mean squared error loss with a standard cross-entropy loss. This maintained stability while also simplifying the implementation. While MixMatch achieved its best performance at only K = 2, we found that augmentation anchoring benefited from a larger value of K = 8. We compare different values of K in section 4 to measure the gain achieved from additional augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">CONTROL THEORY AUGMENT</head><p>AutoAugment (Cubuk et al., 2018) is a method for learning a data augmentation policy which results in high validation set accuracy. An augmentation policy consists a sequence of transformationparameter magnitude tuples to apply to each image. Critically, the AutoAugment policy is learned with supervision: the magnitudes and sequence of transformations are determined via training many models on a proxy task which e.g. involves the use of 4,000 labels on CIFAR-10 and 1,000 labels on <ref type="bibr">SVHN (Cubuk et al., 2018)</ref>. This makes applying AutoAugment methodologically problematic for low-label SSL. To remedy this necessity for training a policy on labeled data, RandAugment (Cubuk et al., 2019) uniformly randomly samples transformations, but requires tuning the hyper-parameters for the random sampling on the validation set, which again is methodologically difficult when only very few (e.g., 40 or 250) labeled examples are available.</p><p>Thus, in this work, we develop CTAugment, an alternative approach to designing high-performance augmentation strategies. Like RandAugment, CTAugment also uniformly randomly samples transformations to apply but dynamically infers magnitudes for each transformation during the training process. Since CTAugment does not need to be optimized on a supervised proxy task and has no sensitive hyperparameters, we can directly include it in our semi-supervised models to experiment with more aggressive data augmentation in semi-supervised learning. Intuitively, for each augmentation parameter, CTAugment learns the likelihood that it will produce an image which is classified as the correct label. Using these likelihoods, CTAugment then only samples augmentations that fall within the network tolerance. This process is related to what is called density-matching in Fast AutoAugment <ref type="bibr" target="#b18">(Lim et al., 2019)</ref>, where policies are optimized so that the density of augmented validation images match the density of images from the training set.</p><p>First, CTAugment divides each parameter for each transformation into bins of distortion magnitude as is done in AutoAugment (see Appendix C for a list of the bin ranges). Let m be the vector of bin weights for some distortion parameter for some transformation. At the beginning of training, all magnitude bins are initialized to have a weight set to 1. These weights are used to determine which magnitude bin to apply to a given image.</p><p>At each training step, for each image two transformations are sampled uniformly at random. To augment images for training, for each parameter of these transformations we produce a modified set of bin weightsm wherem i = m i if m i &gt; 0.8 andm i = 0 otherwise, and sample magnitude bins from Categorical(Normalize(m)). To update the weights of the sampled transformations, we first sample a magnitude bin m i for each transformation parameter uniformly at random. The resulting transformations are applied to a labeled example x with label p to obtain an augmented versionx. Then, we measure the extent to which the model's prediction matches the label as ω = 1 − 1 2L |p model (y|x; θ) − p|. The weight for each sampled magnitude bin is updated as m i = ρm i + (1 − ρ)ω where ρ = 0.99 is a fixed exponential decay hyperparameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">PUTTING IT ALL TOGETHER</head><p>ReMixMatch's algorithm for processing a batch of labeled and unlabeled examples is shown in algorithm 1. The main purpose of this algorithm is to produce the collections X and U , consisting of augmented labeled and unlabeled examples with MixUp applied. The labels and label guesses in X and U are fed into standard cross-entropy loss terms against the model's predictions. Algorithm 1 also outputsÛ 1 , which consists of a single heavily-augmented version of each unlabeled image and its label guesses without MixUp applied.Û 1 is used in two additional loss terms which provide a mild boost in performance in addition to improved stability:</p><p>Pre-mixup unlabeled loss We feed the guessed labels and predictions for example inÛ 1 as-is into a separate cross-entropy loss term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rotation loss</head><p>Recent result have shown that applying ideas from self-supervised learning to SSL can produce strong performance <ref type="bibr" target="#b10">(Gidaris et al., 2018;</ref><ref type="bibr" target="#b29">Zhai et al., 2019)</ref>. We integrate this idea by rotating each image u ∈Û 1 as Rotate(u, r) where we sample the rotation angle r uniformly from r ∼ {0, 90, 180, 270} and then ask the model to predict the rotation amount as a four-class classification problem.</p><p>In total, the ReMixMatch loss is </p><p>Hyperparameters ReMixMatch introduce two new hyperparameters: the weight on the rotation loss λ r and the weight on the un-augmented example λÛ 1 . In practice both are fixed λ r = λÛ 1 = 0.5. ReMixMatch also shares many hyperparameters from MixMatch: the weight for the unlabeled loss λ U , the sharpening temperature T , the MixUp Beta parameter, and the number of augmentations K. All experiments (unless otherwise stated) use T = 0.5, Beta = 0.75, and λ U = 1.5. We found using a larger number of augmentations monotonically increases accuracy, and so set K = 8 for all experiments (as running with K augmentations increases computation by a factor of K).</p><p>We train our models using Adam <ref type="bibr" target="#b15">(Kingma &amp; Ba, 2015)</ref> with a fixed learning rate of 0.002 and weight decay <ref type="bibr" target="#b30">(Zhang et al., 2018)</ref> with a fixed value of 0.02. We take the final model as an exponential moving average over the trained model weights with a decay of 0.999.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We now test the efficacy of ReMixMatch on a set of standard semi-supervised learning benchmarks. Unless otherwise noted, all of the experiments performed in this section use the same codebase and model architecture (a Wide ResNet-28-2 <ref type="bibr" target="#b28">(Zagoruyko &amp; Komodakis, 2016)</ref> with 1.5 million parameters, as used in <ref type="bibr" target="#b22">(Oliver et al., 2018)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">REALISTIC SSL SETTING</head><p>We follow the Realistic Semi-Supervised Learning <ref type="bibr" target="#b22">(Oliver et al., 2018)</ref> recommendations for performing SSL evaluations. In particular, as mentioned above, this means we use the same model and training algorithm in the same codebase for all experiments. We compare against VAT <ref type="bibr" target="#b21">(Miyato et al., 2018)</ref> and MeanTeacher <ref type="bibr" target="#b25">(Tarvainen &amp; Valpola, 2017)</ref>, copying the re-implementations over from the MixMatch codebase <ref type="bibr" target="#b2">(Berthelot et al., 2019)</ref>.</p><p>Fully supervised baseline To begin, we train a fully-supervised baseline to measure the highest accuracy we could hope to obtain with our training pipeline. The experiments we perform use the same model and training algorithm, so these baselines are valid for all discussed SSL techniques. On CIFAR-10, we obtain an fully-supervised error rate of 4.25% using weak flip + crop augmentation, which drops to 3.62% using AutoAugment and 3.91% using CTAugment. Similarly, on SVHN we obtain 2.70% error using weak (flip) augmentation and 2.31% and 2.16% using AutoAugment and CTAugment respectively. While AutoAugment performs slightly better on CIFAR-10 and slightly worse on SVHN compared to CTAugment, it is not our intent to design a better augmentation strategy; just one that can be used without a pre-training or tuning of hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10</head><p>Our results on CIFAR-10 are shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">STL-10</head><p>The STL-10 dataset consists of 5,000 labeled 96 × 96 color images drawn from 10 classes and 100,000 unlabeled images drawn from a similar-but not identical-data distribution. The labeled set is partitioned into ten pre-defined folds of 1,000 images each. For efficiency, we only run our analysis on five of these ten folds. We do not perform evaluation here under the Realistic SSL <ref type="bibr" target="#b22">(Oliver et al., 2018)</ref> setting when comparing to non-MixMatch results. Our results are, however, directly comparable to the MixMatch results. Using the same WRN-37-2 network (23.8 million parameters), we reduce the error rate by a factor of two compared to MixMatch.   <ref type="bibr" target="#b32">(Zhao et al., 2015)</ref> and <ref type="bibr" target="#b8">(Denton et al., 2016)</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">TOWARDS FEW-SHOT LEARNING</head><p>We find that ReMixMatch is able to work in extremely low-label settings. By only changing λ r from 0.5 to 2 we can train CIFAR-10 with just four labels per class and SVHN with only 40 labels total.</p><p>On CIFAR-10 we obtain a median-of-five error rate of 15.08%; on SVHN we reach 3.48% error and on SVHN with the "extra" dataset we reach 2.81% error. Full results are given in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">ABLATION STUDY</head><p>Because we have made several changes to the existing MixMatch algorithm, here we perform an ablation study and remove one component of ReMixMatch at a time to understand from which changes produce the largest accuracy gains. Our ablation results are summarized in <ref type="table" target="#tab_4">Table 3</ref>. We find that removing the pre-mixup unlabeled loss, removing distribution alignment, and lowering K all hurt performance by a small amount. Given that distribution alignment improves performance, we were interested to see whether it also had the intended effect of making marginal distribution of model predictions match the ground-truth marginal class distribution. We measure this directly in appendix D. Removing the rotation loss reduces accuracy at 250 labels by only 0.14 percentage points, but we find that in the 40-label setting rotation loss is necessary to prevent collapse. Changing the cross-entropy loss on unlabeled data to an L2 loss as used in MixMatch hurts performance dramatically, as does removing either of the augmentation components. This validates using augmentation anchoring in place of the consistency regularization mechanism of MixMatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Progress on semi-supervised learning over the past year has upended many of the long-held beliefs about classification, namely, that vast quantities of labeled data is necessary. By introducing augmentation anchoring and distribution alignment to MixMatch, we continue this trend: ReMixMatch reduces the quantity of labeled data needed by a large factor compared to prior work (e.g., beating MixMatch at 4000 labeled examples with only 250 on CIFAR-10, and closely approaching Mix-Match at 5000 labeled examples with only 1000 on STL-10). In future work, we are interested in pushing the limited data regime further to close the gap between few-shot learning and SSL. We also note that in many real-life scenarios, a dataset begins as unlabeled and is incrementally labeled until satisfactory performance is achieved. Our strong empirical results suggest that it will be possible to achieve gains in this "active learning" setting by using ideas from ReMixMatch. Finally, in this paper we present results on widely-studied image benchmarks for ease of comparison. However, the true power of data-efficient learning will come from applying these techniques to real-world problems where obtaining labeling data is expensive or impractical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOF OF EQUATION 2</head><p>The proof here follows closely <ref type="bibr" target="#b3">Bridle et al. (1992)</ref>. We begin with the definition</p><formula xml:id="formula_7">I(y; x) = p(y, x) log p(y, x) p(y)p(x) dy dx<label>(5)</label></formula><p>Rewriting terms we obtain</p><formula xml:id="formula_8">= p(x) dx p(y|x) log p(y|x) p(y) dy (6) = p(x) dx p(y|x) log p(y|x) p(x)p(y|x) dx dy<label>(7)</label></formula><p>Then, rewriting both integrals as expectations we obtain   </p><formula xml:id="formula_9">= E x p(y|x) log p(y|x) E x [p(y|x)] dy (8) = E x L i=1 p(y i |x) log p(y i |x) E x [p(y i |x)] (9) = E x L i=1 p(y i |x) log p(y i |x) − E x L i=1 p(y i |x) log E x [p(y i |x)] (10) = E x L i=1 p(y i |x) log p(y i |x) − L i=1 E x [p(y i |x)] log E x [p(y i |x)]] (11) = H(E x [p model (y|x; θ)]) − E x [H(p model (y|x; θ))]<label>(12</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D MEASURING THE EFFECT OF DISTRIBUTION ALIGNMENT</head><p>Recall that the goal of distribution alignment is to encourage the marginal distribution of the model's predictionsp(y) to match the true marginal class distribution p(y). To measure whether distribution alignment indeed has this effect, we monitored the KL divergence betweenp(y) and p(y) over the course of training. We show the KL divergence for a training run on CIFAR-10 with 250 labels with and without distribution alignment in <ref type="figure" target="#fig_5">fig. 3</ref>. Indeed, the KL divergence betweenp(y) and p(y) is significantly smaller throughout training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E CTAUGMENT PARAMETERS EFFECTS</head><p>In this section we compare the effects of varying the CTAugment hyper-parameters on CIFAR10 with 250 labels, using the standard ReMixMatch settings. The exponential weight decay ρ does not effect the results significantly while depth and threshold have significant effects. The default settings are highlighted in the table. They appear to perform well and have been shown to be robust across many datasets in our previous experiments.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Distribution alignment. Guessed label distributions are adjusted according to the ratio of the empirical ground-truth class distribution divided by the average model predictions on unlabeled data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>a batch of labeled data and their corresponding one-hot labels representing one of L classes and letx b be augmented versions of these labeled examples. Similarly, let U = u b : b ∈ (1, . . . , B) be a batch of unlabeled examples. Finally, let p model (y | x; θ) be the predicted class distribution produced by the model for input x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>ReMixMatch algorithm for producing a collection of processed labeled examples and processed unlabeled examples with label guesses (cf. Berthelot et al. (2019) Algorithm 1.) 1: Input: Batch of labeled examples and their one-hot labels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Add weakly augmented unlabeled examples 14: W = Shuffle Concat(X ,Û) // Combine and shuffle labeled and unlabeled data 15: X = MixUp(Xi, Wi); i ∈ (1, . . . , |X |) // Apply MixUp to labeled data and entries from W 16: U = MixUp(Ûi, W i+|X | ); i ∈ (1, . . . , |Û|) // Apply MixUp to unlabeled data and the rest of W 17: return X , U ,Û1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>p model (y|x; θ)) + λ U u,q∈U H(q, p model (y|u; θ)) p model (y|u; θ)) + λ r u∈Û1 H(r, p model (r| Rotate(u, r); θ))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>KL divergence between the marginal distribution of model predictions vs. the true marginal distribution of class labels over the course of training with and without distribution alignment. This figure corresponds to a training run on CIFAR-10 with 250 labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>table 1 ,Table 1 :</head><label>11</label><figDesc>left. ReMixMatch sets the new stateof-the-art for all numbers of labeled examples. Most importantly, ReMixMatch is 16× more data efficient than MixMatch (e.g., at 250 labeled examples ReMixMatch has identical accuracy compared to MixMatch at 4,000). SVHN Results for SVHN are shown in table 1, right. ReMixMatch reaches state-of-the-art at 250labeled examples, and within the margin of error for state-of-the-art otherwise. Results on CIFAR-10 and SVHN. * For UDA, due to adaptation difficulties, we report the results from<ref type="bibr" target="#b27">Xie et al. (2019)</ref> which are not comparable to our results due to a different network implementation, training procedure, etc. For VAT, Mean Teacher, and MixMatch, we report results using our reimplementation, which makes them directly comparable to ReMixMatch's scores.</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell></cell><cell>SVHN</cell></row><row><cell>Method</cell><cell>250 labels</cell><cell>1000 labels</cell><cell>4000 labels</cell><cell cols="3">250 labels 1000 labels 4000 labels</cell></row><row><cell>VAT</cell><cell cols="4">36.03±2.82 18.64±0.40 11.05±0.31 8.41±1.01</cell><cell>5.98±0.21</cell><cell>4.20±0.15</cell></row><row><cell>Mean Teacher</cell><cell cols="4">47.32±4.71 17.32±4.00 10.36±0.25 6.45±2.43</cell><cell>3.75±0.10</cell><cell>3.39±0.11</cell></row><row><cell>MixMatch</cell><cell>11.08±0.87</cell><cell>7.75±0.32</cell><cell cols="2">6.24±0.06 3.78±0.26</cell><cell>3.27±0.31</cell><cell>2.89±0.06</cell></row><row><cell>ReMixMatch</cell><cell>6.27±0.34</cell><cell>5.73±0.16</cell><cell cols="2">5.14±0.04 3.10±0.50</cell><cell>2.83±0.30</cell><cell>2.42±0.09</cell></row><row><cell>UDA, reported*</cell><cell>8.76±0.90</cell><cell>5.87±0.13</cell><cell cols="2">5.29±0.25 2.76±0.17</cell><cell>2.55±0.09</cell><cell>2.47±0.15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: STL-10 error rate using</cell></row><row><cell>1000-label splits. SWWAE and CC-</cell></row><row><cell>GAN results are from</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Ablation study. Error rates are reported on a single</cell></row><row><cell>250-label split from CIFAR-10.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>the full results for running ReMixMatch with just 40 labeled examples. We sort the table by error rate over five different splits (i.e., 40-label subsets) of the training data. High variance is to be expected when choosing so few labeled examples at random.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>)</cell></row><row><cell>B FULL 40 LABEL RESULTS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>We now report Dataset</cell><cell></cell><cell cols="3">Split (ordered by error rate)</cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>CIFAR-10</cell><cell cols="5">10.88 12.65 15.08 16.78 19.49</cell></row><row><cell>SVHN</cell><cell>3.43</cell><cell>3.46</cell><cell>3.48</cell><cell cols="2">4.06 12.24</cell></row><row><cell>SVHN+extra</cell><cell>2.59</cell><cell>2.71</cell><cell>2.81</cell><cell cols="2">3.50 15.14</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Sorted error rate of ReMixMatch with 40 labeled examples. C TRANSFORMATIONS INCLUDED IN CTAUGMENT</figDesc><table><row><cell cols="2">Transformation Description</cell><cell cols="2">Parameter Range</cell></row><row><cell>Autocontrast</cell><cell>Maximizes the image contrast by setting the dark-</cell><cell>λ</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>est (lightest) pixel to black (white), and then</cell><cell></cell><cell></cell></row><row><cell></cell><cell>blends with the original image with blending ra-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>tio λ.</cell><cell></cell><cell></cell></row><row><cell>Blur</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Brightness</cell><cell>Adjusts the brightness of the image. B = 0 re-</cell><cell>B</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>turns a black image, B = 1 returns the original</cell><cell></cell><cell></cell></row><row><cell></cell><cell>image.</cell><cell></cell><cell></cell></row><row><cell>Color</cell><cell>Adjusts the color balance of the image like in a</cell><cell>C</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>TV. C = 0 returns a black &amp; white image, C = 1</cell><cell></cell><cell></cell></row><row><cell></cell><cell>returns the original image.</cell><cell></cell><cell></cell></row><row><cell>Contrast</cell><cell>Controls the contrast of the image. A C = 0 re-</cell><cell>C</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>turns a gray image, C = 1 returns the original</cell><cell></cell><cell></cell></row><row><cell></cell><cell>image.</cell><cell></cell><cell></cell></row><row><cell>Cutout</cell><cell>Sets a random square patch of side-length</cell><cell>L</cell><cell>[0, 0.5]</cell></row><row><cell></cell><cell>(L×image width) pixels to gray.</cell><cell></cell><cell></cell></row><row><cell>Equalize</cell><cell>Equalizes the image histogram, and then blends</cell><cell>λ</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>with the original image with blending ratio λ.</cell><cell></cell><cell></cell></row><row><cell>Invert</cell><cell>Inverts the pixels of the image, and then blends</cell><cell>λ</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>with the original image with blending ratio λ.</cell><cell></cell><cell></cell></row><row><cell>Identity</cell><cell>Returns the original image.</cell><cell></cell><cell></cell></row><row><cell>Posterize</cell><cell>Reduces each pixel to B bits.</cell><cell>B</cell><cell>[1, 8]</cell></row><row><cell>Rescale</cell><cell>Takes a center crop that is of side-length</cell><cell>L</cell><cell>[0.5, 1.0]</cell></row><row><cell></cell><cell>(L×image width), and rescales to the original im-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>age size using method M .</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>M</cell><cell>see caption</cell></row><row><cell>Rotate</cell><cell>Rotates the image by θ degrees.</cell><cell>θ</cell><cell>[-45, 45]</cell></row><row><cell>Sharpness</cell><cell>Adjusts the sharpness of the image, where S = 0</cell><cell>S</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>returns a blurred image, and S = 1 returns the</cell><cell></cell><cell></cell></row><row><cell></cell><cell>original image.</cell><cell></cell><cell></cell></row><row><cell>Shear x</cell><cell>Shears the image along the horizontal axis with</cell><cell>R</cell><cell>[-0.3, 0.3]</cell></row><row><cell></cell><cell>rate R.</cell><cell></cell><cell></cell></row><row><cell>Shear y</cell><cell>Shears the image along the vertical axis with rate</cell><cell>R</cell><cell>[-0.3, 0.3]</cell></row><row><cell></cell><cell>R.</cell><cell></cell><cell></cell></row><row><cell>Smooth</cell><cell>Adjusts the smoothness of the image, where S =</cell><cell>S</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>0 returns a maximally smooth image, and S = 1</cell><cell></cell><cell></cell></row><row><cell></cell><cell>returns the original image.</cell><cell></cell><cell></cell></row><row><cell>Solarize</cell><cell>Inverts all pixels above a threshold value of T .</cell><cell>T</cell><cell>[0, 1]</cell></row><row><cell>Translate x</cell><cell>Translates the image horizontally by (λ×image</cell><cell>λ</cell><cell>[-0.3, 0.3]</cell></row><row><cell></cell><cell>width) pixels.</cell><cell></cell><cell></cell></row><row><cell>Translate y</cell><cell>Translates the image vertically by (λ×image</cell><cell>λ</cell><cell>[-0.3, 0.3]</cell></row><row><cell></cell><cell>width) pixels.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>The ranges for all of the listed parameters are discretized into 17 equal bins. The only exception is the M parameter of the Rescale transformation, which takes on one of the following six options: anti-alias, bicubic, bilinear, box, hamming, and nearest.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Effects of hyper-parameters for CTAugment, the bold results are the default settings used for all experiments.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Label Propagation and Quadratic Criterion, chapter 11</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Delalleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised classifiers, mutual information and&apos;phantom targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">S</forename><surname>Bridle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J C</forename><surname>Heading</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Verification of forecasts expressed in terms of probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glenn</forename><forename type="middle">W</forename><surname>Brier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Monthey Weather Review</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09501</idno>
		<title level="m">Learning augmentation policies from data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Randaugment</surname></persName>
		</author>
		<idno>arXiv:XXXX.XXXXX</idno>
		<title level="m">An automated, randomized data augmentation strategy</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with context-conditional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06430</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning by transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gammerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodya</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Fourteenth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07728</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Keeping neural networks simple by minimizing the description length of the weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drew Van Camp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Annual ACM Conference on Computational Learning Theory</title>
		<meeting>the 6th Annual ACM Conference on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transductive inference for text classification using support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transductive learning via spectral graph partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbin</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ildoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiheon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.00397</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Fast autoaugment. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep metric transfer for label propagation with limited annotated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.08781</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Iterative reclassification procedure for constructing an asymptotically optimal rule of allocation in discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">350</biblScope>
			<biblScope unit="page" from="365" to="369" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3235" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semi-supervised self-training of object detection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuck</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh IEEE Workshops on Application of Computer Vision</title>
		<meeting>the Seventh IEEE Workshops on Application of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03825</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">s 4 l: Self-supervised semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.03670</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12281</idno>
		<title level="m">Three mechanisms of weight decay regularization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02351</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Stacked what-where auto-encoders. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
