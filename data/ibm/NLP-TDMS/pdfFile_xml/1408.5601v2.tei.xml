<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learn Convolutional Neural Network for Face Anti-Spoofing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
						</author>
						<title level="a" type="main">Learn Convolutional Neural Network for Face Anti-Spoofing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Though having achieved some progresses, the hand-crafted texture features, e.g., LBP [23], LBP-TOP <ref type="bibr" target="#b10">[11]</ref> are still unable to capture the most discriminative cues between genuine and fake faces. In this paper, instead of designing feature by ourselves, we rely on the deep convolutional neural network (CNN) to learn features of high discriminative ability in a supervised manner. Combined with some data pre-processing, the face anti-spoofing performance improves drastically. In the experiments, over 70% relative decrease of Half Total Error Rate (HTER) is achieved on two challenging datasets, CASIA <ref type="bibr" target="#b35">[36]</ref> and REPLAY-ATTACK [7] compared with the -state-ofthe-art. Meanwhile, the experimental results from inter-tests between two datasets indicates CNN can obtain features with better generalization ability. Moreover, the nets trained using combined data from two datasets have less biases between two datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Face anti-spoofing, as a security measure for face recognition system, are drawing increasing attentions in both academic and industrial fields. However, due to the diversity of spoofing types, including print-attacks, replay-attacks, maskattacks, etc., it is still a difficult work to distinguish various fake faces. In <ref type="figure" target="#fig_1">Fig. 1</ref>, some randomly sampled genuine and fake face images are shown to evaluate the anti-spoofing ability of our eyes. Among all the face images, three are genuine and five are fake <ref type="bibr" target="#b0">1</ref> . Admittedly, no obvious visual cues are available for us to pick the genuine face images from the gallery.</p><p>Recently, researchers are devoted to come up with more generalized and discriminative features for face antispoofing, such as LBP <ref type="bibr" target="#b22">[23]</ref> <ref type="bibr" target="#b34">[35]</ref>, HOG <ref type="bibr" target="#b19">[20]</ref> <ref type="bibr" target="#b34">[35]</ref>, LBP-TOP <ref type="bibr" target="#b10">[11]</ref>, DoG <ref type="bibr" target="#b29">[30]</ref>  <ref type="bibr" target="#b26">[27]</ref>, etc. In general, these features are all called hand-crafted features because they are designed manually. In this paper, however, we exploit deep convolutional neural network (CNN) for face anti-spoofing. To the best of our knowledge, this is the first attempt. Compared with above hand-crafted features, the features learned from CNN are able to catch more discriminative cues in a data-driven manner. More importantly, according to the experimental results, it has the potential to learn more general features for various spoofing types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Due to the diversity of spoofing attacks, existing face antispoofing approaches can be mainly categorized into four  groups: texture based, motion based, 3D-shape based and multi-spectral reflectance based. Besides, some other works combined two or more of these methods to improve the antispoofing performance.</p><p>1) Texture-based Anti-Spoofing: In <ref type="bibr" target="#b21">[22]</ref>, Li et al. proposed a method based on the analysis of Fourier spectra. In this method, it is assumed that the photographs contain fewer high frequency components compared with genuine faces. In <ref type="bibr" target="#b29">[30]</ref>, Tan et al. used a variational retinex-based method and the difference-of-Gaussian (DoG) filers to extract latent reflectance features on face images. Inspired by Tan's work, Peixoto et al. <ref type="bibr" target="#b26">[27]</ref> combined the DoG filters and standard Sparse Logistic Regression Model for anti-spoofing under extreme illuminations. After that, Määttä et al. <ref type="bibr" target="#b22">[23]</ref> proposed to use LBP features for anti-spoofing, which outperformed previous methods on the NUAA Photograph Imposter Database <ref type="bibr" target="#b30">[31]</ref>. Furthermore, its efficiency on the REPLAY-ATTACK database was presented in <ref type="bibr" target="#b6">[7]</ref>.</p><p>In <ref type="bibr" target="#b10">[11]</ref>, Pereira et al. used a spatio-temporal texture feature called Local Binary Patterns from Three Orthogonal Planes (LBP-TOP). According to the experimental results on the REPLAY-ATTACK database, it outperformed the LBP-based method in <ref type="bibr" target="#b22">[23]</ref>. In <ref type="bibr" target="#b9">[10]</ref>, it is shown that LBP and LBP-TOP features are applicable in intra-database protocol. However, the countermeasures performance degraded much in a more realistic scenario, i.e., inter-database protocol. The reason for the low generalization ability of texture features was partially explained in the paper <ref type="bibr" target="#b34">[35]</ref>. The authors found many factors may affect the textures on a face image, including abnormal shadings, highlights, device noises, etc. Actually, the usage of texture features are not confined in above papers. In the 1 st and 2 nd competition on 2D face anti-spoofing <ref type="bibr" target="#b3">[4]</ref>  <ref type="bibr" target="#b7">[8]</ref>, most of the teams used textures as clues for anti-spoofing.</p><p>2) Motion-based Anti-Spoofing: Beyond the texture features, motion is another cues for face anti-spoofing. In <ref type="bibr" target="#b28">[29]</ref>[24], Pan et al. used eye blinking for face anti-spoofing.</p><p>In their method, a conditional random field was constructed to model different stages of eye blinking. In <ref type="bibr" target="#b17">[18]</ref>, Kollreider et al. used lip movement classification and lip-reading for the purpose of liveness detection. The system requires users to utter a sequence of words, and then verify whether the observed lip dynamics fit in the words. Furthermore, Chetty et al. <ref type="bibr" target="#b4">[5]</ref> <ref type="bibr" target="#b5">[6]</ref> proposed a multi-modal approach to aggrandize the difficulty of spoofing attacks. It determined the liveness by verifying the fitness between video and audio signals.</p><p>On the other hand, some previous works focused on physical motions for anti-spoofing. In <ref type="bibr" target="#b2">[3]</ref>, Bao et al. presented a method using optical flow fields to distinguish 2-D planar photography attacks and 3-D real faces. Similarly, Kollreider et al. <ref type="bibr" target="#b15">[16]</ref> [19] also relied their method on optical flow analysis. The method is based on the assumption that a 3-D face generates a special 2-D motion which is higher at central face parts (e.g. nose) compared to the outer face regions (e.g. ears). More recently, Anjos et al. proposed to recognize spoofing attacks based on the correlation between optical flows in foreground and background regions <ref type="bibr" target="#b0">[1]</ref>. At the same time, Yang et al. presented a counter measure to replay attacks based on the correlations among optical magnitude/phase sequences from 11 regions, which won the first place after combining with a texture-based method <ref type="bibr" target="#b7">[8]</ref>. Besides, Kollreider et al. <ref type="bibr" target="#b16">[17]</ref> used eye-blinking and face movements for detecting liveness in an interaction scenario.</p><p>3) 3D Shape-based Anti-Spoofing: In <ref type="bibr" target="#b11">[12]</ref>, Marsico et al. proposed a method for moving face anti-spoofing based on 3D projective invariants. However, this method can merely cope with photo attacks without warping, because the coplanar assumption is invalid for warped photos. Though warped photos do not satisfy the coplanar constrains as real face, there are still some intrinsic differences between them. In <ref type="bibr" target="#b32">[33]</ref>, the authors proposed to recover sparse 3D shapes for face images to detect various photo attacks. The performance on different warping types (none, vertically and horizontally) are evaluated, which showed that the method worked perfectly under both intra-database protocols and inter-database protocols. However, both methods will fail when coping with 3D mask spoofing, such as the 3D Mask Attack database (3DMAD) collected by Erdogmus et al. <ref type="bibr" target="#b12">[13]</ref>.</p><p>4) Multi-Spectral Reflectance-based Anti-Spoofing: The multi-spectral methods utilize the illuminations beyond visual spectrum for detect spoofing attacks. In <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b36">[37]</ref>, the authors selected proper working spectrums so that the reflectance differences between genuine and fake faces increased. Different from the methods directly using reflection intensities, a gradient-based multi-spectral method for face anti-spoofing was proposed in <ref type="bibr" target="#b13">[14]</ref>. The authors studied three illumination-robust features and evaluated the performance on different spectral bands. However, these methods need extra devices to capture face images under the invisible lights, thus it is unpractical to deploy such devices to the most of recent FR systems, which are merely based on RGB color face images.</p><p>Moreover, some works combined two or more of above four kinds of approaches. In <ref type="bibr" target="#b24">[25]</ref>, Pan et al. integrated scene context into their earlier eye blinking based antispoofing scheme. However, the so-called scene context is non-existed in many cases, such as the PRINT-ATTACK database. Toward the PRINT-ATTACK database, Tronci et al. employed motion, texture and liveness <ref type="bibr" target="#b31">[32]</ref> and achieved perfect performance on development set and test set. On the same database, Yan et al. <ref type="bibr" target="#b33">[34]</ref> explored multiple scenic clues, including non-rigid motion, face-background consistency and image banding effect, to detect the spoofing attacks, which achieved 100% accuracy on the test set. Recently, Chingovska et al proposed to integrate face recognition module into anti-spoofing system in score-level and feature level <ref type="bibr" target="#b1">[2]</ref>. 1) face localization: Before face anti-spoofing, face localization is indispensable. In previous works, a common face detector, e.g., Viola-Jones in OpenCV, is enough for this task. However, such rectangle-wise detector cannot provide precise face locations. Therefore, we implement the face alignment algorithm proposed in <ref type="bibr" target="#b27">[28]</ref> after a common Viola-Jones face detection. In the training stage, we extracts a set of local binary features, which are then used to learn a linear regressors in each cascade. During testing, an initial rectangle is provided by face detector, followed by a cascaded regression for the final output, i.e. a group of face landmarks. After obtaining the landmarks, their bounding box is regarded as the final face location. As shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, the initial rectangle is refined gradually based on face landmarks to obtain a more precise face location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Preparation</head><p>2) spatial augmentation: Different from some other faceoriented algorithms, such as face detection and face recognition, face anti-spoofing is more like an image quality diagnosing issue. Beyond the conventional face region, the backgrounds are helpful for the classification as well. In <ref type="bibr" target="#b3">[4]</ref>, the team UOULU exploited background region for feature extraction, and achieved best performance in the competition. In <ref type="bibr" target="#b34">[35]</ref>, the authors enlarged the conventional face region to contain a part of background, and proved the positive role of background region with various feature types. Inspired by their works, we also propose to enlarge the face region to contain background region. However, the difference is that we tend to use more backgrounds in our method. Though it is shown in <ref type="bibr" target="#b34">[35]</ref> that extra background made no difference on the face anti-spoofing performance, we argue that the hand-crafted features the author used encounter bottlenecks to exploit more information from background  regions. Alternatively, the CNN is more capable of learning discriminative features from backgrounds.</p><p>As shown in <ref type="figure" target="#fig_3">Fig. 3</ref>, we prepare the input images with five scales. Images corresponding to the first scale merely contain face region. With the increase of scale, images contain more background regions. As for CASIA-FASD dataset, we can easily find that fake images in large-scale contain boundaries of photographs compared with genuine images, which should be exploited as discriminative cues for anti-spoofing. In another case as REPLAY-ATTACK dataset, though fake images have no boundary cues, they contains blurred edges and probable abnormal specular reflections caused by re-capturing compared with genuine samples in whole images <ref type="bibr" target="#b34">[35]</ref>.</p><p>3) temporal augmentation: Besides spatial augmentations above, we also propose to augment the data temporally. Multiple frames are expected to improve the anti-spoofing performance due to more informative data. This has been proved by <ref type="bibr" target="#b10">[11]</ref> to some extent, in which a spatial-temporal texture feature was extracted from consecutive frames. When fed more than one frame, the CNN can not only learn the spatial features, but also temporal features for anti-spoofing. In this paper, we train CNN model using both single frame and multiple frames, and figure out whether multiple frames are helpful for CNN to learn more discriminative features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Feature Learning</head><p>In this paper, we implement a canonical CNN structure for learning features. Specifically, we adopt the configuration in <ref type="bibr" target="#b20">[21]</ref>, which won the ImageNet large scale visual recognition challenge (LSVRC) in 2012. A brief illustration of the CNN structure is presented in <ref type="figure" target="#fig_4">Fig. 4</ref>. In the network, there are five convolutional (Conv) layers, followed by three fullyconnected (FC) layers. In the convolutional layers, responsenormalization layers are used for the outputs of the first and second convolutional layers. The max-pooling layers are plug to process the outputs of the first, second and the last convolutional layers. The ReLU non-linearity is applied to the output of every convolutional and fully-connected layer. To avoid over-fitting, the first two fully-connected layers are followed by two dropout layers, and the last layer, i.e. output layer is followed by softmax.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Classification</head><p>After learning the CNNs, we extract the features from the last fully-connected layer. Then, support vector machine (SVM) is used to learn the classifiers from train data for face anti-spoofing. In this paper, the LibSVM toolkit <ref type="bibr" target="#b8">[9]</ref> is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Settings</head><p>In our experiments, to organize the data, we first detect faces in images via detector from OpenCV. After that, we use the method in Sec. III-A.1 to refine the face regions as the bounding boxes of face landmarks. Then, the bounding boxes are reset to contain most of the face regions, as shown in the first column <ref type="figure" target="#fig_3">Fig. 3</ref>. To make use of the information in backgrounds, we enlarge the original ones with re-scaling ratios {1.4, 1.8, 2.2, 2.6}. Finally, all input images are resized to 128 × 128. Besides above spatial augmentations, we use consecutive frames to augment the data temporally. In our experiments, the number of input face images is from one to three. For the CNN, we use Caffe toolbox <ref type="bibr" target="#b14">[15]</ref> and adopt a commonly used structure, which was ever used in <ref type="bibr" target="#b20">[21]</ref>. In the training of CNN, the learning rate is 0.001; decay rate is 0.001; and the momentum during training is 0.9. Before fed into the CNN, the data are first centralized by the mean of training data. These parameters are constant in our experiments. Given the learned feature, we use SVM with RBF kernel to train classifiers for antis-spoofing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Datasets</head><p>In this paper, the experiments are implemented on two datasets, CASIA and REPLAY-ATTACK datasets. In these two datasets, various spoofing types are simulated. Followings are the brief introduction of two databases:</p><p>• CASIA database <ref type="bibr" target="#b35">[36]</ref>: This database contains 50 subjects in total. For each subject, the genuine faces are captured under three qualities. The spoofing images are fabricated by implementing three kind of attacks, i.e., warped photo attack, cut photo attack and electronic screen attack in three qualities, respectively. As a result, each subject has 12 sequences (3 genuine and 9 fake ones). The overall number of sequences in the database is 600.</p><p>• REPLAY-ATTACK database <ref type="bibr" target="#b6">[7]</ref>: It also contains 50 subjects. For each subject, four genuine video sequences are collected in front of two backgrounds. Similar to CASIA, three spoofing types are used, including print attack, digital photo attack, and video attack. The spoofing sequences are captured under fixed and handhold conditions. The overall number of sequences in the database is 1200.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Protocol</head><p>To make fair comparison with recent works, we use the Half Total Error Rate (HTER) to report the performance. After training, the development set is used to determine the threshold corresponding to Equal Error Rate (EER). Then the threshold is used for the computation of HTER on test set. Similar to <ref type="bibr" target="#b9">[10]</ref>, we divide the training set in CASIA dataset into five folds, and one of them is used as development set and the others for training. The final performance is obtained by averaging the results from five cross validations. In REPLAY-ATTACK dataset, the development set is already given. There is no need to divide the original sets.</p><p>Along with the protocols in <ref type="bibr" target="#b9">[10]</ref>, we conduct intra-test on each dataset, and inter-test to evaluate the generalization ability of our method. Moreover, we also combine two datasets to evaluate our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Results of Intra-test</head><p>1) Test on CASIA dataset: We test our method on CASIA dataset in five different spatial scales from one frame to three frames. In <ref type="table" target="#tab_2">Table I</ref>, the HTERs on development set and test set are shown. In the table, the average performance over scales and frames are presented al well. As we can see, with the increase of spatial scale, the anti-spoofing model perform better than that of original scale, and achieves the best when the scale is equal to 3 averagely. These results indicate the positive effect of background region on face anti-spoofing task. Actually, similar claim has been proved in <ref type="bibr" target="#b34">[35]</ref>. However, the difference is that images corresponding to the best scale in this paper are larger than that in <ref type="bibr" target="#b34">[35]</ref>, which shows the CNN can extract more useful information from the background region compared with the hand-crafted features. However, when the scale reaches 5, the performance degrades slightly. One possible reason is that the diversity of background region weakens the positive effect. As for the number of frames used, the model trained using one frame outperform gently the models trained with more than one frames in average. However, when reviewing the results closely, we find the best performance is obtained by using two frames with scale 2. This specific result indicates multiframe input is positive in certain cases.</p><p>For details, we show the corresponding ROC curves in <ref type="figure">Fig. 5</ref>. From the results, we can find input data with scale 2, 3, 4 improve the anti-spoofing consistently over different frames. These results further show that the background region is useful for distinguishing genuine and fake face images. However, the improvement may discount when containing too much background.</p><p>2) Test on REPLAY-ATTACK dataset: On Replay-Attack dataset, we also report the performance under 15 scenarios.</p><p>In <ref type="table" target="#tab_2">Table II</ref>, we present the EERs and HTERs for different image scales and frame numbers used. In the table, we find some differences from CASIA dataset: (1) the lowest HTER occurs at scale = 1, instead of a larger scale; (2) EERs on development set are larger than HTER on test set. These differences are mainly caused by the bias between development and test sets. On the test set, the models achieve accuracies all above 97%, which are 2%-5% higher than the development set. To evaluate the performance more comprehensively, we draw the ROC curves for all scenarios in <ref type="figure" target="#fig_5">Fig. 6</ref>. Accordingly, with the increase of scale, the performance improve gradually. When trained using input data with scale 5, the anti-spoofing achieves nearly perfect performance.</p><p>3) Comparison: For comparison, <ref type="table" target="#tab_0">Table III</ref> shows the intra-test results on CASIA dataset in <ref type="bibr" target="#b9">[10]</ref>. As mentioned before, we use the same protocols as <ref type="bibr" target="#b9">[10]</ref> for fair comparison. In <ref type="bibr" target="#b9">[10]</ref>, the lowest EER is 21.59 on CASIA dataset, while it is 4.64 in our paper. Meanwhile, the lowest HTER in <ref type="bibr" target="#b9">[10]</ref> is more than 4 times of ours. Such drastic improvements also occur on the REPLAY-ATTACK dataset. Such promising results indicate that the CNN can learn more discriminative features from input data compared with various hand-crafted features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results of Inter-test</head><p>For face anti-spoofing, its adaptation ability from one dataset to another is important for practical applications. In this part, we will evaluate such ability of CNN models. Similar to <ref type="bibr" target="#b9">[10]</ref>, we first train our model using the training set from CASIA dataset, and then validate and test it using Replay-Attack dataset. This procedure is then inverted, i.e., using Replay-Attack dataset for training and CASIA dataset for development and testing. In this inter-test procedure, training data is used to tune the CNN models and train SVM classifiers, which are then used to extract features and perform evaluation on the development and test sets, respectively. When extracting features from development and test sets, the mean of training data is used for centralizations of development and testing data.</p><p>As shown in <ref type="table" target="#tab_2">Table IV</ref>  <ref type="table" target="#tab_4">Table V</ref>. Accordingly, the performance of our method is analogous to that in <ref type="bibr" target="#b9">[10]</ref> when the scale  is 1, which indicates that both hand-crafted and learned features are incapable of capturing common cues from face regions across datasets. However, with the scale increased, such a situation changes. For the REPLAY-ATTACK dataset, the testing performance improves gradually, and the lowest HTER approaches to 23.78 when using one frame with scale 5. Similarly on the CASIA dataset, the HTER also decreases when input data contains backgrounds. The lowest HTER is 38.11 when using three frames with scale 4 as input. In <ref type="figure" target="#fig_6">Fig. 7 and 8</ref>, we show the ROC curves for different inter-test scenarios.</p><p>According the experiments in this part, we can find the cross-datasets anti-spoofing is far from satisfactory. Due to different devices, illuminations, races, etc., there are some inevitable biases among two datasets. In this case, the interdataset can hardly obtain analogous performance to the intratest situation. Fortunately, we find in our experiments that background regions can boost the generalization ability of anti-spoofing model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Results on Combined Datasets</head><p>In this part, we assume training data from two datasets are available. As the protocols proposed in <ref type="bibr" target="#b9">[10]</ref>, our models are trained and developed on combined datasets, and then evaluated on each dataset. In <ref type="table" target="#tab_2">Table VI</ref>, we show the EERs and HTERs of all scenarios. Compared with the results in    <ref type="bibr" target="#b9">[10]</ref>  <ref type="table" target="#tab_2">(Table VII)</ref>, our method achieves much better result on both datasets. On the CASIA dataset, we obtain comparable performance to the intra-test; On the REPLAY-ATTACK dataset, the average HTERs are less than 1% when scale = 4 and 5. In <ref type="figure" target="#fig_7">Fig. 9</ref>, we show ROC curves of different cases. We can find the models trained using samples from two dataset perform similarly to those in the intra-test, which illustrates that CNN are able to learn common features from such two datasets. Moreover, compared with <ref type="bibr" target="#b9">[10]</ref>, the performance is not biased as much between two datasets due to the powerful feature learning ability of CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Discussion</head><p>Thus far, we have evaluated our method in various cases. From the experimental results, we show that the proposed method has achieved much better performance in all testing protocols. These encouraging results prove the power of CNN once again, but the first time in face anti-spoofing. Compared with previous hand-crafted features, such a datadriven feature designing rules out the empirical part, and come up with some more efficient features for face antispoofing. Moreover, it should be pointed out that we did not pay attentions on parameter selecting for CNN, but we believe that a better model can be obtained after some efforts on it.</p><p>Beyond the powerful feature learning toolkit, we also proposed many data augmentation strategies, including spatial and temporal augmentations. By augmenting the input data, we further improve face anti-spoofing performance in all protocols. These improvements suggests that background region is indeed helpful for face anti-spoofing to some extent when using CNN-learned or hand-crafted features <ref type="bibr" target="#b34">[35]</ref>. Though the improvements are seen on both datasets, there are some difference to be pointed out. Specifically, on the CASIA dataset, the best scale is 3, while 5 for REPLAY-ATTACK dataset. This inconsistency can be explained by the input data partially. In the CASIA dataset, all sequences of spoofing attacks contain real-world backgrounds as realaccess sequences. However, all background regions are filled by fake photos in REPLAY-ATTACK dataset. As a result, when the scale is too large, genuine and fake samples in CASIA dataset become more similar rather than different, whereas they are more discriminative on REPLAY-ATTACK dataset. At this point, we argue that face anti-spoofing should not be regarded as a classification problem on faces, but one on the regions where fake faces are shown. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS AND FUTURE WORKS</head><p>In this paper, we have proposed to use CNN to learn features for face anti-spoofing. Upon the CNN model, we tried different data augmentation strategies. According to the experimental results. The proposed method make a significant improvement compared with previous works in different protocols. In the intra-test and combination protocols, we have achieved HTERs lower than 5% on two datasets. In the inter-test protocol, there are also remarkable improvements. However, we must point out that the proposed method is still not able to obtain satisfactory performance in the inter-test protocol. As we discussed before, due to different capturing conditions, the biases among different datasets are inevitable. Towards this point, one of our future work is to find out a way to adapt the learned model to new data based on transfer learning. Also, integrating other cues, such as motions and shapes is another direction.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Jianwei Yang, Zhen Lei, and Stan Z. Li are with Center for Biometrics and Security Research &amp; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China. Email: {jwyang, zlei, szli}@cbsr.ia.ac.cn 1 The second and third images in the top row, and the third image in the bottom row are genuine</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Genuine and fake face images from REPLAY-ATTACK dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Face alignment process on an example image. From left to right, the face location is gradually refined based on face landmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Sample images with different spatial scales are shown. The first two rows are from CASIA dataset and the two rows at bottom are from REPLAY-ATTACK dataset. The even rows are genuine, and odd rows are fake.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Brief illustration of CNN architecture used in this paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>ROC curves for different data augmentations on REPLAY-ATTACK dataset. The display order is similar toFig. 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>ROC curves of inter-test. The models are trained on REPLAY-ATTACK dataset, and developed and tested on CASIA dataset. The display order is similar toFig. 7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>ROC curves for data combination protocol. The top three figures show models tested on CASIA dataset, and the bottom three figures show performance of models tested on REPLAY-ATTACK dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE III INTRA</head><label>III</label><figDesc>-TEST RESULTS ON CASIA AND REPLAY-ATTACK DATASET IN<ref type="bibr" target="#b9">[10]</ref>.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feature</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Correlation</cell><cell cols="2">LBP-TOP u2 8,8,8,1,1,1</cell><cell cols="2">LBP u2 8,1</cell></row><row><cell>Dataset</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell>CASIA</cell><cell>26.65</cell><cell>30.33</cell><cell>21.59</cell><cell>23.75</cell><cell>24.63</cell><cell>23.19</cell></row><row><cell>Replay-Attack</cell><cell>11.66</cell><cell>11.79</cell><cell>8.17</cell><cell>8.51</cell><cell>14.41</cell><cell>15.45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, the top four lines show the EERs and HTERs when using CASIA for training and REPLAY-ATTACK for testing; and the bottom four lines present results from the inverse. For comparison, we show the performance of [] in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I INTRA</head><label>I</label><figDesc>-TEST RESULTS ON CASIA DATASET. THE EERS AND HTERS ARE PRESENTED FOR DIFFERENT DATA AUGMENTATIONS. Fig. 5. ROC curves for different data augmentations on CASIA dataset. From left to right, the curves are obtained from models trained using one frame, two frames and three frames, respectively.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Scale</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>3</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell>Mean</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>dev</cell><cell>test</cell><cell></cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell></cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>7.06</cell><cell>7.38</cell><cell></cell><cell cols="2">5.44 5.58</cell><cell>4.92</cell><cell>5.09</cell><cell>5.81</cell><cell>5.84</cell><cell>6.98</cell><cell></cell><cell>6.99</cell><cell>6.04</cell><cell>6.18</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Frame</cell><cell>2</cell><cell>7.50</cell><cell>8.05</cell><cell></cell><cell cols="2">4.87 4.95</cell><cell>5.51</cell><cell>4.95</cell><cell>6.41</cell><cell>5.53</cell><cell>8.12</cell><cell></cell><cell>7.53</cell><cell>6.48</cell><cell>6.20</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>7.80</cell><cell>7.46</cell><cell></cell><cell cols="2">5.61 5.69</cell><cell>4.64</cell><cell>5.21</cell><cell>4.68</cell><cell>5.60</cell><cell>8.09</cell><cell></cell><cell>7.95</cell><cell>6.16</cell><cell>6.38</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Mean 7.45</cell><cell>7.63</cell><cell></cell><cell cols="2">5.31 5.41</cell><cell>5.02</cell><cell>5.08</cell><cell>5.63</cell><cell>5.66</cell><cell>7.73</cell><cell></cell><cell>7.49</cell><cell>6.23</cell><cell>6.25</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE II</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">INTRA-TEST RESULTS ON REPLAY-ATTACK DATASET.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Scale</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>3</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell>Mean</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>dev</cell><cell>test</cell><cell></cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell></cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>6.10</cell><cell>2.14</cell><cell></cell><cell cols="2">3.51 3.20</cell><cell>4.47</cell><cell>3.13</cell><cell>3.41</cell><cell>2.29</cell><cell>4.14</cell><cell></cell><cell>2.53</cell><cell>4.33</cell><cell>2.66</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Frame</cell><cell>2</cell><cell>8.72</cell><cell>2.57</cell><cell></cell><cell cols="2">2.54 3.09</cell><cell>3.74</cell><cell>2.81</cell><cell>3.55</cell><cell>2.98</cell><cell>3.77</cell><cell></cell><cell>2.55</cell><cell>4.46</cell><cell>2.80</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>7.17</cell><cell>2.19</cell><cell></cell><cell cols="2">3.50 3.28</cell><cell>3.71</cell><cell>2.86</cell><cell>3.05</cell><cell>2.32</cell><cell>3.45</cell><cell></cell><cell>2.21</cell><cell>4.18</cell><cell>2.57</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Mean 7.33</cell><cell>2.30</cell><cell></cell><cell cols="2">3.18 3.19</cell><cell>3.97</cell><cell>2.93</cell><cell>3.37</cell><cell>2.53</cell><cell>3.82</cell><cell></cell><cell>2.43</cell><cell>4.32</cell><cell>2.68</cell></row><row><cell></cell><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=1, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=2</cell><cell></cell><cell></cell><cell>s=1, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=2, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=2</cell><cell></cell><cell></cell><cell>s=2, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=3, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=2</cell><cell></cell><cell></cell><cell>s=3, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=4, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=2</cell><cell></cell><cell></cell><cell>s=4, f=3</cell></row><row><cell></cell><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=5, f=1</cell><cell></cell><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=2</cell><cell></cell><cell></cell><cell>0.4</cell><cell>s=5, f=3</cell></row><row><cell cols="2">False Acceptance Rate (FAR)</cell><cell>0.2 0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Acceptance Rate (FAR)</cell><cell>0.2 0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Acceptance Rate (FAR)</cell><cell>0.2 0.3</cell></row><row><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell></cell><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell></cell><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Rejection Rate (FRR)</cell></row><row><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=1, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=2</cell><cell></cell><cell></cell><cell>s=1, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=2, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=2</cell><cell></cell><cell></cell><cell>s=2, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=3, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=2</cell><cell></cell><cell></cell><cell>s=3, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=4, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=2</cell><cell></cell><cell></cell><cell>s=4, f=3</cell></row><row><cell></cell><cell cols="2">0.08</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=5, f=1</cell><cell></cell><cell cols="2">0.08</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=2</cell><cell></cell><cell cols="2">0.08</cell><cell>s=5, f=3</cell></row><row><cell>False Acceptance Rate (FAR)</cell><cell cols="2">0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell cols="2">0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell cols="2">0.04 0.06</cell></row><row><cell></cell><cell cols="2">0.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.02</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0.02</cell><cell>0.04</cell><cell>0.06</cell><cell>0.08</cell><cell>0.1</cell><cell></cell><cell></cell><cell>0</cell><cell>0.02</cell><cell>0.04</cell><cell>0.06</cell><cell>0.08</cell><cell>0.1</cell><cell></cell><cell></cell><cell>0</cell><cell>0.02</cell><cell>0.04</cell><cell>0.06</cell><cell>0.08</cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Rejection Rate (FRR)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV INTER</head><label>IV</label><figDesc>-TEST RESULTS ON CASIA AND REPLAY-ATTACK DATASETS.Fig. 7. ROC curves of inter-test for different inputs. The models are trained on CASIA dataset, and developed and tested on REPLAY-ATTACK dataset. The display order is similar to Fig. 5.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Scale</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>3</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>5</cell><cell></cell><cell cols="2">Mean</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>dev</cell><cell>test</cell><cell cols="2">dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell cols="2">dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell cols="2">48.22 48.80</cell><cell cols="2">50.17</cell><cell>50.56</cell><cell>41.39</cell><cell>38.02</cell><cell>33.16</cell><cell>36.51</cell><cell cols="2">38.80</cell><cell>23.78</cell><cell>42.25</cell><cell>39.53</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Frame</cell><cell>2</cell><cell cols="2">49.60 51.58</cell><cell cols="2">45.85</cell><cell>46.39</cell><cell>49.20</cell><cell>44.02</cell><cell>35.53</cell><cell>34.93</cell><cell cols="2">42.82</cell><cell>38.21</cell><cell>44.60</cell><cell>43.03</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell cols="2">51.37 55.16</cell><cell cols="2">48.17</cell><cell>47.34</cell><cell>39.25</cell><cell>34.90</cell><cell>30.63</cell><cell>32.14</cell><cell cols="2">33.47</cell><cell>38.03</cell><cell>40.58</cell><cell>41.51</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Mean 49.73 51.91</cell><cell cols="2">48.06</cell><cell>48.10</cell><cell>43.28</cell><cell>38.98</cell><cell>33.10</cell><cell>34.53</cell><cell cols="2">38.36</cell><cell>33.34</cell><cell>42.48</cell><cell>41.36</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell cols="2">45.76 45.49</cell><cell cols="2">43.02</cell><cell>43.63</cell><cell>39.33</cell><cell>39.31</cell><cell>39.97</cell><cell>40.03</cell><cell cols="2">41.90</cell><cell>42.42</cell><cell>42.00</cell><cell>42.18</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Frame</cell><cell>2</cell><cell cols="2">46.48 46.81</cell><cell cols="2">42.70</cell><cell>42.88</cell><cell>38.29</cell><cell>38.38</cell><cell>40.24</cell><cell>40.49</cell><cell cols="2">39.88</cell><cell>40.88</cell><cell>41.52</cell><cell>41.89</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell cols="2">46.07 46.43</cell><cell cols="2">43.25</cell><cell>42.97</cell><cell>40.88</cell><cell>40.78</cell><cell>38.91</cell><cell>38.11</cell><cell cols="2">41.18</cell><cell>41.91</cell><cell>42.06</cell><cell>42.04</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Mean 46.10 46.24</cell><cell cols="2">42.99</cell><cell>43.16</cell><cell>39.50</cell><cell>39.49</cell><cell>39.71</cell><cell>39.54</cell><cell cols="2">40.10</cell><cell>41.74</cell><cell>41.86</cell><cell>42.04</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=1, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=2, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=3, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=4, f=3</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=1</cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=2</cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell>s=5, f=3</cell></row><row><cell>False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=1, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=2, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=3, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=4, f=3</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=1</cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=2</cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell>s=5, f=3</cell></row><row><cell>False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V</head><label>V</label><figDesc></figDesc><table><row><cell cols="7">INTER-TEST RESULTS ON CASIA AND REPLAY-ATTACK DATASETS IN</cell></row><row><cell></cell><cell></cell><cell></cell><cell>[10].</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feature</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Correlation</cell><cell cols="2">LBP-TOP u2 8,8,8,1,1,1</cell><cell cols="2">LBP u2 8,1</cell></row><row><cell>Training Set</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell>CASIA</cell><cell>50.23</cell><cell>50.25</cell><cell>48.97</cell><cell>50.64</cell><cell>44.97</cell><cell>47.05</cell></row><row><cell cols="2">Replay-Attack 47.72</cell><cell>48.28</cell><cell>60.00</cell><cell>61.33</cell><cell>57.32</cell><cell>57.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VII RESULTS</head><label>VII</label><figDesc>OF DATA COMBINATION PROTOCOL ON CASIA AND REPLAY-ATTACK DATASETS IN<ref type="bibr" target="#b9">[10]</ref>.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feature</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Correlation</cell><cell cols="2">LBP-TOP u2 8,8,8,1,1,1</cell><cell cols="2">LBP u2 8,1</cell></row><row><cell>Testing Set</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell>CASIA Replay-Attack</cell><cell>12.18</cell><cell>43.30 24.14</cell><cell>14.29</cell><cell>42.04 10.67</cell><cell>20.45</cell><cell>45.92 10.07</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI RESULTS</head><label>VI</label><figDesc>FROM DATA COMBINATION PROTOCOL. THE MODELS ARE TRAINED ON TWO DATASETS, AND THEN DEVELOPED AND TESTED ON EACH DATASET SEPARATELY.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scale</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>3</cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell>Mean</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>dev</cell><cell></cell><cell>test</cell><cell></cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell><cell cols="2">dev</cell><cell>test</cell><cell>dev</cell><cell>test</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell cols="2">10.89</cell><cell>13.29 3.25</cell><cell></cell><cell>4.85</cell><cell cols="2">9.04 1.77 1.57</cell><cell>6.08 1.34</cell><cell>1.29</cell><cell>6.30 0.70</cell><cell cols="3">2.65</cell><cell>8.62 1.19</cell><cell>4.29</cell><cell>8.67 1.61</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Frame</cell><cell>2</cell><cell cols="2">11.28</cell><cell>13.71 3.58</cell><cell></cell><cell>3.56</cell><cell cols="2">6.58 2.32 1.61</cell><cell>5.81 1.36</cell><cell>1.55</cell><cell>6.59 0.60</cell><cell cols="3">2.79</cell><cell>6.74 0.95</cell><cell>4.30</cell><cell>7.89 1.62</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell cols="2">10.12</cell><cell>11.21 3.90</cell><cell></cell><cell>3.85</cell><cell cols="2">8.27 2.05 1.52</cell><cell>5.37 1.03</cell><cell>2.13</cell><cell>6.54 0.68</cell><cell cols="3">2.07</cell><cell>7.72 0.40</cell><cell>4.04</cell><cell>7.82 1.51</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Mean 10.76</cell><cell>12.74 3.58</cell><cell></cell><cell>4.09</cell><cell cols="2">7.96 2.05 1.57</cell><cell>5.75 1.24</cell><cell>1.66</cell><cell>6.48 0.66</cell><cell cols="3">2.50</cell><cell>7.69 0.85</cell><cell>4.21</cell><cell>8.13 1.58</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=1, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=2</cell><cell></cell><cell></cell><cell>s=1, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=2, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=2</cell><cell></cell><cell></cell><cell>s=2, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=3, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=2</cell><cell></cell><cell></cell><cell>s=3, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=4, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=2</cell><cell></cell><cell></cell><cell>s=4, f=3</cell></row><row><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell>s=5, f=1</cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=2</cell><cell></cell><cell></cell><cell>0.8</cell><cell>s=5, f=3</cell></row><row><cell cols="2">False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Acceptance Rate (FAR)</cell><cell>0.4 0.6</cell></row><row><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell></cell><cell></cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Rejection Rate (FRR)</cell></row><row><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=1, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=1, f=2</cell><cell></cell><cell></cell><cell>s=1, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=2, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=2, f=2</cell><cell></cell><cell></cell><cell>s=2, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=3, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=3, f=2</cell><cell></cell><cell></cell><cell>s=3, f=3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>s=4, f=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=4, f=2</cell><cell></cell><cell></cell><cell>s=4, f=3</cell></row><row><cell></cell><cell cols="2">0.08</cell><cell></cell><cell></cell><cell></cell><cell>s=5, f=1</cell><cell></cell><cell></cell><cell cols="2">0.08</cell><cell></cell><cell></cell><cell></cell><cell cols="2">s=5, f=2</cell><cell></cell><cell cols="2">0.08</cell><cell>s=5, f=3</cell></row><row><cell>False Acceptance Rate (FAR)</cell><cell cols="2">0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell cols="2">0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Acceptance Rate (FAR)</cell><cell cols="2">0.04 0.06</cell></row><row><cell></cell><cell cols="2">0.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.02</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0.02</cell><cell>0.04</cell><cell>0.06</cell><cell>0.08</cell><cell>0.1</cell><cell></cell><cell></cell><cell>0</cell><cell>0.02</cell><cell>0.04</cell><cell>0.06</cell><cell>0.08</cell><cell>0.1</cell><cell></cell><cell></cell><cell>0</cell><cell>0.02</cell><cell>0.04</cell><cell>0.06</cell><cell>0.08</cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False Rejection Rate (FRR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>False Rejection Rate (FRR)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Motion-based countermeasures to photo attacks in face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Chakka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Anti-spoofing in action: joint operation with a verification system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chingovska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<idno>EPFL-CONF-192365</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A liveness detection method for face recognition based on optical flow field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Analysis and Signal Processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="233" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Competition on counter measures to 2-d facial spoofing attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Chakka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tronci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Muntoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fadda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sirena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Murgia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ristori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pedrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lorenzo-Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Määttä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCB</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Biometric liveness checking using multimodal fuzzy fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FUZZ-IEEE</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Audio-visual multimodal fusion for biometric person authentication and liveness verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NICTA-HCSNet Multimodal User Interaction Workshop, MMUI 2005</title>
		<editor>F. Chen and J. Epps</editor>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACS</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
		<respStmt>
			<orgName>CRPIT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the effectiveness of local binary patterns in face anti-spoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chingovska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The 2nd competition on counter measures to 2d face spoofing attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chingovska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kähm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Damer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuijper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nouak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Freitas Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Waris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tronci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sirena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Galbally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fierrez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pedrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICB</title>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Libsvm: a library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Can face anti-spoofing countermeasures work in a real world scenario? In ICB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Freitas Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>De Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Lbptop based countermeasure against face spoofing attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Freitas Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>De Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ACCV 2012 Workshops</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Moving face spoofing detection via 3d projective invariants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Marsico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nappi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Riccio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dugelay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics (ICB), 2012 5th IAPR International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Spoofing 2d face recognition systems with 3d masks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Erdogmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 International Conference of the</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multispectral face liveness detection method based on gradient features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="113102" to="113102" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Caffe: An open source convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating liveness by face images and the structure tensor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kollreider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fronthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigün</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AutoID</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Verifying liveness by multiple experts in face biometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kollreider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fronthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Biometrics</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time face detection and motion analysis with application in &quot;liveness&quot; assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kollreider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fronthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Faraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigün</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3-2</biblScope>
			<biblScope unit="page" from="548" to="558" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Real-time face detection and motion analysis with application in &quot;liveness&quot; assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kollreider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fronthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Faraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigün</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3-2</biblScope>
			<biblScope unit="page" from="548" to="558" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Context based face antispoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics: Theory, Applications and Systems (BTAS), 2013 IEEE Sixth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Live face detection based on the analysis of fourier spectra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometric Technology for Human Identification</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="296" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Face spoofing detection from single images using micro-texture analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Maatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics (IJCB), 2011 International Joint Conference on</title>
		<imprint>
			<date type="published" when="2011-10" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Eyeblink-based anti-spoofing in face recognition from a generic webcamera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Eyeblink-based anti-spoofing in face recognition from a generic webcamera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The imaging issue in an automatic face/disguise detection system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pavlidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Symosek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Beyond the Visible Spectrum: Methods and Applications</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Face liveness detection under bad illumination conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peixoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michelassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3557" to="3560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Face alignment at 3000 fps via regressing local binary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Blinking-based live face detection using conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICB</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="252" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Face liveness detection from a single image with sparse low rank bilinear discriminative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (6)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="504" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Face liveness detection from a single image with sparse low rank bilinear discriminative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (6)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="504" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fusion of multiple clues for photo-attack detection in face recognition systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tronci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Muntoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fadda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sirena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Murgia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ristori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics (IJCB), 2011 International Joint Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Face liveness detection using 3d structure recovered from a single camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometrics (ICB), 2013 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Face liveness detection by exploring multiple scenic clues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Control Automation Robotics &amp; Vision (ICARCV), 2012 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Face liveness detection with component dependent descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICB</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A face antispoofing database with diverse attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<editor>A. K. Jain, A. Ross, S. Prabhakar, and J. Kim</editor>
		<imprint>
			<date type="published" when="2012" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Face liveness detection by learning multispectral reflectance distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="436" to="441" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
