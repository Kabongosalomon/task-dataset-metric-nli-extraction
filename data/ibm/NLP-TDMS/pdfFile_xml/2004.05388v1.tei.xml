<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">You Impress Me: Dialogue Generation via Mutual Persona Perception</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
							<email>†qian.liu@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">♦ UCL Centre for Artificial Intelligence</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country>United Kindom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Chen</surname></persName>
							<email>♦yihong.chen@cs.ucl.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Chen</surname></persName>
							<email>§beichen@microsoft.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
							<email>jlou@microsoft.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixuan</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhou</surname></persName>
							<email>zhoubin@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">♦ UCL Centre for Artificial Intelligence</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country>United Kindom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
							<email>dongmeiz@microsoft.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">You Impress Me: Dialogue Generation via Mutual Persona Perception</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the continuing efforts to improve the engagingness and consistency of chit-chat dialogue systems, the majority of current work simply focus on mimicking human-like responses, leaving understudied the aspects of modeling understanding between interlocutors. The research in cognitive science, instead, suggests that understanding is an essential signal for a high-quality chit-chat conversation. Motivated by this, we propose P 2 BOT, a transmitter-receiver based framework with the aim of explicitly modeling understanding. Specifically, P 2 BOT incorporates mutual persona perception to enhance the quality of personalized dialogue generation. Experiments on a large public dataset, PERSONA-CHAT, demonstrate the effectiveness of our approach, with a considerable boost over the state-of-theart baselines across both automatic metrics and human evaluations.</p><p>PERSONA-CHAT has fueled a growing interest in developing methods for personalized dialogue arXiv:2004.05388v1 [cs.CL] 11 Apr 2020 *</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Thanks to the advance in neural models and the accessibility of massive datasets, open-domain dialogue (i.e. chit-chat) systems have made great progress towards mimicking human-like responses. Nevertheless, there still exist some serious challenges in building personalized chatbots that can deliver engaging conversations and gain user trust <ref type="bibr" target="#b23">(Song et al., 2019)</ref>. For example, current chit-chat systems tend to generate uninformative responses <ref type="bibr" target="#b11">(Li et al., 2016b)</ref>. Moreover, they are usually lack of coherent personality traits due to the fact that training dialogues actually come from a diverse set of speakers <ref type="bibr" target="#b37">(Zhang et al., 2018b)</ref>  Several attempts have been made to alleviate the above issues. Methods like special reward shaping to reduce generic responses <ref type="bibr" target="#b11">(Li et al., 2016b)</ref> and representing the speakers with latent variables <ref type="bibr" target="#b10">(Li et al., 2016a)</ref> were introduced to improve the engagingness of chit-chat systems. A more straightforward approach, which equips chit-chat systems with predefined personas, was proposed accompanied by a novel dataset, PERSONA-CHAT <ref type="bibr" target="#b37">(Zhang et al., 2018b)</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> shows a clipped dialogue from PERSONA-CHAT. Two interlocutors meet for the first time and are having a conversation in order to get to know each other. What makes PERSONA-CHAT unique is that personas of both interlocutors are explicitly described using several profile sentences, facilitating the training of chatbots with configurable and persistent personalities.  generation. <ref type="bibr" target="#b15">Mazaré et al. (2018)</ref> incorporated additional data from Reddit to train the model. <ref type="bibr" target="#b32">Wolf et al. (2019b)</ref> fine-tuned pretrained language model <ref type="bibr" target="#b20">(Radford et al., 2018)</ref> to improve the dialogue generation. Although both works demonstrate promising results, they focus more on mimicking the style of human-like responses, leaving understudied the aspects of explicitly modeling understanding between interlocutors. Our work, instead, takes the perspective of understanding modeling.</p><p>According to the research in cognitive science, effective communication creates similar activation maps in the brains of both interlocutors <ref type="bibr" target="#b5">(Hasson et al., 2012)</ref>, suggesting that understanding between interlocutors is an essential signal for a highquality chit-chat conversation. For instance, in the conversation shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the two interlocutors foster understanding either by raising personarelated topics, "Seen any good movies lately?", or by revealing their own personas through answering questions, "I don't watch movies more of a writer.". The efforts to build understanding keep the conversation flowing.</p><p>Taking into account the above, we propose Persona Perception Bot (P 2 BOT), explicitly modeling the understanding between interlocutors with a transmitter-receiver framework. Distinguished from traditional methods, P 2 BOT highlights a novel concept, mutual persona perception, which is better suited to describe the information exchange process that empowers the interlocutors to get to know each other. In order to train P 2 BOT for personalized dialogue generation, we employ supervised training and self-play fine-tuning piloted by reward signals characterizing mutual persona perception. Experiments on the PERSONA-CHAT dataset demonstrate the superiority of our approach over the baselines in both automatic met-rics and human evaluations 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology Overview</head><p>The central idea of P 2 BOT is to explicitly model understanding between interlocutors and enhance dialogue generation via mutual persona perception. It comprises two components, Transmitter and Receiver, respectively responsible for dialogue generation and mutual persona perception. <ref type="figure" target="#fig_1">Figure 2</ref> gives an overview of P 2 BOT: interlocutor A has a persona w A , described with L profile sentences {w A 1 , · · · , w A L }. When she first meets the other interlocutor B, they are going to know each other through a N -turn dialogue (</p><formula xml:id="formula_0">x A 1 , x B 1 , · · · , x A N , x B N )</formula><p>, where x A n denotes the utterance that A says in nth turn and N denotes the number of total turns. Given the entire dialogue history up to n-th turn h A n = (x A 1 , · · · , x B n−1 ), Transmitter generates x A n according to the distribution p(x A n | w A , h A n ), and transmits it to B. The same process applies to B, keeping the conversation flowing.</p><p>As the conversation goes on, impressions are gradually built via utterances. For example, when A says "I don't watch movies more of a writer.", the impression that "A is a writer." is left on B's mind. As mentioned above, a successful conversation helps interlocutors know each other, which means B's impression of A should correspond to A's persona and vice versa. Receiver aims to measure the proximity between the built impressions and the actual personas. Specifically, as demonstrated by the dashed black lines in <ref type="figure" target="#fig_1">Figure 2</ref>, Receiver first projects impressions and personas into a latent space, and then measures the relevance between them based on the impression encoding (e.g. H A , B's impression on A, projected from A's  <ref type="figure">Figure 3</ref>: The overall architecture of Transmitter. "Block" is short for "Transformer Block". Arrows bridge the current block to subsequent blocks of its following layer. Position encoding is to incorporate position information into block by assigning an embedding for each absolute position in the sequence. Here we omit the architecture inside the block, and refer the readers to <ref type="bibr" target="#b28">Vaswani et al. (2017)</ref> for more details.</p><p>[MASK] tokens are ignored in the training objective. utterances x A ), and persona encoding (e.g. W A , projected from A's persona w A ) 2 . The relevance scores serve as mutual persona perception rewards, and are further incorporated into the training of Transmitter. Details of the two components are presented in Section 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Transmitter</head><p>Following previous work <ref type="bibr" target="#b11">(Li et al., 2016b;</ref><ref type="bibr" target="#b37">Zhang et al., 2018b)</ref>, we treat dialogue generation as a sequence generation problem. Concretely, we employ the pretraining transformer language model introduced in <ref type="bibr" target="#b20">Radford et al. (2018)</ref> (i.e. GPT) to initialize Transmitter. The entire training procedure consists of two steps: (1) Supervised Dialogue Generation. We optimize Transmitter via maximum likelihood estimation (MLE) on the supervised dialogue generation task. (2) Self-play Model Finetuning. We simulate dialogues between two randomly paired interlocutors, encouraging Transmitter to learn a policy that maximizes reward signals via reinforcement learning (RL) <ref type="bibr" target="#b26">(Sutton et al., 1999)</ref>. The design of the reward function considers both language modeling and our proposed mutual persona perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Supervised Dialogue Generation</head><p>As illustrated in <ref type="figure">Figure 3</ref>, Transmitter follows the overall architecture of 12 stacked transformer layers to encode context and generate response. Here, the context contains the persona w A , the dialogue 2 We take A as an example, and all are similar to B. history h A n , and several special tokens (e.g.</p><p>[PS] which indicates the start of persona). Given a training instance (w A , h A n , x A n ), the training objective of MLE is to maximize the conditional loglikelihood as:</p><formula xml:id="formula_1">L mle = t log p θ (x A n,t | w A , h A n , x A n,&lt;t ),<label>(1)</label></formula><p>where θ is the parameter of Transmitter. x A n,t means the t-th token in x A n , and x A n,&lt;t indicates the token sequence before t-th token. Equation 1, hereafter simplified as log p θ (x A n | w A , h A n ), applies to both A and B, and we mention A for the sake of brevity (the same as below).</p><p>During inference, beam search is applied to store top-ranked response candidates {x A n }, and Transmitter subsequently chooses as prediction the one that maximizes the length-normalized score:</p><formula xml:id="formula_2">x A * n = arg max x A n log p θ (x A n | w A , h A n ) |x A n | .<label>(2)</label></formula><p>Besides the sequence generation task, inspired by <ref type="bibr" target="#b32">Wolf et al. (2019b)</ref>, we set up an auxiliary task, Next Utterance Prediction. Apart from training Transmitter to generate responses, we also train it to discriminate whether the response is the next utterance of the given context. Concretely, we append a special token [CLS] to the tail of the generated tokens. A classifier is built on top of the token's hidden state in the last transformer layer, as indicated by the red rounded rectangle in <ref type="figure">Figure</ref> 3. In training, for each response, we randomly sample a distractor and train the classifier to give a higher score on the response than the distractor. In inference, the classifier is used to rank response candidates together with Equation 2. Denoting as y n = 1 the signal indicating the generated responsê x A n is predicted as the next utterance, Equation 2 is extended as:</p><formula xml:id="formula_3">x A * n = arg max x A n α· log p θ (x A n | w A , h A n ) |x A n | +(1 − α) · log p θ (y n = 1|w A , h A n ,x A n ) ,<label>(3)</label></formula><p>where α is a hyper-parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-play Model Fine-tuning</head><p>Although supervised dialogue generation alone can be used to mimic human-like responses, it does not inherently target at understanding. Therefore, we  <ref type="figure">Figure 4</ref>: The illustration of the self-play procedure. Arrows ⇒ represent the process of dialogue generation driven by Transmitter. Note that x A * 1 is directly taken from the dataset as it is difficult to generate high-quality utterances without any dialogue history.</p><p>further fine-tune Transmitter using reinforcement learning with the goal of maximizing mutual persona perception. Analogous to <ref type="bibr" target="#b9">Lewis et al. (2017)</ref>, we apply self-play to simulate the communication between two Transmitters, both of which have been trained as described in Section 3.1.</p><p>Specifically, we have the two Transmitters communicate with each other for several turns. One Transmitter serves as a user with the parameters frozen, while the other is a learnable agent. The parameter of the learnable agent, θ, is fine-tuned during the self-play. Without loss of generality, in our experiments, we let interlocutor A, who starts a conversation, be the user, and correspondingly B be the learnable agent.</p><p>Here we introduce some necessary formulations for modeling our problem with reinforcement learning. A state contains the persona and the dialogue history. For example, the state for B at turn n is defined as</p><formula xml:id="formula_4">s B n = {w B , h B n }.</formula><p>An action a B n is the response to be generated. The action space is infinitely large as the response can be arbitrary long. Taking s B n as input, the parameter θ defines a policy p θ (a B n |s B n ), through which the learnable agent generates its response.</p><p>As illustrated in <ref type="figure">Figure 4</ref>, when it is B's turn to speak, B receives s B n and picks a B n according to the policy p θ . As for A, it receives s A n and generates the response x A * n to simulate a user. A and B alternately produce responses till the number of turns exceeds the given limit. Once a complete dialogue is generated, the reward is collected to optimize θ using policy gradient <ref type="bibr" target="#b26">(Sutton et al., 1999)</ref>. Denoting as R(a B n ) the reward B gets at turn n (more details are provided later), we can optimize it by maximizing the following objective:</p><formula xml:id="formula_5">L rl = E a B n ∼p θ (a B n |s B n ) [R(a B n )].<label>(4)</label></formula><p>Applying likelihood ratio trick, θ is updated by ascending the following gradient:</p><formula xml:id="formula_6">∇ θ L rl = E a B n ∼p θ (a B n |s B n ) ∇ θ logp θ (a B n |s B n )R(a B n ). (5)</formula><p>As aforementioned, the space of action a B n is infinite. In practice, REINFORCE algorithm <ref type="bibr" target="#b30">(Williams, 1992)</ref> is leveraged to approximate Equation 5 by sampling a B n from policy p θ (a B n |s B n ). Furthermore, subtracting a baseline <ref type="bibr" target="#b29">(Weaver and Tao, 2001)</ref>, here the mean reward of a mini-batch, is applied on R(a B n ) to reduce variance. The agent samples tokens one by one through multinomial sampling over the output distribution of B, until the special token [EOS] is sampled or exceeding the maximum allowed decoding step (e.g. 32). Compared to beam search sampling, multinomial sampling provides more diversities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reward Shaping (RS)</head><p>As described in Section 1, we believe that a highquality chit-chat conversation should highlight both human language modeling and mutual persona perception. Bearing this in mind, we design three rewards to address language style, discourse coherence and mutual persona perception respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RS.1 Language Style</head><p>The generated responses should conform to human language styles, which we believe can be evaluated by a pretrained language model (i.e. GPT). After length normalization, the score for a B n is given as:</p><formula xml:id="formula_7">R 1 (a B n ) = 1 |a B n | t log p lm (a B n,t | a B n,&lt;t ),<label>(6)</label></formula><p>where a B n,t and a B n,&lt;t have similar denotation as the previously mentioned x A n,t and x A n,&lt;t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RS.2 Discourse Coherence</head><p>The language score is evaluated individually, without considering the discourse coherence. However, a reasonable response should establish links in meaning with context, which is also an important aspect of humanlike responses. To take into account the discourse coherence, we employ the well-trained Next Utterance Predictor (mentioned in Section 3.1). The reward is given by the log probability of a B n being the next utterance of s B n :</p><formula xml:id="formula_8">R 2 (a B n ) = log p θ (y n = 1 | a B n , s B n ).<label>(7)</label></formula><p>RS. </p><formula xml:id="formula_9">R 3 (a B n ) = r(a B n )+ N k=n+1 γ 2(k−n)−1 r(x A * k ) + γ 2(k−n) r(a B k ) ,<label>(8)</label></formula><p>where r(a B n ) is the persona perception score that B obtains in n-th turn, and r(x A * k ) is defined likewise. r(a B n ) can be computed using a score function:</p><formula xml:id="formula_10">r(a B n ) = score(a B n , w B ).<label>(9)</label></formula><p>In P 2 BOT, the score function comes from Receiver, which will be elaborated in Section 4. The final reward R(a B n ) for a B n is a weighted sum of the rewards listed above:</p><formula xml:id="formula_11">R = λ 1 R 1 + λ 2 R 2 + λ 3 R 3 ,<label>(10)</label></formula><p>where λ 1 , λ 2 and λ 3 are hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Receiver</head><p>Receiver is devised to measure the proximity between the built impressions and the actual personas, implemented by negative sampling. Specifically, in training, we randomly sample a persona distractor w Z . Receiver is trained to identify the real persona w A from {w A , w Z }. In inference, for each utterance, Receiver is responsible for providing a reasonable relevance score, to model our proposed mutual persona perception. The score subsequently joins the self-play fine-tuning on Transmitter as part of the rewards, as in Equation 8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training</head><p>As illustrated in <ref type="figure" target="#fig_2">Figure 5</ref>, Receiver contains two different encoders for impression and persona respectively. Initialized by BERT <ref type="bibr" target="#b1">(Devlin et al., 2019)</ref>, both encoders provide deep contextualized representations for each token. Then we average all the representations, yielding a fixed d-dimensional vector for one sentence. In this way, feeding (x A 1 , x A 2 , · · · , x A N ) into the impression encoder consecutively, we obtain the impression encoding</p><formula xml:id="formula_12">H A ∈ R N ×d . The persona encoding W ∆ ∈ R L×d is produced likewise, where ∆ ∈ {A, Z}.</formula><p>The relevance score matrix U ∆ is computed via the scaled dot product <ref type="bibr" target="#b28">(Vaswani et al., 2017)</ref>:</p><formula xml:id="formula_13">U ∆ = H A (W ∆ ) √ d , ∈ R N ×L .<label>(11)</label></formula><p>In essence, Receiver is expected to capture finegrained correlations between the persona and the dialogue. However, we do not have access to the golden fine-grained correlations. The only thing we know is that, compared with W Z , H A is more correlated to W A . Since the comparison is at a coarse granularity, we gather U ∆ into the cumulative score c ∆ through an aggregate function Agg, as shown in <ref type="figure" target="#fig_2">Figure 5</ref>. To encourage c A while at the same time depress c Z , we design a marginal loss L rec , which makes c A larger than c Z by a margin m. Moreover, considering that an utterance generally relates to zero or one profile, L 1 regularization is enforced to make U ∆ sparse. Combining all of these, the training loss for Receiver is:</p><formula xml:id="formula_14">L rec = max(0, m + c Z − c A ) + β · |U ∆ | 1 ,<label>(12)</label></formula><p>where β is a hyper-parameter for penalty.</p><p>As for Agg, one straightforward way is to average over all positions of U ∆ . However, it maximizes every entry in U A , including all those that Category</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Original Revised should not be activated (e.g. relevance scores between unrelated profile sentences and utterances), introducing unnecessary noise into the training of Transmitter. To alleviate the problem, we choose to implement Agg as a controllable weighted function, which summarizes U ∆ n,: as:</p><formula xml:id="formula_15">Hits@1(%) ↑ ppl ↓ F1(%) ↑ Hits@1(%) ↑ ppl ↓ F1(%) ↑</formula><formula xml:id="formula_16">Agg(U ∆ n,: ) = L k=1 exp(U ∆ n,k /τ ) · U ∆ n,k L k=1 exp(U ∆ n,k /τ ) ,<label>(13)</label></formula><p>where temperature τ &gt; 0 is a tunable parameter <ref type="bibr" target="#b6">(Hinton et al., 2015)</ref> controlling the evolution of Agg. In the beginning, Agg behaves close to average pooling. As τ anneals, Agg gradually focuses more on the highest relevance score. In this way, noise reduces as training goes on. Finally, c ∆ is given by:</p><formula xml:id="formula_17">c ∆ = 1 N N n=1</formula><p>Agg(U ∆ n,: ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inference</head><p>Given x A n and w A , Receiver employs the following function to obtain x A n 's persona perception score, further modeling mutual persona perception as in Equation <ref type="formula" target="#formula_10">9</ref>:</p><formula xml:id="formula_19">score(x A n , w A ) = Agg H A n,: (W A ) √ d ,<label>(15)</label></formula><p>where H A n,: and W A are the impression encoding and persona encoding for x A n and w A respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>We conducted experiments on the dataset PERSONA-CHAT, assessing P 2 BOT using both automatic metrics and human evaluations. To verify the effectiveness of our proposed mutual persona perception, we perform a thorough model analysis in Section 5.3. Finally, we probe Receiver's capability on perceiving persona in Section 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation Details</head><p>PERSONA-CHAT dataset contains 8,939 / 1,000 multi-turn dialogues conditioned on 1,155 / 100 personas for train / dev. Each persona is described with at least 5 profile sentences. To make it more challenging, PERSONA-CHAT also provides revised personas by rephrasing, generalizing or specializing the original ones. For example, "I am overweight." is revised from "I weight 300 pounds.". Our implementation was based on PyTorch <ref type="bibr" target="#b19">(Paszke et al., 2019)</ref>, ParlAI <ref type="bibr" target="#b16">(Miller et al., 2017)</ref>, and HuggingFace's transformers library <ref type="bibr" target="#b31">(Wolf et al., 2019a)</ref>. We used Adam (Kingma and Ba, 2015) optimizer with a learning rate of 6.25e-5 for both Receiver and Transmitter in supervised learning. In the training of Receiver, τ reduced linearly from 10 to 0.5. In the self-play phase of Transmitter, the learning rate was set as 1e-6. The hyperparameters m, α, β, γ, λ 1 , λ 2 and λ 3 were set as 0.4, 0.1, 1e-4, 0.5, 0.4, 0.1 and 0.5 respectively. The supervised training of Transmitter lasted for 2 epochs, and the self-play fine-tuning comprised 2000 dialogues, where the number of turns was 3. The beam search size was set as 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Methods Comparison</head><p>Our baselines fall into three categories: retrievalbased, generative-based and pretrain-finetunebased models. Among the retrieval-based baselines, KV Profile Memory <ref type="bibr" target="#b37">(Zhang et al., 2018b)</ref> was the official baseline which employed the memory network along with profile information, and  Dually Interactive Matching Network <ref type="bibr" target="#b4">(Gu et al., 2019)</ref> proposed a dual matching architecture to match between the responses and their corresponding contexts. Language Model, Generative Profile Memory <ref type="bibr" target="#b37">(Zhang et al., 2018b)</ref> and SEQ2SEQ with attention mechanism <ref type="bibr" target="#b0">(Bahdanau et al., 2015)</ref> were implemented as generative baselines for dialogue generation. The remaining methods were all pretrain-finetune-based. Transfertransfo <ref type="bibr" target="#b32">(Wolf et al., 2019b)</ref> 3 achieved the state-of-the-art performance on automatic metrics, while Lost In Conversation 4 topped the human evaluations <ref type="bibr" target="#b2">(Dinan et al., 2019)</ref>. Analogous to our approach, they employed the pretrained language model GPT to initialize their models, and then fine-tuned it on the dataset. <ref type="table">Table 1</ref> shows the experimental results on automatic metrics. Following <ref type="bibr" target="#b37">Zhang et al. (2018b)</ref>, we reported the official automatic metrics to evaluate the methods: Hits@1, Perplexity (ppl) and F1. Given 20 response candidates, Hits@1 is the probability that the real response ranks the highest according to the model. Perplexity measures the negative log likelihood of the correct sequence output by the model, lower values indicating better performance. F1 is the harmonic mean of word-level precision and recall. As observed, our approach outperforms almost all baselines and achieves new state-of-the-art performance on ppl and F1, with highly competitive performance on Hits@1. In the revised mode, our approach still achieves the best performance, obtaining a relative improvement of 13.4% on F1 against the strongest baseline. It is worth noting that we also tried to employ F1 as the reward, but the result is far from satisfactory.</p><p>As mentioned in <ref type="bibr" target="#b2">Dinan et al. (2019)</ref>, no automatic metric is perfect for evaluating such an opendomain task. Hence, we also performed crowdsourced human evaluations on the state-of-the-art baselines (i.e. Transfertransfo &amp; Lost In Conversation) and our proposed P 2 BOT. Concretely, on the original dev set, we randomly sampled 200 responses generated by these methods and asked each worker to rate them. The rating ranges from 1 3 http://github.com/huggingface/transfer-learning-conv-ai 4 http://github.com/atselousov/transformer chatbot  <ref type="table">Table 3</ref>: Variant analysis results on PERSONA-CHAT revised mode, along with relative improvements (shown inside brackets) compared with P 2 BOT-S. BLEU refers to the cumulative 4-gram BLEU score. "-Persona" means dialogue generation without personas; "-Next" ablates the auxiliary task mentioned in Section 3.1; "+ RS.1" means only using Language Style score as the reward in the self-play fine-tuning phase; " → + RS.2" means adding Discourse Coherence to the reward on the basis of RS.1; " → + RS.3" is equivalent to our proposed P 2 BOT.</p><p>to 4. 1 means the response is good only in terms of grammar and sentence structure; 2 means in addition to valid grammar, the response is also coherent with the context; 3 means the coherent response is meanwhile interesting and informative, instead of just a simple response like Yes; And 4 means the response is consistent with the persona of the interlocutor, which is of extreme importance for the task of reflecting whether the model can effectively utilize the persona information. As shown in Table 2, the results are consistent with the automatic evaluation results, demonstrating the superiority of P 2 BOT against the baselines. We also conducted Wilcoxon signed-rank tests between our method and the baselines and the results show the improvements are significant with p &lt; 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Model Analysis</head><p>Variant Analysis We conducted variant analysis on P 2 BOT to investigate the influence of RS.1, RS.2 and RS.3. Another metric BLEU <ref type="bibr" target="#b18">(Papineni et al., 2002)</ref>, which evaluates the quality of response, was introduced to make the analysis more comprehensive. We show the variant analysis results in <ref type="table">Table 3</ref>, where P 2 BOT-S is the variant of P 2 BOT which is trained only in the supervised setting. As expected, the results on Hits@1 validate the important role of the auxiliary task. Across all the variants, the gains in BLEU and F1 are very small, revealing the difficulty in improving them. Nevertheless, solely by adding RS.3, we obtained a 25% relative improvement on BLEU, indicating the effectiveness of our proposed mutual persona   perception. Similar conclusions can be drawn from the trend of F1.</p><p>Case Study For a more comprehensive comparison, we show in <ref type="table" target="#tab_10">Table 4</ref> some randomly sampled responses of different methods. The results suggest the responses generated by our approach are more human-like. As observed, benefiting from our proposed mutual persona perception, the responses of P 2 BOT are more consistent, engaging and informative. For instance, in the last example in <ref type="table" target="#tab_10">Table 4</ref>, the response "I'm busy with my robot project" explicates why the speaker does not exercise, meanwhile revealing that he is working on the robot, as depicted in his persona.</p><p>Error Analysis Though our approach works well in most cases, we observed that the self-play simulation might fall into repeated cycles after rounds of training, as the challenge mentioned by <ref type="bibr" target="#b11">Li et al. (2016b)</ref>. Another issue is that the bots sometimes ask redundant questions in our approach, which might be due to inappropriate hyperparameters in reward shaping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Persona Perception Probing</head><p>Receiver plays an important role in our approach, and we are interested in its capability on perceiving persona. Therefore, we conducted experi-  <ref type="figure">Figure 6</ref>: Visualization of the relevance scores between a sampled dialogue and its corresponding revised persona. Deeper color means higher score. We omit some context due to space limitation. ments on a synthesized dataset. We constructed the dataset by sampling 31 persona distractors for each dialogue in PERSONA-CHAT. Two widely used ranking metrics were used to evaluate the performance: Hits@1 and Mean Reciprocal Rank (MRR). Hits@1 is the same metric as the one mentioned in Section 5.2, except that the candidate size is 32. Given a dialogue and the complete set of profile sentences, MRR is the average reciprocal ranks of the dialogue-relevant profile sentences. Two simple baselines Random and IR <ref type="bibr" target="#b24">(Sordoni et al., 2015)</ref> were chosen for comparison. <ref type="table" target="#tab_11">Table 5</ref> shows the experimental results of different methods on the synthesized dataset. As observed, our approach achieved excellent results on both original and revised modes. For example, compared with the IR baseline, our approach achieved an absolute improvement of 26.3% on Hits@1 in the original mode. In addition, the surprising results in the revised mode further demonstrate Receiver's capability to perceive rephrased persona.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Revised Persona Dialogue</head><p>To further understand the trained Receiver, we visualize the relevance scores between a sampled dialogue and its corresponding revised persona in <ref type="figure">Figure 6</ref>. As illustrated, the relevance scores between related profile sentences and dialogue utterances are significantly higher. For example, the utterance "I volunteer at the local pool" from the interlocutor implies the profile "I love being in the water", and our Receiver successfully captures the relevance between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Methods to build open-domain dialogue systems generally fall into two major categories: retrievalbased and generative-based. Retrieval-based methods retrieve response candidates and rank them based on the matching scores with the dialogue <ref type="bibr" target="#b24">(Sordoni et al., 2015;</ref><ref type="bibr" target="#b33">Wu et al., 2017;</ref><ref type="bibr" target="#b4">Gu et al., 2019)</ref>. Generative-based methods typically use SEQ2SEQ model as the backbone <ref type="bibr" target="#b25">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b21">Serban et al., 2017;</ref><ref type="bibr" target="#b32">Wolf et al., 2019b)</ref>, where the encoder extracts the information in an utterance and the decoder generates the response. Our work adopts a similar architecture. Besides supervised learning, researchers also explore reinforcement learning based methods. <ref type="bibr" target="#b9">Lewis et al. (2017)</ref> applied reinforcement learning for negotiation dialogues and showed it outperforms supervised learning when negotiating with humans. <ref type="bibr" target="#b34">Yang et al. (2018)</ref> proposed to generate dialogue responses by dual learning based domain adaptation. <ref type="bibr" target="#b36">Zhang et al. (2018a)</ref> built a coherence model to provide the reward signal for penalizing dull responses.  employed reinfrocement learning to learn an intermediate structure span. Our approach differs from this line of work in that we focus on improving personalized dialogues via mutual persona perception, which has not yet been explored before.</p><p>More recently, under the topic of dialogue personalizing, <ref type="bibr" target="#b35">Zemlyanskiy and Sha (2018)</ref> proposed a post-processing method to re-rank candidates generated by beam search, while <ref type="bibr" target="#b17">Olabiyi et al. (2019)</ref> employed adversarial approaches to solve the consistency problem on interlocutors' names. <ref type="bibr" target="#b14">Madotto et al. (2019)</ref> applied meta-learning to quickly adapt to new speakers, and <ref type="bibr" target="#b27">Tigunova et al. (2019)</ref> extracted user attributes from daily dialogues. Compared with them, our work enhances persona based dialogue generation from a novel perspective.</p><p>Furthermore, researchers explored to generate diverse responses conditioned on persona <ref type="bibr" target="#b23">(Song et al., 2019</ref><ref type="bibr" target="#b22">(Song et al., , 2020</ref>. Personalization in goal-oriented di-alogue systems has also received some attention <ref type="bibr" target="#b7">(Joshi et al., 2017;</ref><ref type="bibr" target="#b13">Luo et al., 2019)</ref>. The researches focus more on making the goal-oriented bots adjust the response according to different user profiles, while we aim to endow bots with persistent personalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion &amp; Future Work</head><p>We propose P 2 BOT, a transmitter-receiver framework which explicitly models understanding between interlocutors. Under this framework, mutual persona perception is incorporated as a reward signal to achieve the personalized dialogue generation. Experiments on a large public dataset PERSONA-CHAT demonstrate the effectiveness of our approach. For future work, we would like to extend Receiver to conversational recommender systems. After turns of chatting, the agent should be able to infer the user's persona, based on which personalized contents can be recommended.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A clippled dialogue from PERSONA-CHAT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The overview of P 2 BOT (see text).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>The overall architecture of Receiver (see text).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Work done during an internship at Microsoft Research.</figDesc><table><row><cell>Persona</cell><cell>Persona</cell></row><row><cell>I bought my first home.</cell><cell>I weight 300 pounds.</cell></row><row><cell>I love to barbecue.</cell><cell>I am not healthy.</cell></row><row><cell>I live in Springfield.</cell><cell>I am a man.</cell></row><row><cell>I'm a writer.</cell><cell>I like The Godfather.</cell></row><row><cell cols="2">Hello how are you, I am new to the</cell></row><row><cell>Springfield area.</cell><cell></cell></row><row><cell cols="2">Hi! Seen any good movies lately?</cell></row><row><cell cols="2">I have been to the movies.</cell></row><row><cell cols="2">I love The Godfather, one of my</cell></row><row><cell cols="2">favorites! Was that filmed?</cell></row><row><cell cols="2">I don't believe so. I don't watch</cell></row><row><cell>movies more of a writer.</cell><cell></cell></row><row><cell cols="2">What do you write? Any diet books</cell></row><row><cell cols="2">? I am not very healthy.</cell></row></table><note>.*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Transmitter Interlocutor Receiver Receiver Latent Space Latent Space</head><label></label><figDesc>Transmitter I don't believe so. I don't watch movies more of a writer.What do you write? Any diet books? I am not very healthy.</figDesc><table><row><cell>Interlocutor</cell><cell></cell></row><row><cell>I bought my first home.</cell><cell></cell></row><row><cell>I love to barbecue.</cell><cell>is a writer.</cell></row><row><cell>I live in Springfield.</cell><cell>…</cell></row><row><cell>I'm a writer.</cell><cell></cell></row><row><cell></cell><cell>I weight 300 pounds.</cell></row><row><cell>ℬ is not very healthy</cell><cell>I am not healthy.</cell></row><row><cell>…</cell><cell>I am a man.</cell></row><row><cell></cell><cell>I like The Godfather.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>IsNext Block bought Block … [MASK] Block I Block don't</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Transmitter</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Block Block [MASK] [MASK] Block Block … [EOS] Position Block Block Block Block … … … … … … … I Layer 12 Layer 1 …</cell><cell>…</cell><cell>Block Block</cell></row><row><cell>Encoding</cell><cell>w e</cell><cell>[PS]</cell><cell>I</cell><cell>w e</cell><cell>[SOS]</cell><cell>.</cell><cell>w e</cell><cell>[CLS]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>3 Mutual Persona Perception RS.1 and RS.2 only steer the agent training process towards human-like responding. They do not explicitly encourage understanding between interlocutors. Therefore, we meticulously design the reward to characterize mutual persona perception. Contrast from RS.1 and RS.2, mutual persona perception is a long-term goal throughout the whole dialogue, meaning that the effect of current action might only play out some time later. For instance, receiving "what are your hobbies?" from B, it is highly likely that A's response is relevant to A's hobbies. This suggests that, not only A's response but also B's initial question contributes to mutual persona perception. Denoting as γ the discount factor indicating how far ahead B looks, the reward of mutual persona perception for a B</figDesc><table /><note>n is defined as:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>BOT is also reported. All the results were evaluated on the dev set since the test set was not publicly available.</figDesc><table><row><cell>Retrieval</cell><cell cols="2">KV Profile Memory Dually Interactive Matching 78.8 54.8</cell><cell>--</cell><cell>14.25 -</cell><cell>38.1 70.7</cell><cell>--</cell><cell>13.65 -</cell></row><row><cell></cell><cell cols="2">Generative Profile Memory 10.2</cell><cell>35.01</cell><cell>16.29</cell><cell>9.9</cell><cell>34.94</cell><cell>15.71</cell></row><row><cell>Generative</cell><cell>Language Model</cell><cell>-</cell><cell>50.67</cell><cell>16.30</cell><cell>-</cell><cell>51.61</cell><cell>13.59</cell></row><row><cell></cell><cell>SEQ2SEQ-ATTN</cell><cell>12.5</cell><cell>35.07</cell><cell>16.82</cell><cell>9.8</cell><cell>39.54</cell><cell>15.52</cell></row><row><cell>Pretrain Fintune</cell><cell>Lost In Conversation Transfertransfo P 2 BOT (Our)</cell><cell>17.3 82.1 81.9 [0.1]</cell><cell cols="3">-17.51 15.12 [0.16] 19.77 [0.08] 68.6 [0.2] 17.79 16.2 19.09 -</cell><cell cols="2">--18.89 [0.11] 19.08 [0.07] 16.83 -</cell></row><row><cell cols="8">Table 1: Automatic evaluation results of different methods on the PERSONA-CHAT dataset. The standard deviation</cell></row><row><cell cols="2">[σ] (across 5 runs) of P 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Human evaluation results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>PERSONA i. I love new kids on the block. ii. I was born in the early 80's. iii. I also like old school hip hop. iv. My favorite toy as a child as my lite brite. i. I am a blonde girl with really short hair. ii. I love wearing skinny jeans and leggings. iii. I 'm rather skinny as I like to stay in shape. iv. My favorite hobbies are listening to music and playing video games. i. I've an allergy to water. ii. I'm a famous twitch streamer. iii. I helped design the game StarCraft. iv. I am working on building a robot to be my body double.</figDesc><table><row><cell>CONTEXT</cell><cell>Do you like clowns? They horrify me!</cell><cell>What video game? I relax by knitting. Love it!</cell><cell>Cool. I did hardcore exercise four hours everyday.</cell></row><row><cell>* HUMAN</cell><cell>No! My favorite toy as a kid was lite brite because I was so scared!</cell><cell>I was playing Fallout. What do you look like? I' m blonde thin.</cell><cell>That's a lot of exercising. I hate exercising. I just work on my robot most days .</cell></row><row><cell>*</cell><cell>I do not like them at all. I am a little old for them .</cell><cell>I play RPGs. I like to wear skinny jeans and tees .</cell><cell>I do not exercise at all. I'm busy with my robot project .</cell></row><row><cell>* TRANSFERTRANSFO</cell><cell>I do not have time for clowns. Do you like to listen to music ?</cell><cell>My fav color is blue, I have a lot of friends in my group.</cell><cell>I work at a computer company. I could make you an Android!</cell></row><row><cell cols="3">* LOST IN CONVERSATION I love clowns. they are my favorite. I love HALO 3, what do you knit?</cell><cell>That sounds like a lot of fun !</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>Sampled responses(*) by Human, P 2 BOT and the state-of-the-art baselines.</figDesc><table><row><cell>Model</cell><cell cols="2">Original</cell><cell cols="2">Revised</cell></row><row><cell></cell><cell cols="4">Hits@1 ↑ MRR ↑ Hits@1 ↑ MRR ↑</cell></row><row><cell>Random</cell><cell>3.1</cell><cell>0.2</cell><cell>3.1</cell><cell>0.2</cell></row><row><cell>IR</cell><cell>67.5</cell><cell>20.9</cell><cell>9.7</cell><cell>2.2</cell></row><row><cell>Receiver</cell><cell>93.8</cell><cell>37.5</cell><cell>78.2</cell><cell>16.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>Experimental results on Persona Perception.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code is available at https://github.com/ SivilTaram/Persona-Dialogue-Generation</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank all the anonymous reviewers for their valuable comments. This work was supported in part by National Natural Science Foundation of China (U1736217 and 61932003), and National Key R&amp;D Program of China (2019YFF0302902).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2019</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2019<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<editor>Shrimai Prabhumoye, Alan W. Black, Alexander I. Rudnicky, Jason Williams, Joelle Pineau, Mikhail Burtsev, and Jason Weston</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>The second conversational intelligence challenge (convai2)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1902.00098</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dually interactive matching network for personalized response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Chen</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1193</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Brain-tobrain coupling: a mechanism for creating and sharing a social world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Ghazanfar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Galantucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Simon Garrod, and Christian Keysers</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Personalization in goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boi</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Faltings</surname></persName>
		</author>
		<idno>abs/1706.07503</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations, ICLR 2015</title>
		<meeting>the 3rd International Conference on Learning Representations, ICLR 2015<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deal or no deal? endto-end learning of negotiation dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1094</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1127</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A splitand-recombine approach for follow-up query analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1535</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning personalized end-toend goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiqing</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33016794</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd AAAI Conference on Artificial Intelligence, AAAI 2019, The 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019</title>
		<meeting>the 33rd AAAI Conference on Artificial Intelligence, AAAI 2019, The 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019<address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019-01-27" />
		</imprint>
	</monogr>
	<note>The 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Personalizing dialogue agents via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1542</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Training millions of personalized dialogue agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Emmanuel</forename><surname>Mazaré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1298</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ParlAI: A dialog research software platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-2014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An adversarial learning framework for a persona-based multi-turn dialogue model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oluwatobi</forename><surname>Olabiyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Khazane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Salimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">T</forename><surname>Mueller</surname></persName>
		</author>
		<idno>abs/1905.01992</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alché-Buc, E. Fox, and R. Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019-12-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Tim Salimans, and Ilya Sutskever</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st AAAI Conference on Artificial Intelligence, AAAI 2019</title>
		<meeting>the 31st AAAI Conference on Artificial Intelligence, AAAI 2019<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017-02-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generating persona consistent dialogues by exploiting natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Nan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 34th AAAI Conference on Artificial Intelligence<address><addrLine>New York City; New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploiting persona information for diverse generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/721</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10" />
			<biblScope unit="volume">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-1020</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2015, Denver, Colorado. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2015, Denver, Colorado. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Satinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 12: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1999-11-29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Listening between the lines: Learning personal attributes from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Tigunova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paramita</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/3308558.3313498</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Wide Web Conference, WWW 2019</title>
		<meeting>the World Wide Web Conference, WWW 2019<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-05-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The optimal reward baseline for gradient-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lex</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence, UAI 2001</title>
		<meeting>the 17th Conference in Uncertainty in Artificial Intelligence, UAI 2001<address><addrLine>University of Washington, Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001-08-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00992696</idno>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<idno>abs/1910.03771</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Morgan Funtowicz, and Jamie Brew</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">TransferTransfo: A transfer learning approach for neural network based conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<idno>abs/1901.08149</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1046</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Personalized response generation by dual-learning based domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2018.03.009</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Aiming to know you better perhaps makes me a more engaging dialogue partner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Zemlyanskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K18-1053</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning<address><addrLine>CoNLL; Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Reinforcing coherence for sequence to sequence model in dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hainan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2018/635</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence, IJCAI 2018</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence, IJCAI 2018<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Personalizing dialogue agents: I have a dog, do you have pets too?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1205</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
