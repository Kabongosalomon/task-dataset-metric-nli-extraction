<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Empirical Evaluation of Rectified Activations in Convolution Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
							<email>tqchen@cs.washington.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
							<email>muli@cs.cmu.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Empirical Evaluation of Rectified Activations in Convolution Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we investigate the performance of different types of rectified activation functions in convolutional neural network: standard rectified linear unit (ReLU), leaky rectified linear unit (Leaky ReLU), parametric rectified linear unit (PReLU) and a new randomized leaky rectified linear units (RReLU). We evaluate these activation function on standard image classification task. Our experiments suggest that incorporating a nonzero slope for negative part in rectified activation units could consistently improve the results. Thus our findings are negative on the common belief that sparsity is the key of good performance in ReLU. Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overfitting. They are not as effective as using their randomized counterpart. By using RReLU, we achieved 75.68% accuracy on CIFAR-100 test set without multiple test or ensemble.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional neural network (CNN) has made great success in various computer vision tasks, such as image classification <ref type="bibr" target="#b6">(Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b14">Szegedy et al., 2014)</ref>, object detection <ref type="bibr" target="#b0">(Girshick et al., 2014)</ref> and tracking <ref type="bibr" target="#b15">(Wang et al., 2015)</ref>. Despite its depth, one of the key characteristics of modern deep learning system is to use non-saturated activation function (e.g. ReLU) to replace its saturated counterpart (e.g. sigmoid, tanh). The advantage of using non-saturated activation function lies in two aspects: The first is to solve the so called "exploding/vanishing gradient". The second is to accelerate the convergence speed.</p><p>In all of these non-saturated activation functions, the most notable one is rectified linear unit (ReLU) <ref type="bibr" target="#b10">(Nair &amp; Hinton, 2010;</ref><ref type="bibr" target="#b13">Sun et al., 2014)</ref>. Briefly speaking, it is a piecewise linear function which prunes the negative part to zero, and retains the positive part. It has a desirable property that the activations are sparse after passing ReLU. It is commonly believed that the superior performance of ReLU comes from the sparsity <ref type="bibr" target="#b1">(Glorot et al., 2011;</ref><ref type="bibr" target="#b13">Sun et al., 2014)</ref>. In this paper, we want to ask two questions: First, is sparsity the most important factor for a good performance? Second, can we design better non-saturated activation functions that could beat ReLU?</p><p>We consider a broader class of activation functions, namely the rectified unit family. In particular, we are interested in the leaky ReLU and its variants. In contrast to ReLU, in which the negative part is totally dropped, leaky ReLU assigns a noon-zero slope to it. The first variant is called parametric rectified linear unit (PReLU) <ref type="bibr" target="#b3">(He et al., 2015)</ref>. In PReLU, the slopes of negative part are learned form data rather than predefined. The authors claimed that PReLU is the key factor of surpassing human-level performance on Im-ageNet classification <ref type="bibr" target="#b11">(Russakovsky et al., 2015)</ref> task.</p><p>The second variant is called randomized rectified linear unit (RReLU). In RReLU, the slopes of negative parts are randomized in a given range in the training, and then fixed in the testing. In a recent Kaggle National Data Science Bowl (NDSB) competition 1 , it is reported that RReLU could reduce overfitting due to its randomized nature.</p><p>In this paper, we empirically evaluate these four kinds of activation functions. Based on our experiment, we conclude on small dataset, Leaky ReLU and its variants are consistently better than ReLU in convolutional neural networks. RReLU is favorable due to its randomness in training which reduces the risk of overfitting. While in case of large dataset, more investigation should be done in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Rectified Units</head><p>In this section, we introduce the four kinds of rectified units: rectified linear (ReLU), leaky rectified linear (Leaky ReLU), parametric rectified linear (PReLU) and randomized rectified linear (RReLU). We illustrate them in <ref type="figure" target="#fig_0">Fig.1</ref> for comparisons. In the sequel, we use x ji to denote the input of ith channel in jth example , and y ji to denote the corresponding output after passing the activation function. In the following subsections, we introduce each rectified unit formally. For PReLU, a i is learned and for Leaky ReLU a i is fixed. For RReLU, a ji is a random variable keeps sampling in a given range, and remains fixed in testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Rectified Linear Unit</head><p>Rectified Linear is first used in Restricted Boltzmann Machines <ref type="bibr" target="#b10">(Nair &amp; Hinton, 2010)</ref>. Formally, rectified linear activation is defined as:</p><formula xml:id="formula_0">y i = x i if x i ≥ 0 0 if x i &lt; 0.<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Leaky Rectified Linear Unit</head><p>Leaky Rectified Linear activation is first introduced in acoustic model <ref type="bibr" target="#b8">(Maas et al., 2013)</ref>. Mathematically, we have</p><formula xml:id="formula_1">y i = x i if x i ≥ 0 xi ai if x i &lt; 0,<label>(2)</label></formula><p>where a i is a fixed parameter in range (1, +∞). In original paper, the authors suggest to set a i to a large number like 100. In additional to this setting, we also experiment smaller a i = 5.5 in our paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Parametric Rectified Linear Unit</head><p>Parametric rectified linear is proposed by <ref type="bibr" target="#b3">(He et al., 2015)</ref>. The authors reported its performance is much better than ReLU in large scale image classification task. It is the same as leaky ReLU (Eqn.2) with the exception that a i is learned in the training via back propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Randomized Leaky Rectified Linear Unit</head><p>Randomized Leaky Rectified Linear is the randomized version of leaky ReLU. It is first proposed and used in Kaggle NDSB Competition. The highlight of RReLU is that in training process, a ji is a random number sampled from a uniform distribution U (l, u). Formally, we have:</p><formula xml:id="formula_2">y ji = x ji if x ji ≥ 0 a ji x ji if x ji &lt; 0,<label>(3)</label></formula><p>where a ji ∼ U (l, u), l &lt; u and l, u ∈ [0, 1)</p><p>In the test phase, we take average of all the a ji in training as in the method of dropout <ref type="bibr" target="#b12">(Srivastava et al., 2014)</ref> , and thus set a ji to l+u 2 to get a deterministic result. Suggested by the NDSB competition winner, a ji is sampled from U (3, 8). We use the same configuration in this paper.</p><p>In test time, we use:</p><formula xml:id="formula_4">y ji = x ji l+u 2<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment Settings</head><p>We evaluate classification performance on same convolutional network structure with different activation functions. Due to the large parameter searching space, we use two state-of-art convolutional network structure and same hyper parameters for different activation setting. All models are trained by using CXXNET 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">CIFAR-10 and CIFAR-100</head><p>The CIFAR-10 and CIFAR-100 dataset <ref type="bibr" target="#b5">(Krizhevsky &amp; Hinton, 2009</ref>) are tiny nature image dataset. CIFAR-10 datasets contains 10 different classes images and CIFAR-100 datasets contains 100 different classes. Each image is an RGB image in size 32x32. There are 50,000 training images and 10,000 test images. We use raw images directly without any pre-processing and augmentation. The result is from on single view test without any ensemble.</p><p>The network structure is shown in 8x8, avg pooling, /1 10 or 100 softmax <ref type="table" target="#tab_0">Table 1</ref>. CIFAR-10/CIFAR-100 network structure. Each layer is a convolutional layer if not otherwise specified. Activation function is followed by each convolutional layer.</p><p>In CIFAR-100 experiment, we also tested RReLU on Batch Norm Inception Network <ref type="bibr" target="#b4">(Ioffe &amp; Szegedy, 2015)</ref>. We use a subset of Inception Network which is started from inception-3a module. This network achieved 75.68% test accuracy without any ensemble or multiple view test 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">National Data Science Bowl Competition</head><p>The task for National Data Science Bowl competition is to classify plankton animals from image with award of $170k. There are 30,336 labeled gray scale images in 121 classes and there are 130,400 test data. Since the test set is private, we divide training set into two parts: 25,000 images for training and 5,336 images for validation. The competition uses multi-class log-loss to evaluate classification performance.</p><p>We refer the network and augmentation setting from team AuroraXie 4 , one of competition winners. The network structure is shown in   <ref type="table" target="#tab_4">Table 3</ref> and 4 show the results of CIFAR-10/CIFAR-100 dataset, respectively. <ref type="table" target="#tab_1">Table 5</ref> shows the NDSB result. We use ReLU network as baseline, and compare the convergence curve with other three activations pairwisely in <ref type="figure">Fig. 2, 3</ref> and 4, respectively. All these three leaky ReLU variants are better than baseline on test set. We have the following observations based on our experiment:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Result and Discussion</head><p>1. Not surprisingly, we find the performance of normal leaky ReLU (a = 100) is similar to that of ReLU, but very leaky ReLU with larger a = 5.5 is much better.</p><p>2. On training set, the error of PReLU is always the lowest, and the error of Leaky ReLU and RReLU are higher than ReLU. It indicates that PReLU may suffer from severe overfitting issue in small scale dataset.</p><p>3. The superiority of RReLU is more significant than that on CIFAR-10/CIFAR-100. We conjecture that it is because the in the NDSB dataset, the training set is smaller than that of CIFAR-10/CIFAR-100, but the network we use is even bigger. This validates the effectiveness of RReLU when combating with overfitting.</p><p>4. For RReLU, we still need to investigate how the randomness influences the network training and testing process.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we analyzed four rectified activation functions using various network architectures on three datasets. Our findings strongly suggest that the most popular activation function ReLU is not the end of story: Three types of (modified) leaky ReLU all consistently outperform the original ReLU. However, the reasons of their superior performances still lack rigorous justification from theoretic aspect. Also, how the activations perform on large scale data is still need to be investigated. This is an open question worth pursuing in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>ReLU, Leaky ReLU, PReLU and RReLU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>. It is taken</cell></row><row><cell cols="2">from Network in Network(NIN)(Lin et al., 2013).</cell></row><row><cell cols="2">Input Size NIN</cell></row><row><cell>32 × 32</cell><cell>5x5, 192</cell></row><row><cell>32 × 32</cell><cell>1x1, 160</cell></row><row><cell>32 × 32</cell><cell>1x1, 96</cell></row><row><cell>32 × 32</cell><cell>3x3 max pooling, /2</cell></row><row><cell>16 × 16</cell><cell>dropout, 0.5</cell></row><row><cell>16 × 16</cell><cell>5x5, 192</cell></row><row><cell>16 × 16</cell><cell>1x1, 192</cell></row><row><cell>16 × 16</cell><cell>1x1, 192</cell></row><row><cell>16 × 16</cell><cell>3x3,avg pooling, /2</cell></row><row><cell>8 × 8</cell><cell>dropout, 0.5</cell></row><row><cell>8 × 8</cell><cell>3x3, 192</cell></row><row><cell>8 × 8</cell><cell>1x1, 192</cell></row><row><cell>8 × 8</cell><cell>1x1, 10</cell></row><row><cell>8 × 8</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 5 .</head><label>5</label><figDesc>We only use single view test in our experiment, which is different to original multi-view, multi-scale test.</figDesc><table><row><cell cols="2">Input Size NDSB Net</cell></row><row><cell>70 × 70</cell><cell>3x3, 32</cell></row><row><cell>70 × 70</cell><cell>3x3, 32</cell></row><row><cell>70 × 70</cell><cell>3x3, max pooling, /2</cell></row><row><cell>35 × 35</cell><cell>3x3, 64</cell></row><row><cell>35 × 35</cell><cell>3x3, 64</cell></row><row><cell>35 × 35</cell><cell>3x3, 64</cell></row><row><cell>35 × 35</cell><cell>3x3, max pooling, /2</cell></row><row><cell>17 × 17</cell><cell>split: branch1 -branch 2</cell></row><row><cell>17 × 17</cell><cell>3x3, 96 -3x3, 96</cell></row><row><cell>17 × 17</cell><cell>3x3, 96 -3x3, 96</cell></row><row><cell>17 × 17</cell><cell>3x3, 96 -3x3, 96</cell></row><row><cell>17 × 17</cell><cell>3x3, 96</cell></row><row><cell>17 × 17</cell><cell>channel concat, 192</cell></row><row><cell>17 × 17</cell><cell>3x3, max pooling, /2</cell></row><row><cell>8 × 8</cell><cell>3x3, 256</cell></row><row><cell>8 × 8</cell><cell>3x3, 256</cell></row><row><cell>8 × 8</cell><cell>3x3, 256</cell></row><row><cell>8 × 8</cell><cell>3x3, 256</cell></row><row><cell>8 × 8</cell><cell>3x3, 256</cell></row><row><cell>8 × 8</cell><cell>SPP (He et al., 2014) {1, 2, 4}</cell></row><row><cell cols="2">12544 × 1 flatten</cell></row><row><cell>1024 × 1</cell><cell>fc1</cell></row><row><cell>1024 × 1</cell><cell>fc2</cell></row><row><cell>121</cell><cell>softmax</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>National</figDesc><table><row><cell>Data Science Bowl Competition Net-</cell></row><row><cell>work. All layers are convolutional layers if not otherwise</cell></row><row><cell>specified. Activation function is followed by each convolu-</cell></row><row><cell>tional layer.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Error rate of CIFAR-10 Network in Network with different activation function</figDesc><table><row><cell>Activation</cell><cell cols="2">Training Error Test Error</cell></row><row><cell>ReLU</cell><cell>0.1356</cell><cell>0.429</cell></row><row><cell>Leaky ReLU, a = 100</cell><cell>0.11552</cell><cell>0.4205</cell></row><row><cell>Leaky ReLU, a = 5.5</cell><cell>0.08536</cell><cell>0.4042</cell></row><row><cell>PReLU</cell><cell>0.0633</cell><cell>0.4163</cell></row><row><cell cols="2">RReLU (yji = xji/ l+u 2 ) 0.1141</cell><cell>0.4025</cell></row><row><cell cols="3">Table 4. Error rate of CIFAR-100 Network in Network with</cell></row><row><cell>different activation function</cell><cell></cell><cell></cell></row><row><cell>Activation</cell><cell cols="2">Train Log-Loss Val Log-Loss</cell></row><row><cell>ReLU</cell><cell>0.8092</cell><cell>0.7727</cell></row><row><cell>Leaky ReLU, a = 100</cell><cell>0.7846</cell><cell>0.7601</cell></row><row><cell>Leaky ReLU, a = 5.5</cell><cell>0.7831</cell><cell>0.7391</cell></row><row><cell>PReLU</cell><cell>0.7187</cell><cell>0.7454</cell></row><row><cell cols="2">RReLU (yji = xji/ l+u 2 ) 0.8090</cell><cell>0.7292</cell></row><row><cell cols="3">Table 5. Multi-classes Log-Loss of NDSB Network with dif-</cell></row><row><cell>ferent activation function</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Kaggle National Data Science Bowl Competition: https://www.kaggle.com/c/datasciencebowl</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">CXXNET: https://github.com/dmlc/cxxnet</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">CIFAR-100 Reproduce code: https://github. com/dmlc/mxnet/blob/master/example/notebooks/ cifar-100.ipynb</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Winning Doc of AuroraXie: https://github.com/ auroraxie/Kaggle-NDSB</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank Jason Rolfe from D-Wave system for helpful discussion on test network for randomized leaky ReLU.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics. JMLR W&amp;CP Volume</title>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics. JMLR W&amp;CP Volume</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="346" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.01852</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Andrew Y. Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Empirical Evaluation of Rectified Activations in Convolutional Network Figure 2: Convergence curves for training and test sets of different activations on CIFAR-10 Network in Network. Figure 3: Convergence curves for training and test sets of different activations on CIFAR-100</title>
	</analytic>
	<monogr>
		<title level="m">Convergence curves for training and test sets of different activations on NDSB Net</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Im-ageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sanjeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhiheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-015-0816-y</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deeply learned face representations are sparse, selective, and robust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1265</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yangqing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dumitru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.4842</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Going deeper with convolutions. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Transferring rich feature hierarchies for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Siyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dit-Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.04587</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
