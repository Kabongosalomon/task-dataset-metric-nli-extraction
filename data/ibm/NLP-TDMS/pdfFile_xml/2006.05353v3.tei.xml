<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MeshWalker: Deep Mesh Understanding by Random Walks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-12">2020. December 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lahav</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayellet</forename><surname>Tal</surname></persName>
						</author>
						<title level="a" type="main">MeshWalker: Deep Mesh Understanding by Random Walks</title>
					</analytic>
					<monogr>
						<title level="j" type="main">ACM Trans. Graph</title>
						<imprint>
							<biblScope unit="volume">39</biblScope>
							<date type="published" when="2020-12">2020. December 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3414685.3417806</idno>
					<note>0730-0301/2020/12-ART263 $15.00 Additional Key Words and Phrases: Deep Learning, Random Walks ACM Reference Format:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts: • Computing methodologies → Shape analysis</term>
					<term>Super- vised learning Authors&apos; addresses: Alon Lahav, Technion -Israel Institute of Technology, alonlahav2@ gmailcom</term>
					<term>Ayellet Tal, Technion -Israel Institute of Technology, ayellet@eetechnion acil</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Walk step: Walk step: Walk step: flamingo Fig. 1. Classification by MeshWalker. This figure shows classification results as the walk (in green) proceeds along the surface of a camel (4 faces) from SHREC11 [Lian et al. 2011</p><p>]. The initial point was randomly chosen on the neck. After /50 steps (left), being the number of vertices, the system is uncertain regarding the class, and the highest probability predictions are for the flamingo class and for the hand class (out of 30 classes). After continuing the random walk along the body and the front leg for /7 steps, the probability of being a horse is higher than before, but the camel already has quite a high probability.</p><p>Finally, after /2.5 steps (right) and walking also along the hump, the system correctly classifies the model as a camel.</p><p>Most attempts to represent 3D shapes for deep learning have focused on volumetric grids, multi-view images and point clouds. In this paper we look at the most popular representation of 3D shapes in computer graphicsa triangular mesh-and ask how it can be utilized within deep learning. The few attempts to answer this question propose to adapt convolutions &amp; pooling to suit Convolutional Neural Networks (CNNs). This paper proposes a very different approach, termed MeshWalker to learn the shape directly from a given mesh. The key idea is to represent the mesh by random walks along the surface, which "explore" the mesh's geometry and topology. Each walk is organized as a list of vertices, which in some manner imposes regularity on the mesh. The walk is fed into a Recurrent Neural Network (RNN) that "remembers" the history of the walk. We show that our approach achieves state-of-the-art results for two fundamental shape analysis tasks: shape classification and semantic segmentation. Furthermore, even a very small number of examples suffices for learning. This is highly important, since large datasets of meshes are difficult to acquire.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Fig. 1</ref><p>. Classification by MeshWalker. This figure shows classification results as the walk (in green) proceeds along the surface of a camel (4 faces) from SHREC11 <ref type="bibr" target="#b57">[Lian et al. 2011</ref>]. The initial point was randomly chosen on the neck. After /50 steps (left), being the number of vertices, the system is uncertain regarding the class, and the highest probability predictions are for the flamingo class and for the hand class (out of 30 classes). After continuing the random walk along the body and the front leg for /7 steps, the probability of being a horse is higher than before, but the camel already has quite a high probability. Finally, after /2.5 steps (right) and walking also along the hump, the system correctly classifies the model as a camel.</p><p>Most attempts to represent 3D shapes for deep learning have focused on volumetric grids, multi-view images and point clouds. In this paper we look at the most popular representation of 3D shapes in computer graphicsa triangular mesh-and ask how it can be utilized within deep learning. The few attempts to answer this question propose to adapt convolutions &amp; pooling to suit Convolutional Neural Networks (CNNs). This paper proposes a very different approach, termed MeshWalker to learn the shape directly from a given mesh. The key idea is to represent the mesh by random walks along the surface, which "explore" the mesh's geometry and topology. Each walk is organized as a list of vertices, which in some manner imposes regularity on the mesh. The walk is fed into a Recurrent Neural Network (RNN) that "remembers" the history of the walk. We show that our approach achieves state-of-the-art results for two fundamental shape analysis tasks: shape classification and semantic segmentation. Furthermore, even a very small number of examples suffices for learning. This is highly important, since large datasets of meshes are difficult to acquire. CCS Concepts: • Computing methodologies → Shape analysis; Supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The most-commonly used representation of surfaces in computer graphics is a polygonal mesh, due to its numerous benefits, including efficiency and high-quality. Nevertheless, in the era of deep learning, this representation is often bypassed because of its irregularity, which does not suit Convolutional Neural Networks (CNNs). Instead, 3D data is often represented as volumetric grids <ref type="bibr" target="#b7">[Ben-Shabat et al. 2018;</ref><ref type="bibr" target="#b68">Maturana and Scherer 2015;</ref><ref type="bibr" target="#b80">Roynard et al. 2018;</ref><ref type="bibr" target="#b83">Sedaghat et al. 2016b]</ref> or multiple 2D projections <ref type="bibr" target="#b10">[Boulch et al. 2017;</ref><ref type="bibr" target="#b20">Feng et al. 2018a;</ref><ref type="bibr" target="#b48">Kanezaki et al. 2018;</ref><ref type="bibr" target="#b88">Su et al. 2015;</ref><ref type="bibr" target="#b110">Yavartanoo et al. 2018]</ref>. In some recent works point clouds are utilized and new ways to convolve or pool are proposed <ref type="bibr" target="#b5">[Atzmon et al. 2018;</ref><ref type="bibr" target="#b42">Hua et al. 2018;</ref>; <ref type="bibr" target="#b94">Thomas et al. 2019;</ref><ref type="bibr" target="#b108">Xu et al. 2018]</ref>.</p><p>Despite the benefits of these representations, they miss the notions of neighborhoods and connectivity and might not be as good for capturing local surface properties. Recently, several works have proposed to maintain the potential of the mesh representation, while still utilizing neural networks. FeaStNet <ref type="bibr" target="#b97">[Verma et al. 2018</ref>] proposes a graph neural network in which the neighborhood of each vertex for the convolution operation is calculated dynamically based on its features. MeshCNN <ref type="bibr" target="#b36">[Hanocka et al. 2019</ref>] defines pooling and convolution layers over the mesh edges. MeshNet <ref type="bibr" target="#b19">[Feng et al. 2019]</ref> treats the faces of a mesh as the basic unit and extracts their spatial and structural features individually to offer the final semantic representation. LRF-Conv <ref type="bibr" target="#b109">[Yang et al. 2020</ref>] learns descriptors directly from the raw mesh by defining new continuous convolution kernels that provide robustness to sampling. All these methods redefine the convolution operation, and by doing so, are able to fit the unordered structure of a mesh to a CNN framework.</p><p>We propose a novel and fundamentally different approach, named MeshWalker. As in previous approaches that learn directly from the mesh data, the basic question is how to impose regularity on the unordered data. Our key idea is to represent the mesh by random walks on its surface. These walks explore the local geometry of the surface, as well as its global one. Every walk is fed into a Recurrent Neural Network (RNN), that "remembers" the walk's history.</p><p>In addition to simplicity, our approach has three important benefits. First, we will show that even a small dataset suffices for training. Intuitively, we can generate multiple random walks for a single model; these walks provide multiple explorations of the model. This may be considered as equivalent to using different projections of 3D objects in the case of image datasets. Second, as opposed to CNNs, RNNs are inherently robust to sequence length. This is vital in the case of meshes, as datasets include objects of various granularities. Third, the meshes need not be watertight or have a single connected component; our approach can handle any triangular mesh.</p><p>Our approach is general and can be utilized to address a variety of shape analysis tasks. We demonstrate its benefit in two basic applications: mesh classification and mesh semantic segmentation. Our results are superior to those of state-of-the-art approaches on common datasets and on highly non-uniform meshes. Furthermore, when the training set is limited in size, the accuracy improvement over the state-of-the-art methods is highly evident.</p><p>Hence, this paper makes three contributions:</p><p>(1) We propose a novel representation of meshes for neural networks: random walks on surfaces. (2) We present an end-to-end learning framework that realizes this representation within RNNs. We show that this framework works well even when the dataset is very small. This is important in the case of 3D, where large datasets are seldom available and are difficult to generate. (3) We demonstrate the benefits of our method in two key applications: 3D shape classification and semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work is at the crossroads of three fields, as discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Representing 3D objects for Deep Neural Networks</head><p>A variety of representations of 3D shapes have been proposed in the context of deep learning. The main challenge is how to re-organize the shape description such that it could be processed within deep learning frameworks. Hereafter we briefly review the main representations; see <ref type="bibr" target="#b24">[Gezawa et al. 2020</ref>] for a recent excellent survey.</p><p>Multi-view 2D projections. This representation is essentially a set of 2D images, each of which is a rendering of the object from a different viewpoint <ref type="bibr" target="#b21">Feng et al. 2018b;</ref><ref type="bibr" target="#b26">Gomez-Donoso et al. 2017;</ref><ref type="bibr" target="#b34">Han et al. 2019;</ref><ref type="bibr" target="#b37">He et al. 2018;</ref><ref type="bibr" target="#b44">Johns et al. 2016;</ref><ref type="bibr" target="#b46">Kalogerakis et al. 2017;</ref><ref type="bibr" target="#b48">Kanezaki et al. 2018;</ref><ref type="bibr" target="#b76">Qi et al. 2016;</ref><ref type="bibr" target="#b81">Sarkar et al. 2018;</ref><ref type="bibr" target="#b88">Su et al. 2015;</ref><ref type="bibr" target="#b101">Wang et al. 2019c;</ref><ref type="bibr" target="#b111">Zanuttigh and Minto 2017]</ref>. The major benefit of this representation is that it can naturally utilize any image-based CNN. In addition, high-resolution inputs can be easily handled. However, it is not easy to determine the optimal number of views; if that number is large, the computation might be costly. Furthermore, self-occlusions might be a drawback.</p><p>Volumetric grids. These grids are analogous to the 2D grids of images. Therefore, the main benefit of this representation is that operations that are applied on 2D grids can be extended to 3D in a straightforward manner <ref type="bibr" target="#b11">[Brock et al. 2016;</ref><ref type="bibr" target="#b18">Fanelli et al. 2011;</ref><ref type="bibr" target="#b68">Maturana and Scherer 2015;</ref><ref type="bibr" target="#b82">Sedaghat et al. 2016a;</ref><ref type="bibr" target="#b93">Tchapmi et al. 2017;</ref><ref type="bibr" target="#b100">Wang et al. 2019a;</ref><ref type="bibr" target="#b106">Wu et al. 2015;</ref><ref type="bibr" target="#b113">Zhi et al. 2018]</ref>. The primary drawbacks of volumetric grids are their limited resolution and the heavy computation cost needed.</p><p>Point clouds. This representation consists of a set of 3D points, sampled from the object's surface. The simplicity, close relationship to data acquisition, and the ease of conversion from other representations, make point clouds an attractive representation. Therefore, a variety of recent works proposed successful techniques for point cloud shape analysis using neural networks <ref type="bibr" target="#b5">[Atzmon et al. 2018;</ref><ref type="bibr" target="#b31">Guerrero et al. 2018;</ref><ref type="bibr">Qi et al. 2017a,b;</ref><ref type="bibr" target="#b104">Wang et al. 2019d;</ref><ref type="bibr" target="#b105">Williams et al. 2019;</ref><ref type="bibr" target="#b107">Xu et al. 2019;</ref><ref type="bibr" target="#b115">Zhu et al. 2019</ref>]. These methods attempt to learn a representation for each point, using its neighbors (Euclidean-wise) either by multi layer perceptions or by convolutional layers. Some also define novel pooling layers. Point cloud representations might fall short in applications when the connectivity is highly meaningful (e.g. segmentation) or when the salient information is concentrated in small specific areas.</p><p>Triangular meshes. This representation is the most widespread representation in computer graphics and the focus of our paper. The major challenge of using meshes within deep learning frameworks is the irregularity of the representation-each vertex has a different number of neighbors, at different distances.</p><p>The pioneering work of <ref type="bibr" target="#b67">[Masci et al. 2015]</ref> introduces deep learning of local features and shows how to make the convolution operations intrinsic to the mesh. In <ref type="bibr" target="#b74">[Poulenard and Ovsjanikov 2018]</ref> a new convolutional layer is defined, which allows the propagation of geodesic information throughout the network layers. FeaSt-Net <ref type="bibr" target="#b97">[Verma et al. 2018</ref>] proposes a graph neural network in which the neighborhood of each vertex for the convolution operation is calculated dynamically based on its features. Another line of works exploits the fact that local patches are approximately Euclidean. The 3D manifolds are then parameterized in 2D, where standard CNNs are utilized <ref type="bibr" target="#b9">[Boscaini et al. 2016;</ref><ref type="bibr" target="#b17">Ezuz et al. 2017;</ref><ref type="bibr" target="#b33">Haim et al. 2019;</ref><ref type="bibr" target="#b38">Henaff et al. 2015;</ref><ref type="bibr" target="#b66">Maron et al. 2017;</ref><ref type="bibr" target="#b86">Sinha et al. 2016]</ref>. A different approach is to apply a linear map to a spiral of neighbors <ref type="bibr" target="#b27">[Gong et al. 2019;</ref><ref type="bibr" target="#b59">Lim et al. 2018]</ref>, which works well for meshes with a similar graph structure.</p><p>Two approaches were recently introduced: MeshNet <ref type="bibr" target="#b19">[Feng et al. 2019</ref>] treats faces of a mesh as the basic unit and extracts their spatial and structural features individually, to offer the final semantic representation. MeshCNN <ref type="bibr" target="#b36">[Hanocka et al. 2019</ref>] is based on a very unique idea of using the edges of the mesh to perform pooling and (a) 5 walks on the surface (b) Classification: Samples from the class the input belongs to (c) Semantic segmentation convolution. The convolution operations exploit the regularity of edges-having 4 edges of their incidental triangles. An edge collapse operation is used for pooling, which maintains surface topology and generates new mesh connectivity for further convolutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification</head><p>Object classification refers to the task of classifying a given shape into one of pre-defined categories. Before deep learning methods became widespread, the main challenges were finding good descriptors and good distance functions between these descriptors. According to the thorough review of <ref type="bibr" target="#b58">[Lian et al. 2013]</ref>, the methods could be roughly classified into algorithms employing local features <ref type="bibr" target="#b45">[Johnson and Hebert 1999;</ref><ref type="bibr" target="#b62">Liu et al. 2006;</ref><ref type="bibr" target="#b64">Lowe 2004;</ref><ref type="bibr" target="#b89">Sun et al. 2009</ref>], topological structures <ref type="bibr" target="#b39">[Hilaga et al. 2001;</ref><ref type="bibr" target="#b91">Sundar et al. 2003;</ref><ref type="bibr" target="#b92">Tam and Lau 2007]</ref>, isometry-invariant global geometric properties <ref type="bibr" target="#b43">[Jain and Zhang 2007;</ref><ref type="bibr" target="#b65">Mahmoudi and Sapiro 2009;</ref><ref type="bibr" target="#b78">Reuter et al. 2005]</ref>, direct shape matching, or canonical forms <ref type="bibr" target="#b13">[Bronstein et al. 2006;</ref><ref type="bibr" target="#b16">Elad and Kimmel 2003;</ref><ref type="bibr" target="#b69">Mémoli 2007;</ref><ref type="bibr" target="#b70">Mémoli and Sapiro 2005]</ref>.</p><p>Many of the recent techniques already use deep learning for classification. They are described in Section 2.1, for instance <ref type="bibr" target="#b12">[Bronstein et al. 2011;</ref><ref type="bibr" target="#b17">Ezuz et al. 2017;</ref><ref type="bibr" target="#b19">Feng et al. 2019;</ref><ref type="bibr" target="#b35">Hanocka et al. 2018;</ref><ref type="bibr" target="#b52">Kipf and Welling 2016;</ref><ref type="bibr" target="#b73">Perozzi et al. 2014;</ref><ref type="bibr">Qi et al. 2017a,b;</ref><ref type="bibr" target="#b94">Thomas et al. 2019;</ref><ref type="bibr" target="#b96">Veličković et al. 2017;</ref><ref type="bibr" target="#b102">Wang et al. 2019b</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Semantic segmentation</head><p>Mesh segmentation is a key ingredient in many computer graphics tasks, including modeling, animation and a variety of shape analysis tasks. The goal is to determine, for the basic elements of the mesh (vertex, edge or face), to which segment they belong. Many approaches were proposed, including region growing <ref type="bibr" target="#b14">[Chazelle et al. 1997;</ref><ref type="bibr" target="#b49">Katz et al. 2005;</ref><ref type="bibr" target="#b53">Koschan 2003;</ref><ref type="bibr" target="#b55">Lavoué et al. 2005;</ref><ref type="bibr" target="#b90">Sun et al. 2002;</ref><ref type="bibr" target="#b114">Zhou and Huang 2004]</ref>, clustering <ref type="bibr" target="#b23">Gelfand and Guibas 2004;</ref><ref type="bibr" target="#b50">Katz and Tal 2003;</ref><ref type="bibr" target="#b85">Shlafman et al. 2002]</ref>, spectral analysis <ref type="bibr" target="#b1">[Alpert and Yao 1995;</ref><ref type="bibr" target="#b28">Gotsman 2003;</ref><ref type="bibr" target="#b60">Liu and Zhang 2004;</ref><ref type="bibr" target="#b112">Zhang et al. 2005</ref>] and more. See <ref type="bibr" target="#b79">Rodrigues et al. 2018;</ref><ref type="bibr" target="#b84">Shamir 2008]</ref> for excellent surveys of segmentation methods.</p><p>Lately, deep learning has been utilized for this task as well. Each proposed approach handles a specific shape representation, as described in Section 2.1. These approaches include among others <ref type="bibr" target="#b32">[Guo et al. 2015;</ref><ref type="bibr" target="#b33">Haim et al. 2019;</ref><ref type="bibr" target="#b35">Hanocka et al. 2018;</ref><ref type="bibr" target="#b66">Maron et al. 2017;</ref><ref type="bibr">Qi et al. 2017a,b,b;</ref><ref type="bibr" target="#b109">Yang et al. 2020</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MESHWALKER OUTLINE</head><p>Imagine an ant walking on a surface; it will "climb" on ridges and go through valleys. Thus, it will explore the local geometry of the surface, as well as the global terrain. Random walks have been shown to incorporate both global and local information about a given object <ref type="bibr" target="#b29">[Grady 2006;</ref><ref type="bibr" target="#b54">Lai et al. 2008;</ref><ref type="bibr" target="#b63">Lovász et al. 1993;</ref><ref type="bibr" target="#b71">Noh and Rieger 2004]</ref>. This information may be invaluable for shape analysis tasks, nevertheless, random walks have not been used to represent meshes within a deep learning framework before.</p><p>Given a polygonal mesh, we propose to randomly walk through the vertices of the mesh, along its edges, as shown in <ref type="figure" target="#fig_0">Fig. 2(a)</ref>. In our ant analogy, the longer the walk, the more information is acquired by the ant. But how shall this information be accumulated? We propose to feed this representation into a Recurrent Neural Network (RNN) framework, which aggregates properties of the walk. This aggregated information will enable the ant to perceive the shape of the mesh. This is particularly beneficial for shape analysis tasks that require both the 3D global structure and some local information of the mesh, as demonstrated in <ref type="figure" target="#fig_0">Fig. 2</ref></p><formula xml:id="formula_0">(b-c).</formula><p>Algorithm 1 describes the training procedure of our proposed MeshWalker approach. A defining property of it is that the same piece of algorithm is used for every vertex along the walk (i.e., each vertex the ant passes through). The algorithm iterates on the following: A mesh is first extracted from the dataset (it could be a mesh that was previously extracted). A vertex is chosen randomly as the head of the walk and then a random walk is generated. This walk is the input to an RNN model. Finally, the RNN model's parameters are updated by minimizing the Softmax cross entropy loss , using Adam optimizer [Kingma and Ba 2014].</p><p>Section 4 elaborates on the architecture of our MeshWalker learning model, as well as on each of the ingredients of the iterative step. Section 6.2 explains the mesh pre-processing step, which essentially performs mesh simplification, and provides implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LEARNING TO WALK OVER A SURFACE</head><p>This section explains how to realize Algorithm 1. It begins by elaborating on the construction of a random walk on a mesh. It then proceeds to describe the network that learns from walks in order to understand meshes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">What is a walk?</head><p>Walks provide a novel way to organize the mesh data. A walk is a sequence of vertices (not necessarily adjacent), each of which is associated with basic information.</p><p>Walk generation. We adopt a very simple strategy to generate walks, out of many possible ones. Recall that we are given the first vertex of a walk. Then, to generate the walk , the other vertices are iteratively added, as follows. Given the current vertex of the walk, the next vertex is chosen randomly from its adjacent vertices (those that belong to its one-ring neighbors).</p><p>If such a vertex does not exist (as all the neighbors already belong to the walk), the walk is tracked backwards until an un-visited neighbor is found; this neighbor is added to the walk. In this case, the walk is not a linear sequence of vertices connected via edges, but rather a tree. If the mesh consists of multiple connected component, it is possible that the walk reaches a dead-end. In this case, a new random un-visited vertex is chosen and the walk generation proceeds as before. We note that in all cases, the input to the RNN is a sequence of vertices, arranged by their discovery order. In practice, the length of the walk is set by default to ⌈ /2.5⌉, where is number of vertices.</p><p>Walk representation. Once the walk is determined, the representation of this walk should be defined; this would be the input to the RNN. Each vertex is represented as the 3D translation from the previous vertex in the walk (Δ , Δ , Δ ). This is inline with the deep learning philosophy, which prefers end-to-end learning instead of hand-crafted features that are separated from a classifier, We note that we also tried other representations, including vertex coordinates, normals, and curvatures, but the results did not improve.</p><p>Walks at inference time. At inference, several walks are being used for each mesh. Each walk produces a vector of probabilities to belong to the different classes (in the case of classification). These vectors are averaged to produce the final result. To understand the importance of averaging, let us consider the walks on the camel in <ref type="figure">Fig. 1</ref>. Since walks are generated randomly, we expect some of them to explore atypical parts of the model, such as the legs, which are similar to horse legs. Other walks, however, are likely to explore unique parts, such as the hump or the head. The average result will most likely be the camel, as will be shown in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning from walks</head><p>Once walks are defined, the next challenge is to distillate the information accumulated along a walk into a single descriptor vector. Hereafter we discuss the network architecture and the training.</p><p>Network architecture. The model consists of three sub-networks, as illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref>. The first sub-network is given the current vertex of the walk and learns a new feature space, i.e. it transforms the 3D input feature space into a 256D feature space. This is done by two fully connected (FC) layers, followed by an instance normalization <ref type="bibr" target="#b95">[Ulyanov et al. 2016</ref>] layer and ReLu as nonlinear activation; both empirically outperform other alternatives.</p><p>The second sub-network is the core of our approach. It utilizes a recurrent neural network (RNN) whose defining property is being able to "remember" and accumulate knowledge. Briefly, a recurrent neural network <ref type="bibr" target="#b15">[Cho et al. 2014;</ref><ref type="bibr" target="#b30">Graves et al. 2008;</ref><ref type="bibr" target="#b40">Hochreiter and Schmidhuber 1997</ref>] is a connectionist model that contains a selfconnected hidden layer. The benefit of self-connection is that the 'memory' of previous inputs remains in the network's internal state, allowing it to make use of past context. In our setting, the RNN gets as input a feature vector (the result of the previous sub-network), learns the hidden states that describe the walk up to the current vertex, and outputs a state vector that contains the information gathered along the walk.</p><p>Another benefit of RNNs, which is crucial in our case, is not being confined to fixed-length inputs or outputs. Thus, we can use the model to inference on a walk of a certain length, which may differ from walk lengths the model was trained on.</p><p>To implement the RNN part of our model, we use three Gated Recurrent Unit (GRU) layers of <ref type="bibr" target="#b15">[Cho et al. 2014]</ref>. Briefly, the goal of an GRU layer is to accumulate only the important information from the input sequence and to forget the non-important information.</p><p>Formally, let be the input at time and ℎ be the hidden state at time ; let the reset gate and the update gate be two vectors, which jointly decide which information should be passed from time -1 to time . To realize GRU's goal, the network performs the following calculation, which sets the hidden state at time . Its final content is based on updating the hidden state in the previous time (the update gate determines which information should be passed)  <ref type="figure">figure)</ref>, the network is similar. However, Softmax is applied to each of the resulting vectors of the vertices (the orange circles in the right column); each vertex is classified into a segment. and on its candidate memory contenth :</p><formula xml:id="formula_1">ℎ = ⊙ ℎ −1 + (1 − ) ⊙h ,<label>(1)</label></formula><p>where ⊙ is an element-wise multiplication. Here,h is defined as:</p><formula xml:id="formula_2">ℎ = tanh (ℎ) + (ℎ) ℎ −1 ⊙ + (ℎ) .<label>(2)</label></formula><p>That is, when the reset gate is close to 0, the hidden state ignores the previous hidden state and resets with the current input only. This effectively allows the hidden state to drop any information that will later be found to be irrelevant. Finally, the reset gate and the update gate are defined as:</p><formula xml:id="formula_3">= ( ) + ( ) ℎ −1 + ( ) ,<label>(3)</label></formula><formula xml:id="formula_4">= ( ) + ( ) ℎ −1 + ( ) ,<label>(4)</label></formula><p>where is a logistic Sigmoid function. (ℎ) , ( ) , ( ) , (ℎ) , ( ) and ( ) are trainable weight matrices and (ℎ) , ( ) , ( ) are trainable bias vectors. The initial hidden state ℎ is set to 0. GRU outperforms a vanilla RNN, due to its ability to both remember the important information along the sequence and to forget unimportant content. Furthermore, it is capable of processing long sequences, similarly to the Long Short-Term Memory (LSTM) <ref type="bibr" target="#b40">[Hochreiter and Schmidhuber 1997]</ref>. Being able to accumulate information from long sequences is vital for grasping the shape of a 3D model, which usually consists of thousands of vertices. We chose GRU over LSTM due to its simplicity and its smaller computational requirements. For comparison, LSTM would require 16.8 trainable parameters in our case, whereas uses 12.7 . Furthermore, the inference time is smaller-for instance, a single 100-steps walk takes 5 using LSTM and 3 using GRU.</p><p>The third sub-network in <ref type="figure" target="#fig_1">Fig. 3</ref> predicts the object class in case of classification, or the vertex segment in case of semantic segmentation. It consists of a single fully connected (FC) layer on top of the state vector calculated in the previous sub-network. More details on the architectures &amp; the implementation are given in Section 6.</p><p>Loss calculation. The Softmax cross entropy loss is used on the output of the third part of the network. In the case of the classification task, only the last step of the walk is used as input to the loss function, since it accumulates all prior information from the walk. In <ref type="figure" target="#fig_1">Fig. 3</ref>, this is the bottom-right orange component.</p><p>In the case of the segmentation task, each vertex has its own predicted segment class. Each of the orange components in <ref type="figure" target="#fig_1">Fig. 3</ref> classifies the segment that the respected vertex belongs to. Since at the beginning of the walk the results are not trustworthy (as the mesh is not yet well understood), for the loss calculation in the training process we consider the segment class predictions only for the vertices that belong to the second half of the walk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">APPLICATIONS: CLASSIFICATION &amp; SEGMENTATION</head><p>MeshWalker is a general approach, which may be applied to a variety of applications. We demonstrate its performance for two fundamental tasks in shape analysis: mesh classification and mesh semantic segmentation. Our results are compared against the reported SOTA results for recently-used datasets, hence the methods we compare against vary according to the specific dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Mesh classification</head><p>Given a mesh, the goal is to classify it into one of pre-defined classes. For the given mesh we generate multiple random walks. These walks are run through the trained network. For each walk, the network predicts the probability of this mesh to belong to each class. These prediction vectors are averaged into a single prediction vector. In practice we use 32 walks; Section 6 will discuss the robustness of MeshWalker to the number of walks.</p><p>To test our algorithm, we applied our method to three recentlyused datasets: SHREC11 <ref type="bibr" target="#b57">[Lian et al. 2011</ref>], engraved cubes <ref type="bibr" target="#b36">[Hanocka et al. 2019]</ref> and ModelNet40 <ref type="bibr" target="#b106">[Wu et al. 2015]</ref>, which differ from each other in the number of classes, the number of objects per class, as well as the type of shapes they contain. As common, the accuracy is defined as the ratio of correctly predicted meshes.  <ref type="table" target="#tab_0">Table 1</ref> compares the performance, where each result is the average of the results of 3 randoms splits (of 16/4 or of 10/10). When the split is 10 objects for training and 10 for testing, the advantage of our method is apparent. When 16 objects are used for training and only 4 for testing, we get the same accuracy as that of the current state-of-the-art. In Section 6.1 we show that indeed the smaller the training dataset, the more advantageous our approach is. <ref type="table" target="#tab_0">Table 1</ref>. Classification on SHREC11 <ref type="bibr" target="#b57">[Lian et al. 2011</ref>]. Split-16 and Split-10 are the number of training models per class (out of 20 models in the class). In both cases our method achieves state-of-the-art results, yet it is most advantageous for a small training dataset (Split-10). (We have not found point cloud-based networks that were tested on SHREC11).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Input Split-16 Split-10</p><p>MeshWalker <ref type="formula">(</ref> Cube engraving. This dataset contains 4600 objects, with 3910/690 training/testing split. Each object is a cube "engraved" with a shape at a random face in a random location, as demonstrated in <ref type="figure">Fig. 4</ref>. The engraved shape belongs to a dataset of 23 classes (e.g., car, heart, apple, etc.), each contains roughly 20 shapes. This dataset was created in order to demonstrate that using meshes, rather than point clouds, may be critical for 3D shape analysis. <ref type="table" target="#tab_2">Table 2</ref> provides the results. It demonstrates the benefit of our method over state-of-the-art methods. ModelNet40. This commonly-used dataset contains 12, 311 CAD models from 40 categories, out of which 9, 843 models are used for training and 2, 468 models are used for testing. Unlike previous datasets, many of the objects contain multiple components and are not necessarily watertight, making this dataset prohibitive for some mesh-based methods. However, such models can be handled by MeshWalker since as explained before, if the walk gets into a dead-end during backtracking, it jumps to a new random location. <ref type="table">Table 3</ref> shows that our results outperform those of mesh-based state-of-the-art methods. We note that without 5 classes that are cross-labeled (desk/table &amp; plant/flower-pot/vase) our method's accuracy is 94.4%. The table shows that multi-views approaches are excellent for this dataset. This is due to relying on networks that are pre-trained on a large number of images. However, they might fail for other datasets, such as the engraved cubes, and do not suit other shape analysis tasks, such as semantic segmentation. <ref type="table">Table 3</ref>. Classification on ModelNet40 <ref type="bibr" target="#b106">[Wu et al. 2015]</ref>. MeshWalker is competitive with other mesh-based methods. Multi-view methods are advantageous for this dataset, possibly due to relying on pre-trained networks for image classification and to naturally handling multiple components and non-watertight models, which characterize many meshes in this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Input Accuracy  <ref type="bibr" target="#b21">[Feng et al. 2018b]</ref> multi-views 93.1% 3D2SeqViews <ref type="bibr" target="#b34">[Han et al. 2019]</ref> multi-views 93.4%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Mesh semantic segmentation</head><p>Shape segmentation is an important building block for many applications in shape analysis and synthesis. The goal is to determine, for every vertex, the segment it belongs to. We tested MeshWalker on two datasets: COSEG <ref type="bibr" target="#b103">[Wang et al. 2012</ref>  Our system avoids mis-classifications, not mixing lower legs with lower arms or hands with feet. We note that for most shapes in the dataset, both systems produce equally-good results.</p><p>Given mesh, multiple random walks are generated (in practice, 32 × # segment classes; see the discussion in Section 6). These walks are run through the trained network, which predicts the probabilities of belonging to the segments. Similarly to the training process, only vertices of the second half of each walk are considered trustworthy. For each vertex, the predictions of the walks it belongs to are averaged. Then, as post-processing, we consider the average prediction of the vertex neighbors and add this average with 0.5 weight. Finally, the prediction for each vertex is the argmax-ed.</p><p>Formally, let { } be the set of walks performed on a mesh. Let be the vector that is the Softmax output for vertex from walk (if walk does not visit , is set to a 0-vector). Let be the list of the vertices adjacent to and be the size of this list. The predicted label, of vertex is defined as (where finds the maximum vector entry):</p><formula xml:id="formula_5">= ( ∑︁ ∈ { } + 1 2 ∑︁ ∈ ∑︁ ∈ { }˜)</formula><p>.</p><p>(5)</p><p>We follow the accuracy measure proposed in <ref type="bibr" target="#b36">[Hanocka et al. 2019]</ref>: Given the prediction for each edge, the accuracy is defined as the percentage of the correctly-labeled edges, weighted by their length. Since MeshWalker predicts the segment of the vertices, if the predictions of the endpoints of the edge agree, the edge gets the endpoints' label; otherwise, the label with the higher prediction is chosen. The overall accuracy is the average over all meshes.</p><p>Human-body segmentation. The dataset consists of 370 training models from SCAPE <ref type="bibr" target="#b2">[Anguelov et al. 2005]</ref>, FAUST <ref type="bibr" target="#b8">[Bogo et al. 2014]</ref>, MIT <ref type="bibr" target="#b98">[Vlasic et al. 2008</ref>] and Adobe Fuse <ref type="bibr" target="#b0">[Adobe 2016</ref>]. The test set consists of 18 humans from SHREC'07 <ref type="bibr" target="#b25">[Giorgi et al. 2007</ref>] . The meshes are manually segmented into eight labeled segments according to <ref type="bibr" target="#b47">[Kalogerakis et al. 2010</ref>].</p><p>There are two common measures of segmentation results, according to the correct classification of faces <ref type="bibr" target="#b33">[Haim et al. 2019]</ref> or of edges <ref type="bibr" target="#b36">[Hanocka et al. 2019]</ref>. <ref type="table" target="#tab_4">Tables 4 and 5 compare our results to those of   Table 4</ref>. Human-body segmentation results on <ref type="bibr" target="#b66">[Maron et al. 2017</ref>]. The accuracy is calculated on edges of the simplified meshes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Edge Accuracy</p><p>MeshWalker 94.8% MeshCNN 92.3% previous works, according to the reported measure and the type of objects (simplified or not). Since our method is trained on simplified meshes, to get results on the original meshes, we apply a simple projection to the original meshes jointly with boundary smoothing, as in <ref type="bibr" target="#b50">[Katz and Tal 2003]</ref>. In both measures, MeshWalker outperforms other methods. <ref type="figure" target="#fig_4">Fig. 5</ref> presents qualitative examples where the difference between the resulting segmentations is evident. COSEG segmentation. This dataset contains three large classes: aliens, vases and chairs with 200, 300 and 400 shapes, respectively. Each category is split into 85%/15% train/test sets. <ref type="figure" target="#fig_5">Fig. 6</ref> presents some qualitative results, where it can be seen that our method performs very well. <ref type="table" target="#tab_5">Table 6</ref> shows the accuracy of our results, where the results of the competitors are reported in <ref type="bibr" target="#b36">[Hanocka et al. 2019</ref>]. Our method achieves state-of-the-art results for all categories. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS 6.1 Ablation study</head><p>Size of the training dataset. How many training models are needed in order to achieve good performance? In the 3D case this question is especially important, since creating a dataset is costly. <ref type="table">Table 7</ref> shows the accuracy of our model for the COSEG dataset, when trained on different dataset sizes. As expected, the larger the dataset, the better the results. However, even when using only 4 shapes for training, the results are pretty good (80.5%). This outstanding result can be explained by the fact that we can produce many random walks for each mesh, hence the actual number of training examples is large. This result is consistent across all categories and datasets. <ref type="table">Table 8</ref> shows a similar result for the human-body segmentation dataset.</p><p>Walk length. <ref type="figure">Fig. 1</ref> has shown that the accuracy of our method depends on the walk length. What would be an ideal length for our system to "understand" a shape? <ref type="figure">Fig. 7</ref> analyzes the influence of the length on the task of classification for SHREC11. As expected, the accuracy increases with length. However, it can be seen that when we use at least 16 walks per mesh, a walk whose length is 0.15 suffices to get excellent results. Furthermore, there is a trade-off between the number of walks we use and the length of these walks. Though the exact length depends both on the task in hand and on the dataset, this correlation is consistent across datasets and tasks. Number of walks. How many walks are needed at inference time? <ref type="table" target="#tab_7">Table 9</ref> shows that the more walks, the better the accuracy. However, even very few walks result in very good accuracy. In particular, on SHREC11, even with a single walk the accuracy is 90.8%. For the Engraved-Cubes dataset, more walks are needed, since the model is engraved on a single cube facet, which certain walks might not get to. Even in this difficult case, 4 walks already achieve 92.1% accuracy. We note that the STD is between 2.5% for a single walk to 0.4% for 32 walks. As expected, the more walks used, the more stable the results are and the smaller the STD is. <ref type="figure">Fig. 7</ref>. Walk length analysis. The accuracy increases with walk length, for classification on SHREC11. Here, the axis is number of vertices along the walk, normalized by number of mesh vertices. This figure illustrates trade-off between the number of walks we use and the length of these walks. As the walk begins, using many walks is not beneficial since the RNN has not accumulated enough information yet. However, after e.g. 0.3V, two walks are better than a single 0.6V-length walk. This is because they explore different mesh regions. by increments of 10 • . For each of these rotated versions of the datasets we applied the same testing as before. For both datasets, there was no difference in the results. Furthermore, the meshes are normalized, hence robustness to scaling. Our approach is inherently robust to different triangulations, as random walks (representing the same mesh) may vary greatly anyhow. Specifically, we generated a modified version of the COSEG segmentation dataset by randomly perturbing 30% of the vertex positions, realized as a shift towards a random vertex in its 1-ring. The performance degradation is less than 0.1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Implementation</head><p>Mesh pre-processing: simplification &amp; data augmentation. All the meshes used for training are first simplified into roughly the same number of faces <ref type="bibr" target="#b22">[Garland and Heckbert 1997;</ref><ref type="bibr" target="#b41">Hoppe 1997</ref>] (Mesh-Processing procedure in Algorithm 1). Simplification is analogous to the initial resizing of images. It reduces the network capacity required for training. Moreover, we could use several simplifications for each mesh as a form of data augmentation for training and for testing. For instance, for ModelNet40 we use 1 , 2 and 4 faces. The meshes are normalized into a unit sphere, if necessary.</p><p>In addition, we augment the training data and add diversity by rotating the models. As part of batch preparation, each model is randomly rotated in each axis prior to each training iteration.</p><p>t-SNE analysis. Does the network produce meaningful features? <ref type="figure">Fig. 8</ref> opens the network's "black box" and shows the t-SNE projection to 2D of the multi-dimensional features after each stage of our learning framework, applied to the human-body segmentation task. Each feature vector is colored by its correct label.</p><p>In the input layer all the classes are mixed together. The same behavior is noticed after the first two fully-connected layers, since no information is shared between the vertices up to this stage. In the next three GRU layers, semantic meaning evolves: The features are structured as we get deeper in the network. In the last RNN layer the features are meaningful, as the clusters are evident. This visualization demonstrates the importance of the RNN hierarchy. <ref type="figure">Fig. 9</ref> reveals another invaluable property of our walks. It shows the t-SNE visualization of walks for classification of objects from 5 categories of SHREC11. Each feature vector is colored by its correct label; its shape (rectangle, triangle etc) represents the object the walk belongs to. Not only clusters of shapes from the same category clearly emerge, but also walks that belong to the same object are grouped together! This is another indication to the quality of our proposed features.</p><p>Computation time. Training takes between 5 hours (for classification on SHREC11) to 12 hours (for segmentation on human-body), using GTX 1080 TI graphics card. At inference, a 100-step walk, which is typical for SHREC11, takes about 4 milliseconds. When we use 32 walks per shape, the running time would be 128 milliseconds. Remeshing takes e.g. 4.6 seconds from 400 faces to 1.5 or 0.85 from 100 face to 1.5 faces. We note that our method is easy to parallelize, as every walk could be processed on a different processor, which is yet another benefit of our approach.</p><p>Training configurations. We implemented our network using Ten-sorFlow V2. The network architecture is given in <ref type="table" target="#tab_0">Table 10</ref>. The source code is available on "https://github.com/AlonLahav/MeshWalker".  <ref type="figure">Fig. 8</ref>. t-SNE of the internal layers. This is a visualization of the output of the different layers for the human-body segmentation task. It can be seen how the semantic meaning of the layers' output starts to evolve after the first GRU layer and gets better in the next two layers. <ref type="figure">Fig. 9</ref>. t-SNE analysis for classification. This figure shows feature hierarchy: Meshes that belong to the same category (indicated by the color) are clustered together. Furthermore, walks that belong to the same mesh (indicated by the shape of the 2D point) are also clustered.</p><formula xml:id="formula_6">(a) input (b) FC1 (c) FC2 (d) GRU1 (e) GRU2 (f) GRU3</formula><p>Optimization: To update the network weights, we use Adam optimizer [Kingma and Ba 2014]. The learning rate is set in a cyclic way, as suggested by <ref type="bibr" target="#b87">[Smith 2017]</ref>. The initial and the maximum learning rates are set to 10 −6 and 5 · 10 −4 respectively. The cycle size is 20 iterations.</p><p>Batch strategy: Walks are grouped into batches of 32 walks each. For mesh classification, the walks are generated from different meshes, whereas for semantic segmentation each batch is composed of 4 walks on 8 meshes.</p><p>Training iterations: We train for 60k, 60k, 460k, 200k, 200k iterations for SHREC11, COSEG, human-body segmentation, engravedcubes and ModelNet40 datasets, respectively. This is so since for the loss to converge fast, many of the walks should cover the salient parts of the shape, which distinguish it from other classes/segments. When this is not the case, more iterations are needed in order for the few meaningful walks to influence the loss. This is the case for instance in the engraved cubes dataset, where the salient information lies on a single facet. <ref type="figure">Fig. 10</ref> shows a failure of our algorithm, where parts of the hair were wrongly classified as a torso. This is the case since the training data does not contain enough models with hair to learn from. In general, learning-based algorithms rely on good training data, which is not always available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Limitations</head><p>Another limitation is handling large meshes. The latter require long walks, which in turn might lead to run-time and memory (a) Ground truth (b) Ours (c) <ref type="bibr" target="#b36">[Hanocka et al. 2019</ref>] <ref type="figure">Fig. 10</ref>. Limitation. Our algorithm fails to classify the hair due to not having sufficient similar shapes in the dataset.</p><p>issues. In this paper, this is solved by simplifying the meshes and then projecting the segmentation results onto the original meshes.</p><p>(For classification, this is not a concern, as simplified meshes may be used).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>This paper has introduced a novel approach for representing meshes within deep learning schemes. The key idea is to represent the mesh by random walks on its surface, which intuitively explore the shape of the mesh. Since walks are described by the order of visiting mesh vertices, they suit deep learning. Utilizing this representation, the paper has proposed an end-toend learning framework, termed MeshWalker. The random walks are fed into a Recurrent Neural Network (RNN), that "remembers" the walk's history (i.e. the geometry of the mesh). Prior works indicated that RNNs are unsuitable for point clouds due to both the unordered nature of the data and the number of vertices used to represent a shape. Surprisingly, we have shown that RNNs work extremely well for meshes, through the concept of random walks.</p><p>Our approach is general, yet simple. It has several additional benefits. Most notably, it works well even for extremely small datasets. e.g. even 4 meshes per class suffice to get good results. In addition, the meshes are not require to be watertight or to consist of a single component (as demonstrated by ModelNet40 <ref type="bibr" target="#b106">[Wu et al. 2015]</ref>); some other mesh-based approaches impose these conditions and require the meshes to be manifolds.</p><p>Last but not least, the power of this approach has been demonstrated for two key tasks in shape analysis: mesh classification and mesh semantic segmentation. In both cases, we present state-of-theart results.</p><p>An interesting question for future work is whether there are optimal walks for meshes, rather than random walks. For instance, are there good starting points of walks? Additionally, reinforcement learning could be utilized to learn good walks. Exploring other applications, such as shape correspondence, is another intriguing future direction. Another interesting practical future work would be to work on the mesh as is, without simplification as pre-processing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Outline. To explore a mesh, walks on its surface are generated and study the surface both locally and globally (a). These walks provide sufficient information to perform shape analysis tasks, such as classification and segmentation. Specifically, (b) shows samples from the class to which MeshWalker correctly classified the model from (a) and (c) shows the resulting segmentation. The models are from SHREC11<ref type="bibr" target="#b57">[Lian et al. 2011</ref>].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Network architecture. The network consists of three components: The first component (FC layers) changes the feature space; the second component (RNN layers) aggregates the information along the walk; and the third component (an FC layer) predicts the outcome of the network. For classification, the prediction of the last vertex of the walk is considered and Softmax is applied to its resulting vector (the bottom-right orange circle, classified as a camel). For segmentation (not shown in this</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>SHREC11.</head><label></label><figDesc>This dataset consists of 30 classes, with 20 examples per class. Typical classes are camels, cats, glasses, centaurs, hands etc. Following the setup of [Ezuz et al. 2017], we split the objects in each class into 16 (/10) training examples and 4 (/10) testing examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>] and human-body Segmentation [Maron et al. 2017].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Qualitative results for human shape segmentation from [Maron et al. 2017].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Qualitative results of segmentation for meshes from COSEG<ref type="bibr" target="#b103">[Wang et al. 2012</ref>].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>ALGORITHM 1 :</head><label>1</label><figDesc>MeshWalker TrainingInput: Labeled mesh dataset, M Output: -RNN model parameters</figDesc><table><row><cell>0 ←</cell><cell>random parameters;</cell><cell></cell></row><row><cell cols="2">M ← MeshPreprocessing(M);</cell><cell></cell></row><row><cell>repeat</cell><cell></cell><cell></cell></row><row><cell cols="2">( , ) ← random mesh</cell><cell>∈ M and label(s) ;</cell></row><row><cell cols="3">← random starting vertex;</cell></row><row><cell>←</cell><cell cols="2">( , );</cell></row><row><cell>←</cell><cell>( ,</cell><cell>);</cell></row><row><cell>←</cell><cell cols="2">( −1 , , );</cell></row><row><cell cols="2">until Convergence;</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Classification on Cube Engraving<ref type="bibr" target="#b36">[Hanocka et al. 2019]</ref>. Our results outperform those of state-of-the-art algorithms.</figDesc><table><row><cell>Method</cell><cell>Input</cell><cell>accuracy</cell></row><row><cell>MeshWalker (ours)</cell><cell>Mesh</cell><cell>98.6%</cell></row><row><cell cols="2">MeshCNN [Hanocka et al. 2019] Mesh</cell><cell>92.16%</cell></row><row><cell>PointNet++ [Qi et al. 2017b]</cell><cell>Point cloud</cell><cell>64.26%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Human-body segmentation results on [Maron et al. 2017]. The reported results are on the original meshes; For MeshCNN, the results shown are ours. Our results outperform those of state-of-the-art algorithms.</figDesc><table><row><cell>Method</cell><cell>Input</cell><cell>Face</cell></row><row><cell></cell><cell></cell><cell>Accuracy</cell></row><row><cell>MeshWalker (ours)</cell><cell>Mesh</cell><cell>92.7%</cell></row><row><cell>MeshCNN [Hanocka et al. 2019]</cell><cell>Mesh</cell><cell>89.0%</cell></row><row><cell>LRF-Conv [Yang et al. 2020]</cell><cell>Mesh</cell><cell>89.9%</cell></row><row><cell>SNGC [Haim et al. 2019]</cell><cell>Mesh</cell><cell>91.3%</cell></row><row><cell>Toric Cover [Maron et al. 2017]</cell><cell>Mesh</cell><cell>88.0%</cell></row><row><cell>GCNN [Masci et al. 2015]</cell><cell>Mesh</cell><cell>86.4%</cell></row><row><cell>MDGCNN</cell><cell>Mesh</cell><cell>89.5%</cell></row><row><cell>[Poulenard and Ovsjanikov 2018]</cell><cell></cell><cell></cell></row><row><cell>PointNet++ [Qi et al. 2017b]</cell><cell>Point cloud</cell><cell>90.8%</cell></row><row><cell cols="2">DynGraphCNN [Wang et al. 2019d] Point cloud</cell><cell>89.7%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Segmentation results on COSEG<ref type="bibr" target="#b103">[Wang et al. 2012]</ref>. Our method achieves state-of-the-art results for all categories.</figDesc><table><row><cell>Method</cell><cell cols="3">Vases Chairs Telealiens Mean</cell></row><row><cell>MeshWalker (ours)</cell><cell>98.7% 99.6%</cell><cell>99.1%</cell><cell>99.1%</cell></row><row><cell>MeshCNN</cell><cell>97.3% 99.6%</cell><cell>97.6%</cell><cell>98.2%</cell></row><row><cell>PointNet++</cell><cell>94.7% 98.9%</cell><cell>79.1%</cell><cell>90.9%</cell></row><row><cell cols="2">PointCNN [Li et al. 2018] 96.4% 99.3%</cell><cell>97.4%</cell><cell>97.7%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .Table 8 .</head><label>78</label><figDesc>Analysis of the training dataset size (COSEG segmentation). "Full" training is 170, 255 and 240 shapes for tele-aliens, vases and chairs, respectively. As expected, the larger the dataset, the better the results. However, even if the training dataset is very small, our results are good. Analysis of the training dataset size (human-body segmentation). As before, the performance of our method degrades gracefully with the size of the training set. We note that the results of MeshCNN are not reported in their paper, but rather the results of new runs of their system.</figDesc><table><row><cell cols="4"># training shapes Vases Chairs Tele-aliens Mean</cell></row><row><cell>Full</cell><cell>98.7% 99.6%</cell><cell>99.1%</cell><cell>99.1%</cell></row><row><cell>32</cell><cell>95.3% 98.5%</cell><cell>94.2%</cell><cell>96.0%</cell></row><row><cell>16</cell><cell>93.6% 93.4%</cell><cell>92.4%</cell><cell>93.1%</cell></row><row><cell>8</cell><cell>83.7% 87.7%</cell><cell>86.7%</cell><cell>86.0%</cell></row><row><cell>4</cell><cell>77.5% 83.7%</cell><cell>80.4%</cell><cell>80.5%</cell></row><row><cell>2</cell><cell>67.3% 78.4%</cell><cell>69.7%</cell><cell>71.8%</cell></row><row><cell>1</cell><cell>60.9% 59.9%</cell><cell>40.6%</cell><cell>53.8%</cell></row><row><cell cols="2"># training shapes MeshWalker</cell><cell cols="2">MeshCNN</cell></row><row><cell></cell><cell>(ours)</cell><cell cols="2">[Hanocka et al. 2019]</cell></row><row><cell>381 (full)</cell><cell>94.8%</cell><cell>92.3%</cell><cell></cell></row><row><cell>16</cell><cell>92.0%</cell><cell>55.7%</cell><cell></cell></row><row><cell>4</cell><cell>84.3%</cell><cell>48.3%</cell><cell></cell></row><row><cell>2</cell><cell>80.8%</cell><cell>42.4%</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 .</head><label>9</label><figDesc>Number of walks analysis. The accuracy improves with the number of walks per shape (demonstrated on 2 datasets).</figDesc><table><row><cell cols="3"># Walks SHREC11 Acc Eng.Cubes Acc</cell></row><row><cell>32</cell><cell>98.3%</cell><cell>97.6%</cell></row><row><cell>16</cell><cell>97.8%</cell><cell>97.4%</cell></row><row><cell>8</cell><cell>97.8%</cell><cell>95.3%</cell></row><row><cell>4</cell><cell>95.5%</cell><cell>92.1%</cell></row><row><cell>2</cell><cell>95.0%</cell><cell>84.8%</cell></row><row><cell>1</cell><cell>90.8%</cell><cell>77.1%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 .</head><label>10</label><figDesc>Training configuration</figDesc><table><row><cell>Layer</cell><cell>Output Dimension</cell></row><row><cell>Vertex description</cell><cell>3</cell></row><row><cell>Fully Connected</cell><cell>128</cell></row><row><cell>Instance Normalization</cell><cell>128</cell></row><row><cell>ReLU</cell><cell>128</cell></row><row><cell>Fully Connected</cell><cell>256</cell></row><row><cell>Instance Normalization</cell><cell>256</cell></row><row><cell>ReLU</cell><cell>256</cell></row><row><cell>GRU</cell><cell>1024</cell></row><row><cell>GRU</cell><cell>1024</cell></row><row><cell>GRU</cell><cell>512</cell></row><row><cell>Fully Connected</cell><cell># of classes</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Trans. Graph., Vol. 39, No. 6, Article 263. Publication date: December 2020.MeshWalker: Deep Mesh Understanding by Random Walks • 263:5</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ACM Trans. Graph., Vol. 39, No. 6, Article 263. Publication date: December 2020. MeshWalker: Deep Mesh Understanding by Random Walks • 263:7</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Robustness. We use various rotations within data augmentation, hence robustness to orientations. In particular, to test the robustness to rotation, we rotated the models in the Human-body segmentation dataset and in SHREC11 classification dataset 36 times for each axis, ACM Trans. Graph., Vol. 39, No. 6, Article 263. Publication date: December 2020.MeshWalker: Deep Mesh Understanding by Random Walks • 263:9</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We gratefully acknowledge the support of the Israel Science Foundation (ISF) 1083/18 amd PMRI -Peter Munk Research Institute -Technion.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Adobe Fuse 3D Characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adobe</forename></persName>
		</author>
		<ptr target="https://www.mixamo.com" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spectral partitioning: the more eigenvectors, the better</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">So-Zen</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd annual ACM/IEEE Design Automation Conference</title>
		<meeting>the 32nd annual ACM/IEEE Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SCAPE: shape completion and animation of people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2005 Papers</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="408" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hierarchical mesh segmentation based on fitting primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Attene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Falcidieno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michela</forename><surname>Spagnuolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="193" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mesh Segmentation -A Comparative Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Attene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mortara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spagnuolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Shape Modeling and Applications</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="7" to="7" />
		</imprint>
	</monogr>
	<note>SMI&apos;06</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.10091</idno>
		<title level="m">Point convolutional neural networks by extension operators</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gift: A real-time and scalable 3d shape search engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5023" to="5032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Threedimensional point cloud classification in real-time using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="3145" to="3152" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">FAUST: Dataset and evaluation for 3D mesh registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3794" to="3801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning shape correspondence with anisotropic convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rodolà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3189" to="3197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unstructured Point Cloud Semantic Labeling Using Deep Segmentation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Audebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">3DOR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.04236</idno>
		<title level="m">Generative and discriminative voxel modeling with convolutional neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shape google: Geometric words and expressions for invariant shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexander M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient computation of isometry-invariant distances between surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alexander M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kimmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1812" to="1836" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Strategies for polyhedral surface decomposition: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Chazelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>David P Dobkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayellet</forename><surname>Shouraboura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="327" to="342" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">On bending invariant signatures for surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asi</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Kimmel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1285" to="1295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">GWCNN: A metric alignment layer for deep shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Ezuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirela</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ben-Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Real time head pose estimation from consumer depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Fanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibaut</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint pattern recognition symposium</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MeshNet: mesh neural network for 3D shape representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8279" to="8286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GVCNN: Group-view convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="264" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Surface simplification using quadric error metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heckbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 24th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shape segmentation using local slippage analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasha</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Eurographics/ACM SIGGRAPH symposium on Geometry processing</title>
		<meeting>the 2004 Eurographics/ACM SIGGRAPH symposium on Geometry processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Review on Deep Learning Approaches for 3D Data Representations in Retrieval and Classifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Abubakar Sulaiman Gezawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qicong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yunqi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="57566" to="57593" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Shape retrieval contest 2007: Watertight models track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Biasotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Paraboschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SHREC competition</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lonchanet: A sliced-based cnn architecture for real-time 3d object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Gomez-Donoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Orts-Escolano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cazorla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Spiral-net++: A fast and highly efficient mesh convolution operator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunwang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On graph partitioning, spectral analysis, and digital mesh processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Gotsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Shape Modeling International. IEEE</title>
		<imprint>
			<biblScope unit="page" from="165" to="171" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Random walks for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Grady</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1768" to="1783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A novel connectionist system for unconstrained handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Bertolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="855" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PCPNet learning local shape properties from raw point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanir</forename><surname>Kleiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="75" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">3d mesh labeling via deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongqing</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Surface Networks via General Covers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nimrod</forename><surname>Segol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heli</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="632" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Aggregating sequential views for 3d global feature learning by cnn with hierarchical attention aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Man</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl Philip</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3986" to="3999" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Alignet: Partial-shape agnostic alignment via unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rana</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noa</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rana</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noa</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Triplet-center loss for multi-view 3d object retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Topology matching for fully automatic similarity estimation of 3D shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Hilaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshihisa</forename><surname>Shinagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kohmura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tosiyasu L</forename><surname>Kunii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 28th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">View-dependent refinement of progressive meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 24th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="189" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pointwise convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binh-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Khoi</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="984" to="993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A spectral approach to shape-based retrieval of articulated 3D models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="398" to="407" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pairwise decomposition of image sequences for active multi-view recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3813" to="3822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Using spin images for efficient object recognition in cluttered 3D scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="433" to="449" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">3D shape segmentation with projective convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melinos</forename><surname>Averkiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3779" to="3788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning 3D mesh segmentation and labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2010 papers</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Rotationnet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asako</forename><surname>Kanezaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuyuki</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshifumi</forename><surname>Nishida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5010" to="5019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Mesh segmentation using feature point and core extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagi</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Leifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayellet</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hierarchical mesh decomposition using fuzzy clustering and cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagi</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayellet</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="954" to="961" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Perception-based 3D triangle mesh segmentation using fast marching watersheds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Af Koschan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>II</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fast Mesh Segmentation Using Random Walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Kun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">L</forename><surname>Rosin</surname></persName>
		</author>
		<idno type="DOI">10.1145/1364901.1364927</idno>
		<ptr target="https://doi.org/10.1145/1364901.1364927" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM Symposium on Solid and Physical Modeling (SPM &apos;08)</title>
		<meeting>the 2008 ACM Symposium on Solid and Physical Modeling (SPM &apos;08)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="183" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A new CAD mesh segmentation method, based on curvature tensor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lavoué</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atilla</forename><surname>Baskurt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="820" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Shape retrieval on non-rigid 3D watertight meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Godil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bustos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kawamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kurita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P Dp</forename><surname>Lavoua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics workshop on 3d object retrieval (3DOR)</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A comparison of methods for non-rigid 3D shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhui</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afzal</forename><surname>Godil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Bustos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Daoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeroen</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Kawamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukinori</forename><surname>Kurita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lavoué</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hien</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryutarou</forename><surname>Ohbuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="449" to="461" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A simple approach to intrinsic correspondence learning on unstructured 3d meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaak</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Dielen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Campen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leif</forename><surname>Kobbelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Segmentation of 3D meshes through spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th Pacific Conference on Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="298" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8895" to="8904" />
		</imprint>
	</monogr>
	<note>Shiming Xiang, and Chunhong Pan</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Shape topics: A compact representation and new algorithms for 3d partial shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2025" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Random walks on graphs: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">László</forename><surname>Lovász</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Paul erdos is eighty</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="46" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
	<note>Combinatorics</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Distinctive image features from scale-invariant keypoints. International journal of computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Three-dimensional point cloud recognition via distributions of geometric distances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Mahmoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical Models</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="22" to="31" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on surfaces via seamless toric covers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meirav</forename><surname>Haggai Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miri</forename><surname>Aigerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Trope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Dym</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="71" to="72" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Geodesic convolutional neural networks on riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision workshops</title>
		<meeting>the IEEE international conference on computer vision workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="922" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">On the use of Gromov-Hausdorff distances for shape comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facundo</forename><surname>Mémoli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A theoretical and computational framework for isometry invariant recognition of point cloud data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facundo</forename><surname>Mémoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational Mathematics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="313" to="347" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Random walks on complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><surname>Dong Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Rieger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">118701</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Shape google: a computer vision approach to isometry invariant shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="320" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Multi-directional geodesic neural networks via equivariant convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Poulenard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5648" to="5656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Laplace-spectra as fingerprints for shape matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz-Erich</forename><surname>Wolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Peinecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 ACM symposium on Solid and physical modeling</title>
		<meeting>the 2005 ACM symposium on Solid and physical modeling</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Part-based mesh segmentation: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel Jp</forename><surname>Morgado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gomes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="235" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Roynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Goulette</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03583</idno>
		<title level="m">Classification of point cloud scenes with multiscale voxel deep network</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Learning 3d shapes as multi-layered height-maps using 2d convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kripasindhu</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basavaraj</forename><surname>Hampiholi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiran</forename><surname>Varanasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didier</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="71" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Sedaghat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Zolfaghari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Amiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.03351</idno>
		<title level="m">Orientation-boosted voxel nets for 3d object recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Orientationboosted Voxel Nets for 3D Object Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Sedaghat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Zolfaghari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.03351</idno>
		<ptr target="http://arxiv.org/abs/1604.03351" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A survey on mesh segmentation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1539" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Metamorphosis of polyhedral surfaces using decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shymon</forename><surname>Shlafman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayellet</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagi</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Deep learning 3D shape surfaces using geometry images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayan</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Ramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="223" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Cyclical learning rates for training neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="464" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Multiview convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="945" to="953" />
		</imprint>
	</monogr>
	<note>Evangelos Kalogerakis, and Erik Learned-Miller</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">A concise and provably informative multi-scale signature based on heat diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1383" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Triangle mesh-based edge detection and its application to surface segmentation and adaptive surface smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiyong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Lon</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joon</forename><forename type="middle">Ki</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Koschan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mongi A</forename><surname>Abidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. International Conference on Image Processing</title>
		<meeting>International Conference on Image Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="825" to="828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Skeleton based shape matching and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hari</forename><surname>Sundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Gagvani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Shape Modeling International. IEEE</title>
		<imprint>
			<biblScope unit="page" from="130" to="139" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Deformable model retrieval based on topological and geometric signatures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="470" to="482" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Segcloud: Semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyne</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 international conference on 3D vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="537" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6411" to="6420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Instance normalization: The missing ingredient for fast stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Feastnet: Feature-steered graph convolutions for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitika</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmond</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2598" to="2606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Articulated mesh animation from multi-view silhouettes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Vlasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Baran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jovan</forename><surname>Popović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2008 papers</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Article 263. Publication date</title>
	</analytic>
	<monogr>
		<title level="m">MeshWalker: Deep Mesh Understanding by Random Walks</title>
		<imprint>
			<date type="published" when="2020-12" />
			<biblScope unit="volume">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">NormalNet: A voxel-based CNN for 3D object classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdous</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="139" to="147" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Dominant set clustering and pooling for multi-view 3d object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleem</forename><surname>Siddiqi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01592</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Graph attention convolution for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaolin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenman</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10296" to="10305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Active co-analysis of a set of shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shmulik</forename><surname>Asafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Van Kaick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Deep geometric prior for surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teseo</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Zorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Panozzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10130" to="10139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="1912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.10644</idno>
		<title level="m">Geometry Sharing Network for 3D Point Cloud Classification and Segmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Spidercnn: Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangsihao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Birdal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02506</idno>
		<title level="m">Srinath Sridhar, and Leonidas Guibas. 2020. Continuous Geodesic Convolutions for Learning on 3D Shapes</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">SPNet: Deep 3D Object Classification and Retrieval using Stereographic Projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Yavartanoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Euyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01571</idno>
		<ptr target="http://arxiv.org/abs/1811.01571" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Deep learning for 3d shape classification from multiple depth maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Zanuttigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovico</forename><surname>Minto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3615" to="3619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Mesh segmentation via recursive and visually salient spectral cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of vision, modeling, and visualization</title>
		<meeting>of vision, modeling, and visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="429" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Toward real-time 3D object recognition: A lightweight volumetric CNN framework using multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaifeng</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="199" to="207" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Decomposing polygon meshes by means of critical points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Multimedia Modelling Conference</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="187" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Random Walk Network for 3D Point Cloud Classification and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xubin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisheng</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1921" to="1926" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
