<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CDFI: Compression-Driven Network Design for Frame Interpolation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Ding</surname></persName>
							<email>tding1@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luming</forename><surname>Liang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Zhu</surname></persName>
							<email>zhihui.zhu@du.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Denver</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Zharkov</surname></persName>
							<email>zharkov@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CDFI: Compression-Driven Network Design for Frame Interpolation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>DNN-based frame interpolation-that generates the intermediate frames given two consecutive frames-typically relies on heavy model architectures with a huge number of features, preventing them from being deployed on systems with limited resources, e.g., mobile devices. We propose a compression-driven network design for frame interpolation (CDFI), that leverages model pruning through sparsityinducing optimization to significantly reduce the model size while achieving superior performance. Concretely, we first compress the recently proposed AdaCoF model and show that a 10× compressed AdaCoF performs similarly as its original counterpart; then we further improve this compressed model by introducing a multi-resolution warping module, which boosts visual consistencies with multi-level details. As a consequence, we achieve a significant performance gain with only a quarter in size compared with the original AdaCoF. Moreover, our model performs favorably against other state-of-the-arts in a broad range of datasets. Finally, the proposed compression-driven framework is generic and can be easily transferred to other DNNbased frame interpolation algorithm. Our source code is available at https://github.com/tding1/CDFI. * Equal contribution. This work was done when Tianyu Ding was an intern at Applied Sciences Group, Microsoft. † Corresponding author.</p><p>Recently, a large number of researches have been conducted in this area, especially those based on deep neural networks (DNN) for their promising results in motion estimation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b57">58]</ref>, occlusion reasoning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b45">46]</ref> and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Video frame interpolation is a lower level computer vision task referring to the generation of intermediate (nonexistent) frames between actual frames in a sequence, which is able to largely increase the temporal resolution. It plays an important role in many applications, including frame rate up-conversion <ref type="bibr" target="#b3">[4]</ref>, slow-motion generation <ref type="bibr" target="#b26">[27]</ref>, and novel view synthesis <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b65">66]</ref>. Though fundamental, the problem is challenging in that the complex motion, occlusion and feature variation in real world videos are difficult to estimate and predict in a transparent way. <ref type="figure">Figure 1</ref>. A challenging example consists of large motion, severe occlusion and non-stationary finer details. From top to bottom: the overlaid two inputs, the ground-truth middle frame, the frame generated by AdaCoF <ref type="bibr" target="#b31">[32]</ref>, the frame generated by the 10× compressed AdaCoF, and the frame generated by our method. The compressed AdaCoF even outperforms the full one in this case. rapid expansion in optical flow <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b59">60]</ref>, many approaches either utilize an off-the-shelf flow model <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b60">61]</ref> or estimate their own task-specific flow <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b44">45]</ref> as a guidance of pixel-level motion interpolation. However, integrating a pre-trained flow model makes the whole architecture cumbersome, while with only pixel-level information the task-oriented flow alone is still insufficient in handling complex occlusion and blur. As opposed to this, kernel-based methods <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46]</ref> synthesize the intermediate frames by convolution operations over local patches surrounding each output pixel. Nevertheless, it cannot deal with large motions beyond the kernel size and it typically suffers from high computational cost. There are also hybrid methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> that combine the advantages of flow-based and kernel-based methods, but the networks are much heavier and thus limit their applications.</p><p>We observe a growing tendency that more and more complicated and heavy DNN-based models are designed for interpolating video frames. Most of the methods proposed in the past few years <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b60">61]</ref> involve training and inference on DNN models consisting of over 20 million parameters. For example, the hybrid MEMC-Net <ref type="bibr" target="#b2">[3]</ref> consists of more than 70 million parameters and requires around 280 megabytes if stored in 32bit floating point. Normally, large models are difficult to train and inefficient during inference. Moreover, they are not likely to be deployed on mobile devices, which restricts their scenarios to a great extent. In the mean time, other work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref> directly focus on simple and lightweight video interpolation algorithms. However, they either perform less competitively on benchmark datasets or are bound to specific design that lack of transferability.</p><p>In this paper, we propose a compression-driven network design for video interpolation (CDFI) that takes advantage of model compression <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b66">67]</ref>. To the best of our knowledge, we are the first to explore the over-parameterization issue appearing in the state-of-the-art DNN models for video interpolation. Concretely, we compress the recently proposed AdaCoF <ref type="bibr" target="#b31">[32]</ref> via fine-grained pruning <ref type="bibr" target="#b66">[67]</ref> based on sparsity-inducing optimization <ref type="bibr" target="#b6">[7]</ref>, and show that a 10× compressed AdaCoF is still able to maintain a similar benchmark performance as before, indicating a considerable amount of redundancy in the original model. The compression provides us two direct benefits: (i) it helps us understand the model architecture in depth, which in turn inspires an efficient design; (ii) the obtained compact model makes more room for further improvements that could potentially boost the performance to a new level. Towards justifying the latter point, observing that AdaCoF is capable of handling large motion while is short of dealing with occlusion or preserving finer details, we improve upon the compact model by introducing a multi-resolution warping module that utilizes a feature pyramid representation of the input frames to help with the image synthesis. As a result, our final model outperforms AdaCoF on three benchmark datasets with a large margin (more than 1 dB of PSNR on the Middlebury [1] dataset) while is only a quarter of its initial size. Note that typically it is difficult to implement the same improvements on the original heavy model. Experiments show that our model also performs favorably against other state-of-the-art methods.</p><p>In short, we present a compression-driven framework for video interpolation, in which we take a step back with reflections on over-parameterization. We first compress AdaCoF and obtain a compact model but performs similarly well, then we improve on top of it. The pipeline of CDFI is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. This retrospective approach leads to superior performance and can be easily transferred to any other DNN-based frame interpolation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Video frame interpolation</head><p>Conventional video frame interpolation is modeled as an image sequence problem, e.g., the path-based <ref type="bibr" target="#b37">[38]</ref> and phase-based approach <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>. Unfortunately, these methods are less effective in complex scenes due to their incapability of accurately estimating the path (flow) or representing high-frequency components.</p><p>Convolutional neural network (CNN) has recently demonstrated its success in understanding temporal motion <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b59">60]</ref> through predicting optical flow, leading to flow-based motion interpolation algorithms. <ref type="bibr" target="#b36">[37]</ref> trains a deep CNN to directly synthesize the intermediate frame. <ref type="bibr" target="#b35">[36]</ref> estimates the flow by sampling from the 3D spatio-temporal neighborhood of each output pixel. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref> utilize bi-directional flows to warp frames and resort to additional modules to handle occlusion. <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref> integrate an off-the-shelf flow model <ref type="bibr" target="#b54">[55]</ref> into the network. Also, quadratic <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b60">61]</ref> and cubic <ref type="bibr" target="#b13">[14]</ref> non-liner models are proposed to approximate complex motions.</p><p>One major drawback of the flow-based methods is that only pixel-wise information is used for interpolation. In contrast, kernel-based methods propose to generate the image by convolving over local patches near each output pixel. For example, <ref type="bibr" target="#b43">[44]</ref> estimates spatially-adaptive 2D convolution kernels and <ref type="bibr" target="#b42">[43]</ref> improves its efficiency by using pairs of 1D kernels for all output pixels simultaneously. <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> integrate both optical flow and local kernels; specifically <ref type="bibr" target="#b1">[2]</ref> detects the occlusion with depth information. However, those methods only rely on local kernels and cannot deal with large motion beyond the rectangular kernel region.</p><p>Inspired by the flexible spatial sampling locations of deformable convolution (DConv) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b67">68]</ref>, <ref type="bibr" target="#b31">[32]</ref> proposes the AdaCoF model that utilizes a spatially-adaptive separable DConv to synthesize each output pixel. <ref type="bibr" target="#b50">[51]</ref> generalizes it by allowing sampling in the full spatial-temporal space. <ref type="bibr" target="#b11">[12]</ref> is similar to AdaCoF except that it estimates 1D separable kernels to approximate 2D kernels. <ref type="bibr" target="#b10">[11]</ref> extends <ref type="bibr" target="#b11">[12]</ref> to produce the intermediate frame at arbitrary time step. This paper is also based on AdaCoF; however, unlike the previous work, for the first time we explore the over-parameterization issue presenting in the existing DNN-based approaches, and show that a much smaller model performs similarly well through compression. Moreover, by addressing its drawbacks upon the compression, one can easily build a model (still small) so that it outperforms the original one to a large extent. This compressiondriven network design is generic and can be transferred to any other DNN-based frame interpolation algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Pruning-based model compression</head><p>Model compression <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13]</ref> is particularly important to DNN models, which are known to suffer high cost of storage and computation. In general, model compression can be categorized into several types: pruning <ref type="bibr" target="#b66">[67]</ref>, quantization <ref type="bibr" target="#b47">[48]</ref>, knowledge distillation <ref type="bibr" target="#b24">[25]</ref> and AutoML <ref type="bibr" target="#b23">[24]</ref>. We adopt the pruning technique for its simplicity, which seeks to induce sparse connections. There are many hybrid pruning methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b55">56]</ref> that are suitable for model deployment, but they may be overkill for our purpose of searching and designing the architecture after the compression. That being said, compression plays a completely different role in our work, namely it works as a tool for a better understanding of the underlying architecture and makes room for further improvements. For this reason, we turn our attention to optimization-based sparsity-inducing pruning techniques <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b64">65]</ref> which involve training with sparsity constraints, e.g. 0 or 1 regularizers. Specifically, we use a simple three-step pipeline (see Stage (I) in <ref type="figure" target="#fig_0">Figure 2</ref>) which is most similar to <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref> that involves: (i) training with 1 -norm sparsity constraint; (ii) reformulating a small dense network according to the sparse structures identified <ref type="bibr">Ground-truth</ref> AdaCoF <ref type="bibr" target="#b31">[32]</ref> Ours <ref type="figure">Figure 3</ref>. Visualization of the difference between the interpolation and the ground-truth image.</p><p>in each layer; and (iii) retraining the small network to verify its performance. We will see shortly (Sec. 3.2) that its implementation and test is straightforward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed approach</head><p>Given two consecutive frames I 0 and I 1 in a video sequence, the goal of video frame interpolation is to synthesize an intermediate frame I t , where t ∈ (0, 1) is an arbitrary temporal position. A common practice is t = 0.5, that is synthesizing the middle frame between I 0 and I 1 . We now introduce the proposed CDFI framework with the recently proposed AdaCoF <ref type="bibr" target="#b31">[32]</ref> as an instance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Motivation</head><p>To describe AdaCoF, we begin with the introduction of one of its key components, a spatially-adaptive separable DConv operation for synthesizing one image (denoted by I out ) from another one (denoted by I in ). Towards synthesizing I out from I in , the input image I in is padded such that I out preserves the original shape of I in . For each pixel (i, j) in I out , AdaCoF computes I out (i, j) by convolving a deformable patch surrounding the reference pixel (i, j) in I in :</p><formula xml:id="formula_0">F −1 k=0 F −1 l=0 W (k,l) i,j I in i + dk + α (k,l) i,j , j + dl + β (k,l) i,j , (1) where F is the deformable kernel size, W (k,l) i,j is the (k, l)-th kernel weight in synthesizing I out (i, j), ∆ := α (k,l) i,j , β (k,l) i,j</formula><p>is the offset vector of the (k, l)-th sampling point associated with I in (i, j), and d ∈ {0, 1, 2, · · · } is the dilation parameter that helps to explore a wider area. Note that the values of F and d are pre-determined. For synthesizing each output pixel in I out , a total number of F 2 points are sampled in I in . With the offset vector ∆, the F 2 sampling points are not necessarily restricted inside a rigid rectangular region centered at the reference point. On the other hand, unlike the classic DConv, AdaCoF uses different ker-feature pyramid</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthesis</head><p>Net <ref type="figure">Figure 4</ref>. Illustration of our architecture design based on the compressed AdaCoF <ref type="bibr" target="#b31">[32]</ref>. The lower part (AdaCoF) consists of a U-Net, a group of sub-networks for estimating two sets of {Wi, αi, βi} in AdaCoF operation (1) correspond to backward/forward warping, and an occlusion mask V1 for synthesizing one candidate intermediate frame I nel weights across different reference pixels (i, j), indicated by W (k,l) i,j in (1); hence the attribute "separable" <ref type="bibr" target="#b43">[44]</ref>. Although AdaCoF is flexible in handling large and complex motion since the parameters {W</p><formula xml:id="formula_1">! " ! # 1x1 Conv AdaCoF AdaCoF $ # % # &amp; # $ ' % ' &amp; ' ( # ( ' AdaCoF AdaCoF Conv + Relu AvgPool Sigmoid Upsample Softmax</formula><formula xml:id="formula_2">(k,l) i,j , α (k,l) i,j , β (k,l)</formula><p>i,j } are computed specifically for each pair of input frames, it is unable to deal with severe occlusion and non-stationary finer details, as shown in <ref type="figure">Figure 1</ref>. We further visualize the difference between the interpolation and the ground-truth in <ref type="figure">Figure 3</ref>. AdaCoF is insufficient in preserving the contextual information because the interpolation is simply obtained by blending the two warped frames through a sigmoid mask (V 1 ), as demonstrated in <ref type="figure">Figure 4</ref>. A natural question to ask is that if we can make direct improvements on top of it. However, we find the architecture design of the AdaCoF model is relatively cumbersome, especially the encoder-decoder part. For example, six 512 × 512 × 3 × 3 convolutional layers are employed in the middle, which is an entire heuristic since it is unclear whether this design is sufficient or not for the interpolation task. The original AdaCoF model has 21.8 millions of parameters when F = 5, d = 1 and requires 83.4 megabytes if stored with PyTorch. Typically, such a large model takes a long time for training and validation, and thus prohibits direct improvements upon it. Towards better understanding the architecture and improving its performance, we propose a compression-driven approach described as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">First stage: compression of the baseline</head><p>As the first stage in our approach, we compress the baseline model, i.e., AdaCoF here, by leveraging the fine-grained model pruning <ref type="bibr" target="#b66">[67]</ref> through sparsity-inducing optimization <ref type="bibr" target="#b5">[6]</ref>. Specifically, given a pre-trained full model M 0 , we start by re-training (fine-tuning) its weights θ by imposing an 1 norm sparsity regularizer, and solve the following optimization problem:</p><formula xml:id="formula_3">min θ f (θ|M 0 ) + λ θ 1 ,<label>(2)</label></formula><p>where f (·) denotes the training objective for our task (see Sec. 3.4 for details) and λ &gt; 0 is the regularization constant. It is known that with appropriately chosen λ the formulation (2) promotes a sparse solution, with which one can easily identify those important connections among neurons, namely the ones corresponding to non-zero weights. Towards solving (2), we utilize the newly proposed orthant-based stochastic method <ref type="bibr" target="#b6">[7]</ref> for its efficient mechanism in promoting sparsity and less performance regression compared with other solvers. By solving the 1regularized problem <ref type="formula" target="#formula_3">(2)</ref>, we indeed perform a fine-grained pruning since zeros are promoted in an unstructured manner. Note that one can also impose group sparsity constraints <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b64">65]</ref>, e.g., mixed 1 / 2 , to prune the kernel weights in a group-wise fashion. We only adopt the 1 constraint in the presentation for its simplicity. After obtaining a sparse solutionθ, different than [23] that directly operates on the sparse network, we re-design a small dense network M 1 based on the sparsity computed in each layer. Given the l-th convolutional layer consisting of K l = C in l × C out l × q × q parameters (denoted asθ l ), where C in l is the number of input channels, C out l is the number of output channels, q × q is the kernel size, then the sparsity s l Inspired by <ref type="bibr" target="#b7">[8]</ref>, we use d l as the compression ratio and compute C in l := d l · C in l as the number of kernels we actually need in that layer. The main intuition is that the density ratio d l reflects the minimal amount of necessary information that needs to be encoded in that layer without affecting performance largely. Since C in l ≡ C out l−1 , we also update C out l−1 = C in l , then repeat the above process for computing the number of kernels in the (l − 1)-th layer by C in l−1 := d l−1 · C in l−1 , and so on. In words, we reformulate a small network by updating the number of kernels in each convolutional layer according to its density ratio, and proceed from back to the front. Since AdaCoF is fully convolutional (see <ref type="figure">Figure 4)</ref>, the above procedure can be easily implemented by reducing the number of input/output channels for each layer, leading to a much more compact architecture. In fact, the strategy does not bind to convolutional layers. One can also operate on a fully connected layer by re-computing its number of input/output features accordingly, making it extensible to other architectures.</p><p>Finally, we train the compressed model M 1 from scratch (without the 1 constraint) to verify its performance. Typically, it takes a significantly shorter time than that of the full model M 0 due to its compactness. The entire compression pipeline is illustrated as the Stage (I) of <ref type="figure" target="#fig_0">Figure 2</ref>. We remark that a pre-trained M 0 is not necessarily required for the sake of compression since problem <ref type="formula" target="#formula_3">(2)</ref> is suitable for a one-shot training/pruning, but M 0 allows us to make sure the compressed model works competitively as before.</p><p>Compression of AdaCoF. We now apply the compression strategy to the AdaCoF model <ref type="bibr" target="#b31">[32]</ref>. We use the pretrained model provided by the authors. Starting with the 1regularized problem (2), where λ is set as 10 −4 , we run the orthant-based stochastic solver <ref type="bibr" target="#b6">[7]</ref> for 20 epochs by feeding the model with only 1000 video triplets from Vimeo-90K <ref type="bibr" target="#b61">[62]</ref>. For each epoch, we record the network density and the PSNR evaluated on the Middlebury dataset <ref type="bibr" target="#b0">[1]</ref>, as plotted in <ref type="figure" target="#fig_1">Figure 5</ref>. One can see that the model performance declines as more sparsity is promoted. After 20 epochs of training, the density of the network is down to 26%. In- terestingly, by examining the density ratio of each layer, we find that the six 512×512×3×3 convolutional layers in the middle of the U-Net are among the most redundant portions.</p><p>In particular, the 512 × 512 × 3 × 3 convolutional layer following the upsampling layer achieves a density ratio of only 7%, which means 93% of the kernel is of little use. This observation confirms our previous conjecture that the original architecture design has a considerable amount of redundancy. Then we reformulate a compact network guided by the computed density ratio in each layer, as described before, and train it from scratch by using the entire taining set (51312 video triplets) of Vimeo-90K. In this case, the training of the compressed AdaCoF is about 5× faster than previously. When it finishes, we compare the before-andafter models in <ref type="table" target="#tab_0">Table 1</ref>, where PSNR and SSIM <ref type="bibr" target="#b56">[57]</ref> are evaluated on the Middlebury dataset, and time and FLOPS are calculated in synthesizing a 3 × 1280 × 720 frame on RTX 6000 Ti GPU. Note that although the PSNR drops below 34.2 during the 1 optimization, after formulating and training the compressed model rises again to <ref type="bibr">35.46</ref>, which is on par with the original uncompressed AdaCoF. We conclude that a 10× compressed AdaCoF still maintains a similar performance as its original counterpart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Second stage: improve upon the compression</head><p>In the second stage, we improve upon the compression against its deficiencies. The point is that the compression makes room for further improvements due to its compactness, which is typically difficult if directly operating on the original large model, e.g., the long training and validation time appears daunting in the first place.</p><p>Observing that AdaCoF is short of handling severe occlusion and preserving finer details, we design three specific components, i.e., a feature pyramid, an image synthesis network and a path selection mechanism, on top of the compressed AdaCoF. Note that the improvements are case by case since different baselines have their own weakness.</p><p>Feature pyramid. In AdaCoF, the final interpolation frame is computed by blending the two warped frames through a single sigmoid mask V 1 (see <ref type="figure">Figure 4</ref>), which is a generalization of using a binary mask to determine the occlusion weights of the two warped frames for each output pixel. We argue that with only raw pixel information the loss of contextual details in the input frames is inevitable Vimeo-90K <ref type="bibr" target="#b61">[62]</ref> Middlebury <ref type="bibr" target="#b0">[1]</ref> UCF101-DVF <ref type="bibr">[</ref>  <ref type="table">Table 2</ref>. Ablation experiments on the architecture design of our approach. <ref type="figure">Figure 6</ref>. Examples of adding the path selection (PS) mechanism in our design.</p><p>since it lacks guidance from the feature space. Instead, we extract a feature pyramid representation <ref type="bibr" target="#b41">[42]</ref> of the input frames from the encoder part of the U-Net. Specifically, it has five feature levels in accordance with the encoder, and for each level we utilize a 1-by-1 convolution to filter the encoder at multi-scale with 4, 8, 12, 16, 20 output features (in descending order by the feature scale). The extracted multiscale features are then warped by AdaCoF operation <ref type="formula">(1)</ref>, which captures the motion in the feature space. Image synthesis network. To better make use of the extracted multi-scale features, we resort to a GridNet <ref type="bibr" target="#b20">[21]</ref> architecture with three rows and six columns in synthesizing the image, which is also employed in <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref> for its superiority in combining multi-scale information. Particularly, we feed the synthesis network with both the forwardand backward-warped multi-scale feature maps, generating a single RGB image that focuses on the contextual details.</p><p>Path selection. In order to take advantage of both Ada-CoF (handling complex motion) and our own components (handling contextual details), we apply a path selection mechanism in generating the final interpolation result. As shown in <ref type="figure">Figure 4</ref>, one path leads to the output of the original AdaCoF (denoted as I (1) 0.5 ), which is computed by blending two warped input frames using the occlusion mask V 1 . Parallel to this, another path leads to the output of the synthesis network (denoted as I (2) 0.5 ), which is computed by combining the warped multi-scale feature maps. In the end, we learn another occlusion module V 2 to synthesize the final result from I <ref type="bibr" target="#b0">(1)</ref> 0.5 and I <ref type="bibr" target="#b1">(2)</ref> 0.5 , and we expect that I <ref type="bibr" target="#b1">(2)</ref> 0.5 can compensate for the lack of contextual information in I (1) 0.5 . The above three specific components can not only be easily incorporated into the compressed AdaCoF, but also boost the performance to a large extent while still maintain the compactness (see Sec. 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training</head><p>With the architecture described above, we train it using AdaMax <ref type="bibr" target="#b28">[29]</ref> with β 1 = 0.9, β 2 = 0.999, an initial learning rate of 0.001 which decays half every 20 epochs, a minibatch size of 8, and a maximum training epochs of 100.</p><p>Objective function. Given the interpolated frame I out of our network and its ground truth I gt , we first employ the Charbonnier penalty <ref type="bibr" target="#b35">[36]</ref> as a surrogate for the 1 loss:</p><formula xml:id="formula_4">L Charbon = ρ(I out − I gt )<label>(4)</label></formula><p>where ρ(x) = ( x 2 2 + 2 ) 1/2 and is set to 0.001. Next, we follow <ref type="bibr" target="#b31">[32]</ref> and use a perceptual loss with feature φ extracted from conv4 3 of the pre-trained VGG16 <ref type="bibr" target="#b51">[52]</ref>:</p><formula xml:id="formula_5">L vgg = φ(I out ) − φ(I gt ) 2 .<label>(5)</label></formula><p>Then, inspired by the implementation of AdaCoF, we use a total variation loss imposed on the offset vectors for ensuring spatial continuity and smoothness:</p><formula xml:id="formula_6">L tv = τ (α 1 ) + τ (α 2 ) + τ (β 1 ) + τ (β 2 )<label>(6)</label></formula><p>where τ (I) = i,j ρ(I i,j+1 − I i,j ) + ρ(I i+1,j − I i,j ), and α 1 , α 2 , β 1 , β 2 are the offsets modules computed within our network. Lastly, we formulate our final loss function as</p><formula xml:id="formula_7">L = L Charbon + λ vgg L vgg + λ tv L tv<label>(7)</label></formula><p>where we set λ vgg = 0.005, λ tv = 0.01 in the experiments.  <ref type="table">Table 3</ref>. Quantitative comparisons with state-of-the-art methods. The results of methods marked with † are cloned from <ref type="bibr" target="#b41">[42]</ref>.</p><p>Training dataset. We use the Vimeo-90K dataset <ref type="bibr" target="#b61">[62]</ref> for training, which contains 51312/3782 video triplets of size 256×448 for training/validation. We further augment the data by randomly flipping them horizontally and vertically as well as perturbing the temporal order.</p><p>Evaluation. Besides the validation set of Vimeo-90K, we also evaluate the model on the well-known Middlebury dataset <ref type="bibr" target="#b0">[1]</ref> and UCF101 <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b53">54]</ref>. The metrics we use are PSNR, SSIM <ref type="bibr" target="#b56">[57]</ref> and LPIPS <ref type="bibr" target="#b63">[64]</ref>. Note higher values of PSNR and SSIM indicate better performance, while for LPIPS a lower value corresponds to a better result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ablation study</head><p>We analyze three components in our proposed method: model compression, feature pyramid, and path selection.</p><p>Model compression. As described in Sec. 3.2, we compress the baseline model to remove a large mount of redundancy, which also facilitates the training and inference. In <ref type="table">Table 2</ref>, we compare the performance of the AdaCoF and the compressed counterpart. It shows that a 10× compressed model does not sacrifice much when evaluated on the three benchmark datasets in different settings of (F, d) (which are the parameters in (1)), revealing the redundancy in AdaCoF and the necessity of the compression stage.</p><p>Feature pyramid. In order to better capture the contextual details, we incorporate the feature pyramid (FP) module into the compressed AdaCoF followed by warping operations and an image synthesis network (see Sec. 3.3). We isolate its effect by training a network that only outputs the synthesized image without a path selection mechanism. It turns out that by using only FP module (see "Ours -FP", <ref type="table">Table 2</ref>) on top of the compressed AdaCoF (F = 5, d = 1), we achieve visible improvements in terms of PSNR, SSIM and LPIPS on the Vimeo-90K and Middlebury datasets. Note that it substantially improves LPIPS on all the three benchmark datasets. Moreover, filtering the multi-scale fea-ture maps with 1-by-1 convolutions leads to better PSNR and SSIM as well as a slightly smaller model size.</p><p>Path selection. Although by adding only the FP module (and 1-by-1 convolutions) we are able to achieve promising quantitative results as shown in <ref type="table">Table 2</ref>, it does not take advantage of the capability of AdaCoF in handling complex motion, which can be integrated into our design with the proposed path selection (PS) mechanism. The left example in <ref type="figure">Figure 6</ref> shows that, when there is only fine detail variations in the input frames, adding PS or not does not quite affect our interpolation performance since FP module is capable of synthesizing details (also note the output of AdaCoF is blurry due to the loss of information). On the other hand, the right example contains large motion of two balls, and with only FP module the model is difficult in capturing the motion of the right ball precisely. In contrast, our final model with the embedded PS mechanism can deal with the large motion very well (even sharper on the edges of the balls compared to AdaCoF). More importantly, our approach preserves the finger shape (see the bottom-left corner) while AdaCoF totally misses that part of information. In conclusion, our completed model with FP and PS can handle both fine details and large motion, and achieves significant improvements when evaluated quantitatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Quantitative evaluation</head><p>We evaluate our compression-driven approach based on AdaCoF with F = 11, d = 2 against the other stateof-the-art DNN methods in <ref type="table">Table 3</ref>. Since SepCov <ref type="bibr" target="#b43">[44]</ref>, CtxSyn <ref type="bibr" target="#b40">[41]</ref> and SoftSplat <ref type="bibr" target="#b41">[42]</ref> are not open source, we directly copy their numerical results as well as DAIN's <ref type="bibr" target="#b1">[2]</ref> from <ref type="bibr" target="#b41">[42]</ref>. For the rest of the methods, we evaluate their pre-trained models on the three datasets. Note that "Ada-CoF" corresponds to the setting of F = 5, d = 1 while "AdaCoF+" is associated with F = 11, d = 2.</p><p>As shown in <ref type="table">Table 3</ref>, first note that our approach performs favorably against all the compared methods in terms of SSIM and LPIPS. As for PSNR, the proposed method also outperforms all the other methods with a large margin <ref type="bibr">Figure 7</ref>. Visual comparisons on the DAVIS 2016 dataset <ref type="bibr" target="#b46">[47]</ref>. Our compression-driven method not only outperforms the baseline model AdaCoF but also is more appealing compared with more recently proposed methods in handling large motion, occlusion and fine details. except for SoftSplat <ref type="bibr" target="#b41">[42]</ref>. Moreover, our model is significantly smaller than the other competitors. We remark that in the past there do exist some light-weight frame interpolation models, e.g., DVF <ref type="bibr" target="#b35">[36]</ref>, ToFlow <ref type="bibr" target="#b61">[62]</ref> and CyclicGen <ref type="bibr" target="#b34">[35]</ref>, but they fail to compete with SepConv <ref type="bibr" target="#b43">[44]</ref> or CtxSyn <ref type="bibr" target="#b40">[41]</ref> as reported in <ref type="bibr" target="#b41">[42]</ref>. Lastly, we observe that AdaCoF <ref type="bibr" target="#b31">[32]</ref> is only mediocre among those methods, but our final model which is based upon it has a significantly better performance while maintains compactness, indicating the superiority of the proposed CDFI design framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Qualitative evaluation</head><p>We demonstrate the visual comparisons on the DAVIS dataset <ref type="bibr" target="#b46">[47]</ref> in <ref type="figure">Figure 7</ref>. The first and third example contain complex motion and occlusion, while the second example involves many non-stationary finer details. Note that AdaCoF+ <ref type="bibr" target="#b31">[32]</ref> generates relatively blurry interpolation frame for all these examples (see the motorbike, house and swing stool). In contrast, our method built upon it predicts sharper and more realistic results due to our newly added FP module and PS mechanism. Furthermore, we compare with BMBC <ref type="bibr" target="#b44">[45]</ref>, CAIN <ref type="bibr" target="#b15">[16]</ref> and EDSC <ref type="bibr" target="#b10">[11]</ref>, which are all newly developed within the year. In particular, similar to AdaCoF, EDSC relies on the deformable separable convolution but estimates an extra mask to help with the image synthesis. However, they are not as appealing as our method on the provided examples. One can see that their interpola-tions normally contain visible artifacts and are not capable of preserving clear details. Note that BMBC <ref type="bibr" target="#b44">[45]</ref> occasionally synthesizes sharp results but is not as consistent as ours. We conjecture that the additional bilateral cost volume in BMBC benefits the intermediate motion estimations, which can also be incorporated into our design. Recall that the size of our model is the smallest among them, which again confirms the advantage of the CDFI network design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We presented a compression-driven network design for frame interpolation (CDFI) that uses model compression as a guide in determining an efficient architecture and then improves upon it. For the first time, we considered the redundancy in the existing methods. As an instance, we showed that a much smaller AdaCoF model performs similarly as the original one, and with simple modifications it is able to outperform the baseline with a large extent and is also superior against other state-of-the-art methods. We emphasize that the optimization-based compression over a baseline model does not rely on particular design of the baseline. Therefore, we believe that our framework is generic to be applied to other models and provides a new perspective on developing efficient frame interpolation algorithms. In future work, it will be of interest to construct a better association between the compression and design stages which iteratively refines the underlying architecture.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Pipeline of CDFI. Stage (I): compression of the baseline; Stage (II): improvements upon the compression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>5 .</head><label>5</label><figDesc>The upper part (our design) extracts a feature pyramid representation of the input frames through 1-by-1 convolutions from the encoder of the U-Net, then the multi-scale features are warped by AdaCoF operation of learned backward/forward parameters, which are fed into a synthesis network to generate another candidate intermediate frame I (2) 0.5 . Note that the pink and blue AdaCoF modules are associated with {W1, α1, β1} and {W2, α2, β2}, respectively. Finally, the network outputs the interpolation frame by blending I (1) 0.5 and I (2) 0.5 via an extra occlusion mask V2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>OFigure 5 .</head><label>5</label><figDesc>p ti m iz in g th e " p ro b le m Plot of PSNR against the density of AdaCoF, trained on Middlebury, within 20 epochs of optimizing equation (2). and density ratio d l of this layer are respectively defined as s l := # of zeros inθ l /K l and d l := 1 − s l . (3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The statistics of AdaCoF and the compressed version.</figDesc><table><row><cell></cell><cell>Original AdaCoF</cell><cell>After</cell></row><row><cell></cell><cell>(F = 5, d = 1)</cell><cell>Compression</cell></row><row><cell>PSNR</cell><cell>35.72</cell><cell>35.43</cell></row><row><cell>SSIM</cell><cell>0.96</cell><cell>0.96</cell></row><row><cell>Size (MB)</cell><cell>83.4</cell><cell>9.4</cell></row><row><cell>Time (ms)</cell><cell>82.6</cell><cell>60.4</cell></row><row><cell>FLOPS (G)</cell><cell>359.2</cell><cell>185.9</cell></row><row><cell>Parameters (M)</cell><cell>21.8</cell><cell>2.45</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A database and evaluation methodology for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Depth-aware video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3703" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Memc-net: Motion estimation and motion compensation driven neural network for video interpolation and enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">High-order model and dynamic filtering for frame rate up-conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3813" to="3826" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Buciluǎ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="535" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A Fast Reduced-Space Algorithmic Framework for Sparse Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Orthant based proximal stochastic gradient method for 1-regularized optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03639</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Neural network compression via sparse optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biyi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.04868</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Half-space proximal stochastic gradient method for group-sparsity regularized problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12078</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Compressing neural networks with the hashing trick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2285" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Multiple video frame interpolation via enhanced deformable separable convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianhang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08070</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Video frame interpolation via deformable separable convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianhang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10607" to="10614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A survey of model compression and acceleration for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09282</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">All at once: Temporally adaptive multi-frame interpolation with advanced motion modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadi</forename><surname>Nasiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos N</forename><surname>Plataniotis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.11762</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scene-adaptive video frame interpolation via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myungsub</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janghoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyong</forename><surname>Baik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9444" to="9453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Channel attention is all you need for video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myungsub</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10663" to="10671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Flownet: Learning optical flow with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caner</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2758" to="2766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to generate chairs with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1538" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deepstereo: Learning to predict new views from the world&apos;s imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Neulander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5515" to="5524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Residual conv-deconv grid network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Fourure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Fromont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Muselet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Tremeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07958</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huizi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.00149</idno>
		<title level="m">Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Amc: Automl for model compression and acceleration on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanrui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="784" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Flownet 2.0: Evolution of optical flow estimation with deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margret</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2462" to="2470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Super slomo: High quality estimation of multiple intermediate frames for video interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaizu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Learned-Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9000" to="9008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning-based view synthesis for light field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Nima Khademi Kalantari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep convolutional inverse graphics network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tejas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2539" to="2547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast convnets using group-wise brain damage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Lebedev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2554" to="2564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adacof: Adaptive collaboration of flows for video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeongmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeoh</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Young</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daehyun</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuseok</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangyoun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5316" to="5325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Durdanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">Peter</forename><surname>Graf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.08710</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Pruning filters for efficient convnets. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Enhanced quadratic video interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangbin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Siyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxiu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.04642</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep video frame interpolation using cyclic frame generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Lun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Tung</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Yu</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8794" to="8802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Video frame synthesis using deep voxel flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aseem</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agarwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4463" to="4471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning image matching by simply watching video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gucan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Kneip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="434" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Moving gradients: a path-based method for plausible image interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Chung</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Phasenet for video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="498" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Phase-based frame interpolation for video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1410" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Context-aware synthesis for video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1701" to="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Softmax splatting for video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5437" to="5446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Video frame interpolation via adaptive convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="670" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Video frame interpolation via adaptive separable convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="261" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Bmbc: Bilateral motion estimation with bilateral cost volume for video interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junheum</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keunsoo</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chul</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.12622</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Im-net for high resolution video frame interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doron</forename><surname>Sabo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omry</forename><surname>Sendik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2398" to="2407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A benchmark dataset and evaluation methodology for video object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Model compression via distillation and quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Polino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Alistarh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05668</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Motion compensated frame interpolation with a symmetric optical flow constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Lau Rakêt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Roholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrés</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Visual Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="447" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised video interpolation using cycle consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitsum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Reda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aysegul</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Dundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guilin</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="892" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Video interpolation via generalized deformable convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangdi</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhui</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10680</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaerin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjun</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12987</idno>
		<title level="m">Aim 2020 challenge on video temporal super-resolution</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Ucf101: A dataset of 101 human actions classes from videos in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khurram</forename><surname>Soomro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Amir Roshan Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.0402</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8934" to="8943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Soft weight-sharing for neural network compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Meeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.04008</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eero P</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deepflow: Large displacement optical flow with deep matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaid</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1385" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning structured sparsity in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunpeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2074" to="2082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Optical flow guided tv-l 1 video interpolation and restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Werlberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="273" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Quadratic video interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Siyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxiu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1647" to="1656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Video enhancement with taskoriented flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglai</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1106" to="1125" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Zoom-in-to-check: Boosting video interpolation via instance-level discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangzhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hantian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12183" to="12191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of deep features as a perceptual metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="586" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Less is more: Towards compact cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="662" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">View synthesis by appearance flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Tulsiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="286" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">To prune, or not to prune: exploring the efficacy of pruning for model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyog</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.01878</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deformable convnets v2: More deformable, better results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9308" to="9316" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
