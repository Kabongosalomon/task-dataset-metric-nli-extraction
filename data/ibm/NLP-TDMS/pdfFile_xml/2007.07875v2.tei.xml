<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive L 2 Regularization in Person Re-Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyang</forename><surname>Ni</surname></persName>
							<email>xingyang.ni@tuni.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Technology and Communication Sciences</orgName>
								<orgName type="institution">Tampere University</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Fang</surname></persName>
							<email>liang.fang@tuni.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Technology and Communication Sciences</orgName>
								<orgName type="institution">Tampere University</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heikki</forename><surname>Huttunen</surname></persName>
							<email>heikki.huttunen@tuni.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Information Technology and Communication Sciences</orgName>
								<orgName type="institution">Tampere University</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive L 2 Regularization in Person Re-Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce an adaptive L2 regularization mechanism in the setting of person re-identification. In the literature, it is common practice to utilize hand-picked regularization factors which remain constant throughout the training procedure. Unlike existing approaches, the regularization factors in our proposed method are updated adaptively through backpropagation. This is achieved by incorporating trainable scalar variables as the regularization factors, which are further fed into a scaled hard sigmoid function. Extensive experiments on the Market-1501, DukeMTMC-reID and MSMT17 datasets validate the effectiveness of our framework. Most notably, we obtain stateof-the-art performance on MSMT17, which is the largest dataset for person re-identification. Source code is publicly available at https://github.com/nixingyang/AdaptiveL2Regularization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Person re-identification involves retrieving corresponding samples from a gallery set based on the appearance of a query sample across multiple cameras. It is a challenging task since images may differ significantly due to variations in factors such as illumination, camera angle and human pose. On account of the availability of large-scale datasets <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, remarkable progress has been witnessed in recent studies on person re-identification, e.g., utilizing local feature representations <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, leveraging extra attribute labels <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, improving policies for data augmentation <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, adding a separate re-ranking step <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> and switching to videobased datasets <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>.</p><p>L 2 regularization imposes constraints on the parameters of neural networks and adds penalties to the objective function during optimization. It is a commonly adopted technique which can improve the model's generalization ability. Although some works <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> provide insights on the underlying mechanism of L 2 regularization, it is an understudied topic and has not received sufficient attention. In most literature, L 2 regularization is taken for granted, and the text dedicated to it is typically shrunk into one sentence as in <ref type="bibr" target="#b17">[18]</ref>. On the other hand, existing approaches assign constant values to regularization factors in the training procedure, and such hyperparameters are hand-picked via hyperparameter optimization which is a tedious and time-consuming process. The primary purpose of this work is to address the bottleneck of conventional L 2 regularization and introduce a mechanism which learns the regularization factors and update those values adaptively.</p><p>In this paper, our major contributions are twofold:</p><p>• We introduce an adaptive L 2 regularization mechanism, which optimizes each regularization factor adaptively as the training procedure progresses. • With the proposed framework, we obtain state-of-the-art performance on MSMT17, which is the largest dataset for person re-identification. The rest of this paper is organized as follows. Section II reviews important works in person re-identification and L 2 regularization. In Section III, we present the essential components of our baseline, alongside the proposed adaptive L 2 regularization mechanism. Section IV describes the details of our experiments, including datasets, evaluation metrics and comprehensive analysis of our proposed method. Finally, Section V concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we give a brief overview of two distinct research topics, namely, person re-identification and L 2 regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Person Re-Identification</head><p>Utilizing local feature representations which are specific to certain regions, has been shown successful. Varior et al. <ref type="bibr" target="#b3">[4]</ref> propose a Long Short-Term Memory architecture which models the spatial dependency and thus extracts more discriminative local features. Sun et al. <ref type="bibr" target="#b4">[5]</ref> apply a uniform partition strategy which divides the feature maps evenly into individual parts, and the part-informed features are concatenated to form the final descriptor.</p><p>Besides, methods based on auxiliary features are advocated, aiming to utilize extra attributes in addition to the identity labels. Su et al. <ref type="bibr" target="#b5">[6]</ref> shows that learning mid-level human attributes can be used to address the challenge of visual appearance variations. Specifically, an attribute prediction model is trained on an independent dataset which contains the attribute labels. Lin et al. <ref type="bibr" target="#b6">[7]</ref> manually annotate attribute labels which contain detailed local descriptions. A multi-task network is proposed to learn an embedding for re-identification and also predict the attribute labels. In addition to the performance improvement in re-identification, such system can speed up the retrieval process by ten times.</p><p>By applying random manipulations on training samples, data augmentation has played an essential role in suppressing the overfitting issue and improving the generalization of models. Zhong et al. <ref type="bibr" target="#b7">[8]</ref> introduce an approach which erases the pixel values in a random rectangle region during training. By contrast, Dai et al. <ref type="bibr" target="#b8">[9]</ref> suggest dropping the same region for all samples in the same batch. Such feature dropping branch strengthens the learned features of local regions.</p><p>Adding a separate re-ranking step to refine the initial ranking list can lead to significant improvements. Zhong et al. <ref type="bibr" target="#b9">[10]</ref> develop a k-reciprocal encoding method based on the hypothesis that a gallery image is more likely to be a true match if it is similar to the probe in the k-reciprocal nearest neighbours. Zhou et al. <ref type="bibr" target="#b10">[11]</ref> rank the predictions with a specified local metric by exploiting negative samples for each online query, rather than implementing a general global metric for all query probes.</p><p>Lastly, some works shift the emphasis from image-based to video-based person re-identification. Liu et al. <ref type="bibr" target="#b11">[12]</ref> introduce a spatio-temporal body-action model which exploits the periodicity exhibited by a walking person in a video sequence. Alternatively, Dai et al. <ref type="bibr" target="#b12">[13]</ref> present a learning approach which unifies two modules: one module extracts the features of consecutive frames, and the other module tackles the poor spatial alignment of moving pedestrians.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. L 2 regularization</head><p>Laarhoven <ref type="bibr" target="#b13">[14]</ref> prove that L 2 regularization would not regularize properly in the presence of normalization operations, i.e., batch normalization <ref type="bibr" target="#b18">[19]</ref> and weight normalization <ref type="bibr" target="#b19">[20]</ref>. Instead, L 2 regularization will affect the scale of weights, and therefore it has an influence on the effective learning rate.</p><p>Similarly, Hoffer et al. <ref type="bibr" target="#b14">[15]</ref> investigate how does applying weight decay before batch normalization affect learning dynamics. Combining weight decay and batch normalization would constrain the norm to a small range of values and lead to a more stable step size for the weight direction. It enables better control over the effective step size through the learning rate.</p><p>Later on, Loshchilov et al. <ref type="bibr" target="#b15">[16]</ref> clarify a long-established misunderstanding that L 2 regularization is equivalent to weight decay. The aforementioned statement does not hold when applying adaptive gradient algorithms, e.g., Adam <ref type="bibr" target="#b20">[21]</ref>. Furthermore, they suggest decoupling the weight decay from the optimization steps, and it leads to the original formulation of weight decay.</p><p>Most recently, Lewkowycz et al. <ref type="bibr" target="#b16">[17]</ref> present an empirical study on the relations among the L 2 coefficient, the learning rate, and the number of training epochs and the performance of the model. In a similar manner as learning rate schedules, a manually designed schedule for the L2 parameter is proposed to increase training speed and boost model's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Maps</head><p>GlobalAveragePooling BatchNormalization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dense TripletLoss CrossEntropyLoss</head><p>Clipping Feature Embeddings</p><p>In Inference <ref type="figure">Fig. 1</ref>. Structure of an objective module. In the training procedure, two objective functions are applied: triplet loss <ref type="bibr" target="#b21">[22]</ref> and categorical cross-entropy loss. In the inference procedure, the feature embeddings before the batch normalization <ref type="bibr" target="#b18">[19]</ref> layer are extracted as the representations. Note that blocks in yellow are excluded from the minimal setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>In this section, we first present a minimal setup for person re-identification. Later on, we explain five components that contribute to significant improvements in performance and use the resulting method as the baseline in our study. Most importantly, we discuss the proposed adaptive L 2 regularization mechanism at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Minimal setup</head><p>Backbone: ResNet50 <ref type="bibr" target="#b17">[18]</ref>, initialized with ImageNet [23] pre-trained weights, is selected as the backbone model. For convenience, it is separated into five individual blocks, i.e., block 1-5, as illustrated in <ref type="figure">Figure 2</ref>. Additionally, the stride arguments of the first convolution layer in block 5 are set to 1, rather than default value 2. This enlarges the feature maps by a scale factor of 2 along with both height and width dimensions while reusing the pre-trained weights and keeping the total amount of parameters identical.</p><p>Objective module: <ref type="figure">Figure 1</ref> demonstrates the structure of an objective module that converts the feature maps to learning objectives. A global average pooling layer squeezes the spatial dimensions in the feature maps, and the following batch normalization <ref type="bibr" target="#b18">[19]</ref> layer generates the normalized feature vectors. The concluding fully-connected layer does not contain a bias vector, and it produces the predicted probabilities of each unique identity so that the model can be optimized using the categorical cross-entropy loss. In the inference procedure, the feature embeddings before the batch normalization layer are extracted as the representations, and cosine distance is adopted to measure the distance between two samples. Global Branch</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regional Branches</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Images</head><p>Block 1-4 Overall topology: The topology of the overall model is shown in <ref type="figure">Figure 2</ref>. It is to be observed that the minimal setup only contains the global branch. Given a batch of images, the individual blocks from the backbone model utilize successively, and an objective module is appended at the end.</p><p>Data augmentation: The image is resized to target resolution using a bilinear interpolation method. Besides, the image is flipped horizontally at random with probability set to 0.5. Zero paddings are added to all sides of the image, i.e., the top, bottom, left, and right sides. A random part with target resolution is subsequently cropped.</p><p>Learning rate: The learning rate increases linearly from a low value to the pre-defined base learning rate in the early stage of the training procedure, and it is divided by ten once the performance on the validation set plateaus. On the one hand, the warmup strategy suppresses the distorted gradient issue at the beginning <ref type="bibr" target="#b23">[24]</ref>. On the other hand, periodically reducing the learning rate boosts the performance even further.</p><p>Label smoothing: The label smoothing regularization <ref type="bibr" target="#b24">[25]</ref> is applied alongside with the categorical cross-entropy loss function. Given a sample with ground truth label y ∈ {1, 2, . . . , N }, the one-hot encoded label q(i) equals to 1 only if the index i is as the same as label y, and 0 otherwise. The smoothed label introduces a hyperparameter ∈ (0, 1) and is calculated as:</p><formula xml:id="formula_0">q (i) = (1 − )q(i) + N .<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Baseline</head><p>Triplet loss: As highlighted in <ref type="figure">Figure 1</ref>, the triplet loss <ref type="bibr" target="#b21">[22]</ref> is applied on the feature embeddings before the batch normalization layer. It mines the moderate hard triplets instead of all possible combinations of triplets, given that using all possible triplets may destabilize the training procedure. Considering that multiple loss functions are present, the weighting coefficients of each loss function are set to 1 on account of simplicity.</p><p>Regional branches: In addition to the global branch, two regional branches are integrated into the model. <ref type="figure">Figure 2</ref> illustrates the diagram of those regional branches. Firstly, the block 5 from the backbone model is replicated, and it is not shared with the global branch. Secondly, we adopt the uniform partition scheme as in <ref type="bibr" target="#b4">[5]</ref>. The slicing layer explicitly divides the feature maps into two horizontal stripes. Lastly, dimensionality reduction is performed using a convolutional layer on each stripe. Separate objective modules are appended afterwards. In the inference procedure, feature embeddings from multiple objective modules are concatenated.</p><p>Random erasing: In addition to random horizontal flipping, random erasing <ref type="bibr" target="#b7">[8]</ref> is utilized in data augmentation. During training, it erases an area of original images to improve the robustness of the model, especially for the occlusion cases.</p><p>Clipping: The clipping layer is inserted between the global average pooling layer and the batch normalization layer in <ref type="figure">Figure 1</ref>. It performs element-wise value clipping so that values in its output are contained in a closed interval. The clipping layer works in a similar manner as the ReLUn units <ref type="bibr" target="#b25">[26]</ref>, and it relieves optimization difficulties in the succeeding triplet loss <ref type="bibr" target="#b21">[22]</ref>. L 2 regularization: Conventional L 2 regularization is utilized to all trainable parameters, i.e., the regularization factors remain constant throughout the training procedure. Additionally, those regularization factors need to be hand-picked via hyperparameter optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Adaptive L 2 regularization</head><p>A neural network consists of a set of N distinct parameters,</p><formula xml:id="formula_1">P = {w n | n = 1, . . . , N },<label>(2)</label></formula><p>with P containing all trainable parameters. Each w n is an array which could be a vector, a matrix or a 3rd-order tensor. For example, the kernel and bias terms in a fully-connected layer are a matrix and a vector, respectively. Conventional L 2 regularization imposes an additional penalty term to the objective function, which can be formulated as follows:</p><formula xml:id="formula_2">L λ (P ) = L(P ) + λ N n=1 w n 2 2 ,<label>(3)</label></formula><p>where L(P ) and L λ (P ) denote the original and updated objective functions, respectively. In our case (see <ref type="figure">Figures 1  and 2</ref>), L(P ) is a weighted sum of triplet loss <ref type="bibr" target="#b21">[22]</ref> and categorical cross-entropy loss functions. In addition, w n refers to the square of the L 2 norm 1 of w n , and the constant coefficient λ ∈ R + defines the regularization strength.</p><p>One may wish to add penalties in a different way, e.g., applying lighter regularization in the early layers but stronger in the last ones. Thus, it is possible to generalize even further, i.e., defining a unique coefficient for each w n 2 2 :</p><formula xml:id="formula_3">L λ (P ) = L(P ) + N n=1 λ n w n 2 2 ,<label>(4)</label></formula><p>where each parameter w n is associated with an individual regularization factor λ n ∈ R + . Obviously, it is infeasible to manually fine-tune those regularization factors λ n for n = 1, . . . , N one by one, since N is in the order of 100 for models trained with ResNet50. Therefore, we treat them as any other learnable parameters and find suitable values from the data itself.</p><p>To make the aforementioned regularization factors adaptive, a straightforward extension is obtained by replacing the predefined constant λ n with scalar variables which are trainable through backpropagation. After the modification, Equation 4 remains unchanged while λ n ∈ R. However, such an approach without any constraints on λ n will fail. Namely, setting negative values for λ n allows naively increasing w n 2 2 so that L λ (P ) decreases sharply. In other words, the L 2 regularization penalties would become dominant in the optimization process. Thus the model collapses and would not learn useful feature embeddings.</p><p>To address the collapse problem, we apply the hard sigmoid function which assures that the regularization factor λ n would always have non-negative values. The hard sigmoid function is defined as</p><formula xml:id="formula_4">f (x) =      0, if x &lt; −c 1, if x &gt; c x/(2c) + 0.5, otherwise.<label>(5)</label></formula><p>In our experiments, we use c = 2.5, but any other positive values can be used as well.</p><p>The regularization factor λ n is obtained by applying the hard sigmoid on the raw parameters as</p><formula xml:id="formula_5">λ n = f (θ n ),<label>(6)</label></formula><p>where θ n ∈ R (n = 1, . . . , N ) are the trainable scalar variables. Furthermore, we introduce a hyperparameter A ∈ R + which represents the amplitude. Hence, we get λ n = Af (θ n ).</p><p>The amplitude A offers flexibility of avoiding excessively large regularization factors which could deteriorate the training procedure. Combining Equation (4) and <ref type="formula" target="#formula_6">(7)</ref> gives</p><formula xml:id="formula_7">L λ (P ) = L(P ) + N n=1</formula><p>Af (θ n ) w n 2 2 . (8) <ref type="bibr" target="#b0">1</ref> We define w 2 2 to denote the sum of squares of all elements also when w is a matrix or a 3rd-order tensor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we explain datasets, evaluation metrics and comprehensive analysis of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>We conduct experiments on three person re-identification datasets, namely, Market-1501 <ref type="bibr" target="#b0">[1]</ref>, DukeMTMC-reID <ref type="bibr" target="#b1">[2]</ref> and MSMT17 <ref type="bibr" target="#b2">[3]</ref>. <ref type="table" target="#tab_1">Table I</ref> makes a comparison of those datasets. The MSMT17 dataset outshines the other two due to its large scale.</p><p>The Market-1501 dataset is collected with six different cameras in total. It contains 32,217 images from 1,501 pedestrians, and at least two cameras capture each pedestrian. The training set includes 751 pedestrians with 12,936 images, while the test set consists of the remaining images from 750 pedestrians and one distractor class.</p><p>The DukeMTMC-reID dataset includes 1,404 pedestrians that appear in at least two cameras and 408 pedestrians that appear only in one camera. The training and test sets contain 16,522 and 19,889 images, respectively. The query and gallery samples in the test set are randomly split.</p><p>The MSMT17 dataset is the largest person re-identification dataset which is publicly available, as of July 2020. It contains 126,441 images from 4,101 pedestrians, while 3 indoor cameras and 12 outdoor cameras are employed. In particular, the test set has approximately three times as much samples as the training set. Such setting motivates the research community to leverage a limited number of training samples that are available since data annotation is costly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation metrics</head><p>Following the practices in <ref type="bibr" target="#b0">[1]</ref>, two evaluation metrics are applied to measure the performance, i.e., mean Average Precision (mAP), and Cumulative Matching Characteristic (CMC) rank-k accuracy. The metrics take the distance matrix between query and gallery samples, in conjunction with the ground truth identities and camera IDs as input arguments. Gallery samples are discarded if they have been taken from the same camera as the query sample. As a result, greater emphasis is laid on the performance in the cross-camera setting.</p><p>Since the query samples may have multiple ground truth matches in the gallery set, mAP is preferable than rank-k accuracy for the reason that mAP considers both precision and recall. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation study of baseline</head><p>The baseline differs from the minimal setup in five aspects, as discussed in Section III-B. <ref type="table" target="#tab_1">Table III</ref> presents an ablation study to demonstrate how each component contributes to the performance on person re-identification. On the one hand, the triplet loss <ref type="bibr" target="#b21">[22]</ref> brings the most significant improvements on all three datasets. The boost is due to the fact that the triplet loss is applied to the feature embeddings which are retrieved in the inference procedure (see <ref type="figure">Figure 1</ref>). Since the triplet loss directly optimizes the model in a manner comparable to similarity search, it closes the gap between the training and inference procedures. On the other hand, the other four components bring moderate improvements. It is conceivable that the model reaches better generalization by using hand-picked L 2 regularization factors which remain constant throughout the training procedure. <ref type="table" target="#tab_1">Table II</ref> shows performance comparisons among baseline, adaptive L 2 regularization and existing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparisons with existing approaches</head><p>Firstly, all methods listed in <ref type="table" target="#tab_1">Table II</ref> have surpassed the best-performing human annotators <ref type="bibr" target="#b26">[27]</ref> on the Market-1501 dataset. In light of the scale of the Market-1501 and DukeMTMC-reID datasets (see <ref type="table" target="#tab_1">Table I</ref>), these two small-scale datasets might have been saturated and more emphasis should be put on the MSMT17 dataset. Since mAP is preferable than rank-k accuracy, the mAP score on MSMT17 is the most reliable indicator of performance.</p><p>Secondly, the proposed adaptive L 2 regularization mechanism contributes with decent improvements to the baseline, especially on MSMT17 in which the mAP score increases from 57.7% to 59.4%. Among methods which utilize the ResNet50 backbone, it is noteworthy that the adaptive L 2 regularization method obtains the state-of-the-art performance on DukeMTMC-reID and MSMT17, very close to state-ofthe-art performance on Market-1501.</p><p>Last but not least, deeper backbones (i.e., ResNet101 and ResNet152) further improve the performance, at the cost of extra computations. Attributed to the re-ranking <ref type="bibr" target="#b9">[10]</ref> method which exploits the test data in the inference procedure, new milestones have been accomplished, i.e., the mAP scores on Market-1501, DukeMTMC-reID and MSMT17 stand at 94.4%, 90.7% and 76.7%, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Quantitative analysis of regularization factors</head><p>Depending on the associated distinct parameter (see Equation 2), the regularization factors can be classified into five categories: conv kernel, conv bias, bn gamma, bn beta and dense kernel, where conv, bn and dense denote the convolutional, batch normalization and fully-connected layers. In the following, we examine the regularization factors for a model trained on MSMT17 using the ResNet50 backbone. <ref type="figure" target="#fig_0">Figure 3</ref> visualizes the median value of regularization factors in each category, with respect to the number of iterations. Note that the learning rate gets reduced at iterations 8000 and 14000. While conv kernel, bn gamma and bn beta behave similarly, conv bias remains constant throughout the training procedure and dense kernel drops to 0 in the early stage. <ref type="figure">Figure 4</ref> demonstrates a histogram of regularization factors in the last epoch, i.e., the training procedure completes. The interval [0, 0.0025] is divided evenly into five buckets. For regularization factors from the same category, the values could differ significantly, e.g., 2 and 38 regularization factors from conv bias fall within the interval [0, 0.0005] and [0.0020, 0.0025], respectively. To be specific, the regularization factors from conv bias in the two Reduction blocks are 0 (see <ref type="figure">Figure 2</ref>). If omitting the effects of the Clipping layer in <ref type="figure">Figure 1</ref>, those convolutional layers are followed by batch normalization layers which intrinsically cancels out the bias terms in aforementioned convolutional layers. Consequently, such regularization factors would converge to 0. In summary, this phenomenon reflects the superiority of our proposed method, in which each regularization factor is optimized separately. <ref type="figure">Figure 5</ref> illustrates selected query samples with corresponding top 5 matches from the gallery set. Although query samples and erroneous matches may have similar appearances, minor differences could be observed under careful inspection, e.g., the dissimilarity between backpacks. Furthermore, our models could retrieve correct matches even in the presence of large illumination changes, e.g., the two examples from the MSMT17 dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Qualitative analysis of predictions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this work, we revisited L 2 regularization in neural networks. Unlike employing constant and hand-picked regularization factors, our proposed method optimizes the strength of L 2 regularization adaptively through backpropagation. More specifically, we applied a scaled hard sigmoid function to trainable scalar variables and used those as the regularization factors. Extensive experiments substantiate that our framework boosts model's performance, and we obtained state-of-theart performance on MSMT17 which is the largest person reidentification dataset. Although the current study is constrained within the domain of person re-identification, it is self-evident that the proposed adaptive L 2 regularization mechanism can be seamlessly integrated into the training procedure of any neural networks. Accordingly, further studies can be conducted on other topics, e.g., image classification, image retrieval and object detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>This work was financially supported by Business Finland project 408/31/2018 MIDAS.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>The median value of regularization factors in each category, with respect to the number of iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 . 5 Fig. 5 .</head><label>455</label><figDesc>Histogram of regularization factors in the last epoch. Selected query samples with corresponding top 5 matches from the gallery set. Images with orange, green and red border are query samples, correct matches and erroneous matches, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF THREE PERSON RE-IDENTIFICATION DATASETS, NAMELY, MARKET-1501<ref type="bibr" target="#b0">[1]</ref>, DUKEMTMC-REID [2] AND MSMT17<ref type="bibr" target="#b2">[3]</ref>.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Market-1501 DukeMTMC-reID MSMT17</cell></row><row><cell>Train Samples</cell><cell>12,936</cell><cell>16,522</cell><cell>32,621</cell></row><row><cell>Train Identities</cell><cell>751</cell><cell>702</cell><cell>1,041</cell></row><row><cell>Test Query Samples</cell><cell>3,368</cell><cell>2,228</cell><cell>11,659</cell></row><row><cell>Test Gallery Samples</cell><cell>15,913</cell><cell>17,661</cell><cell>82,161</cell></row><row><cell>Test Identities</cell><cell>751</cell><cell>1,110</cell><cell>3,060</cell></row><row><cell>Cameras</cell><cell>6</cell><cell>8</cell><cell>15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II PERFORMANCE</head><label>II</label><figDesc>COMPARISONS AMONG BASELINE, ADAPTIVE L 2 REGULARIZATION AND EXISTING APPROACHES. THE MAP SCORE ON MSMT17 IS THE MOST RELIABLE INDICATOR OF PERFORMANCE. R1: RANK-1 ACCURACY. -: NOT AVAILABLE. †: RE-RANKING [10] IS APPLIED.</figDesc><table><row><cell>Method</cell><cell cols="2">Venue</cell><cell>Backbone</cell><cell></cell><cell cols="2">Market-1501 mAP</cell><cell>R1</cell><cell cols="2">DukeMTMC-reID mAP R1</cell><cell>mAP</cell><cell>MSMT17</cell><cell>R1</cell></row><row><cell>Annotators [27]</cell><cell cols="2">arXiv 2017</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="2">93.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PCB [5]</cell><cell cols="2">ECCV 2018</cell><cell>ResNet50</cell><cell></cell><cell>81.6</cell><cell cols="2">93.8</cell><cell>69.2</cell><cell>83.3</cell><cell>-</cell><cell>-</cell></row><row><cell>IANet [28]</cell><cell cols="2">CVPR 2019</cell><cell>ResNet50</cell><cell></cell><cell>83.1</cell><cell cols="2">94.4</cell><cell>73.4</cell><cell>87.1</cell><cell>46.8</cell><cell>75.5</cell></row><row><cell>AANet [29]</cell><cell cols="2">CVPR 2019</cell><cell>ResNet50</cell><cell></cell><cell>82.5</cell><cell cols="2">93.9</cell><cell>72.6</cell><cell>86.4</cell><cell>-</cell><cell>-</cell></row><row><cell>CAMA [30]</cell><cell cols="2">CVPR 2019</cell><cell>ResNet50</cell><cell></cell><cell>84.5</cell><cell cols="2">94.7</cell><cell>72.9</cell><cell>85.8</cell><cell>-</cell><cell>-</cell></row><row><cell>DGNet [31]</cell><cell cols="2">CVPR 2019</cell><cell>ResNet50</cell><cell></cell><cell>86.0</cell><cell cols="2">94.8</cell><cell>74.8</cell><cell>86.6</cell><cell>52.3</cell><cell>77.2</cell></row><row><cell>OSNet [32]</cell><cell cols="2">ICCV 2019</cell><cell>OSNet</cell><cell></cell><cell>84.9</cell><cell cols="2">94.8</cell><cell>73.5</cell><cell>88.6</cell><cell>52.9</cell><cell>78.7</cell></row><row><cell>MHN [33]</cell><cell cols="2">ICCV 2019</cell><cell>ResNet50</cell><cell></cell><cell>85.0</cell><cell cols="2">95.1</cell><cell>77.2</cell><cell>89.1</cell><cell>-</cell><cell>-</cell></row><row><cell>BDB [9]</cell><cell cols="2">ICCV 2019</cell><cell>ResNet50</cell><cell></cell><cell>86.7</cell><cell cols="2">95.3</cell><cell>76.0</cell><cell>89.0</cell><cell>-</cell><cell>-</cell></row><row><cell>BAT-net [34]</cell><cell cols="2">ICCV 2019</cell><cell cols="2">GoogLeNet</cell><cell>87.4</cell><cell cols="2">95.1</cell><cell>77.3</cell><cell>87.7</cell><cell>56.8</cell><cell>79.5</cell></row><row><cell>SNR [35]</cell><cell cols="2">CVPR 2020</cell><cell>ResNet50</cell><cell></cell><cell>84.7</cell><cell cols="2">94.4</cell><cell>72.9</cell><cell>84.4</cell><cell>-</cell><cell>-</cell></row><row><cell>HOReID [36]</cell><cell cols="2">CVPR 2020</cell><cell>ResNet50</cell><cell></cell><cell>84.9</cell><cell cols="2">94.2</cell><cell>75.6</cell><cell>86.9</cell><cell>-</cell><cell>-</cell></row><row><cell>RGA-SC [37]</cell><cell cols="2">CVPR 2020</cell><cell>ResNet50</cell><cell></cell><cell>88.4</cell><cell cols="2">96.1</cell><cell>-</cell><cell>-</cell><cell>57.5</cell><cell>80.3</cell></row><row><cell>SCSN [38]</cell><cell cols="2">CVPR 2020</cell><cell>ResNet50</cell><cell></cell><cell>88.5</cell><cell cols="2">95.7</cell><cell>79.0</cell><cell>91.0</cell><cell>58.5</cell><cell>83.8</cell></row><row><cell>Baseline (Ours)</cell><cell>-</cell><cell></cell><cell>ResNet50</cell><cell></cell><cell>87.2</cell><cell cols="2">94.6</cell><cell>78.9</cell><cell>88.0</cell><cell>57.7</cell><cell>79.1</cell></row><row><cell>Adaptive L 2 Regularization (Ours)</cell><cell>-</cell><cell></cell><cell cols="2">ResNet50 ResNet101 ResNet152 ResNet152  †</cell><cell>88.3 88.6 88.9 94.4</cell><cell cols="2">95.3 94.8 95.6 96.0</cell><cell>79.9 80.6 81.0 90.7</cell><cell>88.9 89.2 90.2 92.2</cell><cell>59.4 61.9 62.2 76.7</cell><cell>79.6 81.3 81.7 84.9</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE III</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">ABLATION STUDY OF BASELINE USING THE RESNET50 BACKBONE.</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">R1: RANK-1 ACCURACY.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="2">Market-1501 mAP R1</cell><cell cols="2">DukeMTMC-reID mAP R1</cell><cell cols="2">MSMT17 mAP R1</cell><cell></cell><cell></cell></row><row><cell>Minimal Setup</cell><cell>28.3</cell><cell>60.0</cell><cell>28.7</cell><cell>49.9</cell><cell>11.4</cell><cell>34.0</cell><cell></cell><cell></cell></row><row><cell>+ Triplet Loss</cell><cell>79.9</cell><cell>92.0</cell><cell>68.8</cell><cell>82.2</cell><cell>44.0</cell><cell>70.9</cell><cell></cell><cell></cell></row><row><cell>+ Regional Branches</cell><cell>81.3</cell><cell>93.3</cell><cell>71.2</cell><cell>84.2</cell><cell>47.9</cell><cell>74.2</cell><cell></cell><cell></cell></row><row><cell>+ Random Erasing</cell><cell>85.8</cell><cell>94.4</cell><cell>76.6</cell><cell>87.0</cell><cell>54.1</cell><cell>77.0</cell><cell></cell><cell></cell></row><row><cell>+ Clipping</cell><cell>86.8</cell><cell>94.3</cell><cell>78.1</cell><cell>87.6</cell><cell>56.5</cell><cell>78.4</cell><cell></cell><cell></cell></row><row><cell>+ L 2 regularization</cell><cell>87.2</cell><cell>94.6</cell><cell>78.9</cell><cell>88.0</cell><cell>57.7</cell><cell>79.1</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1116" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="17" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Person transfer gan to bridge domain gap for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A siamese long short-term memory architecture for human re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Varior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="135" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Beyond part models: Person retrieval with refined part pooling (and a strong convolutional baseline)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="480" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep attributes driven multi-camera person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="475" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving person re-identification by attribute and identity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04896</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Batch DropBlock network for person re-identification and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3691" to="3701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Re-ranking person reidentification with k-reciprocal encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1318" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient online local metric adaptation via negative samples for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2420" to="2428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A spatio-temporal appearance representation for viceo-based pedestrian re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3810" to="3818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Video person reidentification by temporal residual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1366" to="1377" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Laarhoven</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05350</idno>
		<title level="m">L2 regularization versus batch and weight normalization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Norm matters: efficient and accurate normalization schemes in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Banner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2160" to="2170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gur-Ari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08643</idno>
		<title level="m">On the training dynamics of deep networks with $ L 2 $ regularization</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="901" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">In defense of the triplet loss for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.03265</idno>
		<title level="m">On the variance of the adaptive learning rate and beyond</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks on cifar-10</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Unpublished manuscript</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Alignedreid: Surpassing human-level performance in person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.08184</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interactionand-aggregation network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9317" to="9326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aanet: Attribute attention network for person re-identifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-P</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Yap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7134" to="7143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards rich feature discovery with class activation maps augmentation for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1389" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Joint discriminative and generative learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2138" to="2147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Omni-scale feature learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3702" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mixed high-order attention network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="371" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bilinear attention networks for person retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8030" to="8039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Style normalization and restitution for generalizable person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3143" to="3152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6449" to="6458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Relation-Aware Global Attention for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3186" to="3195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Salience-Guided Cascaded Suppression Network for Person Re-Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3300" to="3310" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
