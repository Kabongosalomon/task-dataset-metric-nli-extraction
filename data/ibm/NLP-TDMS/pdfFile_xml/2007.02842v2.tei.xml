<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><forename type="middle">Bai</forename><surname>Unsw</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sydney</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
							<email>lina.yao@unsw.edu.au</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Li</surname></persName>
							<email>can.li4@student.unsw.edu.au</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Wang</surname></persName>
							<email>xianzhi.wang@uts.edu.au</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
							<email>can.wang@griffith.edu.au</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">UNSW</orgName>
								<address>
									<country>Sydney</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">UNSW</orgName>
								<address>
									<settlement>Sydney</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Griffith University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modeling complex spatial and temporal correlations in the correlated time series data is indispensable for understanding the traffic dynamics and predicting the future status of an evolving traffic system. Recent works focus on designing complicated graph neural network architectures to capture shared patterns with the help of pre-defined graphs. In this paper, we argue that learning node-specific patterns is essential for traffic forecasting while the pre-defined graph is avoidable. To this end, we propose two adaptive modules for enhancing Graph Convolutional Network (GCN) with new capabilities: 1) a Node Adaptive Parameter Learning (NAPL) module to capture node-specific patterns; 2) a Data Adaptive Graph Generation (DAGG) module to infer the inter-dependencies among different traffic series automatically. We further propose an Adaptive Graph Convolutional Recurrent Network (AGCRN) to capture fine-grained spatial and temporal correlations in traffic series automatically based on the two modules and recurrent networks. Our experiments 1 on two real-world traffic datasets show AGCRN outperforms state-of-the-art by a significant margin without pre-defined graphs about spatial connections.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The fast urbanization introduces growing populations in cities and presents significant mobility and sustainability challenges. Among those challenges, Intelligent Transportation Systems (ITS) has become an active research area <ref type="bibr" target="#b0">[1]</ref>, given its potential to promote system efficiency and decisionmaking. As an essential step towards the ITS, traffic forecasting aims at predicting the future status (e.g., traffic flow and speed, and passenger demand) of urban traffic systems. It plays a vital role in traffic scheduling and management and has attracted tremendous attention from the machine learning research community in recent years <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>Traffic forecasting is challenging due to the complex intra-dependencies (i.e., temporal correlations within one traffic series) and inter-dependencies (i.e., spatial correlations among multitudinous correlated traffic series) <ref type="bibr" target="#b2">[3]</ref> generated from different sources, e.g., different loop detectors/intersections for traffic flow &amp; traffic speed prediction, and various stations/regions for passenger demand prediction. Traditional methods simply deploy time series models, e.g., Auto-Regressive Integrated Moving Average (ARIMA) and Vector Auto-Regression (VAR), for traffic forecasting. They cannot capture the nonlinear correlations nor intricate spatial-temporal patterns among large scale traffic data. Recently, researchers shift to deep-learning-based methods and focus on designing new neural network architectures to capture prominent spatial-temporal patterns shared by all traffic series. They typically model temporal dependencies with recurrent neural networks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> (e.g., Long-Short Term Memory and Gated Recurrent Unit) or temporal convolution modules <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. Regarding spatial correlations, they commonly use GCN-based methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12]</ref> to model unstructured traffic series and their inter-dependencies. <ref type="figure">Figure 1</ref>: Examples of traffic flow with diverse patterns. The traffic flow of road 3 is steady in the day time. As a contrast, the traffic flows of road 1, 2 and 4 have obvious evening peak, morning peak, and both peaks, respectively.</p><p>While recent deep-learning-based methods achieve promising results, they are biased to the prominent and shared patterns among all traffic series-the shared parameter space makes current methods inferior in capturing fine-grained data-source specific patterns accurately. In fact, traffic series exhibit diversified patterns (as shown in <ref type="figure">Fig. 1</ref>), they may appear similar, dissimilar, and even contradictory owning to the distinct attributes across a variety of data sources <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref>. Moreover, existing GCN-based methods require pre-defining an inter-connection graph by similarity or distance measures <ref type="bibr" target="#b13">[14]</ref> to capture the spatial correlations. That further requires substantial domain knowledge and is sensitive to the graph quality. The graphs generated in this manner are normally intuitive, incomplete, and not directly specific to the prediction tasks; they may contain biases and not adaptable to domains without appropriate knowledge.</p><p>Instead of designing more complicated network architectures, we propose two concise yet effective mechanisms by revising the basic building block of current methods (i.e., GCN) to solve the above problems separately. Specifically, we propose to enhance GCN with two adaptive modules for traffic forecasting tasks: 1) a Node Adaptive Parameter Learning (NAPL) module to learn node-specific patterns for each traffic series-NAPL factorizes the parameters in traditional GCN and generates node-specific parameters from a weights pool and bias pool shared by all nodes according to the node embedding; 2) a Data Adaptive Graph Generation (DAGG) module to infer the node embedding (attributes) from data and to generate the graph during training. NAPL and DAGG are independent and can be adapted to existing GCN-based traffic forecasting models both separately and jointly. All the parameters in the modules can be easily learned in an end-to-end manner. Furthermore, we combine NAPL and DAGG with recurrent networks and propose a unified traffic forecasting model -Adaptive Graph Convolutional Recurrent Network (AGCRN). AGCRN can capture fine-grained node-specific spatial and temporal correlations in the traffic series and unify the nodes embeddings in the revised GCNs with the embedding in DAGG. As such, training AGCRN can result in a meaningful node representation vector for each traffic series source (e.g., roads for traffic speed/flow, stations/regions for passenger demand). The learned node representation contains valuable information about the road/region and can be potentially applied to other tasks <ref type="bibr" target="#b14">[15]</ref>.</p><p>We evaluate AGCRN on two real-world datasets for the multi-step traffic prediction task and compare it with several representative traffic forecasting models. The experimental results show that AGCRN outperforms state-of-the-art with a significant margin. We also conduct ablation studies and demonstrate the effectiveness of both NAPL and DAGG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Correlated time series prediction Traffic forecasting belongs to correlated time series analysis (or multivariate time series analysis) and has been studied for decades. In recent years, deep learning has dominated the correlated time series prediction due to its superior ability in modeling complex functions and learning correlations from data automatically. A majority of such studies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref> rely on LSTM or GRU to model the temporal dynamics in the time series data. Some efforts employ temporal convolutional networks <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> to enable the model process very long sequence with fewer time. However, these studies do not explicitly model the inter-dependencies among different time series. A very recent work <ref type="bibr" target="#b24">[25]</ref> uses transformers for correlated time series prediction. Such work normally requires massive training samples due to tremendous trainable parameters <ref type="bibr" target="#b25">[26]</ref>.</p><p>GCN based Traffic forecasting Different with general correlated time series prediction, traffic forecasting researches also pay more attention to spatial correlations among the traffic series from different sources (spaces/regions/sensors) except for the temporal correlations. A part of these studies <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9]</ref> utilize CNN to capture spatial correlations among near regions based on the assumption that traffic series are generated from grid-partitioned cities <ref type="bibr" target="#b27">[28]</ref>, which does not always hold. To develop more general and widely-used traffic forecasting methods, researchers are shifting to GCN-based models in recent years. These efforts <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref> formulate the traffic forecasting problem on graph and utilize the spectral GCN developed in <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref> for capturing the prominent spatial interactions among different traffic series. DCRNN <ref type="bibr" target="#b1">[2]</ref> re-formulates the spatial dependency of traffic as a diffusion process and extends the previous GCN <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref> to a directed graph. Following DCRNN, Graph Wavenet <ref type="bibr" target="#b4">[5]</ref> combines GCN with dilated causal convolution networks for saving computation cost in handling long sequence and propose a self-adaptive adaptive adjacency matrix as a complement for the pre-defined adjacent matrix to capture spatial correlations. More recent works such as ASTGCN <ref type="bibr" target="#b5">[6]</ref>, STSGCN <ref type="bibr" target="#b10">[11]</ref> and GMAN <ref type="bibr" target="#b11">[12]</ref> further add more complicated spatial and temporal attention mechanisms with GCN to capture the dynamic spatial and temporal correlations. However, these methods can only capture shared patterns among all traffic series and still rely on the pre-defined spatial connection graph.</p><p>Graph Convolutional Networks GCN <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref> is a special kind of CNN generalized for graphstructured data, which is widely used in node classification, link prediction, and graph classification <ref type="bibr" target="#b33">[34]</ref>. Most of these works focus on graph representation, which learns node embedding by integrating the features from node's local neighbours based on the given graph structure. To manipulate neighbours' information more accurately, GAT <ref type="bibr" target="#b34">[35]</ref> learns to weight the information from different neighbours with attention scores learned by multi-head self-attention mechanism. DIFFPOOL <ref type="bibr" target="#b35">[36]</ref> enhances GCN with node clustering to generate hierarchical graph representations. Different from these works dealing with static features, our work deals with dynamically evolving streams and operates on both spatial and temporal dimensions without the given graph structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>We target on the multi-step traffic forecasting problem. Consider multitudinous traffic series that contains N correlated univariate time series represented as X = {X :,0 , X :,1 , ..., X :,t , ...}, where X :,t = {x 1,t , x 2,t , ..., x i,t , ...x N,t } T ∈ R N ×1 is the recording of N sources at time step t, our target is to predict the future values of the correlated traffic series based on the observed historical values. Following in the practice in the time series prediction, we formulate the problem as finding a function F to forecast the next τ steps data based on the past T steps historical data:</p><p>{X :,t+1 , X :,t+2 , ..., X :,t+τ } = F θ (X :,t , X :,t−1 , ..., X :,t−T +1 )</p><p>where θ denotes all the learnable parameters in the model. In order to accurately manipulate the spatial correlations between different traffic series, the problem is further formulated on graph G = (V, E, A), where V is a set of nodes represent the sources of traffic series and |V| = N , E is a set of edges, and A ∈ R N ×N is the adjacent matrix of the graph representing the proximity between nodes or traffic series (e.g., a function of traffic network distance or traffic series similarity). Thus, the problem is modified as:</p><formula xml:id="formula_1">{X :,t+1 , X :,t+2 , ..., X :,t+τ } = F θ (X :,t , X :,t−1 , ..., X :,t−T +1 ; G)<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Node Adaptive Parameter Learning</head><p>Most recent work in traffic forecasting deploys GCN to capture the spatial correlations among traffic series and follows the calculations proposed in the spectral domain <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. According to <ref type="bibr" target="#b32">[33]</ref>, the graph convolution operation can be well-approximated by 1 st order Chebyshev polynomial expansion and generalized to high-dimensional GCN as:</p><formula xml:id="formula_2">Z = (I N + D − 1 2 AD − 1 2 )XΘ + b<label>(3)</label></formula><p>where A ∈ R N ×N is the adjacent matrix of the graph, D is the degree matrix, X ∈ R N ×C and Z ∈ R N ×F are input and output of the GCN layer, Θ ∈ R C×F and b ∈ R F denote the learnable weights and bias, separately. From the view of one node (e.g., node i), the GCN operation can be regarded as transforming the features of node X i ∈ R 1×C to Z i ∈ R 1×F with the shared Θ and b among all nodes. While sharing parameters may be useful to learn the most prominent patterns among all nodes in many problems and can significantly reduce the parameter numbers, we find its sub-optimal for traffic forecasting problems. Except for the close spatial correlations between close related traffic series, there also exist diverse patterns among different traffic series due to the dynamic propriety of time series data and various factors of the node that could influence traffic. On the one hand, the traffic streams from two adjacent nodes may also present dissimilar patterns at some particular period because of their specific attributes (e.g., PoI, weather). On the other hand, the traffic series from two disjoint nodes may even show reverse patterns. As a result, only capturing shared patterns among all nodes is not enough for accurate traffic forecasting, and it is essential to maintain a unique parameter space for each node to learn node-specific patterns.</p><p>However, assigning parameters for each node will result in Θ ∈ R N ×C×F , which is too huge to optimize and would lead to over-fitting problem, especially when N is big. To solve the issue, we propose to enhance traditional GCN with a Node Adaptive Parameter Learning module, which draws insights from the matrix factorization. Instead of directly learning Θ ∈ R N ×C×F , NAPL learns two smaller parameter matrix: 1) a node-embedding matrix E G ∈ R N ×d , where d is the embedding dimension, and d &lt;&lt; N ; 2) a weight pool W G ∈ R d×C×F . Then, Θ can be generated by Θ = E G · W G . From the view of one node (e.g., node i), this process extracts parameters Θ i for i from a large shared weight pool W G according to the node embedding E i G , which can be interpreted as learning node specific patterns from a set of candidate patterns discovered from all traffic series. The same operation can also be used for b. Finally, the NAPL enhanced GCN (i.e., NAPL-GCN) can be formulaed as:</p><formula xml:id="formula_3">Z = (I N + D − 1 2 AD − 1 2 )XE G W G + E G b G (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Adaptive Graph Generation</head><p>Another problem lies in existing GCN-based traffic forecasting models, which require a pre-defined adjacent matrix A for the graph convolution operation. Existing work mainly utilizes distance function or similarity metrics to calculate the graph in advance. There are mainly two approaches for defining A: 1) distance function, which defines the graph according to the geographic distance among different nodes <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>; 2) similarity function, which defines the node proximity by measuring the similarity of the node attributes (e.g., PoI information) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref> or traffic series itself <ref type="bibr" target="#b2">[3]</ref>. However, these approaches are quite intuitive. The pre-defined graph cannot contain complete information about spatial dependency and is not directly related to prediction tasks, which may result in considerable biases. Besides, these approaches cannot be adapted to other domains without appropriate knowledge, making existing GCN-based models ineffective.</p><p>To solve the issue, we propose a Data Adaptive Graph Generation (DAGG) module to infer the hidden inter-dependencies from data automatically. The DAGG module first randomly initialize a learnable node embedding dictionaries E A ∈ R N ×de for all nodes, where each row of E A represents the embedding of a node and d e denotes the dimension of node embedding. Then, similar as defining the graph by nodes similarity, we can infer the spatial dependencies between each pair of nodes by multiplying E A and E T A :</p><formula xml:id="formula_4">D − 1 2 AD − 1 2 = sof tmax(ReLU (E A · E T A )) (5)</formula><p>where sof tmax function is used to normalize the adaptive matrix. Here, instead of generating A and calculating a Laplacian matrix, we directly generate D − 1 2 AD − 1 2 to avoid unnecessary and repeated calculations in the iterative training process. During training, E A will be updated automatically to learn the hidden dependencies among different traffic series and get the adaptive matrix for graph convolutions. Comparing with the self-adaptive adjacent matrix in <ref type="bibr" target="#b4">[5]</ref>, DAGG module is simpler and the learned E A has better interpret-ability. Finally, the DAGG enhanced GCN can be formulated as:</p><formula xml:id="formula_5">Z = (I N + sof tmax(ReLU (E A · E T A )))XΘ<label>(6)</label></formula><p>When dealing with extremely large graphs (i.e., N is huge), DAGG may require heavy computation cost. Graph partition and sub-graph training methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b36">37]</ref> could be applied to address the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Adaptive Graph Convolutional Recurrent Network</head><p>Except for the spatial correlations, traffic forecasting also involves complex temporal correlations. In this part, we introduce an Adaptive Graph Convolutional Recurrent Network (AGCRN), which integrates NAPL-GCN, DAGG, and Gated Recurrent Units (GRU) to capture both node-specific spatial and temporal correlations in traffic series. AGCRN replaces the MLP layers in GRU with our NAPL-GCN to learn node-specific patterns. Besides, it discoveries spatial dependencies automatically with the DAGG module. Formally:</p><formula xml:id="formula_6">A = sof tmax(ReLU (EE T )) z t = σ( A[X :,t , h t−1 ]EW z + Eb z r t = σ( A[X :,t , h t−1 ]EW r + Eb r h t = tanh( A[X :,t , r h t−1 ]EWĥ + Ebĥ h t = z h t−1 + (1 − z) ĥ t<label>(7)</label></formula><p>where X :,t and h t are input and output at time step t, [·] denotes the concate operation, z and r are reset gate and update gate, respectively. E, W z , W r , Wĥ, b z , b r , and bĥ are learnable parameters in AGCRN. Similar to GRU, all the parameters in AGCRN can be trained end-to-end with backpropagation through time. As can be observed from the equation, AGCRN unifies all the embedding matrix to be E instead of learning separate node embedding matrix in different NAPL-GCN layers and DAGG. This gives a strong regularizer to ensure the nodes embedding consistent among all GCN blocks and gives our model better interpretability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Multi-step traffic prediction</head><p>To achieve multi-step traffic prediction, we stack several AGCRN layers as an encoder to capture the node-specific spatial-temporal patterns and represents the input (i.e., historical data) as H ∈ R N ×do . Then, we can directly obtain the traffic prediction for the next τ steps of all nodes by applying a linear transformation to project the representation from R N ×do to R N ×τ . Here, we do not generate the output in the sequential manner as it would increase the time consumption significantly.</p><p>We choose L1 loss as our training objective and optimize the loss for multi-step prediction together. Thus, the loss function of AGCRN for multi-step traffic prediction can be formulated as:</p><formula xml:id="formula_7">L(W θ ) = i=t+τ i=t+1 |X :,i − X :,i |<label>(8)</label></formula><p>where W θ represents all the learnable parameters in the network, X :,i is the ground truth, and X :,i is the prediction of all nodes at time step i. The problem can be solved via back-propagation and Adam optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>To evaluate the performance of our work, we conduct experiments on two public real-world traffic datasets: PeMSD4 and PeMSD8 <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>. PeMS means Caltrans Performance Measure System (PeMS) <ref type="bibr" target="#b37">[38]</ref>, which measures the highway traffic of California in real-time every 30 seconds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Preprocess:</head><p>The missing values in the datasets are filled by linear interpolation. Then, both datasets are aggregated into 5-minute windows, resulting in 288 data points per day. Besides, we normalize the dataset by standard normalization method to make the training process more stable.</p><p>For multi-step traffic forecasting, we use one-hour historical data to predict the next hour's data, i.e., we organize 12 steps' historical data as input and the following 12 steps data as output. We split the datasets into training sets, validation sets, and test sets according to the chronological order. The split ratio is 6:2:2 for both datasets. Although our method does not need a pre-defined graph, we use the pre-defined graph for our baselines. Detailed dataset statistics are provided in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>To evaluate the overall performance of our work, we compare AGCRN with widely used baselines and state-of-the-art models, including 1) Historical Average (HA): which models the traffic as a seasonal process and uses the average of previous seasons (e.g., the same time slot of previous days) as the prediction; 2) Vector Auto-Regression (VAR) <ref type="bibr" target="#b38">[39]</ref>: a time series model that captures spatial correlations among all traffic series; 3) GRU-ED: an GRU-based baseline and utilize the encoderdecoder framework <ref type="bibr" target="#b39">[40]</ref> for multi-step time series prediction; 4) DSANet <ref type="bibr" target="#b40">[41]</ref>: a correlated time series prediction model using CNN networks for capturing temporal correlations with one time-series and self-attention mechanism for spatial correlations; 5) DCRNN <ref type="bibr" target="#b1">[2]</ref>: diffusion convolution recurrent neural network, which formulates the graph convolution with the diffusion process and combines GCN with recurrent models in an encoder-decoder manner for multi-step prediction; 6) STGCN <ref type="bibr" target="#b3">[4]</ref>: a spatio-temporal graph convolutional network that deploys GCN and temporal convolution to capture spatial and temporal correlations, respectively; 7) ASTGCN <ref type="bibr" target="#b5">[6]</ref>: attention-based spatio-temporal graph convolutional network, which further integrates spatial and temporal attention mechanisms to STGCN for capturing dynamic spatial and temporal patterns. We take its recent components to ensure the fairness of comparison; 8) STSGCN <ref type="bibr" target="#b10">[11]</ref>: Spatial-Temporal Synchronous Graph Convolutional Network that captures spatial-temporal correlations by stacking multiple localized GCN layers with adjacent matrix over the time axis.</p><p>All the deep-learning-based models, including our AGCRN, are implemented in Python with Pytorch 1.3.1 and executed on a server with one NVIDIA Titan X GPU card. We optimize all the models by Adam optimizer for a maximum of 100 epochs and use an early stop strategy with the patience of 15.</p><p>The best parameters for all deep learning models are chosen through a carefully parameter-tuning process on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overall Comparison</head><p>We deploy three widely used metrics -Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE) to measure the performance of predictive models. <ref type="table" target="#tab_0">Table 1</ref> presents the overall prediction performances, which are the averaged MAE, RMSE and MAPE over 12 prediction horizons, of our AGCRN and eight representative comparison methods. We can observe that: 1) GCN-based methods outperform baselines and self-attention-based DSANet, demonstrating the importance of modeling spatial correlations explicitly and the effectiveness of GCN in traffic forecasting; 2) our method further improves GCN-based methods with a significant margin. AGCRN brings more than 5% relative improvements to the existing best results in MAE and MAPE for both PeMSD4 and PeMSD8 dataset. <ref type="figure" target="#fig_1">Fig. 2</ref> further shows the prediction performance at each horizon in the PeMSD4 dataset. AGCRN balances short-term and long-term prediction well and achieves the best performance for almost all horizons (except for the first step). Besides, the performance of AGCRN deteriorate much slower than other GCN-based models (see appendix for similar results in the PeMSD8 dataset).</p><p>Overall, the results demonstrate that AGCRN can accurately capture the spatial and temporal correlations in the correlated traffic series and achieve promising predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>To better evaluate the performance of NAPL and DAGG, we conduct a comprehensive ablation study. The baseline for our ablation study is GCGRU, which integrates traditional GCN with GRU to capture spatial and temporal correlations. We construct NAPL-GCGRU by replacing traditional GCN with our NAPL-GCN and DAGG-GCGRU by replacing the pre-defined graph with the DAGG module. AGCCRN-I is the variant of our AGCRN, which does not unify the node embeddings but employs an independent node embedding matrix among different NAPL-GCN layers and DAGG. The experiments on the PeMSD4 dataset are illustrated in <ref type="figure" target="#fig_2">Fig. 3</ref>. We can observe that: 1) NAPL-GCGRU generally outperforms GCGRU and AGCRN-I outperforms DAGG-GCGRU, demonstrating the  necessity of capturing node-specific patterns. Moreover, NAPL mainly enhances the long-term (e.g., 30Min and 60 Min) prediction but slightly harms the short-term (e.g., 5Min and 15 Min) prediction. We conjecture the reason is that long-term prediction lacks enough useful information from historical observations and thus benefits from the specific node embedding learned by the NAPL module to deduce future patters. At the same time, short-term prediction can obtain enough information from historical observations. 2) DAGG-GCGRU improves GCGRU, and AGCRN-I beats NAPL-GCGRU. Both demonstrate the superiority of DAGG in inferring spatial correlations. The results also indicate that GCN-based methods can potentially be applied to more general correlated time series forecasting tasks with the help of our DAGG module, and pre-defining an adjacent matrix is not necessary; 3) AGCRN achieves the best performance, demonstrating that we can share the node embedding among all the modules and learn a unified node embedding for each node from the data.</p><p>Overall, our NAPL and DAGG modules can be deployed either separately and jointly, and they consistently boost the prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Model Analysis</head><p>Graph Generation To further investigate DAGG, we compare it with two variants: 1) DAGG-r, which removes the identity matrix in Eq. 6; 2) DAGG-2 which mimics the second-order Chebyshev polynomial expansion in GCN <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b32">33]</ref> with our learned D − 1 2 AD − 1 2 . The backbone network is AGCRN-I, which does not share the embedding matrix among NAPL-GCN and DAGG to avoid the constraints from the NAPL module. As shown in <ref type="table" target="#tab_1">Table 2</ref> (where DAGG-1 follows Eq. 6), removing the identity matrix from DAGG significantly harms the prediction performance, which presents the  importance of highlighting the self-information manually in prediction. Besides, DAGG-2 achieves similar performance with DAGG-1, which is consistent with the existing works <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b1">2]</ref> using pre-defined graphs. The results reveal that the generated graph Laplacian matrix D − 1 2 AD − 1 2 shares similar property as the pre-defined graph in Chebyshev polynomial expansion. Embedding Dimension One key parameter in AGCRN is the dimensions of the node embedding, which not only influences the quality of the learned graph but also decides the parameter diversity in NAPL-GCN layers. <ref type="figure" target="#fig_3">Fig. 4</ref> shows the effects of different embedding dimensions to AGCRN on the PeMSD4 dataset. AGCRN obtains relatively good performance for all the tested embedding dimensions, which shows the robustness of our methods. Besides, AGCRN achieves the best performance when the embedding dimension is set to 10. Both an excessively small and large node embedding dimension will lead to weaker performance. On the one hand, node embedding with a larger dimension can contain more information and thus help our DAGG module to deduce more accurate spatial correlations. On the other hand, a larger node embedding dimension will significantly increase the parameter numbers in the NAPL module, making the model harder to optimize and causing over-fitting. Overall, it would be a good practice for AGCRN to find a suitable node embedding dimension and balance the model's performance and complexity.</p><p>Computation Cost To evaluate the computation cost, we compare the parameter numbers and training time of AGCRN with DCRNN, STGCN, and ASTGCN on the PeMSD4 dataset in <ref type="table" target="#tab_2">Table 3</ref>. When he node embedding dimension is set to 10, AGCRN has five times more parameters than the DCRNN model as a sacrifice for learning node-specific patterns. In terms of the training time, AGCRN runs slightly faster than DCRNN as we generate all predictions directly instead of the iterative manner in DCRNN. STGCN is the fastest thanks to the temporal convolution structure. However, it will require more parameters and training time to add spatial and temporal attention mechanisms to STGCN for learning more accurate spatial-temporal patterns (e.g., ASTGCN). Considering the significant performance improvement (as shown in <ref type="table" target="#tab_0">Table 1</ref>), the computation cost of AGCRN is moderate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Multivariate/correlated time series prediction is a fundamental task for many applications, such as epidemic transmission forecasting <ref type="bibr" target="#b41">[42]</ref>, meteorology (e.g., air quality, rainfall) prediction <ref type="bibr" target="#b42">[43]</ref>, stock forecasting <ref type="bibr" target="#b43">[44]</ref>, and sale prediction <ref type="bibr" target="#b44">[45]</ref>. While our work is motivated by the traffic forecasting task, the proposed two adaptive modules and our AGCRN model may also be adapted to a wide variety of multivariate/correlated time series predictive tasks separately or jointly. It is possible to automatically discover the inter-dependency among different correlated series from data, which bridges the gap between graph-based prediction models and general correlated time series forecasting problems that cannot pre-define the graph easily. Our future work will focus on examining the scale-ability of our work from two perspectives: 1) data perspective -validating the performance of AGCRN on more time series prediction tasks; 2) model perspective -adapting NAPL and DAGG to more GCN-based traffic forecasting models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose to enhance the traditional graph convolutional network with node adaptive parameter learning and data-adaptive graph generation modules for learning node-specific patterns and discovering spatial correlations from data, separately. Based on the two modules, we further propose the Adaptive Graph Convolutional Recurrent Network, which can capture node-specific spatial and temporal correlations in time-series data automatically without a pre-defined graph. Extensive experiments on multi-step traffic forecasting tasks demonstrate the effectiveness of both AGCRN and the proposed adaptive modules. This work sheds light on applying GCN-based models in correlated time series forecasting by inferring the inter-dependency from data and reveals that learning node-specific patterns is essential for understanding correlated time series data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>In general, this work enables more accurate traffic forecasting, which facilities the higher-lever traffic scheduling such as taxi dispatch and route planing. In this way, our work can help save time for travelers, improve efficiency and income for transport operators, and save energy consumption. In a broad sense, adaptability is desirable in correlated time series analysis for broad social and business applications in the era of big data. The proposed adaptive modules enable elevated robustness of data analysis and relevant applications based on dynamic, interdependent, time-series data. This research generally supports better modeling and analysis of multiple channels of data based on graph structures with complex explicit and implicit correlations. It has implications and potentially accelerates the research progress in address many world-scale economic and societal issues that rely on complex times series data, such as predictions of influenza outbreak, economic growth, and climate change. A potential negative impact of this work is the fairness problem in the ride-sharing platforms. In the case that cabs supply cannot guarantee demand, platforms may emphasize the predicted high-demand areas too much, which would increase the waiting time of travelers in the low-demand areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>To support reproducibility of the results in this paper, we have submitted our code and datasets as the supplementary information. Here, we will present the datasets statistics, evaluation metrics, implementation details, and more results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Datasets Statistics</head><p>The dataset used in our experiments (namely PeMSD4 dataset and PeMSD8 dataset) contain the traffic flow data measured by road traffic sensors. As introduced in Section 3.1, we formulate the traffic forecasting problem on a graph where each node corresponds to a traffic sensor. Our ASTGCN can infer spatial proximity from data by DAGG module automatically. Thus is does not require pre-defining the adjacent matrix. For graph-based baselines, we reuse the pre-defined graph given in <ref type="bibr" target="#b10">[11]</ref> to capture spatial correlations. The connectivity between different nodes is determined by the actual road network. If two monitors are on the same road, then they are considered connected. The statistics about the two datasets are shown in <ref type="table" target="#tab_3">Table 4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Evaluation Metrics</head><p>We use three evaluation metrics to measure the performance of predictive models. Let X :,i ∈ R N ×1 be the ground truth traffic of all nodes at time step i, X :,i ∈ R N ×1 be the predicted values, and Ω be indices of observed samples. The metrics are defined as follows.</p><p>Mean Absolute Error (MAE)</p><formula xml:id="formula_8">M AE = 1 |Ω| i∈Ω |X :,i − X :,i | Root Mean Square Error (RMSE) RM SE = 1 |Ω| i∈Ω (X :,i − X :,i ) 2</formula><p>Mean Absolute Percentage Error (MAPE)</p><formula xml:id="formula_9">M AP E = 1 |Ω| i∈Ω X :,i − X :,i X :,i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Implementation Details</head><p>The details of the baselines are as follows:</p><p>• HA: the historical average model operates on each traffic series separately, and it averages all the historical traffic at the same time slot to predict current traffic. Historical Average does not depend on recent data and thus the performance is invariant for 12 forecasting horizons.</p><p>• VAR: we implement the VAR model based on statsmodel python package and search the number of lags among {1, 3, 6, 9, 12}. The number of lags is set to 12 for both PeMSD4 and PeMSD8 datasets.</p><p>• GRU-ED: we implement an encoder-decoder model based on GRU with Pytorch. GRU-ED contains two layers of GUR for both encoder and decoder; each layer has 128 hidden units. A fully-connected layer projects the output of the decoder at each time step to a prediction. We set the batch size to 64, learning rate to 0.001, and the loss function to L1 when training the model.</p><p>• DSANet: we reuse the code released in the original paper and tune the parameters carefully for our dataset according to the validation error. We set the CNN filter size to 3, number of CNN kernels to 64, number of attention blocks to 3, dropout probability to 0.1, and the learning rate to 0.001.</p><p>• DCRNN: similar to GRU-ED, the DCRNN model also deploys the ecoder-decoder framework for multi-step traffic forecasting. It contains two-layers DCGRU for both encoder and decoder. We set the number of GRU hidden units to 64, the maximum step of randoms walks to 3, the initial learning rate to 0.01. We decrease the learning rate tby 1 10 every 20 epochs starting from 10 th epochs.</p><p>• STGCN: STGCN contains two spatial-temporal convlutional blocks, one temporal convolutional layer and one output layer. Different from the original STGCN, we implement the output layer to generate prediction for all horizons at one time (instead of one step per time). Following the practice of STGCN, we set the size of temporal kernel to 2, the order of Chebyshev polynomials to 1, and the filter number to 64 for both CNN and GCN. Besides, We set the learning rate to 0.003 for the PeMSD4 dataset and 0.001 for the PeMDS8 dataset.</p><p>• ASTGCN: The orginal ASTGCN model ensembles three bolocks to process the recent, dailyperiodic, and weekly-periodic segments for capturing multi-scale temporal correlations. We take its recent component that only uses recent input segments for a fair comparison. For implementation, we reuse the code and parameters released in the original paper and train the model with a L1 loss function.</p><p>• STSGCN: We reuse the results reported in the original paper directly for our overall comparison as it conducts experiments on the PeMSD4 and PeMSD8 datasets with the same evaluation metrics. AGCRN: Our model stacks two layers AGCRN to capture the node-specific spatial and temporal dynamics. The output at the last step is used as the representation of the historical traffic series, which is directly mapped to the predictions for all horizons by linear transformation . For the hype-parameters, we set the hidden unit to 64 for all the AGCRN cells and the batch size also to 64. We search the learning rate among {0.0007, 0.001, 0.003, 0.005, 0.009}, the embedding dimension among {1, 3, 5, 10, 15, 20, 30} for the PeMSD4 dataset and among {1, 2, 3, 5, 8, 10, 15} for the PeMSD8 dataset. Finally, the learning rate is set to 0.003 for both datasets, and the embedding dimension is to 10 for the PeMSD4 dataset and 2 for the PeMSD8 dataset. Besides, we choose L1 Loss as the loss function and do not use any non-mentioned optimization tricks such as learning rate decay, weights decay, or gradient normalization when training our model.</p><p>For all the deep learning models, we optimize them with the Adam optimizer for 100 epochs and use an early stop strategy with the patience of 15 by monitoring the loss in the validation set.   <ref type="figure" target="#fig_4">5</ref> presents the prediction performance of our AGCRN and baselines at each horizon on the PeMSD8 dataset. STSGCN is not included because the step-wise results of it are not reported in <ref type="bibr" target="#b10">[11]</ref>. Besides, we omit HA as it's performance is consistent for all 12 horizons. Our AGCRN model outperforms existing baselines with a significant margin, especially for long-term predictions. Besides, the performance of AGCRN deteriorates much slower than the other GCN-based models. The observations are similar on the PeMSD4 dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Multi-step Prediction on PeMSD8</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Prediction Visualization</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>PeMSD4:</head><label></label><figDesc>The PeMSD4 dataset refers to the traffic flow data in the San Francisco Bay Area. There are 307 loop detectors selected within the period from 1/Jan/2018 to 28/Feb/2018. PeMSD8: The PeMSD8 dataset contains traffic flow information collected from 170 loop detectors on the San Bernardino area from 1/Jul/2016 -31/Aug/2016.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Prediction performance comparison at each horizon on the PeMSD4 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Ablation study on the PeMSD4 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Influence of the embedding dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Prediction performance comparison at each horizon on the PeMSD8 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.</head><label></label><figDesc>Fig. 5 presents the prediction performance of our AGCRN and baselines at each horizon on the PeMSD8 dataset. STSGCN is not included because the step-wise results of it are not reported in [11]. Besides, we omit HA as it's performance is consistent for all 12 horizons. Our AGCRN model outperforms existing baselines with a significant margin, especially for long-term predictions. Besides, the performance of AGCRN deteriorates much slower than the other GCN-based models. The observations are similar on the PeMSD4 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Traffic forecasting visualization. Traffic forecasting visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Overall prediction performance of different methods on the PeMSD4 dataset and PeMSD8 dataset, results with * are reported performance in the paper used the same datasets and results with __ are the best performance achieved by baselines. (smaller value means better performance)</figDesc><table><row><cell>Model</cell><cell>Dataset</cell><cell></cell><cell>PeMSD4</cell><cell></cell><cell></cell><cell>PeMSD8</cell></row><row><cell></cell><cell>Metrics</cell><cell>MAE</cell><cell>RMSE</cell><cell>MAPE</cell><cell>MAE</cell><cell>RMSE</cell><cell>MAPE</cell></row><row><cell></cell><cell>HA</cell><cell>38.03</cell><cell>59.24</cell><cell>27.88%</cell><cell>34.86</cell><cell>52.04</cell><cell>24.07%</cell></row><row><cell></cell><cell>VAR</cell><cell>24.54</cell><cell>38.61</cell><cell>17.24%</cell><cell>19.19</cell><cell>29.81</cell><cell>13.10%</cell></row><row><cell cols="2">GRU-ED</cell><cell>23.68</cell><cell>39.27</cell><cell>16.44%</cell><cell>22.00</cell><cell>36.23</cell><cell>13.33%</cell></row><row><cell cols="2">DSANet [41]</cell><cell>22.79</cell><cell>35.77</cell><cell>16.03%</cell><cell>17.14</cell><cell>26.96</cell><cell>11.32%</cell></row><row><cell cols="2">DCRNN [2]</cell><cell>21.22</cell><cell>33.44</cell><cell>14.17%</cell><cell>16.82</cell><cell>26.36</cell><cell>10.92%</cell></row><row><cell cols="2">STGCN [4]</cell><cell>21.16</cell><cell>34.89</cell><cell>13.83%</cell><cell>17.50</cell><cell>27.09</cell><cell>11.29%</cell></row><row><cell cols="2">ASTGCN [6]</cell><cell>22.93</cell><cell>35.22</cell><cell>16.56%</cell><cell>18.25</cell><cell>28.06</cell><cell>11.64%</cell></row><row><cell cols="2">STSGCN [11]</cell><cell>21.19*</cell><cell cols="3">33.65* 13.90%* 17.13*</cell><cell cols="2">26.86* 10.96%*</cell></row><row><cell cols="2">AGCRN (ours)</cell><cell>19.83</cell><cell>32.26</cell><cell>12.97%</cell><cell>15.95</cell><cell>25.22</cell><cell>10.09%</cell></row><row><cell cols="8">Improvements +6.29% +3.52% +6.22% +5.17% +4.32% +7.60%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Analysis of graph generation process on the PeMSD4 dataset. 21.85 35.03 14.96% 26.54 41.07 17.91% 23.35 37.07 15.82% DAGG-1 19.15 30.65 13.15% 21.98 34.91 14.82% 20.18 32.30 13.70% DAGG-2 19.26 31.20 13.06% 21.58 34.73 14.49% 20.11 32.56 13.58%</figDesc><table><row><cell>Model</cell><cell>15 Min</cell><cell>60 Min</cell><cell>Average</cell></row><row><cell></cell><cell cols="3">MAE RMSE MAPE MAE RMSE MAPE MAE RMSE MAPE</cell></row><row><cell>DAGG-r</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>The computation cost on the PeMSD4 dataset, "dim" means the dimension of E.</figDesc><table><row><cell>Model</cell><cell cols="2"># Parameters Training Time (epoch)</cell></row><row><cell>DCRNN</cell><cell>149057</cell><cell>36.39 s</cell></row><row><cell>STGCN</cell><cell>211596</cell><cell>16.36 s</cell></row><row><cell>ASTGCN</cell><cell>450031</cell><cell>49.47 s</cell></row><row><cell>AGCRN (dim=2)</cell><cell>150386</cell><cell>33.88 s</cell></row><row><cell>AGCRN (dim=10)</cell><cell>748810</cell><cell>35.56 s</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Summary statistics of the PeMSD4 and PeMSD8 dataset</figDesc><table><row><cell>Dataset</cell><cell>Time Span</cell><cell cols="5">#Nodes #Edges #Samples Data Range Median</cell></row><row><cell cols="2">PeMSD4 1/Jan/2018 -28/Feb/2018</cell><cell>307</cell><cell>340</cell><cell>16992</cell><cell>0 ∼919</cell><cell>180</cell></row><row><cell cols="2">PeMSD8 1/Jul/2016 -31/Aug/2016</cell><cell>170</cell><cell>277</cell><cell>17856</cell><cell>0 ∼1147</cell><cell>215</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Streets: A novel camera network dataset for traffic flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corey</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10242" to="10253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rose</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Sixth International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stg2seq: spatial-temporal graph to sequence model for multi-step passenger demand forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Kanhere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1981" to="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph wavenet for deep spatial-temporal graph modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1907" to="1913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Attention based spatialtemporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Passenger demand forecasting with multi-task convolutional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Kanhere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Joint modeling of local and global temporal dynamics for multivariate time series forecasting with missing values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charu</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10273</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep multi-view spatial-temporal network for taxi demand prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitian</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinghua</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deepar: Probabilistic forecasting with autoregressive recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Flunkert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Gasthaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Januschowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spatial-temporal sychronous graph convolutional networks: A new framework for spatial-temporal network data forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Gman: A graph multiattention network for traffic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanpan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhong</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08415</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Urban traffic prediction from spatio-temporal data using deep meta learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyi</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1720" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spatiotemporal multi-graph convolution network for ride-hailing demand forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3656" to="3663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning of spatial data via multimodal embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Porter</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Knowledge adaption for demand prediction based on multi-task memory neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S Travis</forename><surname>Waller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multivariate time series imputation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1596" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep state space models for time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><forename type="middle">W</forename><surname>Syama Sundar Rangapuram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Gasthaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyang</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Januschowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7785" to="7794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Brits: Bidirectional recurrent imputation for time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6775" to="6785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modeling long-and short-term temporal patterns with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Borovykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Bohte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelis W</forename><surname>Oosterlee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04691</idno>
		<title level="m">Conditional time series forecasting with convolutional neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01271</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Think globally, act locally: A deep neural network approach to high-dimensional time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiang-Fu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjit S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4838" to="4847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenrui</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunmiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.02908</idno>
		<title level="m">Spatial-temporal transformer networks for traffic flow forecasting</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">You may not need order in time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shurui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueying</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09620</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dnn-based prediction model for spatio-temporal data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuwen</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems</title>
		<meeting>the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal residual networks for citywide crowd flows prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional and recurrent networks for citywide passenger demand prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Kanhere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2293" to="2296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">How to build a graph-based deep learning architecture in traffic domain: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexia</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanjuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kejiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengzhong</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11691</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genze</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinze</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanming</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baocai</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08555</idno>
		<title level="m">A comprehensive survey on traffic prediction</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S Yu</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4800" to="4810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Graph-partitioningbased diffusion convolution recurrent neural network for large-scale traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanwi</forename><surname>Mallick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><surname>Balaprakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Rask</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Macfarlane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11197</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Freeway performance measurement system: mining loop detector data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Skabardonis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pravin</forename><surname>Varaiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanfeng</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">1748</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="102" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Vector autoregressive models for multivariate time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Zivot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modeling Financial Time Series with S-Plus®</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="385" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoderdecoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dsanet: Dual self-attention network for multivariate time series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siteng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuehan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ao</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2129" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Epideep: Exploiting embeddings for epidemic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bijaya</forename><surname>Adhikari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naren</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B Aditya</forename><surname>Prakash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="577" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-group encoder-decoder networks to fuse heterogeneous data for next-day air quality prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duanfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hannigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4341" to="4347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multi-task recurrent neural networks and higherorder markov random fields for stock price movement prediction: Multi-task rnn and higer-order mrfs for stock price classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1141" to="1151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A deep neural framework for sales forecasting in e-commerce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunwei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuming</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="299" to="308" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
