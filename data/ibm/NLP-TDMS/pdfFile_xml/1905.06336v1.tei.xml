<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sina Weibo</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongwen</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sina Weibo</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sina Weibo</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Click through rate (CTR) estimation is a fundamental task in personalized advertising and recommender systems. Recent years have witnessed the success of both the deep learning based model and attention mechanism in various tasks in computer vision (CV) and natural language processing (NLP). How to combine the attention mechanism with deep CTR model is a promising direction because it may ensemble the advantages of both sides. Although some CTR model such as Attentional Factorization Machine (AFM) has been proposed to model the weight of second order interaction features, we posit the evaluation of feature importance before explicit feature interaction procedure is also important for CTR prediction tasks because the model can learn to selectively highlight the informative features and suppress less useful ones if the task has many input features. In this paper, we propose a new neural CTR model named Field Attentive Deep Fieldaware Factorization Machine (FAT-DeepFFM) by combining the Deep Field-aware Factorization Machine (DeepFFM) with Compose-Excitation network (CENet) field attention mechanism which is proposed by us as an enhanced version of Squeeze-Excitation network (SENet) to highlight the feature importance. We conduct extensive experiments on two real-world datasets and the experiment results show that FAT-DeepFFM achieves the best performance and obtains different improvements over the state-of-the-art methods. We also compare two kinds of attention mechanisms (attention before explicit feature interaction vs. attention after explicit feature interaction) and demonstrate that the former one outperforms the latter one significantly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>CTR estimation is a fundamental task in personalized advertising and recommender systems. Many models have been proposed to resolve this problem such as Logistic Regression (LR) <ref type="bibr" target="#b10">[McMahan et al., 2013]</ref>, Polynomial-2 (Poly2) <ref type="bibr" target="#b9">[Juan et al., 2016]</ref>, tree-based models <ref type="bibr" target="#b7">[He et al., 2014]</ref>, tensorbased models <ref type="bibr" target="#b10">[Koren et al., 2009]</ref>, Bayesian models <ref type="bibr" target="#b4">[Graepel et al., 2010]</ref>, and Field-aware Factorization Machines (FFMs) <ref type="bibr" target="#b9">[Juan et al., 2016]</ref>. Deep learning techniques have shown promising results in many research fields such as computer vision <ref type="bibr" target="#b10">[Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b8">He et al., 2016]</ref>, speech recognition <ref type="bibr" target="#b5">[Graves et al., 2013]</ref> and natural language understanding <ref type="bibr" target="#b10">[Mikolov et al., 2010;</ref><ref type="bibr" target="#b2">Cho et al., 2014]</ref>. As a result, employing DNNs for CTR estimation has also been a research trend in this field <ref type="bibr" target="#b0">Cheng et al., 2016;</ref><ref type="bibr" target="#b11">Xiao et al., 2017;</ref><ref type="bibr" target="#b6">Guo et al., 2017;</ref><ref type="bibr" target="#b10">Lian et al., 2018;</ref><ref type="bibr" target="#b11">Wang et al., 2017;</ref><ref type="bibr">He and Chua, 2017]</ref>. Some deep learning based models have been introduced and achieved success such as Factorisation-Machine Supported Neural Networks(FNN) , Attentional Factorization Machine (AFM) <ref type="bibr" target="#b11">[Xiao et al., 2017</ref><ref type="bibr">],wide &amp; deep[Cheng et al., 2016</ref>,DeepFM <ref type="bibr" target="#b6">[Guo et al., 2017]</ref> etc. On the other side, Attention mechanism can filter out the uninformative features from raw inputs and attention-based model has also been widely used and shown promising results on various tasks. How to combine the attention mechanism with deep CTR model is a promising direction because it may ensemble the advantages of both sides. Although some CTR model such as Attentional Factorization Machine <ref type="bibr" target="#b11">[Xiao et al., 2017]</ref> (AFM) has been proposed to model the weight of second order interaction features, we think the feature importance evaluation before explicit feature interaction is also important for CTR prediction tasks because the model can learn to selectively highlight the informative features and suppress less useful ones if the task has many input features.</p><p>In this work, we propose a new neural CTR model named Field ATtentive Deep Field-aware Factorization Machines (FAT-DeepFFM) by combining the neural field-aware factorization machines <ref type="bibr">[Yang et al., 2017]</ref> with field attention mechanism. Specifically, what we do in this work is to introduce the Compose-Excitation network (CENet) which is an enhanced version of Squeeze-Excitation network (SENet) <ref type="bibr">[Hu et al., 2017]</ref> like attention into DeepFFM model in order to improve the representational ability of deep CTR network. We aim to dynamically capture each feature's importance by explicitly modeling the interdependencies among all different features of an input instance before factorization machines's feature interaction procedure. Our goal is to use the CENet like attention mechanism to perform feature recali-bration through which it can learn to selectively highlight the informative features and suppress less useful ones effectively.</p><p>The contributions of our work are summarized as follows: 1) We propose a novel model named FAT-DeepFFM that enhances the DeepFFM model by introducing the CENet field attention to dynamically capture each feature's importance before explicit feature interaction procedure. 2) We compare two different kinds of attention mechanisms(attention on features before explicit feature interaction vs. attention on cross features after explicit feature interaction ) and the experiment results demonstrate that the former one outperforms the latter one significantly. 3) We conduct extensive experiments on two real-world datasets and the experiment results show that FAT-DeepFFM achieves the best performance and obtains different improvements over the state-of-the-art methods. The rest of this paper is organized as follows. Section 2 introduces some related works which are relevant with our proposed model. We introduce our proposed Field Attentive Deep Field-aware Factorization Machine (FAT-DeepFFM) model in detail in Section 3. The experimental results on Criteo and Avazu datasets are presented and discussed in Section 4. Section 5 concludes our work in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Factorization Machines and Field-aware Factorization Machine</head><p>Factorization Machines (FMs) <ref type="bibr" target="#b11">[Rendle, 2010]</ref> and Fieldaware Factorization Machines (FFMs) <ref type="bibr" target="#b9">[Juan et al., 2016]</ref> are two of the most successful CTR models. FMs use the dot product of two embedding vectors to model the effect of pairwise feature interactions. FFMs extended the ideas of Factorization Machines by additionally leveraging the field information and won two competitions hosted by Criteo and Avazu. When one feature interacts with other features from different fields, FFMs will learn different embedding vectors for each feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Learning based CTR Models</head><p>With the great success of deep learning in many research fields such as Computer Vision and Natural language processing, many deep learning based CTR models have also been proposed in recent years. How to effectively model the feature interactions is the key factor for most of these neural network based models.  <ref type="bibr" target="#b10">[Lian et al., 2018</ref>] also models the loworder and high-order feature interactions in an explicit way by proposing a novel Compressed Interaction Network (CIN) part.</p><p>Our approach is based on neural FFM which was firstly proposed by <ref type="bibr">Yang[Yang et al., 2017]</ref> in Tencent Social Ads contest . It can be regarded as replacing the FM part of DeepFM with FFM and we will describe the model in detail in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Attentive CTR Models</head><p>Attention mechanism is motivated by human visual attention and it can filter out the uninformative features from raw inputs by reducing the side effects of noisy data. Attention-based model has been widely used and shown promising results on tasks such as speech recognition and machine translation. Attention mechanism is also introduced in some CTR models. For example, Attentional Factorization Machine (AFM) <ref type="bibr" target="#b11">[Xiao et al., 2017]</ref> improves FM by discriminating and learning the importance of different feature interactions from data via a neural attention network. DIN  represents users' diverse interests with an interest distribution and designs an attention-like network structure to locally activate the related interests according to the candidate ad.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Field Attentive DeepFFM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DeepFFM</head><p>Our work initially aims at introducing the FFM model into neural CTR systems. However, a similar effort to ours has been reported by Yang etc. <ref type="bibr">[Yang et al., 2017]</ref> in Tencent Social Ads competition 2017. The authors report substantial gains after using neural FFM in their CTR prediction system. Neural FFM was quite successful in that competition: the 3rd place winner solution was based on this single Model and the ensemble version won the 1rd place in the competition. Because it's hard to find the detailed technical descriptions about this model, we will firstly introduce the neural FFM which will be called DeepFFM model in this paper.</p><p>As we all know, FMs <ref type="bibr" target="#b11">[Rendle, 2010]</ref> model interactions between features i and j as the dot products of their corresponding embedding vectors as follows:</p><formula xml:id="formula_0">y(x) = w 0 + m i=1 w i x i + m i=1 m j=i+1 v i , v j x i x j<label>(1)</label></formula><p>An embedding vector v i ∈ R k for each feature is learned by FM, k is a hyper-parameter which is usually a small integer and m is the feature number. However, FM neglects the fact that a feature might behave differently when it interacts with features from other fields. To explicitly take this difference into consideration, Field-aware Factorization Machines (FFMs) learn extra n-1 embedding vectors for each feature(here n denotes field number):</p><formula xml:id="formula_1">y(x) = w 0 + m i=1 w i x i + m i=1 m j=i+1 v ij , v ji x i x j (2)</formula><p>where v ij ∈ R k denotes the embedding vector of the j-th entry of feature i when feature i is interacting with fields j. k is the embedding size. As depicted in <ref type="figure" target="#fig_0">Figure 1</ref>, DeepFFM is designed to embody the idea of FFM through neural network. An input instance is firstly transformed into a high-dimensional sparse features via one-hot encoding to denote the raw feature input. The following embedding matrix layer is fully connected with sparse input layer to compress a raw feature to a low dimensional, dense real-value matrix. Specifically, for feature i, a corresponding 2-dimensional embedding matrix</p><formula xml:id="formula_2">EM i = [v i1 , v i2 , · · · , v ij , · · · , v in ]</formula><p>with size k × n is used to measure its impact of interactions with other features, where v ij ∈ R k refers to the j-th embedding vector of field i, n is the number of fields and k is the size of embedding vector. So it's obvious that embedding matrix layer EM is a 3-dimensional matrix with size k × n × n because we have n fields and each field has one corresponding 2-dimensional embedding matrix.</p><p>The following feature interaction layer tries to capture the two way feature interactions between any pair of features from different fields on the embedding matrix EM . Denoting the feature interaction layer as vector A, we have two different types of feature interaction approaches: inner-product version and Hadamard-product version. We can formalize two methods in this layer as follows:</p><formula xml:id="formula_3">A = [v 12 ⊕ v 21 , · · · , v ij ⊕ v ji , · · · , v (n−1)n ⊕ v n(n−1) ] Inner P roduct A = [v 12 ⊗ v 21 , · · · , v ij × v ji , · · · , v (n−1)n ⊗ v n(n−1) ] Hadamard P roduct</formula><p>where n is field number, v ij ⊕ v ji means the inner product of two embedding vectors as a scalar v ij , v ji and v ij × v ji refers to the Hadamard product of two embedding vectors as following vector:</p><formula xml:id="formula_4">v ij ⊕ v ji = [v 1 ij · v 1 ji , v 2 ij · v 2 ji , · · · , v k ij · v k ji ]</formula><p>where k is the size of embedding vector v ji . Notice that j &gt; i is required in order to avoid the repeated computation. We can see from here that feature interaction layer A is a wide concatenated vector and the size of this vector is n(n−1)/2 if we adopt inner-product version while the size is kn(n − 1)/2 if the Hadamard product version is adopted.</p><p>Multiple hidden layer is a feed-forward neural network on the feature interaction layer to implicitly learn high-order feature interactions. Denote the output of the feature interaction layer as vector and we can feed it into hidden layer of feedforward neural network. So the forward process is :</p><formula xml:id="formula_5">x 1 = σ(W 1 A + b 1 ) (3) x l = σ(W l x 1−1 + b l )<label>(4)</label></formula><p>where l is the layer depth, σ is an activation function, and x l is the output of the l-th hidden layer. Adding the linear part, the output unit of DeepFFM behaves as follows:</p><formula xml:id="formula_6">y(X) = σ(W 1inear x linear + W l+1 x l + b l+1 )<label>(5)</label></formula><p>where σ is the sigmoid function, x linear is the raw features, x l is the output of multiple hidden layer, W 1inear , W l+1 and b l+1 are learnable parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CENet Field Attention on Embedding Matrix Layer</head><p>Hu proposed the "Squeeze-and-Excitation Network" (SENet) <ref type="bibr">[Hu et al., 2017]</ref> to improve the representational power of a network by explicitly modeling the interdependencies between the channels of convolutional features in various image classification tasks. The SENet is proved to be successful in image classification tasks and won first place in ILSVRC 2017 classification task. Our work is inspired by SENet's success in computer vision field. To improve the representational ability of deep CTR network, we introduce the Compose-Excitation network (CENet) attention mechanism which is an enhanced version of SENet into DeepFFM model on embedding matrix Layer. We aim to dynamically capture each feature's importance by explicitly modeling the interdependencies among all different features before FM's feature interaction procedure. Our goal is to use the CENet attention mechanism to perform feature recalibration through which it can learn to selectively highlights the informative features and suppress less useful ones.</p><p>It can be seen from <ref type="figure" target="#fig_1">Figure 2</ref> that the CENet like field attention mechanism involves two phases: Compose phase and Excitation phase. The first phase calculates "summary statistics" of each embedding vector of each field by composing all the information of one embedding vector into a simple feature descriptor; the second phase applies attentive transformations to these feature descriptors and then rescales the original embedding matrix using the calculated attention values. </p><formula xml:id="formula_7">Compose Phase: Let EM i = [v i1 , v i2 , · · · , v ij , · · · , v in ] de- notes the 2-dimensional k × n embedding matrix of field i,</formula><p>where v ij ∈ R k refers to the j-th embedding vector of field i, n is the number of fields and k is the size of embedding vector. In this phase we compose the embedding vector v ij into one single number to represent the summary information of the feature. This can be achieved by using 1 × 1 convolution <ref type="bibr" target="#b11">[Szegedy et al., 2016;</ref><ref type="bibr" target="#b3">Chollet, 2017</ref>] to generate feature-wise statistics instead of those squeeze operations such as global max pooling or sum operation commonly used in SENet. The 1 × 1 convolution, also called a pointwise convolution, is responsible for building new features through computing linear combinations of one input feature embedding. In SENet, we generate a statistic vector z ∈ R n for field i by shrinking each embedding vector, where the f-th element of z i is z if ∈ R which can be calculated by:</p><formula xml:id="formula_8">z if = F sq (v if ) = max 1≤t≤k v t if</formula><p>Global M ax P ooling <ref type="formula">(6)</ref> Here, k means the embedding size of each embedding vector.</p><p>The most commonly used squeeze operation is global max pooling in CV field which can capture the strongest feature in corresponding channel. We change the method in this phase by using 1 × 1 convolution because we posit each position in feature embedding vector is informative in CTR task. So the 1 × 1 convolution can introduce parameters to learn the composing weight of each position in feature embedding. The 1 × 1 convolution is calculated as follows:</p><formula xml:id="formula_9">z if = conv1d(U if , v if ) = Relu(U if v if )<label>(7)</label></formula><p>where U if is the convolution weight, the size of convolution kernal is 1 × 1, the number of filters is 1 and the activation function is set to 'Relu'. Excitation phase: After the first phase, the embedding matrix of field i EM i = [v i1 , v i2 , · · · , v ij , · · · , v in ] has been transformed into a descriptor vector DV i = [z i1 , z i2 , · · · , z ij , · · · , z in ] . We have n different fields, so we summarize all the descriptors by concatenating each descriptor vector as follows:</p><formula xml:id="formula_10">D = concate(DV 1 , DV 2 , · · · , DV n )<label>(8)</label></formula><p>where the size of vector D is n 2 . To calculate the attention from descriptor vector , two fully connected (FC) layers are used. The first FC layer is a dimensionality-reduction layer with parameters W 1 with reduction ratio r which is a hyper-parameter and it uses ReLU as nonlinear function. The second FC layer increases dimensionality with parameters W 2 , which is equal to dimension of descriptor vector D and it also uses ReLU as nonlinear activation function. Formally, the field attention is calculated as follows:</p><formula xml:id="formula_11">S = F ex (D, W ) = δ(W 2 δ(W 1 D))<label>(9)</label></formula><p>where δ refers to the ReLU function, W 1 ∈ R n 2 r ×n 2 and W 1 ∈ R n 2 × n 2 r ,the size of attention vector S is n 2 . The activation of the ReLU function is used as the final field attention value without softmax normalization operation because we want to encourage multiple features to be important instead of just few of them. Then the values in original embedding matrix EM i of field i are rescaled by the accordingly calculated field attention vector S i as follows:</p><formula xml:id="formula_12">AEM i = F scale (S i , EM i ) = [S i1 ·v i1 , · · · , S ij ·v ij , · · · , S in ·v in ]</formula><p>(10) where F scale (S i , EM i ) refers to vector-wise multiplication between embedding vector v ij and the scalar S ij . The bigger attention value S ij implies that the model dynamically identifies an important feature and this attention value is used to boost the original embedding vector v ij . On the contrary, small attention value S ij will suppress the uninformative features or even noise by decreasing the values in the corresponding embedding vector v ij .</p><p>After the compose phase and excitation phase, we have a new 3-dimensional embedding matrix AEM with size k ×n×n, which is equal to the size of the original embedding matrix EM . We call the new embedding matrix attentive embedding layer in our paper. As discussed in Section 3.2, the CENet attention mechanism can perform feature recalibration through which it can learn to selectively highlights the informative features and suppress less useful ones. We can enhance DeepFFM model which is described in section 3.1 by inserting the CENet attention module into it. <ref type="figure" target="#fig_2">Figure 3</ref> provides overall architecture of our proposed Field Attentive Deep Field-aware Factorization Machine (FAT-DeepFFM). It's similar in neural structure to DeepFFM while the original embedding matrix layer is replaced by the SE-Net like field attention module. We call this newly plugged-in module attentive embedding matrix layer. The other components of FAT-DeepFFM are same as the DeepFFM model. Similar to the DeepFFM, there are also two versions of FAT-DeepFFM according to the feature interaction type: inner-product version and Hadamard-product version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combining the field attention and DeepFFM</head><p>We can see from the above-mentioned descriptions that our proposed attention mechanism is a kind of attention before cross features were produced. So a natural research question arises that which one will perform better if we introduce attention on cross features after the explicit feature interaction procedure just like AFM does? To answer this question, we also conduct some experiments to compare the performance difference of two kinds of attention mechanisms. The experimental results demonstrate that the attention before feature interaction outperforms the one after feature interaction consistently. We will discuss these experiments in detail in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>To comprehensively evaluate our proposed method, we design some experiments to answer the following research questions: RQ1 Can our proposed FAT-DeepFFM outperform the stateof-the-art deep learning based CTR models? RQ2 Which attention mechanism (attention on features before explicit feature interaction vs. attention on cross features after explicit feature interaction) will perform better on the real world CTR datasets? RQ3 Which feature interaction method (Inner-Product vs. Hadamard-product) is more effective in neural network based CTR models?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup Datasets</head><p>The following two data sets are used in our experiments:</p><p>1. Criteo 1 Dataset. As a very famous public real world display ad dataset with each ad display information and corresponding user click feedback, Criteo data set is widely used in many CTR model evaluation. There are 26 anonymous categorical fields and 13 continuous feature fields in Criteo data set. We split the data into training and test set randomly by 90%:10%. 2. Avazu 2 Dataset. The Avazu dataset consists of several days of ad click-through data which is ordered chronologically. For each click data, there are 24 fields which 1 http://labs.criteo.com/downloads/ 2 http://www.kaggle.com/c/avazu-ctr-prediction indicate elements of a single ad impression. We split the data into training and test set randomly by 80%:20%. <ref type="table" target="#tab_1">Table 1</ref> lists the statistics of the evaluation datasets. For these two datasets, a small improvement in prediction accuracy is regarded as practically significant because it will bring a large increase in a company's revenue if the company has a very large user base.</p><p>Evaluation Metrics AUC (Area Under ROC) and Logloss (cross entropy) are used in our experiments as the evaluation metrics. These two metrics are very popular for binary classification tasks. AUC is insensitive to the classification threshold and the positive ratio. AUC's upper bound is 1 and larger value indicates a better performance. Log loss measures the distance between two distributions and smaller log loss value means a better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models for Comparisons</head><p>We compare the performance of the following CTR estimation models as baseline:LR, FM, FFM, FNN, DeepFM, AFM, Deep&amp;Cross Network(DCN) , xDeepFM and DeepFFM, all of which are discussed in Section 2 and Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>We implement all the models with Tensorflow in our experiments. For optimization method, we use the Adam with a mini-batch size of 1000 and a learning rate is set to 0.0001. Focusing on neural networks structures in our paper, we make the dimension of field embedding for all models to be a fixed value of 10. For models with DNN part, the depth of hidden layers is set to 3, the number of neurons per layer is 1600 for FFM-related models and 400 for all other deep models, all activation function are ReLU and dropout rate is set to 0.5. For CENet component, the activation function is ReLU and the reduction ratio is set to 1 in all the related experiments. We conduct our experiments with 2 Tesla K40 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison (RQ1)</head><p>The overall performance for CTR prediction of different models on Criteo dataset and Avazu dataset is shown in <ref type="table" target="#tab_2">Table  2</ref>. We have the following key observations:</p><p>1. FAT-DeepFFM achieves the best performance in general and obtains different improvements over the state-ofthe-art methods. As the best model, FAT-DeepFM outperforms FM by 3.64% and 1.80% in terms of Logloss (2.28% and 1.50% in terms of AUC) and outperforms LR by 5.64% and 3.29% in terms of Logloss (3.79% and 2.99% in terms of AUC) on Criteo and Avazu datasets. 2. FAT-DeepFFM consistently outperforms DeepFFM on both datasets. This indicates that CENet field attentive mechanism is rather helpful for learning the importance of raw features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Attention Mechanism Comparison (RQ2)</head><p>In this subsection, we will discuss the performance of two different kinds of attention mechanisms: one is an attention before explicit feature interaction just like above-mentioned field attention; the other is the attention on cross features after explicit feature interaction procedure just like AFM does. As for the specific approach for the attention on cross features, two methods are implemented: the similar CENet attention as described in section 3.2 and the MLP based attention just like AFM does, the hyper-parameters are tuned to achieve the best performance. The experimental results is shown in table 3 and the experiments with prefix "MLP" refer to the MLP based attention on cross features while the experiments with prefix "CE" mean the CENet attention is used on cross features. <ref type="table" target="#tab_4">Table 3</ref> lists the overall performance of two attention mechanisms on Criteo dataset and Avazu dataset. We have the following key observations:  As we discussed in section 3, both the DeepFFM and FAT-DeepFFM model have two kinds of feature interaction approaches: inner product version vs. hadamard product version. So a natural research question arises that which approach will perform better? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a new neural CTR model called Field Attentive Deep Field-aware Factorization Machine (FAT-DeepFFM) by combining the deep field-aware factorization machine (DeepFFM) with CENet field attention mechanism. We conduct extensive experiments on two realworld datasets and the experiment results show that FAT-DeepFFM achieves the best performance and obtains different improvements over the state-of-the-art methods. We also show that FAT-DeepFFM consistently outperforms DeepFFM on both datasets which indicates that CENet field attentive mechanism is rather helpful for learning the importance of raw features when the task has many input features. We also compare two different types of attention mechanisms (attention before explicit feature interaction vs. attention after explicit feature interaction) and the experiment results demonstrate that the former one outperforms the latter one significantly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The Neural Structure of Inner-Product version DeepFFM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>CENet Field Attention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Neural Structure of Field Attentive DeepFFM (Inner product version)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Deep model, which means that the cross-product transformation also requires to be manually designed. To alleviate manual efforts in feature engineering, DeepFM<ref type="bibr" target="#b6">[Guo et al., 2017]</ref> replaces the wide part of Wide &amp; Deep model with FM and shares the feature embedding between the FM and deep component. DeepFM is regarded as one state-of-the-art model in CTR estimation field.</figDesc><table><row><cell>wide part of Wide &amp; Deep &amp; Cross Network (DCN)[Wang et al., 2017] effi-</cell></row><row><cell>ciently captures feature interactions of bounded degrees in</cell></row><row><cell>an explicit fashion. Similarly, eXtreme Deep Factorization</cell></row><row><cell>Machine (xDeepFM)</cell></row><row><cell>Factorisation-Machine Supported Neural Networks</cell></row><row><cell>(FNN)[Zhang et al., 2016] is a feed-forward neural network</cell></row><row><cell>using FM to pre-train the embedding layer. However, FNN</cell></row><row><cell>can capture only high-order feature interactions. Wide &amp;</cell></row><row><cell>Deep Learning[Cheng et al., 2016] was initially introduced</cell></row><row><cell>for App recommendation in Google play. Wide &amp; Deep</cell></row><row><cell>Learning jointly trains wide linear models and deep neural</cell></row><row><cell>networks to combine the benefits of memorization and</cell></row><row><cell>generalization for recommender systems. However, exper-</cell></row><row><cell>tise feature engineering is still needed on the input to the</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the evaluation datasets</figDesc><table><row><cell cols="4">Datasets #Instances #Fields #Features</cell></row><row><cell>Criteo</cell><cell>45M</cell><cell>39</cell><cell>2.3M</cell></row><row><cell>Avazu</cell><cell>40.43M</cell><cell>24</cell><cell>0.64M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="5">: Overall performance of different models on Criteo and</cell></row><row><cell cols="5">Avazu(the model name with suffix "I" means inner-product version</cell></row><row><cell cols="4">while with suffix "H" means Hadamard product version)</cell></row><row><cell></cell><cell></cell><cell>Criteo</cell><cell cols="2">Avazu</cell></row><row><cell>Model Name</cell><cell>AUC</cell><cell cols="2">Logloss AUC</cell><cell>Logloss</cell></row><row><cell>LR</cell><cell cols="2">0.7808 0.4681</cell><cell cols="2">0.7633 0.3891</cell></row><row><cell>FM</cell><cell cols="2">0.7923 0.4584</cell><cell cols="2">0.7745 0.3832</cell></row><row><cell>FFM</cell><cell cols="2">0.8001 0.4525</cell><cell cols="2">0.7795 0.3810</cell></row><row><cell>FNN</cell><cell cols="2">0.8057 0.4464</cell><cell cols="2">0.7802 0.3800</cell></row><row><cell>AFM</cell><cell cols="2">0.7965 0.4541</cell><cell cols="2">0.7740 0.3839</cell></row><row><cell>DeepFM</cell><cell cols="2">0.8085 0.4445</cell><cell cols="2">0.7786 0.3810</cell></row><row><cell>DCN</cell><cell cols="2">0.7977 0.4617</cell><cell cols="2">0.7680 0.3940</cell></row><row><cell>xDeepFM</cell><cell cols="2">0.8091 0.4461</cell><cell cols="2">0.7808 0.3819</cell></row><row><cell>DeepFFM-I</cell><cell cols="2">0.8087 0.4434</cell><cell cols="2">0.7839 0.3783</cell></row><row><cell>DeepFFM-H</cell><cell cols="2">0.8088 0.4434</cell><cell cols="2">0.7835 0.3782</cell></row><row><cell>FAT-DeepFFM-I</cell><cell cols="2">0.8099 0.4421</cell><cell cols="2">0.7857 0.3763</cell></row><row><cell cols="3">FAT-DeepFFM-H 0.8104 0.4416</cell><cell cols="2">0.7863 0.3761</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Overall performance of two attention mechanisms on Criteo and Avazu(the model name with suffix "I" means inner-product version while with suffix "H" means Hadamard product version)</figDesc><table><row><cell></cell><cell></cell><cell>Criteo</cell><cell></cell><cell>Avazu</cell></row><row><cell>Model</cell><cell>AUC</cell><cell cols="2">Logloss AUC</cell><cell>Logloss</cell></row><row><cell>DeepFFM-I</cell><cell cols="2">0.8087 0.4434</cell><cell cols="2">0.7839 0.3783</cell></row><row><cell>MLP-DeepFFM-I</cell><cell cols="2">0.8022 0.4499</cell><cell cols="2">0.7819 0.3796</cell></row><row><cell>CE-DeepFFM-I</cell><cell>0.808</cell><cell>0.444</cell><cell cols="2">0.7816 0.381</cell></row><row><cell>FAT-DeepFFM-I</cell><cell cols="2">0.8099 0.4422</cell><cell cols="2">0.7857 0.3763</cell></row><row><cell>DeepFFM-H</cell><cell cols="2">0.8088 0.4434</cell><cell cols="2">0.7835 0.3782</cell></row><row><cell cols="3">MLP-DeepFFM-H 0.8083 0.444</cell><cell cols="2">0.7847 0.3778</cell></row><row><cell>CE-DeepFFM-H</cell><cell cols="2">0.8092 0.443</cell><cell cols="2">0.7822 0.3786</cell></row><row><cell cols="3">FAT-DeepFFM-H 0.8104 0.4417</cell><cell cols="2">0.7861 0.3773</cell></row><row><cell cols="4">4.4 Feature Interaction Method(RQ3)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>also shows 4 groups of comparable experiments (model names with same prefix and different suffixes form one group such as DeepFFM-I and DeepFFM-H ) on two datasets. We have the following key observations: 1. No apparent performance difference is observed if we don't adopt any attention to the DeepFFM model, no matter which feature interaction method is used (DeepFFM-I vs. DeepFFM-H). 2. The Hadamard product function should be preferred to the inner product function if we adopt attention to the DeepFFM model, no matter attention on features or attention on cross features. We can see from table 3 that this conclusion holds in most cases.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Tushar Chandra</publisher>
			<pubPlace>Jeremiah Harmsen, Tal Shaked</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
		<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chollet</surname></persName>
		</author>
		<title level="m">François Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1610" to="02357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Webscale bayesian click-through rate prediction for sponsored search advertising in microsoft&apos;s bing search engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Graepel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Omnipress</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, speech and signal processing (icassp), 2013 ieee international conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Xiangnan He and Tat-Seng Chua. Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04247</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Deepfm: a factorization-machine based neural network for ctr prediction</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Practical lessons from predicting clicks on ads at facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Workshop on Data Mining for Online Advertising</title>
		<meeting>the Eighth International Workshop on Data Mining for Online Advertising</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01507</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<editor>Jie Hu, Li Shen,</editor>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>and Gang Sun. Squeeze-and-excitation networks</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Field-aware factorization machines for ctr prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Juan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
		<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">xdeepfm: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Koren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05170</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1222" to="1230" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Eleventh Annual Conference of the International Speech Communication Association</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Steffen Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04617</idno>
		<ptr target="https://cs.nju.edu.cn/31/60/c1654a209248/page.htm" />
	</analytic>
	<monogr>
		<title level="m">Fei Wu, and Tat-Seng Chua. Attentional factorization machines: Learning the weight of feature interactions via attention networks</title>
		<editor>Yang et al., 2017] Yi Yang, Shaofeng Shen, and Yu liang</editor>
		<meeting><address><addrLine>Hao Ye, Xiangnan He, Hanwang Zhang</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>European conference on information retrieval</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep interest network for clickthrough rate prediction</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1059" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
