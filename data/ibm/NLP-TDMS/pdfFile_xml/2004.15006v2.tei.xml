<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Template Guided Text Generation for Task-Oriented Dialogue</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><forename type="middle">Kale</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research Mountain View</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mountain</forename><surname>View</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research Mountain View</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research Mountain View</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Template Guided Text Generation for Task-Oriented Dialogue</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Virtual assistants such as Google Assistant, Amazon Alexa, and Apple Siri enable users to interact with a large number of services and APIs on the web using natural language. In this work, we investigate two methods for Natural Language Generation (NLG) using a single domain-independent model across a large number of APIs. First, we propose a schemaguided approach which conditions the generation on a schema describing the API in natural language. Our second method investigates the use of a small number of templates, growing linearly in number of slots, to convey the semantics of the API. To generate utterances for an arbitrary slot combination, a few simple templates are first concatenated to give a semantically correct, but possibly incoherent and ungrammatical utterance. A pre-trained language model is subsequently employed to rewrite it into coherent, natural sounding text. Through automatic metrics and human evaluation, we show that our method improves over strong baselines, is robust to out-of-domain inputs and shows improved sample efficiency. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Virtual assistants have become popular in recent years and task-completion is one of their most important aspects. These assistants help users in accomplishing tasks such as finding restaurants, buying sports tickets, finding the weather etc., by providing a natural language interface to many services or APIs available on the web. Most systems include a natural language understanding and dialogue state tracking module for semantic parsing of the dialogue history. This is followed by a policy module which interacts with the APIs, whenever required, and generates the actions to be taken by the system to continue the dialog. In the end, the Natural Language Generation (NLG) module converts these actions into an utterance, which is surfaced to the user. Being the user-facing interface of the dialogue system, NLG is one of the most important components impacting user experience.</p><p>Traditional NLG systems heavily utilize a set of templates to produce system utterances. Although the use of templates gives good control over the outputs generated by the system, defining templates becomes increasingly tedious as more APIs are added. Supporting multi-domain conversations spanning multiple APIs quickly grows out of hand, requiring expert linguists and rigorous testing to ensure the grammatical correctness and appropriateness of generated utterances. Consequently, data-driven generative approaches have gained prominence. Such systems require much less effort and can generate utterances containing novel patterns. Meanwhile, with the rapid proliferation of personal assistants, supporting large number of APIs across multiple domains has become increasingly important, resulting in research on supporting new APIs with few labelled examples (few-shot learning). To this end, generative models pre-trained on large amounts of unannotated text have been increasingly successful.</p><p>In this work, we address the challenges of joint modeling across a large number of domains, and data efficient generalization to new domains and APIs for NLG. Our contributions are the following:</p><p>1. We propose two methods for zero-shot and few-shot NLG. Our first method, the Schema-Guided NLG, represents slots using their natural language descriptions. Our second method -Template Guided Text Generation (T2G2) employs a simple template-based representation of system actions and formulates NLG as an utterance rewriting task <ref type="figure">(Figure 1</ref>). <ref type="figure">Figure 1</ref>: Overall architecture of our proposed template guided approach. 1. The policy module outputs a set of actions in response to the user utterance. 2. Simple templates convert each action into a natural language utterance. 3. Template-generated utterances are concatenated and fed to a T5 encoder-decoder model <ref type="bibr" target="#b19">(Raffel et al., 2020)</ref>. The model rewrites it to a conversational response surfaced to the user.</p><p>2. We present the first NLG results on the Schema-Guided dialogue dataset <ref type="bibr" target="#b20">(Rastogi et al., 2019)</ref>, which exceeds all other datasets in scale, providing a total of 45 APIs over 20 domains. While the current state-of-the-art pre-training based methods struggle to generalize to unseen (zero-shot) APIs, our proposed methods are robust to out-of-domain inputs and display improved sample efficiency.</p><p>3. We conduct an extensive set of experiments to investigate the role of dialogue history context, cross-domain transfer learning and few-shot learning. We share our findings to guide the design choices in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Natural language generation from structured input (NLG) has been an active area of research, facilitated by creation of datasets like WikiBio <ref type="bibr" target="#b10">(Lebret et al., 2016)</ref>, E2E challenge <ref type="bibr" target="#b15">(Novikova et al., 2017)</ref>, WebNLG <ref type="bibr" target="#b3">(Gardent et al., 2017)</ref> and <ref type="bibr">MultiWOZ (Budzianowski et al., 2018)</ref>. Neural sequence models have been extensively used in a variety of configurations for NLG in dialogue systems. <ref type="bibr">Wen et al. (2017)</ref> proposed a two-step approach: first generating a delexicalized utterance with placeholders for slots and then post-processing it to replace placeholders with values from API results, whereas <ref type="bibr" target="#b14">Nayak et al. (2017)</ref> highlighted the importance of conditioning responses on slot values. Sequence to sequence architectures directly converting a sequential representation of system ac-tions to a system response are also very common <ref type="bibr" target="#b24">(Wen et al., 2015;</ref><ref type="bibr">Du sek and Jurcicek, 2016b;</ref><ref type="bibr">Zhu et al., 2019;</ref><ref type="bibr" target="#b12">Chen et al., 2019)</ref>. Domainadaptation and transfer learning in low resource settings has also been an extensively studied problem <ref type="bibr" target="#b21">(Tran and Le Nguyen, 2018;</ref><ref type="bibr">Chen et al., 2020;</ref><ref type="bibr" target="#b17">Peng et al., 2020;</ref><ref type="bibr" target="#b13">Mi et al., 2019)</ref>, with recently released datasets like SGD <ref type="bibr" target="#b20">(Rastogi et al., 2019)</ref> and FewShotWOZ <ref type="bibr" target="#b17">(Peng et al., 2020)</ref> providing a good benchmark. Meanwhile, language models pre-trained on large amount of unannotated text corpus have achieved state-of-the-art performance across several natural language processing tasks <ref type="bibr">(Devlin et al., 2019;</ref><ref type="bibr">Yang et al., 2019;</ref><ref type="bibr" target="#b12">Liu et al., 2019;</ref><ref type="bibr" target="#b18">Radford et al., 2019;</ref><ref type="bibr" target="#b8">Keskar et al., 2019)</ref>, including natural language generation <ref type="bibr" target="#b17">(Peng et al., 2020;</ref><ref type="bibr" target="#b7">Kale and Roy, 2020)</ref>.</p><p>Our template based approach bears similarities to sentence fusion <ref type="bibr" target="#b1">(Barzilay and McKeown, 2005)</ref>, and prototype based text editing <ref type="bibr" target="#b5">(Hossain et al., 2020;</ref><ref type="bibr">Cao et al., 2018;</ref><ref type="bibr" target="#b4">Guu et al., 2018;</ref><ref type="bibr" target="#b18">Wu et al., 2019)</ref>. However, none of these works tackle text generation from structured data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For a given system dialogue turn, let</head><formula xml:id="formula_0">A = {d i (s i = v i )} A i=1</formula><p>be the set of actions which are produced by the system, where A is the total number of actions for this turn. Each action consists of a single dialogue act d i representing the semantics of the action, along with optional slot and value parameters -s i and v i respectively. For example, inform, req more and request are some of the dialogue acts defined in the SGD dataset <ref type="bibr" target="#b20">(Rastogi et al., 2019)</ref>, which are used for informing the value of a slot to the user, asking if the user needs some other help, and requesting the value of a slot from the user respectively. Some acts like inform require both the slot and value parameters, whereas acts like request require the slot parameter only and acts like req more require none. Some datasets allow multiple slot-value arguments for a single act, but such actions can generally be converted to the above representation by decomposing them into multiple actions with the same act, each containing exactly one slot-value pair.</p><p>The goal of NLG is to translate A to a natural language response with the same semantic content. To this end, we first convert the set A into a sequence. Then, we finetune a Text-to-Text Transfer Transformer (T5) <ref type="bibr" target="#b19">(Raffel et al., 2020)</ref> model, which is a pre-trained sequence to sequence transformer, to generate the natural language response using this sequence as input. Now, we present three different methods for converting A into a sequence, the last two being our contributions. They are also summarized in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Naive Representation</head><p>This approach uses the most basic representation of actions, similar to that used in many prior works <ref type="bibr" target="#b15">(Novikova et al., 2017;</ref><ref type="bibr">Zhu et al., 2019;</ref><ref type="bibr" target="#b17">Peng et al., 2020)</ref>. Canonical representations of each action a i , a i (s i ) or a i (s i = v i ), depending on the parameters present in the action, are concatenated together to obtain a sequence representation of A. Although this representation is simple to obtain and gives state of the art results for several data-to-text benchmarks <ref type="bibr" target="#b6">(Kale and Rastogi, 2020)</ref>, it suffers from two drawbacks -(i) Semantics -This representation doesn't convey much information about the semantics of a slot. Consequently, the model may need a larger number of training examples to identify the semantics of a slot from its usage in the system utterances in the training data.</p><p>(ii) Representation Bias -This representation is very different from what the encoder has seen during pre-training phase, which is natural language text. As a result, the representations learnt during pre-training may not transfer well. <ref type="bibr" target="#b17">Peng et al. (2020)</ref> mitigate this by conducting additional pre-training using large scale annotated dialogue datasets. While this method is effective, a large in-domain corpus may not always be available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Schema Guided Representation</head><p>Recent work on low-resource natural language understanding tasks have used natural language descriptions of slots. These descriptions are easy to obtain, directly encode the semantics of the slot and have been shown to help when in-domain training data is sparse. While description based representations have become popular for tasks like spoken language understanding <ref type="bibr" target="#b0">(Bapna et al., 2017)</ref> and dialogue state tracking <ref type="bibr" target="#b20">(Rastogi et al., 2019)</ref>, they have not yet been applied to the language generation task. We propose an extension of the Naive representation by replacing the slot names with their natural language descriptions. The action representations, as illustrated in <ref type="figure">Figure 2</ref>, are a i , a i (desc(s i )) and a i (desc(s i ) = v i ), where desc(s) represents a natural language description of slot s. This solves the first drawback of the Naive representation mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Template Guided Representation</head><p>We solve the representation bias problem by converting the set of actions output by the system into a natural language utterance. We employ a technique similar to that used in <ref type="bibr" target="#b20">Rastogi et al. (2019)</ref>, where simple utterances are generated using a minimal set of manually defined templates. Specifically, as shown in <ref type="figure" target="#fig_0">Figure 3</ref>, we define one template for each  Note that, our focus here is not to generate conversational and grammatically correct utterances, but to have a simple representation of the actions, which can be rewritten by the model into a natural and fluent response. Hence, we do not need to cover all edge cases typically required in template based methods -handling of plurals, subject-verb agreement, morphological inflection etc. -and only need to define a small number of templates. For most APIs, this amounts to around 15-30 templates, which can easily be written by the API developer. The actual number varies depending on the number of slots and intents supported by the API 2 . Some special slots like date, time and price are formatted using special rules, which can be reused across APIs. For instance, we convert the date "2019-03-06" to "6th March", the time "18:40" to "6:40 pm", and price "60" to "$60". We call this step value paraphrasing. Since this method relies on a combination of templates and transfer learning from language models, we name it Template Guided Text Generation (T2G2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>We conduct a series of experiments to compare the three system action representations presented above. We also evaluate NLG in few-shot settings and investigate a few other aspects of the SGD dataset. In each of the experiments reported in this 2 Please see Appendix D for more examples of templates. paper, we start with a pre-trained T5-small model 3 . It has 6 layers each in the encoder and decoder, with a total of around 60 million parameters. The model is then fine-tuned on the corresponding dataset using a constant learning rate of 0.001 and batch size of 256 for 5000 steps. The checkpoint yielding the highest BLEU score on the development set is picked for reporting test set results. During inference, we use beam search with a width of 4 and length penalty α = 0.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Action Representations</head><p>We compare the different methods of action representation on MultiWOZ 2.1 <ref type="bibr">(Budzianowski et al., 2018)</ref>, the cleaned version of the E2E restaurant corpus <ref type="bibr" target="#b15">(Novikova et al., 2017;</ref><ref type="bibr">Du sek et al., 2019)</ref> and the Schema-Guided Dialogue (SGD) <ref type="bibr" target="#b20">(Rastogi et al., 2019)</ref> dataset. The SGD dataset features a larger number of domains and slots, and the presence of multiple APIs per domain ( <ref type="figure" target="#fig_1">Figure 4</ref>) makes it representative of practical scale-related challenges faced by today's virtual assistants. Furthermore, as opposed to the other two datasets, its evaluation sets contain many domains, and consequently slots, which are not present in the training set. Even for domains shared between the training and evaluation sets, the evaluation sets contain additional slots in some cases. This focus on zero-shot generalization to new domains and APIs makes SGD more challenging than existing NLG benchmarks. <ref type="table">Table 1</ref> compares these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic Evaluation</head><p>Following prior work <ref type="bibr" target="#b24">(Wen et al., 2015)</ref>, we use BLEU <ref type="bibr" target="#b16">(Papineni et al., 2002)</ref> and Slot Error Rate   (SER) <ref type="bibr" target="#b2">(Dušek and Jurcicek, 2019)</ref> as automatic metrics. SER represents the fraction of generated texts where at least one slot was not correctly copied from the structured data. Since this metric relies on string matching, we cannot use it to evaluate binary slots like has live music. Its exact match nature also prevents it from identifying paraphrases of slot values, e.g. expensive and costly. For E2E we use additional metrics used in prior work for this benchmark -NIST <ref type="bibr">(Doddington, 2002)</ref>, ROUGE-L <ref type="bibr" target="#b11">(Lin, 2004)</ref>, METEOR <ref type="bibr" target="#b9">(Lavie and Agarwal, 2007)</ref>, CIDEr <ref type="bibr" target="#b22">(Vedantam et al., 2015)</ref>, and BLEU.  MultiWOZ is slightly worse in comparison with SC-GPT. SC-GPT generates 5 predictions for each input and then ranks them based on the SER score itself. On the other hand, we generate a single output, on which SER is evaluated. Overall, the results indicate that with enough annotated data, the Naive approach is enough to attain good performance. Both datasets are large and feature limited variety (MultiWOZ has 57K utterances spread over just 5 domains, while E2E has 33k utterances spread over just 8 slots). Zero-shot and few-shot settings offer a greater and more realistic challenge, and we explore these settings next. The SGD dataset, which spans 20 domains, enables us to study these settings.  Adaptation to New Domains The ideal NLG model should be able to handle domains it was not exposed to during training. The SGD dataset, which features unseen domains in the evaluation sets, lets us us assess the zero-shot capability of NLG systems. We report results in <ref type="table" target="#tab_8">Table 4</ref> on two test sets -the seen set consists of domains that were seen during training, while the unseen set consists of brand new domains aka the zeroshot setting. Firstly, all models exhibit low SER scores in both seen and unseen domains, with the template approach being the lowest. This suggests that pre-trained language models are adept at copying and this skill also generalizes to out-of-domain examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MultiWOZ and E2E</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BLEU</head><p>The Schema-Guided representation performs at par with Naive representation on seen domains. At the same time, the slot descriptions do improve performance on the unseen domains (+0.9 BLEU), albeit to a limited degree. More effective ways of incorporating descriptions is a promising area for future work. For the seen domains, T2G2 outperforms Naive by 1.7 BLEU. The results on the Model Input or Generated sequence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Actions</head><p>Flights offer(airlines=American Airlines, outbound departure time=2:40 pm, is nonstop=True, price=$78) Template</p><p>Would you like to fly with American Airlines? The onward flight takes off at 2:40 pm. It is a direct flight. The ticket costs $78.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>Do you wish to fly on American Airlines? The onward direct flight leaves at 2:40 pm, and the ticket price is $78. The ticket costs $78 Naive</p><p>There is an American Airlines flight that leaves at 2:40 pm and is not stop. The ticket costs $78.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Schema</head><p>There is an American Airlines flight that leaves at 2:40 pm and is not stop. The total cost is $78. T2G2</p><p>How about an American Airlines flight that leaves at 2:40 pm? It's a direct flight and costs $78.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Actions</head><p>RentalCars confirm(has insurance=True, car type=hatchback) Template</p><p>Please confirm the following details: It is a Hatchback car. It comes with insurance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>Please confirm: You want me to book a Hatchback car with insurance. Naive</p><p>Please confirm: You want me to reserve a Hatchback car with a reassurance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Schema</head><p>Please confirm: You want to rent a Hatchback. T2G2</p><p>Okay, please confirm that you'd like to have a Hatchback car with an insurance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Actions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Media inform(starring=Andrea Martin) Template</head><p>Antonio Bustorff acted in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The actor is Antonio Bustorff. Naive</p><p>The movie is directed by Antonio Bustorff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Schema</head><p>The movie is directed by Antonio Bustorff. T2G2</p><p>Antonio Bustorff acted in the movie. unseen domains are more striking with an improvement of 7.3 points. This confirms the hypothesis that our simple template based input scheme offers superior generalization capabilities with a low overhead. The template model learns to "fuse" sentences and is able to successfully extend this skill to unseen domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative Analysis</head><p>In <ref type="figure" target="#fig_2">Figure 5</ref> we list a few examples of model predictions. The first example illustrates a case where the model has to deal with a seen domain Flights but an unseen slot is nonstop. Such a case would be common when new functionality needs to be added to an existing domain. Both Naive and Schema are unable to verbalize the slot correctly. While the template input contains all the information, it sounds very robotic. T2G2, on the other hand, takes the 4 template sentences as input and rewrites them into a fully accurate but much more natural sounding response. The next example is from RentalCars, and features an unseen slot has insurance. Schema fails to mention this slot. Naive attempts to verbalize it, but uses the wrong word (reassurance). T2G2, however, is able to paraphrase the template input into grammatical text without dropping any information.</p><p>The final example features an unseen slot starring from the Movies domain. Naive and Schema treat Antonio Bustroff as a director, since the slot directed by appears during training. However, T2G2 simply relies on the template input and copies the phrase acted in. We refer the reader to Appendix F for more qualitative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Human Evaluation</head><p>We conduct a human evaluation study via crowd sourcing 4 . Each human rater is shown the responses generated by different models and the ground truth response in a random order. Following <ref type="bibr" target="#b17">(Peng et al., 2020)</ref>, they are asked to rate each response on a scale of 1 (bad) to 3 (good) along two axes -informativeness and naturalness. Informativeness quantifies whether the response contains all the information contained in the dialogue acts, whereas naturalness evaluates whether the response sounds coherent, grammatical and natural. Each example is rated by 3 different workers. The final metric is an average of all the ratings.</p><p>A total of 500 randomly chosen examples are rated -250 each from seen and unseen domainsacross the 3 models discussed above and the ground truth response (human). With 3 ratings per example, this leads to a total of 6,000 ratings. Results are shown in <ref type="table" target="#tab_10">Table 5</ref>. Naturalness On the overall test set, all models outperform the human authored ground truth. This showcases the strength of pre-trained language models in generating natural sounding utterances, echoing findings from prior works. <ref type="bibr" target="#b18">(Radford et al., 2019;</ref><ref type="bibr" target="#b17">Peng et al., 2020)</ref>.  Informativeness Simply generating a fluent response is not enough. Its paramount for the responses to be factually grounded in the structured data, so that the wrong information is not conveyed to the user. For informativeness, we notice that all models perform well on the seen domains. However, on unseen domains, the Naive approach fares poorly. Schema outperforms Naive by a large margin on unseen domains. T2G2 further improves upon Schema. These results suggest Schema and T2G2 offer promising avenues to improve the zero-shot generalization capability of NLG systems. Moreover, both Naive and Schema see large drops on unseen domains, while T2G2 performs equally well on both seen and unseen domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naturalness</head><p>Recall that Naive representation demonstrated strong scores on the SER metric for unseen domains. However, the low human scores on informativeness suggest that getting perfect scores on metrics like SER may not be a reliable way to judge factual accuracy. As models become stronger, better evaluation metrics need to be developed to accurately measure the improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Few-Shot NLG</head><p>Virtual assistants need to support a constantly increasing number of domains and APIs. In order to keep labelled data costs under control, improving few-shot learning methods is important. In this section, we study the trade-off between the number of annotated training examples and performance of NLG.  Prior work <ref type="bibr" target="#b13">(Mi et al., 2019;</ref><ref type="bibr" target="#b21">Tran and Le Nguyen, 2018;</ref><ref type="bibr" target="#b23">Wen et al., 2016)</ref> has studied few-shot learning and domain adaptation in a simulated setting by creating small subsets. However, lack of knowledge of the exact data splits makes it difficult to make comparisons to other methods. To remedy this, we create a new canonical split of the SGD dataset as described below.</p><p>• We make K-shot subsets for varying values of K <ref type="bibr">[5,</ref><ref type="bibr">10,</ref><ref type="bibr">20,</ref><ref type="bibr">40,</ref><ref type="bibr">80]</ref>. In this setting each of the 14 domains from the training set have K dialogs.</p><p>• For all the few-shot splits we make sure that they contain examples for every dialogue act and slot type present in the full training set. For every domain, we make sure that each dialog act (inform, request etc.) and slot (name, time, price etc.) is represented at least once. However, all combinations of dialog acts and slots may not exist.</p><p>• The dev and test sets are left untouched.</p><p>This benchmark is referred to as FewShotSGD and we make the exact splits publicly available. The exact number of examples in each split is given in <ref type="table" target="#tab_12">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>In few shot experiments, we examine the performance of different models as a function of the amount of labelled data. The training setup remains the same, as described in section 4. Results are reported in <ref type="figure" target="#fig_3">Figure 6</ref>, where we can clearly see the performance improving as more training data becomes available. In all the K-shot settings, T2G2 gives consistent improvements of 4-5 BLEU while reducing the SER by a large margin. Even in the extreme 5-shot setting, the SER is just 3.6%. Remarkably, T2G2 in the 80-shot setting outperforms the Naive model trained on the entire dataset, which is 20x larger. In the 5-shot setting, T2G2 performs on par with 80-shot Naive. We take this as evidence that our template guided input representation can lead to significant reduction in labelled data requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Other Experiments</head><p>In this section, we conduct experiments to explore a few other aspects of our setup on the SGD dataset.</p><p>For these experiments we use the Naive representation, since it is more widely adopted in prior work. We hope that these experiments will guide design choices in the future NLG models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Joint Modeling</head><p>Joint modeling, instead of domain specific models, could be beneficial in low resource settings if there is some similarity between the underlying structure. Furthermore, having a single model for all domains also reduces the maintenance workload and is resource efficient. For NLG systems, it could also help in maintaining consistent styles across domains and APIs. Because of these merits, we investigate the effect of joint modeling on SGD dataset. We focus on the 12 domains that are present in all 3 splits -train, dev and test. We train a single model on   all these domains and compare it with individual models trained for each domain separately. As shown in <ref type="table" target="#tab_14">Table 7</ref>, joint modeling leads to a winwin situation by improving BLEU by 3.4 points and reducing SER from 4.7% to just 1%, while requiring fewer parameters and resources. For further analysis of transfer learning across domains, we refer the reader to Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Role of Context</head><p>Dialogue acts represent the semantic content of the system response, but they don't contain any information about the lexical and syntactic content. The previous utterances in the dialogue history or context are important for generating good responses because they can help model conversational phenomena such as co-reference, elision, entrainment (lexical and syntactic alignment of responses) and avoid repetition (Du sek and Jurcicek, 2016a). Context also helps add variations to the responses generated across different conversations for the same system actions. <ref type="table" target="#tab_15">Table 8</ref> shows the performance of NLG as more utterances from the dialogue context are given as input. In these experiments, we concatenate the last k utterances to the system action representation obtained from the Naive method. The model benefits from the additional context, showing an improvement of upto 6 BLEU. Just a single context utterance -the previous user utterance -results in an improvement of nearly 3 BLEU.</p><p>The evaluation for k &gt;= 2 is not completely realistic, because we used the ground truth system utterances in the context during evaluation as opposed to the utterances generated by the NLG model itself. Regardless, the improvements clearly point to effectiveness of the added context at the cost of more resources. We hope these results inspire more work in this exciting direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>In this work, we proposed schema guided and template guided input representation schemes for task oriented response generation. Coupled with pretrained language models, the template guided approach enables zero-shot generalization to new domains with little effort. Moreover, we show that it can lead to drastic reduction in annotation costs. We also present the first set of results on the multidomain SGD dataset, which we hope will pave the way for further research in few-shot, zero-shot and multi-domain language generation.</p><p>While in this paper we use standard pre-trained models, designing pre-training tasks tailored to sentence fusion is an interesting line of future work. We also hope to apply T2G2 to languages other than English. Obtaining annotated data in non-English languages is an even bigger challenge, making the sample efficiency of our template rewriting approach especially suited to this setting. Another interesting line of future work is to investigate the use of T2G2 for generating user utterances, which could be useful for dialogue data augmentation and user simulation. This requires adding the ability to generate utterances with stylistic variations to capture different user personalities while maintaining consistency in style and vocabulary over a single dialogue. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Experiment Details</head><p>All models are trained on a 4x4 TPU slice, each taking 1-3 hours to finish training for 5000 steps. We provide development set BLEU scores in Tables 9 and 10. These scores are computed on the entire development set which includes both seen and unseen domains. In <ref type="table" target="#tab_20">Table 11</ref>, we list the exact performance numbers for the few-shot NLG experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Automatic Metrics</head><p>Prior work has used different metrics for different benchmarks. Moreover, for the same metric (e.g. BLEU), different implementations are used. For fair comparison, for each dataset, we report the results using the implementation used in prior work. For E2E, we use the implementation from the e2emetrics 5 suite. For computing BLEU on Multi-WOZ, we use code made available in the SC-GPT codebase 6 . For model development i.e checking the best checkpoint based on the validation set, we rely on sacrebleu 7 across all experiments, since 5 https://github.com/tuetschek/e2e-metrics 6 https://github.com/pengbaolin/SC-GPT 7 https://github.com/mjpost/sacreBLEU model BLEU Naive 28.8 SG 29.9 T2G2 30.3  it has become the standard implementation in machine translation literature. We urge the NLG community to also converge upon a single implementation of BLEU. Taking inspiration from MT, the BLEU scores on experiments involving the SGD dataset are computed using sacrebleu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Transfer Learning Across Domains</head><p>To measure the amount of transfer learning from one domain to another, we evaluate each domain specific model trained in Section 7.1 on all the domains and observe domain specific metrics. Results can be found in <ref type="table" target="#tab_4">Table 12</ref> and 13.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Templates</head><p>In <ref type="table" target="#tab_8">Tables 14, 15</ref> and 16, we provide templates used for a few different APIs. The full set of templates is available with the code. Note that the linguistic quality of the templates does not need to be very    high, as long as the semantics of the dialog act are captured. This makes it easy for the API developers themselves to quickly create the simple templates. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Human Evaluation Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Example Outputs</head><p>Sample utterances generated using the different models for various domains are shown in the examples below. The system actions, its template based representation used by the T2G2 model as input, and the reference response are also provided. The predictions are from models trained on the full SGD dataset and without any dialogue history context. The unseen domains have been marked with an asterisk.     Antonio Bustorff acted in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The actor is Antonio Bustorff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naive</head><p>The movie is directed by Antonio Bustorff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>The movie is directed by Antonio Bustorff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T2G2</head><p>Antonio Bustorff acted in the movie. Where are you leaving from and when do you plan to leave? <ref type="figure">Figure 9</ref>: A few examples of utterances generated from different models, along with the system actions, their template based representation (as shown in <ref type="figure">Figure 1</ref>) and the reference output. The unseen domains have been marked with an asterisk. There is an alarm for 4 pm with name Event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Music</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>A 4 pm alarm with name Event. Naive</p><p>There is an event at 4 pm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>There is an event at 4 pm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T2G2</head><p>There is an alarm for 4 pm with event name.</p><p>Alarm * Actions offer(alarm time=10:30 am) offer(alarm name=commute) inform count(count=1) Template</p><p>You have 1 alarms currently set. There is an alarm for 10:30 am with name Commute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>You have 1 alarm at 10:30 am. with name commute Naive I found 1 suitable for you. It's at 10:30 am and it's a commute. SlotDesc I found 1 alarm at 10:30 am. It's a commute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T2G2</head><p>You have 1 alarm for 10:30 am with the name Commute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weather</head><p>Actions inform(humidity=30) Template</p><p>The humidity is around 30 percent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The humidity is about 30 percent. Naive</p><p>It's 30 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>The humidity is 30. T2G2</p><p>The humidity is around 30 percent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weather</head><p>Actions inform(humidity=75) inform(wind=4) Template</p><p>The humidity is around 75 percent. The average wind speed should be 4 miles per hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The humidity for today is around 75 percent. The average wind is 4 miles an hour. Naive</p><p>It's a 7 star, and it's a 4 star.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>The humidity is 75 and the wind speed is 4 miles per hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T2G2</head><p>The average wind speed should be 4 miles per hour and the humidity is around 75 percent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Messaging * Actions notify success Template</head><p>You've successfully shared the location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The location was successfully shared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naive</head><p>Your reservation has been made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>Your contact has been confirmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T2G2</head><p>Your location has been shared.</p><p>Messaging * Actions confirm(location=2190 Bancroft Way) confirm(contact name=Peter) Template</p><p>Please confirm the following details: You're sharing the location 2190 Bancroft Way with Peter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>So share the location 2190 Bancroft Way with Peter? Naive</p><p>Please confirm the following details: You are scheduling a visit to Peter at 2190 Bancroft Way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>Please confirm the following details: You would like to contact Peter at 2190 Bancroft Way. T2G2</p><p>Please confirm the following details: You're sharing the location 2190 Bancroft Way with Peter.</p><p>Trains * Actions offer(journey start time=7:10 am) offer(total=$91) Template</p><p>What about the train departing at 7:10 am? It costs $91 in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>There is a train leaving at 7:10 am and costs $91. Naive</p><p>There is a bus that departs at 7:10 am and costs $91.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SlotDesc</head><p>There is a 7:10 am train that costs $91. T2G2</p><p>How about the 7:10 am train? It costs $91 in total.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Example templates for a ride-sharing API. Parameterized templates are defined for actions which contain a slot value. system action. The representation of A is obtained by concatenating the corresponding templatized representation of each action in A. See Figure 2 for a complete example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Schemas of two APIs from the Media domain present in the SGD dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>A few examples of utterances generated from different models, along with the system actions, their template based representation (as shown inFigure 1) and the reference output. The errors are underlined.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Performance in few-shot settings. The x-axis indicates the number of dialogues per domain in the training set. For exact scores, please refer to Appendix A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figures 7</head><label>7</label><figDesc>and 8 show examples of rater tasks for naturalness and informativeness respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Example of a human rater task to evaluate naturalness. Each row represents the output from one of Naive, Schema, T2G2 and Ground Truth. The order of rows is shuffled across different tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Example of a human rater task to evaluate informativeness. Each row represents the output from one of Naive, Schema, T2G2 and Ground Truth. The order of rows is shuffled across different tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Continuation of examples inFigure 9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Schema Guided inform ( name of restaurant = Opa! ) inform ( type of food served = greek ) Template Guided How about the restaurant Opa!. The restaurant serves greek food. Ground Truth Opa! is a nice greek restaurant. How does it sound? Figure 2: An example showing the representation of system actions utilized by the three schemes. The template representation is generated by concatenating sentences obtained from two templates, which are "inform(restaurant = $x) → How about the restaurant $x." and "inform(cuisine = $x) → The restaurant serves $x food.".</figDesc><table><row><cell>Approach</cell><cell>Representation of System Actions</cell></row><row><cell>Naive</cell><cell>inform ( restaurant = Opa! ) inform ( cuisine = greek )</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Performance of models on MultiWOZ.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>Model</cell><cell cols="2">BLEU N</cell><cell>M</cell><cell>R</cell><cell>C</cell></row><row><cell>SC-LSTM</cell><cell>23.7</cell><cell cols="4">4.0 32.9 39.3 0.4</cell></row><row><cell>TGen</cell><cell>40.7</cell><cell cols="4">6.2 37.8 56.1 1.9</cell></row><row><cell>Naive</cell><cell>42.1</cell><cell cols="4">6.4 38.5 56.2 1.9</cell></row><row><cell>Schema</cell><cell>43.1</cell><cell cols="4">6.4 38.7 56.8 1.9</cell></row><row><cell>T2G2</cell><cell>42.5</cell><cell cols="4">6.4 38.7 56.9 1.9</cell></row></table><note>lists results on the MultiWOZ and Table 3 on E2E. We train separate models for each dataset. On both datasets, T2G2 and Schema are comparable to the state-of-the-art Naive approach. We note that the SER score on</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Performance of models on E2E. Results for SC-LSTM (Wen et al., 2015) and TGen (Novikova et al., 2017) have been taken from Du sek et al. (2019). N,M,R,C stand for NIST, METEOR, ROUGE and CIDEr respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>BLEU and SER metrics on SGD dataset. Copy refers to a trivial baseline comprising of the template based input representation and has 0 SER by definition.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Human evaluation results comparing different</cell></row><row><cell>models and the ground truth. The superscripts 1 to 4 in-</cell></row><row><cell>dicate that the model is significantly better than Naive,</cell></row><row><cell>Schema, T2G2 and ground truth respectively, as deter-</cell></row><row><cell>mined by a one-tailed paired t-test with p &lt; 0.05.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>Data statistics of FewShotSGD training splits.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>Joint vs domain-specific (separate) NLG.</figDesc><table><row><cell>k</cell><cell>0</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>7</cell></row><row><cell cols="6">BLEU 26.2 29.0 31.5 32.4 32.6</cell></row><row><cell>SER</cell><cell>1.0</cell><cell>1.0</cell><cell>0.8</cell><cell>0.9</cell><cell>0.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>Changing the size of the context. k represents the number of previous utterances used.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gasic. 2018. MultiWOZ-A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016-5026.</figDesc><table><row><cell>Proceedings of the 2015 Conference on Empirical</cell><cell></cell></row><row><cell>Methods in Natural Language Processing, pages</cell><cell></cell></row><row><cell>1711-1721.</cell><cell></cell></row><row><cell>Tsung-Hsien Wen, David Vandyke, Nikola Mrk si'c,</cell><cell></cell></row><row><cell>Milica Gasic, Lina M Rojas Barahona, Pei-Hao Su,</cell><cell></cell></row><row><cell>Stefan Ultes, and Steve Young. 2017. A Network-</cell><cell></cell></row><row><cell>based End-to-End Trainable Task-oriented Dialogue</cell><cell></cell></row><row><cell>System. In Proceedings of the 15th Conference of the European Chapter of the Association for Compu-tational Linguistics: Volume 1, Long Papers, pages</cell><cell cols="2">Ziqiang Cao, Wenjie Li, Sujian Li, and Furu Wei. 2018. Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization. In Proceedings of the 56th</cell></row><row><cell>438-449.</cell><cell cols="2">Annual Meeting of the Association for Computa-</cell></row><row><cell>Yu Wu, Furu Wei, Shaohan Huang, Yunli Wang, Zhou-jun Li, and Ming Zhou. 2019. Response Genera-</cell><cell cols="2">tional Linguistics (Volume 1: Long Papers), pages 152-161.</cell></row><row><cell>tion by Context-Aware Prototype Editing. In Pro-ceedings of the AAAI Conference on Artificial Intel-ligence, volume 33, pages 7281-7288.</cell><cell cols="2">Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan, and William Yang Wang. 2019. Semantically con-ditioned dialog response generation via hierarchical</cell></row><row><cell>Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-bonell, Russ R Salakhutdinov, and Quoc V Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In Advances in neural in-</cell><cell cols="2">disentangled self-attention. In Proceedings of the 57th Annual Meeting of the Association for Com-putational Linguistics, pages 3696-3709, Florence, Italy. Association for Computational Linguistics.</cell></row><row><cell>formation processing systems, pages 5754-5764.</cell><cell cols="2">Zhiyu Chen, Harini Eavani, Wenhu Chen, Yinyin Liu,</cell></row><row><cell>Chenguang Zhu, Michael Zeng, and Xuedong Huang.</cell><cell cols="2">and William Yang Wang. 2020. Few-shot NLG with</cell></row><row><cell>2019. Multi-task Learning for Natural Language</cell><cell cols="2">pre-trained language model. In Proceedings of the</cell></row><row><cell>Generation in Task-Oriented Dialogue. In Proceed-</cell><cell cols="2">58th Annual Meeting of the Association for Compu-</cell></row><row><cell>ings of the 2019 Conference on Empirical Methods</cell><cell cols="2">tational Linguistics, pages 183-190, Online. Associ-</cell></row><row><cell>in Natural Language Processing and the 9th Inter-</cell><cell cols="2">ation for Computational Linguistics.</cell></row><row><cell>national Joint Conference on Natural Language Pro-</cell><cell></cell></row><row><cell>cessing (EMNLP-IJCNLP), pages 1261-1266.</cell><cell cols="2">Jacob Devlin, Ming-Wei Chang, Kenton Lee, and</cell></row><row><cell></cell><cell cols="2">Kristina Toutanova. 2019. BERT: Pre-training of</cell></row><row><cell></cell><cell cols="2">Deep Bidirectional Transformers for Language Un-</cell></row><row><cell></cell><cell cols="2">derstanding. In Proceedings of the 2019 Conference</cell></row><row><cell></cell><cell cols="2">of the North American Chapter of the Association</cell></row><row><cell></cell><cell cols="2">for Computational Linguistics: Human Language</cell></row><row><cell></cell><cell cols="2">Technologies, Volume 1 (Long and Short Papers),</cell></row><row><cell></cell><cell>pages 4171-4186.</cell></row><row><cell></cell><cell>George Doddington. 2002.</cell><cell>Automatic evaluation</cell></row><row><cell></cell><cell cols="2">of machine translation quality using n-gram co-</cell></row><row><cell></cell><cell cols="2">occurrence statistics. In Proceedings of the sec-</cell></row><row><cell></cell><cell cols="2">ond international conference on Human Language</cell></row><row><cell></cell><cell cols="2">Technology Research, pages 138-145. Morgan Kauf-</cell></row><row><cell></cell><cell>mann Publishers Inc.</cell></row><row><cell></cell><cell cols="2">Ond rej Du sek, David M Howcroft, and Verena Rieser.</cell></row><row><cell></cell><cell cols="2">2019. Semantic Noise Matters for Neural Natural</cell></row><row><cell></cell><cell cols="2">Language Generation. In Proceedings of the 12th</cell></row><row><cell></cell><cell cols="2">International Conference on Natural Language Gen-</cell></row><row><cell></cell><cell>eration, pages 421-426.</cell></row><row><cell></cell><cell cols="2">Ond rej Du sek and Filip Jurcicek. 2016a. A Context-</cell></row><row><cell></cell><cell cols="2">aware Natural Language Generator for Dialogue</cell></row><row><cell></cell><cell cols="2">Systems. In Proceedings of the 17th Annual Meet-</cell></row><row><cell></cell><cell cols="2">ing of the Special Interest Group on Discourse and</cell></row><row><cell></cell><cell>Dialogue, pages 185-190.</cell></row><row><cell></cell><cell cols="2">Ond rej Du sek and Filip Jurcicek. 2016b. Sequence-to-</cell></row><row><cell></cell><cell cols="2">Sequence Generation for Spoken Dialogue via Deep</cell></row><row><cell></cell><cell cols="2">Syntax Trees and Strings. In Proceedings of the</cell></row><row><cell></cell><cell cols="2">54th Annual Meeting of the Association for Compu-</cell></row><row><cell></cell><cell cols="2">tational Linguistics (Volume 2: Short Papers), pages</cell></row><row><cell></cell><cell>45-51.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 9 :</head><label>9</label><figDesc>Development set performance on the SGD dataset.</figDesc><table><row><cell>K</cell><cell cols="3">Naive Schema T2G2</cell></row><row><cell>5</cell><cell>19.8</cell><cell>20.0</cell><cell>22.0</cell></row><row><cell>10</cell><cell>21.3</cell><cell>22.0</cell><cell>24.0</cell></row><row><cell>20</cell><cell>23.4</cell><cell>22.4</cell><cell>24.5</cell></row><row><cell>40</cell><cell>23.1</cell><cell>25.3</cell><cell>25.6</cell></row><row><cell>80</cell><cell>26.1</cell><cell>24.9</cell><cell>27.8</cell></row><row><cell cols="2">All 28.8</cell><cell>29.9</cell><cell>27.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 10 :</head><label>10</label><figDesc>Development set BLEU scores in few-shot settings. K-shot denotes K dialogs for an API in the training set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 11 :</head><label>11</label><figDesc>Test set performance in few-shot settings. Kshot denotes K dialogs for an API in the training set.</figDesc><table><row><cell></cell><cell cols="12">homes buses media rides movies flights music services rental restaurants events hotels</cell></row><row><cell>homes</cell><cell>1.6</cell><cell>14.7</cell><cell>7.7</cell><cell>6.2</cell><cell>11.7</cell><cell>17.1</cell><cell>28.3</cell><cell>20</cell><cell>17.1</cell><cell>18</cell><cell>27.9</cell><cell>12.6</cell></row><row><cell>buses</cell><cell>13.8</cell><cell>4</cell><cell>19.8</cell><cell>2.9</cell><cell>26.4</cell><cell>19.2</cell><cell>32.4</cell><cell>24.5</cell><cell>22.9</cell><cell>21.2</cell><cell>30.1</cell><cell>19</cell></row><row><cell>media</cell><cell>38.6</cell><cell>42.4</cell><cell>8.4</cell><cell>20.2</cell><cell>33.6</cell><cell>48.7</cell><cell>26.9</cell><cell>44.6</cell><cell>38.7</cell><cell>36.7</cell><cell>40.8</cell><cell>37.4</cell></row><row><cell>rides</cell><cell>34.9</cell><cell>31.8</cell><cell>19.4</cell><cell>2.1</cell><cell>37.3</cell><cell>43.9</cell><cell>41.4</cell><cell>37.6</cell><cell>34.1</cell><cell>28.8</cell><cell>35.5</cell><cell>31.1</cell></row><row><cell>movies</cell><cell>24.5</cell><cell>32.8</cell><cell>11</cell><cell>7.1</cell><cell>23</cell><cell>35.7</cell><cell>22.8</cell><cell>24.8</cell><cell>24.4</cell><cell>22.6</cell><cell>30.2</cell><cell>20.2</cell></row><row><cell>flights</cell><cell>9.7</cell><cell>5.1</cell><cell>17</cell><cell>2.2</cell><cell>22.3</cell><cell>1</cell><cell>25.9</cell><cell>18.1</cell><cell>8.2</cell><cell>14.4</cell><cell>21.3</cell><cell>19.1</cell></row><row><cell>music</cell><cell>36.6</cell><cell>38.5</cell><cell>3.9</cell><cell>20.1</cell><cell>24</cell><cell>48.4</cell><cell>0.6</cell><cell>26.3</cell><cell>28.4</cell><cell>23.9</cell><cell>38.3</cell><cell>33.6</cell></row><row><cell>services</cell><cell>4.8</cell><cell>19.1</cell><cell>3.7</cell><cell>5.8</cell><cell>10.4</cell><cell>29.6</cell><cell>20.8</cell><cell>0.6</cell><cell>20.6</cell><cell>5.8</cell><cell>16.4</cell><cell>11.6</cell></row><row><cell>rental</cell><cell>17.8</cell><cell>7</cell><cell>15.5</cell><cell>5.6</cell><cell>21.2</cell><cell>15.4</cell><cell>28.7</cell><cell>19.7</cell><cell>9.2</cell><cell>16.6</cell><cell>22.8</cell><cell>19.7</cell></row><row><cell cols="2">restaurants 9.8</cell><cell>21.9</cell><cell>10.9</cell><cell>5.2</cell><cell>21.9</cell><cell>33.1</cell><cell>24.7</cell><cell>6.9</cell><cell>18.4</cell><cell>4</cell><cell>15.7</cell><cell>19.2</cell></row><row><cell>events</cell><cell>1.4</cell><cell>30.4</cell><cell>3.7</cell><cell>1.3</cell><cell>10</cell><cell>32.2</cell><cell>14.4</cell><cell>8.3</cell><cell>20.7</cell><cell>10</cell><cell>0.5</cell><cell>13.4</cell></row><row><cell>hotels</cell><cell>5.2</cell><cell>10.1</cell><cell>6.3</cell><cell>1.3</cell><cell>8.8</cell><cell>19.8</cell><cell>18.6</cell><cell>5.2</cell><cell>6.7</cell><cell>6.3</cell><cell>8.5</cell><cell>1.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 12 :</head><label>12</label><figDesc>SER scores for domain specific models, when evaluated on all domains. The column denotes the domain on which the model was trained, while the row represents the domain used for evaluation.</figDesc><table><row><cell></cell><cell cols="12">homes buses media ridesg movies flights music services rental restaurants events hotels</cell></row><row><cell>homes</cell><cell>22.9</cell><cell>7.4</cell><cell>17.5</cell><cell>11.6</cell><cell>18.4</cell><cell>7.6</cell><cell>6.3</cell><cell>15.8</cell><cell>10.5</cell><cell>12.7</cell><cell>17</cell><cell>15.8</cell></row><row><cell>buses</cell><cell>12.6</cell><cell>18.6</cell><cell>11.2</cell><cell>11.2</cell><cell>11.3</cell><cell>9.7</cell><cell>4.6</cell><cell>13</cell><cell>12</cell><cell>12</cell><cell>17.5</cell><cell>12.9</cell></row><row><cell>media</cell><cell>6.1</cell><cell>5.6</cell><cell>28.9</cell><cell>9.1</cell><cell>16.2</cell><cell>3.8</cell><cell>10.6</cell><cell>9.5</cell><cell>4.9</cell><cell>8.7</cell><cell>8.4</cell><cell>11.5</cell></row><row><cell>rides</cell><cell>6.8</cell><cell>4.7</cell><cell>11.6</cell><cell>20.3</cell><cell>9.2</cell><cell>3.1</cell><cell>5.1</cell><cell>7.6</cell><cell>6.1</cell><cell>8.5</cell><cell>7.6</cell><cell>12.3</cell></row><row><cell>movies</cell><cell>9.6</cell><cell>7.5</cell><cell>21</cell><cell>9.3</cell><cell>21.4</cell><cell>7.3</cell><cell>9.9</cell><cell>14</cell><cell>9.5</cell><cell>11.5</cell><cell>15.1</cell><cell>15.7</cell></row><row><cell>flights</cell><cell>11.5</cell><cell>13.1</cell><cell>12.6</cell><cell>10.7</cell><cell>13.5</cell><cell>19.7</cell><cell>6</cell><cell>13</cell><cell>12.9</cell><cell>11.2</cell><cell>16.1</cell><cell>11.8</cell></row><row><cell>music</cell><cell>8.5</cell><cell>5.3</cell><cell>21.7</cell><cell>8.3</cell><cell>17.9</cell><cell>3.9</cell><cell>25.3</cell><cell>11.2</cell><cell>5.2</cell><cell>9.6</cell><cell>10.9</cell><cell>12.1</cell></row><row><cell>services</cell><cell>14.8</cell><cell>10.7</cell><cell>18.7</cell><cell>9.9</cell><cell>21</cell><cell>7.5</cell><cell>9.5</cell><cell>25.3</cell><cell>13.7</cell><cell>20.5</cell><cell>20.9</cell><cell>18.8</cell></row><row><cell>rental</cell><cell>11.7</cell><cell>11.9</cell><cell>12</cell><cell>9.6</cell><cell>14.1</cell><cell>7.9</cell><cell>4.5</cell><cell>15</cell><cell>17.6</cell><cell>14.2</cell><cell>16.8</cell><cell>14.3</cell></row><row><cell cols="2">restaurants 15.4</cell><cell>10</cell><cell>17.4</cell><cell>10.5</cell><cell>17.1</cell><cell>8</cell><cell>9.5</cell><cell>21.2</cell><cell>12</cell><cell>25.8</cell><cell>19.3</cell><cell>17.9</cell></row><row><cell>events</cell><cell>17.4</cell><cell>11.4</cell><cell>19.3</cell><cell>12.6</cell><cell>23.5</cell><cell>10.2</cell><cell>10.9</cell><cell>19.8</cell><cell>14</cell><cell>19.4</cell><cell>30.7</cell><cell>19.1</cell></row><row><cell>hotels</cell><cell>12.1</cell><cell>9.1</cell><cell>15.6</cell><cell>8.7</cell><cell>18.9</cell><cell>8</cell><cell>6.9</cell><cell>17.2</cell><cell>10.5</cell><cell>16.8</cell><cell>17.3</cell><cell>26.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 13 :</head><label>13</label><figDesc>BLEU scores for domain specific models, when evaluated on all domains. The column denotes the domain on which the model was trained, while the row represents the domain used for evaluation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 15 :</head><label>15</label><figDesc>Templates from a RideSharing API.</figDesc><table><row><cell>Dialog Act</cell><cell>Template</cell></row><row><cell>CONFIRM!!subtitle language!!@</cell><cell>with subtitles in @.</cell></row><row><cell>CONFIRM!!title!!@</cell><cell>playing @</cell></row><row><cell>GOODBYE</cell><cell>Have a good day.</cell></row><row><cell>INFORM!!genre!!@</cell><cell>It is a @ movie.</cell></row><row><cell>INFORM!!starring!!@</cell><cell>@ acted in it.</cell></row><row><cell cols="2">INFORM COUNT!!FindMovies!!count!!@ There're @ movies you may like.</cell></row><row><cell>NOTIFY FAILURE!!FindMovies</cell><cell>I failed to find any movies matching your preference.</cell></row><row><cell>NOTIFY FAILURE!!PlayMovie</cell><cell>Failed to play the movie.</cell></row><row><cell>NOTIFY SUCCESS!!PlayMovie</cell><cell>Started playing the movie.</cell></row><row><cell>OFFER!!title!!@</cell><cell>What about @?</cell></row><row><cell>OFFER!!title!!@@</cell><cell>What about @ or @?</cell></row><row><cell>OFFER!!title!!@@@</cell><cell>Do you like @, @ or @?</cell></row><row><cell>OFFER INTENT!!PlayMovie</cell><cell>Do you want to play the movie?</cell></row><row><cell>REQUEST!!genre</cell><cell>What kind of movies do you like?</cell></row><row><cell>REQUEST!!title</cell><cell>Which movie do you want to watch?</cell></row><row><cell>REQ MORE</cell><cell>What else can I help?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 16 :</head><label>16</label><figDesc>Templates from a Movies API.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head></head><label></label><figDesc>Template Do you want to have the car from March 12th? Where do you want to pick up the car? Reference Will you be renting the car from March 12th? Please provide the pick-up location as well. Naive When do you want to start on March 12th and where do you want to pick it up? SlotDesc When do you want it from March 12th to pick it up? T2G2 Do you want to pick up the car from March 12th and where do you want to pick it up? Hotels Actions inform(smoking allowed=False) notify success Template Successfully booked the hotel. No, smoking is not allowed on the property. Reference Your reservation is booked. No, smoking is not allowed on the property at this hotel. Naive Your reservation has been made. Unfortunately, the hotel does not allow you to make the reservation. SlotDesc Your reservation has been made. Unfortunately, they do not allow smoking. T2G2 I have booked the hotel. No, smoking is not allowed on the property. Template Please confirm the following details: Booking a table at Nizza La Bella. The city is Albany. The reservation is at 6:15 pm. The reservation is for 2 people. The date is March 7th.</figDesc><table><row><cell>Domain</cell><cell>Model</cell><cell>Input or Generated sequence</cell></row><row><cell>RentalCars</cell><cell>Actions</cell><cell>request(start date=March 12th) request(pickup location)</cell></row><row><cell>Homes</cell><cell>Actions</cell><cell>confirm(property name=Almaden lake Apartments) confirm(visit date=March 13th)</cell></row><row><cell></cell><cell>Template</cell><cell>Please confirm the following details: You are scheduling a visit to Almaden Lake Apartments and you</cell></row><row><cell></cell><cell></cell><cell>want to visit the property on March 13th.</cell></row><row><cell></cell><cell>Reference</cell><cell>Please confirm details to schedule a visit to Almaden lake Apartments on March 13th.</cell></row><row><cell></cell><cell>Naive</cell><cell>Please confirm the following details: You are scheduling a visit to Almaden lake Apartments on March</cell></row><row><cell></cell><cell></cell><cell>13th.</cell></row><row><cell></cell><cell>SlotDesc</cell><cell>Please confirm: You want to visit Almaden lake Apartments on March 13th.</cell></row><row><cell></cell><cell>T2G2</cell><cell>Please confirm the following details: You are scheduling a visit to Almaden Lake Apartments on March</cell></row><row><cell></cell><cell></cell><cell>13th.</cell></row><row><cell>Services</cell><cell>Actions</cell><cell>request(type)</cell></row><row><cell></cell><cell>Template</cell><cell>What kind of therapist do you need?</cell></row><row><cell></cell><cell>Reference</cell><cell>Let me know your required type of Therapist to search for.</cell></row><row><cell></cell><cell>Naive</cell><cell>What kind of doctor are you looking for?</cell></row><row><cell></cell><cell>SlotDesc</cell><cell>What kind of therapist are you looking for?</cell></row><row><cell></cell><cell>T2G2</cell><cell>What kind of therapist do you need?</cell></row><row><cell>Restaurants</cell><cell>Actions</cell><cell>confirm(restaurant name=Nizza La Bella) confirm(location=Albany) confirm(time=6:15 pm) con-</cell></row><row><cell></cell><cell></cell><cell>firm(number of seats=2) confirm(date=March 7th)</cell></row><row><cell></cell><cell>Reference</cell><cell>Please confirm: You want me to book a table for 2 people at Nizza La Bella located in Albany for 6:15</cell></row><row><cell></cell><cell></cell><cell>pm on March 7th.</cell></row><row><cell></cell><cell>Naive</cell><cell>Please confirm the following details: Booking a table at Nizza La Bella in Albany at 6:15 pm for 2</cell></row><row><cell></cell><cell></cell><cell>people on March 7th.</cell></row><row><cell></cell><cell>SlotDesc</cell><cell>Please confirm the following details: Booking a table at Nizza La Bella in Albany at 6:15 pm for 2</cell></row><row><cell></cell><cell></cell><cell>people on March 7th.</cell></row><row><cell></cell><cell>T2G2</cell><cell>Please confirm the following details: Booking a table at Nizza La Bella in Albany at 6:15 pm on March</cell></row><row><cell></cell><cell></cell><cell>7th for 2 people.</cell></row><row><cell>Media</cell><cell>Actions</cell><cell>inform(starring=Antonio Bustorff)</cell></row><row><cell></cell><cell>Template</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head></head><label></label><figDesc>Template Please confirm the following details: playing the song Strangers in Patio Reference Please confirm: play strangers in patio? Naive Please confirm the following details: Play strangers on the Patio. SlotDesc Please confirm: play strangers on Patio. T2G2 Please confirm the following details: playing Strangers in Patio.</figDesc><table><row><cell></cell><cell>Actions</cell><cell>confirm(track=strangers) confirm(device=Patio)</cell></row><row><cell>Buses</cell><cell>Actions</cell><cell>request(from city) request(departure date)</cell></row><row><cell></cell><cell>Template</cell><cell>Where are you leaving from? When do you plan to leave?</cell></row><row><cell></cell><cell>Reference</cell><cell>What is your departure date and city?</cell></row><row><cell></cell><cell>Naive</cell><cell>Where are you leaving from and when do you plan to leave?</cell></row><row><cell></cell><cell>SlotDesc</cell><cell>Where are you leaving from and when do you plan to leave?</cell></row><row><cell></cell><cell>T2G2</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head></head><label></label><figDesc>Template Please confirm the following details: Booking tickets for Acting For Teens. You have 4 tickets in your reservation. The date of it is March 11th. The event is taking place in New York. Reference Please confirm: You want me to purchase 4 tickets for the event called Acting For Teens taking place in New York on March 11th. Naive Please confirm: 4 tickets to Acting For Teens on March 11th in New York. SlotDesc Please confirm: 4 tickets to Acting For Teens on March 11th in New York. T2G2 Please confirm: Booking 4 tickets for Acting For Teens on March 11th in New York. Template Please confirm the following details: Booking tickets for Mxmtoon. You have 2 tickets in your reservation. The date of it is March 10th. The event is taking place in New York. Reference Can you please confirm that you want to buy 2 tickets for the Mxmtoon event which happens on March 10th in New York? Naive Please confirm: 2 tickets for Mxmtoon on March 10th in New York. SlotDesc Please confirm: 2 tickets to Mxmtoon on March 10th in New York. T2G2 Please confirm: 2 tickets for Mxmtoon on March 10th in New York.</figDesc><table><row><cell>Domain</cell><cell>Model</cell><cell>Input or Generated sequence</cell></row><row><cell>Events</cell><cell>Actions</cell><cell>confirm(event name=Acting For Teens) confirm(number of tickets=4) confirm(date=March 11th) con-</cell></row><row><cell></cell><cell></cell><cell>firm(city=New York)</cell></row><row><cell>Events</cell><cell>Actions</cell><cell>confirm(event name=Mxmtoon) confirm(number of tickets=2) confirm(date=March 10th) con-</cell></row><row><cell></cell><cell></cell><cell>firm(city=New York)</cell></row><row><cell>Alarm *</cell><cell>Actions</cell><cell>offer(alarm time=4 pm) offer(alarm name=Event)</cell></row><row><cell></cell><cell>Template</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head></head><label></label><figDesc>Travel Actions offer(attraction name=BODY WORLDS London) offer(category=Museum) Template You should check out BODY WORLDS London. This is a Museum. Reference I suggest a museum called BODY WORLDS London. Naive BODY WORLDS London is a Museum. SlotDesc BODY WORLDS London is a museum.</figDesc><table /><note>T2G2 BODY WORLDS London is a museum.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code and data is available at github.com/googleresearch/schema-guided-dialogue</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">github.com/google-research/text-to-text-transfertransformer</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Examples of the rating UI can be found in Appendix E.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards Zero-Shot Frame Semantic Parsing for Domain Scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2017-518</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech 2017</title>
		<meeting>Interspeech 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2476" to="2480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentence Fusion for Multidocument News Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kathleen R Mckeown</surname></persName>
		</author>
		<idno type="DOI">10.1162/089120105774321091</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="328" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural Generation for Czech: Data and Baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jurcicek</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-8670</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Natural Language Generation</title>
		<meeting>the 12th International Conference on Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="563" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The WebNLG Challenge: Generating Text from RDF Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-3518</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Natural Language Generation</title>
		<meeting>the 10th International Conference on Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating Sentences by Editing Prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00030</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="437" to="450" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simple and Effective Retrieve-Edit-Rerank Text Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nabil</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.228</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2532" to="2538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">2005</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Text-to-Text Pre-Training for Data-to-Text Tasks. arXiv</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Machine Translation Pre-training for Data-to-Text Generation-A Case Study in Czech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02077</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Nitish Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05858</idno>
		<title level="m">CTRL: A Conditional Transformer Language Model for Controllable Generation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhaya</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation</title>
		<meeting>the Second Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="228" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural Text Generation from Structured Data with Application to the Biography Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R&amp;apos;emi</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1128</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1203" to="1213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boi</forename><surname>Faltings</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/437</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3151" to="3157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">To Plan or not to Plan? Discourse Planning in Slot-Value Informed Sequence to Sequence Models for Language Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neha</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2017-1525</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3339" to="3343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The E2E Dataset: New Challenges For End-to-End Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Ond Rej Du Sek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rieser</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-5525</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BLEU: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Few-shot Natural Language Generation for Task-Oriented Dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12328</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Language Models are Unsupervised Multitask Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ope-nAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Khaitan</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6394</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adversarial Domain Adaptation for Variational Neural Language Generation in Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><forename type="middle">Le</forename><surname>Van-Khanh Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1205" to="1217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CIDEr: Consensus-based Image Description Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4566" to="4575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-domain Neural Network Language Generation for Spoken Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina M Rojas</forename><surname>Mrk Si&amp;apos;c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1015</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Mrk Si&amp;apos;c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1199</idno>
	</analytic>
	<monogr>
		<title level="m">Dialog Act Template GOODBYE Enjoy! INFORM!!free entry!!False No, entry to this place is not free. INFORM!!free entry!!True Yes</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>entry is free</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">INFORM!!good for kids!!False No, this place isn&apos;t exactly good for kids. INFORM!!good for kids!!True Yes, the place is pretty nice to take your kids to. INFORM!!phone number!!@ Their phone number is @</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">INFORM COUNT!!FindAttractions!!count!!@ There are @ attractions that could interest you. NOTIFY FAILURE!!FindAttractions Sorry, can&apos;t find anything for your constraints</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">!!location Where should I search for attractions in? REQ MORE Anything else I could assist with? is expected in @ minutes. NOTIFY FAILURE!!GetRide I&apos;m sorry, I could not find a ride for you at this time. NOTIFY SUCCESS!!GetRide I booked your ride and the cab is on its way. REQUEST!!destination Where do you want to go to? REQUEST!!destination!!@ Are you going to @? REQUEST!!destination!!@@ Are you going to @ or @? REQUEST!!number of seats How many seats do you need?</title>
		<imprint/>
	</monogr>
	<note>REQUEST!!ride type Do you have a preferred type of ride? REQ MORE Can I help you with anything else</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
