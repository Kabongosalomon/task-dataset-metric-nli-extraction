<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Visual Domain Adaptation: A Deep Max-Margin Gaussian Process Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyoung</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Electronic Engineering</orgName>
								<orgName type="institution">Seoul National University of Science &amp; Technology</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pritish</forename><surname>Sahu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Gholami</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Pavlovic</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Visual Domain Adaptation: A Deep Max-Margin Gaussian Process Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In unsupervised domain adaptation, it is widely known that the target domain error can be provably reduced by having a shared input representation that makes the source and target domains indistinguishable from each other. Very recently it has been studied that not just matching the marginal input distributions, but the alignment of output (class) distributions is also critical. The latter can be achieved by minimizing the maximum discrepancy of predictors (classifiers). In this paper, we adopt this principle, but propose a more systematic and effective way to achieve hypothesis consistency via Gaussian processes (GP). The GP allows us to define/induce a hypothesis space of the classifiers from the posterior distribution of the latent random functions, turning the learning into a simple large-margin posterior separation problem, far easier to solve than previous approaches based on adversarial minimax optimization. We formulate a learning objective that effectively pushes the posterior to minimize the maximum discrepancy. This is further shown to be equivalent to maximizing margins and minimizing uncertainty of the class predictions in the target domain, a well-established principle in classical (semi-)supervised learning. Empirical results demonstrate that our approach is comparable or superior to the existing methods on several benchmark domain adaptation datasets. *</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The success of deep visual learning largely relies on the abundance of data annotated with ground-truth labels where the main assumption is that the training and test data follow from the same underlying distribution. However, in real-world problems this presumption rarely holds due to a number of artifacts, such as the different types of noise or sensors, changes in object view or context, resulting in degradation of performance during inference on test data. One way to address this problem would be to collect labeled data in the test domain and learn a test-specific classifier while possibly leveraging the model estimated from the training data. Nevertheless, this would typically be a highly costly effort.</p><p>Domain adaptation, a formalism to circumvent the aforementioned problem, is the task of adapting a model trained in one domain, called the source, to another target domain, where the source domain data is typically fully labeled but we only have access to images from the target domain with no (or very few) labels. Although there are several slightly different setups for the problem, in this paper we focus on the unsupervised domain adaptation (UDA) with classification of instances as the ultimate objective. That is, given the fully labeled data from the source domain and unlabeled data from the target, the goal is to learn a classifier that performs well on the target domain itself.</p><p>One mainstream direction to tackle UDA is the shared space embedding process. The idea is to find a latent space shared by both domains such that the classifier learned on it using the fully labeled data from the source will also perform well on the target domain. This is accomplished, and supported in theory <ref type="bibr" target="#b2">[3]</ref>, by enforcing a requirement that the distributions of latent points in the two domains be indistinguishable from each other. A large family of UDA approaches including <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b14">15]</ref> leverage this idea (see Sec. 4 for more details). However, their performance remains unsatisfactory, in part because the methods inherently rely on matching of marginal, class-free, distributions while using the underlying assumption that the shift in the two distributions, termed covariate shift <ref type="bibr" target="#b52">[53]</ref>, can be reduced without using the target domain labels.</p><p>To address this issue, an effective solution was proposed in <ref type="bibr" target="#b48">[49]</ref>, which aims to take into account the class-specific decision boundary. Its motivation follows the theorem in <ref type="bibr" target="#b1">[2]</ref> relating the target domain error to the maximal disagreement between any two classifiers, tighter than the former bound in <ref type="bibr" target="#b2">[3]</ref>. It implies that a provably small target error is achievable by minimizing the maximum classifier discrepancy (MCD). The approach in <ref type="bibr" target="#b48">[49]</ref>, the MCD Algorithm (MCDA for short), attempted to minimize MCD directly using adversarial learning similar to GAN training <ref type="bibr" target="#b17">[18]</ref>, i.e., through solving a minimax problem that finds the pair of most discrepant classifiers and reduces their disagreement.</p><p>In this paper we further extend the MCD principle by proposing a more systematic and effective way to achieve consistency in the hypothesis space of classifiers H through Gaussian process (GP) <ref type="bibr" target="#b44">[45]</ref> endowed priors, with deep neural networks (DNNs) used to induce their mean and covariance functions. The crux of our approach is to regard the classifiers as random functions and use their posterior distribution conditioned on the source samples, as the prior on H. The key consequence and advantages of this Bayesian treatment are: (1) One can effectively minimize the inconsistency in H over the target domain by regularizing the source-induced prior using a max-margin learning principle <ref type="bibr" target="#b58">[59]</ref>, a significantly easier-to-solve task than the minimax optimization of <ref type="bibr" target="#b48">[49]</ref> which may suffer from the difficulty of attaining an equilibrium point coupled with the need for proper initialization. <ref type="bibr" target="#b1">(2)</ref> We can quantify the measure of prediction uncertainty and use it to credibly gauge the quality of prediction at test time.</p><p>Although GP models were previously known to suffer from the scalability issues <ref type="bibr" target="#b44">[45]</ref>, we utilize recent deep kernel techniques <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b59">60]</ref> to turn the non-parametric Bayesian inference into a more tractable parametric one, leading to a learning algorithm computationally as scalable and efficient as conventional (non-Bayesian) deep models. Our extensive experimental results on several standard benchmarks demonstrate that the proposed approach achieves state-of-the-art prediction performance, outpacing recent UDA methods including MCDA [49].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Setup and Preliminaries</head><p>We begin with the formal description of the UDA task for a multi-class classification problem. Unsupervised domain adaptation: Consider the joint space of inputs and class labels, X × Y where Y = {1, . . . , K} for (K-way) classification. Suppose we have two domains on this joint space, source (S) and target (T), defined by unknown distributions p S (x, y) and p T (x, y), respectively. We are given source-domain training examples with labels</p><formula xml:id="formula_0">D S = {(x S i , y S i )} N S i=1 and target data D T = {x T i } N T i=1</formula><p>with no labels. We assume the shared set of class labels between the two domains. The goal is to assign the correct class labels {y T i } to target data points D T . To tackle the problem in the shared latent space framework, we seek to learn the embedding function G : X → Z and a classifier h : Z → Y in the shared latent space Z. The embedding function G(·) and the classifier h(·) are shared across both domains and will be applied to classify samples in the target domain using the composition y = h(z) = h(G(x)).</p><p>Our goal is to find the pair (h, G) resulting in the lowest generalization error on the target domain,</p><formula xml:id="formula_1">(h * , G * ) = arg min h,G e T (h, G) = arg min h,G E (x,y)∼p T (x,y) [I(h(G(x)) = y)],<label>(1)</label></formula><p>with I(·) the 1/0 indicator function. Optimizing e T directly is typically infeasible. Instead, one can exploit the upper bounds proposed in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b2">[3]</ref>, which we restate, without loss of generality, for the case of fixed G.</p><p>Theorem 1 <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> Suppose that H is symmetric (i.e., h ∈ H implies −h ∈ H). For any h ∈ H, the following holds 1 :</p><formula xml:id="formula_2">e T (h) ≤ e S (h) + sup h,h ∈H d S (h, h ) − d T (h, h ) + e * (2) ≤ e S (h) + sup h∈H d S (h, +1) − d T (h, +1)] + e *<label>(3)</label></formula><p>Here e S (h) is the error rate of h(·) on the source domain, e * := min h∈H e S (h) + e T (h), and d S (h, h ) := E z∼S [I(h(z) = h (z))] denotes the discrepancy between two classifiers h and h on the source domain S, and similarly for d T (h, h ). We use z ∼ S to denote the distribution of z in the latent space induced by G and p S (x, y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Looser bound.</head><p>With e * the uncontrollable quantity, due to the lack of labels for T in the training data, the optimal h can be sought through minimization of the source error e S (h) and the worst-case discrepancy terms. In the looser bound (3), the supremum term is, up to a constant, equivalent to sup h∈H E z∼S [I(h(z) = +1)] + E z∼T [I(h(z) = −1)], the maximal accuracy of a domain discriminator (labeling S as +1 and T as −1). Hence, to reduce the upper bound one needs to choose the embedding G where the source and the target inputs are indistinguishable from each other in Z. This input density matching was exploited in many previous approaches <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b55">56]</ref>, and typically accomplished through adversarial learning <ref type="bibr" target="#b17">[18]</ref> or the maximum mean discrepancy <ref type="bibr" target="#b20">[21]</ref>.</p><p>Tighter bound. Recently, <ref type="bibr" target="#b48">[49]</ref> exploited the tighter bound (2) under the assumption that H is restricted to classifiers with small errors on S. Consequently, d S (h, h ) becomes negligible as any two h, h ∈ H agree on the source domain. The supremum in <ref type="bibr" target="#b1">(2)</ref>, interpreted as the Maximum Classifier Discrepancy (MCD), reduces to: sup</p><formula xml:id="formula_3">h,h ∈H E (x,y)∼p T (x,y) [I(h(z) = h (z))].<label>(4)</label></formula><p>Named MCDA, <ref type="bibr" target="#b48">[49]</ref> aims to minimize (4) directly via adversarial-cooperative learning of two deep classifier networks h(z) and h (z). For the source domain data, these two classifiers and G aim to minimize the classification errors cooperatively. An adversarial game is played in the target domain: h and h aim to be maximally discrepant, whereas G seeks to minimize the discrepancy 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Approach</head><p>Overview. We adopt the MCD principle, but propose a more systematic and effective way to achieve hypothesis consistency, instead of the difficult minimax optimization. Our idea is to adopt a Bayesian framework to induce the hypothesis space. Specifically, we build a Gaussian process classifier model <ref type="bibr" target="#b44">[45]</ref> on top of the share space. The GP posterior inferred from the source domain data naturally defines our hypothesis space H. We then optimize the embedding G and the kernel of the GP so that the posterior hypothesis distribution leads to consistent (least discrepant) class predictions most of the time, resulting in reduction of (4). The details are described in the below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">GP-endowed Maximum Separation Model</head><p>We consider a multi-class Gaussian process classifier defined on Z: there are K underlying latent functions f (·) := {f j (·)} K j=1 , a priori independently GP distributed, namely</p><formula xml:id="formula_4">P (f ) = K j=1 P (f j ), f j ∼ GP 0, k j (·, ·) ,<label>(5)</label></formula><p>where each k j is a covariance function of f j , defined on Z × Z. For an input point z ∈ Z, we regard f j (z) as the model's confidence toward class j, leading to the class prediction rule:</p><formula xml:id="formula_5">class(z) = arg max 1≤j≤K f j (z).<label>(6)</label></formula><p>We use the softmax likelihood model,</p><formula xml:id="formula_6">P (y = j|f (z)) = e fj (z) K r=1 e fr(z)</formula><p>, for j = 1, . . . , K.</p><p>Source-driven H Prior. The labeled source data, D S , induces a posterior distribution on the latent functions f ,</p><formula xml:id="formula_8">p(f |D S ) ∝ p(f ) · N S i=1 P (y S i |f (z S i )),<label>(8)</label></formula><p>where</p><formula xml:id="formula_9">z S i = G(x S i ).</formula><p>The key idea is to use (8) to define our hypothesis space H. The posterior places most of its probability mass on those f that attain high likelihood scores on S while being smooth due to the GP prior. It should be noted that we used the term prior of the hypothesis space H that is induced from the posterior of the latent functions f . We use the H prior and the posterior of f interchangeably.</p><p>Note that due to the non-linear/non-Gaussian likelihood <ref type="bibr" target="#b6">(7)</ref>, exact posterior inference is intractable, and one has to resort to approximate inference. We will discuss an approach for efficient variational approximate inference in Sec. 3.2. For the exposition here, let us assume that the posterior distribution is accessible. For each posterior, we also depict two plausible samples (marked as crosses). In p A , most samples f (z), including the two shown, are consistent in deciding the class label (class 2, red, predicted in this case). On the other hand, in p B where f 1 (z) and f 2 (z) have considerable overlap, there is significant chance of different predictions: class 2 for the first sample and class 1 for the second.</p><p>Target-driven Maximally Consistent Posterior. While D S serves to induce the prior of H, D T will be used to reshape this prior. According to MCD, we want this hypothesis space to be shaped in the following way: for each target domain point z = G(x), x ∼ T , the latent function values f (z) sampled from the posterior (8) should lead to the class prediction (made by <ref type="bibr" target="#b5">(6)</ref>) that is as consistent as possible across the samples. This is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. Consider two different H priors p A and p B at a point z, p A (f (z)) and p B (f (z)), where for brevity we drop the conditioning on D S in notation. The class cardinality is K = 3. For simplicity, we assume that the latent functions f j 's are independent from each other. <ref type="figure" target="#fig_0">Fig. 1</ref> shows that the distributions of f j 's are well-separated from each other in p A , yet overlap significantly in p B . Hence, there is a strong chance for the class predictions to be inconsistent in p B (identical ordering of colored samples below figure), but consistent in p A . This means that the hypothesis space induced from p B contains highly discrepant classifiers, whereas most classifiers in the hypothesis space of p A agree with each other (least discrepant). In other words, the maximum discrepancy principle translates into the maximum posterior separation in our Bayesian GP framework.</p><p>We describe how this goal can be properly formulated. First we consider the posterior of f to be approximated as an independent Gaussian 3 . For any target domain point z ∼ T and each j = 1, . . . , K let the mean and the variance of the H prior in (8) be:</p><formula xml:id="formula_10">µ j (z) := f j (z) p f j (z)|D S , z df j (z),<label>(9)</label></formula><formula xml:id="formula_11">σ 2 j (z) := (f j (z) − µ j (z)) 2 p f j (z)|D S , z df j (z).<label>(10)</label></formula><p>The maximum-a-posterior (MAP) class prediction by the model is denoted by j * = arg max 1≤j≤K µ j (z). As we seek to avoid fluctuations in class prediction j * across samples, we consider the worst scenario where even an unlikely (e.g., at 5% chance level) sample from f j (z), j other than j * , cannot overtake µ j * (z). That is, we seek</p><formula xml:id="formula_12">µ j * (z) − ασ j * (z) ≥ max j =j * µ j (z) + ασ j (z) ,<label>(11)</label></formula><p>where α is the normal cutting point for the least chance (e.g., α = 1.96 if 2.5% one-side is considered). While this should hold for most samples, it will not hold for all. We therefore introduce an additional slack ξ ≥ 0 to relax the desideratum. Furthermore, for ease of optimization 4 , we impose slightly stricter constraint than <ref type="bibr" target="#b10">(11)</ref>, leading to the final constraint: max</p><formula xml:id="formula_13">1≤j≤K µ j (z) ≥ 1 + max j =j * µ j (z) + α max 1≤j≤K σ j (z) − ξ(z).<label>(12)</label></formula><p>A constant, 1 here, was added to normalize the scale of f j 's. Our objective now is to find such embedding G, GP kernel parameters k, and minimal slacks ξ, to impose <ref type="bibr" target="#b11">(12)</ref>. Equiva-lently, we pose it as the following optimization problem, for each z ∼ T : <ref type="bibr" target="#b12">13)</ref> with (a) + = max(0, a). Note that <ref type="formula" target="#formula_1">(12)</ref> and <ref type="formula" target="#formula_1">(13)</ref> are reminiscent of the large-margin classifier learning in traditional supervised learning <ref type="bibr" target="#b57">[58]</ref>. In contrast, we replace the ground-truth labels with the the most confidently predicted labels by our model since the target domain is unlabeled. This aims to place class boundaries in low-density regions, in line with entropy minimization or max-margin confident prediction principle of classical semi-supervised learning <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b66">67]</ref>.</p><formula xml:id="formula_14">min G,k max j =j * µj(z) − max 1≤j≤K µj(z) + 1 + α max 1≤j≤K σj(z) +<label>(</label></formula><p>In what follows, we describe an approximate, scalable GP posterior inference, where we combine the variational inference optimization with the aforementioned posterior maximum separation criterion (13).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Variational Inference with Deep Kernels</head><p>We describe our scalable variational inference approach to approximate the posterior <ref type="bibr" target="#b7">(8)</ref>. Although there are scalable GP approximation schemes based on the random feature expansion <ref type="bibr" target="#b43">[44]</ref> and the pseudo/induced inputs <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b11">12]</ref>, here we adopt the deep kernel trick <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b59">60]</ref> to exploit the deeply structured features. The main idea is to model an explicit finitedimensional feature space mapping to define a covariance function. Specifically, we consider a nonlinear feature mapping φ : Z → R d such that the covariance function is defined as an inner product in a feature space, namely k(z, z ) := φ(z) φ(z ), where we model φ(·) as a deep neural network. A critical advantage of explicit feature representation is that we turn the non-parametric GP into a parametric Bayesian model. As a consequence, all inference operations in the non-parametric GP reduce to computationally more efficient parametric ones, avoiding the need to store the Gram matrix of the entire training data set, as well as its inversion.</p><p>Formally, we consider K latent functions modeled as f j (z) = w j φ(z) with w j ∼ N (0, I) independently for j = 1, . . . , K. We let W = [w 1 , . . . , w K ] . Note that the feature function φ(·) is shared across classes to reduce the number of parameters and avoid overfitting. The parameters of the deep model that represents φ(·) serve as GP kernel parameters,</p><formula xml:id="formula_15">since Cov(f (z), f (z )) = Cov(w φ(z), w φ(z )) = φ(z) φ(z ) = k(z, z ). Consequently, the source-driven H prior (8) becomes p(W|D S ) ∝ K j=1 N (w j ; 0, I) · N S i=1 P (y S i |Wφ(z S i )).<label>(14)</label></formula><p>Since computing <ref type="formula" target="#formula_1">(14)</ref> is intractable, we introduce a variational density q(W) to approximate it. We assume a fully factorized Gaussian,</p><formula xml:id="formula_16">q(W) = K j=1 N (w j ; m j , S j ),<label>(15)</label></formula><p>where m j ∈ R d and S j ∈ R d×d constitute the variational parameters. We further let S j 's be diagonal matrices. To have q(W) ≈ p(W|D S ), we use the following fact that the marginal log-likelihood can be lower bounded:</p><formula xml:id="formula_17">log P {y S i } N S i=1 {z S i } N S i=1 , φ(·) ≥ ELBO,<label>(16)</label></formula><p>where the evidence lower-bound (ELBO) is defined as:</p><formula xml:id="formula_18">ELBO := N S i=1 E q(W) log P (y S i |Wφ(z S i )) − K j=1 KL q(w j ) || N (w j ; 0, I) ,<label>(17)</label></formula><p>with the likelihood stemming from <ref type="bibr" target="#b6">(7)</ref>. As the gap in <ref type="bibr" target="#b15">(16)</ref> is the KL divergence between q(W) and the true posterior p(W|D S ), increasing the ELBO wrt the variational parameters {(m j , S j )} brings q(W) closer to the true posterior. Raising the ELBO wrt the GP kernel parameters (i.e., the parameters of φ) and the embedding 5 G can potentially improve the marginal likelihood (i.e., the left hand side in <ref type="bibr" target="#b15">(16)</ref>).</p><p>In optimizing the ELBO (17), the KL term (denoted by KL) can be analytically derived as</p><formula xml:id="formula_19">KL = 1 2 K j=1 Tr(S j ) + ||m j || 2 2 − log det(S j ) − d .<label>(18)</label></formula><p>However, there are two key challenges: the log-likelihood expectation over q(W) does not admit a closed form, and one has to deal with large N S . To address the former, we adopt Monte-Carlo estimation using M iid samples {W (m) } M m=1 from q(W), where the samples are expressed in terms of the variational parameters (i.e., the reparametrization trick <ref type="bibr" target="#b27">[28]</ref>) to facilitate optimization. That is, for each j and m,</p><formula xml:id="formula_20">w (m) j = m j + S 1/2 j (m) j , (m) j ∼ N (0, I).<label>(19)</label></formula><p>For the latter issue, we use stochastic optimization with a random mini-batch B S ⊂ D S . That is, we optimize the sample estimate of the log-likelihood defined as:</p><formula xml:id="formula_21">LL = 1 M M m=1 N S |B S | i∈B S log P (y S i |W (m) φ(z S i )).<label>(20)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization Strategy</head><p>Now we combine the maximum posterior separation criterion in <ref type="bibr" target="#b12">(13)</ref> with the variational inference discussed in the previous section to arrive at the comprehensive optimization task.</p><p>Our approximate posterior (15) leads to closed-form expressions for µ j (z) and σ j (z) in (9-10) as follows:</p><formula xml:id="formula_22">µ j (z) ≈ m j φ(z), σ j (z) ≈ φ(z) S j φ(z) 1/2 .<label>(21)</label></formula><p>With q(W) fixed, we rewrite our posterior maximum separation loss in (13) as follows. We consider stochastic optimization with a random mini-batch</p><formula xml:id="formula_23">B T ⊂ D T = {z T i } N T i=1 sampled from the target domain data. MS := 1 |B T | i∈B T max j =j * m j φ(z T i ) − max 1≤j≤K m j φ(z T i ) + 1 + α max 1≤j≤K φ(z T i ) S j φ(z T i ) 1/2 +<label>(22)</label></formula><p>Combining all objectives thus far, our algorithm 6 can be summarized as the following two optimizations alternating with each other:</p><formula xml:id="formula_24">• min {mj ,Sj } −LL + KL (variational inference) • min G,k −LL + KL + λ · MS (model selection)</formula><p>where λ is the impact of the maximum separation loss (e.g., λ = 10.0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>There has been extensive prior work on domain adaptation <ref type="bibr" target="#b8">[9]</ref>. Recent approaches have focused on transferring deep neural network representations from a labeled source dataset to an unlabeled target domain by matching the distributions of features between different domains, aiming to extract domain-invariant features <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b46">47]</ref>. To this end, it is critical to first define a measure of distance (divergence) between source and target distributions. One popular measure is the non-parametric Maximum Mean Discrepancy (MMD) (adopted by <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b33">34]</ref>), which measures the distance between the sample means of the two domains in the reproducing Kernel Hilbert Space (RKHS) induced by a pre-specified kernel. The deep Correlation Alignment (CORAL) method <ref type="bibr" target="#b53">[54]</ref> attempted to match the sample mean and covariance of the source/target distributions, while it was further generalized to potentially infinite-dimensional feature spaces in <ref type="bibr" target="#b64">[65]</ref> to effectively align the RKHS covariance matrices (descriptors) across domains.</p><p>The Deep Adaptation Network (DAN) <ref type="bibr" target="#b32">[33]</ref> applied MMD to layers embedded in a RKHS to match higher order moments of the two distributions more effectively. The Deep Transfer Network (DTN) <ref type="bibr" target="#b63">[64]</ref> achieved alignment of source and target distributions using two types of network layers based on the MMD distance: the shared feature extraction layer that can learn a subspace that matches the marginal distributions of the source and the target samples, and the discrimination layer that can match the conditional distributions by classifier transduction.</p><p>Many recent UDA approaches leverage deep neural networks with the adversarial training strategy <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b62">63]</ref>, which allows the learning of feature representations to be simultaneously discriminative for the labeled source domain data and indistinguishable between source and target domains. For instance, <ref type="bibr" target="#b12">[13]</ref> proposed a technique called the Domain-Adversarial Training of Neural Networks (DANN), which allows the network to learn domain invariant representations in  an adversarial fashion by adding an auxiliary domain classifier and back-propagating inverse gradients. The Adversarial Discriminative Domain Adaptation (ADDA) <ref type="bibr" target="#b55">[56]</ref> first learns a discriminative feature subspace using the labeled source samples. Then, it encodes the target data to this subspace using an asymmetric transformation learned through a domainadversarial loss. The DupGAN <ref type="bibr" target="#b23">[24]</ref> proposed a GAN-like model <ref type="bibr" target="#b17">[18]</ref> with duplex discriminators to restrict the latent representation to be domain invariant while its category information being preserved.</p><p>In parallel, within the shared-latent space framework, <ref type="bibr" target="#b30">[31]</ref> proposed an unsupervised image-to-image translation (UNIT) framework based on the Coupled GANs <ref type="bibr" target="#b31">[32]</ref>. Another interesting idea is the pixel-level domain adaptation method (PixelDA) <ref type="bibr" target="#b5">[6]</ref> where they imposed alignment of distributions not in the feature space but directly in the raw pixel space via the adversarial approaches. The intention is to adapt the source samples as if they were drawn from the target domain, while maintaining the original content. Similarly, <ref type="bibr" target="#b39">[40]</ref> utilized the CycleGAN [66] to constrain the features extracted by the encoder network to reconstruct the images in both domains. In <ref type="bibr" target="#b49">[50]</ref>, they proposed a joint adversarial discriminative approach that can transfer the information of the target distribution to the learned embedding using a generator-discriminator pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>We compare the proposed method with state-of-the-art on standard benchmark datasets. Digit classification task consists of three datasets, containing ten digit classes: MNIST <ref type="bibr" target="#b28">[29]</ref>, SVHN <ref type="bibr" target="#b40">[41]</ref>, USPS <ref type="bibr" target="#b55">[56]</ref>. We also evaluated our method on the traffic sign datasets, Synthetic Traffic Signs (SYN SIGNS) <ref type="bibr" target="#b37">[38]</ref> and the German Traffic Signs Recognition Benchmark <ref type="bibr" target="#b51">[52]</ref> (GTSRB), which contain 43 types of signs. Finally, we report performance on VisDA object classification dataset <ref type="bibr" target="#b41">[42]</ref> with more than 280K images across twelve categories ( the details of the datasets are available in the Supplementary Material). <ref type="figure" target="#fig_2">Fig. 2</ref> illustrates image samples from different datasets and domains.</p><p>We evaluate the performance of all methods with the classification accuracy score. We used ADAM <ref type="bibr" target="#b26">[27]</ref> for training; the learning rate was set to 0.0002 and momentum to 0.5 and 0.999. We used batches of size 32 from each domain, and the input images were mean-centered. The hyper-parameters are empirically set as λ = 50.0, α = 2.0. The sensitivity w.r.t. hyperparameters λ and α will be discussed in Sec. 5.3. We also used the same network structure as <ref type="bibr" target="#b48">[49]</ref>. Specifically, we employed the CNN architecture used in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b5">[6]</ref> for digit and traffic sign datasets and used ResNet101 [23] model pre-trained on Imagenet <ref type="bibr" target="#b9">[10]</ref>. We added batch normalization to each layer in these models. Quantitative evaluation involves a comparison of the performance of our model to previous works and to Source Only that do not use any domain adaptation. For "Source Only" baseline, we train models on the unaltered source training data and evaluate on the target test data. The training details for comparing methods are available in our Supplementary material due to the space limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results on Digit and Traffic Signs datasets</head><p>We show the accuracy of different methods in Tab. 1. It can be seen the proposed method outperformed competitors in all settings confirming consistently better generalization of our model over target data. This is partially due to combining DNNs and GPs/Bayesian approach. GPs exploit local generalization by locally interpolating between neighbors <ref type="bibr" target="#b4">[5]</ref>, adjusting the target functions rapidly in the presence of training data. DNNs have good generalization capability for unseen input configurations by learning multiple levels of distributed representations. The results demonstrate GPDA can improve generalization performance by adopting both of these advantages.  <ref type="table">Table 1</ref>: Classification results on the digits and traffic signs datasets (best viewed in color). The best score is in bold red, second best in light red. Results are cited from each study. The score of MMD is cited from DSN <ref type="bibr" target="#b6">[7]</ref>. † indicates the method used a few labeled target samples as validation, different from our GPDA setting. We repeated each experiment five times and report the average and the standard deviation of the accuracy. The accuracy for MCDA was obtained from classifier F 1 . n is MCDA's hyper-parameter, which denotes the number of times the feature generator is updated to mimic classifiers. MNIST * and USPS * denote all the training samples were used to train the models.  <ref type="table">Table 2</ref>: Accuracy of ResNet101 model fine-tuned on the VisDA dataset. Last column shows the average rank of each method over all classes. The best (in bold red), the second best (in red).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results on VisDA dataset</head><p>Results for this experiment are summarized in Tab. 2. We observe that our GPDA achieved, on average, the best performance compared to other competing methods. Due to vastly varying difficulty of classifying different categories of objects, in addition to reporting the average classification accuracy we also report the average rank of each method over all objects (the lower rank, the better). The higher performance of GPDA compared to other methods is mainly attributed to modeling the classifier as a random function and consequently incorporating the classifier uncertainty (variance of the prediction) into the proposed loss function, Eq. 28. The image structure for this dataset is more complex than that of digits, yet our method exhibits very strong performance even under such challenging conditions. Another key observation is that some of the competing methods (e.g., MMD, DANN) perform worse than the source-only model in classes such as car and plant, while GPDA and MCDA performed better across all classes, which clearly demonstrates the effectiveness of the MCD principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Studies</head><p>Two complementary studies are conducted to investigate the impact of two hyper-parameters α and λ, controlling the trade off of the variance of the classifier's posterior distribution and the MCD loss term, respectively. To this end, we conducted additional experiments for the digit datasets to analyze the parameter sensitivity of GPDA w.r.t. α and λ, with results depicted in <ref type="figure" target="#fig_4">Fig. 3a and 3b</ref>, respectively. Sensitivity analysis is performed by varying one parameter at the time over a given range, while for the other parameters we set them to their final values (α = 2, λ = 50). From <ref type="figure" target="#fig_4">Fig. 3b</ref>, we see that when λ = 0 (no  MCD regularization term), the performance drops considerably. As λ increases from 0 to 50, the performance also increases demonstrating the benefit of hypothesis consistency (MS term) over the target samples. Indeed, using the proposed learning scheme, we find a representation space in which we embed the knowledge from the target domain into the learned classifier. Similarly, from <ref type="figure" target="#fig_4">Fig. 3a</ref>, we see that when α = 0 (no prediction uncertainty) the classification accuracy is lower than the case where we utilize the prediction uncertainty, α &gt; 0. The key observation is that it is more beneficial to make use of the information from the full posterior distribution of the classifier during the learning process in contrast to when the classifier is considered as a deterministic function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Prediction Uncertainty vs. Prediction Quality</head><p>Another advantage of our GPDA model, inherited from Bayesian modeling, is that it provides a quantified measure of prediction uncertainty. In the multi-class setup considered here, this uncertainty amounts to the degree of overlap between two largest mean posteriors, p(f j * (z)|D S ) and p(f j † (z)|D S ), where j * and j † are the indices of the largest and the second largest among the posterior means {µ j (z)} K j=1 , respectively (c.f., <ref type="bibr" target="#b8">(9)</ref>). Intuitively, if the two are overlapped significantly, our model's decision is less certain, meaning that we anticipate the class prediction may not be trustworthy. On the other hand, if the two are well separated, we expect high prediction quality.</p><p>To verify this hypothesis more rigorously, we evaluate the distances between two posteriors (i.e., measure of certainty in prediction) for two different cohorts: correctly classified test target samples by our model and incorrectly predicted ones. More specifically, for the SVHN to MNIST adaptation task, we evaluate the Bhattacharyya distances <ref type="bibr" target="#b10">[11]</ref> for the samples in the two cohorts. In our variational Gaussian approximation <ref type="bibr" target="#b20">(21)</ref>, the Bhattacharyya distance can be computed in a closed form (See Appendix in supplementary for details).</p><p>The histograms of the distances are depicted in <ref type="figure" target="#fig_6">Fig. 4</ref> where we contrast the two models, one at an early stage of training and the other after convergence. Our final model in <ref type="figure" target="#fig_6">Fig. 4(a)</ref> exhibits large distances for most of the samples in the correctly predicted cohort (green), implying well separated posteriors or high certainty. For the incorrectly predicted samples (red), the distances are small implying significant overlap between the two posteriors, i.e., high uncertainty. On the other hand, for the model prior to convergence, <ref type="figure" target="#fig_6">Fig. 4(b)</ref>, the two posteriors overlap strongly (small distances along horizontal axis) for most samples regardless of the correctness of prediction. This confirms that our algorithm enforces posterior separation by large margin during the training process.</p><p>This analysis also suggests that the measure of prediction uncertainty provided by our GPDA model, can be used as an indicator of prediction quality, namely whether the prediction made by our model is trustworthy or not. To verify this, we depict some sample test images in <ref type="figure" target="#fig_7">Fig. 5</ref>. We differentiate samples according to their Bhattacharyya distances. When the prediction is uncertain (left panel), we see that the images are indeed difficult examples even for human. An interesting case is when the prediction certainty is high but incorrectly classified (lower right panel), where the images look peculiar in the sense that humans are also prone to misclassify those with considerably high certainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Analysis of Shared Space Embedding</head><p>We use t-SNE <ref type="bibr" target="#b34">[35]</ref> on VisDA dataset to visualize the feature representations from different classes.  The X-axis is the Bhattacharyya distance b/w two largest mean posteriors, an indication of prediction certainty; the higher the distance, the more certain the prediction is. For each model, we compute histograms of correctly and incorrectly predicted samples separately (by color). In our final model (a), there is a strong correlation between prediction (un)certainty (horizontal axis) and prediction correctness (color). due to the use of the proposed probabilistic MCD approach, which shrinks the classifier hypothesis class to contain only consistent classifiers on target samples while exploiting the uncertainty in the prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVHN MNIST</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We proposed a novel probabilistic approach for UDA that learns an efficient domain-adaptive classifier with strong generalization to target domains. The key to the proposed approach is to model the classifier's hypothesis space in Bayesian fashion and impose consistency over the target samples in their space by constraining the classifier's posterior distribution. To tackle the intractability of computing the exact posteriors, we combined the variational Bayesian method with a deep kernel technique to efficiently approximate the classifier's posterior distribution. We showed on three challenging benchmark datasets for image classification that the proposed method outperforms current state-of-the-art in unsupervised domain adaptation of visual categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>In this Supplement, we present additional analyses highlighting the ability of our model, GPDA, to leverage its inherent measure of uncertainty to both produce increasingly accurate predictions as well as provide a measure of its own trustworthiness. These new results are summarized in Appendix B. Appendix C provides further analysis showing the key connection between GPDA and the max-margin Gaussian Process classification in the original space X , surpassing the explicit need for a shared space Z of traditional domain adaptation approaches. We then present specific details of all datasets used in our experiments as well as the particulars of relevant experimental setups in Appendix D. Finally, we provide a brief overview of Gaussian Process models in Appendix E and another related state-of-the-art domain adaptation approach, the MCDA, in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional Analyses: Prediction Uncertainty vs. Prediction Quality</head><p>A key benefit of our GPDA algorithm, inherited from Bayesian modeling, is that it provides a quantified measure of prediction uncertainty. In the multi-class setup, for an input x we measure the uncertainty as the degree of overlap between the two largest mean posteriors, p(f j * (z)|D S ) and p(f j † (z)|D S ), where z = G(x), j * and j † are the indices of the largest and the second largest among the posterior means {µ j (z)} K j=1 , respectively, If the two overlap significantly, our model's decision is less certain, signifying that we anticipate the class prediction not to be trustworthy. On the other hand, if the two are well separated, we expect high prediction quality.</p><p>Bhattacharyya distance. In the main paper (Sec. 5.4 and <ref type="figure" target="#fig_6">Fig. 4)</ref>, we have verified this hypothesis by evaluating the Bhattacharyya distances (BD) between two posteriors (i.e., a measure of certainty in prediction) for two different cohorts: correctly classified test target samples by our model and incorrectly predicted ones, for the SVHN to MNIST adaptation task. Since we use variational Gaussian approximation of the posteriors p(f j (z)|D S ) ≈ N (µ j (z), σ j (z) 2 ), where µ j (z) and σ j (z) are determined by Eq. (22) in the main paper, the Bhattacharyya distance can be computed in closed form:</p><formula xml:id="formula_25">BD = 1 4 log 1 4 σ 2 j * σ 2 j † + σ 2 j † σ 2 j * + 2 + 1 4 (µ j * − µ j † ) 2 σ 2 j * + σ 2 j † .<label>(23)</label></formula><p>Bayes Optimal Error Rate. An alternative metric to measure the prediction uncertainty, perhaps more principled in the Bayesian sense, is the Bayes optimal error rate between the two largest mean posteriors, which can be computed as</p><formula xml:id="formula_26">Bayes error = 1 2 ∞ D N (x; µ j † , σ 2 j † ) dx + 1 2 D −∞ N (x; µ j * , σ 2 j * ) dx = 1 2 Φ µ j † − D σ j † + Φ D − µ j * σ j * ,<label>(24)</label></formula><p>where Φ is the CDF of N (0, 1) and D is the Bayes optimal decision threshold, D = (µ j * − µ j † )/ (σ 2 j * + σ 2 j † )/2. The interpretation is: the smaller the Bayes error rate, the more certain our prediction is, and vice versa. We depict the histograms of the Bayes error rates for two cohorts in <ref type="figure">Fig. 7</ref>. As shown, the conclusion is very similar to our earlier analysis based on Bhattacharyya distances: Our final model in <ref type="figure">Fig. 7</ref>(a) exhibits low error rates for most of the samples in the correctly predicted cohort (green), implying well separated posteriors or high certainty of prediction. For the incorrectly predicted samples (red), the error rates are mostly high implying significant overlap between the two posteriors, i.e., high uncertainty of prediction.</p><p>Uncertainty in GPDA vs MCDA. Lastly, to demonstrate that it is the unique property of our GPDA model that the uncertainty measure can be used to credibly gauge the quality of prediction at test time, we contrast our model with other non-Bayesian approaches. Specifically, we consider MCDA, as the second-best competing method. The MCDA is a non-Bayesian method that yields point estimate class prediction, namely p(y|x). By point estimate, we mean that the MCDA prediction places all its probability mass on a single (softmax) probability (score) value p(y = j|x) for each class j, unable to provide a degree of uncertainty in its prediction (e.g., σ j in our GPDA model).</p><p>However, one can define a heuristic notion of uncertainty for the MCDA by measuring how distant the two largest score predictions are from each other. More specifically, we compute the following quantity, dubbed Bhattacharyya pseudo distance (BPD), as a measure of uncertainty in the MCDA:</p><p>BPD := log p(y = j * |x) − log p(y = j † |x) Correctly predicted samples Inorrectly predicted samples <ref type="figure">Figure 7</ref>: (For our GPDA) Histograms of Bayes error rates (prediction uncertainty) for our two models: (a) after convergence, (b) at an early stage of training. The X-axis is the Bayes optimal error rate (24) b/w two largest mean posteriors, an indication of prediction uncertainty; the higher the error rate, the more uncertain the prediction is. For each model, we compute histograms of correctly and incorrectly predicted samples separately (by color). In our final model (a), there is a strong correlation between prediction uncertainty (horizontal axis) and prediction correctness (color).  The X-axis is the Bhattacharyya distance, an indication of prediction certainty; the higher the distance, the more certain the prediction is. For the non-Bayesian point-estimate-based MCDA, we compute the Bhattacharyya pseudo distance instead, as described in the text. Qualitatively, our GPDA model exhibits stronger correlation (histograms less overlapped) between prediction uncertainty (horizontal axis) and prediction correctness (color).</p><p>where j * and j † are the indices of the largest and the second largest among the scores log p(y = j|x), respectively. Note that <ref type="bibr" target="#b24">(25)</ref> is the log-ratio between the largest two class prediction scores. We name it the pseudo distance as it reduces to the Bhattacharyya distance if we form Gaussians with the mean equal to log p(y = j|x) and the same variances for both j * and j † .</p><p>We depict the histograms of the pseudo distances for MCDA's two cohorts in <ref type="figure" target="#fig_11">Fig. 8(b)</ref>, where the Bhattacharyya histograms for our GPDA are also shown in <ref type="figure" target="#fig_11">Fig. 8(a)</ref> for comparison. Unlike the more clear separation attained in our GPDA model, the MCDA exhibits two issues: i) For the correctly predicted samples (green), a considerable number of points have large overlap between j * and j † (i.e., low BPDs). ii) For the incorrectly predicted samples (red), the number of cases where the two largest scores are relatively well separated 7 exceeds that of our GPDA model, suggesting higher prediction uncertainty. This signifies the unique benefit of our Bayesian domain adaptation approach, that is, the capability to utilize the prediction uncertainty as a gauge of prediction quality.</p><p>GPDA vs. MCDA -Hard vs. Easy Instances. As a counterpart to <ref type="figure" target="#fig_7">Fig. 5</ref> in the main paper, we also depict in <ref type="figure" target="#fig_12">Fig. 9</ref>(b) some sample target test images that are correctly/incorrectly predicted by the MCDA with low/high certainty according to the BPD. For ease of comparison, we also show the samples for our GPDA from the main paper, <ref type="figure" target="#fig_7">Fig. 5</ref>, in <ref type="figure" target="#fig_12">Fig. 9(a)</ref>. Unlike the GPDA, the uncertainty prediction made by the MCDA shows less agreement with the human assessment. Images whose BPDs are low (i.e., uncertain prediction judged by the MCDA shown in the left panel of <ref type="figure" target="#fig_12">Fig. 9(b)</ref>), appear to be visually easy to classify by a human, with no ambiguity, with a possible exception in few cases: e.g., the last example in the correct/low quadrant that may look like "five", while the first example in the incorrect/low quadrant may be interpreted as "four". Furthermore, the sample images in the incorrect/high quadrant of <ref type="figure" target="#fig_12">Fig. 9(b)</ref>, i.e., those predicted by the MCDA with high certainty but misclassified, are relatively easy-to-classify examples for a human, other than the second example that may be confused as "one".</p><p>This empirical analysis verifies that the measure of prediction uncertainty provided by our GPDA model can be used as a more accurate indicator of prediction quality than that implied by the MCDA, our top competitor. That is, our model's quantitative uncertainty measure can determine, with high precision, whether the prediction made by the model is trustworthy or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. A Remark on Proposed GPDA Algorithm</head><p>In this section we discuss the strong connection between the GPDA algorithm and the max-margin confident prediction (or the entropy minimization) framework in classical semi-supervised learning <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b66">67]</ref>. More specifically, we show that our GPDA algorithm, in the algorithmic point of view, can be viewed as a max-margin Gaussian process classifier on the original input space X without explicitly considering a shared space Z.</p><p>Recall that the GPDA algorithm can be summarized as the following two alternating optimizations:</p><formula xml:id="formula_28">• min {mj ,Sj } −LL + KL (variational inference) • min G,k −LL + KL + λ · MS (model selection)</formula><p>where the key terms in these objectives are defined as follows:</p><formula xml:id="formula_29">KL = 1 2 K j=1 Tr(S j ) + ||m j || 2 2 − log det(S j ) − d ,<label>(26)</label></formula><formula xml:id="formula_30">LL = 1 M M m=1 N S |B S | i∈B S log P (y S i |W (m) φ(z S i )),<label>(27)</label></formula><p>and</p><formula xml:id="formula_31">MS := 1 |B T | i∈B T max j =j * m j φ(z T i ) − max 1≤j≤K m j φ(z T i ) + 1 + α max 1≤j≤K φ(z T i ) S j φ(z T i ) 1/2 + .<label>(28)</label></formula><p>Note that z = G(x). Although we have built a GP classification model on top of the shared space Z, leading to the algorithm above, in our learning objective terms <ref type="bibr" target="#b25">(26)</ref><ref type="bibr" target="#b26">(27)</ref><ref type="bibr" target="#b27">(28)</ref>, the deep kernel feature mapping φ(·) and the embedding function G(·) always appear together in the composite form φ(G(·)). Thus, our approach is functionally equivalent to building a GP classification model on top of the original X space, where the explicit feature mapping is x → (φ • G)(x). More formally, our classifier can be written as f (x) = Wφ(G(x)), a function of x. Consequently, our approach can be viewed as a max-margin Gaussian process classifier, without explicitly considering the shared space, where we push the posterior inferred from the source domain data to meet the large margin criterion on the (unlabeled) target domain data. This is clearly in line with entropy minimization or max-margin confident prediction principles in classical semi-supervised learning <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b66">67]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Details of Datasets and Experimental Setups</head><p>We now present additional details of experiments on the three datasets used in the main paper. For all experiments, we set M = 50, the number of posterior samples from the variational density q(W) (Sec. 3.2 in the main paper for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Digit and Traffic Signs Datasets</head><p>We followed the experimental setup used in <ref type="bibr" target="#b12">[13]</ref> in the following three adaptation scenarios. For this experiment, we compare our GPDA model with various state-of-the-art unsupervised domain adaptation approaces, namely: MMD <ref type="bibr" target="#b32">[33]</ref>, DANN <ref type="bibr" target="#b12">[13]</ref>, DSN <ref type="bibr" target="#b6">[7]</ref>, ADDA <ref type="bibr" target="#b55">[56]</ref>, CoGAN <ref type="bibr" target="#b31">[32]</ref>, PixelDA <ref type="bibr" target="#b5">[6]</ref>, ATDA <ref type="bibr" target="#b47">[48]</ref>, ASSC <ref type="bibr" target="#b21">[22]</ref>, DRCN <ref type="bibr" target="#b14">[15]</ref>, and, MCDA <ref type="bibr" target="#b48">[49]</ref>.</p><p>• SVHN→MNIST. In this adaptation scenario, we used the standard training set as our training samples, and the standard testing set as our testing samples both for source and target samples.</p><p>• SYN SIGNS→GTSRB. Following MCDA <ref type="bibr" target="#b48">[49]</ref>, we randomly selected 31367 samples for the target training set and evaluated the accuracy on the remaining samples.</p><p>• MNIST↔USPS. For this experiment, we followed the protocols used in ADDA <ref type="bibr" target="#b55">[56]</ref> and PixelDA <ref type="bibr" target="#b5">[6]</ref>. ADDA provides the setting where a part of training samples are utilized during training. 2,000 training samples are picked up for MNIST and 1,800 samples are used for USPS. PixelDA allows one to utilize all of the standard training samples during learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. VisDA Dataset</head><p>We used VisDA dataset <ref type="bibr" target="#b41">[42]</ref> to evaluate adaptation from synthetic to real-object images. The dataset is an instance of cross-domain object classification, with over 280K images across 12 categories in the combined training, validation, and testing domains. The source images, 152,397 synthetic images, were generated by rendering 3D models of the same object categories as in the real data from different angles and under different lighting conditions. The validation set of 55,388 images was collected from MSCOCO <ref type="bibr" target="#b29">[30]</ref>. In our experiment, we considered the images of validation splits as the target domain and trained models in the unsupervised domain adaptation settings. We evaluate the performance of ResNet101 [23] model pre-trained on Imagenet <ref type="bibr" target="#b9">[10]</ref>. For this experiment, we compare our model with MMD <ref type="bibr" target="#b32">[33]</ref>, DANN <ref type="bibr" target="#b12">[13]</ref>, and MCDA <ref type="bibr" target="#b48">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Background -Gaussian Process</head><p>A Gaussian Process (GP) is an infinite collection of random variables {f (x)|x ∈ X}, such that any finite number of samples have a joint Gaussian distribution. A GP is fully specified by the mean function µ(x) and the covariance function k(x, x ), typically user-defined. GPs can also be interpreted as a distribution over functions f (x) ∼ GP(µ(x), k(x, x)) such that any finite collection of function values [f (x 1 ), . . . , f (x N )] have a joint Gaussian distribution:</p><p>[f (x 1 ), . . . , f (x N )] ∼ N (µ, K),</p><p>where µ is the N × 1 vector µ i = µ(x i ) and K is the N × N covariance matrix with K ij = k(x i , x j ).</p><p>A training dataset consists of N pairs of data (x i , y i ) N i=1 , where y i are noisy observations of some latent function f with Gaussian noise y i = f (x i ) + i , i ∈ N (0, σ 2 ). The likelihood of the data y|f ∼ N (f, σ 2 I) and the prior f ∼ N (0, K) give the joint probability model p(f , y) = p(y|f )p(f ), where y denotes the noisy targets and f denotes the vector of underlying latent function values. The predictive distribution at a set of test points X * is given in closed form using the properties of conditional Gaussians, f * |y, X, X * , θ, σ 2 ∼ N (f * , Cov(f * )) (30) f * = K * (K + σ 2 I) −1 y</p><p>Cov(f * ) = K * * − K * (K + σ 2 I) −1 K T * , (32) where K * * denotes the covariance matrix evaluated among the test inputs X * and K * denotes the covariance matrix evaluated between the test points X * and the training set X. If there are N * test points, the covariance matrix K * * is of size N * × N * and K * is of size N * × N .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Gaussian Process Classification</head><p>In Gaussian Process Classification (GPC), the target values are discrete class labels, hence it is not appropriate to model them via a multivariate Gaussian density. Instead, we use the Gaussian process as a latent function whose sign determines the class label for binary classification; for multi-class classification one can use multiple GPs or a multivariate GP.</p><p>The key difference between the GP regression and GPC is how the output data, y, are connected to the underlying function values, f . Precisely, they are no longer connected via a simple noise process as in the previous section, instead now discrete: for example, for binary classification framework, say y = 1 for one class and y = −1 for the other. In this case, one could try fitting a GP that produces an output of 1 for some values of x and −1 for others, simulating the discrete nature of the problem. Then, the classification of a new data point x * involves two steps:</p><p>1. Evaluate a 'latent function' f which models qualitatively how the likelihood of one class versus the other changes over the x axis. This is the usual GP.</p><p>2. Squeeze the output of this latent function onto [0, 1] using logistic function, π(f ) = σ(y = 1|f ).</p><p>Writing these two steps schematically,</p><p>data, x * GP −→ latent function, f * |x * sigmoid − −−− → class probability, π(f * ) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Background -MCDA [49]</head><p>For multi-class classification, the MCDA adopts classifier networks that output class prediction probabilities, h(z) = [p(y = 1|z), . . . , p(y = K|z)] . The discrepancy between h and h is defined as the expected normalized L 1 difference, that is, E||h(z) − h (z)|| 1 /K. The learning algorithm is a coordinate descent optimization alternating among three steps:</p><p>1. min G,h,h L S := E (x,y)∼S CE(y; h(G(x))) + CE(y; h (G(x))) 2. (Fix G) min h,h L S − L adv , where L adv := E x∼T ||h(G(x)) − h (G(x))|| 1 /K</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">(Fix h, h ) min G L adv</head><p>Here, CE(y; p) stands for the cross entropy (or log) loss, i.e., CE(y; p) = − log p(y). All the expectations are approximately estimated on a mini-batch. Optionally, Step-3 can be repeated 2 ∼ 4 times (on the same mini-batch) to boost the convergence of the embedding network G(·).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of ideal (p A ) and problematic (p B ) posteriors at some fixed point z in the target domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Digits.(b) Traffic Signs.(c) VisDA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Example images from benchmark datasets. (a) Samples from MNIST, USPS, and SVHN datasets. (b) Samples from SYN SIGNS (first two rows), and GTSRB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Sensitivity analysis of our GPDA on the Digit datasets. S → M denotes adaptation from SVHN to MNIST (similarly for others), and M → U (all) indicates using all training samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig. 6depicts the embedding of the learned features G(x), and the original features x. Colors indicate source (red) and target (blue) domains. Notice that GPDA significantly reduces the domain mismatch, resulting in the expected tight clustering. This is partially 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Histograms of prediction (un)certainty for our two models: (a) after convergence, (b) at an early stage of training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Selected test (MNIST) images according to the Bhattacharyya distances. Right: samples with low distances (uncertain prediction). Left: high distances (certain prediction). Top: correctly classified by our model. Bottom: incorrectly classified. For each image, GT, Pr, and d means ground-truth label, predicted label, and the distance, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Feature visualization for embedding of digit datasets for adapting SVHN to MNIST using t-SNE algorithm. The first and the second columns show the domains and classes, respectively, with color indicating domain and class membership. a,b Original features. c,d learned features for GPDA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Model before convergence (epoch 10)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>(GPDA vs. MCDA) Histograms of Bhattacharyya distances between two largest mean posteriors (prediction certainty) for (a) GPDA and (b) MCDA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Selected test (MNIST) images according to the Bhattacharyya (pseudo) distances estimated by (a) GPDA and (b) MCDA. For each figure, Left: samples with low distances (uncertain prediction). Right: high distances (certain prediction). Top: correctly classified by the model. Bottom: incorrectly classified. For each image, GT, Pr, and d stand for ground-truth label, predicted label, and the (pseudo) distance, respectively.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that the theorems assume binary classification (y ∈ {+1, −1}), however, they can be straightforwardly extended to multi-class setups.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">See the Supplementary Material for further technical details.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This choice conforms to the variational density family we choose in Sec. 3.2.<ref type="bibr" target="#b3">4</ref> We used the topk() function in PyTorch to compute the largest and the second largest elements. The function allows automatic gradients.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Note that the inputs z also depend on G.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">In the algorithmic point of view, our algorithm can be viewed as a max-margin Gaussian process classifier on the original input space X without explicitly considering a shared space Z. For further details about this connection, the reader is encouraged to refer to the Supplementary Material.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">E.g., those with BPD &gt; 1.0, namely, certain predictions.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by domain invariant projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">One-sided unsupervised domain mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Benaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="752" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised pixel-level domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint distribution optimal transportation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A comprehensive survey on domain adaptation for visual applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The bhattacharyya measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Derpanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mendeley Computer</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1990" to="1992" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scalable inference for Gaussian process models with black-box likelihoods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">V</forename><surname>Bonilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<title level="m">Unsupervised domain adaptation by backpropagation. International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep reconstruction-classification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Euroupean Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Probabilistic unsupervised domain adaptation for knowledge transfer across visual categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gholami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3581" to="3590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="222" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Domain adaptation for object recognition: An unsupervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="999" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Advances in Neural Information Processing Systems</title>
		<meeting>of Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A kernel two-sample test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schlkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="723" to="773" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Associative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Frerix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Duplex generative adversarial network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1498" to="1507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scalable Gaussian process regression using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bi-shifting auto-encoder for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3846" to="3854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Learning Representations, ICLR</title>
		<meeting>the Second International Conference on Learning Representations, ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="700" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<title level="m">Learning transferable features with deep adaptation networks. International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Transfer joint matching for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1410" to="1417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Boosting domain adaptation by discovering latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.01386</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with imbalanced cross-domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T. Ming Harry</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-A</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H. Hubert</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-R</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C. Frank</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4121" to="4129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evaluation of traffic sign recognition methods trained on synthetically generated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moiseev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Konev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chigorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Konushin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advanced Concepts for Intelligent Vision Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="576" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Few-shot adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6673" to="6683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Image to image translation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Murez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00479</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Usman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06924</idno>
		<title level="m">Visda: The visual domain adaptation challenge</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A unifying view of sparse approximate Gaussian process regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quiñonero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1939" to="1959" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20</title>
		<editor>Platt, J. C., Koller, D., Singer, Y., and Roweis, S. T.</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Gaussian Processes for Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning multiple visual domains with residual adapters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="506" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Residual parameter transfer for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Maximum classifier discrepancy for unsupervised domain adaptation. Computer Vision and Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Generate to adapt: Aligning domains using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<idno>abs/1704.01705</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sparse Gaussian processes using pseudo-inputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Snelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The german traffic sign recognition benchmark: a multi-class classification competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stallkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlipsing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2011 International Joint Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1453" to="1460" />
		</imprint>
	</monogr>
	<note>Neural Networks (IJCNN)</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Direct importance estimation with model selection and its application to covariate shift adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Buenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1433" to="1440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Variational learning of inducing variables in sparse Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Titsias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Twelfth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Deep domain confusion: Maximizing for domain invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Max-margin multiple-instance dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="846" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Deep kernel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Central moment discrepancy (cmd) for domain-invariant representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zellinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lughofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Natschläger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saminger-Platz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Joint geometrical and statistical alignment for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ogunbona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Deep transfer network: Unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.00591</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Aligning infinite-dimensional covariance matrices in reproducing kernel hilbert spaces for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nehorai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3437" to="3445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Introduction to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Morgan &amp; Claypool</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
