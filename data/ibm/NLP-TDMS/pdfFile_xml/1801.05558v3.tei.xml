<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonho</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjin</forename><surname>Choi</surname></persName>
						</author>
						<title level="a" type="main">Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during metatesting. Our primary contribution is the MT-net, which enables the meta-learner to learn on each layer's activation space a subspace that the taskspecific learner performs gradient descent on. Additionally, a task-specific learner of an MT-net performs gradient descent with respect to a metalearned distance metric, which warps the activation space to be more sensitive to task identity. We demonstrate that the dimension of this learned subspace reflects the complexity of the task-specific learner's adaptation task, and also that our model is less sensitive to the choice of initial learning rates than previous gradient-based meta-learning methods. Our method achieves state-of-the-art or comparable performance on few-shot classification and regression tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>While recent deep learning methods achieve superhuman performance on various tasks including image classification <ref type="bibr" target="#b17">(Krizhevsky et al., 2012)</ref> or playing games <ref type="bibr" target="#b25">(Mnih et al., 2015)</ref>, they can only do so using copious amounts of data and computational resources. In many problems of interest, learners may not have such luxuries. Meta-learning <ref type="bibr" target="#b31">(Schmidhuber, 1987;</ref><ref type="bibr" target="#b32">Schmidhuber et al., 1997;</ref><ref type="bibr" target="#b35">Thrun &amp; Pratt, 1998)</ref> methods are a potential solution to this problem; these methods leverage information gathered from prior learning experience to learn more effectively in novel tasks. This line of research typically casts learning as a twolevel process, each with a different scope. The meta-learner operates on the level of tasks, gathering information from several instances of task-specific learners. A task-specific learner, on the other hand, operates on the level of datapoints, and incorporates the meta-learner's knowledge in its learning process.</p><p>Model-agnostic meta-learning (MAML)  is a meta-learning method that directly optimizes the gradient descent procedure of task-specific learners. All taskspecific learners of MAML share initial parameters, and a meta-learner optimizes these initial parameters such that gradient descent starting from such initial parameters quickly yields good performance. An implicit assumption in having the meta-learner operate in the same space as task-specific learners is that the two different scopes of learning require equal degrees of freedom.</p><p>Our primary contribution is the MT-net <ref type="figure" target="#fig_3">(Figure 1</ref>), a neural network architecture and task-specific learning procedure. An MT-net differs from previous gradient-based metalearning methods in that the meta-learner determines a subspace and a corresponding metric that task-specific learners can learn in, thus setting the degrees of freedom of taskspecific learners to an appropriate amount. Note that the activation space of the cell shown in <ref type="figure" target="#fig_3">Fig.1(b)</ref> is 3-dimensional. Because the task-specific learners can only change weights that affect two of the three intermediate activations, taskspecific learning only happens on a subspace with 2 degrees of freedom. Additionally, meta-learned parameters T alter the geometry of the activation space ( <ref type="figure" target="#fig_3">Fig.1(c)</ref>) of taskspecific parameters so that task-specific learners are more sensitive to change in task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Problem Setup</head><p>We briefly explain the meta-learning problem setup which we apply to few-shot tasks.</p><p>The problems of k-shot regression and classification are as follows.</p><p>In the training phase for a metalearner, we are given a (possibly infinite) set of tasks  <ref type="figure" target="#fig_3">Figure 1</ref>. Task-specific learning in an MT-net. (a) A cell (rounded rectangle) consists of two layers. In addition to initial weights (black), the meta-learner specifies weights to be changed (dotted lines) by task-specific learners (colored). (b) Activation of this cell has 3 dimensions, but activation of task-specific learners only change within a subspace (white plane). (c) The value of T affects task-specific learning so that gradients of W are sensitive to task identity. Best seen in color.</p><formula xml:id="formula_0">{T 1 , T 2 , T 3 ,</formula><p>is assumed to be drawn from the distribution of tasks p(T ). Given a task T ∼ p(T ), the task-specific model f θ T (our work considers a feedforward neural network) is trained using the dataset D T ,train and its corresponding loss L T (θ T , D T ,train ). Denote by θ T parameters obtained by optimizing L T (θ T , D T ,train ). Then, the meta-learner f θ is updated using the feedback from the collection of</p><formula xml:id="formula_1">losses L T ( θ T , D T ,test ) T ∼p(T )</formula><p>, where the loss of each task is evaluated using the test data D T ,test . Given a new task T new (not considered during meta-training), the metalearner helps the model f θ Tnew to quickly adapt to the new task T new , by warm-starting the gradient updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Model-Agnostic Meta-Learning</head><p>We briefly review model-agnostic meta-learning (MAML) , emphasizing commonalities and differences between MAML and our method. MAML is a meta-learning method that can be used on any model that learns using gradient descent. This method is loosely inspired by fine-tuning, and it learns initial parameters of a network such that the network's loss after a few (usually 1 ∼ 5) gradient steps is minimized.</p><p>Consider a model with parameters θ. MAML alternates between the two updates <ref type="formula">(1)</ref> and <ref type="formula" target="#formula_2">(2)</ref> to determine initial parameters θ for task-specific learners to warm-start the gradient descent updates, such that new tasks can be solved using a small number of examples. Each task-specific learner updates its parameters by gradient descent (1) using the loss evaluated with the training data {D T ,train }. The meta-optimization across tasks <ref type="bibr" target="#b42">(2)</ref> is performed such that the parameters θ are updated using the loss evaluated with {D T ,test }. Note that during meta-optimization (2), the gradient is computed with respect to initial parameters θ but the test loss is computed with respect to task-specific parameters θ T .</p><formula xml:id="formula_2">θ T ← θ − α∇ θ L T (θ, D T ,train ) (1) θ ← θ − β∇ θ   T ∼p(T ) L T θ T , D T ,test   ,<label>(2)</label></formula><p>where α &gt; 0 and β &gt; 0 are learning rates and the summation in <ref type="formula" target="#formula_2">(2)</ref> is computed using minibatches of tasks sampled from p(T ).</p><p>Intuitively, a well-learned initial parameter θ is close to some local optimum for every task T ∼ p(T ). Furthermore, the update (1) is sensitive to task identity in the sense that θ T1 and θ T2 have different behaviors for different tasks T 1 , T 2 ∼ p(T ).</p><p>Recent work has shown that gradient-based optimization is a universal learning algorithm , meaning that any learning algorithm can be approximated up to arbitrary accuracy using some parameterized model and gradient descent. Thus, no expressiveness is lost by only considering gradient-based learners as in <ref type="bibr" target="#b41">(1)</ref>. Note that since MAML operates using a single fixed model, one may have to go through trial and error to find such a good model.</p><p>Our method is similar to MAML in that our method also differentiates through gradient update steps to optimize performance after fine-tuning. However, while MAML assumes a fixed model, our method actually chooses a subset of its weights to fine-tune. In other words, it (meta-)learns which model is most suitable for the task at hand. Furthermore, whereas MAML learns with standard gradient descent, a subset of our method's parameters effectively 'warp' the parameter space of the parameters to be learned during metatesting to enable faster learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Meta-Learning Models</head><p>We present our two models in this section: Transformation Networks (T-net) and Mask Transformation Networks (MTnet), both of which are trained with gradient-based metalearning. A T-net learns a metric in its activation space; this metric informs each task-specific learner's update direction and step size. An MT-net additionally learns which subset of its weights to update for task-specific learning. Therefore, an MT-net learns to automatically assign one of two roles (task-specific or task-mutual) to each of its weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">T-net</head><p>We consider a model f θ (·) with paramaters θ. This model consists of L cells, where each cell is parameterized * as TW:</p><formula xml:id="formula_3">f θ (x) = T L W L σ T L−1 W L−1 . . . σ T 1 W 1 x ,<label>(3)</label></formula><p>where x ∈ R D is an input, and σ(·) is a nonlinear activation function. T-nets get their name from transformation matrices (T) because the linear transformation defined by a T plays a crucial role in meta-learning. Note that a cell has the same expressive power as a linear layer. Model parameters θ are therefore a collection of W's and T's, i.e.,</p><formula xml:id="formula_4">θ =      W 1 , . . . , W L θ W , T 1 , . . . , T L θ T      .</formula><p>Transformation parameters θ T , which are shared across taskspecific models, are determined by the meta-learner. All task-specific learners share the same initial θ W but update to * For convolutional cells, W is a convolutional layer with some size and stride and and T is a 1×1 convolution that doesn't change the number of channels</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Transformation Networks (T-net)</head><p>Require: p(T ) Require: α, β 1: randomly initialize θ 2: while not done do 3:</p><formula xml:id="formula_5">Sample batch of tasks T i ∼ p(T ) 4:</formula><p>for all T j do 5:</p><p>for i = 1, · · · , L do 6:</p><p>Compute W T according to (4) 7:</p><p>end for 8:</p><formula xml:id="formula_6">θ W,Tj = { W 1 Tj , · · · W L Tj } 9:</formula><p>end for 10:</p><formula xml:id="formula_7">θ ← θ − β∇ θ j L T ( θ W,Tj , θ T , D Tj ,test ) 11: end while</formula><p>different values since each uses their corresponding train set D T ,train . Thus we denote such (adjusted) parameters for task T as θ W,T . Though they may look similar, T denotes a task while T denotes a transformation matrix.</p><p>Given a task T , each W is adjusted with the gradient update</p><formula xml:id="formula_8">W T ← W − α∇ W L T (θ W , θ T , D T ,train ) . (4) Again, θ W,T is defined as { W 1 T , . . . , W L T }.</formula><p>Using the task-specific learner θ W,T , the meta-learner improves itself with the gradient update</p><formula xml:id="formula_9">θ ← θ − β∇ θ   T ∼p(T ) L T θ W,T , θ T , D T ,test   . (5)</formula><p>α &gt; 0 and β &gt; 0 are learning rate hyperparameters. We show our full algorithm in Algorithm 1.</p><p>To evaluate on a new task T * , we do the following. We compute task-specific parameters θ W,T * using (4), starting from the meta-learned initial value θ W . We report the loss of task-specific parameters θ W,T * on the test set D T * ,test .</p><p>We now briefly examine a single cell:</p><formula xml:id="formula_10">y = TWx,</formula><p>where x is the input to the cell and y its output. The squared length of a change in output ∆y = y * − y 0 is calculated as</p><formula xml:id="formula_11">∆y 2 = ((∆W)x) T T ((∆W)x) ,<label>(6)</label></formula><p>where ∆W is similarly defined as W * − W 0 . We see here that the magnitude of ∆y is determined by the interaction between (∆W)x and T T. Since a task-specific learner performs gradient descent only on W and not T, the change in y resulting from <ref type="formula">(4)</ref> is guided by the meta-learned value T T. We provide a more precise analysis of this behavior in Section 4. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">MT-net</head><p>The MT-net is built on the same feedforward model <ref type="formula" target="#formula_3">(3)</ref> as the T-net:</p><formula xml:id="formula_12">f θ (x) = T L W L σ T L−1 W L−1 . . . σ T 1 W 1 x . (7)</formula><p>The MT-net differs from the T-net in the binary mask applied to the gradient update to determine which parameters are to be updated. The update rule for task-specific parameters W T is given by</p><formula xml:id="formula_13">W T ← W − αM ∇ W L(θ W , θ T , D T ,train ),<label>(8)</label></formula><p>where is the Hadamard (elementwise) product between matrices of the same dimension. M is a binary gradient mask which is sampled each time the task-specific learner encounters a new task. Each row of M is either an allones vector 1 or an all-zeros vector 0. We parameterize the probability of row j in M being 1 with a scalar variable ζ j :</p><formula xml:id="formula_14">M = [m 1 , . . . , m n ] , m j ∼ Bern exp (ζ j ) exp (ζ j ) + 1 1 ,<label>(9)</label></formula><p>where Bern(·) denotes the Bernoulli distribution. Each logit ζ acts on a row of a weight matrix W, so weights that contribute to the same immediate activation are updated or not updated together.</p><p>We approximately differentiate through the Bernoulli sampling of masks using the Gumbel-Softmax estimator <ref type="bibr" target="#b13">(Jang et al., 2017;</ref><ref type="bibr" target="#b22">Maddison et al., 2017)</ref>: for all T j do 5:</p><formula xml:id="formula_15">g 1 , g 2 ∼ Gumbel(0, 1),<label>(10)</label></formula><formula xml:id="formula_16">m j ← exp ζj +g1 c exp ζj +g1 c + exp g2 c 1 ,<label>(11)</label></formula><p>for i = 1, · · · , L do 6:</p><p>Sample binary mask M i according to <ref type="formula" target="#formula_16">(11)</ref> 7:</p><p>Compute W i Tj according to <ref type="formula" target="#formula_13">(8)</ref> 8:</p><p>end for 9:</p><formula xml:id="formula_17">θ W,Tj = { W 1 Tj , · · · W L Tj } 10: end for 11: θ ← θ − β∇ θ j L T θ W,T , θ T , θ ζ , D T ,test 12: end while</formula><p>where c is a temperature hyperparameter. This reparameterization allows us to directly backpropagate through the mask. At the limit of c → 0, (11) follows the behavior of (9).</p><p>As in T-nets, we denote the collection of altered weights as θ W,</p><formula xml:id="formula_18">T = { W 1 T , . . . , W L T }.</formula><p>The meta-learner learns all parameters θ:</p><formula xml:id="formula_19">θ =        W 1 , . . . , W L θ W , T 1 , . . . , T L θ T , ζ 1 , . . . , ζ L θ ζ ,        .<label>(12)</label></formula><p>As in a T-net, the meta-learner performs stochastic gradient descent on L T θ W,T , θ T , θ ζ , D T ,test :</p><formula xml:id="formula_20">θ ← θ − β∇ θ   T ∼p(T ) L T θ W,T , θ T , θ ζ , D T ,test   . (13)</formula><p>The full algorithm is shown in Algorithm 2.</p><p>We emphasize that the binary mask used for task-specific learning (M) depends on meta-learned parameter weights (ζ). Since the meta-learner optimizes the loss in a task after a gradient step <ref type="formula" target="#formula_13">(8)</ref>, the matrix M gets assigned a high probability of having value 1 for weights that are meant to encode task-specific information. Furthermore, since we update M along with model parameters W and T, the metalearner is incentivized to learn configurations of W and T in which there exists a clear divide between task-specific and task-mutual neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analysis</head><p>In this section, we provide further analysis of the update schemes of T-nets and MT-nets.</p><p>We analyse how the activation space of a single cell of a Tnet or MT-net behaves during task-specific learning. More specifically, we make precise how W encodes a learned curvature matrix. By using such an analysis to reason about a whole network consisting of several cells, we are impliticly approximating the full curvature matrix of the network by a block-diagonal curvature matrix. In this approximation, second-order interactions only occur among weights in the same layer (or cell). Previous works <ref type="bibr" target="#b11">(Heskes, 2000;</ref><ref type="bibr" target="#b23">Martens &amp; Grosse, 2015;</ref><ref type="bibr" target="#b2">Desjardins et al., 2015)</ref> have used such an approximation of the curvature of a neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">T-nets Learn a Metric in Activation Space</head><p>We consider a cell in a T-net where the pre-activation value y is given by</p><formula xml:id="formula_21">y = TWx = Ax,<label>(14)</label></formula><p>where A = TW and x is the input to the cell. We omit superscripts throughout this section.</p><p>A standard feedforward network resorts to the gradient of a loss function L T (which involves a particular task T ∼ p(T )) with respect to the parameter matrix A, to update model parameters. In such a case, a single gradient step yields</p><formula xml:id="formula_22">y new = (A − α∇ A L T )x = y − α∇ A L T x.<label>(15)</label></formula><p>The update of a T-net (4) results in the following new value of y:</p><formula xml:id="formula_23">y new = T T −1 A − α∇ T −1 A L T x = y − α TT ∇ A L T x,<label>(16)</label></formula><p>where T is determined by the meta-learner. Thus, in a T-net, the incremental change of y is proportional to the negative of the gradient TT ∇ A L T , while the standard feedforward net resorts to a step proportional to the negative of ∇ A L T . Task-specific learning in the T-net is guided by a full rank metric in each cell's activation space, which is determined by each cell's transformation matrix T. This metric (TT ) −1 warps (scaling, rotation, etc.) the activation space of the model so that in this warped space, a single gradient step with respect to the loss of a new task yields parameters that are well suited for that task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">MT-nets Learn a Subspace with a Metric</head><p>We now consider MT-nets and analyze what their update (8) means from the viewpoint of y = TWx = Ax.</p><p>MT-nets can restrict its task-specific learner to any subspace of its gradient space: Proposition 1. Fix x and A. Let y = TWx be a cell in an MT-net and let ζ be its corresponding mask parameters. Let U be a d-dimensional subspace of R n (d ≤ n). There exist configurations of T, W, and ζ such that the span of y new − y is U while satisfying A = TW.</p><p>Proof. See Appendix B.</p><p>This proposition states that W, T, and ζ have sufficient expressive power to restrict updates of y to any subspace. Note that this construction is only possible because of the transformation T; if we only had binary masks M, we would only be able to restrict gradients to axis-aligned subspaces.</p><p>In addition to learning a subspace that we project gradients onto (U), we are also learning a metric in this subspace. We first provide an intuitive exposition of this idea.</p><p>We unroll the update of an MT-net as we did with T-nets in <ref type="formula" target="#formula_11">(16)</ref>:</p><formula xml:id="formula_24">y new =T((T −1 A − αM ∇ T −1 A L T )x) =y − αT(M (T ∇ A L T ))x =y − αT(M T T )∇ A L T x =y − α(T M T )(M T T )∇ A L T x. (17)</formula><p>Where M T is an m×m matrix which has the same columns as M. Let's denote T M = M T T . We see that the update of a task-specific learner in an MT-net performs the update T M T M ∇ A L T . Note that T M T M is an n × n matrix that only has nonzero elements in rows and columns where m is 1. By setting appropriate ζ, we can view T M T M as a full-rank d × d metric tensor.</p><p>This observation can be formally stated as:</p><p>Proposition 2. Fix x, A, and a loss function L T . Let y = TWx be a cell in an MT-net and let ζ be its corresponding mask parameters. Let U be a d-dimensional subspace of R n , and g(·, ·) a metric tensor on U. There exist configurations of T, W, and ζ such that the vector y new − y is in the steepest direction of descent on L T with respect to the metric g(·, ·).</p><p>Proof. See Appendix B.</p><p>Therefore, not only can MT-nets project gradients of taskspecific learners onto a subspace of the pre-activation (y) space, they can also learn a metric in that subspace and thereby learning a low-dimensional linear embedding of the activation space. The MT-net update (8) is gradient descent in this low-dimensional embedding, so the meta-objective shown in <ref type="formula" target="#formula_3">(13)</ref> is minimized when gradient descent in this embedding requires few steps to converge and is sensitive to task identity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Work</head><p>A successful line of research in few-shot learning uses feedforward neural networks as learners. These approaches learn update rules <ref type="bibr" target="#b27">(Ravi &amp; Larochelle, 2017;</ref><ref type="bibr" target="#b20">Li &amp; Malik, 2016;</ref><ref type="bibr" target="#b1">Andrychowicz et al., 2016)</ref> or directly generate weights <ref type="bibr" target="#b9">(Ha et al., 2016)</ref>. A related research direction is to learn initial parameters  while fixing the learning rule to gradient descent, or additionally learning learning rates for each weight . <ref type="bibr" target="#b8">(Grant et al., 2018)</ref> interprets such gradient-based meta-learning as hierarchical bayesian inference, and  states that such methods are expressive enough to approximate any learning algorithm.</p><p>Our work is closely related to this line of research. Unlike previous work, MT-nets learn how many degrees of freedom the task-specific learner should have at meta-test time.</p><p>Additionally, while MT-nets learn update rules, these update rules are directly embedded in the network itself instead of being stored in a separate model.</p><p>Distance metric learning <ref type="bibr" target="#b40">(Xing et al., 2003;</ref><ref type="bibr" target="#b39">Weinberger et al., 2006)</ref> methods learn a distance function between datapoints. Similarly, MT-nets learn a full metric matrix. Whereas those methods required constrained optimization techniques to enforce that the learned matrix represents a metric, our parameterization allows us to directly learn such a metric using gradient descent. Recently, neural networks have been used to learn a metric between images <ref type="bibr" target="#b16">(Koch et al., 2015;</ref><ref type="bibr" target="#b38">Vinyals et al., 2016;</ref><ref type="bibr" target="#b33">Snell et al., 2017)</ref>, achieving state-of-the-art performance on few-shot classification benchmarks. Unlike these methods, we learn a metric in feature space instead of input space. Our method applies to a larger class of problems including regression and reinforcement learning, since all MT-nets require is a differentiable loss function.</p><p>Another line of research in few-shot learning is to use a recurrent neural network (RNN) as a learner <ref type="bibr" target="#b30">(Santoro et al., 2016;</ref><ref type="bibr" target="#b26">Munkhdalai &amp; Yu, 2017)</ref>. Here, the meta-learning algorithm is gradient descent on an RNN, and the learning algorithm is the update of hidden cells. The (meta-learned) weights of the RNN specify a learning strategy, which processes training data and uses the resulting hidden state vector to make decisions about test data. A recent work that uses temporal convolutions for meta-learning <ref type="bibr" target="#b24">(Mishra et al., 2018)</ref> is also closely related to this line of research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>We performed experiments to answer:</p><p>• Do our novel components (TW, M etc) improve metalearning performance? (6.1)</p><p>• Is applying a mask M row-wise actually better than Models 5-shot 10-shot 20-shot MAML <ref type="bibr" target="#b41">1</ref> 1.07 ± 0.11 0.71 ± 0.07 0.50 ± 0.05 Meta-SGD 1 0.88 ± 0.14 0.53 ± 0.09 0.35 ± 0.06 M-net-full 0.91 ± 0.09 0.63 ± 0.07 0.38 ± 0.04 M-net 0.88 ± 0.09 0.60 ± 0.06 0.41 ± 0.04 T-net 0.83 ± 0.08 0.56 ± 0.06 0.38 ± 0.04 MT-net-full 0.81 ± 0.08 0.51 ± 0.05 0.35 ± 0.04 MT-net 0.76 ± 0.09 0.49 ± 0.05 0.33 ± 0.04 <ref type="table">Table 1</ref>. Loss on sine wave regression. Networks were metatrained using 10-shot regression tasks. Reported losses were calculated after adaptation using various numbers of examples. <ref type="bibr" target="#b41">1</ref> Reported by .</p><p>applying one parameter-wise? (6.1)</p><p>• To what degree does T alleviate the need for careful tuning of step size α? (6.2)</p><p>• In MT-nets, does learned subspace dimension reflect the difficulty of tasks? (6.3)</p><p>• Can T-nets and MT-nets scale to large-scale metalearning problems? (6.4)</p><p>Most of our experiments were performed by modifying the code accompanying , and we follow their experimental protocol and hyperparameters unless specified otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Toy Regression Problem</head><p>We start with a K-shot regression problem and compare results to previous meta-learning methods . The details of our regression task are the same as . Each individual task is to regress from the input x to the output y of a sine function</p><formula xml:id="formula_25">y(x) = A sin(wx + b)<label>(18)</label></formula><p>For each task, A, w, b are sampled uniformly from [0.1, 5.0], [0.8, <ref type="bibr">1.2]</ref>, and [0, π], respectively. Each task consists of K ∈ {5, 10, 20} training examples and 10 testing examples. We sample x uniformly from [−5.0, 5.0] for both train and test sets. Our regressor architecture has two hidden cells each with activation size 40. After every T is a ReLU nonlinearity. The loss function is the mean squared error (MSE) between the regressor's prediction f (x) and the true value y(x). We used Adam <ref type="bibr" target="#b15">(Kingma &amp; Ba, 2015)</ref> as our meta-optimizer with a learning rate of β = 10 −3 . Taskspecifc learners used step size α = 10 −2 . We initialize all ζ to 0, all T as identity matrices, and all W as truncated normal matrices with standard deviation 10 −2 . While we trained our meta-learner with K = 10 examples, we tested using various numbers of examples (K ∈ {5, 10, 20}).   <ref type="table">Table 2</ref>. Loss on 10-shot sine wave regression. T-nets and MT-nets are bost robust to change in step size α. This is due to the metalearned matrix T inside each cell, which alters the effective step size.</p><p>We show results in <ref type="table">Table 1</ref>. To see if each of our novel components increased meta-learning performance, we also performed the same experiments with variations of MT-nets. An M-net uses a mask M like an MT-net, but each cell consists of a single matrix W instead of TW. A model with "-full" at the end of its name learns a separate mask parameter for each weight of W instead of sharing a mask among weights that contribute to the same activation. For example, if W has size 5 × 10, the corresponding ζ in an MT-net would be of dimension 5, but in MT-net-full, the dimension of ζ would be 50. MT-nets outperform MAML, meta-SGD, and all variations of MT-nets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Robustness to learning rate change</head><p>The transformation T of our method can change the effective step size α. We performed experiments to see how robust our method is to variations in α. We perform the same sinusoid experiment as in section 6.1, but with various step sizes (α ∈ {10 −4 , 10 −3 , 10 −2 , 10 −1 , 1, 10}). We evaluate on K = 10 training examples, and all other settings are identical to the experiments in section 6.1.</p><p>We show losses after adaptation of both MAML and MTnets in <ref type="table">Table 2</ref>. We can see that MT-nets are more robust to change in step size. This indicates that as shown in section 4.2, the matrix T is capable of warping the parameter space to recover from suboptimal step size α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Task Complexity and Subspace Dimension</head><p>We performed this experiment to see whether the dimension of the learned subspace of MT-nets reflect the underlying complexity of its given set of tasks.</p><p>We consider 10-shot regression tasks in which the target function is a polynomial. A polynomial regression meta-task consists of polynomials of the same order with various coefficients. To generate a polynomial of order n ( n i=0 c i x i ), we uniformly sampled c 0 , . . . , c n from [− <ref type="bibr" target="#b41">1,</ref><ref type="bibr" target="#b41">1]</ref>. We used the same network architecture and hyperparameters as in Section 6.1 and performed 10-shot regression for polynomial orders n ∈ {0, 1, 2}. Since the number of free parameters is proportional to the order of the polynomial, we expect higher-order polynomials to require more parameters to adapt to. The fraction of parameters that task-specific learners change is calculated as the expected value of e −ζ e −ζ +1 over all logits ζ.</p><p>We show results in <ref type="figure" target="#fig_2">Figure 4</ref>, and additional results in Appendix C. The number of weights that the meta-learner of an MT-net sets to be altered increases as the task gets more complex. We interpret this as the meta-learner of MT-nets having an effect akin to Occam's razor: it selects a taskspecific model of just enough complexity to learn in a set of tasks. This behavior emerges even though we do not introduce any additional loss terms to encourage such behavior. We think this is caused by the noise inherent in stochastic gradient descent. Since the meta-learner of an MT-net can choose whether or not to perform gradient descent in a particular direction, it is incentivized not to do so in directions that are not model-specific, because doing so would introduce more noise into the network parameters and thus (in expectation) suffer more loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Classification</head><p>To compare the performance of MT-nets to prior work in meta-learning, we evaluate our method on few-shot classification on the Omniglot <ref type="bibr" target="#b18">(Lake et al., 2015)</ref> and MiniImagenet <ref type="bibr" target="#b27">(Ravi &amp; Larochelle, 2017)</ref> datasets. We used the miniIma-  <ref type="bibr">(Snell et al., 2017) 97.4</ref> 92.0 mAP-SSVM <ref type="bibr" target="#b36">(Triantafillou et al., 2017)</ref> 98.6 95.4 MAML  98.7 ± 0.4 95.8 ± 0.3 Meta-SGD  99.  <ref type="bibr">(Snell et al., 2017) 2</ref> 46.61 ± 0.78 mAP-SSVM <ref type="bibr" target="#b36">(Triantafillou et al., 2017)</ref> 50.32 ± 0.80 Fine-tune baseline <ref type="bibr" target="#b41">1</ref> 28.86 ± 0.54 Nearest Neighbor baseline 1 41.08 ± 0.70 meta-learner LSTM <ref type="bibr" target="#b27">(Ravi &amp; Larochelle, 2017)</ref> 43.44 ± 0.77 MAML  48.70 ± 1.84 L-MAML <ref type="bibr" target="#b8">(Grant et al., 2018)</ref> 49.40 ± 1.83 Meta-SGD  50.47 ± 1.87 T-net (ours) 50.86 ± 1.82 MT-net (ours) 51.70 ± 1.84  <ref type="bibr" target="#b41">1</ref> Reported by <ref type="bibr" target="#b27">(Ravi &amp; Larochelle, 2017)</ref>. <ref type="bibr" target="#b42">2</ref> Reported results for 5-way 1-shot. genet splits proposed by <ref type="bibr" target="#b27">(Ravi &amp; Larochelle, 2017)</ref> in our experiments.</p><p>Our CNN model uses the same architecture as . The model has 4 modules: each has 3 × 3 convolutions and 64 filters, followed by batch normalization <ref type="bibr" target="#b12">(Ioffe &amp; Szegedy, 2015)</ref>. As in , we used 32 filters per layer in miniImagenet. Convolutions have stride 2 × 2 on Omniglot, and 2 × 2 max-pooling is used after batch normalization instead of strided convolutions on Mini-Imagenet. We evaluate with 3, 5, and 10 gradient steps for Omniglot 5-way, Omniglot 20-way, and miniImagenet 5-way, respectively.</p><p>Results are shown in <ref type="table" target="#tab_6">Table 3</ref>. MT-nets achieve state-of-theart or comparable performance on both problems. Several works <ref type="bibr" target="#b24">(Mishra et al., 2018;</ref><ref type="bibr" target="#b26">Munkhdalai &amp; Yu, 2017;</ref><ref type="bibr" target="#b34">Sung et al., 2017)</ref> have reported improved performance on Mini-Imagenet using a significantly more expressive architecture. We only report methods that have equal or comparable expressiveness to the model first described in <ref type="bibr" target="#b38">(Vinyals et al., 2016)</ref>. Not controlling for network expressivity, the highest reported accuracy so far on 5-way 1-shot miniImagenet classification is 57.02 <ref type="bibr" target="#b34">(Sung et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We introduced T-nets and MT-nets. One can transform any feedforward neural network into an MT-net, so any future architectural advances can take advantage of our method. Experiments showed that our method alleviates the need for careful tuning of the learning rate in few-shot learning problems and that the mask M reflects the complexity of the set of tasks it is learning to adapt in. MT-nets also showed state-of-the-art performance in a challenging fewshot classification benchmark (MiniImagenet).</p><p>While we think MT-nets are a gradient-based meta-learning method, our analysis has shown that it has some interesting commonalities with optimizer learning methods such as <ref type="bibr" target="#b27">(Ravi &amp; Larochelle, 2017)</ref>. We will investigate this connection between two seemingly disparate approaches to meta-learning in future work.</p><p>One of the biggest weaknesses of deep networks is that they are very data intensive. By learning what to learn when a new task is encountered, we can train networks with high capacity using a small amount of data. We believe that designing effective gradient-based meta-learners will be beneficial not just for the few-shot learning setting, but also machine learning problems in general. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional Experiments</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>A diagram of the adaptation process of a Transformation Network (T-net). Blue values are meta-learned and shared across all tasks. Orange values are different for each task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>A diagram of the adaptation process of a Mask Transformation Network (MT-net). Blue values are meta-learned and shared across all tasks. Orange values are different for each task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>10-shot regression tasks to sets of polynomials of various degrees. MT-nets choose to update a larger fraction of weights as the set of tasks gets more complex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Additional qualitative results from the polynomial regression task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Department of Computer Science and Engineering, Pohang University of Science and Technology, Korea. Correspondence to: Yoonho Lee &lt;einet89@postech.ac.kr&gt;, Seungjin Choi &lt;se-ungjin@postech.ac.kr&gt;. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).</figDesc><table /><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. . .}. Each task provides a training set and a test set {D Ti,train , D Ti,test }. We assume here that the training set D Ti,train has k examples per class, hence the name k-shot learning. A particular task T ∈ {T 1 , T 2 , T 3 , . . .}</figDesc><table><row><cell>(a)</cell><cell>(b)</cell><cell>(c)</cell></row><row><cell>arXiv:1801.05558v3 [stat.ML] 14 Jun 2018</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc> </figDesc><table><row><cell>Require: p(T ) Require: α, β 1: randomly initialize θ 2: while not done do 3: Sample batch of tasks T i ∼ p(T ) 4:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Models 5-way 1-shot acc. (%) 20-way 1-shot acc. (%) Matching Networks(Vinyals et al., 2016) 98.1 93.8 Prototypical Networks</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Few-shot classification accuracy on (top) held-out Omniglot characters and (bottom) test split of MiniImagenet. ± represents 95% confidence intervals.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements SC was supported by Samsung DS Software Center, Samsung Research, and Naver.   We used the same hyperparameters as <ref type="bibr" target="#b41">[1]</ref> and terminated training after the same number of examples specifid in <ref type="bibr" target="#b41">[1]</ref>. We used a temperature c of 1, which was recommended in <ref type="bibr" target="#b42">[2]</ref>. We initialized T to be an identity matrix and all ζ to zero.</p><p>Compated to MAML <ref type="bibr" target="#b41">[1]</ref>, training a convolutional MT-net takes roughly 0.4 times longer (omniglot 40k steps took 7h 19m for MT-net and 5h 14m for MAML). This gap is fairly small because 1 × 1 convolutions require little compute compared to regular convolutions. This gap is larger (roughly 1.1 times) for fully connected MT-nets. We additionally observed that MT-nets take less training steps to converge compared to MAML.</p><p>We provide our official implementation of MT-nets at https://github.com/yoonholee/MT-net.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Further Experimental Details</head><p>Proof. We show by construction that Proposition 1 is true.</p><p>Suppose that {v 1 , v 2 , . . . , v n } is a basis of R n such that {v 1 , v 2 , . . . , v d } is a basis of U. Let T be the n × n matrix [v 1 , v 2 , . . . , v n ]. T is invertible since it consists of linearly independent columns. Let W = T −1 A and let ζ 1 , ζ 2 , . . . , ζ d → ∞ and ζ d+1 , . . . , ζ n → −∞. The resulting mask M that ζ generates is a matrix with only ones in the first d rows and zeroes elsewhere.</p><p>Since all but the first d rows of M are 0, (M ∇ W L T )x is an n-dimensional vector in which nonzero elements can only appear in the first d dimensions. Therefore, the vector</p><p>Thus the span of y new − y is U.</p><p>Proof. We show Proposition 2 is true by construction as well.</p><p>We begin by constructing a representation for the arbitrary metric tensor g(·, ·).</p><p>We can express any metric tensor g(·, ·) using such coefficients c:</p><p>where G is a positive definite matrix. Because of this, there exists an invertible d × d matrix H such that G = H H. Note that g(u 1 , u 2 ) = (Hc 1 ) (Hc 2 ): the metric g(·, ·) is equal to the inner product after multiplying H to given vectors c.</p><p>Using H, we can alternatively parameterize vectors in U as</p><p>Here, we are using Hc 1 as a d-dimensional parameterization and the columns of the n × d matrix VH −1 as an alternative basis of U.</p><p>Let v H 1 , . . . , v H d be the columns of VH −1 , and set</p><p>} is a basis of U and thus T is an invertible matrix. As in Proposition 1, set W = T −1 A, ζ 1 , ζ 2 , . . . , ζ d → ∞, and ζ d+1 , . . . , ζ n → −∞. Note that this configuration of ζ generates a mask M that projects gradients onto the first d rows, which will later be multiplied by the vectors {v H 1 , . . . , v H d }. We can express y as y = V c y = VH −1 (Hc y ), where c y is again a d-dimensional vector. Note that VH −1 is constant in the network and change in W only affects Hc y . Since ∇ W L T = (∇ Wx L T )x , the task-specific update is in the direction of steepest descent of L T in the space of Hc y (with the Euclidean metric). This is exactly the direction of steepest descent of L T in U with respect to the metric g(·, ·).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Natural gradient works efficiently in learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="276" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gómez Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Deepmind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards a Neural Statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Meta-learning and universality: Deep representations and gradient descent can approximate any learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11622</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Gaussian Prototypical Networks for Few-Shot Learning on Omniglot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fort</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02735</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Few-Shot Learning with Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04043</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Low-shot visual object recognition by shrinking and hallucinating features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV)</title>
		<meeting>the International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On natural learning and pruning in multilayered perceptrons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning to Remember Rare Events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ima-geNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to Generalize: Meta-Learning for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI National Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI National Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to Optimize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meta-Sgd</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09835</idno>
		<title level="m">Learning to Learn Quickly for Few Shot Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Optimizing neural networks with kronecker-factored approximate curvature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Meta</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Networks</surname></persName>
		</author>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Metalearning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A stochastic approximation method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Monro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="407" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lilicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Evolutionary Principles in Self-Referential Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Technical University of Munich</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Shifting inductive bias with success-story algorithm, adaptive levin search, and incremental self-improvement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="105" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning to Compare: Relation Network for Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.06025</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning to Learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Few-shot learning through an information retrieval lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Improving One-Shot Learning through Fusing Side Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08347</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distance metric learning, with application to clustering with side-information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">2017. x and A. Let U be a d-dimensional subspace of R n (d ≤ n)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">There exist configurations of T, W, and ζ such that the span of y new − y is U while satisfying A = TW</title>
		<imprint/>
	</monogr>
	<note>Proceedings of the International Conference on Learning Representations (ICLR</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">MT-nets Learn a Metric in their Subspace Proposition 2. Fix x, A, and a loss function L T . Let U be a d-dimensional subspace of R n , and g(·, ·) a metric tensor on U. There exist configurations of T, W, and ζ such that the vector y new − y is in the steepest direction of</title>
		<imprint/>
	</monogr>
	<note>descent on L T with respect to the metric du</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
