<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Question Answering Approach to Emotion Cause Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Mathematics and Computer Science</orgName>
								<orgName type="institution">Fuzhou University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiannan</forename><surname>Hu</surname></persName>
							<email>hujiannan0526@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Engineering and Applied Science</orgName>
								<orgName type="institution">Aston University</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
							<email>xuruifeng@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Guangdong Provincial Engineering Technology Research Center for Data Science</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">the Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Du</surname></persName>
							<email>dujiachen@stmail.hitsz.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Question Answering Approach to Emotion Cause Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text. It is a much more difficult task compared to emotion classification. Inspired by recent advances in using deep memory networks for question answering (QA), we propose a new approach which considers emotion cause identification as a reading comprehension task in QA. Inspired by convolutional neural networks, we propose a new mechanism to store relevant context in different memory slots to model context information. Our proposed approach can extract both word level sequence features and lexical features. Performance evaluation shows that our method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the rapid growth of social network platforms, more and more people tend to share their experiences and emotions online. Emotion analysis of online text becomes a new challenge in Natural Language Processing (NLP). In recent years, studies in emotion analysis largely focus on emotion classification including detection of writers' emotions <ref type="bibr" target="#b9">(Gao et al., 2013)</ref> as well as readers' emotions <ref type="bibr" target="#b3">(Chang et al., 2015)</ref>. There are also some information extraction tasks defined in emotion analysis <ref type="bibr" target="#b4">(Chen et al., 2016;</ref><ref type="bibr" target="#b0">Balahur et al., 2011)</ref>, such as extracting the feeler of an emotion <ref type="bibr" target="#b6">(Das and Bandyopadhyay, 2010)</ref>. These methods † Corresponding Author: xuruifeng@hit.edu.cn assume that emotion expressions are already observed. Sometimes, however, we care more about the stimuli, or the cause of an emotion. For instance, Samsung wants to know why people love or hate Note 7 rather than the distribution of different emotions. Ex.1 我的手机昨天丢了，我现在很难过。 Ex.1 Because I lost my phone yesterday, I feel sad now.</p><p>In an example shown above, "sad" is an emotion word, and the cause of "sad" is "I lost my phone". The emotion cause extraction task aims to identify the reason behind an emotion expression. It is a more difficult task compared to emotion classification since it requires a deep understanding of the text that conveys an emotions.</p><p>Existing approaches to emotion cause extraction mostly rely on methods typically used in information extraction, such as rule based template matching, sequence labeling and classification based methods. Most of them use linguistic rules or lexicon features, but do not consider the semantic information and ignore the relation between the emotion word and emotion cause.</p><p>In this paper, we present a new method for emotion cause extraction. We consider emotion cause extraction as a question answering (QA) task. Given a text containing the description of an event which may or may not cause a certain emotion, we take an emotion word in context, such as "sad", as a query. The question to the QA system is: "Does the described event cause the emotion of sadness?". The expected answer is either "yes" or "no". (see <ref type="figure" target="#fig_0">Figure 1</ref>). We build our QA system based on a deep memory network. The memory network has two inputs: a piece of text, referred to as a story in QA systems, and a query. The story is represented using a sequence of word embeddings.</p><p>A recurrent structure is implemented to mine the deep relation between a query and a text. It measures the importance of each word in the text by an attention mechanism. Based on the learned attention result, the network maps the text into a low dimensional vector space. This vector is then used to generate an answer. Existing memory network based approaches to QA use weighted sum of attentions to jointly consider short text segments stored in memory. However, they do not explicitly model sequential information in the context. In this paper, we propose a new deep memory network architecture to model the context of each word simultaneously by multiple memory slots which capture sequential information using convolutional operations <ref type="bibr" target="#b14">(Kim, 2014)</ref>, and achieves the state-of-the-art performance compared to existing methods which use manual rules, common sense knowledge bases or other machine learning models.</p><p>The rest of the paper is organized as follows. Section 2 gives a review of related works on emotion analysis. Section 3 presents our proposed deep memory network based model for emotion cause extraction. Section 4 discusses evaluation results. Finally, Section 5 concludes the work and outlines the future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Identifying emotion categories in text is one of the key tasks in NLP <ref type="bibr" target="#b18">(Liu, 2015)</ref>. Going one step further, emotion cause extraction can reveal important information about what causes a certain emotion and why there is an emotion change. In this section, we introduce related work on emotion analysis including emotion cause extraction.</p><p>In emotion analysis, we first need to determine the taxonomy of emotions. Researchers have proposed a list of primary emotions <ref type="bibr" target="#b27">(Plutchik, 1980;</ref><ref type="bibr" target="#b7">Ekman, 1984;</ref><ref type="bibr" target="#b34">Turner, 2000)</ref>. In this study, we adopt Ekman's emotion classification scheme <ref type="bibr" target="#b7">(Ekman, 1984)</ref>, which identifies six primary emotions, namely happiness, sadness, fear, anger, disgust and surprise, known as the "Big6" scheme in the W3C Emotion Markup Language. This emotion classification scheme is agreed upon by most previous works in Chinese emotion analysis.</p><p>Existing work in emotion analysis mostly focuses on emotion classification  and emotion information extraction <ref type="bibr" target="#b1">(Balahur et al., 2013)</ref>. <ref type="bibr" target="#b36">Xu et al. (2012)</ref> used a coarse to fine method to classify emotions in Chinese blogs. <ref type="bibr" target="#b9">Gao et al. (2013)</ref> proposed a joint model to co-train a polarity classifier and an emotion classifier. <ref type="bibr" target="#b2">Beck et al. (2014)</ref> proposed a Multi-task Gaussian-process based method for emotion classification. <ref type="bibr" target="#b3">Chang et al. (2015)</ref> used linguistic templates to predict reader's emotions. <ref type="bibr" target="#b6">Das and Bandyopadhyay (2010)</ref> used an unsupervised method to extract emotion feelers from Bengali blogs. There are other studies which focused on joint learning of sentiments <ref type="bibr" target="#b20">(Luo et al., 2015;</ref><ref type="bibr" target="#b25">Mohtarami et al., 2013)</ref> or emotions in tweets or blogs <ref type="bibr" target="#b29">(Quan and Ren, 2009;</ref><ref type="bibr" target="#b13">Hasegawa et al., 2013;</ref><ref type="bibr" target="#b28">Qadir and Riloff, 2014;</ref><ref type="bibr" target="#b26">Ou et al., 2014)</ref>, and emotion lexicon construction <ref type="bibr" target="#b24">(Mohammad and Turney, 2013;</ref><ref type="bibr" target="#b31">Staiano and Guerini, 2014)</ref>. However, the aforementioned work all focused on analysis of emotion expressions rather than emotion causes.  first proposed a task on emotion cause extraction. They manually constructed a corpus from the Academia Sinica Balanced Chinese Corpus. Based on this corpus,  proposed a rule based method to detect emotion causes based on manually define linguistic rules. Some studies <ref type="bibr" target="#b12">(Gui et al., 2014;</ref><ref type="bibr" target="#b12">Li and Xu, 2014;</ref><ref type="bibr" target="#b8">Gao et al., 2015)</ref> extended the rule based method to informal text in Weibo text (Chinese tweets).</p><p>Other than rule based methods, <ref type="bibr" target="#b30">Russo et al. (2011)</ref> proposed a crowdsourcing method to construct a common-sense knowledge base which is related to emotion causes. But it is challenging to extend the common-sense knowledge base automatically. <ref type="bibr" target="#b10">Ghazi et al. (2015)</ref> used Conditional Random Fields (CRFs) to extract emotion causes. However, it requires emotion cause and emotion keywords to be in the same sentence. More recently, <ref type="bibr" target="#b11">Gui et al. (2016)</ref> proposed a multi-kernel based method to extract emotion causes through learning from a manually annotated emotion cause dataset.</p><p>Most existing work does not consider the relation between an emotion word and the cause of such an emotion, or they simply use the emotion word as a feature in their model learning. Since emotion cause extraction requires an understanding of a given piece of text in order to correctly identify the relation between the description of an event which causes an emotion and the expression of that emotion, it can essentially be considered as a QA task. In our work, we choose the memory network, which is designed to model the relation between a story and a query for QA systems <ref type="bibr">(Weston et al., 2014;</ref><ref type="bibr" target="#b32">Sukhbaatar et al., 2015)</ref>. Apart from its application in QA, memory network has also achieved great successes in other NLP tasks, such as machine translation <ref type="bibr" target="#b21">(Luong et al., 2015)</ref>, sentiment analysis <ref type="bibr" target="#b33">(Tang et al., 2016)</ref> or summarization (M. <ref type="bibr" target="#b22">Rush et al., 2015)</ref>. To the best of our knowledge, this is the first work which uses memory network for emotion cause extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>In this section, we will first define our task. Then, a brief introduction of memory network will be given, including its basic learning structure of memory network and deep architecture. Last, our modified deep memory network for emotion cause extraction will be presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>The formal definition of emotion cause extraction is given in <ref type="bibr" target="#b11">(Gui et al., 2016)</ref>. In this task, a given document, which is a passage about an emotion event, contains an emotion word E and the cause of the event. The document is manually segmented in the clause level. For each clause c = {w 1 , w 2 , ...w k } consisting of k words, the goal is to identify which clause contains the emotion cause. For data representation, we can map each word into a low dimensional embedding space, a.k.a word vector <ref type="bibr" target="#b23">(Mikolov et al., 2013)</ref>. All the word vectors are stacked in a word embedding matrix L ∈ R d× V , where d is the dimension of word vector and V is the vocabulary size.</p><p>For example, the sentence, "I lost my phone yesterday, I feel so sad now." shown in <ref type="figure" target="#fig_0">Figure 1</ref>, consists of two clauses. The first clause contains the emotion cause while the second clause ex-presses the emotion of sadness. Current methods to emotion cause extraction cannot handle complex sentence structures where the expression of an emotion and its cause are not adjacent. We envision that the memory network can better model the relation between a emotion word and its emotion causes in such complex sentence structures. In our approach, we only select the clause with the highest probability to be the emotion cause in each document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Memory Network</head><p>We first present a basic memory network model for emotion cause extraction (shown in <ref type="figure" target="#fig_1">Figure 2)</ref>. Given a clause c = {w 1 , w 2 , ..., w k }, and an emotion word, we first obtain the emotion word's representation in an embedding space, denoted by E. For the clause, let the embedding representations of the words be denoted by e 1 , e 2 , ..., e k . Here, both e i and E are defined in R d . Then, we use the inner product to evaluate the correlation between each word i in a clause and the emotion word, denoted as m i :</p><formula xml:id="formula_0">m i = e i · E.<label>(1)</label></formula><p>We then normalize the value of m i to [0, 1] using a softmax function, denoted by α i as:</p><formula xml:id="formula_1">α i = exp (m i ) k j=1 exp (m j ) ,<label>(2)</label></formula><p>where k is the length of the clause. k also serves as the size of the memory. Obviously, α i ∈ [0, 1] and k i=1 α i = 1. α i can serve as an attention weight to measure the importance of each word in our model. Then, a sum over the word embedding e i , weighted by the attention vector form the output of the memory network for the prediction of o:</p><formula xml:id="formula_2">o = k i=1 e i · α i + E.<label>(3)</label></formula><p>The final prediction is an output from a softmax function, denoted asô:</p><formula xml:id="formula_3">o = softmax W T o .<label>(4)</label></formula><p>Usually, W is a d × d weight matrix and T is the transposition. Since the answer in our task is a simple "yes" or "no", we use a d × 1 matrix for W . As the distance between a clause and an emotion words is a very important feature according to <ref type="bibr" target="#b11">(Gui et al., 2016)</ref>, we simply add this distance into the softmax function as an additional feature in our work. The basic model can be extended to deep architecture consisting of multiple layers to handle L hop operations. The network is stacked as follows:</p><p>• For hop 1, the query is E and the prediction vector is o 1 ;</p><p>• For hop i, the query is the prediction vector of the previous hop and the prediction vector is o i ;</p><p>• The output vector is at the top of the network. It is a softmax function on the prediction vector from hop L:</p><formula xml:id="formula_4">ô = softmax W T o L .</formula><p>The illustration of a deep memory network with three layers is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Since a memory network models the emotion cause at a fine-grained level, each word has a corresponding weight to measure its importance in this task. Comparing to previous approaches in emotion cause extraction which are mostly based on manually defined rules or linguistic features, a memory network is a more principled way to identify the emotion cause from text. However, the basic memory network model does not capture the sequential information in context which is important in emotion cause extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Convolutional Multiple-Slot Deep Memory Network</head><p>It is often the case that the meaning of a word is determined by its context, such as the previous word and the following word. Also, negations and emotion transitions are context sensitive. However, the memory network described in Section 3.2 has only one memory slot with size d × k to represent a clause, where d is the dimension of a word embedding and k is the length of a clause. It means that when the memory network models a clause, it only considers each word separately.</p><p>In order to capture context information for clauses, we propose a new architecture which contains more memory slot to model the context with a convolutional operation. The basic architecture of Convolutional Multiple-Slot Memory Network (in short: ConvMS-Memnet) is shown in <ref type="figure" target="#fig_3">Figure 4</ref>. Considering the text length is usually short in the dataset used here for emotion cause extraction, we set the size of the convolutional kernel to 3. That is, the weight of word w i in the i-th position considers both the previous word w i−1 and the following word w i+1 by a convolutional operation:</p><formula xml:id="formula_5">m i = 3 j=1 e i−2+j · E<label>(5)</label></formula><p>For the first and the last word in a clause, we use zero padding, w 0 = w k+1 = 0, where k is the length of a clause. Then, the attention weight for each word position in the clause is now defined as:</p><formula xml:id="formula_6">α i = exp (m i ) k j=1 exp m j<label>(6)</label></formula><p>Note that we obtain the attention for each position rather than each word. It means that the corresponding attention for the i-th word in the previous convolutional slot should be α i+1 . Hence, there are three prediction output vectors, namely, o previous , o current , o f ollowing :</p><formula xml:id="formula_7">o previous = k i=1 e i−1 · α i + E (7) o current = k i=1 e i · α i + E (8) o f ollowing = k i=1 e i+1 · α i + E<label>(9)</label></formula><p>At last, we concatenate the three vectors as o = o previous o current o f ollowing for the prediction by a softmax function:</p><formula xml:id="formula_8">o = softmax W T m o<label>(10)</label></formula><p>Here, the size of W m is (3 · d) × d. Since the prediction vector is a concatenation of three outputs. We implement a concatenation operation rather than averaging or other operations because the parameters in different memory slots can be updated by back propagation. The concatenation of three output vectors forms a sequence-level feature which can be used in the training. Such a feature is important especially when the size of annotated training data is small.</p><p>For deep architecture with multiple layer training, the network is more complex (shown in <ref type="figure">Figure  5</ref>).</p><p>• For the first layer, the query is an embedding of the emotion word, E.</p><p>• In the next layer, there are three input queries since the previous layer has three outputs: o 1 previous , o 1 current , o 1 f ollowing . So, for the j-th layer (j = 1), we need to re-define the weight function (5) as: m i = e i−1 ·o j−1 previous +e i ·o j−1 current +e i+1 ·o j−1 f ollowing (11) <ref type="figure">Figure 5</ref>: ConvMS-Memnet with three computational layers (hops).</p><p>• In the last layer, the concatenation of the three prediction vectors form the final prediction vector to generate the answer.</p><p>For model training, we use stochastic gradient descent and back propagation to optimize the loss function. Word embeddings are learned using a skip-gram model. The size of the word embedding is 20 since the vocabulary size in our dataset is small. The dropout is set to 0.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Evaluation</head><p>We first presents the experimental settings and then report the results in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup and Dataset</head><p>We conduct experiments on a simplified Chinese emotion cause corpus <ref type="bibr" target="#b11">(Gui et al., 2016</ref>) * , the only publicly available dataset on this task to the best of our knowledge. The corpus contains 2,105 documents from SINA city news † . Each document has only one emotion word and one or more emotion causes. The documents are segmented into clauses manually. The main task is to identify which clause contains the emotion cause.</p><p>Details of the corpus are shown in <ref type="table" target="#tab_1">Table 1</ref>. The metrics we used in evaluation follows . It is commonly accepted so that we can compare our results with others. If a proposed emotion cause clause covers the annotated answer, the word sequence is considered correct. The precision, recall, and F-measure are defined by  </p><formula xml:id="formula_9">, F = 2 × P × R P + R .</formula><p>In the experiments, we randomly select 90% of the dataset as training data and 10% as testing data. In order to obtain statistically credible results, we evaluate our method and baseline methods 25 times with different train/test splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation and Comparison</head><p>We compare with the following baseline methods:</p><p>• RB (Rule based method): The rule based method proposed in .</p><p>• CB (Common-sense based method): This is the knowledge based method proposed by <ref type="bibr" target="#b30">(Russo et al., 2011)</ref>. We use the Chinese Emotion Cognition Lexicon <ref type="bibr" target="#b37">(Xu et al., 2013)</ref> as the common-sense knowledge base. The lexicon contains more than 5,000 kinds of emotion stimulation and their corresponding reflection words.</p><p>• RB+CB+ML (Machine learning method trained from rule-based features and facts from a common-sense knowledge base): This methods was previously proposed for emotion cause classification in . It takes rules and facts in a knowledge base as features for classifier training. We train a SVM using features extracted from the rules defined in  and the Chinese Emotion Cognition Lexicon <ref type="bibr" target="#b37">(Xu et al., 2013)</ref>.</p><p>• SVM: This is a SVM classifier using the unigram, bigram and trigram features. It is a baseline previously used in <ref type="bibr" target="#b11">Gui et al., 2016)</ref>   • Word2vec: This is a SVM classifier using word representations learned by Word2vec <ref type="bibr" target="#b23">(Mikolov et al., 2013)</ref> as features.</p><p>• Multi-kernel: This is the state-of-the-art method using the multi-kernel method <ref type="bibr" target="#b11">(Gui et al., 2016)</ref> to identify the emotion cause. We use the best performance reported in their paper.</p><p>• CNN: The convolutional neural network for sentence classification <ref type="bibr" target="#b14">(Kim, 2014)</ref>.</p><p>• Memnet: The deep memory network described in Section 3.2. Word embeddings are pre-trained by skip-grams. The number of hops is set to 3.</p><p>• ConvMS-Memnet:</p><p>The convolutional multiple-slot deep memory network we proposed in Section 3.3. Word embeddings are pre-trained by skip-grams. The number of hops is 3 in our experiments. <ref type="table" target="#tab_3">Table 2</ref> shows the evaluation results. The rule based RB gives fairly high precision but with low recall. CB, the common-sense based method, achieves the highest recall. Yet, its precision is the worst. RB+CB, the combination of RB and CB gives higher the F-measure But, the improvement of 1.27% is only marginal compared to RB.</p><p>For machine learning methods, RB+CB+ML uses both rules and common-sense knowledge as features to train a machine learning classifier. It achieves F-measure of 0.5597, outperforming RB+CB. Both SVM and word2vec are word feature based methods and they have similar performance. For word2vec, even though word representations are obtained from the SINA news raw corpus, it still performs worse than SVM trained using n-gram features only. The multi-kernel method <ref type="bibr" target="#b11">(Gui et al., 2016)</ref> is the best performer   among the baselines because it considers context information in a structured way. It models text by its syntactic tree and also considers an emotion lexicon. Their work shows that the structure information is important for the emotion cause extraction task. Naively applying the original deep memory network or convolutional network for emotion cause extraction outperforms all the baselines except the convolutional multi-kernel method. However, using our proposed ConvMS-Memnet architecture, we manage to boost the performance by 11.54% in precision, 4.84% in recall and 8.24% in Fmeasure respectively when compared to Memnet. The improvement is very significant with p-value less than 0.01 in t-test. The ConvMS-Memnet also outperforms the previous best-performing method, multi-kernel, by 3.01% in F-measure. It shows that by effectively capturing context information, ConvMS-Memnet is able to identify the emotion cause better compared to other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">More Insights into the ConvMS-Memnet</head><p>To gain better insights into our proposed ConvMS-Memnet, we conduct further experiments to understand the impact on performance by using: 1) pre-trained or randomly initialized word embedding; 2) multiple hops; 3) attention visualizations; 4) more training epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Pre-trained Word Embeddings</head><p>In our ConvMS-Memnet, we use pre-trained word embedding as the input. The embedding maps each word into a lower dimensional real-value vector as its representation. Words sharing simi-lar meanings should have similar representations. It enables our model to deal with synonyms more effectively.</p><p>The question is, "can we train the network without using pre-trained word embeddings?". We initialize word vectors randomly, and use an embedding matrix to update the word vectors in the training of the network simultaneously. Comparison results are shown in <ref type="table" target="#tab_5">Table 3</ref>. It can be observed that pre-trained word embedding gives 2.59% higher F-measure compared to random initialization. This is partly due to the limited size of our training data. Hence using word embedding trained from other much larger corpus gives better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Multiple Hops</head><p>It is widely acknowledged that computational models using deep architecture with multiple layers have better ability to learn data representations with multiple levels of abstractions. In this section, we evaluate the power of multiple hops in this task. We set the number of hops from 1 to 9 with 1 standing for the simplest single layer network shown in <ref type="figure" target="#fig_3">Figure 4</ref>. The more hops are stacked, the more complicated the model is. Results are shown in <ref type="table" target="#tab_6">Table 4</ref>. The single layer network has achieved a competitive performance. With the increasing number of hops, the performance improves. However, when the number of hops is larger than 3, the performance decreases due to overfitting. Since the dataset for this task is small, more parameters will lead to overfitting. As such, we choose 3 hops in our final model since it gives the best performance in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Word-Level Attention Weights</head><p>Essentially, memory network aims to measure the weight of each word in the clause with respect to the emotion word. The question is, will the model really focus on the words which describe the emotion cause? We choose one example to show the attention results in <ref type="table" target="#tab_8">Table 5</ref>:</p><formula xml:id="formula_10">Ex.2 家 人/family 的/'s 坚 持/insistence 更/more 让/makes 人/people 感动/touched</formula><p>In this example, the cause of the emotion "touched" is "insistence". We show in <ref type="table" target="#tab_8">Table 5</ref> the distribution of word-level attention weights in different hops of memory network training. We can observe that in the first two hops, the highest attention weights centered on the word "more". However, from the third hop onwards, the highest atten-   tion weight moves to the word sub-sequence centred on the word "insistence". This shows that our model is effective in identifying the most important keyword relating to the emotion cause. Also, better results are obtained using deep memory network trained with at least 3 hops. This is consistent with what we observed in Section 4.3.2.</p><p>In order to evaluate the quality of keywords extracted by memory networks, we define a new metric on the keyword level of emotion cause extraction. The keyword is defined as the word which obtains the highest attention weight in the identified clause. If the keywords extracted by our algorithm is located within the boundary of annotation, it is treated as correct. Thus, we can obtain the precision, recall, and F-measure by comparing the proposed keywords with the correct keywords by:</p><formula xml:id="formula_11">P = correct keywords 1 proposed keywords 1 , R = correct keywords 1 annotated keywords 1 , F = 2 × P × R P + R .</formula><p>Since the reference methods do not focus on the keywords level, we only compare the performance of Memnet and ConvMS-Memnet in Table 6. It can be observed that our proposed ConvMS-Memnet outperforms Memnet by 5.6% in F-measure. It shows that by capturing context features, ConvMS-Memnet is able to identify the word level emotion cause better compare to Memnet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Training Epochs</head><p>In our model, the training epochs are set to 20. In this section, we examine the testing error using a case study. Due to the page length limit, we only choose one example from the corpus. The text below has four clauses: Ex.3 45天，对于失去儿子的他们是多么的漫 长，宝贝回家了，这个春节是多么幸福。 Ex.3 45 days, it is long time for the parents who lost their baby. If the baby comes back home, they would become so happy in this Spring Festival.</p><p>In this example, the cause of emotion "happy" is described in the third clause.</p><p>We show in <ref type="table">Table 7</ref> the probability of each clause containing an emotion cause in different training epochs. It is interesting to see that our model is able to detect the correct clause with only 5 epochs. With the increasing number of training epochs, the probability associated with the correct clause increases further while the probabilities of incorrect clauses decrease generally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Limitations</head><p>We have shown in Section 4.3.4 a simple example consisting of only four clauses from which our model can identify the clause containing the emotion cause correctly. We notice that for some complex text passages which contain long distance dependency relations, negations or emotion transitions, our model may have a difficulty in detecting the correct clause containing the emotion causes. It is a challenging task to properly model the discourse relations among clauses. In the future, we will explore different network architecture with consideration of various discourse relations possibly through transfer learning of larger annotated data available for other tasks.</p><p>Another shortcoming of our model is that, the answer generated from our model is simply "yes" or "no". The main reason is that the size of the annotated corpus is too small to train a model which can output natural language answers in full sentences. Ideally, we would like to develop a model which can directly give the cause of an emotion  <ref type="table">Table 7</ref>: The probability of a clause containing the emotion cause in different iterations in the multipleslot memory network.</p><p>expressed in text. However, since the manual annotation of data is too expensive for this task, we need to explore feasible ways to automatically collect annotate data for emotion cause detection.</p><p>We also need to study effective evaluation mechanisms for such QA systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, we treat emotion cause extraction as a QA task and propose a new model based on deep memory networks for identifying the emotion causes for an emotion expressed in text. The key property of this approach is the use of context information in the learning process which is ignored in the original memory network. Our new memory network architecture is able to store context in different memory slots to capture context information in proper sequence by convolutional operation. Our model achieves the state-of-the-art performance on a dataset for emotion cause detection when compared to a number of competitive baselines. In the future, we will explore effective ways to model discourse relations among clauses and develop a QA system which can directly output the cause of emotions as answers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of emotion cause extraction based on the QA framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>A single layer memory network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Deep memory network with three computational layers (hops).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>A single layer ConvMS-Memnet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Details of the dataset.</figDesc><table><row><cell>P =</cell><cell>correct causes 1 proposed causes 1</cell><cell>,</cell></row><row><cell>R =</cell><cell cols="2">correct causes 1 annotated causes 1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison with existing methods.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Comparison of using pre-trained or randomly initialized word embedding.</figDesc><table><row><cell>Method</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>Hop 1</cell><cell cols="3">0.6597 0.6444 0.6520</cell></row><row><cell>Hop 2</cell><cell cols="3">0.6877 0.6718 0.6796</cell></row><row><cell>Hop 3</cell><cell cols="3">0.7076 0.6838 0.6955</cell></row><row><cell>Hop 4</cell><cell cols="3">0.6882 0.6722 0.6801</cell></row><row><cell>Hop 5</cell><cell cols="3">0.6763 0.6606 0.6683</cell></row><row><cell>Hop 6</cell><cell cols="3">0.6664 0.6509 0.6585</cell></row><row><cell>Hop 7</cell><cell cols="3">0.6483 0.6333 0.6407</cell></row><row><cell>Hop 8</cell><cell cols="3">0.6261 0.6116 0.6187</cell></row><row><cell>Hop 9</cell><cell cols="3">0.6161 0.6109 0.6089</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Performance with different number of</cell></row><row><cell>hops in ConvMS-Memnet.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>The distribution of attention in different hops.</figDesc><table><row><cell>Method</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>Memnet</cell><cell cols="3">0.5688 0.5588 0.5635</cell></row><row><cell cols="4">ConvMS-Memnet 0.6250 0.6140 0.6195</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Comparison of word level emotion cause extraction.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Emotinet: A knowledge base for emotion detection in text built on the appraisal theories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><forename type="middle">M</forename><surname>Hermida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Applications of Natural Language to Information Systems</title>
		<meeting>International Conference on Applications of Natural Language to Information Systems</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="27" to="39" />
		</imprint>
	</monogr>
	<note>Andrés Montoyo, and Rafael Muñoz</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Detecting implicit emotion expressions from text using ontological resources and lexical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><forename type="middle">M</forename><surname>Hermida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory and Applications of Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="235" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint emotion analysis via multi-task gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1798" to="1803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Linguistic template extraction for recognizing reader-emotion and emotional resonance writing assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Chun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cen-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Lun</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="775" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A computer-assistance learning system for emotional wording</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><forename type="middle">Hua</forename><surname>Wei Fan Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">Lung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Emotion cause detection with linguistic constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Yat Mei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="179" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding emotion holder from bengali blog texts-an unsupervised syntactic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipankar</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="621" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Expression and the nature of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Approaches to Emotion</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="19" to="344" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A rulebased approach to emotion cause detection for chinese micro-blogs. Expert Systems with Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiushuo</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="4517" to="4528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint learning on sentiment and emotion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Yat Mei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1505" to="1508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting emotion stimuli in emotion-bearing sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diman</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="152" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Event-driven emotion cause extraction with corpus construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1639" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Emotion cause detection with linguistic construction in chinese weibo text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Chinese Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting and eliciting addressee&apos;s emotion in online dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhiro</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Toyoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="964" to="972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A text-driven rule-based system for emotion cause detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Yat Mei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</title>
		<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentence-level emotion classification with label and context dependence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1045" to="1053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Text-based emotion classification using emotion cause extraction. Expert Systems with Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1742" to="1749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Sentiment analysis: Mining opinions, sentiments, and emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint modeling of news reader&apos;s and comment writer&apos;s emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanhuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peifeng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="511" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Jeam: A novel model for cross-domain sentiment classification based on emotion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Kun-Hu Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2503" to="2508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Crowdsourcing a word-emotion association lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic sense sentiment similarity through hidden emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitra</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="983" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploiting community emotion for microblog event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaoyan</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengjiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1159" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Emotion: A psychoevolutionary synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Plutchik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning emotion indicators from tweets: Hashtags, hashtag patterns, and phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1203" to="1209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Construction of a blog emotion corpus for chinese emotional expression analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqin</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuji</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1446" to="1454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Emocause: an easy-adaptable approach to emotion cause contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ester</forename><surname>Boldrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricio</forename><surname>Martínez-Barco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</title>
		<meeting>the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Depechemood: a lexicon for emotion analysis from crowd-annotated news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacopo</forename><surname>Staiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.1605</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2431" to="2439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Aspect level sentiment classification with deep memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="214" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">On the origins of human emotions: A sociological inquiry into the evolution of human affect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Stanford University Press</publisher>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Bordes. 2014. Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Coarse-to-fine sentence-level emotion classification based on the intra-sentence features and sentential context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2455" to="2458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A new emotion dictionary based on the distinguish of emotion expression and emotion cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengtian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Information Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="90" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A topic model for building fine-grained domainspecific emotion lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingju</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Pui</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL(2)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="421" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Emotion distribution learning from texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="638" to="647" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
