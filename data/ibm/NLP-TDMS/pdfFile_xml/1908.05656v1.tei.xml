<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PHYRE: A New Benchmark for Physical Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Gustafson</surname></persName>
							<email>lgustafson@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PHYRE: A New Benchmark for Physical Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Understanding and reasoning about physics is an important ability of intelligent agents. We develop the PHYRE benchmark for physical reasoning that contains a set of simple classical mechanics puzzles in a 2D physical environment. The benchmark is designed to encourage the development of learning algorithms that are sample-efficient and generalize well across puzzles. We test several modern learning algorithms on PHYRE and find that these algorithms fall short in solving the puzzles efficiently. We expect that PHYRE will encourage the development of novel sample-efficient agents that learn efficient but useful models of physics. For code and to play PHYRE for yourself, please visit https://player.phyre.ai.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Understanding and reasoning about physics is a hallmark of intelligence <ref type="bibr" target="#b8">[9]</ref>. Humans can make sense of novel physical situations by reasoning about abstract concepts like gravity, mass, inertia, and friction. For this reason, testing the ability to solve novel physics puzzles has been used to measure the reasoning abilities of human children <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b52">53]</ref> as well as non-human animals such as capuchin monkeys <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54]</ref>, chimpanzees <ref type="bibr" target="#b39">[40]</ref>, crows <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b47">48]</ref>, finches <ref type="bibr" target="#b48">[49]</ref>, and rooks <ref type="bibr" target="#b4">[5]</ref>. A key aspect of physical intelligence is generalization: after learning to solve a physics puzzle, an intelligent agent should be able to generalize that knowledge and quickly solve related tasks. Robust generalization may set humans apart from other species-prior research showed that four species of non-human primates can learn to solve novel physics puzzles, but struggle to generalize to related tasks <ref type="bibr" target="#b29">[30]</ref>.</p><p>We want to develop artificial systems that can reason and generalize about physics as well as people. However, we hypothesize that in the realm of physical reasoning, present-day machine learning methods will struggle to quickly solve new puzzles. We anticipate that more effective methods may involve fundamental improvements to sample-efficient learning and the ability to learn computationally efficient but useful models of physics.</p><p>Towards this goal, we have developed the PHYRE (PHYsical REasoning) benchmark. PHYRE provides a set of physics puzzles in a simulated 2D world. Each puzzle has a goal state (e.g., "make the green ball touch the blue wall") and an initial state in which the goal is not satisfied; see <ref type="figure">Figure 1</ref>. A puzzle can be solved by placing one or more new bodies in the environment such that when the physical simulation is run the goal is satisfied. An agent playing this game must solve previously unseen puzzles in as few attempts as possible. PHYRE was designed to satisfy three main goals:</p><p>• Focus on physical reasoning: Tasks are as simple as possible but still require nontrivial physical reasoning. Scenes are built only from balls and rectangular bars. Dynamics are deterministic, with only collision, gravity, and friction. Goals are symbolic, so natural language is not required. • Focus on generalization: After training on one set of tasks, we should expect an effective agent to solve new, previously unseen puzzles. The benchmark is structured such that puzzles are split into training tasks and evaluation tasks, and involves two different degrees of generalization. • Focus on sample-efficiency: Our evaluation rewards solving tasks with as few attempts as possible.</p><p>Methods that master a task only after thousands of attempts will not perform well.</p><p>Make the green ball touch the blue ball Make the green ball touch the blue bar Make the green ball touch the blue ball Make the green ball touch the blue ball <ref type="figure">Figure 1</ref>: Three examples of PHYRE tasks (left) and one example solution (right). Black objects are static; objects with any other color are dynamic and subject to gravity. The tasks describe a terminal goal state that can be achieved by placing additional object(s) in the world and running the simulator. The task in the left-most pane requires placement of two balls to be solved, whereas the others can be solved with one ball. The right-most pane illustrates a solution (red ball) and the solution dynamics. <ref type="figure">Figure 1</ref> shows three examples of PHYRE tasks. Each task comprises static and dynamic objects in a 2D environment and a goal description. Upon looking at these examples, you, the reader, will likely form an intuitive hypothesis for how to solve each problem. If your first attempt were to fail, you would likely be able to use your observations of what happened to refine your attempt into a successful solution. PHYRE encourages the development of learning agents with similar abilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>PHYRE is related to prior work on intuitive physics, visual reasoning, and learning in computer games and simulated (robotics) environments. It was developed concurrently with the Tools game <ref type="bibr" target="#b0">[1]</ref>.</p><p>Intuitive physics. Foundational work in cognitive psychology suggests that people reason about the physical world using simplified intuitive theories <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref>. Early computational instantiations of this framework used probabilistic models over physical simulations <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b60">61]</ref>, while more recent methods use feedforward neural networks trained to make pixelwise <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b59">60]</ref> or qualitative <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b60">61]</ref> predictions about the future, sometimes in conjuction with simulation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>. Many methods are evaluated on the constrained task of predicting whether a 3D stack of blocks will topple; some recent studies instead ask models to determine whether videos of more complex scenes are physically plausible <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b40">41]</ref>. In contrast, PHYRE provides a suite of goal-driven tasks to test intuitive physical understanding: rather than evaluating intermediate tasks like future prediction or stability modeling, PHYRE requires agents to intervene in the scene to achieve a desired end goal.</p><p>Visual reasoning. Work on visual reasoning dates to SHRDLU <ref type="bibr" target="#b55">[56]</ref> which probed scene understanding using natural language; more recent benchmarks require systems to answer natural-language questions about images <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20]</ref>. Recent methods use neural networks to extract sub-symbolic image representations, which are used in subsequent reasoning modules <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b42">43]</ref>. Like PHYRE, these tasks require reasoning about the interactions of multiple objects in a scene; however unlike PHYRE they assume a static world, and do not require reasoning about world dynamics.</p><p>Learning in computer games. Computer games often involve complex 2D and 3D environments and require agents to possess some level of physical understanding <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b45">46]</ref>. For instance, Atari games such as Pong involve precise positioning of a paddle based on observed ball dynamics <ref type="bibr" target="#b34">[35]</ref>. The main difference between prior work in computer games and our work is that PHYRE requires the agent to learn a single model to solve a wide range of different tasks rather than a specialized model for each task. Moreover, in contrast to most work in computer games, PHYRE requires the agent to learn in a sample-efficient manner, penalizing agents that require many samples to learn.</p><p>Learning in simulated (robotics) environments. A range of prior work studies learning in simulated (robotics) environments for self-driving cars <ref type="bibr" target="#b9">[10]</ref>, humanoid robotics <ref type="bibr" target="#b49">[50]</ref>, or navigation tasks <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b58">59]</ref>. In contrast to PHYRE, these prior studies focus on agents operating in realistic non-deterministic 3D environments in which the world is not fully observed, which hampers systematic study of reasoning capabilities of the agent. By contrast, PHYRE takes inspiration from CLEVR <ref type="bibr" target="#b19">[20]</ref> and limits the complexity of the environment, facilitating more systematic analysis of reasoning abilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PHYRE Physical Reasoning Benchmark</head><p>The PHYRE environment is a two-dimensional world that simulates simple deterministic Newtonian physics. There is a constant downward gravitational force and a small amount of friction. All bodies are non-deformable and are either static or dynamic, distinguished by color. Static bodies remain at a fixed position and are not influenced by gravity or collision, while dynamic bodies move in response to these forces. All bodies come from a small vocabulary 1 , varying in scale, location, and orientation.</p><p>A PHYRE task consists of an initial world state and a goal. The initial world state is a pre-defined configuration of bodies. The goal is a (subject, relation, object) triplet identifying a relationship between two bodies that the agent needs to achieve when the simulation terminates. At present all tasks use a single relation, touching for at least 3 seconds, which we found sufficient for developing a diverse set of tasks. The environment can be extended in the future to include additional relationships.</p><p>The agent aims to achieve the goal by taking a single action, placing one or more new dynamic bodies into the world. Bodies placed by the action may not extend beyond the world boundaries or intersect other bodies; such actions are rejected by the simulator as invalid. After the action is taken, the simulator runs until the goal is reached or until a time limit elapses, whichever happens first. The agent cannot perform additional actions while the simulator runs. Once the simulation is complete, the agent receives a binary reward indicating whether the goal was achieved, and gains access to observations of the intermediate world states produced by the simulator. If the goal was not achieved, the world resets to its initial state and the agent tries again, possibly informed by its prior attempts.</p><p>The full world state, comprising exact positions and orientations of bodies as well as their masses and velocities, is not revealed to agents since human observers cannot directly perceive such values from their environments. Instead, the agent receives coarser initial and intermediate world states as observation images which rasterize the world to a 256×256 grid. Each grid cell takes one of seven values specifying whether that location is a (1) dynamic goal object, (2) static goal subject, (3) dynamic goal subject, (4) static confounding body, (5) dynamic confounding body, (6) body placed by the agent, or <ref type="bibr" target="#b6">(7)</ref> background. With only one relation, the colors in the initial observation encode the goal, eliminating the need for natural-language goal specification or grounding. <ref type="figure">Figure 1</ref> shows three PHYRE tasks with goals written in natural language solely for the convenience of the reader.</p><p>Without any restrictions on the action space, for example on the body types, their properties, and the number of bodies that may be placed, the action space is large and complex. We therefore define two restricted action tiers for the current benchmark, which we describe next. After research progresses on these tiers, more complex ones may be added to the benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Benchmark Tiers</head><p>This work studies two benchmark tiers of increasing difficulty. A tier comprises a combination of: (1) a predefined set of all actions the agent is allowed perform and (2) a set of tasks that can be solved by at least one action from this action set. The two tiers we developed for this study are:</p><p>• PHYRE-B. Action set containing all valid locations and radii for a single ball (3D; continuous).</p><p>• PHYRE-2B. Action set containing all valid pairs of two balls (6D; continuous).</p><p>The two tiers each contain 25 task templates. A task template defines a set of related tasks that are generated by varying task template parameters (such as positions of initial world bodies). All tasks in the same template share a common goal, but have different initial world states. Each template defines 100 such tasks. Task templates are used to measure an agent's generalization ability in two settings.</p><p>In the within-template setting, an agent trains on a subset of tasks in the template and is evaluated on the remaining tasks within that template. To measure cross-template generalization, test tasks are selected exclusively from templates that were not used for training. Our criteria for task design, additional analysis, and visualizations of tasks are provided in the supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Setting</head><p>Because the agent can only perform a single action to solve a PHYRE task, PHYRE is similar to a contextual bandit setting <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25]</ref>. PHYRE differs from traditional contextual bandit settings in two   error bars indicate one standard deviation. Two-ball tasks are much harder to solve by chance than single ball tasks. Each tier contains a spectrum of task difficulty with respect to random guessing.</p><p>main ways: (1) it has an offline training phase that precedes the online learning testing phase and (2) the agent receives privileged information <ref type="bibr" target="#b50">[51]</ref> in addition to the binary reward signal, viz., it has access to observations of intermediate world states produced by the simulator on previous attempts.</p><p>In the training phase, the agent has access to the training tasks and unlimited access to the simulator. The agent does not have access to task solutions, but can use the simulator to train models that can solve tasks. Such models may include forward-prediction or action-prediction models.</p><p>In the testing phase, the agent receives test tasks that it needs to solve in as few attempts (queries to the simulator) as possible. After each attempt, the agent receives a binary reward and observations of intermediate world states. The agent can use this information to refine its action for the next attempt. Some actions may be invalid, i.e., correspond to an object that overlaps with other objects. In such cases, we neither give the agent any reward nor count this attempt toward the query budget. The agent receives access to all test tasks at once, allowing it to choose the order in which it solves tasks.</p><p>Performance measure. We judge an agent's performance by how efficiently it solves tasks in the testing phase. We characterize efficiency in terms of the number of actions that were attempted to solve a given task; fewer attempts corresponds to greater efficiency. We formalize this intuition by recording the cumulative percentage of test tasks that were solved (the success percentage) as a function of the number of attempts taken per task. To compare the performance of agents on PHYRE, we plot this success-percentage curve. We also compute a performance measure, called AUCCESS, that aggregates the success percentages in the curve via a weighted average. To place more emphasis on solving tasks with fewer attempts, we consider the range of attempts k ∈ {1, . . . , 100} and use weights w k = log(k + 1) − log(k), yielding AUCCESS = k w k · s k / k w k , where s k is the success percentage at k attempts. The relative weight of the first 10 attempts in the AUCCESS measure is ∼0.5: agents that need more than 10 attempts cannot get an AUCCESS score of more than 50%. This encourages the development of sample-efficient agents. AUCCESS is equivalent to the area under the success-percentage curve formed by replacing the discrete samples with a piecewise constant function and placing the number of attempts on a log scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis</head><p>To assess the difficulty of the tasks in both PHYRE tiers, we measured what percentage of PHYRE tasks can be solved by an agent that randomly samples actions from the action space. <ref type="figure" target="#fig_2">Figure 2a</ref> shows the percentage of tasks (y-axis) that this random agent solves in at most k attempts (x-axis), averaged over 10 runs on all PHYRE tasks. The figure reveals that tasks vary greatly in difficulty level: a few tasks can be solved by a random agent in just a few attempts, whereas other tasks require thousands of attempts to be solved. The figure also shows that tasks in the PHYRE-B tier are, on average, harder than those in PHYRE-2B because the action space in that tier has more degrees of freedom.</p><p>We designed the PHYRE tasks such that, on average, it takes a random agent no more than 10,000 attempts to solve task in the PHYRE-B tier and no more than 100,000 attempts to solve a task in the PHYRE-2B tier. <ref type="figure" target="#fig_2">Figure 2b</ref> illustrates this by displaying the average probability that a random attempt solves a task for each of the 25 task templates in both PHYRE tiers. In line with the previous analysis, the figure also shows that tasks in PHYRE-2B are substantially harder than those in PHYRE-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conduct experiments to obtain baseline results for within-template and cross-template generalization on the PHYRE benchmark. Experiments are performed separately on each tier. Code reproducing the results of our experiments is available from https://phyre.ai.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline Agents</head><p>We experiment with five baseline agents that rank actions given an observation of the initial state (recall that the observation encodes the goal): (1) a random agent, (2) a non-parametric agent, (3) a deep Q-network <ref type="bibr" target="#b34">[35]</ref>, and (4-5) counterparts to <ref type="formula">(2)</ref> and <ref type="formula">(3)</ref> that update the agent online during testing.</p><p>Random agent (RAND). This agent does not perform any training and instead samples actions uniformly at random from the 3D or 6D (depending on the tier) action space at test time.</p><p>Non-parametric agent (MEM). At training time, this agent generates a set of R random actions and uses the simulator to check if each of these actions can solve each of the training tasks. For each action a, the agent computes p a : the fraction of training tasks that the action solves. The agent then sorts the R actions by p a (highest to lowest), and tries them in this order at test time. This agent is non-parametric because it uses a list of "memorized" actions at test time.</p><p>In the cross-template setting, the test tasks come from previously unseen task templates and this simple agent cannot relate them to tasks seen during training. It therefore uses the same action ranking for all tasks and ignores the observation of the initial state. In the within-template setting, each test task comes from a task template that was seen during training. In this case, we give the agent access to the task template id for each test task. The agent maintains a per-task-template ranking of the R actions. The same set of actions is shared across all templates; only the ranking changes. The set of actions attempted on each task may vary because invalid actions are ignored; see Section 3.2.</p><p>Non-parametric agent with online learning (MEM-O). This agent has the same training phase as the non-parametric agent, but continues to learn online at test time. Specifically, after finishing each test task (either successfully or unsuccessfully), the agent updates p a based on the reward received for each action a in the subset of the actions it attempted. The updated ranking is used when the next task is attempted. Such online updates are beneficial, in particular, in the cross-template setting because they allow the agent to learn something about the tasks in the previously unseen templates. We use cross-validation to tune the relative weight of the update on each train-val fold (see Section 4.2).</p><p>Deep Q-network (DQN). As before, the DQN agent collects a set of observation-action-reward triplets by randomly sampling actions and running them through the simulator. The agent trains a deep network on the resulting data to predict the reward for an observation-action pair. Following <ref type="bibr" target="#b3">[4]</ref>, we train the network by minimizing the cross-entropy between the soft prediction and the observed reward. During training, we sample batches with an equal number of positive and negative triplets.</p><p>Our network comprises: (1) an action encoder that transforms the 3D or 6D (depending on the tier) action representation using a multi-layer perceptron with a single hidden layer; (2) an observation encoder that transforms the observation image into a hidden representation using a convolutional network (CNN); and (3) a fusion module that combines the action and observation representations and makes a prediction. Our action encoder is a MLP with a single hidden layer with 512 units and ReLU activations. Our observation encoder is a ResNet-18 <ref type="bibr" target="#b12">[13]</ref>. For the fusion module, we follow <ref type="bibr" target="#b36">[37]</ref> and use the action encoder to predict a bias and gain for each channel in the CNN. The output of the action encoder thus contains twice as many values as there are channels in the CNN at the fusion point. To expedite action ranking, we fuse both models before the last residual block of the CNN. We tried other fusion points but did not observe performance differences (see supplemental material).</p><p>The observation of the initial state is a 256×256 image with one of 7 colors at each pixel, which encodes properties of each body and the goal. We map this observation into a 7-channel image for input to the CNN; each colored pixel in the image yields a 7D one-hot vector. Following common practice, the network is trained end-to-end using stochastic gradient descent with the Adam optimizer <ref type="bibr" target="#b21">[22]</ref>. We anneal the learning rate to 0 using a half cosine schedule without restarts <ref type="bibr" target="#b27">[28]</ref>.</p><p>Deep Q-network with online learning (DQN-O). Akin to MEM-O, this agent uses rewards from test tasks to perform online updates. After finishing a test task, the agent performs a number of gradient descent updates using examples obtained from that task. The updated model is then used for the next test task. The number of updates and corresponding learning rate are set via cross-validation.</p><p>Contextual bandits. While PHYRE is a contextual-bandit setting, we found that contextual bandits (CBs) do not work well on our complex observation and action space. Most CBs model the expected reward given the context and action using linear models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25]</ref>, Gaussian processes <ref type="bibr" target="#b46">[47]</ref>, or deep neural networks <ref type="bibr" target="#b41">[42]</ref>. Linear models do not yield useful context representations (which are observation images). Gaussian processes require a reasonable kernel function on the observation image space, which is difficult to define. Methods based on deep neural network seem more suitable. We tried to use the implementation from <ref type="bibr" target="#b41">[42]</ref> 2 , but were unable to train the model once we replaced the shallow MLP used in <ref type="bibr" target="#b41">[42]</ref> by a CNN that is better suited for image encoding. In addition, CBs generally assume a fixed (usually small) number of arms without a similarity metric between the arms, which is problematic for PHYRE tasks: when reasonably discretized, the number of arms in PHYRE-B is ∼10 6 . Moreover, without considering similarity between actions, agents try various non-working arms in the same region of the action space without diversifying them (see Section 4.4).</p><p>Policy learners. We faced similar issues with policy learners such as PPO <ref type="bibr" target="#b44">[45]</ref> and A2C <ref type="bibr" target="#b35">[36]</ref>. While we were able to factorize the action space over each dimension and use continuous action spaces, we were unable to train models that outperform our random baseline due to poor training stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>We measure success percentage and AUCCESS on PHYRE using the learning setting of 3.2. To make results reproducible and allow fair comparisons between agents across studies, PHYRE provides:</p><p>• A fully deterministic environment: agents always produce the same result on a task.</p><p>• A process that deterministically splits the tasks into 10 folds containing a training, validation, and test set. As a result, agents are always compared on exactly the same task splits. Task splits are available for both tiers and both generalization settings (within-template and cross-template).</p><p>To avoid overfitting on test tasks, hyperparameter tuning is only to be performed based on the validation set: we discourage tuning of hyperparameters based on test task performance. For results on the test set, we use these tuned hyperparameter and train agents on the union of the training and validation sets. To compare agents, we use the non-parametric Wilcoxon signed-rank test for median difference <ref type="bibr" target="#b54">[55]</ref> with one-sided null hypotheses and p = 0.01. We use this test as it does not have a normality assumption, is efficient with small sample sizes, and works with relative values on each fold instead of absolute values. To facilitate comparisons with our baselines, we provide our AUCCESS scores on all 10 folds in the supplementary material.</p><p>At test time, all agents (except the random agent) rank the same set of 10,000 actions on each task and propose the highest-scoring actions for that task as solution attempts. The MEM(-O) agents were trained on the same 10,000 actions. The DQN(-O) agents were trained on 100,000 actions per task. <ref type="bibr" target="#b2">3</ref> All agents are permitted to make up to 100 attempts per task. This fact subtly implies that when computing the success percentage at k &lt; 100 attempts, online agents will have learned from up to 100 (not k) attempts per task; this pragmatic choice makes the benchmark computationally tractable as otherwise online agents would need to be re-run for every value of k ∈ {1, . . . , 100}.  <ref type="table" target="#tab_1">Table 1a</ref> presents the corresponding mean AUCCESS (and its standard deviation). The results are in line with the trends observed in Section 3.3: the within-template setting is much easier than the cross-template setting for all (non-random) agents. As forecasted, the two tiers also have different difficulty characteristics. In the cross-template setting, the best agent,   In <ref type="table" target="#tab_1">Table 1b</ref>, we present the percentage of tasks that were solved within 10 attempts by each agent. This low-attempt regime is emphasized by AUCCESS and a goal of the PHYRE benchmark is to encourage research that improves results in this regime. The results are in line with prior observations and illustrate that the PHYRE-2B cross-template setting presents a significant challenge for all agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis</head><p>Here, we analyze the effect of: (1) the number of actions that are ranked by agents at test time and (2) the "aggressiveness" of agent updates on the performance of online agents. In the supplement, we also ablate the deep Q-network (DQN) design. For these experiments, agents are trained and evaluated on the train and validation splits, respectively, using the first three (out of 10) folds.</p><p>Number of actions ranked. <ref type="figure">Figure 4</ref> shows the AUCCESS of the RAND, MEM, and DQN agents as a function of the number of actions that are ranked by the agents at test time. We also present an OPTIMAL ranking agent that performs oracle ranking of the action set. The performance of the OPTIMAL agent suggests that ranking is a reasonable strategy: it solves all tasks in PHYRE-B and 95% of tasks in PHYRE-2B by ranking fewer than 100,000 attempts. For non-oracle agents, DQN is a much better ranker than MEM. As expected, AUCCESS increases as more actions are ranked, but eventually plateaus and sometimes decreases beyond a certain number of attempts. This is due to a lack of diversity in the rankings produced by the agents, which do not have a model of similarity between actions and may suggest multiple similar attempts when sampling of actions is fine-grained.</p><p>Effect of online updates. Online agents use examples obtained during both the training and testing stages. <ref type="figure">Figure 5</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Future Work</head><p>PHYRE aims to enable the development of physical reasoning algorithms with strong generalization properties mirroring those of humans <ref type="bibr" target="#b29">[30]</ref>. Yet the baseline methods studied in this work are far from this goal, demonstrating limited generalization abilities. We foresee several areas for advancement:</p><p>• Agents should use intermediate observations from the simulator following an (unsuccessful) attempt to refine their next attempt. Our current failure to do so makes the agents sample-inefficient, as these observations contain rich information on the specific task that the agent is solving that should be used effectively for efficient problem-solving. Doing so requires counterfactual reasoning: agents need to reason about what would happen upon a particular change to a previous attempt. • Agents should use a forward-prediction model that mimics the simulator by a learnable function <ref type="bibr" target="#b14">[15]</ref>. Such a model can be integrated into a DQN by running attempts through it for a number of time steps, and using the resulting state predictions as additional inputs into the Q-network. • Agents should explicitly diversify attempts when solving a task.</p><p>• Agents should use an active strategy at test time, e.g., by starting with solving simple tasks. • While each task is different from the others, they share the same underlying causal model (physics).</p><p>Methods aimed at invariant causal prediction (ICP) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b37">38]</ref> may be well-suited for PHYRE.</p><p>Based on these observations, we expect to witness rapid progress on the PHYRE benchmark. To this point, we highlight that PHYRE is an extensible platform upon which more challenging puzzle tiers may be built. The two tiers provided in this initial benchmark are designed to be approachable, yet challenging. Future tiers may involve substantially larger and more complex action spaces.</p><p>We also foresee approaches that implement a simulator "internal" to the agent and then query it to brute-force a solution before submitting any attempts to the real simulator. Based on initial experiments, we expect that training a neural network to exactly mimic the simulator will be difficult. However, one might instead use hand-coded rules specific to PHYRE-in the extreme, one could simply call the real simulator inside the agent. We view such approaches as violating the spirit of the benchmark. We discourage this line of attack as well as in-between solutions that combine function approximation with extensive hand-coded inductive biases that are specific to PHYRE. <ref type="figure" target="#fig_7">Figure 6</ref> shows the effect on AUCCESS of six modifications to our DQN agent. The modifications encompass changes to the architecture of the action encoder (Act1024 and Act1024×2), the fusion mechanism (FuseGlobal, FuseFirst, and FuseAll), and the balancing of training batches (NoBalancing); see the figure caption for full details. We make four main observations:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Ablation Study of Deep Q-Network (DQN)</head><p>• Class-balancing training batches is critical to the DQN agent's performance, particularly on the PHYRE-2B tier where only 0.3% of randomly chosen actions yield a positive example. • Early fusion of action information into the ResNet-18 observation encoder does not help. Early fusion is also inefficient for action ranking: it prohibits caching of the observation encoder's output. • Our default fusion method uses channel-wise bias and gain modulation immediately before the ResNet-18 conv5 stage; applying this fusion the final globally pooled features, instead, substantially deteriorates AUCCESS. • Larger action encoders can improve performance, but the gains are not consistent across settings.  <ref type="bibr" target="#b36">[37]</ref>): Baseline fuses with the input to the ResNet-18 conv5 stage; FuseFirst fuses with the input to the conv2 stage; FuseAll fuses with the inputs to each stage from conv2 to conv5; and FuseGlobal fuses with the globally max-pooled output of the conv5 stage. Act1024 and Act1024×2 DQN agents use Baseline fusion but larger action encoder networks with one or two hidden layers of 1024 units, respectively. The NoBalancing agents trains the Baseline DQN without balancing the positive and negative examples in the batches. We refer the reader to our code release on https://phyre.ai for full details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PHYRE Tasks</head><p>As discussed in the main paper, the current PHYRE benchmark provides two task tiers: PHYRE-B tasks can be solved by placing a single ball in the initial world, whereas PHYRE-2B tasks require placement of two balls in the initial scene. Each tier provides 25 task templates, and each task template contains 100 tasks that are similar in design but that have a different initial configuration of bodies in the world. <ref type="figure">Figure 7</ref> shows an example task from each of the 25 task templates in the PHYRE-B tier, and <ref type="figure">Figure 8</ref> shows an example task for each of the 25 task templates in the PHYRE-2B tier.</p><p>Stable solutions. When designing the PHYRE tasks, we made sure that each task has a stable solution. We define a stable solution to be an action that: (1) solves the task and (2) still solves the task if the action is slightly perturbed. The perturbations we consider are translations by 0.5 pixels along each axis (8 shifts in total).</p><p>Task solvability. Because the current benchmark contains (25 + 25) × 100 = 5, 000 tasks, it is cumbersome to manually find stable solutions for each task. Moreover, it is not possible to do brute-force search over all possible actions because the action space is continuous. Therefore, we used the following stochastic approach to evaluate whether or not a task is solvable. Let a denote an action and τ a task. We define the random variable stably_solves(a, τ ) to be 1 if action a is a stable solution for task τ and 0 otherwise. The random variable valid(a, τ ) is 1 iff action a is a valid action for task τ . We define the solvability level of task τ to be: s(τ ) = P (stably_solves(a, τ ) = 1|valid(a, τ ) = 1). To determine whether task τ is solvable, we would ideally seek to reject the hypothesis s(τ ) = 0.</p><p>Exact testing of this hypothesis is, however, infeasible, and so we resort to a proxy that uses a small constant p 0 , randomly selected actions, and a binomial statistical test to reject at least one of the hypotheses: s(τ ) ≤ p 0 or s(τ ) ≥ 2p 0 . We sample random actions until we can reject one of the two hypotheses. If the s(τ ) ≤ p 0 hypothesis is rejected, we define the task to be solvable. Alternatively, we define the task unsolvable if the s(τ ) ≥ 2p 0 hypothesis is rejected. In the unlikely event that both hypotheses are rejected we categorize the task as solvable.</p><p>It is possible to show that this algorithm requires no more than 1 32p0 action samples to reject at least one of the hypotheses with p-value 0.05. In practice, the value of p 0 was chosen to match our intuitive sense of task solvability: for PHYRE-B, we set p 0 = 10 −5 ; for PHYRE-2B, we set p 0 = 10 −6 .</p><p>Tier requirements. We used the definition of task solvability to check the correctness of the implementation of a task template. We also used task solvability to guide the selection of tasks within a template, e.g., the task creator may impose the constraint that a template only contains tasks with two-ball solutions and no single-ball solutions and enforce this constraint automatically.</p><p>We designed the task templates in both tiers to meet the following criteria: (1) all tasks in a tier to be solvable according to the definition of task solvability described above using samples from the action space corresponding to that tier and (2) less than 50% of the tasks in a PHYRE-2B task template can be solvable using a single ball. Hence, the task templates in PHYRE-2B are strictly harder to solve than those in PHYRE-B. Solution diversity. The task templates are designed such that solving a task instance within a template should not be trivial for an agent that knows how to solve other tasks in the template. For example, a task template should not have a single "master solution" that solves (nearly) all tasks in the template. At the same time, it is nearly impossible to prevent that multiple tasks in the same template share solutions because these tasks share the same design (see <ref type="figure">Figure 9</ref>).</p><p>To measure the solution diversity of a task template, we count the number of tasks within the template that each action can solve. Since the action space is continuous we cannot check every action. Instead, we randomly sample 10 6 actions to estimate solution diversity. We plot the results, for each task template, as histograms in <ref type="figure" target="#fig_8">Figure 10</ref> and 11. Each histogram shows the number of actions (y-axis) that can each solve a particular number of tasks (x-axis) within the template. We are interested to see if one or more actions are able to solve a large fraction of the tasks within a template, which will appear as bars (of any height) on the right side of the x-axis. The figures show that in general tasks in the PHYRE-2B tier require more diverse solutions to be solved than those in the PHYRE-B tier. <ref type="figure">Figure 7</ref>: The 25 task templates in the PHYRE-B tier. In each task the goal is to make the (dynamic) green body touch the (static) purple body or the (dynamic) blue body; black bodies are static and gray bodies are dynamic. Each of the PHYRE-B task templates gives rise to 100 tasks, each of which can be solved by adding a single dynamic ball to the scene. <ref type="figure">Figure 8</ref>: The 25 task templates in the PHYRE-2B tier. In each task the goal is to make the (dynamic) green body touch the (static) purple body or the (dynamic) blue body; black bodies are static and gray bodies are dynamic. Each of the PHYRE-2B task templates gives rise to 100 related tasks, all of which can be solved by adding two dynamic balls to the scene. <ref type="figure">Figure 9</ref>: Each row shows five example tasks from the same task template. The size, initial position, and orientation of bodies vary within a template, so each task requires its own solution; however all tasks within a template share similar physical intuition and high-level strategy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Comparing Agents</head><p>To determine if one agent outperforms another agent, we use the one-sided Wilcoxon test as implemented in the scipy.stats Python package. <ref type="bibr" target="#b3">4</ref> To enable future work to compare with our baselines, we provide AUCCESS scores for all folds and evaluation settings in <ref type="table">Table 2</ref>.  <ref type="table">Table 2</ref>: AUCCESS scores (on a 0.0 to 1.0 scale) of our five agents in both generalization settings, for each of our 10 folds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Percentage of tasks solved by a random agent (y-axis) as a function of the number of attempts (x-axis; log scale) for both PHYRE tiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Probability (y-axis; log scale) that a random attempt solves each of the 25 task templates (xaxis) in a tier for both PHYRE tiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>PHYRE complexity analysis. Values are averaged over 10 runs over all tasks in the tier;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>presents success-percentage curves for all five agents on both PHYRE tiers (-B and -2B) in both generalization settings (within-template and cross-template): the curves show the percentage of tasks solved as a function of the number of solution attempts per task, and are computed by averaging over all 10 folds in PHYRE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Percentage of solved tasks (success percentage) as a function of the number of attempts per task of five agents on PHYRE-{B, 2B} in the within-template and cross-template settings. Success percentages are averaged over all test tasks and 10 folds. Shaded regions show one standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>analyzes the effect of re-weighting both types of examples on the performance of online agents (on three folds). The results show that the AUCCESS of MEM-O is fairly independent of the weight used. The AUCCESS of the DQN-O agent does vary as a function of how many updates were performed at test time: online updates even impede DQN-O in the within-template setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 : 2 Figure 5 :</head><label>425</label><figDesc>AUCCESS as a function of the number of actions being ranked by the agent for the RANDOM, MEM, and DQN agents and for an agent that is OPTIMAL in terms of scoring attempts. AUCCESS of MEM-O and DQN-O agents as the "aggressiveness" of the online update is varied during the testing phase. The left-most point in each plot is an offline version of the agent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Mean AUCCESS on PHYRE-{B, 2B} of six DQN variants of the Baseline in the main text. Error bars show one standard deviation. FuseFirst, FuseAll, and FuseGlobal DQN agents perform fusion of observation and action features in alternative locations via channel-wise bias and gain modulation (akin to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Analysis of the solution diversity of the task templates in the PHYRE-B tier. Histograms show the number of actions (y-axis) that solve a certain number of tasks in the template (x-axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Analysis of the solution diversity of the task templates in the PHYRE-2B tier. Histograms show the number of actions (y-axis) that solve a certain number of tasks in the template (x-axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>) RAND 0.0517 0.0212 0.0099 0.0442 0.0038 0.0356 0.0178 0.0177 0.0264 0.0275 MEM 0.0728 0.0289 0.0135 0.0783 0.0090 0.0463 0.0186 0.0387 0.0376 0.0274 MEM-O 0.0967 0.0371 0.0164 0.0933 0.0094 0.0815 0.0242 0.0451 0.0535 0.0345 DQN 0.3818 0.1944 0.1072 0.3051 0.0732 0.2703 0.2388 0.2216 0.2528 0.2730 DQN-O 0.5149 0.2682 0.2596 0.5298 0.2809 0.5313 0.4828 0.3330 0.3581 0.3987 2B (within) RAND 0.0271 0.0367 0.0428 0.0301 0.0394 0.0452 0.0336 0.0287 0.0380 0.0335 MEM 0.0325 0.0336 0.0315 0.0371 0.0304 0.0314 0.0282 0.0320 0.0330 0.0347 MEM-O 0.0325 0.0336 0.0315 0.0371 0.0304 0.0314 0.0282 0.0320 0.0330 0.0347 DQN 0.6447 0.6829 0.6747 0.6763 0.6999 0.6700 0.6879 0.6704 0.6877 0.6824 DQN-O 0.6447 0.6829 0.6747 0.6763 0.6999 0.6700 0.6879 0.6704 0.6877 0.6824 B (cross) RAND 0.1178 0.1242 0.1818 0.1242 0.0381 0.2250 0.1173 0.1329 0.0894 0.1460 MEM 0.2059 0.1656 0.2004 0.2263 0.1159 0.2488 0.1416 0.2467 0.1055 0.1881 MEM-O 0.2578 0.2551 0.2443 0.2552 0.2327 0.2508 0.1469 0.2801 0.1281 0.2273 DQN 0.4369 0.3096 0.4305 0.4391 0.2277 0.4440 0.3453 0.3920 0.1898 0.4646 DQN-O 0.6859 0.4867 0.6671 0.5995 0.4916 0.6560 0.5100 0.6573 0.3733 0.4884 B (within) RAND 0.1344 0.1401 0.1379 0.1380 0.1275 0.1334 0.1395 0.1430 0.1336 0.1433 MEM 0.0198 0.0258 0.0230 0.0269 0.0223 0.0286 0.0237 0.0214 0.0223 0.0288 MEM-O 0.0198 0.0258 0.0230 0.0269 0.0223 0.0286 0.0237 0.0214 0.0223 0.0288 DQN 0.7682 0.7972 0.7822 0.7586 0.7703 0.7842 0.7801 0.7734 0.7804 0.7687 DQN-O 0.7682 0.7972 0.7822 0.7586 0.7703 0.7842 0.7801 0.7734 0.7804 0.7687</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Comparison of the five agents on PHYRE-{B, 2B}. Mean and standard deviation on the 10 folds are reported. MEM-O and DQN-O perform best with no update in the within-template setting, making them equivalent to MEM and DQN in this case; thus, we omit their results. *Indicates an agent's AUCCESS is better than all others per the Wilcoxon one-sided test with p = 0.01.DQN-O, is able to reach a reasonably high AUCCESS of 56.2% on PHYRE-B, but is at just 39.6% on PHYRE-2B. This small change in the action space substantially decreases agent success. Notably, agents that perform online learning ( -O) substantially outperform their offline counterparts.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The current body vocabulary contains balls, bars, standing sticks, and jars.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/tensorflow/models/tree/master/research/deep_contextual_bandits<ref type="bibr" target="#b2">3</ref> To simplify follow-up research, we will release the simulation results of these 100,000 actions per task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Specifically, we call scipy.stats.wilcoxon(A, B, zero_method='wilcox', correction=False, alternative='greater') to test if the AUCCESS vector A outperforms AUCCESS vector B, where A and B are component-wise paired with one component for each fold.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Mayank Rana for his help with early versions of PHYRE, and Audrey Durand, Joelle Pineau, Arthur Szlam, Alessandro Lazaric, Devi Parikh, Dhruv Batra, and Tim Rocktäschel for helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The tools challenge: Rapid trial-and-error learning in physical problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno>arXiv 1907.09620</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VQA: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Simulation as an engine of physical scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A distributional perspective on reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rooks use stones to raise the water level to reach a floating worm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Emery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1410" to="1414" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An empirical evaluation of thompson sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How do children solve aesop&apos;s fable?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Cheke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Loissel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">40574</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Contextual bandits with linear payoff functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Reyzin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Physical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An open urban driving simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Codevilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on Robot Learning</title>
		<meeting>the Annual Conference on Robot Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Unsupervised learning for physical interaction through video prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shapestacks: Learning vision-based physical intuition for generalised object stacking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Invariant causal prediction for nonlinear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heinze-Deml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Prediction under uncertainty with error-encoding networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno>arXiv 1711.04994</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to reason: End-to-end module networks for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Compositional attention networks for machine reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reasoning about physical interactions with object-oriented prediction and planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Janner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using the aesop&apos;s fable paradigm to investigate causal understanding of water displacement by new caledonian crows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Jelbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Cheke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">92895</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inferring and executing programs for visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The epoch-greedy algorithm for contextual multi-armed bandits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning physical intuition of block towers by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A contextual-bandit approach to personalized news article recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on World wide web</title>
		<meeting>the 19th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">To fall or not to fall: A visual approach to physical stability prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.00066</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual stability prediction and its application to manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sgdr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<title level="m">Stochastic gradient descent with warm restarts</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tubes, tables and traps: great apes solve two functionally equivalent trap tasks but show no evidence of transfer across tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Martin-Ordas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Call</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Colmenares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Animal cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="423" to="430" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Naive physics: The curvilinear impetus principle and its role in interactions with moving objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Curvilinear motion in the absence of external forces: Naive beliefs about the motion of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caramazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="issue">4474</biblScope>
			<biblScope unit="page" from="1139" to="1141" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Intuitive physics: the straight-down belief and its origin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Washburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Felch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">636</biblScope>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalizable features from unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Film: Visual reasoning with a general conditioning layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Causal discovery with continuous additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Piloto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.01128</idno>
		<title level="m">Probing physics knowledge using tools from developmental psychology</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Folk physics for apes: The chimpanzee&apos;s theory of how the world works</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povinelli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Intphys: A framework and benchmark for visual intuitive physics reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Riochet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Izard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dupoux</surname></persName>
		</author>
		<idno>arXiv 1803.07616</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Deep bayesian bandits showdown: An empirical comparison of bayesian deep networks for thompson sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Riquelme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.09127</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4967" to="4976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kadian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Maksymets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wijmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01201</idno>
		<title level="m">Habitat: A platform for embodied ai research</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno>arXiv 1707.06347</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Running the table: An AI for computer billiards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">American Association for Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0912.3995</idno>
		<title level="m">Gaussian process optimization in the bandit setting: No regret and experimental design</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Do new caledonian crows solve physical problems through causal reasoning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="247" to="254" />
			<date type="published" when="1655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Physical cognition and tool-use: performance of darwin&apos;s finches in the two-trap tube task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Teschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tebbich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Animal Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="563" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Mujoco: A physics engine for model-based control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Intelligent Robots and Systems</title>
		<meeting>the International Conference on Intelligent Robots and Systems</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A new learning paradigm: Learning using privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vashist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="544" to="557" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Lack of comprehension of cause effect relations in tool-using capuchin monkeys (cebus apella)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Visalberghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Limongelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Comparative Psychology</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Acting and understanding: Tool use revisited through the minds of capuchin monkeys. Reaching into thought: The minds of the great apes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Visalberghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Limongelli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="57" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Tool use in capuchin monkeys: Distinguishing between performing and understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Visalberghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Trinca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Primates</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="511" to="521" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Individual comparisons by ranking methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics bulletin</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="80" to="83" />
			<date type="published" when="1945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Procedures as a representation for data in a computer program for understanding natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
		</imprint>
		<respStmt>
			<orgName>MIT AI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Galileo: Perceiving physical object properties by integrating a physics engine with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yildirim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning to see physics via visual de-animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Building generalizable agents with a realistic and rich 3D environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02209</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">A comparative evaluation of approximate probabilistic simulation and deep neural networks as accounts of human physical scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<editor>CogSci</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
