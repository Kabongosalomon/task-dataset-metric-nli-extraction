<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Re-evaluation of Knowledge Graph Completion Methods</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
							<email>zhiqings@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Vashishth</surname></persName>
							<email>svashish@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
							<email>soumyasanyal@iisc.ac.in</email>
							<affiliation key="aff1">
								<orgName type="department">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
							<email>yiming@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Re-evaluation of Knowledge Graph Completion Methods</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing methods using our protocol. The reproducible code has been made publicly available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Real-world knowledge bases are usually expressed as multi-relational graphs, which are collections of factual triplets, where each triplet (h, r, t) represents a relation r between a head entity h and a tail entity t. However, real-word knowledge bases are usually incomplete <ref type="bibr" target="#b4">(Dong et al., 2014)</ref>, which motivates the research of automatically predicting missing links. A popular approach for Knowledge Graph Completion (KGC) is to embed entities and relations into continuous vector or matrix space, and use a well-designed score function f (h, r, t) to measure the plausibility of the triplet (h, r, t). Most of the previous methods use translation distance based <ref type="bibr" target="#b1">(Bordes et al., 2013;</ref><ref type="bibr" target="#b23">Wang et al., 2014;</ref><ref type="bibr" target="#b24">Xiao et al., 2016;</ref><ref type="bibr" target="#b19">Sun et al., 2019)</ref> and semantic matching based <ref type="bibr" target="#b15">(Nickel and Tresp, 2013;</ref><ref type="bibr" target="#b25">Yang et al., 2014;</ref><ref type="bibr" target="#b14">Nickel et al., 2016;</ref><ref type="bibr" target="#b21">Trouillon et al., 2016</ref>; * Equal contribution. <ref type="bibr" target="#b9">Liu et al., 2017)</ref> scoring functions which are easy to analyze.</p><p>However, recently, a vast number of neural network-based methods have been proposed. They have complex score functions which utilize blackbox neural networks including Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b3">(Dettmers et al., 2018;</ref><ref type="bibr" target="#b12">Nguyen et al., 2018)</ref>, Recurrent Neural Networks (RNNs) <ref type="bibr" target="#b8">(Lin et al., 2015;</ref><ref type="bibr" target="#b22">Wang et al., 2018)</ref>, Graph Neural Networks (GNNs) <ref type="bibr" target="#b17">(Schlichtkrull et al., 2017;</ref><ref type="bibr" target="#b18">Shang et al., 2019)</ref>, and Capsule Networks <ref type="bibr" target="#b13">(Nguyen et al., 2019)</ref>. While some of them report state-of-the-art performance on several benchmark datasets that are competitive to previous embedding-based approaches, a considerable portion of recent neural network-based papers report very high performance gains which are not consistent across different datasets. Moreover, most of these unusual behaviors are not at all analyzed. Such a pattern has become prominent and is misleading the whole community.</p><p>In this paper, we investigate this problem and find that this is attributed to the inappropriate evaluation protocol used by these approaches. We demonstrate that their evaluation protocol gives a perfect score to a model that always outputs a constant irrespective of the input. This has lead to artificial inflation of performance of several models. For this, we find a simple evaluation protocol that creates a fair comparison environment for all types of score functions. We conduct extensive experiments to re-examine some recent methods and fairly compare them with existing approaches. The source code of the paper has been publicly available at http://github.com/svjan5/kg-reeval. note the set of entities and relations and T = {(h, r, t) | h, t ∈ E, r ∈ R} is the set of triplets (facts), the task of Knowledge Graph Completion (KGC) involves inferring missing facts based on the known facts. Most the existing methods define an embedding for each entity and relation in G, i.e., e h , e r ∀h ∈ E, r ∈ R and a score function f (h, r, t) : E × R × E → R which assigns a high score for valid triplets than the invalid ones.</p><p>KGC Evaluation During KGC evaluation, for predicting t in a given triplet (h, r, t), a KGC model scores all the triplets in the set T = {(h, r, t ) | t ∈ E}. Based on the score, the model first sorts all the triplets and subsequently finds the rank of the valid triplet (h, r, t) in the list. In a more relaxed setting called filtered setting, all the known correct triplets (from train, valid, and test triplets) are removed from T except the one being evaluated <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref>. The triplets in T − {t} are called negative samples.</p><p>Related Work Prior to our work, <ref type="bibr" target="#b7">Kadlec et al. (2017)</ref>; <ref type="bibr" target="#b6">Jain et al. (2020)</ref> cast doubt on the claim that performance improvement of several models is due to architectural changes as opposed to hyperparameter tuning or different training objective. In our work, we raise similar concerns but through a different angle by highlighting issues with the evaluation procedure used by several recent methods. <ref type="bibr" target="#b2">Chandrahas et al. (2018)</ref> analyze the geometry of KG embeddings and its correlation with task performance while <ref type="bibr" target="#b11">Nayyeri et al. (2019)</ref> examine the effect of different loss functions on performance. Also, <ref type="bibr" target="#b5">Jain et al. (2018)</ref> investigate evaluation protocols for handling out-of-vocabulary entities. However, their analysis is restricted to non-neural approaches. Triplet Score <ref type="figure">Figure 1</ref>: Sorted score distribution of ConvKB for an example valid triplet and its negative samples. The score is normalized into [0, 1] (lower the better). Dotted line indicate the score for the valid triplet. We find that in this example, around 58.5% negative sampled triplets obtain the exact same score as the valid triplet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Observations</head><p>In this section, we first describe our observations and concerns and then investigate the reason behind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Inconsistent Improvements over Benchmark Datasets</head><p>Several recently proposed methods report high performance gains on a particular dataset. However, their performance on another dataset is not consistently improved. In <ref type="table">Table 1</ref>, we report change in MRR score on FB15k-237 <ref type="bibr" target="#b20">(Toutanova and Chen, 2015)</ref> and WN18RR <ref type="bibr" target="#b3">(Dettmers et al., 2018)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Observations on Score Functions</head><p>Score distribution When evaluating KGC methods, for a given triplet (h, r, t), the ranking of t given h and r is computed by scoring all the triplets of form {(h, r, t ) | t ∈ E}, where E is the set of all entities. On investing a few recent NN based approaches, we find that they have unusual score distribution, where some negatively sampled triplets have the same score as the valid triplet. An instance of FB15k-237 dataset is presented in <ref type="figure">Figure  1</ref>. Here, out of 14,541 negatively sampled triplets, 8,520 have the exact same score as the valid triplet.</p><p>Statistics on the whole dataset In <ref type="figure" target="#fig_1">Figure 2</ref>, we report the total number of triplets with the exact same score over the entire dataset for ConvKB <ref type="bibr" target="#b12">(Nguyen et al., 2018)</ref>  Root of the problem Further, we investigate the cause behind such unusual score distribution. In <ref type="figure">Figure 3</ref>, we plot the ratio of neurons becoming zero after ReLU activation for the valid triplets vs. their normalized frequency on FB15k-237 dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Protocols for KGC</head><p>In this section, we present different evaluation protocols that can be adopted in knowledge graph completion. We further show that inappropriate evaluation protocol is the key reason behind the unusual behavior of some recent NN-based methods.</p><p>How to deal with the same scores? An essential aspect of the evaluation method is to decide how to break ties for triplets with the same score. More concretely, while scoring the candidate set T , if there are multiple triplets with the same score from the model, one should decide which triplet to pick. Assuming that the triplets are sorted in a stable manner, we design a general evaluation scheme for KGC, which consists of the following three different protocols:</p><p>• TOP: In this setting, the correct triplet is inserted in the beginning of T . • BOTTOM: Here, the correct triplet is inserted at the end of T . • RANDOM: In this, the correct triplet is placed randomly in T .  Discussion Based on the definition of the three evaluation protocols, it is clear that TOP evaluation protocol does not evaluate the model rigorously. It gives the models that have a bias to provide the same score for different triplets, an inappropriate advantage. On the other hand, BOTTOM evaluation protocol can be unfair to the model during inference time because it penalizes the model for giving the same score to multiple triplets, i.e., if many triplets have the same score as the correct triple, the correct triplet gets the least rank possible. As a result, RANDOM is the best evaluation technique which is both rigorous and fair to the model. It is in line with the situation we meet in the real world: given several same scored candidates, the only option is to select one of them randomly. Hence, we propose to use RANDOM evaluation scheme for all model performance comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we conduct extensive experiments using our proposed evaluation protocols and make a fair comparison for several existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We evaluate the proposed protocols on FB15k-237 <ref type="bibr" target="#b20">(Toutanova and Chen, 2015)</ref> dataset 1 , which is a subset of FB15k <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref> with inverse relations deleted to prevent direct inference of test triples from training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Methods Analyzed</head><p>In our experiments, we categorize existing KGC methods into the following two categories: <ref type="bibr">1</ref> We also report our results on WN18RR <ref type="bibr" target="#b3">(Dettmers et al., 2018)</ref> dataset in the appendix.</p><p>• Non-Affected: This includes methods which give consistent performance under different evaluation protocols. For experiments in this paper, we consider three such methods -ConvE, Ro-tatE, and TuckER.</p><p>• Affected: This category consists of recently proposed neural-network based methods whose performance is affected by different evaluation protocols. ConvKB, CapsE, TransGate 2 , and KBAT are methods in this category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation Metrics</head><p>For all the methods, we use the code and the hyperparameters provided by the authors in their respective papers. Model performance is evaluated by Mean Reciprocal Rank (MRR), Mean Rank (MR) and Hits@10 (H@10) on the filtered setting <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation Results</head><p>To analyze the effect of different evaluation protocols described in Section 4, we study the performance variation of the models listed in Section 5.2.</p><p>We study the effect of using TOP and BOTTOM protocols and compare them to RANDOM protocol. In their original paper, ConvE, RotatE, and TuckER use a strategy similar to the proposed RANDOM protocol, while ConvKB, CapsE, and KBAT use TOP protocol. We also study the random error in RANDOM protocol with multiple runs, where we report the average and standard deviation on 5 runs with different random seeds. The results are presented in Tables 2.</p><p>We observe that for Non-Affected methods like ConvE, RotatE, and TuckER, the performance remains consistent across different evaluation protocols. However, with Affected methods, there is a considerable variation in performance. Specifically, we can observe that these models perform best when evaluated using TOP and worst when evaluated using BOTTOM 3 . Finally, we find that the proposed RANDOM protocol is very robust to different random seeds. Although the theoretic upper and lower bounds of a RANDOM score are TOP and BOTTOM scores respectively, when we evaluate knowledge graph completion for real-world largescale knowledge graphs, the randomness doesn't affect the evaluation results much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we performed an extensive reexamination study of recent neural network based KGC techniques. We find that many such models have issues with their score functions. Combined with inappropriate evaluation protocol, such methods reported inflated performance. Based on our observations, we propose RANDOM evaluation protocol that can clearly distinguish between these affected methods from others. We also strongly encourage the research community to follow the RANDOM evaluation protocol for all KGC evaluation purposes.  <ref type="table">Table 3</ref>: Performance comparison under different evaluation protocols on WN18RR dataset. For TOP and BOT-TOM, we report changes in performance with respect to RANDOM protocol. ‡: CapsE uses the pre-trained 100dimensional Glove <ref type="bibr" target="#b16">(Pennington et al., 2014)</ref> word embeddings for initialization on WN18RR dataset, which makes the comparison on WN18RR still unfair. †: KBAT has test data leakage in their original implementation, which is fixed in our experiments. Number of Triplets with Same Score 1 -4 5 -1 6 1 7 -6 4 6 5 -2 5 6 2 5 7 -1 0 2 4 1 0 2 5 -4 0 9 6 4 0 9 7 -1 6 3 8 4 1 6 3 8 5 -6 5 5 3 6</p><p>ConvKB CapsE ConvE <ref type="figure">Figure 4</ref>: Plot shows the frequency of the number of negative triplets with the same assigned score as the valid triplet during evaluation on WN18RR dataset. The results show that Unlike FB15k-237, in this dataset, only ConvKB has a large number of negative triplets get the same score as the valid triplets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Plot shows the frequency of the number of negative triplets with the same assigned score as the valid triplet during evaluation on FB15k-237 dataset. The results show that for methods like ConvKB and CapsE, a large number of negative triplets get the same score as the valid triplets whereas for methods like ConvE such occurrences are rare.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc><ref type="bibr" target="#b26">Yuan et al., 2019)</ref>. Overall, we find that for a few recent NN based methods, there are inconsistent gains on these two datasets. For instance, in ConvKB, there is a 21.8% improvement over ConvE on FB15k-237, but a degradation of 42.3% on WN18RR, which is surprising given the method is claimed to be better than ConvE. On the other hand, methods like RotatE and TuckER give consistent improvement across both benchmark datasets.</figDesc><table><row><cell>datasets with respect to ConvE (Dettmers</cell></row><row><cell>et al., 2018) for different methods including RotatE</cell></row><row><cell>(Sun et al., 2019), TuckER (Balažević et al., 2019),</cell></row><row><cell>ConvKB (Nguyen et al., 2018), CapsE (Nguyen</cell></row><row><cell>et al., 2019), KBAT (Nathani et al., 2019), and</cell></row><row><cell>TransGate (</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>MR ↓ H@10 ↑ MRR ↑ MR ↓ H@10 ↑ MRR ↑ MR ↓ H@10 ↑ MRR ↑ MR ↓ H@10 ↑</figDesc><table><row><cell></cell><cell></cell><cell>Reported</cell><cell></cell><cell>RANDOM</cell><cell></cell><cell>TOP</cell><cell></cell><cell></cell><cell>BOTTOM</cell></row><row><cell cols="2">MRR ↑ ConvE .325</cell><cell>244</cell><cell>.501</cell><cell cols="2">.324 ± .0 285 ± 0 .501 ± .0 .324</cell><cell>285</cell><cell>.501</cell><cell>.324</cell><cell>285</cell><cell>.501</cell></row><row><cell>RotatE</cell><cell>.338</cell><cell>177</cell><cell>.533</cell><cell cols="2">.336 ± .0 178 ± 0 .530 ± .0 .336</cell><cell>178</cell><cell>.530</cell><cell>.336</cell><cell>178</cell><cell>.530</cell></row><row><cell>TuckER</cell><cell>.358</cell><cell>-</cell><cell>.544</cell><cell cols="2">.353 ± .0 162 ± 0 .536 ± .0 .353</cell><cell>162</cell><cell>.536</cell><cell>.353</cell><cell>162</cell><cell>.536</cell></row><row><cell cols="2">ConvKB .396</cell><cell>257</cell><cell>.517</cell><cell>.243 ± .0 309 ± 2 .421 ± .0</cell><cell cols="6">.407 (+.164) (-63) (+.106) (-.113) (+64) (-.038) 246 .527 .130 373 .383</cell></row><row><cell>CapsE</cell><cell>.523</cell><cell>303</cell><cell>.593</cell><cell>.150 ± .0 403 ± 2 .356 ± .0</cell><cell cols="6">.511 (+.361) (-99) (+.229) (-.016) (+99) (-.059) 305 .586 .134 502 .297</cell></row><row><cell>KBAT</cell><cell cols="5">.518 † 210 † .626 † .157 ± .0 270 ± 0 .331 ± .0 .157</cell><cell>270</cell><cell>.331</cell><cell>.157</cell><cell>270</cell><cell>.331</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Effect of different evaluation protocols on recent KG embedding methods on FB15k-237 dataset. For TOP and BOTTOM, we report changes in performance with respect to RANDOM protocol. Please refer to Section 5.4 for details. †: KBAT has test data leakage in their original implementation, which is fixed in our experiments.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>MRR ↑ MR ↓ H@10 ↑ MRR ↑ MR ↓ H@10 ↑ MRR ↑ MR ↓ H@10 ↑ MRR ↑ MR ↓ H@10 ↑</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>RANDOM</cell><cell></cell><cell>TOP</cell><cell></cell><cell>BOTTOM</cell></row><row><cell>ConvE</cell><cell cols="2">.43 4187</cell><cell cols="3">.52 .444 ± .0 4950 ± 0 .503 ± .0 .444 4950</cell><cell>.503</cell><cell>.444</cell><cell>4950</cell><cell>.503</cell></row><row><cell>RotatE</cell><cell cols="5">.476 3340 .571 .473 ± .0 3343 ± 0 .571 ± .0 .473 3343</cell><cell>.571</cell><cell>.473</cell><cell>3343</cell><cell>.571</cell></row><row><cell cols="2">TuckER .470</cell><cell>-</cell><cell cols="3">.526 .461 ± .0 6324 ± 0 .516 ± .0 .461 6324</cell><cell>.516</cell><cell>.461</cell><cell>6324</cell><cell>.516</cell></row><row><cell cols="4">ConvKB .248 2554 .525 .249 ± .0 3433 ± 42 .524 ± .0</cell><cell cols="4">.251 1696 (+.002) (-1737) (+.005) (-.085) (+1735) (-.008) .529 .164 5168 .516</cell></row><row><cell cols="3">CapsE ‡ .415 719</cell><cell cols="2">.560 .415 ± .0 718 ± 0 .559 ± .0 .415</cell><cell>718</cell><cell>.559</cell><cell>.323 (-.092) (+1) (-.004) 719 .555</cell></row><row><cell>KBAT</cell><cell cols="5">.440 † 1940 † .581 † .412 ± .0 1921 ± 0 .554 ± .0 .412 1921</cell><cell>.554</cell><cell>.412</cell><cell>1921</cell><cell>.554</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Since we cannot find any open-source implementation of TransGate, we leave the re-evaluation of TransGate as our future work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">KBAT incorporates ConvKB in the last layer of its model architecture, which should be affected by different evaluation protocols. But we find another bug on the leakage of test triples during negative sampling in the reported model, which results in more significant performance degradation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Besides FB15k-237, we also evaluate the proposed protocols on WN18RR<ref type="bibr" target="#b3">(Dettmers et al., 2018)</ref> dataset, which is a subset of WN18<ref type="bibr" target="#b1">(Bordes et al., 2013)</ref> containing lexical relations between words. Similar to FB15k-237, inverse relations are removed in WN18RR. The results on WN18RR are shown inTable 3. From these results, we can draw similar conclusions as in Section 5. We also show the total number of triplets with the exact same score over the entire WN18RR dataset for Con-vKB, CapsE and ConvE inFigure 4.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the reviewers for their helpful comments. This work is supported in part by the National Science Foundation (NSF) under grant IIS-1546329 and Google PhD Fellowship.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>A Results on WN18RR dataset</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tucker: Tensor factorization for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balažević</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards understanding the geometry of knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Chandrahas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Talukdar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1012</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="122" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minervini</forename><surname>Pasquale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stenetorp</forename><surname>Pontus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1811" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2623330.2623623</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mitigating the effect of out-of-vocabulary entity pairs in matrix factorization for kb inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prachi</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4122" to="4129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prachi</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sushant</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00804</idno>
	</analytic>
	<monogr>
		<title level="m">Baseline strikes back (Again). arXiv e-prints</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledge base completion: Baselines strike back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bajgar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2609</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="69" to="74" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling relation paths for representation learning of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="705" to="714" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analogical inference for multi-relational embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Australia. PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2168" to="2178" />
		</imprint>
	</monogr>
	<note>Sydney</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning attention-based embeddings for relation prediction in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Nathani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jatin</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Kaul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Toward Understanding The Effect Of Loss function On Then Performance Of Knowledge Graph Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Nayyeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00519</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Hamed Shariat Yazdi, and Jens Lehmann</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A novel embedding model for knowledge base completion based on convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2053</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="327" to="333" />
		</imprint>
	</monogr>
	<note>Short Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Capsule Network-based Embedding Model for Knowledge Graph Completion and Search Personalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2180" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1955" to="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tensor factorization for multi-relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Volker Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="617" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06103</idno>
		<title level="m">Modeling relational data with graph convolutional networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>End-to-end structure-aware convolutional networks for knowledge base completion</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">DOLORES: deep contextualized knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1811.00147</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</title>
		<meeting>the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Transg : A generative model for knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1219</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2316" to="2325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>abs/1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Transgate: Knowledge graph embedding with shared gate structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neng</forename><surname>Jun Wen Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
