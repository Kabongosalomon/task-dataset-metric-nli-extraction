<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recurrent Rational Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Delfosse</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Schramowski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Molina</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
						</author>
						<title level="a" type="main">Recurrent Rational Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Latest insights from biology show that intelligence does not only emerge from the connections between the neurons, but that individual neurons shoulder more computational responsibility. Current Neural Network architecture design and search are biased on fixed activation functions. Using more advanced learnable activation functions provide Neural Networks with higher learning capacity. However, general guidance for building such networks is still missing. In this work, we first explain why rationals offer an optimal choice for activation functions. We then show that they are closed under residual connections, and inspired by recurrence for residual networks we derive a self-regularized version of Rationals: Recurrent Rationals. We demonstrate that (Recurrent) Rational Networks lead to high performance improvements on Image Classification and Deep Reinforcement Learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Neural Networks' efficiency in approximating any function has made them the most used approximation function for many machine learning tasks. They consist of successive layers, that topologically reshape the input space, transform and extract new features, that are then separately activated. Neuro-Scientists first explained that the brainpower resides in the combinations happening through trillions of connections. However, research has progressively shown that individual neurons are actually more capable than first thought, and latest results have shown that dendritic compartments can compute complex functions, (e.g. XOR), previously categorized as unsolvable by single-neuron systems <ref type="bibr" target="#b7">(Gidon et al., 2020)</ref>.</p><p>In current neural network design, most of the research is focusing on well-performing architectural patterns (Liu <ref type="figure">Figure 1</ref>. Recurrent Rational Network in its folded and unfolded forms. The input passed along the layers and recurrently in the rational function of the network. <ref type="bibr" target="#b37">Xie et al., 2019)</ref>, while keeping a fixed, predetermined activation function. Nevertheless, many different functions have been adopted across different domains (e.g. Leaky ReLU in YOLO <ref type="bibr" target="#b26">(Redmon et al., 2016)</ref>, GELU in GTP-3 <ref type="bibr">(Brown et al., 2020)</ref>, Tanh in PPO <ref type="bibr" target="#b28">(Schulman et al., 2017)</ref>). This indicates that the performance of neural networks jointly depends on the task, the architecture, hyper-parameters, the dataset (or environment), as well as the activation functions.</p><p>To reduce the bias introduced by a fixed activation function and achieve higher expressive power, one can use learnable activation functions. While Neural Architecture Search uses Reinforcement Learning or evolutionary algorithms on a preset family of activation functions to find performing patterns <ref type="bibr" target="#b16">Liu et al., 2018)</ref>, one can directly make use of gradient descent to optimize parametric activation functions. In this way, one can learn a linear combination of an arbitrary family of activation functions <ref type="bibr" target="#b19">(Manessi &amp; Rozza, 2018)</ref>, or use polynomial activation functions, where the polynomials' coefficients are considered as weights to be optimized <ref type="bibr" target="#b8">(Goyal et al., 2019)</ref>.</p><p>A finer approach consists in learning a rational function (i.e. a ratio of polynomials, see Eq 1). Rational functions and arXiv:2102.09407v1 <ref type="bibr">[cs.</ref>LG] 18 Feb 2021 polynomials can converge to any continuous function, but rational functions are better approximants than polynomials in terms of convergence <ref type="bibr" target="#b31">(Telgarsky, 2017)</ref>. Rational activation functions were first introduced as Padé Activation Units <ref type="bibr" target="#b22">(Molina et al., 2020)</ref>.</p><formula xml:id="formula_0">R(x) = P(x) Q(x) = m j=0 a j x j 1 + n k=1 b k x k</formula><p>(1) <ref type="bibr" target="#b22">Molina et al. (2020)</ref> have shown that Rational Units outperform other activation functions on several supervised learning tasks. However, neural networks embedding rationals tend to overfit and ways to regularize the rationals are required.</p><p>In this paper, we uncover important properties of rationals that explain their performance. We show that they can learn various features, carried by different handcrafted activation functions <ref type="bibr" target="#b3">(Clevert et al., 2016;</ref><ref type="bibr" target="#b5">Elfwing et al., 2018;</ref><ref type="bibr" target="#b24">Ramachandran et al., 2017;</ref><ref type="bibr" target="#b20">Misra, 2020;</ref><ref type="bibr" target="#b6">Georgescu et al., 2020)</ref>. In addition, we demonstrate that, if properly constructed, they can express similar behavior to residual blocks, as they are closed under residual connection. Therefore, we use rational functions to replace residual blocks in a residual neural network and show that the performance is maintained or even increased, while the number of parameters decreases. Furthermore, inspired by weight sharing for Residual Networks, we introduce Recurrent Rational Networks, whose recurrence acts as a natural regularizer. We evaluate Rational and Recurrent Rational both on supervised learning tasks and Reinforcement Learning. Our empirical evidence 1 demonstrates that (recurrent) rational functions dominate domain. We used five different seeds for networks and (potentially environment) initialization. For all the details and hyper parameters of our experiments, refer to the appendix.</p><p>Our source code 2 to reproduce our experimental evaluation and our Rational Network library 3 are publicly available.</p><p>Contributions. We make the following contributions:</p><p>• We investigate the performance gains and analyze important properties of Rational Units, e.g. the natural embedding of residual connections. We proceed as follows. We start by describing the role of activation in Neural Networks. Then, we analyze the properties of rational activation functions, notably showing that they can incorporate residual blocks. Inspired by recurrence for residual networks, we introduce Recurrent Rational Networks. We demonstrate that these self-regularized networks improve generalization performances on supervised learning classification. We then evaluate on Reinforcement Learning tasks, and show Rational Networks outperforms every non-learnable baselines and our Recurrent version dominate. Before concluding, we discuss best practices and outlooks for these emerging Rational Network types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">On the Role of Activation Functions</head><p>Let us start by investigating the role of activation functions in (deep) neural networks.</p><p>Activation Functions Perform Internal Space Transformations. Contrary to the rest of the layer, activation functions separately act on every dimension of the input, i.e. they perform elementwise operations. They can be compared to the brains' dendrites that perform scalar transformations on the signal they propagate, further merged into the neuron body <ref type="bibr" target="#b14">(Li et al., 2020)</ref>. The transformation operated by the activation function cannot extract new feature spaces by recombining the inputs, as convolutions do, but only stretch, compress and cut the space. We refer to these transformations as internal transformations, and to the ones performed by layers (without their activation functions) as external ones. Different types of internal transformations exist: <ref type="bibr" target="#b23">Naitzat et al. (2020)</ref> showed that ReLU and its variants not only help to tackle the vanishing gradient problem but allow non-homeomorphic topological transformations. In contrast, Sigmoid or Tanh can only perform homeomorphic ones. In other terms, ReLU can fold its input space, sending the whole negative to one point, whereas Sigmoid and Tanh continuously squish it.</p><p>Diversity Inside the Network. Dendrites do not share identical behavior inside the biological brain <ref type="bibr" target="#b30">(Tavosanis, 2012)</ref>. However, most common neural network architectures use a fixed function across the network during learning. Some architectures use a cell that contains different activation functions, as LSTMs <ref type="bibr">(Greff et al., 2015)</ref>, or in Networks discovered by Neural Architecture Search <ref type="bibr" target="#b16">(Liu et al., 2018)</ref>. Providing each layer with the ability to refine the activation function for its specific need leads to higher modeling capacity. In Rational Networks, we thus place different rational functions at each layer, as done in <ref type="bibr" target="#b22">(Molina et al., 2020)</ref>.</p><p>Rationals Embed Desired Properties. Researchers have often searched for a golden activation function. A combination of exhaustive and reinforcement learning-based search led to SiLU/Swish <ref type="bibr" target="#b24">(Ramachandran et al., 2017)</ref>, later refined with Mish by <ref type="bibr" target="#b20">Misra et al. (2020)</ref>, who showed common properties of well-performing functions such as bounded negative domains and non-monotonic shapes. This properties are learned by some of our trained Rationals (cf. <ref type="figure" target="#fig_0">Fig. 2  right)</ref>. Inspired by the biological results described above, ADA, particularly suited for performing XOR operation, was recently introduced <ref type="bibr" target="#b6">(Georgescu et al., 2020)</ref>. This complex operation is feasible because of the spike (high nonmonocity) of ADA. We, here again, observe this property learned by a trained Rational Unit. (cf. <ref type="figure" target="#fig_0">Fig. 2 left)</ref>. <ref type="bibr" target="#b35">Veit et al. (2016)</ref> have exhibited Residual Networks (ResNet) ability to tackle the Vanishing Gradient Problem. However, they were first introduced following the idea that, for very deep networks, it is easier to start learning from an identity layer and deviate from it, rather than trying to converge to it if necessary <ref type="bibr" target="#b12">(He et al., 2016)</ref>. ResNets propagate an input x through two paths: a transforming block of layers that preserve dimensionality (F ) and a residual connection (identity). The output y of such a block satisfies Eq 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Rationals to Replace Residual Blocks</head><formula xml:id="formula_1">y(x) = F (x) + x<label>(2)</label></formula><p>Rational functions can also follow this precept. They can be initialized as the identity function, by having a j = 1 j=1 and b k = 0 for all j, k in Eq 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rationals are Closed Under Residual Connections.</head><p>Moreover, adding a residual connection to a Rational Unit R(x) gives:</p><formula xml:id="formula_2">R(x) + x = m j=0 a j x j n k=0 b k x k + x = m j=0 a j x j + n k=0 b k x k+1 n k=0 b k x k (3) = M j=0 c j x j n k=0 b k x k = R ' (x) , where: M = max(m, n + 1) , ∀j ∈ {0, . . . , M }, c j = a j + b j−1 , ∀j / ∈ {0, . . . , m}, a j = 0 , and ∀k / ∈ {0, . . . , n}, b k = 0 .</formula><p>This shows that rationals (with m &gt; n) embed residual connections, and as rationals are also closed under compositions, successive (residual) rationals can be embedded into a single rational function. Hence, in order to provide Rational Units with residual connections, one should select a numerator with a higher order than the denominator.</p><p>ResNets Need Internal Space Transformations. However, ResNet blocks differ from rationals as they act on multi-dimensional input space. Whereas the rational acts on every dimension separately, they perform internal transformations.</p><p>For very deep ResNet, <ref type="bibr" target="#b11">Greff et al. (2017)</ref> showed that Residual blocks are unrolled iterative estimation that refines upon their input representation. They show that feature recombination does not occur inside the blocks, which thus perform only internal transformations. These transitions to new levels of representations (external transformations) occur during dimensionality change. This view explains why lesioning and shuffling do not affect ResNet performances significantly, and is also compatible with the findings obtained by <ref type="bibr" target="#b22">Molina et al. (2020)</ref>, in pruned ResNets. We hypothesize that the Residual Networks mentioned in these papers could benefit more from internal transformations than from the external ones that these blocks can provide.</p><p>To test this hypothesis, we conduct lesioning experiments on a pretrained ResNet101, on which we either remove the residual block (as in <ref type="bibr" target="#b35">(Veit et al., 2016)</ref>), or we replace it with a Rational units. We finetune the surrounding blocks and in our case the identity-initialized rational. Using Rational Units lead to performance improvements, even above the original model (cf. Tab. 1). We are here mainly interested in the train loss, as it shows how effectively the model can learn. Nevertheless, the test accuracy is also provided.</p><p>These findings empirically show that Residual Networks (ResNets) with rational activation functions are less affected Nonetheless, retraining with rationals on pretrained network, whose architecture and weights have been optimized along with identity blocks might have led the architecture to a local optimum. Using rationals from the beginning might lead to a different optimum, and would require more investigations.</p><p>Additionally, <ref type="bibr" target="#b18">Lu et al. (2018)</ref> have bridged the gap between Numerical Differential Equations and Residual Networks. Binding together Rational Units with the latter thus implicitly connect rational functions to Linear Sytems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Recurrent Rational Networks</head><p>In the previous section, we bridged the gap between rationals and Residual Networks. Continuing along these lines, <ref type="bibr" target="#b11">Greff et al. (2017)</ref> further indicate that sharing the weights in blocks can improve learning performances, as shown for Highway <ref type="bibr" target="#b17">(Lu &amp; Renals, 2016)</ref>  shallow Recurrent Neural Networks with weight sharing among the layer. Inspired by this findings, we introduce Recurrent Rational Networks (RRN), a novel type a Recurrent Network where weights are shared between rationals. In this type of Networks, the input is propagated through different layers, but always passed in the same rational activation function.</p><p>Moreover, <ref type="bibr" target="#b22">Molina et al. (2020)</ref> showed that rational tend to overfit and suggested to further investigate regularization for Rationals. We advocate that recurrence can act as a natural regularizer for rationals. We test this hypothesis by comparing Rational Networks and Recurrent Rational Networks to a baseline in Tab. 2 and later on Reinforcement Learning Tasks (cf. Section 5). Our empirical results also indicate that recurrence helps regularize on CIFAR100.</p><p>Localized Recurrence. <ref type="bibr" target="#b15">Liao et al. (2016)</ref> also investigate where weight sharing could be the most beneficial for the network. They show that for visual tasks, recurrent computations are more beneficial in early visual areas than at middle and later stages, and as explained in their conclusion, these findings later found psychophysics support <ref type="bibr" target="#b4">(Eberhardt et al., 2016)</ref>. We thus evaluate networks different recurrence localizations, and report the results in Tab. 3 (and Tab. ?? in the appendix). Our findings partially confirm these hypotheses, as the best performing networks are the one sharing weights in the two early and the two last layers. Localized recurrence is thus a good balance between modeling power of the network and regularization.</p><p>For bigger networks, testing every possible localized recurrence combination is resource intensive, as the number of network architectures to test grows exponentially (2 n−1 different networks for n activation functions). Therefore, having a way to automatically detect which layer need weight sharing would considerably reduce computations. In <ref type="figure">Fig. 3</ref>, we plot the shapes of the learned activation functions and note that the first two functions have similar profiles as well  <ref type="figure">Figure 3</ref>. Learned rational functions confirm biological intuition that weight sharing in early layers is beneficial. Shown are the profiles of rational functions learned at each layer (increasing layers from left to right) of a simple convolutional network on CIFAR10. As one can see, similar profiles are learned in the early resp. late layers. The input distributions, as well as the neural distance between each function are reported on the graph, and confirms the intuition.</p><p>as the last two functions. However, we here want to quantify objectively the similarity, or the distance, between profiles of functions.</p><p>Neurally equivalent activation functions. We first concentrate on equivalence between neural networks, to derive properties of a suited metric. Research on neural network equivalence is usually interested in changing the shape of the neural network, especially reducing its amount of parameters (Al-Rawi &amp; Al-Rawi, 2010; <ref type="bibr" target="#b13">Kumar et al., 2019)</ref>. Two networks are defined to be equivalent if they produce the same output for any given input. In this work, we focus on equivalence between neural networks that differ only in their activation functions. The neural networks we consider are equipped with linear layers such as convolutional or fully connected ones. To provide some intuition, we first point out that such neural networks, at any given layer, dividing the activation function by a constant and multiplying the weights of the next layer by this constant produces an equivalent neural network. Any learned activation function is thus scale independent (for vertical scaling). Such transformations can be applied to the bias with addition on the activation function. Formally, we consider f 1 and f 2 two functions such that:</p><formula xml:id="formula_3">∀x, f 1 (x) = a.f 2 (c.x + d) + b ,</formula><p>we derive:</p><formula xml:id="formula_4">W i f 1 (W i−1 x + B i−1 ) + B i = a.W i f 2 (c.W i−1 x + (c.B i−1 + d)) + (B i + b) = W i f 1 (W i−1 x + B i−1 ) + B i ,</formula><p>Thus, replacing f 1 by f 2 at a given layer of a neural network and changing the weights and bias of this layer or the next one produces an equivalent neural network.</p><p>Equivalence between activation is scale and shift independent. Considering this, we introduce a new metric between two functions f 1 and f 2 in Equation 4, that is shift With this definition, ND is actually a quasi-pseudo-metric, as it does not respect the symmetry and the positive definiteness. We can easily turn it into a pseudo-metric by taking the minimum between ND(f 1 , f 2 ) and ND(f 2 , f 1 ) as the new metric, thus solving the symmetry. However, the positive definite property (i.e. ND(f 1 , f 2 ) = 0 ⇒ f 1 = f 2 ) is not verified on purpose, as this is used as neural equivalence property. We provide the distance measured between the rational functions learned at each layer in the <ref type="figure">Fig. 3</ref>. The two smallest distances correspond to the pairs of functions with similar profiles, and confirm that merging those functions is an optimal choice, as it is a good balance between regularization and modeling capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Boosting DQN using Recurrent RNs</head><p>As mentioned in the introduction, different activation functions are often used for different tasks. Earlier work has shown that Rationals are suited for supervised learning classification <ref type="bibr" target="#b22">(Molina et al., 2020)</ref> and image generation <ref type="bibr">(Boullé et al., 2020)</ref>. In this section, we would like to extend the use of Rational Networks to Deep Reinforcement Learning.</p><p>Deep Reinforcement Learning requires additional constraints on the network, as the policy influences the input and output distributions, and it has often be shown that unstable policies could lead to a drop in performance <ref type="bibr" target="#b27">(Schulman et al., 2015;</ref><ref type="bibr" target="#b31">2017)</ref>. Therefore, plugging rational networks in a Reinforcement Learning agent might lead to instabilities. In this section, we demonstrate that rational networks indeed enhance the performance of the original DQN agent. We also evaluate the self-regularized Recurrent Rational version, that helps to prevent potential instabilities introduced by the higher modeling capacity of Rational Networks. Here the scores are normalized according to Eq 5. score normalized = 100 × score agent − score random score baseline − score random 4 .</p><p>(5)  <ref type="figure" target="#fig_1">Fig. 4</ref>).</p><p>Comparison to Swish/SiLU. The SiLU activation function (SiLU(x) = x · sigmoid(x)) and its derivative dSiLU were introduced by <ref type="bibr" target="#b5">Elfwing et al. (2018)</ref>. The authors showed that using SiLU or a combination of SiLU (on convolutional layers) and its derivative dSiLU (on fully connected layers) in DQN agents perform better on several games than ReLU networks. Swish, a refined version of SiLU was later discovered via Reinforcement Learning based automatic search in <ref type="bibr" target="#b25">(Ramachandran et al., 2018)</ref>   with SiLU were only able to outperform Rational Networks on one game out of 15 (Kangaroo), whereas Recurrent Rational Networks achieve better performance than every nonlearnable activation function for every game, doubling the score of the runner up, which is the Rational Network, on Space Invaders.</p><p>Rational Flexibility to Solve Overestimation. A known problem of the DQN algorithm is overestimation. Overestimation is due to the combination Bootstrapping, Off-policy learning and a function approximator (Neural Network) operated by DQN. To solve this problem, <ref type="bibr" target="#b33">Van et al. (2016)</ref> introduced DDQN, that uses an addition network to separate action selection and action evaluation.</p><p>Q-learning overestimation was initially investigated in <ref type="bibr" target="#b32">(Thrun &amp; Schwartz, 1993)</ref> and notably attributed to insufficiently flexibility in the function approximation, that lacks accuracy. Learnable rational functions provide additional flexibility and accuracy while adding a minimal number of parameters to the network, that might help tackle the overestimation problem. To verify this hypothesis, we compare the performance of our DQN agent equipped with (Recurrent) Rational Networks to a standard DDQN agent in Tab. 5.  DDQN only delays performance drops. As our (Recurrent) Rational DQN agents continue learning for longer than 200 epochs on several games (cf. Asterix on <ref type="figure" target="#fig_2">Fig. 5</ref>, we let our agent train for 500 epochs. This shows that for several games (Breakout, JamesBond, Kangaroo, Seaquest, TimePilot), DDQNs do not solve performance drops, but only delay them, sometimes lowering its performance below DQNs. A complete graph, with the performance evolution of every tested agent on every game is provided in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Rationals: Beyond Existing Activations</head><p>Accross our rational journey, we found several best practices that we discuss in this section.</p><p>Importance of Tracking the Input. Properties of different new activation functions <ref type="bibr" target="#b6">(Georgescu et al., 2020;</ref><ref type="bibr" target="#b20">Misra, 2020)</ref> were reported as crucial for neural networks performances. To verify this hypothesis, the input distribution of the function should be taken into consideration, as the network can make use of the different parts of the activation function's domain. This is particularly relevant for highly learnable functions such as rational functions. Therefore, in every activation function graph provided in this work, we also provided the input distribution. An efficient and direct way of tracking the distribution is provided in our rational framework.</p><p>Refining the Neural Equivalence Metric. Continuing along these lines, we present in Equation 6 a refined version of our neural distance that takes into account the input distribution ρ.</p><formula xml:id="formula_5">rND(f 1 , f 2 ) = min a,b,c,d ρ(x)|f 1 (x)−af 2 (c.x+d)+b| dx .<label>(6)</label></formula><p>This new neural distance gives more importance to parts that are more used. One could also use explainability techniques <ref type="bibr" target="#b36">(Wang et al., 2019;</ref><ref type="bibr">Shao et al., 2021)</ref> to track the importance across the input of the rational function.</p><p>Embedding Different Function. In <ref type="figure" target="#fig_3">Fig. 6</ref> we provide the learned Rational and Recurrent Rational functions for trained networks on several games. We observe that several learned profiles are similar to the dSiLU one (notably Recurrent Rationals), and that every activation function is nonmonotonous (as the one of supervised learning experiments, cf. <ref type="figure">Fig. 3</ref>), experimentally confirming that non-monotonicity helps the learning process <ref type="bibr" target="#b20">(Misra, 2020)</ref>. Furthermore, if we look at the inputs of those functions, we see that they follow Gaussian distributions. For some of them (Asterix, Kangaroo, Space Invaders, Tutankham), multimodality appears in the distribution along learning. This lead us to think that the input distribution is split during training, and that the rational learns several functions, one next to the other for these different input groups. If these modes are produced by different neurons of the layer, this means that several neuron groups need different activation functions, and that the network could benefit from having several rational activation functions across one layer. Detecting this need by tracking the input distribution during learning could lead to performance improvements.</p><p>The need for a new batch normalization. Consequently, using batch normalization prevents this behavior, as at every layer, the input distribution is normalized. Future work might benefit from a batch normalization that would not prevent input distribution split.</p><p>Rationals' Automatic Scaling. Another interesting property of both recurrent rationals and rationals on Reinforcement Learning is that for all of them, the size of the codomain is lower than one, besides their long domain range. While the supervised learning experiments consist in classifying, DQN requires a precise regression for the Q-value estimation. This enforces the network to accurately estimate the expected return of the current policy. We hypothesize that this automatic vertical scaling mainly observed for reinforcement learning (cf. <ref type="figure" target="#fig_3">Fig. 6 vs Fig. 3)</ref> helps the network to accurately predict the Q-Value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we provided several explanations on the role of activation functions and shed some light on the reasons why rational functions are so efficient notably with their implicit residual connection embedding. Importantly, we introduced Recurrent Rational Networks, whose nature selfregularizing behavior allow to improve generalization performances, solving the biggest flaw of Rational Networks. For the first time, the evaluation of learnable rational activations was brought to Deep Reinforcement Learning, exhibiting drastic performance improvements. Importantly, we show that Recurrent Rational Networks further increase the performance of DQN agents. Alongside releasing an efficient library for building Rational and Recurrent Rational Networks, we discussed several best practices for their use, such as tracking the input distribution and similarity of the functions across a Rational Network for automatic merging.</p><p>Our work provides several interesting avenues for future work.    Here we present the evolution of the scores of different agents. Rational and Recurrent Rational DQN agents are always the best-performing ones. Experiments on several games (e.g. Jamesbond, Seaquest) show that using DDQN does not prevent the agent's performance drop but only delays this. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Rational Units (Rat.) discover biologically relevant operations automatically. Rational Unit from trained DQN Agents on Time Pilot compared to ADA<ref type="bibr" target="#b6">(Georgescu et al., 2020)</ref>, which like biological neurons can perform XOR, and Recurrent one on Tuthankham to dSiLU, with bounded negative domains and nonmonotonic shape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Rational and Recurrent Rational Networks lead to superhuman performance. DQN agents equipped with the Leaky ReLU baseline (LReLU), Rational Networks (RN) and Recurrent Rational Networks (RRN). The asterisk (*) is highlighting games for which RN/RRN performs better than human baseline, whereas baseline does not (67%). and scale -both vertical and horizontal-independent. ND(f 1 , f 2 ) = min a,b,c,d |f 1 (x)−(af 2 (c.x+d)+b)| dx (4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>DDQN delays performance drop instead of solving it. Evolution of the scores of DQN agents with Rational Networks (RN) and Recurrent RN (RRN) and DQN and DDQN with LReLU. The line corresponds to the mean score of every agent and the shaded area to the std. dev. of five executed runs. A figure including the evolution on every game is provided in the appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Learned rational activation functions of Reinforcement Learning Agents automatically reduced their co-domains. Several input distribution has converged to multimodal Gaussians (e.g. Asterix, Space Invaders and Tutankham). (Left) activation functions at the successive layers in Rational Networks. As for supervised learning, several desired properties (as nonmoncity and bounded negative domains are also learned by these parametric functions). (Right) Common activation function of every layer in a Recurrent Rational Network. A Figure with parametric functions for every games is provided in the appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>left: Rational Network with Rational Activation Functions (Rat.). Any other network with classical activation functions (as Leaky Relu or SiLU) would be similar, with the corresponding activation function instead of the Rational one. right: Recurrent Rational Network. In the Recurrent Rational Network, the same activation is used at different layers. The parameters of the rational activation function are shared. Operations are in grey and parameters in blue. Profiles of Rationals (left) and Recurrent Rationals (right) on different games. Every function from the recurrent agents seems to converge to pretty similar functions. The codomain of most of these functions has been reduced.Additionally, hereafter are the profiles of the functions learned by Rational and Recurrent Rational Networks after convergence on MNIST and Fashion MNIST with VGG-8 Network, as well as scores for VGG-8 and Lenet networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Profiles of Rational and Recurrent Rational VGG-8 MNIST and Fashion MNIST after convergence. The learned functions in layers 3 and 4 for MNIST and Fashion MNIST are very close, suggesting that parameters could be shared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Evolution of the scores on every tested game for Rational and Recurrent Rational DQN agents, and original DQN agents with Leaky ReLU, SiLU+dSiLU, and SiLU as well as for a DDQN agent with Leaky ReLU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Eval Lesion L2.B3 L3.B13 L3.B19 L4.B2 train Std. (Veit et al.) 100.9 120.2 90.5 58.9 Rat. (our) 101.1 120.3 104.0 91.1 test Std. (Veit et al.) 93.1 102.0 97.1 Table 1. Rational functions improve lesioning. Recovery percentage for retrained networks after lesioning (Veit et al., 2016) of a ResNet layer's (L) block (B). Residual blocks were lesioned, i.e. replaced, with a Identity (Std.) or a Rational (Rat.) from a pretrained ResNet101 (44M parameters). Then, the surrounding blocks (and implanted Rational Activation) are retrained for 15 epochs. The best results are highlighted bold. ± .0 99.8 ± .0• 99.8 ± .0• Test 56.6 ± .4 57.7 ± .3• 60.0 ± .2• Recurrence helps the network to regularize and thus improves the performances on the test set. Train and test accuracies (with std. dev.) for different architectures trained with Leaky ReLU (baseline), Rational and Recurrent Rational Networks. The best results are highlighted bold and results outperforming the LReLU baseline with • markers.when compressing the neural network, i.e. that internal transformations performed by rationals compensate for the dropped neural connections.</figDesc><table><row><cell cols="2">Rat. (our)</cell><cell cols="3">90.5 102.6 97.6</cell><cell>81.7 85.3</cell></row><row><cell cols="4">% dropped params 0.63 2.51</cell><cell>2.51</cell><cell>10.0</cell></row><row><cell cols="2">Network</cell><cell>LReLU</cell><cell>RN</cell><cell>RRN</cell></row><row><cell>VGG8 VGG11</cell><cell cols="4">Train 98.7 ± .0 99.5 ± .0• 99.2 ± .0• Test 61.7 ± .0 61.3 ± .3 64.0 ± .1• Train 99.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Train 74.3±.4 76.6±.6 75.1±.5 75.9±1. Test 74.9±.6 76.7±.5 74.9±.4 75.7±.0 100 Train 40.7±1. 43.5±.8 43.7±1. 44.4±.0 Test 40.4±.3 42.5±.4 42.3±.0 42.1±.9 Recurrence in early stages leads to the best performances. Mean accuracies with std. dev. are provided. The evaluation is conducted on a simple Convolutional Neural Network on CIFAR10 (10) and CIFAR100(100)for Recurrent Rational Networks and networks where recurrence is shared for two successive layers. For local recurrent networks, best train accuracy (for 10) and test accuracies are obtained when weights are shared at the first two layers, best train accuracy (for 100) for recurrence in the last layers. The best results are highlighted bold.</figDesc><table><row><cell>2016) Networks.</cell><cell>and Residual (Liao &amp; Poggio,</cell></row></table><note>Recurrent Rational Networks. Liao et al. (2016) link Residual Learning, Recurrent Neural Networks and Visual Cortex. They first show that very deep ResNets approximate</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Rational Networks leading to dramatic performance improvement. Normalized mean scores (cf. Eq 5 in percentage with LReLU as baseline), averaged over 5 reruns, of DQN agents equipped with Recurrent Rational and Rational Networks, and with SiLU and SiLU + dSiLU. The best results are highlighted bold and runner-up with • markers. The last row summarizes the number of improvements over the Leaky ReLU baseline.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 .</head><label>5</label><figDesc>DQN equipped with Recurrent Rational and Rational Networks always outperform the more complex DDQN algorithm, equipped with the baseline. Mean raw scores (averaged over 5 reruns) are provided. DDQN agents are equipped with Leaky ReLU (LReLU). The DQN baseline is also provided. The best results are highlighted bold and runner-up with • markers. The last row summarizes the total wins.</figDesc><table><row><cell>Our result show that for every tested game, indeed both Rational and Recurrent Rational DQN agents outperform the DDQNs equipped with the baseline activation.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Rat. R.Rat. R.Rat. R.Rat. Rat. Rat. Rat.</head><label></label><figDesc>To implement Rational Networks, rational functions have so far been inserted in existing neural networks architectures. To investigate this further, one should incorporate Rational Networks into other architectures, e.g. Transformers<ref type="bibr" target="#b34">(Vaswani et al., 2017)</ref>, and evaluate them on different tasks. Most interesting is the incorporation of Rational Networks into Neural Architecture Search<ref type="bibr" target="#b16">(Liu et al., 2018)</ref> to discover new efficient Rational Network Architectures. Finally, rich insight could be gained from the Linear System field<ref type="bibr" target="#b18">(Lu et al., 2018)</ref>, linked with rationals through residual connections in this work.Here are presented two different neural networks used in our RL experiments, with their parameters. The graphs are generated using a modified version of pytorchviz 1 . Rational activations are available on github. 2</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Technical Appendix</cell></row><row><cell cols="5">A. Additional resources</cell><cell></cell></row><row><cell cols="6">A.1 Neural Network visualisation</cell></row><row><cell></cell><cell></cell><cell>(32)</cell><cell cols="2">(32, 4, 8, 8)</cell><cell></cell><cell>(32)</cell><cell>(32, 4, 8, 8)</cell></row><row><cell></cell><cell></cell><cell>View</cell><cell cols="2">Convolution</cell><cell></cell><cell>View</cell><cell>Convolution</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Add</cell><cell>(6)</cell><cell>(4)</cell><cell>(6)</cell><cell>Add</cell><cell>(4)</cell></row><row><cell></cell><cell>(64)</cell><cell cols="2">(64, 32, 4, 4)</cell><cell>PAU</cell><cell></cell><cell>PAU</cell><cell>(64, 32, 4, 4)</cell><cell>(64)</cell></row><row><cell cols="2">View</cell><cell cols="2">Convolution</cell><cell></cell><cell></cell><cell>Convolution</cell><cell>View</cell></row><row><cell></cell><cell></cell><cell>Add</cell><cell>(6)</cell><cell>(4)</cell><cell></cell><cell>Add</cell></row><row><cell>(64)</cell><cell cols="2">(64, 64, 3, 3)</cell><cell>PAU</cell><cell></cell><cell></cell><cell>(64, 64, 3, 3)</cell><cell>PAU R.Rat.</cell><cell>(64)</cell></row><row><cell>View</cell><cell cols="2">Convolution</cell><cell></cell><cell></cell><cell></cell><cell>Convolution</cell><cell>View</cell></row><row><cell cols="2">Add</cell><cell>(6)</cell><cell>(4)</cell><cell></cell><cell></cell><cell>Add</cell></row><row><cell></cell><cell></cell><cell>PAU</cell><cell cols="2">(512, 3136)</cell><cell></cell><cell>(512, 3136)</cell><cell>PAU</cell></row><row><cell cols="2">(512)</cell><cell>View</cell><cell cols="2">Mult</cell><cell></cell><cell>(512)</cell><cell>Mult</cell><cell>View</cell></row><row><cell>(6)</cell><cell></cell><cell>Addmm</cell><cell>(4)</cell><cell>(6, 512)</cell><cell></cell><cell>Addmm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(6, 512)</cell></row><row><cell></cell><cell></cell><cell>PAU</cell><cell>(6)</cell><cell>Mult</cell><cell></cell><cell>Mult</cell><cell>PAU</cell><cell>(6)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Addmm</cell><cell></cell><cell></cell><cell>Addmm</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Loss</cell><cell></cell><cell></cell><cell>Loss</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>± 0.05 99.38 ± 0.04 99.47 ± 0.02 99.05 ± 0.06 99.09 ± 0.06 99.15 ± 0.04 fmnist 89.22 ± 0.39 91.53 ± 0.21 92.29 ± 0.1 87.76 ± 0.2 89.52 ± 0.62 89.32 ± 0.2 Table 7: Means accuracies and std. dev. of Rational (RN), Recurrent Rationals (RRN) VGG-8 and LeNet Networks, as well as their baseline (LReLU).</figDesc><table><row><cell>Network mnist</cell><cell>LReLU 99.23</cell><cell>VGG RN</cell><cell>RRN</cell><cell>LReLU</cell><cell>LeNet RN</cell><cell>RRN</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/szagoruyko/pytorchviz 2 https://github.com/ml-research/rational_activations</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/ml-research/rational_sl 4 https://github.com/ml-research/rational_rl 5 pytorch.org/vision/0.8/_modules/torchvision/models/resnet.html#resnet101</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Here are given all the mean final scores obtained by the Rational and Recurrent Rational DQN Agent and original DQN ones (with Leaky ReLU, SiLU, d+SiLU), a DDQN (Leaky ReLU) agent, and the Random agents we used in our experiments with their standard deviations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Learnt activation functions</head><p>This section first provides the learned parametric rational functions from rational agents (left) and the Recurrent Rational Agents (right) after convergence for every different tested game of the gym Atari 2600 environment. Histograms of the input distributions (in grey) display the parts used in each function.    <ref type="formula">(100 )</ref>. Comparison between a rational network (RN), with no recurrence, recurrent rational network (RRN), and every combination. For the other networks, rX represent recurrent rationals shared for X successive layer. For example, r3r2 represents a rational network where the first three layers share one recurrent rational activation function, and the last two layers share another one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments details</head><p>Every conducted experiment can be reproduced with the default parameters of the different repositories provided 3,4 . Every random experiment was (re-)launched with (at least) 5 seeds (from 0 to 4). For every experiment conducted in this paper, we use Rationals and Recurrent Rationals with polynomials of degrees m = 5 and n = 4 (m &gt; n). Leaky ReLU (LReLU) is the closest classical activation function to the identity function, and preliminary experiments CIFAR10 and breakout have shown that DQN agents with Leaky ReLU networks outperform ReLU ones. Therefore, we initialized our (Recurrent) Rational functions to be approximating the Leaky ReLU function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Supervised Learning</head><p>Lesioning on Residual Networks: For lesioning, we take a ResNet101 5 and replace a specific block with an identity function (for lesioning) or with a Rational Activation Function and retrain the previous and successive block (and potentially the Rational function) for 15 epochs with batches of size 128. We use SGD optimizer with learning rate of 0.001, momentum of 0.9. F/MNIST: We train on MNIST and FMNIST for 100 epochs, using a SGD optimizer with a learning rate of 0.01 and momentum of 0.5. The batch size is 64. Weights are initialized using Xavier normal method. CIFAR10/100: Networks are trained on CIFAR10/100 for 60 epochs. We use SGD, with a learning rate of 0.02, momentum of 0.9, and weight decay of 5e −4 . Weights are initialized using Xavier normal method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Reinforcement Learning</head><p>The convolutional network used in the RL experiments is exactly the one proposed in the Original DQN paper and reused in the DDQN paper (cf. A.1 Neural Network visualisation). Instead of RMSprop, we use Adam optimizer as it corresponds to a more efficient version of the optimization algorithm with a learning rate of 0.00025, and we use a smooth l1 loss. We use 32 as batch size.</p><p>For every game, we used the same hyperparameters across the agents. In details, we use an evaluation frequency of 250000, a target update frequency of 10000, an initial replay size 50000, a max replay size of 500000 and a test samples of 125000. We use the Deterministic-v4 version of every tested game. For training, epsilon linearly goes from 1.0 to 0.1 in 1000000 steps and for testing, the epsilon value is set to 0.05. We let every agent run for 100 epochs on Pong, 200 on VideoPinball and Skiing, and 500 on all the other games.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the equivalence between ordinary neural networks and higher order neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Al-Rawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Al-Rawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Higher Order Neural Networks for Computer Science and Engineering: Trends for Emerging Applications</title>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="138" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rational neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boullé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nakatsukasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Townsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems (NeurIPS)</title>
		<editor>Lin, H.</editor>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amodei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems (NeurIPS)</title>
		<editor>Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.</editor>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations (ICLR)</title>
		<editor>Bengio, Y. and LeCun, Y.</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">How deep is the feature analysis underlying rapid visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Cader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems (NeurIPS)</title>
		<editor>Lee, D. D., Sugiyama, M., von Luxburg, U., Guyon, I., and Garnett, R.</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1100" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sigmoid-weighted linear units for neural network function approximation in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elfwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Uchibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="3" to="11" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Non-linear neurons with human-like apical dendrite activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-I</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-C</forename><surname>Ristea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dendritic action potentials and computation in human layer 2/3 cortical neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Zolnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fidzinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bolduan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papoutsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Holtkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Larkum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="issue">6473</biblScope>
			<biblScope unit="page" from="83" to="87" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning activation functions: A new paradigm of understanding neural networks. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">LSTM: A search space odyssey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1503.04069</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Highway and residual networks learn unrolled iterative estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Equivalent and approximate transformations of deep neural networks. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Powerefficient neural network with artificial dendrites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Nanotechnology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="776" to="782" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bridging the gaps between residual learning, recurrent neural networks and visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Poggio</surname></persName>
		</author>
		<idno>abs/1604.03640</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2018 -15th European Conference</title>
		<editor>Ferrari, V., Hebert, M., Sminchisescu, C., and Weiss, Y.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">11205</biblScope>
			<biblScope unit="page" from="19" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Small-footprint deep neural networks with highway connections for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Annual Conference of the International Speech Communication Association (INTERSPEECH)</title>
		<editor>Morgan, N.</editor>
		<imprint>
			<publisher>ISCA</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="12" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3282" to="3291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning combinations of activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Manessi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A self regularized non-monotonic activation function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st British Machine Vision Conference 2020 (BMVC)</title>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Padé activation units: End-to-end learning of flexible activation functions in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schramowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Topology of deep neural networks. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Naitzat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhitnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Searching for activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1710.05941</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Searching for activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Trust region policy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML)</title>
		<editor>Bach, F. R. and Blei, D. M.</editor>
		<meeting>the 32nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<publisher>JMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1889" to="1897" />
		</imprint>
	</monogr>
	<note>of JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno>abs/1707.06347</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Right for better reasons: Training differentiable models by constraining their influence function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Skryagin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schramowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Stammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dendritic structural plasticity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tavosanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental neurobiology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="86" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neural networks and rational functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<editor>Precup, D. and Teh, Y. W.</editor>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3387" to="3393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Issues in using function approximation for reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1993 Connectionist Models</title>
		<meeting>the 1993 Connectionist Models<address><addrLine>Summer School Hillsdale, NJ. Lawrence Erlbaum</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with double q-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth Conference on Artificial Intelligence (AAAI)</title>
		<editor>Schuurmans, D. and Wellman, M. P.</editor>
		<meeting>the Thirtieth Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2094" to="2100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>R.</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Residual networks behave like ensembles of relatively shallow networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wilber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems (NeurIPS)</title>
		<editor>Lee, D. D., Sugiyama, M., von Luxburg, U., Guyon, I., and Garnett, R.</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="550" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Score-cam: Improved visual explanations via score-weighted class activation mapping. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR). OpenReview.net</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
