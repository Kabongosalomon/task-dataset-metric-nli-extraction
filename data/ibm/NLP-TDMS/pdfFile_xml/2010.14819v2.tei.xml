<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Model Rubik&apos;s Cube: Twisting Resolution, Depth and Width for TinyNets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">State Key Lab of Computer Science</orgName>
								<orgName type="institution">ISCAS &amp; UCAS</orgName>
								<address>
									<addrLine>3 BUPT 4 HKUST</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiulin</forename><surname>Zhang</surname></persName>
							<email>qiulinzhang@bupt.edu.cntongzhang@tongzhang-ml.org</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
							<email>xuchunjing@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Model Rubik&apos;s Cube: Twisting Resolution, Depth and Width for TinyNets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To obtain excellent deep neural architectures, a series of techniques are carefully designed in EfficientNets. The giant formula for simultaneously enlarging the resolution, depth and width provides us a Rubik's cube for neural networks. So that we can find networks with high efficiency and excellent performance by twisting the three dimensions. This paper aims to explore the twisting rules for obtaining deep neural networks with minimum model sizes and computational costs. Different from the network enlarging, we observe that resolution and depth are more important than width for tiny networks. Therefore, the original method, i.e. the compound scaling in EfficientNet is no longer suitable. To this end, we summarize a tiny formula for downsizing neural architectures through a series of smaller models derived from the EfficientNet-B0 with the FLOPs constraint. Experimental results on the ImageNet benchmark illustrate that our TinyNet performs much better than the smaller version of EfficientNets using the inversed giant formula. For instance, our TinyNet-E achieves a 59.9% Top-1 accuracy with only 24M FLOPs, which is about 1.9% higher than that of the previous best MobileNetV3 with similar computational cost. Code will be available at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep convolutional neural networks (CNNs) have achieved great success in many visual tasks, such as image recognition <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b9">10]</ref>, object detection <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9]</ref>, and super-resolution <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b40">41]</ref>. In the past few decades, the evolution of neural architectures has greatly increased the performance of deep learning models. From LeNet <ref type="bibr" target="#b22">[23]</ref> and AlexNet <ref type="bibr" target="#b21">[22]</ref> to modern ResNet <ref type="bibr" target="#b13">[14]</ref> and EfficientNet <ref type="bibr" target="#b43">[44]</ref>, there are a number of novel components including shortcuts and depth-wise convolution. Neural architecture search <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b44">45]</ref> also provides more possibility of network architectures. These various architectures have provided candidates for a large variety of real-world applications.</p><p>To deploy the networks on mobile devices, the depth, the width and the image resolution are continuously adjusted to reduce memory and latency. For example, ResNet <ref type="bibr" target="#b13">[14]</ref> provides models with different number of layers, and MobileNet <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b38">39]</ref> changes the number of channels (i.e. the width of neural network) and image resolution for different FLOPs. Most of existing works only scale one of the three dimensions -resolution, depth, and width (denoted as r, d, and w). Tan and Le explore the EfficientNet <ref type="bibr" target="#b43">[44]</ref>, which enlarges CNNs with a compound scaling method. The great success made by EfficientNets bring a Rubik's cube to the deep learning community, i.e. we can twist it for better neural architectures using some pre-defined formulas. For example, the EfficientNet-B7 is derivate from the B0 version by uniformly increasing these three dimensions. Nevertheless, the original EfficientNet and some improved versions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b50">51]</ref> only discuss the giant formula, the rules for effectively downsize the baseline model has not been fully investigated.</p><p>The straightforward way for designing tiny networks is to apply the experience used in Efficient-Net <ref type="bibr" target="#b43">[44]</ref>. For example, we can obtain an EfficientNet-B −1 with a 200M FLOPs (floating-point operations). Since the giant formula is explored for enlarging networks, this naive strategy could not perfectly find a network with the highest performance. To this end, we randomly generate 100 models by twisting the three dimensions (r, d, w) from the baseline EfficientNet-B0. FLOPs of these models are less than or equal to that of the baseline. It can be found in <ref type="figure">Figure 1</ref>, the performance of best models is about 2.5% higher than that of models obtained using the inversed giant formula of EfficientNet (green line) with different FLOPs. <ref type="figure">Figure 1</ref>: Accuracy v.s. FLOPs of the models randomly donwsized from EfficientNet-B0. Five models using the inversed giant formula (green) and the frontier models (red) with both higher performance and lower FLOPs are highlighted.</p><p>In this paper, we study the relationship between the accuracy and the three dimensions (r, d, w) and explore a tiny formula for the model Rubik's cube. Firstly, we find that resolution and depth are more important than width for retaining the performance of a smaller neural architecture. We then point out that the inversed giant formula, i.e. the compound scaling method in EfficientNets is no longer suitable for designing portable networks for mobile devices, due to the reduction on the resolution is relatively large. Therefore, we explore a tiny formula for the cube through massive experiments and observations. In contrast to the giant formula in EfficientNet that is handcrafted, the proposed scheme twists the three dimensions based on the observation of frontier models. Specifically, for the given upper limit of FLOPs, we calculate the optimal resolution and depth exploiting the tiny formula, i.e. the Gaussian process regression on frontier models. The width of the resulting model is then determined according to the FLOPs constraint and previously obtained r and d. The proposed tiny formula for establishing TinyNets is simple yet effective. For instance, TinyNet-A achieves a 76.8% Top-1 accuracy with about 339M FLOPs but the EfficientNet-B0 with the similar performance needs about 387M FLOPs. In addition, TinyNet-E achieves a 59.9% Top-1 accuracy with only 24M FLOPs, being 1.9% higher than the previous best MobileNetV3 with similar FLOPs. To our best knowledge, we are the first to study how to generate tiny neural networks via simultaneously twisting resolution, depth and width. Besides the validations on EfficientNet, our tiny formula can be directly applied on ResNet architectures to obtain small but effective neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Here we revisit the existing model compression methods for shrinking neural networks, and discuss about resolution, depth and width of CNNs.</p><p>Model Compression. Model compression aims to reduce the computation, energy and storage cost, which can be categorized into four main parts: pruning, low-bit quantization, low-rank factorization and knowledge distillation. Pruning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b24">25]</ref> is used to reduce the redundant parameters in neural networks that are insensitive to the model performance. For example, <ref type="bibr" target="#b23">[24]</ref> uses 1 -norm to calculate the importance of each filter and prunes the unimportant ones accordingly. ThiNet <ref type="bibr" target="#b30">[31]</ref> prunes filters based on statistics computed from their next layers. Low-bit quantization <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19]</ref> represents weights or activations in neural networks using low-bit values. DorefaNet <ref type="bibr" target="#b60">[61]</ref> trains neural networks with both low-bit weights and activations. BinaryNet <ref type="bibr" target="#b17">[18]</ref> and XNORNet <ref type="bibr" target="#b35">[36]</ref> quantize each neuron into only 1-bit and learn the binary weights or activations directly during the model training. Low-rank factorization methods try to estimate the informative parameters using matrix/tensor decomposition <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b57">58]</ref>. Low-rank factorization achieves some advances in model compression, but it involves complex decomposition operations and is thus computationally expensive. Knowledge distillation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b51">52]</ref> attempts to teach a compact model, also called student model, with knowledge distilled from a large teacher network. The common part of these compression methods is that their performance is usually upper bounded by the given pretrained models.</p><p>Resolution, Depth and Width of CNNs. The three dimensions including resolution, depth and width of convolutional neural networks have much impact on the performance and have been explored for scaling the CNNs. ResNet <ref type="bibr" target="#b13">[14]</ref> proposes models of different depth, from ResNet-18 to ResNet-152, to provide choices between model size and model performance. WideResNet <ref type="bibr" target="#b48">[49]</ref> propose to decrease the depth and increase the width of residual networks, demonstrating that a wider network is superior to a deep and thin counterpart. The input images of higher resolution provides more information that is helpful to model performance but also leads to higher computation cost <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b15">16]</ref>. Considering all the three CNN dimensions into account, EffectiveNet <ref type="bibr" target="#b43">[44]</ref> proposes a compound scaling method to scale up networks with a handcrafted formula. However, it is still an open problem of how to shrink a given model to small and compact versions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>In this section, we first rethink the importance of resolution, depth and width, and find original EfficientNet rule lose its efficiency for smaller models. Based on the observation, we propose a new tiny formula for model Rubik's cube to generate smaller neural networks.</p><p>3.1 Rethinking the Importance of (r, d, w)</p><p>Given a baseline CNN, we aim to find the smaller versions of it for deployment on low-resource devices. Resolution, depth and width are three key factors that affect the performance of CNNs as discussed in EfficientNet <ref type="bibr" target="#b43">[44]</ref>. However, which of them has more impact on the performance has not been well investigated in the previous works. Here we propose to evaluate the impact of (r, d, w) under the fixed FLOPs or memory constraint. In practice, the FLOPs constraint is more common so we explore under FLOPs constraint and the methods can also be applied for memory constraint.</p><p>To be specific, the FLOPs of the given baseline CNN are C 0 , the resolution of the input image is R 0 × R 0 , the width is W 0 and the depth is D 0 .  Resolution Is More Important. Here we start from EfficientNet-B0 with C 0 FLOPs, and sample models with FLOPs of around 0.5C 0 . In order to search around the target FLOPs, we randomly search the resolution and the depth, and tune the width around w = 0.5/d/r 2 to make the resulted model has the target FLOPs (the difference ≤ 3%). These random searched models are fully trained for 100 epochs on ImageNet-100 dataset. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, the accuracy is more related to the resolution, compared with the depth and the width. We find that the top accuracies are obtained around the range from 0.8 to 1.4. When r &lt; 0.8, the accuracy is higher if the resolution is larger, while the accuracy drops slightly when r &gt; 1.4. As for the depth, the models with high performance may have various depth from 0.5 to 2, that is to say, we may miss some good models if we narrowly restrict the depth. When fixing FLOPs, the width has roughly negative correlation to the accuracy. The good models are mostly distributed at w &lt; 1.</p><p>If we follow the EfficientNet rule to obtain a model with 0.5C 0 FLOPs, namely EfficientNet-B −1 , whose three dimensions are calculated and tuned as r = 0.86, d = 0.8, w = 0.89. Its accuracy on ImageNet-100 is only 75.8%, which is far from the optimal combination for 0.5C 0 FLOPs. It can be found in <ref type="figure" target="#fig_1">Figure 2</ref>, there is a number of models with higher performance even though they are randomly generated. This observation motivates us to explore a new model twisting formula that can obtain better models under a fixed FLOPs constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tiny Formula for Model Rubik's Cube</head><p>For a given arbitrary baseline neural network, and with a FLOPs constraint of c · C 0 , where 0 &lt; c &lt; 1 is the reduction factor, our goal is to provide the optimal values of the three dimensions (r, d, w) for shrinking the model. Basically, we assume the optimal coefficients r, w, d for shrinking resolution, width and depth are</p><formula xml:id="formula_0">r = f 1 (c), w = f 2 (c), d = f 3 (c),<label>(1)</label></formula><p>where f 1 (·), f 2 (·) and f 3 (·) are the functions for calculating the three dimensions. We will give the formulation of the equations in the following.</p><p>Then, we randomly sample a number of models with different coefficients and verify them to explore the relationship between the performance and the three dimensions. The coefficients are randomly sampled from a given range. We preserve the models whose FLOPs are between 0.03·C 0 and 1.05·C 0 .</p><p>After fully training and testing these models, we can obtain their accuracies on validation set. We plot scatter diagram of accuracy v.s. FLOPs as shown in <ref type="figure">Figure 1</ref>. Obviously, there are a number of models whose performance is better than the vanilla EfficientNet-B0 and its shrunken versions obtained by exploiting the inversed compound scaling scheme.</p><p>To further explore the property of the best models, we select the models on the Accuracy-FLOPs Pareto front. Pareto front is a set of nondominated solutions, being chosen as optimal, if no objective can be improved without sacrificing at least one other objective <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b3">4]</ref>. In particular, the top 20% models with higher performance and lower computational complexities (i.e. FLOPs) are selected using NSGA-III nondominated sorting strategy <ref type="bibr" target="#b3">[4]</ref>. We show the relation between depth/width/resolution and FLOPs of these selected models in <ref type="figure" target="#fig_3">Figure 3</ref>. Spearman correlation coefficient (Spearmanr) are calculated to measure the correlation between depth/width/resolution and FLOPs. From the results in <ref type="figure" target="#fig_3">Figure 3</ref>, the rank of correlations between the three dimensions with FLOPs is r &gt; d &gt; w. Wherein, the Spearmanr score for resolution is 0.81, which is much higher than that of width.  Inspired by the observation of relationship between (r, d, w) and FLOPs, we propose the tiny formula for shrinking neural architectures as follows. For the given requirement of FLOPs c · C 0 , our goal is to calculate the optimal combinations of (r, d, w) for building models with high performance. Since the correlations between resolution/depth and FLOPs are higher than that of width, we present to first twist the resolution and depth to ensure the performance of the smaller model. Taking the formula of resolution as the example, the nonparametric Guassign process regression <ref type="bibr" target="#b34">[35]</ref> is utilized to model the mapping from c ∈ R to r ∈ R. Let {(c i , r i )} m i=1 be the training set with m i.i.d. examples from <ref type="figure" target="#fig_3">Figure 3</ref>(a), we have</p><formula xml:id="formula_1">r i = g(c i ) + i , i = 1, · · · , m,<label>(2)</label></formula><p>where i is i.i.d. noise variable from N (0, σ 2 ) distribution, and g(·) follows the zero-mean Gaussian process prior, i.e. f (·) ∼ GP(0, k(·, ·)) with covariance function k(·, ·). For convenience, we denote c = [c 1 , c 2 , · · · , c m ] T ∈ R m , r = [r 1 , r 2 , · · · , r m ] ∈ R m . Then the joint prior distribution of the training data c and the test point c * belongs to a Gaussian distribution:</p><formula xml:id="formula_2">r r * c, c * ∼ N 0, K( c, c) + σ 2 I K( c, c * ) K(c * , c) k(c * , c * ) + σ 2 ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">K( c, c) ∈ R m×m in which (K( c, c)) ij = k(c i , c j ), K( c, c * ) ∈ R m×1 , and K(c * , c) ∈ R 1×m .</formula><p>Thus, we can calculate the posterior distribution of prediction r * as </p><formula xml:id="formula_4">r * | r, c, c * ∼ N (µ * , Σ * ),<label>(4)</label></formula><formula xml:id="formula_5">w = c/(r 2 d), s.t. 0 &lt; c &lt; 1.<label>(5)</label></formula><p>In contrast to the handcrafted compound scaling method in EfficientNets, the proposed model shrinking rule is designed based on the observation of frontier small models, which are more effective for producing tiny networks with higher performance.</p><p>TinyNet. Our tiny formula for model Rubik's cube can be applied to any network architecture. Here we start from the excellent baseline network, EfficientNet-B0 <ref type="bibr" target="#b43">[44]</ref>, and apply our shrinking method to obtain smaller networks. With about 5.3M parameters and 390M FLOPs, EfficientNet-B0 consists of 16 mobile inverted residual bottlenecks <ref type="bibr" target="#b38">[39]</ref>, in addition to the normal stem layer and classification head layers. To apply our tiny formula, we first construct a number of networks whose (r, w, d) are randomly sampled as shown in <ref type="figure">Figure 1</ref>. After obtaining the accuracy on ImageNet-100, we can train the Gaussian process regression model for resolution and depth. Here we adopt the widely used RBF kernel as the covariance function. Then, given the desired FLOPs constraint c, we can determine the three dimensions, aka (r, w, d), by the above equations. We set c in {0.9, 0.5, 0.25, 0.13, 0.06}, and obtain a series of smaller EfficientNet-B0, namely, TinyNet-A to E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we apply our tiny formula for model Rubik's cube to shrink EfficientNet-B0 and ResNet-50. The effectiveness of our method is verified on the visual recognition benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Experimental Settings</head><p>ImageNet-1000. ImageNet ILSVRC2012 dataset <ref type="bibr" target="#b4">[5]</ref> is a large-scale image classification dataset containing 1.2 million images for training and 50,000 validation images belonging to 1,000 categories. We use the common data augmentation strategy <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b15">16]</ref> including random crop, random flip and color jitter. The base input resolution is 224 for r = 1.</p><p>ImageNet-100. ImageNet-100 is the subset of ImageNet-1000 that contains randomly sampled 100 classes. 500 training images are randomly sampled for each class, and the corresponding 5,000 images are used as validation set. The data augmentation strategy is the same as that in ImageNet-1000.</p><p>Implementation details. All the models are implemented using PyTorch <ref type="bibr" target="#b33">[34]</ref> and trained on NVIDIA Tesla V100 GPUs. The EfficientNet-B0 based models are trained using similar settings as <ref type="bibr" target="#b43">[44]</ref>. We train the models for 450 epochs using the RMSProp optimizer with momentum 0.9 and decay 0.9. The weight decay is 1e-5 and batch normalization momentum is set as 0.99. The initial learning rate is 0.048 and decays by 0.97 every 2.4 epochs. Learning rate warmup <ref type="bibr" target="#b6">[7]</ref> is applied for the first 3 epochs. The batch size is 1024 for 8 GPUs with 128 images per chip. The dropout of 0.2 is applied on the last fully-connected layer for regularization. We also use exponential moving average (EMA) with decay 0.9999. For ResNets, the models are trained for 90 epochs with batch size of 1024. SGD optimizer with the momentum 0.9 and weight decay 1e-4 is used to update the weights. The learning rate starts from 0.4 and decays by 0.1 every 30 epochs.</p><p>In the original EfficientNet rule for giant models <ref type="bibr" target="#b43">[44]</ref>, the FLOPs value of a model is calculated as 2 −φ · C 0 . We denote the models obtained from the inversed giant formula in original EfficientNet as EfficientNet-B −φ where φ = 1, 2, 3, 4, with about 200M, 100M, 50M, 25M FLOPs, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments on ImageNet-100</head><p>Random Sample Results. As stated in the above sections, we randomly sample a number of models with different resolution, depth and width. In particular, resolution, depth or width is randomly sampled from the range of 0.35 ≤ r ≤ 2.8, 0.35 ≤ d ≤ 2.8 and 0.35 ≤ w ≤ 2.8. The sampled models are trained on ImageNet-100 dataset for 100 epochs. The other training hyperparameters are the same as those in implementation details for EfficientNet-B0 based models. 100 models are sampled in total and it takes about 2.5 GPU hours on average to train one model. The results of all the models are shown in <ref type="figure">Figure 1</ref>. Larger FLOPs lead to higher accuracy generally. Some of the sampled models perform better than the shrunken models using inversed giant formula of EfficientNet. For example, a sampled model with 318M FLOPs achieves 79.7% accuracy while EfficientNet-B0 with 387M FLOPs only achieves 78.8%. These observations indicate the necessity to design a more effective model shrinking method. Comparison to EfficientNet Rule. In order to verify the effectiveness of the proposed model shrinking method, we compare our method with the inversed giant formula of EfficientNet and separately changing r, d or w. From <ref type="table" target="#tab_0">Table 1</ref>, the proposed method outperforms both EfficientNet rule and separately adjusting resolution, depth or width, demonstrating the effectiveness of the proposed tiny formula for model shrinking. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shrinking</head><p>ResNet. In addition to EfficientNet-B0, we also apply our method for shrinking the widely-used ResNet network architecture. ResNet-50 is adopted as the baseline model, and it is shrunken in different ways including reducing layers, EfficientNet rule and our method. The results on ImageNet-100 are shown in <ref type="table" target="#tab_1">Table 2</ref>. Our models outperform other models generally, suggesting the effectiveness of the proposed model shrinking method for ResNet architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments on ImageNet-1000</head><p>The tiny formula obtained on ImageNet-100 can be well transferred to other datasets as demonstrated in NAS literature <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b49">50]</ref>. We evaluate our tiny formula on the large-scale ImageNet-1000 dataset to verify its generalization.</p><p>TinyNet Performance. We compare TinyNet models with other competitive small neural networks, including the models from original EfficientNet rule, i.e. EfficientNet-B −φ , and other state-of-the-art small CNNs such as MobileNet series <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b15">16]</ref>, ShuffleNet series <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b31">32]</ref>, and MnasNet <ref type="bibr" target="#b42">[43]</ref>, are compared here. Several competitive NAS-based models are also included. <ref type="table" target="#tab_2">Table 3</ref> shows the performance of all the compared models. Our TinyNet models generally outperform other CNNs. In particular, our TinyNet-E achieves 59.9% Top-1 accuracy with 24M FLOPs, being 1.9% higher than the previous best MobileNetV3 Small 0.5× <ref type="bibr" target="#b15">[16]</ref> with similar computational cost.</p><p>RandAugment <ref type="bibr" target="#b2">[3]</ref> is a practical automated data augmentation strategy to improve the generalization of deep learning models. We use RandAugment with magnitude 9 and standard deviation 0.5 to improve the performance of our TinyNet-A and EfficientNet-B0, and show the results in <ref type="table" target="#tab_2">Table 3</ref>. For the TinyNet models, RandAugment is beneficial to the performance. In particular, TinyNet-A + RA achieves 77.7% Top-1 accuracy which is 0.9% higher than vanilla TinyNet-A.  Visualization of Class Activation Map. We visualize the class activation map <ref type="bibr" target="#b59">[60]</ref> for EfficientNet-B −4 and TinyNet-E to better demonstrate the superiority of our TinyNet. The images are randomly picked from ImageNet-1000 validation set. As shown in <ref type="figure" target="#fig_6">Figure 5</ref>, TinyNet-E pays attention to the more relevant regions, while EfficientNet-B −4 sometimes only focuses on the unrelated objects or the local part of target objects.  Shrinking by r, d, w Separately. We also compare the proposed model shrinking rule with the naive method, i.e. changing resolution, depth and width separately. We tune resolution, width or depth separately to form models with 100M and 200M FLOPs. Note that the minimum viable depth for EfficientNet-B0 is reached with 7 inverted residual bottlenecks, and the corresponding FLOPs 174M. The results are shown in <ref type="figure" target="#fig_7">Figure 6</ref>. In general, all shrinking approaches lead to lower accuracy when the number of FLOPs decreases, but our model shrinking method can alleviate the accuracy drop, suggesting the effectiveness of the proposed method.</p><p>Inference Latency Comparison. We also measure the inference latency of several representative CNNs on Huawei P40 smartphone. We test under single-threaded mode with batch size 1 <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b15">16]</ref> using the MindSpore Lite tool <ref type="bibr" target="#b0">[1]</ref>. The results are listed in <ref type="table" target="#tab_3">Table 4</ref>, where we run 1000 times and report average latency. Our TinyNet-A runs 15% faster than EfficientNet-B0 while their accuracies are similar. TinyNet-E can obtain 3.2% accuracy gain compared to EfficientNet-B −4 with similar latency. Generalization on Object Detection. To verify the generalization of our models, we apply tinynets on object detection task. We adopt SSDLite <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b38">39]</ref> with 512×512 input as baseline network due to its efficiency and test on MS COCO dataset <ref type="bibr" target="#b26">[27]</ref>. The experimental setting is similar to that in <ref type="bibr" target="#b38">[39]</ref>. From results in <ref type="table" target="#tab_4">Table 5</ref>, we can see that our TinyNet-D outperforms EfficientNet-B −3 by a large margin with comparable computational cost. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Discussion</head><p>In this paper, we study the model Rubik's cube for shrinking deep neural networks. Based on a series of observations, we find that the original giant formula in EfficientNet is unsuitable for generating smaller neural architectures. To this end, we thoroughly analyze the importance of resolution, depth and width w.r.t. the performance of portable deep networks. Then, we suggest to pay more concentration on the resolution and depth and calculate the model width to satisfy FLOPs constraint. We explore a series of TinyNets by utilizing the tiny formula to twist the three dimensions. The experimental results for both EfficientNets and ResNets demonstrate effectiveness of the proposed simple but effective scheme for designing tiny networks. Moreover, the tiny formula in this work is summarized according to the observation on smaller models. These smaller models can also be further enlarged to obtain higher performance with some new rules beyond the giant formula in EfficientNets, which will be investigated in future works.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Accuracy v.s. (r, d, w) for the models with ∼200M FLOPs on ImageNet-100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Resolution/depth/width v.s. FLOPs for the models on Pareto front.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>where µ * = K(c * , c)(K( c, c) + σ 2 I) −1 r and Σ * = k(c * , c * ) + σ 2 − K(c * , c)(K( c, c) + σ 2 I) −1 K( c, c * )are the mean and variance for the test point c * . The formula for depth can be obtained similarly. Then, the last dimension, i.e. width, can be determined by FLOPs constraint:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .Figure 4 :</head><label>44</label><figDesc>From Figure 4(a), the accuracy of TinyNet-E is higher than that of EfficientNet-B −4 by a large margin consistently during training. In the end of training, our TinyNet-E outperforms EfficientNet-B −4 by an accuracy gain of 3.2%. The train and validation loss curves in Figure 4(b) also show the superiority of our TinyNet. (a) Validation accuracy (b) Loss Learning curves of EfficientNet-B −4 and our TinyNet-E on ImageNet-1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Class Activation Map for EfficientNet-B −4 and our TinyNet-E.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Accuracy v.s. FLOPs of the models shrunken using different ways on ImageNet-1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Top-1 Accuracy v.s. FLOPs on ImageNet dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>Model</cell><cell>FLOPs</cell><cell>Acc.</cell><cell>Model</cell><cell>FLOPs</cell><cell>Acc.</cell></row><row><cell>EfficientNet-B −1</cell><cell>200M</cell><cell>75.8%</cell><cell>EfficientNet-B −2</cell><cell>97M</cell><cell>72.1%</cell></row><row><cell>shrink B0 by r = 0.70</cell><cell>196M</cell><cell>74.9%</cell><cell>shrink B0 by r = 0.46</cell><cell>103M</cell><cell>70.3%</cell></row><row><cell>shrink B0 by d = 0.45</cell><cell>196M</cell><cell>76.5%</cell><cell>depth underflow  †</cell><cell>-</cell><cell>-</cell></row><row><cell>shrink B0 by w = 0.65</cell><cell>205M</cell><cell>77.2%</cell><cell>shrink B0 by w = 0.38</cell><cell>99M</cell><cell>73.2%</cell></row><row><cell>TinyNet-B (ours)</cell><cell>201M</cell><cell>77.6%</cell><cell>TinyNet-C (ours)</cell><cell>97M</cell><cell>74.1%</cell></row></table><note>TinyNet Performance on ImageNet-100. All the models are shrunken from the EfficientNet- B0 baseline.† Shrinking B0 to the minimum depth results in 173M FLOPs (&gt;100M).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of shrunken ResNet on ImageNet-100 dataset.</figDesc><table><row><cell>Model</cell><cell>FLOPs</cell><cell>Acc.</cell></row><row><cell>Baseline ResNet-50 [14]</cell><cell>4.1B</cell><cell>78.7%</cell></row><row><cell>ResNet-34 [14]</cell><cell>3.7B</cell><cell>77.9%</cell></row><row><cell>Shrunken by EfficientNet rule</cell><cell>3.7B</cell><cell>78.3%</cell></row><row><cell>ResNet-50-A (ours)</cell><cell>3.6B</cell><cell>79.3%</cell></row><row><cell>ResNet-18 [14]</cell><cell>1.8B</cell><cell>76.5%</cell></row><row><cell>Shrunken by EfficientNet rule</cell><cell>1.8B</cell><cell>76.9%</cell></row><row><cell>ResNet-50-B (ours)</cell><cell>1.8B</cell><cell>78.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of state-of-the-art small networks over classification accuracy, the number of weights and FLOPs on ImageNet-1000 dataset. "-" mean no reported results available.</figDesc><table><row><cell>Model</cell><cell>Weights</cell><cell>FLOPs</cell><cell>Top-1 Acc.</cell><cell>Top-5 Acc.</cell></row><row><cell>MobileNetV3 Large 1.25× [16]</cell><cell>7.5M</cell><cell>356M</cell><cell>76.6%</cell><cell>-</cell></row><row><cell>MnasNet-A1 [43]</cell><cell>3.9M</cell><cell>312M</cell><cell>75.2%</cell><cell>92.5%</cell></row><row><cell>Baseline EfficientNet-B0 [44]</cell><cell>5.3M</cell><cell>387M</cell><cell>76.7%</cell><cell>93.2%</cell></row><row><cell>TinyNet-A</cell><cell>6.2M</cell><cell>339M</cell><cell>76.8%</cell><cell>93.3%</cell></row><row><cell>EfficientNet-B0 [44] + RA</cell><cell>5.3M</cell><cell>387M</cell><cell>77.7%</cell><cell>93.5%</cell></row><row><cell>TinyNet-A + RA</cell><cell>6.2M</cell><cell>339M</cell><cell>77.7%</cell><cell>93.5%</cell></row><row><cell>MobileNetV2 1.0× [39]</cell><cell>3.5M</cell><cell>300M</cell><cell>71.8%</cell><cell>91.0%</cell></row><row><cell>ShuffleNetV2 1.5× [32]</cell><cell>3.5M</cell><cell>299M</cell><cell>72.6%</cell><cell>90.6%</cell></row><row><cell>FBNet-B [50]</cell><cell>4.5M</cell><cell>295M</cell><cell>74.1%</cell><cell>-</cell></row><row><cell>ProxylessNAS [2]</cell><cell>4.1M</cell><cell>320M</cell><cell>74.6%</cell><cell>92.2%</cell></row><row><cell>EfficientNet-B −1</cell><cell>3.6M</cell><cell>201M</cell><cell>74.7%</cell><cell>92.1%</cell></row><row><cell>TinyNet-B</cell><cell>3.7M</cell><cell>202M</cell><cell>75.0%</cell><cell>92.2%</cell></row><row><cell>MobileNetV1 0.5× (r=0.86) [17]</cell><cell>1.3M</cell><cell>110M</cell><cell>61.7%</cell><cell>83.6%</cell></row><row><cell>MobileNetV2 0.5× [39]</cell><cell>2.0M</cell><cell>97M</cell><cell>65.4%</cell><cell>86.4%</cell></row><row><cell>MobileNetV3 Small 1.25× [16]</cell><cell>3.6M</cell><cell>91M</cell><cell>70.4%</cell><cell>-</cell></row><row><cell>EfficientNet-B −2</cell><cell>3.0M</cell><cell>98M</cell><cell>70.5%</cell><cell>89.5%</cell></row><row><cell>TinyNet-C</cell><cell>2.5M</cell><cell>100M</cell><cell>71.2%</cell><cell>89.7%</cell></row><row><cell>MobileNetV2 0.35× [39]</cell><cell>1.7M</cell><cell>59M</cell><cell>60.3%</cell><cell>82.9%</cell></row><row><cell>ShuffleNetV2 0.5× [32]</cell><cell>1.4M</cell><cell>41M</cell><cell>61.1%</cell><cell>82.6%</cell></row><row><cell>MnasNet-A1 0.35× [43]</cell><cell>1.7M</cell><cell>63M</cell><cell>64.1%</cell><cell>85.1%</cell></row><row><cell>MobileNetV3 Small 0.75× [16]</cell><cell>2.4M</cell><cell>44M</cell><cell>65.4%</cell><cell>-</cell></row><row><cell>EfficientNet-B −3</cell><cell>2.0M</cell><cell>51M</cell><cell>65.0%</cell><cell>85.2%</cell></row><row><cell>TinyNet-D</cell><cell>2.3M</cell><cell>52M</cell><cell>67.0%</cell><cell>87.1%</cell></row><row><cell>MobileNetV2 0.35× (r=0.71) [39]</cell><cell>1.7M</cell><cell>30M</cell><cell>55.7%</cell><cell>79.1%</cell></row><row><cell>MnasNet-A1 0.35× (r=0.57) [43]</cell><cell>1.7M</cell><cell>22M</cell><cell>54.8%</cell><cell>78.1%</cell></row><row><cell>MobileNetV3 Small 0.5× [16]</cell><cell>1.6M</cell><cell>23M</cell><cell>58.0%</cell><cell>-</cell></row><row><cell>MobileNetV3 Small 1.0× (r=0.57) [16]</cell><cell>2.5M</cell><cell>20M</cell><cell>57.3%</cell><cell>-</cell></row><row><cell>EfficientNet-B −4</cell><cell>1.3M</cell><cell>24M</cell><cell>56.7%</cell><cell>79.8%</cell></row><row><cell>TinyNet-E</cell><cell>2.0M</cell><cell>24M</cell><cell>59.9%</cell><cell>81.8%</cell></row><row><cell cols="5">Visualization of Learning Curves. To better demonstrate the effect of our method, we plot the</cell></row><row><cell cols="2">learning curves of EfficientNet-B −4 and our TinyNet-E in</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Inference latency comparison.</figDesc><table><row><cell>Model</cell><cell>FLOPs</cell><cell>Latency</cell><cell>Top-1</cell><cell>Model</cell><cell>FLOPs</cell><cell>Latency</cell><cell>Top-1</cell></row><row><cell>EfficientNet-B0</cell><cell>387M</cell><cell>99.85 ms</cell><cell>76.7%</cell><cell>EfficientNet-B −4</cell><cell>24M</cell><cell>11.54 ms</cell><cell>56.7%</cell></row><row><cell>TinyNet-A</cell><cell>339M</cell><cell>81.30 ms</cell><cell>76.8%</cell><cell>TinyNet-E</cell><cell>24M</cell><cell>9.18 ms</cell><cell>59.9%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Results on MS COCO dataset.</figDesc><table><row><cell>Model</cell><cell>Backbone FLOPs</cell><cell>mAP</cell><cell>AP50</cell><cell>AP75</cell><cell>APS</cell><cell>APM</cell><cell>APL</cell></row><row><cell>EfficientNet-B −3</cell><cell>51M</cell><cell>17.1</cell><cell>29.9</cell><cell>17.0</cell><cell>5.2</cell><cell>30.5</cell><cell>54.8</cell></row><row><cell>TinyNet-D</cell><cell>52M</cell><cell>19.2</cell><cell>32.6</cell><cell>19.2</cell><cell>7.0</cell><cell>33.9</cell><cell>57.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>GhostNet results on ImageNet dataset.</figDesc><table><row><cell>Model</cell><cell cols="4">Weights FLOPs Top-1 Acc. Top-5 Acc.</cell></row><row><cell>EfficientNet-B1 [44]</cell><cell>7.8M</cell><cell>700M</cell><cell>78.7%</cell><cell>-</cell></row><row><cell>GhostNet-A</cell><cell>11.9M</cell><cell>591M</cell><cell>78.7%</cell><cell>94.2%</cell></row><row><cell>GhostNet-A + HSwish</cell><cell>11.9M</cell><cell>591M</cell><cell>78.9%</cell><cell>94.4%</cell></row><row><cell>GhostNet-A + HSwish + RA</cell><cell>11.9M</cell><cell>591M</cell><cell>79.4%</cell><cell>94.5%</cell></row><row><cell>EfficientNet-B0 [44]</cell><cell>5.3M</cell><cell>387M</cell><cell>76.7%</cell><cell>93.2%</cell></row><row><cell>GhostNet-1.5× [11]</cell><cell>9.1M</cell><cell>300M</cell><cell>76.4%</cell><cell>92.9%</cell></row><row><cell>GhostNet-B</cell><cell>8.0M</cell><cell>300M</cell><cell>77.0%</cell><cell>93.3%</cell></row><row><cell>GhostNet-B + HSwish</cell><cell>8.0M</cell><cell>300M</cell><cell>77.1%</cell><cell>93.4%</cell></row><row><cell>GhostNet-B + HSwish + RA</cell><cell>8.0M</cell><cell>300M</cell><cell>77.6%</cell><cell>93.5%</cell></row><row><cell>MobileNetV3 Large 0.75× [16]</cell><cell>4.0M</cell><cell>155M</cell><cell>73.3%</cell><cell>-</cell></row><row><cell>GhostNet-1.0× [11]</cell><cell>5.2M</cell><cell>141M</cell><cell>73.9%</cell><cell>91.4%</cell></row><row><cell>GhostNet-C</cell><cell>5.0M</cell><cell>141M</cell><cell>74.2%</cell><cell>91.7%</cell></row><row><cell>GhostNet-C + HSwish</cell><cell>5.0M</cell><cell>141M</cell><cell>74.8%</cell><cell>92.0%</cell></row><row><cell>GhostNet-C + HSwish + RA</cell><cell>5.0M</cell><cell>141M</cell><cell>75.0%</cell><cell>92.0%</cell></row><row><cell>MobileNetV3 Small 0.75× [16]</cell><cell>2.4M</cell><cell>44M</cell><cell>65.4%</cell><cell>-</cell></row><row><cell>GhostNet-0.5× [11]</cell><cell>2.6M</cell><cell>42M</cell><cell>66.2%</cell><cell>86.6%</cell></row><row><cell>GhostNet-D</cell><cell>2.6M</cell><cell>52M</cell><cell>67.7%</cell><cell>87.5%</cell></row><row><cell>GhostNet-D + HSwish</cell><cell>2.6M</cell><cell>52M</cell><cell>68.4%</cell><cell>87.8%</cell></row><row><cell>GhostNet-D + HSwish + RA</cell><cell>2.6M</cell><cell>52M</cell><cell>68.6%</cell><cell>88.1%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>GhostNet-A architecture. #exp means expansion ratio. #out means the number of output channels. SE denotes whether using SE module (reduction ratio 10). #repeat denotes repeat times.</figDesc><table><row><cell>Input size</cell><cell>Operator</cell><cell cols="5">#exp #out SE Stride #repeat</cell></row><row><cell>240 2 × 3</cell><cell>Conv 3×3</cell><cell>-</cell><cell>28</cell><cell>-</cell><cell>2</cell><cell>1</cell></row><row><cell>120 2 × 28</cell><cell>G-bneck</cell><cell>1</cell><cell>28</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>120 2 × 28</cell><cell>G-bneck</cell><cell>3</cell><cell>44</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>60 2 × 44</cell><cell>G-bneck</cell><cell>3</cell><cell>44</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>60 2 × 44</cell><cell>G-bneck</cell><cell>3</cell><cell>72</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>30 2 × 72</cell><cell>G-bneck</cell><cell>3</cell><cell>72</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>30 2 × 72</cell><cell>G-bneck</cell><cell>6</cell><cell>140</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>15 2 × 140</cell><cell>G-bneck</cell><cell>2.5</cell><cell>140</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell>15 2 × 140</cell><cell>G-bneck</cell><cell>6</cell><cell>196</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell>15 2 × 196</cell><cell>G-bneck</cell><cell>6</cell><cell>280</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>8 2 × 280</cell><cell>G-bneck</cell><cell>6</cell><cell>280</cell><cell>1</cell><cell>1</cell><cell>5</cell></row><row><cell>8 2 × 280</cell><cell>Conv 1×1</cell><cell>-</cell><cell>1680</cell><cell>-</cell><cell>1</cell><cell>1</cell></row><row><cell>8 2 × 1680</cell><cell>Pooling</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1</cell></row><row><cell cols="2">1 2 × 1680 Conv 1×1</cell><cell>-</cell><cell>1400</cell><cell>-</cell><cell>1</cell><cell>1</cell></row><row><cell>1 2 × 1400</cell><cell>FC</cell><cell>-</cell><cell>1000</cell><cell>-</cell><cell>-</cell><cell>1</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>The widely usage of deep neural networks which require large amount of computation resource is putting pressure on the energy source and the natural environment. The proposed model shrinking method for obtaining tiny neural networks is beneficial to energy conservation and environment protection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Experiments on GhostNet</head><p>We also verify the effectiveness of the proposed model Rubik's cube on the state-of-the-art portal network GhostNet <ref type="bibr" target="#b10">[11]</ref>. We first build a baseline GhostNet with about 591M FLOPs, which is denoted as GhostNet-A (details in <ref type="table">Table 7</ref>). We start from GhostNet-A and shrink the model by the proposed tiny formula, resulting in a serious of smaller models, i.e. GhostNet-B/C/D. The new models are trained using the similar setting as TinyNets. The comparison with the original GhostNets on ImageNet dataset is shown in <ref type="table">Table 6</ref>. We can see that the new GhostNet models obtained by the proposed model Rubik's cube outperform the original GhostNets which only change the width.</p><p>Note that GhostNets use ReLU as activation function, and more complex activations (e.g. HSwish <ref type="bibr" target="#b15">[16]</ref>) may further improve the performance. We also show the results with automated data augmentation strategy, i.e. RandAugment <ref type="bibr" target="#b2">[3]</ref> in <ref type="table">Table 6</ref>. Both fancy activation function and data augmentation could boost GhostNets to higher performance.</p><p>For better comparison, we plot the results in <ref type="figure">Fig. 7</ref>. The compared methods include recent state-ofthe-art models, i.e. MobileNetV2 <ref type="bibr" target="#b38">[39]</ref>, MobileNetV3 <ref type="bibr" target="#b15">[16]</ref>, EfficientNet <ref type="bibr" target="#b43">[44]</ref>, ShuffleNetV2 <ref type="bibr" target="#b31">[32]</ref>, FBNet <ref type="bibr" target="#b49">[50]</ref>, MnasNet <ref type="bibr" target="#b42">[43]</ref>, ProxylessNAS <ref type="bibr" target="#b1">[2]</ref> and GreedyNAS <ref type="bibr" target="#b54">[55]</ref>. GhostNet models enhanced by TinyNet technique consistently outperform other models by a significant margin.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mindspore</surname></persName>
		</author>
		<ptr target="https://www.mindspore.cn/" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part i: solving problems with box constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="577" to="601" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting linear structure within convolutional networks for efficient evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Emily L Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1269" to="1277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Projection convolutional neural networks for 1-bit cnns via discrete back propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hit-detector: Hierarchical trinity architecture search for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attribute-aware attention model for fine-grained representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingjian</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ghostnet: More features from cheap operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Training binary neural networks through learning with noisy supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huizi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ruoming Pang, Vijay Vasudevan, et al. Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Binarized neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itay</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4107" to="4115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Quantization and training of neural networks for efficient integerarithmetic-only inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skirmantas</forename><surname>Kligys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2704" to="2713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Speeding up convolutional neural networks with low rank expansions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Pruning filters for efficient convnets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Durdanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">Peter</forename><surname>Graf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hrank: Filter pruning using high-rank feature map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards optimal structured cnn pruning via generative adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenqian</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liujuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Darts: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bi-real net: Enhancing the performance of 1-bit cnns with improved representational capability and advanced training algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Thinet: A filter level pruning method for deep neural network compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Hao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5058" to="5066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Tradeoff decision in multiple criteria decision making. Multiple criteria decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meisel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="page" from="461" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Gaussian processes for machine learning (adaptive computation and machine learning)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">Edward</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Xnor-net: Imagenet classification using binary convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="525" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fitnets: Hints for thin deep nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Coevolutionary compression for unpaired image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficient residual dense block search for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Inception-v4, inceptionresnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2820" to="2828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A semi-supervised assessor of neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Reborn filters: Pruning convolutional neural networks with limited data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Ntire 2017 challenge on single image super-resolution: Methods and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="114" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Gan slimming: All-in-one gan compression by a unified optimization framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shupeng</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haichuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A P</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10734" to="10742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Positiveunlabeled compression on the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Xu Chunjing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cars: Continuous evolution for efficient neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Legonet: Efficient convolutional neural networks with lego filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanjian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Greedynas: Towards fast one-shot nas with greedy supernet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingmin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning from multiple teacher networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">On compressing deep models by low rank and sparse decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Split to be slim: An overlooked redundancy in vanilla convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiulin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuqing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qishuo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxin</forename><surname>Jia&amp;apos;nan Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Men</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuchang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuheng</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06160</idno>
		<title level="m">Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
