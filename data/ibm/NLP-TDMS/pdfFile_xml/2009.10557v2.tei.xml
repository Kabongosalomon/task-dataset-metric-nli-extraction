<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based Sentiment Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaishao</forename><surname>Luo</surname></persName>
							<email>huaishaoluo@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">Southwest Jiaotong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Ji</surname></persName>
							<email>leiji@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Institute of Computing Technology, Chinese Academy of Science</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianrui</forename><surname>Li</surname></persName>
							<email>trli@swjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">Southwest Jiaotong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
							<email>nanduan@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
							<email>djiang@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">STCA NLP Group</orgName>
								<address>
									<settlement>Microsoft, Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based Sentiment Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we focus on the imbalance issue, which is rarely studied in aspect term extraction and aspect sentiment classification when regarding them as sequence labeling tasks. Besides, previous works usually ignore the interaction between aspect terms when labeling polarities. We propose a GRadient hArmonized and CascadEd labeling model (GRACE) to solve these problems. Specifically, a cascaded labeling module is developed to enhance the interchange between aspect terms and improve the attention of sentiment tokens when labeling sentiment polarities. The polarities sequence is designed to depend on the generated aspect terms labels. To alleviate the imbalance issue, we extend the gradient harmonized mechanism used in object detection to the aspect-based sentiment analysis by adjusting the weight of each label dynamically. The proposed GRACE adopts a post-pretraining BERT as its backbone. Experimental results demonstrate that the proposed model achieves consistency improvement on multiple benchmark datasets and generates state-of-the-art results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Aspect terms extraction (ATE) and aspect sentiment classification (ASC) are two fundamental, fine-grained subtasks in aspect-based sentiment analysis (ABSA). ATE is the task of extracting the aspect terms (or attributes) of an entity upon which opinions have been expressed, and ASC is the task of identifying the polarities expressed on these extracted terms in the opinion text <ref type="bibr" target="#b8">(Hu and Liu, 2004)</ref>. Consider the example in <ref type="figure">Figure 1</ref>, which contains comments that people expressed about the aspect terms "operating system" and "keyboard", and their polarities are all positive. * Work is done during an internship at MSR Asia. † Correspongding author. To better satisfy the practical applications, the aspect term-polarity co-extraction, which solves ATE and ASC simultaneously, receives much attention in recent years <ref type="bibr" target="#b24">Luo et al., 2019b;</ref><ref type="bibr" target="#b44">Hu et al., 2019;</ref><ref type="bibr" target="#b38">Wan et al., 2020)</ref>. A big challenge of the aspect term-polarity co-extraction in a unified model is that ATE and ASC belong to different tasks: ATE is usually a sequence labeling task, and ASC is usually a classification task. Previous works usually transform the ASC task into sequence labeling. Thus the ATE and ASC have the same formulation.</p><p>There are two approaches of sequence labeling on the aspect term-polarity co-extraction. As shown in <ref type="figure">Figure 1</ref>, one is the joint approach, and the other is the collapsed approach. The preceding one jointly labels each sentence with two different tag sets: aspect term tags and polarity tags. The subsequent one uses collapsed labels as the tags set, e.g., "B-POS" and "I-POS", in which each tag indicates the aspect term boundary and its polarity. Except for the joint and collapsed approaches, a pipelined approach first labels the given sentence using aspect term tags, e.g., "B" and "I" (the beginning and inside of an aspect term), and then feeds the aspect terms into a classifier to obtain their corresponding polarities.</p><p>Several related works have been published in these approaches. <ref type="bibr" target="#b28">Mitchell et al. (2013)</ref> and  found that the joint and collapsed approaches are superior to the pipelined approach on named entities and their sentiments co-extraction.  proposed a unified model with the collapsed approach to do aspect term-polarity co-extraction. <ref type="bibr" target="#b44">Hu et al. (2019)</ref> solved this task with a pipelined approach. <ref type="bibr" target="#b24">Luo et al. (2019b)</ref> adopted the joint approach to do such a co-extraction. We follow the joint approach in this paper, and believe that it has a more apparent of responsibilities than the collapsed approach through learning parallel sequence labels.</p><p>However, previous works on the joint approach usually ignore the interaction between aspect terms when labeling polarities. Such an interaction is useful in identifying the polarity. As an instance, in <ref type="figure">Figure 1</ref>, if "operating system" is positive, "keyboard" should be positive due to these two aspect terms are connected by coordinating conjunction "and". Besides, almost all of previous works do not concern the imbalance of labels in such sequence labeling tasks. As shown in 2a, the number of 'O' labels is much larger than that of 'B' and 'I', which tends to dominant the training loss. Moreover, we find the same gradient phenomenon as  in the sequence labeling task. As shown in <ref type="figure">Figure 2b</ref>, most of the labels own low gradients, which have a significant impact on the global gradient due to their large number.</p><p>Considering the above issues, we propose a GRadient hArmonized and CascadEd labeling model (GRACE) in this paper. The proposed GRACE is shown in <ref type="figure" target="#fig_1">Figure 3</ref>. Unlike previous works, GRACE is a cascaded labeling model, which uses the generated aspect term labels to enhance the polarity labeling in a unified framework. Specifically, we use two encoder modules shared with lower layers to extract representation. One encoder module is for ATE, and the other is for ASC after giving the aspect term labels generated by the preceding encoder. Thus, the GRACE could consider the interaction between aspect terms in the ASC module through a stacked Multi-Head Attention <ref type="bibr" target="#b37">(Vaswani et al., 2017)</ref>. Besides, we extend a gradient harmonized loss to address the imbalance labels in the model training phase.</p><p>Our contributions are summarized as follows:</p><p>• A novel framework GRACE is proposed to address the aspect term-polarity co-extraction problem in an end-to-end fashion. It utilizes a cascaded labeling approach to consider the interaction between aspect terms when labeling their sentiment tags.</p><p>• The imbalance issue of labels is considered, and a gradient harmonized strategy is extended to alleviate it. We also use virtual adversarial training and post-training on domain datasets to improve co-extraction performance.</p><p>In the following, we describe the proposed framework GRACE in Section 2. The experiments are conducted in Section 3, followed by the related work in Section 4. Finally, we conclude the paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>An overview of GRACE is given in <ref type="figure" target="#fig_1">Figure 3</ref>. It is comprised of two modules with the shared shallow layers: one is for ATE, and the other is for ASC. We will first formulate the co-extraction problem and then describe the framework in detail in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Statement</head><p>This paper deals with aspect term-polarity coextraction, in which the aspect terms are explicitly mentioned in the text. We solve it as two sequence labeling tasks. Formally, given a review sentence S with n words from a particular domain, denoted by S = {w i |i = 1, . . . , n}. For each word w i , the objective of our task is to assign a tag t e i ∈ T e , and a tag t c i ∈ T c to it, where T e = {B, I, O} and T c = {POS, NEU, NEG, CON, O}. The tags 'B', 'I' and 'O' in T e stand for the beginning, the inside of an aspect term, and other words, respectively. The tags POS, NEU, NEG, and CON indicate polarity categories: positive, neutral, negative, and conflict, respectively 1 .  other words like that in T e . <ref type="figure">Figure 1</ref> shows a labeling example of the joint and collapsed approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GRACE: Gradient Harmonized and Cascaded Model</head><p>We focus on the joint labeling approach in the paper. As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, the proposed GRACE contains two branches with the shared shallow layers. In order to benefit from the pretrained model, we use the BERT-Base as our backbone. Then the representation H e of ATE can be generated on the pretrained BERT:</p><formula xml:id="formula_0">H [1:L] = BERT(S),<label>(1)</label></formula><formula xml:id="formula_1">H e = H L ,<label>(2)</label></formula><p>where H [1:L] denotes the representation of each layer of BERT. It varies from the 1st layer to the L-th layer. L is the max layer of BERT, e.g., 12 in BERT-Base. H e ∈ R (n+2)×h is the representation H L belonging to the last layer, in which two extra embeddings belong to special tokens [CLS] and <ref type="bibr">[SEP]</ref>, and the labels of them are set to 'O' in the experiments. h is the hidden size,n is the length of S after tokenizing by the wordpiece vocabulary. Different layers of BERT capture different levels of information, e.g., phrase-level information in the lower layers and linguistic information in intermediate layers <ref type="bibr" target="#b9">(Jawahar et al., 2019)</ref>. The higher layers are usually task-related. Thus, a shared BERT between ATE and ASC tasks is the right choice. We extract the representation H c for ASC task from the l-th layer of BERT:</p><formula xml:id="formula_2">H c = H l .<label>(3)</label></formula><p>Thus, H [l+1:L] is task-specific for ATE. An extreme state is l = L, where all layers are shared across both tasks. We omit an exhaustive description of BERT and refer readers to <ref type="bibr" target="#b3">Devlin et al. (2019)</ref> for more details.</p><p>Cascaded Labeling We can do sequence labeling on the H e and H c directly. However, it is not a customized feature for ASC. Conversely, ASC may decline the ATE performance. One reason is the difference between ATE and ASC. The polarity of an aspect term usually does not come from the term itself. For example, the polarity of aspect term "operating system" in <ref type="figure">Figure 1</ref> comes from the adjective "nice". When labeling the "operating system", the model needs to point to the "nice". The other reason is the interaction between aspect terms is ignored when labeling their sentiment labels. For example, the "operating system" and "keyboard" are connected by coordinating conjunction "and". If "operating system" is positive, "keyboard" should be positive, too. Thus, we propose the cascaded labeling approach, which uses the generated aspect terms sequence as the input to generate the sentiment sequence. As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, the H c is fed to a new Transformer-Decoder <ref type="bibr" target="#b37">(Vaswani et al., 2017)</ref> as key K and value V to generate a new aspect sentiment representation G c :</p><formula xml:id="formula_3">G c = Transformer-Decoder(H c , Q), (4)</formula><p>where Q represents the aspect term labels generated by the ATE module (ground-truth labels in the training phase). The vocab size is |T e | in the word embedding of the Transformer-Decoder.</p><p>Note that the Transformer-Decoder here is not the same as the original transformer decoder. The difference is that we use Multi-Head Attention instead of Masked Multi-Head Attention as the first sub-layer because the ASC is not an autoregressive task and does not need to predict the output sequence one element at a time. Gradient Harmonized Loss The cross entropy is used to train the model:</p><formula xml:id="formula_4">p τ = softmax(M τ w τ ),<label>(5)</label></formula><formula xml:id="formula_5">L τ = − 1 n n i=1 I (t τ i ) (log (p τ i )) ,<label>(6)</label></formula><formula xml:id="formula_6">where τ ∈ {e, c}, M = H if τ is e, and M = G if τ is c, I(t τ i ) means the one-hot vector of t τ i ∈ T τ , w τ is a trainable weight matrix.</formula><p>Then, the losses from both tasks are constructed as the joint loss of the entire model:</p><formula xml:id="formula_7">J (Θ) = L e + L c ,<label>(7)</label></formula><p>where L e and L c denote the loss for aspect term and polarity, respectively. Θ represents the model parameters containing all trainable weight matrices and bias vectors. However, there are two well-known disharmonies to affect the performance through the optimization of the above losses. The first one is the imbalance between positive and negative examples, and the other one is the imbalance between easy and hard examples . Specifically, there exists the imbalance between each label in our labeling task. As shown in <ref type="figure">Figure 2a</ref>, the label 'O' occupies a tremendous rate than other labels. According to the work from , the easy and hard attributes of labels can be represented by the norm of gradient g:</p><formula xml:id="formula_8">g = ∂L ∂z = |p −t|,<label>(8)</label></formula><p>wheret is the ground-truth with value 0 or 1, p is the score calculated by a softmax operation, z is the logit output of a model, L is the cross entropy. E.g., z = M τ w τ and p in Eq. (5), and L in Eq. (6). <ref type="figure">Figure 2b</ref> shows the statistic of labels w.r.t gradient norm g. Most of the labels own low gradients, which have a significant impact on the global gradient due to their large number. A strategy is to decrease the weight of loss from these labels.</p><p>We rewrite the Eq. (6) following GHM-C, which used in object detection , as follows:</p><formula xml:id="formula_9">L τ = − 1 n n i=1 β t τ i I (t τ i ) (log (p τ i )) ,<label>(9)</label></formula><formula xml:id="formula_10">β t τ i = N τ ρ g t τ i ,<label>(10)</label></formula><p>where g t τ i is the gradient norm of t τ i calculated by Eq. <ref type="formula" target="#formula_8">(8)</ref>, N τ is the total number of labels, ρ(g) is gradient density:</p><formula xml:id="formula_11">ρ(g) = 1 l (g) N τ k=1 δ (g k , g) ,<label>(11)</label></formula><p>where δ (x, y) is 1 if y − 2 ≤ x &lt; y + 2 otherwise 0. The ρ(g) denotes the number of labels lying in the region centered at g with a length of and normalized by the valid length</p><formula xml:id="formula_12">l (g) = min g + 2 , 1 − max g − 2 , 0 of the region.</formula><p>The calculation of β t τ i will use the unit region to reduce complexity. Specifically, the gradient norm g will put into m = 1/ unit regions. For the j-th unit region u j = j − , j , the gradient density can be approximated as:</p><formula xml:id="formula_13">ρ(g) = U ind(g) / = mU ind(g) ,<label>(12)</label></formula><p>where U j denotes the number of labels lying in u j ,</p><formula xml:id="formula_14">ind(g) = κ s.t. (κ − 1) ≤ g &lt; κ is the index of the unit region in which g lies.</formula><p>The calculation ofρ(g) assumpts that the examples lying in the same unit region share the same gradient density. So it can be calculated by the algorithm of histogram statistics.</p><p>A further reasonable manner is to statistics U (t) j in the t-th iteration to reduce the complexity of U j 's statistic cross the dataset, and uses A (t) j to approximate the real U j as follows:</p><formula xml:id="formula_15">A (t) j = αA (t−1) j + (1 − α)U (t) j ,<label>(13)</label></formula><p>where α is a momentum parameter. Thus, theρ(g) is updated by:</p><formula xml:id="formula_16">ρ(g) = A ind(g) / = mA ind(g) ,<label>(14)</label></formula><p>Virtual Adversarial Training To make the model more robust to adversarial noise, we utilize the virtual adversarial training (VAT) used in <ref type="bibr" target="#b29">(Miyato et al., 2016)</ref> to make small perturbations r to the input Token Embedding E when training model. The additional loss is as follows:</p><formula xml:id="formula_17">E * = E + r,<label>(15)</label></formula><formula xml:id="formula_18">L VAT = 1 n n i=1 D KL p(·|E;Θ) p (·|E * ;Θ) ,<label>(16)</label></formula><p>the adversarial perturbation r is calculated by:</p><formula xml:id="formula_19">E = E + ξd,<label>(17)</label></formula><formula xml:id="formula_20">g = ∇ E D KL p · |E;Θ p · |E ;Θ , (18) r = g/ g 2 ,<label>(19)</label></formula><p>where and ξ are hyperparameters, d is sampled from normal distribution N (0, I),Θ is a constant set to the current parameters Θ, D KL (· ·) is the KL divergence, p(·|·) is the model conditional probability.</p><p>On the whole, the total loss of the proposed GRACE is:</p><formula xml:id="formula_21">J (Θ) = L e + L c + L VAT ,<label>(20)</label></formula><p>where L e and L c are calculated by Eq. <ref type="formula" target="#formula_9">(9)</ref>, denote the loss for aspect term and polarity, respectively. L VAT denotes the VAT loss, calculated by Eq. <ref type="formula" target="#formula_0">(16)</ref>.</p><p>Consistent Polarity Label A question when regarding sentiment classification as polarity sequence labeling is that the generated sequence labels are not always consistent. For instance, the polarity labels may be 'POS NEG' for the aspect term 'operating system'. To solve this problem, we design a strategy on the representation of tokens within the same aspect term. To the generated sequence labels of ASC, we first get the boundaries of aspect terms according to the meaning of the label, e.g., Then the aspect sentiment representation G c , and the classification is calculated as follows:</p><formula xml:id="formula_22">g i = max(G c [b ind : e ind ]),<label>(21)</label></formula><formula xml:id="formula_23">h i = f (g i w h ),<label>(22)</label></formula><p>where G c [b ind : e ind ] is a snippet of G c from b ind to e ind (exclusive), max is a max-pooling operator along with the sequence dimension. w h is a trainable weight matrix. f (·) is the ReLU function. We use h i to calculate loss as Eq. (5) and Eq. (9). It is a consistent strategy to generate sentiment labels, although it cannot improve the performance in our preliminary experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We evaluate the proposed model on three benchmark sentiment analysis datasets, two of which  come from the SemEval challenges, and the last comes from an English Twitter dataset, as shown in <ref type="table" target="#tab_2">Table 1</ref>. D L contains laptop reviews from SemEval 2014 <ref type="bibr" target="#b33">(Pontiki et al., 2014)</ref>, and D R are restaurant reviews merged from SemEval 2014 (D R-14 ), Se-mEval 2015 (D R-15 ) <ref type="bibr" target="#b31">(Pontiki et al., 2015)</ref>, and Se-mEval 2016 (D R-16 ) <ref type="bibr" target="#b32">(Pontiki et al., 2016)</ref>. We keep the official data division of these datasets for the training set, validation set, and testing set. The reported results of D L and D R are average scores of 5 runs. D T consists of English tweets. Due to a lack of standard train-test split, we report the ten-fold cross-validation results of D T as done in <ref type="bibr" target="#b24">Luo et al., 2019b)</ref>. The evaluation metrics are precision (P), recall (R), and F1 score based on the exact match of aspect term and its polarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Post-training</head><p>Domain knowledge is proved useful for domainspecific tasks <ref type="bibr" target="#b44">(Xu et al., 2019;</ref><ref type="bibr" target="#b24">Luo et al., 2019b)</ref>. In this paper, we adopt Amazon reviews 2 and Yelp reviews 3 , which are in-domain corpora for laptop and restaurant, respectively, to do a post-training on uncased BERT-Base for our tasks. The Amazon review dataset contains 142.8M reviews, and the Yelp review dataset contains 2.2M restaurant reviews. We combine all these reviews to finish our post-training. The maximum length of posttraining is set to 320. The batch size is 4,096 for BERT-Base with gradient accumulation (every 32 steps). The BERT-Base is implemented base on the transformers library with Pytorch 4 . The mask strategy is Whole Word Masking (WWM), the same as the official BERT 5 . We use Adam optimizer and set the learning rate to be 5e-5 with 10% warmup steps.</p><p>Our pretrained model is carried out 10 epochs on 8 NVIDIA Tesla V100 GPU. We use fp16 to speed up training and to reduce memory usage. The pretraining process takes more than 5 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Settings</head><p>During fine-tuning on ATE and ASC tasks, the optimizer is Adam with 10% warmup steps. A twostage training strategy is utilized in our cascaded labeling model. In the first stage, we first finetune the ATE part initialized with the post-trained BERT weights. The learning rate is set to 3e-5 with 32 batch size, and running 5 epochs without virtual adversarial training. Then we plus virtual adversarial to continue to fine-tune 1 epoch for D L and 3 epochs for other datasets with learning rate 1e-5. In the second stage, we fine-tune both ATE and ASC modules initialized with the weights from the first stage. The ASC decoder is initialized with the last corresponding layers of the ATE module. The learning rate is set to 3e-5 for the ASC part and 3e-6 for the ATE part with 32 batch size, and running 10 epochs. The maximum length is set to 128 on all datasets. in Eq. <ref type="formula" target="#formula_0">(11)</ref> is 24, and the momentum parameter α in Eq. (13) is 0.75. ξ in Eq. <ref type="formula" target="#formula_0">(17)</ref> is set to 1e-6, and in Eq. <ref type="formula" target="#formula_0">(19)</ref> is set to 2. We set the shared layers l = 9, and the number of transformer layers for ASC to 2. All the above hyper-parameters are tuned on the validation set of D L and D R . We implement our GRACE using the same library as post-training, and all computations are done on NVIDIA Tesla V100 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Baseline Methods</head><p>We compare our model 6 with the following models: E2E-TBSA  is an end-to-end model of the collapsed approach proposed to address ATE and ASC simultaneously. DOER <ref type="bibr" target="#b24">(Luo et al., 2019b)</ref> employs a cross-shared unit to train the ATE and ASC jointly. SPAN <ref type="figure">(Hu et al., 2019)</ref> is a pipeline approach built on BERT-Large (SPAN Large ) to solve aspect term-sentiment pairs extraction. We implement its BERT-Base version (SPAN Base ) using the available code 7 . BERT-E2E-ABSA <ref type="bibr" target="#b18">(Li et al., 2019c</ref>) is a BERTbased benchmark for aspect term-sentiment pairs <ref type="bibr">6</ref> Code and pre-trained weights will be released at: https: //github.com/ArrowLuo/GRACE 7 https://github.com/huminghao16/ SpanABSA extraction. We use the BERT+GRU for D L and BERT+SAN for D R as our baselines due to their best-reported performance. Besides, we produce the results on D T with BERT+SAN keeping the settings the same as on D R 8 . We compare our model with the above baselines on D L , D R , and D T , and compare it with the following baselines on D L , D R-14 , D R-15 , and D R-16 because of the common datasets reported by the official implementation. IMN <ref type="bibr" target="#b5">(He et al., 2019)</ref> uses an interactive architecture with multi-task learning for end-to-end ABSA tasks. It contains aspect term and opinion term extraction besides aspect-level sentiment classification. DREGCN <ref type="bibr" target="#b19">(Liang et al., 2020a</ref>) designs a dependency syntactic knowledge augmented interactive architecture with multi-task learning for end-toend ABSA. DREGCN is short for the official DREGCN+CNN+BERT due to its better performance. WHW <ref type="bibr" target="#b30">(Peng et al., 2020</ref>) develops a two-stage framework to address aspect term extraction, aspect sentiment classification, and opinion extraction. TAS-BERT <ref type="bibr" target="#b38">(Wan et al., 2020)</ref> proposes a method based on BERT-Base that can capture the dependence on both aspect terms and categories for sentiment prediction. TAS-BERT is short for the official TAS-BERT-SW-BIO-CRF due to its better performance.</p><p>IKTN+BERT <ref type="bibr" target="#b20">(Liang et al., 2020b</ref>) discriminately transfers the document-level linguistic knowledge to aspect term, opinion term extraction, and aspectlevel sentiment classification. DHGNN  presents a dynamic heterogeneous graph to model the aspect extraction and sentiment detection explicitly jointly. RACL-BERT (Chen and Qian, 2020) is built on BERT-Large and allows the aspect term extraction, opinion term extraction, and aspect-level sentiment classification to work coordinately via the multitask learning and relation propagation mechanisms in a stacked multi-layer network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results and Analysis</head><p>Comparison Results. The comparison results are shown in <ref type="table" target="#tab_4">Table 2</ref> and <ref type="table">Table 3</ref> because different baselines officially report on different datasets. Overall, our proposed GRACE consistently ob-   <ref type="table">Table 3</ref>: Comparison results of F1 score (%) for aspect term-polarity pair extraction on four benchmark datasets. '-' denotes unreported results. '-w/o GHL', '-w/o VAT', and '-w/o PTR' have the same meaning as which in <ref type="table" target="#tab_4">Table 2.</ref> tains the best F1 score across all datasets and significantly outperforms the strongest baselines in most cases on aspect term-polarity co-extraction. Compared to the state-of-the-art pipeline approach, the GRACE outperforms SPAN Base by 8.50%, 6.50%, and 2.07% on D L , D R , and D T , respectively. Even comparing to SPAN Large built on 24-layers BERT-Large, the improvements are still 2.65%, 3.15%, and 0.59% on D L , D R , and D T , respectively. It indicates that a carefully-designed joint model has capable of achieving better performance than pipeline approaches on our task. Compared to other multi-task models containing additional information, e.g., opinion terms and aspect term categories, the GRACE achieves absolute gains over the IMN, WHW, TAS-BERT, IKTN+BERT,  and RACL-BERT at least by 7.31%, 1.84%, 2.05%, and 0.81% on D L , D R-14 , D R-15 , D R-16 , respectively. It suggests that GRACE can extend to more tasks of ABSA. Ablation Study. To study the effectiveness of the gradient harmonized loss (GHL), VAT, and postpretraining, we conduct ablation experiments on each of them. The results are shown in the second block in <ref type="table" target="#tab_4">Table 2 and Table 3</ref>. We can see that the scores drop more seriously without GHL comparing to that without VAT. It points out that GRACE can benefit more from the gradient harmonized loss than VAT, and alleviate the imbalance issue of labels is more important to the sequence labeling. The drop of scores without post-training is the worst on all laptop and restaurant datasets, which indicates that the domain-specific knowledge can improve the task-related datasets massively.</p><formula xml:id="formula_24">Model D L D R D T P R F1 P R F1 P R F1 E2E-</formula><formula xml:id="formula_25">Model D L D R D T DE-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on ATE.</head><p>As an extra output of the proposed GRACE, we also compare ATE results with   <ref type="table" target="#tab_6">Table 4</ref>. Our GRACE achieves state-of-the-art results over baselines. The lower scores of GRACE without the ASC branch indicate that the ASC task could enhance the ATE.</p><p>Results on Cascaded Labeling. To verify the effectiveness of our cascaded labeling strategy, as a particular case of the GRACE, we set the shared layers l = 12 and set the number of transformer layers for ASC to 0, and refer it as BASE. Thus, there is no generated aspect term label from ATE branch when training the ASC branch. The F1 scores of BASE are 68.35% and 76.76% on D L and D R , respectively. The results are lower than 70.71% and 78.07% of GRACE on the same datasets. This fact indicates that considering the interaction between aspect terms and paying more attention to other tokens are benefit to the sentiment labeling.</p><p>Case Study. <ref type="table" target="#tab_8">Table 5</ref> shows some examples of BASE, GRACE without gradient harmonized loss (w/o GHL), and GRACE sampled from D L and D R . As observed in the first two examples, the GRACE incorrectly predicts both aspect terms and their sentiments. Comparing with the BASE, we believe the cascaded labeling strategy can make an interaction between aspect terms within a sentence, which enhances the judgment of sentiment labels. The last two rows indicate that GRACE can get correct results, even the CON is minimal. The reason is not only the more comprehensive information proved by cascaded labeling strategy but also the balance of labels given by gradient harmonized loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Aspect term extraction and aspect sentiment classification are two major topics of aspect-based sentiment analysis. Many researchers have studied each of them for a long time. For the ATE task, unsupervised methods such as frequent pattern mining <ref type="bibr" target="#b8">(Hu and Liu, 2004)</ref>, rule-based approach <ref type="bibr" target="#b35">(Qiu et al., 2011;</ref><ref type="bibr" target="#b21">Liu et al., 2015)</ref>, topic modeling <ref type="bibr" target="#b6">(He et al., 2011;</ref><ref type="bibr" target="#b0">Chen et al., 2014)</ref>, and supervised methods such as sequence labeling based models <ref type="bibr" target="#b41">(Wang et al., 2016a;</ref><ref type="bibr" target="#b45">Yin et al., 2016;</ref><ref type="bibr" target="#b43">Xu et al., 2018;</ref><ref type="bibr" target="#b23">Luo et al., 2019a;</ref><ref type="bibr" target="#b26">Ma et al., 2019)</ref> are two main directions. For the ASC task, the relation or position between the aspect terms and the surrounding context words are usually used <ref type="bibr" target="#b36">(Tang et al., 2016;</ref><ref type="bibr" target="#b11">Laddha and Mukherjee, 2016)</ref>.</p><p>Besides, there are some other approaches, such as convolution neural networks <ref type="bibr" target="#b34">(Poria et al., 2016;</ref><ref type="bibr" target="#b15">Li and Xue, 2018)</ref>, attention networks <ref type="bibr" target="#b42">(Wang et al., 2016b;</ref><ref type="bibr" target="#b27">Ma et al., 2017;</ref><ref type="bibr" target="#b4">He et al., 2017)</ref>, memory networks , capsule network <ref type="bibr" target="#b1">(Chen and Qian, 2019)</ref>, and graph neural networks <ref type="bibr" target="#b39">(Wang et al., 2020)</ref>. We regard ATE and ASC as two parallel sequence labeling tasks in this paper. Compared with the separate methods, this approach can concisely generate all aspect term-polarity pairs of input sentences. Like our work, <ref type="bibr" target="#b28">Mitchell et al. (2013)</ref> and  are also about performing two sequence labeling tasks, but they extract named entities and their sentiment classes jointly. We have a different objective and utilize a different model. <ref type="bibr" target="#b13">Li and Lu (2017)</ref>, <ref type="bibr" target="#b25">Ma et al. (2018)</ref> and  have the same objective as us. The main difference is that their approaches belong to a collapsed approach, but ours is a joint approach. <ref type="bibr" target="#b24">Luo et al. (2019b)</ref> use joint approach like ours, they fo-cus on the interaction between two tasks, and some extra objectives are designed to assist the extraction. <ref type="bibr" target="#b44">Hu et al. (2019)</ref> consider the ATE as a span extraction question, and extract aspect term and its sentiment polarity using a pipeline approach. There are some other approaches to address these two tasks <ref type="bibr" target="#b18">(Li et al., 2019c;</ref><ref type="bibr" target="#b5">He et al., 2019;</ref><ref type="bibr" target="#b19">Liang et al., 2020a;</ref><ref type="bibr" target="#b30">Peng et al., 2020;</ref><ref type="bibr" target="#b38">Wan et al., 2020;</ref><ref type="bibr" target="#b20">Liang et al., 2020b;</ref><ref type="bibr" target="#b2">Chen and Qian, 2020)</ref>. However, almost all of previous models do not concern the imbalance of labels in such sequence labeling tasks. To the best of our knowledge, this is the first work to alleviate the imbalance issue in the ABSA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a novel framework GRACE to solve aspect term extraction and aspect sentiment classification simultaneously. The proposed framework adopted a cascaded labeling approach to enhance the interaction between aspect terms and improve the attention of sentiment tokens for each term by a multi-head attention architecture. Besides, we alleviated the imbalance issue of labels in our labeling tasks by a gradient harmonized method borrowed from object detection. The virtual adversarial training and post-training on domain datasets were also introduced to improve the extraction performance. Experimental results on three benchmark datasets verified the effectiveness of GRACE and showed that it significantly outperforms the baselines on aspect term-polarity co-extraction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Joint and Collapsed labeling approaches on aspect terms and their polarities. POS means positive. Label statistics and gradient distribution on the laptop dataset of SemEval-14. The y-axis in (b) uses a log scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The main structure of our GRACE. It is a cascaded labeling architecture, which means that the generated aspect term labels[O,B,I,O,B]  are fed to the right part as key K and value V to generate sentiment labels[O,POS,POS,O,POS]. The perturbed embeddings r · is added to the Token embeddings E · .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>the boundary of the labels 'O B I O B' in Figure 3 is {[1, 2), [2, 4), [2, 4), [4, 5), [5, 6)}, in which the element [b ind , e ind ) means begin index (inclusive) and end index (exclusive).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics. D L , D R , and D T denote laptop, restaurant, and twitter datasets, respectively. #POS, #NEU, #NEG, and #CON refer to the number of positive, neutral, negative, and conflict polarity categories, respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>TBSA 61.27 54.89 57.90 68.64 71.01 69.80 53.08 43.56 48.01 DOER 61.43 59.31 60.35 80.32 66.54 72.78 55.54 47.79 51.37 SPAN Base 66.19 58.68 62.21 71.22 71.91 71.57 60.92 52.24 56.21 SPAN Large 69.46 66.72 68.06 76.14 73.74 74.92 60.72 55.02 57.69 BERT-E2E-ABSA 61.88 60.47 61.12 72.92 76.72 74.72 57.63 54.47 55.94 GRACE 72.38 69.12 70.71 75.95 80.31 78.07 58.36 58.22 58.28 -w/o GHL 68.64 65.90 67.24 75.16 78.66 76.87 55.53 55.62 55.56 -w/o VAT 72.28 67.67 69.89 75.75 79.97 77.80 56.81 58.41 57.58 -w/o PTR 66.39 61.70 63.96 73.28 76.53 74.87 57.26 58.86 58.04</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Comparison results (%) for aspect term-polarity pair extraction on three benchmark datasets. State-ofthe-art results are marked in bold. '-w/o GHL' means GRACE without gradient harmonized loss, '-w/o VAT' is GRACE without virtual adversarial training, and '-w/o PTR' is GRACE without post-training on BERT-Base.</figDesc><table><row><cell>Model</cell><cell>D L</cell><cell cols="3">D R-14 D R-15 D R-16</cell></row><row><cell>IMN</cell><cell cols="3">58.37 69.54 59.18</cell><cell>-</cell></row><row><cell>DREGCN</cell><cell cols="3">63.04 72.60 62.37</cell><cell>-</cell></row><row><cell>WHW</cell><cell cols="4">62.34 71.95 65.79 71.73</cell></row><row><cell>TAS-BERT</cell><cell>-</cell><cell>-</cell><cell cols="2">66.11 75.68</cell></row><row><cell cols="4">IKTN-BERT 62.34 71.75 62.33</cell><cell>-</cell></row><row><cell>DHGNN</cell><cell cols="3">59.61 68.91 58.37</cell><cell>-</cell></row><row><cell cols="4">RACL-BERT 63.40 75.42 66.05</cell><cell>-</cell></row><row><cell>GRACE</cell><cell cols="4">70.71 77.26 68.16 76.49</cell></row><row><cell cols="5">-w/o GHL 67.24 75.83 66.73 75.09</cell></row><row><cell cols="5">-w/o VAT 69.89 77.16 67.75 76.03</cell></row><row><cell cols="5">-w/o PTR 63.96 71.56 59.82 66.95</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: F1 score (%) comparison for aspect term ex-</cell></row><row><cell>traction. '-' denotes unreported results. '-w/o ASC'</cell></row><row><cell>means training without the ASC branch.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Case analysis on BASE, GRACE w/o GHL, and GRACE. means wrong prediction.</figDesc><table><row><cell>state-of-the-art baselines. DE-CNN (Xu et al.,</cell></row><row><cell>2018) adopts CNN training on general purpose</cell></row><row><cell>embeddings domain specific embeddings to fin-</cell></row><row><cell>ish ATE. BERT-PT (Xu et al., 2019) post-trains</cell></row><row><cell>BERTs weights using in-domain review datasets</cell></row><row><cell>and MRC dataset. It is implemented based on</cell></row><row><cell>BERT-Base. BERT-PT-AUG (Li et al., 2020) is an</cell></row><row><cell>improvement version of BERT-PT with a control-</cell></row><row><cell>lable data augmentation approach. BAT (Karimi</cell></row><row><cell>et al., 2020) is a BERT adversarial training model.</cell></row><row><cell>The results of the ATE are shown in</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We regard neutral as a polarity as many prior works.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://jmcauley.ucsd.edu/data/amazon/ 3 https://www.yelp.com/academic_dataset 4 https://huggingface.co/transformers 5 https://github.com/google-research/ bert</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://github.com/lixin4ever/ BERT-E2E-ABSA</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by National Key R&amp;D Program of China(2019YFB2101802)and Sichuan Key R&amp;D project (2020YFG0035).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aspect extraction with automated prior knowledge learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="347" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transfer capsule network for aspect level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyun</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="547" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Relation-aware collaborative learning for unified aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyun</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3685" to="3694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An unsupervised neural attention model for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Wee Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="388" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An interactive multi-task learning network for end-to-end aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Wee Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatically extracting polarity-bearing topics for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harith</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Open-domain targeted sentiment analysis via span-based extraction and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">What does BERT learn about the structure of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3651" to="3657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adversarial training for aspect-based sentiment analysis with bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akbar</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Prati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Full</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.11316</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extracting aspect specific opinion expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Laddha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="627" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient harmonized single-stage detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8577" to="8584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning latent sentiment scopes for entity-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3482" to="3489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conditional augmentation for aspect term extraction via masked sequence-tosequence generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Aspect based sentiment analysis with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2514" to="2523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A unified model for opinion target extraction and target sentiment prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6714" to="6721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Aspect term extraction with history attention and selective transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimou</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4194" to="4200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploiting BERT for end-to-end aspectbased sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">W-NUT@EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="34" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A dependency syntactic knowledge augmented interactive architecture for end-to-end aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01951</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">An iterative knowledge transfer network with routing for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01935</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automated rule selection for aspect extraction in opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1291" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Jointly modeling aspect and sentiment with dynamic heterogeneous graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06427</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving aspect term extraction with bidirectional dependency tree representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaishao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianrui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herwig</forename><surname>Unger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1201" to="1212" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DOER: dual cross-shared RNN for aspect term-polarity co-extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaishao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianrui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="591" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint learning for targeted sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4737" to="4742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploring sequence-tosequence learning in aspect term extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3538" to="3547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interactive attention networks for aspect-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4068" to="4074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Open domain targeted sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqui</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1643" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Adversarial training methods for semi-supervised text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07725</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Knowing what, how and why: a near complete solution for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 12: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval@NAACL-HLT</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="486" to="495" />
		</imprint>
	</monogr>
	<note>Suresh Manandhar, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 5: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval@NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Se-mEval@COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, and Suresh Manandhar</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Aspect extraction for opinion mining with a deep convolutional neural network. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Opinion word expansion and target extraction through double propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="27" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Effective lstms for target-dependent sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3298" to="3307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Target-aspect-sentiment joint detection for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunxun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Relational graph attention network for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhou</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Target-sensitive memory networks for aspect sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahisnu</forename><surname>Mazumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mianwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="957" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recursive neural conditional random fields for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="616" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attention-based lstm for aspectlevel sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Double embeddings and cnn-based sequence labeling for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="592" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">BERT post-training for review reading comprehension and aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2324" to="2335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised word and dependency path embeddings for aspect term extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaimeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2979" to="2985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural networks for open domain targeted sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy Tin</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="612" to="621" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
