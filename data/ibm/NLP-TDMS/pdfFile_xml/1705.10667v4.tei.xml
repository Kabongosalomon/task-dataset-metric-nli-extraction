<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conditional Adversarial Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Research Center for Big Data</orgName>
								<orgName type="laboratory">KLiss</orgName>
								<orgName type="institution" key="instit1">MOE; BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>Berkeley</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Research Center for Big Data</orgName>
								<orgName type="laboratory">KLiss</orgName>
								<orgName type="institution" key="instit1">MOE; BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>Berkeley</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
							<email>jimwang@tsinghua.edu.cncaozhangjie14@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Research Center for Big Data</orgName>
								<orgName type="laboratory">KLiss</orgName>
								<orgName type="institution" key="instit1">MOE; BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>Berkeley</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
							<email>jordan@berkeley.edu</email>
						</author>
						<title level="a" type="main">Conditional Adversarial Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may not effectively align different domains of multimodal distributions native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the crosscovariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. With theoretical guarantees and a few lines of codes, the approach has exceeded state-of-the-art results on five datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep networks have significantly improved the state-of-the-arts for diverse machine learning problems and applications. When trained on large-scale datasets, deep networks learn representations which are generically useful across a variety of tasks <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b53">54]</ref>. However, deep networks can be weak at generalizing learned knowledge to new datasets or environments. Even a subtle change from the training domain can cause deep networks to make spurious predictions on the target domain <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b35">36]</ref>. While in many real applications, there is the need to transfer a deep network from a source domain where sufficient training data is available to a target domain where only unlabeled data is available, such a transfer learning paradigm is hindered by the shift in data distributions across domains <ref type="bibr" target="#b38">[39]</ref>.</p><p>Learning a model that reduces the dataset shift between training and testing distributions is known as domain adaptation <ref type="bibr" target="#b37">[38]</ref>. Previous domain adaptation methods in the shallow regime either bridge the source and target by learning invariant feature representations or estimating instance importances using labeled source data and unlabeled target data <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b14">15]</ref>. Recent advances of deep domain adaptation methods leverage deep networks to learn transferable representations by embedding adaptation modules in deep architectures, simultaneously disentangling the explanatory factors of variations behind data and matching feature distributions across domains <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>Adversarial domain adaptation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b50">51]</ref> integrates adversarial learning and domain adaptation in a two-player game similarly to Generative Adversarial Networks (GANs) <ref type="bibr" target="#b16">[17]</ref>. A domain discriminator is learned by minimizing the classification error of distinguishing the source from the target domains, while a deep classification model learns transferable representations that are indistinguishable by the domain discriminator. On par with these feature-level approaches, generative pixel-level adaptation models perform distribution alignment in raw pixel space, by translating source data to the style of a target domain using Image to Image translation techniques <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b42">43]</ref>. Another line of works align distributions of features and classes separately using different domain discriminators <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b49">50]</ref>. <ref type="bibr">32nd</ref> Conference on Neural Information Processing Systems (NeurIPS 2018), Montr√©al, Canada.</p><p>Despite their general efficacy for various tasks ranging from classification <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b27">28]</ref> to segmentation <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b21">22]</ref>, these adversarial domain adaptation methods may still be constrained by two bottlenecks. First, when data distributions embody complex multimodal structures, adversarial adaptation methods may fail to capture such multimodal structures for a discriminative alignment of distributions without mode mismatch. Such a risk comes from the equilibrium challenge of adversarial learning in that even if the discriminator is fully confused, we have no guarantee that two distributions are sufficiently similar <ref type="bibr" target="#b2">[3]</ref>. Note that this risk cannot be tackled by aligning distributions of features and classes via separate domain discriminators as <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b49">50]</ref>, since the multimodal structures can only be captured sufficiently by the cross-covariance dependency between the features and classes <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b43">44]</ref>. Second, it is risky to condition the domain discriminator on the discriminative information when it is uncertain.</p><p>In this paper, we tackle the two aforementioned challenges by formalizing a conditional adversarial domain adaptation framework. Recent advances in the Conditional Generative Adversarial Networks (CGANs) <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref> disclose that the distributions of real and generated images can be made similar by conditioning the generator and discriminator on discriminative information. Motivated by the conditioning insight, this paper presents Conditional Domain Adversarial Networks (CDANs) to exploit discriminative information conveyed in the classifier predictions to assist adversarial adaptation.</p><p>The key to the CDAN models is a novel conditional domain discriminator conditioned on the crosscovariance of domain-specific feature representations and classifier predictions. We further condition the domain discriminator on the uncertainty of classifier predictions, prioritizing the discriminator on easy-to-transfer examples. The overall system can be solved in linear-time through back-propagation. Based on the domain adaptation theory <ref type="bibr" target="#b3">[4]</ref>, we give a theoretical guarantee on the generalization error bound. Experiments show that our models exceed state-of-the-art results on five benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Domain adaptation <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> generalizes a learner across different domains of different distributions, by either matching the marginal distributions <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b14">15]</ref> or the conditional distributions <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b9">10]</ref>. It finds wide applications in computer vision <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref> and natural language processing <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref>. Besides the aforementioned shallow architectures, recent studies reveal that deep networks learn more transferable representations that disentangle the explanatory factors of variations behind data <ref type="bibr" target="#b5">[6]</ref> and manifest invariant factors underlying different populations <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b35">36]</ref>. As deep representations can only reduce, but not remove, the cross-domain distribution discrepancy <ref type="bibr" target="#b53">[54]</ref>, recent research on deep domain adaptation further embeds adaptation modules in deep networks using two main technologies for distribution matching: moment matching <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b29">30]</ref> and adversarial training <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>Pioneered by the Generative Adversarial Networks (GANs) <ref type="bibr" target="#b16">[17]</ref>, the adversarial learning has been successfully explored for generative modeling. GANs constitute two networks in a two-player game: a generator that captures data distribution and a discriminator that distinguishes between generated samples and real data. The networks are trained in a minimax paradigm such that the generator is learned to fool the discriminator while the discriminator struggles to be not fooled. Several difficulties of GANs have been addressed, e.g. improved training <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1]</ref> and mode collapse <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b34">35]</ref>, but others still remain, e.g. failure in matching two distributions <ref type="bibr" target="#b2">[3]</ref>. Towards adversarial learning for domain adaptation, unconditional ones have been leveraged while conditional ones remain under explored.</p><p>Sharing some spirit of the conditional GANs <ref type="bibr" target="#b2">[3]</ref>, another line of works match the features and classes using separate domain discriminators. Hoffman et al. <ref type="bibr" target="#b22">[23]</ref> performs global domain alignment by learning features to deceive the domain discriminator, and category specific adaptation by minimizing a constrained multiple instance loss. In particular, the adversarial module for feature representation is not conditioned on the class-adaptation module with class information. Chen et al. <ref type="bibr" target="#b7">[8]</ref> performs classwise alignment over the classifier layer; i.e., multiple domain discriminators take as inputs only the softmax probabilities of source classifier, rather than conditioned on the class information. Tsai et al. <ref type="bibr" target="#b49">[50]</ref> imposes two independent domain discriminators on the feature and class layers. These methods do not explore the dependency between the features and classes in a unified conditional domain discriminator, which is important to capture the multimodal structures underlying data distributions. This paper extends the conditional adversarial mechanism to enable discriminative and transferable domain adaptation, by defining the domain discriminator on the features while conditioning it on the class information. Two novel conditioning strategies are designed to capture the cross-covariance dependency between the feature representations and class predictions while controlling the uncertainty of classifier predictions. This is different from aligning the features and classes separately <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b49">50</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conditional Adversarial Domain Adaptation</head><p>In unsupervised domain adaptation, we are given a source domain D s = {(x s i , y s i )} ns i=1 of n s labeled examples and a target domain D t = {x t j } nt j=1 of n t unlabeled examples. The source domain and target domain are sampled from joint distributions P (x s , y s ) and Q(x t , y t ) respectively, and the i.i.d. assumption is violated as P = Q. The goal of this paper is to design a deep network G : x ‚Üí y which formally reduces the shifts in the data distributions across domains, such that the target risk t (G) = E (x t ,y t )‚àºQ [G (x t ) = y t ] can be bounded by the source risk s (G) = E (x s ,y s )‚àºP [G (x s ) = y s ] plus the distribution discrepancy disc(P, Q) quantified by a novel conditional domain discriminator.</p><p>Adversarial learning, the key idea to enabling Generative Adversarial Networks (GANs) <ref type="bibr" target="#b16">[17]</ref>, has been successfully explored to minimize the cross-domain discrepancy <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b50">51]</ref>. Denote by f = F (x) the feature representation and by g = G (x) the classifier prediction generated from the deep network G. Domain adversarial neural network (DANN) <ref type="bibr" target="#b12">[13]</ref> is a two-player game: the first player is the domain discriminator D trained to distinguish the source domain from the target domain and the second player is the feature representation F trained simultaneously to confuse the domain discriminator D.</p><p>The error function of the domain discriminator corresponds well to the discrepancy between feature distributions P (f ) and Q(f ) <ref type="bibr" target="#b11">[12]</ref>, a key to bound the target risk in the domain adaptation theory <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Conditional Discriminator</head><p>We further improve existing adversarial domain adaptation methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b50">51]</ref> in two directions. First, when the joint distributions of feature and class, i.e. P (x s , y s ) and Q(x t , y t ), are non-identical across domains, adapting only the feature representation f may be insufficient. Due to a quantitative study <ref type="bibr" target="#b53">[54]</ref>, deep representations eventually transition from general to specific along deep networks, with transferability decreased remarkably in the domain-specific feature layer f and classifier layer g. Second, when the feature distribution is multimodal, which is a real scenario due to the nature of multi-class classification, adapting only the feature representation may be challenging for adversarial networks. Recent work [17, 2, 7, 1] reveals the high risk of failure in matching only a fraction of components underlying different distributions with the adversarial networks. Even if the discriminator is fully confused, we have no theoretical guarantee that two different distributions are identical <ref type="bibr" target="#b2">[3]</ref>. This paper tackles the two aforementioned challenges by formalizing a conditional adversarial domain adaptation framework. Recent advances in Conditional Generative Adversarial Networks (CGANs) <ref type="bibr" target="#b33">[34]</ref> discover that different distributions can be matched better by conditioning the generator and discriminator on relevant information, such as associated labels and affiliated modality. Conditional GANs <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b34">35]</ref> generate globally coherent images from datasets with high variability and multimodal distributions. Motivated by conditional GANs, we observe that in adversarial domain adaptation, the classifier prediction g conveys discriminative information potentially revealing the multimodal structures, which can be conditioned on when adapting feature representation f . By conditioning, domain variances in both feature representation f and classifier prediction g can be modeled simultaneously.</p><p>We formulate Conditional Domain Adversarial Network (CDAN) as a minimax optimization problem with two competitive error terms: (a) E(G) on the source classifier G, which is minimized to guarantee lower source risk; (b) E(D, G) on the source classifier G and the domain discriminator D across the source and target domains, which is minimized over D but maximized over f = F (x) and g = G(x):</p><formula xml:id="formula_0">E(G) = E (x s i ,y s i )‚àºDs L (G (x s i ) , y s i ) ,<label>(1)</label></formula><formula xml:id="formula_1">E(D, G) = ‚àíE x s i ‚àºDs log [D (f s i , g s i )] ‚àí E x t j ‚àºDt log 1 ‚àí D f t j , g t j ,<label>(2)</label></formula><p>where L(¬∑, ¬∑) is the cross-entropy loss, and h = (f , g) is the joint variable of feature representation f and classifier prediction g. The minimax game of conditional domain adversarial network (CDAN) is</p><formula xml:id="formula_2">min G E(G) ‚àí ŒªE(D, G) min D E(D, G),<label>(3)</label></formula><p>where Œª is a hyper-parameter between the two objectives to tradeoff source risk and domain adversary.</p><p>We condition domain discriminator D on the classifier prediction g through joint variable h = (f , g). This conditional domain discriminator can potentially tackle the two aforementioned challenges of adversarial domain adaptation. A simple conditioning of D is D(f ‚äï g), where we concatenate the feature representation and classifier prediction in vector f ‚äï g and feed it to conditional domain discriminator D. This conditioning strategy is widely adopted by existing conditional GANs <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35]</ref>. However, with the concatenation strategy, f and g are independent on each other, thus failing to fully capture multiplicative interactions between feature representation and classifier prediction, which are crucial to domain adaptation. As a result, the multimodal information conveyed in classifier prediction cannot be fully exploited to match the multimodal distributions of complex domains <ref type="bibr" target="#b46">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multilinear Conditioning</head><p>The multilinear map is defined as the outer product of multiple random vectors. And the multilinear map of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint distribution or conditional distribution into reproducing kernel Hilbert spaces <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b29">30]</ref>. Given two random vectors x and y, the joint distribution P (x, y) can be modeled by the cross-covariance</p><formula xml:id="formula_3">E xy [œÜ(x) ‚äó œÜ(y)],</formula><p>where œÜ is a feature map induced by some reproducing kernel. Such kernel embeddings enable manipulation of the multiplicative interactions across multiple random variables.</p><p>Besides the theoretical benefit of the multilinear map x ‚äó y over the concatenation x ‚äï y <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b45">46]</ref>, we further explain its superiority intuitively. Assume linear map œÜ(x) = x and one-hot label vector y in C classes. As can be verified,</p><formula xml:id="formula_4">mean map E xy [x ‚äï y] = E x [x] ‚äï E y [y] computes the means of x and y independently. In contrast, mean map E xy [x ‚äó y] = E x [x|y = 1] ‚äï . . . ‚äï E x [x|y = C]</formula><p>computes the means of each of the C class-conditional distributions P (x|y). Superior than concatenation, the multilinear map x ‚äó y can fully capture the multimodal structures behind complex data distributions.</p><p>Taking the advantage of multilinear map, in this paper, we condition D on g with the multilinear map</p><formula xml:id="formula_5">T ‚äó (f , g) = f ‚äó g, (4) where T ‚äó is a multilinear map and D(f , g) = D(f ‚äó g).</formula><p>As such, the conditional domain discriminator successfully models the multimodal information and joint distributions of f and g. Also, the multi-linearity can accommodate random vectors f and g with different cardinalities and magnitudes.</p><p>A disadvantage of the multilinear map is dimension explosion. Denoting by d f and d g the dimensions of vectors f and g respectively, the dimension of multilinear map f ‚äó g is d f √ó d g , often too highdimensional to be embedded into deep networks without causing parameter explosion. This paper addresses the dimension explosion by randomized methods <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b25">26]</ref>. Note that multilinear map holds</p><formula xml:id="formula_6">T ‚äó (f , g) , T ‚äó (f , g ) = f ‚äó g, f ‚äó g = f , f g, g ‚âà T (f , g) , T (f , g ) ,<label>(5)</label></formula><p>where T (f , g) is the explicit randomized multilinear map of dimension d d f √ó d g . We define</p><formula xml:id="formula_7">T (f , g) = 1 ‚àö d (R f f ) (R g g) ,<label>(6)</label></formula><p>where is element-wise product, R f and R g are random matrices sampled only once and fixed in training, and each element R ij follows a symmetric distribution with univariance, i.e. E [R ij ] = 0, E[R 2 ij ] = 1. Applicable distributions include Gaussian distribution and Uniform distribution. As the inner-product on T ‚äó can be accurately approximated by the inner-product on T , we can directly adopt T (f , g) for computation efficiency. We guarantee such approximation quality by a theorem. Theorem 1. The expectation and variance of using</p><formula xml:id="formula_8">T (f , g) (6) to approximate T ‚äó (f , g) (4) satisfy E [ T (f , g) , T (f , g ) ] = f , f g, g , var [ T (f , g) , T (f , g ) ] = d i=1 Œ≤ R f i , f Œ≤ (R g i , g) + C,<label>(7)</label></formula><p>where</p><formula xml:id="formula_9">Œ≤ R f i , f = 1 d d f j=1 [f 2 j f j 2 E[(R f ij ) 4 ] + C ]</formula><p>and similarly for Œ≤ (R g i , g), C, C are constants.</p><p>Proof. The proof is given in the supplemental material.</p><p>This verifies that T is an unbiased estimate of T ‚äó in terms of inner product, with estimation variance depending only on the fourth-order moments E[(R f ij ) <ref type="bibr" target="#b3">4</ref> ] and E[(R g ij ) <ref type="bibr" target="#b3">4</ref> ], which are constants for many symmetric distributions with univariance, including Gaussian distribution and Uniform distribution. The bound reveals that wen can further minimize the approximation error by normalizing the features.</p><p>For simplicity we define the conditioning strategy used by the conditional domain discriminator D as</p><formula xml:id="formula_10">T (h) = T ‚äó (f , g) if d f √ó d g 4096 T (f , g) otherwise,<label>(8)</label></formula><p>where 4096 is the largest number of units in typical deep networks (e.g. AlexNet), and if dimension of the multilinear map T ‚äó is larger than 4096, then we will choose randomized multilinear map T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conditional Domain Adversarial Network</head><p>We enable conditional adversarial domain adaptation over domain-specific feature representation f and classifier prediction g. We jointly minimize <ref type="formula" target="#formula_0">(1)</ref>  </p><formula xml:id="formula_11">+ Œª E x s i ‚àºDs log [D (T (h s i ))] + E x t j ‚àºDt log 1 ‚àí D T h t j max D E x s i ‚àºDs log [D (T (h s i ))] + E x t j ‚àºDt log 1 ‚àí D T h t j ,<label>(9)</label></formula><p>where Œª is a hyper-parameter between source classifier and conditional domain discriminator, and note that h = (f , g) is the joint variable of domain-specific feature representation f and classifier prediction g for adversarial adaptation. As a rule of thumb, we can safely set f as the last feature layer representation and g as the classifier layer prediction. In cases where lower-layer features are not transferable as in pixel-level adaptation tasks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b21">22]</ref>, we can change f to lower-layer representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entropy Conditioning</head><p>The minimax problem for the conditional domain discriminator (9) imposes equal importance for different examples, while hard-to-transfer examples with uncertain predictions may deteriorate the conditional adversarial adaptation procedure. Towards safe transfer, we quantify the uncertainty of classifier predictions by the entropy criterion H (g) = ‚àí C c=1 g c log g c , where C is the number of classes and g c is the probability of predicting an example to class c. We prioritize the discriminator on those easy-to-transfer examples with certain predictions by reweighting each training example of the conditional domain discriminator by an entropy-aware weight w(H (g)) = 1+e ‚àíH(g) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The entropy conditioning variant of CDAN (CDAN+E) for improved transferability is formulated as min</head><formula xml:id="formula_12">G E (x s i ,y s i )‚àºDs L (G (x s i ) , y s i ) + Œª E x s i ‚àºDs w (H (g s i )) log [D (T (h s i ))] + E x t j ‚àºDt w H g t j log 1 ‚àí D T h t j max D E x s i ‚àºDs w (H (g s i )) log [D (T (h s i ))] + E x t j ‚àºDt w H g t j log 1 ‚àí D T h t j .<label>(10)</label></formula><p>The domain discriminator empowers the entropy minimization principle <ref type="bibr" target="#b18">[19]</ref> and encourages certain predictions, enabling CDAN+E to further perform semi-supervised learning on unlabeled target data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Generalization Error Analysis</head><p>We give an analysis of the CDAN method taking similar formalism of the domain adaptation theory <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4]</ref>. We first consider the source and target domains over the fixed representation space f = F (x), and a family of source classifiers G in hypothesis space H <ref type="bibr" target="#b12">[13]</ref>. Denote by P (G) = E (f ,y)‚àºP [G (f ) = y] the risk of a hypothesis G ‚àà H w.r.t. distribution P , and P (G 1 ,</p><formula xml:id="formula_13">G 2 ) = E (f ,y)‚àºP [G 1 (f ) = G 2 (f )]</formula><p>the disagreement between hypotheses G 1 , G 2 ‚àà H. Let G * = arg min G P (G) + Q (G) be the ideal hypothesis that explicitly embodies the notion of adaptability. The probabilistic bound <ref type="bibr" target="#b3">[4]</ref> of the target risk Q (G) of hypothesis G is given by the source risk P (G) plus the distribution discrepancy</p><formula xml:id="formula_14">Q (G) P (G) + [ P (G * ) + Q (G * )] + | P (G, G * ) ‚àí Q (G, G * )| .<label>(11)</label></formula><p>The goal of domain adaptation is to reduce the distribution discrepancy | P (G, G * ) ‚àí Q (G, G * )|.</p><formula xml:id="formula_15">By definition, P (G, G * ) = E (f ,y)‚àºP [G (f ) = G * (f )] = E (f ,g)‚àºP G [g = G * (f )] = P G (G * ), and similarly, Q (G, G * ) = Q G (G * ). Note that, P G = (f , G (f )) f ‚àºP (f ) and Q G = (f , G (f )) f ‚àºQ(f )</formula><p>are the proxies of the joint distributions P (f , y) and Q(f , y), respectively <ref type="bibr" target="#b9">[10]</ref>. Based on the proxies,</p><formula xml:id="formula_16">| P (G, G * ) ‚àí Q (G, G * )| = | P G (G * ) ‚àí Q G (G * )|. Define a (loss) difference hypothesis space ‚àÜ {Œ¥ = |g ‚àí G * (f )| : G * ‚àà H} over the joint variable (f , g), where Œ¥ : (f , g) ‚Üí {0</formula><p>, 1} outputs the loss of G * ‚àà H. Based on the above difference hypothesis space ‚àÜ, we define the ‚àÜ-distance as</p><formula xml:id="formula_17">d‚àÜ (PG, QG) sup Œ¥‚àà‚àÜ E (f ,g)‚àºP G [Œ¥ (f , g) = 0] ‚àí E (f ,g)‚àºQ G [Œ¥ (f , g) = 0] = sup G * ‚ààH E (f ,g)‚àºP G [|g ‚àí G * (f )| = 0] ‚àí E (f ,g)‚àºQ G [|g ‚àí G * (f )| = 0] E (f ,g)‚àºP G [g = G * (f )] ‚àí E (f ,g)‚àºQ G [g = G * (f )] = | P G (G * ) ‚àí Q G (G * )| .<label>(12)</label></formula><p>Hence, the domain discrepancy | P (G, G * ) ‚àí Q (G, G * )| can be upper-bounded by the ‚àÜ-distance.</p><p>Since the difference hypothesis space ‚àÜ is a continuous function class, assume the family of domain discriminators H D is rich enough to contain ‚àÜ, ‚àÜ ‚äÇ H D . Such an assumption is not unrealistic as we have the freedom to choose H D , for example, a multilayer perceptrons that can fit any functions. Given these assumptions, we show that training domain discriminator D is related to d ‚àÜ (P G , Q G ):</p><formula xml:id="formula_18">d ‚àÜ (P G , Q G ) sup D‚ààH D E (f ,g)‚àºP G [D (f , g) = 0] ‚àí E (f ,g)‚àºQ G [D (f , g) = 0] sup D‚ààH D E (f ,g)‚àºP G [D (f , g) = 1] + E (f ,g)‚àºQ G [D (f , g) = 0] .<label>(13)</label></formula><p>This supremum is achieved in the process of training the optimal discriminator D in CDAN, giving an upper bound of d ‚àÜ (P G , Q G ). Simultaneously, we learn representation f to minimize d ‚àÜ (P G , Q G ), yielding better approximation of Q (G) by P (G) to bound the target risk in the minimax paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate the proposed conditional domain adversarial networks with many state-of-the-art transfer learning and deep learning methods. Codes will be available at http://github.com/thuml/CDAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Office-31 <ref type="bibr" target="#b41">[42]</ref> is the most widely used dataset for visual domain adaptation, with 4,652 images and 31 categories collected from three distinct domains: Amazon (A), Webcam (W) and DSLR (D). We evaluate all methods on six transfer tasks A ‚Üí W, D ‚Üí W, W ‚Üí D, A ‚Üí D, D ‚Üí A, and W ‚Üí A.</p><p>ImageCLEF-DA 1 is a dataset organized by selecting the 12 common classes shared by three public datasets (domains): Caltech-256 (C), ImageNet ILSVRC 2012 (I), and Pascal VOC 2012 (P). We permute all three domains and build six transfer tasks: I ‚Üí P, P ‚Üí I, I ‚Üí C, C ‚Üí I, C ‚Üí P, P ‚Üí C.</p><p>Office-Home [53] is a better organized but more difficult dataset than Office-31, which consists of 15,500 images in 65 object classes in office and home settings, forming four extremely dissimilar domains: Artistic images (Ar), Clip Art (Cl), Product images (Pr), and Real-World images (Rw).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digits</head><p>We investigate three digits datasets: MNIST, USPS, and Street View House Numbers (SVHN). We adopt the evaluation protocol of CyCADA <ref type="bibr" target="#b21">[22]</ref> with three transfer tasks: USPS to MNIST (U ‚Üí M), MNIST to USPS (M ‚Üí U), and SVHN to MNIST (S ‚Üí M). We train our model using the training sets: MNIST (60,000), USPS (7,291), standard SVHN train (73,257). Evaluation is reported on the standard test sets: MNIST (10,000), USPS (2,007) (the numbers of images are in parentheses).</p><p>VisDA-2017 2 is a challenging simulation-to-real dataset, with two very distinct domains: Synthetic, renderings of 3D models from different angles and with different lightning conditions; Real, natural images. It contains over 280K images across 12 classes in the training, validation and test domains.</p><p>We compare Conditional Domain Adversarial Network (CDAN) with state-of-art domain adaptation methods: Deep Adaptation Network (DAN) <ref type="bibr" target="#b28">[29]</ref>, Residual Transfer Network (RTN) <ref type="bibr" target="#b30">[31]</ref>, Domain Adversarial Neural Network (DANN) <ref type="bibr" target="#b12">[13]</ref>, Adversarial Discriminative Domain Adaptation (ADDA) <ref type="bibr" target="#b50">[51]</ref>, Joint Adaptation Network (JAN) <ref type="bibr" target="#b29">[30]</ref>, Unsupervised Image-to-Image Translation (UNIT) <ref type="bibr" target="#b27">[28]</ref>, Generate to Adapt (GTA) <ref type="bibr" target="#b42">[43]</ref>, Cycle-Consistent Adversarial Domain Adaptation (CyCADA) <ref type="bibr" target="#b21">[22]</ref>.</p><p>We follow the standard protocols for unsupervised domain adaptation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>. We use all labeled source examples and all unlabeled target examples and compare the average classification accuracy based on three random experiments. We conduct importance-weighted cross-validation (IWCV) <ref type="bibr" target="#b47">[48]</ref> to select hyper-parameters for all methods. As CDAN performs stably under different parameters, we fix Œª = 1 for all experiments. For MMD-based methods (TCA, DAN, RTN, and JAN), we use Gaussian kernel with bandwidth set to median pairwise distances on training data <ref type="bibr" target="#b28">[29]</ref>. We adopt AlexNet <ref type="bibr" target="#b26">[27]</ref> and ResNet-50 <ref type="bibr" target="#b19">[20]</ref> as base networks and all methods differ only in their discriminators.</p><p>We implement AlexNet-based methods in Caffe and ResNet-based methods in PyTorch. We finetune from ImageNet pre-trained models <ref type="bibr" target="#b40">[41]</ref>, except the digit datasets that we train our models from scratch. We train the new layers and classifier layer through back-propagation, where the classifier is trained from scratch with learning rate 10 times that of the lower layers. We adopt mini-batch SGD with momentum of 0.9 and the learning rate annealing strategy as <ref type="bibr" target="#b12">[13]</ref>: the learning rate is adjusted by Œ∑ p = Œ∑ 0 (1 + Œ±p) ‚àíŒ≤ , where p is the training progress changing from 0 to 1, and Œ∑ 0 = 0.01, Œ± = 10, Œ≤ = 0.75 are optimized by the importance-weighted cross-validation <ref type="bibr" target="#b47">[48]</ref>. We adopt a progressive training strategy for the discriminator, increasing Œª from 0 to 1 by multiplying to 1‚àíexp(‚àíŒ¥p) 1+exp(‚àíŒ¥p) , Œ¥ = 10. <ref type="table">Table 1</ref>: Accuracy (%) on Office-31 for unsupervised domain adaptation (AlexNet and ResNet) </p><formula xml:id="formula_19">Method A ‚Üí W D ‚Üí W W ‚Üí D A ‚Üí D D ‚Üí A W ‚Üí A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The results on Office-31 based on AlexNet and ResNet are reported in <ref type="table">Table 1</ref>, with results of baselines directly reported from the original papers if protocol is the same. The CDAN models significantly outperform all comparison methods on most transfer tasks, where CDAN+E is a top-performing variant and CDAN performs slightly worse. It is desirable that CDAN promotes the classification accuracies substantially on hard transfer tasks, e.g. A ‚Üí W and A ‚Üí D, where the source and target domains are substantially different <ref type="bibr" target="#b41">[42]</ref>. Note that, CDAN+E even outperforms generative pixel-level domain adaptation method GTA, which has a very complex design in both architecture and objectives.</p><p>The results on the ImageCLEF-DA dataset are reported in <ref type="table" target="#tab_1">Table 2</ref>. The CDAN models outperform the comparison methods on most transfer tasks, but with smaller rooms of improvement. This is reasonable since the three domains in ImageCLEF-DA are of equal size and balanced in each category, and are visually more similar than Office-31, making the former dataset easier for domain adaptation.   The results on Office-Home are reported in <ref type="table" target="#tab_2">Table 3</ref>. The CDAN models substantially outperform the comparison methods on most transfer tasks, and with larger rooms of improvement. An interpretation is that the four domains in Office-Home are with more categories, are visually more dissimilar with each other, and are difficult in each domain with much lower in-domain classification accuracy <ref type="bibr" target="#b52">[53]</ref>. Since domain alignment is category agnostic in previous work, it is possible that the aligned domains are not classification friendly in the presence of large number of categories. It is desirable that CDAN models yield larger boosts on such difficult domain adaptation tasks, which highlights the power of adversarial domain adaptation by exploiting complex multimodal structures in classifier predictions.</p><p>Strong results are also achieved on the digits datasets and synthetic to real datasets as reported in <ref type="table" target="#tab_3">Table 4</ref>. Note that the generative pixel-level adaptation methods UNIT, CyCADA, and GTA are specifically tailored to the digits and synthetic to real adaptation tasks. This explains why the previous feature-level adaptation method JAN performs fairly weakly. To our knowledge, CDAN+E is the only approach that works reasonably well on all five datasets, and remains a simple discriminative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>Ablation Study We examine the sampling strategies of the random matrices in Equation <ref type="bibr" target="#b5">(6)</ref>. We testify CDAN+E (w/ gaussian sampling) and CDAN+E (w/ uniform sampling) with their random matrices sampled only once from Gaussian and Uniform distributions, respectively. <ref type="table" target="#tab_4">Table 5</ref> shows that CDAN+E (w/o random sampling) performs best while CDAN+E (w/ uniform sampling) performs the best across the randomized variants. <ref type="table" target="#tab_3">Table 1‚àº4</ref> shows that CDAN+E outperforms CDAN, proving that entropy conditioning can prioritize easy-to-transfer examples and encourage certain predictions.</p><p>Conditioning Strategies Besides multilinear conditioning, we investigate DANN-[f,g] with the domain discriminator imposed on the concatenation of f and g, DANN-f and DANN-g with the domain discriminator plugged in feature layer f and classifier layer g. <ref type="figure" target="#fig_2">Figure 2</ref>(a) shows accuracies on A ‚Üí W and A ‚Üí D based on ResNet-50. The concatenation strategy is not successful, as it cannot capture the cross-covariance between features and classes, which are crucial to domain adaptation <ref type="bibr" target="#b9">[10]</ref>. <ref type="figure" target="#fig_2">Figure 2(b)</ref> shows that the entropy weight e ‚àíH(g) corresponds well with the prediction correctness: entropy weight ‚âà 1 if the prediction is correct, and much smaller than 1 when prediction is incorrect (uncertain). This reveals the power of the entropy conditioning to guarantee example transferability. Distribution Discrepancy The A-distance is a measure for distribution discrepancy <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b32">33]</ref>, defined as dist A = 2 (1 ‚àí 2 ), where is the test error of a classifier trained to discriminate the source from target. <ref type="figure" target="#fig_2">Figure 2</ref>(c) shows dist A on tasks A ‚Üí W, W ‚Üí D with features of ResNet, DANN, and CDAN. We observe that dist A on CDAN features is smaller than dist A on both ResNet and DANN features, implying that CDAN features can reduce the domain gap more effectively. As domains W and D are similar, dist A of task W ‚Üí D is smaller than that of A ‚Üí W, implying higher accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A-&gt;W</head><p>Convergence We testify the convergence of ResNet, DANN, and CDANs, with the test errors on task A ‚Üí W shown in <ref type="figure" target="#fig_2">Figure 2(d)</ref>. CDAN enjoys faster convergence than DANN, while CDAN (M) converges faster than CDAN (RM). Note that CDAN (M) constitutes high-dimensional multilinear map, which is slightly more costly than CDAN (RM), while CDAN (RM) has similar cost as DANN. Visualization We visualize by t-SNE <ref type="bibr" target="#b31">[32]</ref> in Figures 3(a)-3(d) the representations of task A ‚Üí W (31 classes) by ResNet, DANN, CDAN-f, and CDAN-fg. The source and target are not aligned well with ResNet, better aligned with DANN but categories are not discriminated well. They are aligned better and categories are discriminated better by CDAN-f, while CDAN-fg is evidently better than CDAN-f. This shows the benefit of conditioning adversarial adaptation on discriminative predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presented conditional domain adversarial networks (CDANs), novel approaches to domain adaptation with multimodal distributions. Unlike previous adversarial adaptation methods that solely match the feature representation across domains which is prone to under-matching, the proposed approach further conditions the adversarial domain adaptation on discriminative information to enable alignment of multimodal distributions. Experiments validated the efficacy of the proposed approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Architectures of Conditional Domain Adversarial Networks (CDAN) for domain adaptation, where domain-specific feature representation f and classifier prediction g embody the cross-domain gap to be reduced jointly by the conditional domain discriminator D. (a) Multilinear (M) Conditioning, applicable to lower-dimensional scenario, where D is conditioned on classifier prediction g via multilinear map f ‚äó g; (b) Randomized Multilinear (RM) Conditioning, fit to higher-dimensional scenario, where D is conditioned on classifier prediction g via randomized multilinear map 1 ‚àö d (R f f ) (R g g). Entropy Conditioning (dashed line) leads to CDAN+E that prioritizes D on easy-to-transfer examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>w.r.t. source classifier G and feature extractor F , minimize (2) w.r.t. domain discriminator D, and maximize (2) w.r.t. feature extractor F and source classifier G. This yields the minimax problem of Conditional Domain Adversarial Network (CDAN): min G E (x s i ,y s i )‚àºDs L (G (x s i ) , y s i )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Analysis of conditioning strategies, distribution discrepancy, and convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>T-SNE of (a) ResNet, (b) DANN, (c) CDAN-f, (d) CDAN-fg (red: A; blue: W).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Accuracy (%) on ImageCLEF-DA for unsupervised domain adaptation (AlexNet and ResNet)</figDesc><table><row><cell>Method</cell><cell>I ‚Üí P</cell><cell>P ‚Üí I</cell><cell>I ‚Üí C</cell><cell>C ‚Üí I</cell><cell>C ‚Üí P</cell><cell>P ‚Üí C</cell><cell>Avg</cell></row><row><cell>AlexNet [27]</cell><cell>66.2¬±0.2</cell><cell>70.0¬±0.2</cell><cell>84.3¬±0.2</cell><cell>71.3¬±0.4</cell><cell>59.3¬±0.5</cell><cell>84.5¬±0.3</cell><cell>73.9</cell></row><row><cell>DAN [29]</cell><cell>67.3¬±0.2</cell><cell>80.5¬±0.3</cell><cell>87.7¬±0.3</cell><cell>76.0¬±0.3</cell><cell>61.6¬±0.3</cell><cell>88.4¬±0.2</cell><cell>76.9</cell></row><row><cell>DANN [13]</cell><cell>66.5¬±0.6</cell><cell>81.8¬±0.3</cell><cell>89.0¬±0.4</cell><cell>79.8¬±0.6</cell><cell>63.5¬±0.5</cell><cell>88.7¬±0.3</cell><cell>78.2</cell></row><row><cell>JAN [30]</cell><cell>67.2¬±0.5</cell><cell>82.8¬±0.4</cell><cell>91.3¬±0.5</cell><cell>80.0¬±0.5</cell><cell>63.5¬±0.4</cell><cell>91.0¬±0.4</cell><cell>79.3</cell></row><row><cell>CDAN</cell><cell>67.7¬±0.3</cell><cell>83.3¬±0.1</cell><cell>91.8¬±0.2</cell><cell>81.5¬±0.2</cell><cell>63.0¬±0.2</cell><cell>91.5¬±0.3</cell><cell>79.8</cell></row><row><cell>CDAN+E</cell><cell>67.0¬±0.4</cell><cell>84.8¬±0.2</cell><cell>92.4¬±0.3</cell><cell>81.3¬±0.3</cell><cell>64.7¬±0.3</cell><cell>91.6¬±0.4</cell><cell>80.3</cell></row><row><cell>ResNet-50 [20]</cell><cell>74.8¬±0.3</cell><cell>83.9¬±0.1</cell><cell>91.5¬±0.3</cell><cell>78.0¬±0.2</cell><cell>65.5¬±0.3</cell><cell>91.2¬±0.3</cell><cell>80.7</cell></row><row><cell>DAN [29]</cell><cell>74.5¬±0.4</cell><cell>82.2¬±0.2</cell><cell>92.8¬±0.2</cell><cell>86.3¬±0.4</cell><cell>69.2¬±0.4</cell><cell>89.8¬±0.4</cell><cell>82.5</cell></row><row><cell>DANN [13]</cell><cell>75.0¬±0.6</cell><cell>86.0¬±0.3</cell><cell>96.2¬±0.4</cell><cell>87.0¬±0.5</cell><cell>74.3¬±0.5</cell><cell>91.5¬±0.6</cell><cell>85.0</cell></row><row><cell>JAN [30]</cell><cell>76.8¬±0.4</cell><cell>88.0¬±0.2</cell><cell>94.7¬±0.2</cell><cell>89.5¬±0.3</cell><cell>74.2¬±0.3</cell><cell>91.7¬±0.3</cell><cell>85.8</cell></row><row><cell>CDAN</cell><cell>76.7¬±0.3</cell><cell>90.6¬±0.3</cell><cell>97.0¬±0.4</cell><cell>90.5¬±0.4</cell><cell>74.5¬±0.3</cell><cell>93.5¬±0.4</cell><cell>87.1</cell></row><row><cell>CDAN+E</cell><cell>77.7¬±0.3</cell><cell>90.7¬±0.2</cell><cell>97.7¬±0.3</cell><cell>91.3¬±0.3</cell><cell>74.2¬±0.2</cell><cell>94.3¬±0.3</cell><cell>87.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="5">: Accuracy (%) on Office-Home for unsupervised domain adaptation (AlexNet and ResNet)</cell></row><row><cell>Method</cell><cell cols="4">Ar Cl Ar Pr Ar Rw Cl Ar Cl Pr Cl Rw Pr Ar Pr Cl Pr Rw Rw Ar Rw Cl Rw Pr Avg</cell></row><row><cell cols="2">AlexNet [27] 26.4 32.6 41.3 22.1 41.7 42.1 20.5 20.3 51.1</cell><cell>31.0</cell><cell>27.9</cell><cell>54.9 34.3</cell></row><row><cell>DAN [29]</cell><cell>31.7 43.2 55.1 33.8 48.6 50.8 30.1 35.1 57.7</cell><cell>44.6</cell><cell>39.3</cell><cell>63.7 44.5</cell></row><row><cell cols="2">DANN [13] 36.4 45.2 54.7 35.2 51.8 55.1 31.6 39.7 59.3</cell><cell>45.7</cell><cell>46.4</cell><cell>65.9 47.3</cell></row><row><cell>JAN [30]</cell><cell>35.5 46.1 57.7 36.4 53.3 54.5 33.4 40.3 60.1</cell><cell>45.9</cell><cell>47.4</cell><cell>67.9 48.2</cell></row><row><cell>CDAN</cell><cell>36.2 47.3 58.6 37.3 54.4 58.3 33.2 43.9 62.1</cell><cell>48.2</cell><cell>48.1</cell><cell>70.7 49.9</cell></row><row><cell>CDAN+E</cell><cell>38.1 50.3 60.3 39.7 56.4 57.8 35.5 43.1 63.2</cell><cell>48.4</cell><cell>48.5</cell><cell>71.1 51.0</cell></row><row><cell cols="2">ResNet-50 [20] 34.9 50.0 58.0 37.4 41.9 46.2 38.5 31.2 60.4</cell><cell>53.9</cell><cell>41.2</cell><cell>59.9 46.1</cell></row><row><cell>DAN [29]</cell><cell>43.6 57.0 67.9 45.8 56.5 60.4 44.0 43.6 67.7</cell><cell>63.1</cell><cell>51.5</cell><cell>74.3 56.3</cell></row><row><cell cols="2">DANN [13] 45.6 59.3 70.1 47.0 58.5 60.9 46.1 43.7 68.5</cell><cell>63.2</cell><cell>51.8</cell><cell>76.8 57.6</cell></row><row><cell>JAN [30]</cell><cell>45.9 61.2 68.9 50.4 59.7 61.0 45.8 43.4 70.3</cell><cell>63.9</cell><cell>52.4</cell><cell>76.8 58.3</cell></row><row><cell>CDAN</cell><cell>49.0 69.3 74.5 54.4 66.0 68.4 55.6 48.3 75.9</cell><cell>68.4</cell><cell>55.4</cell><cell>80.5 63.8</cell></row><row><cell>CDAN+E</cell><cell>50.7 70.6 76.0 57.6 70.0 70.0 57.4 50.9 77.3</cell><cell>70.9</cell><cell>56.7</cell><cell>81.6 65.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Accuracy (%) on Digits and VisDA-2017 for unsupervised domain adaptation (ResNet-50)</figDesc><table><row><cell>Method</cell><cell>M ‚Üí U</cell><cell>U ‚Üí M</cell><cell>S ‚Üí M</cell><cell>Avg</cell><cell>Method</cell><cell>Synthetic ‚Üí Real</cell></row><row><cell>UNIT [28]</cell><cell>96.0</cell><cell>93.6</cell><cell>90.5</cell><cell>93.4</cell><cell>JAN [30]</cell><cell>61.6</cell></row><row><cell>CyCADA [22]</cell><cell>95.6</cell><cell>96.5</cell><cell>90.4</cell><cell>94.2</cell><cell>GTA [43]</cell><cell>69.5</cell></row><row><cell>CDAN</cell><cell>93.9</cell><cell>96.9</cell><cell>88.5</cell><cell>93.1</cell><cell>CDAN</cell><cell>66.8</cell></row><row><cell>CDAN+E</cell><cell>95.6</cell><cell>98.0</cell><cell>89.2</cell><cell>94.3</cell><cell>CDAN+E</cell><cell>70.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Accuracy (%) of CDAN variants on Office-31 for unsupervised domain adaptation (ResNet) / gaussian sampling) 93.0¬±0.2 98.4¬±0.2 100.0¬±.0 89.2¬±0.3 70.2¬±0.4 67.4¬±0.4 86.4 CDAN+E (w/ uniform sampling) 94.0¬±0.2 98.4¬±0.2 100.0¬±.0 89.8¬±0.3 70.1¬±0.4 69.4¬±0.4 87.0 CDAN+E (w/o random sampling) 94.1¬±0.1 98.6¬±0.1 100.0¬±.0 92.9¬±0.2 71.0¬±0.3 69.3¬±0.3 87.7</figDesc><table><row><cell>Method</cell><cell>A ‚Üí W</cell><cell>D ‚Üí W</cell><cell>W ‚Üí D</cell><cell>A ‚Üí D</cell><cell>D ‚Üí A</cell><cell>W ‚Üí A</cell><cell>Avg</cell></row><row><cell>CDAN+E (w</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://imageclef.org/2014/adaptation</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://ai.bu.edu/visda-2017/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Yuchen Zhang at Tsinghua University for insightful discussions. This work was supported by the National Key R&amp;D Program of China (2016YFB1000701), the Natural Science Foundation of China (61772299, 71690231, 61502265) and the DARPA Program on Lifelong Learning Machines.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalization and equilibrium in generative adversarial nets (gans)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Mode regularized generative adversarial networks. International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">No more discrimination: Cross city adaptation of road scene segmenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2011" to="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint distribution optimal transportation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3730" to="3739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Connecting the dots with landmarks: Discriminatively learning domaininvariant features for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain adaptation for object recognition: An unsupervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LSDA: Large scale detection through adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CyCADA: Cycleconsistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1989" to="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1612.02649</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Correcting sample selection bias by unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random feature maps for dot product kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Karnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="583" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="700" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Domain adaptation: Learning bounds and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computational Learning Theory (COLT</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning and transferring mid-level image representations using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Domain adaptation via transfer component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks (TNN)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="210" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Dataset shift in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1177" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ImageNet Large Scale Visual Recognition Challenge</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Generate to adapt: Aligning domains using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Hilbert space embeddings of hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boots</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Robust low rank kernel embeddings of multivariate distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3228" to="3236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Kernel embeddings of conditional distributions: A unified kernel framework for nonparametric inference in graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="98" to="111" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hilbert space embeddings of conditional distributions with applications to dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukumizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Covariate shift adaptation by importance weighted cross validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krauledat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="985" to="1005" />
			<date type="published" when="2007-05" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Direct importance estimation with model selection and its application to covariate shift adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Buenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Domain adaptation under target and conditional shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
