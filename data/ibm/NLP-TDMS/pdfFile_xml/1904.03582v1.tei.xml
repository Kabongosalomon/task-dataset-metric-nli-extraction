<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Label Image Recognition with Graph Convolutional Networks *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Megvii Research Nanjing</orgName>
								<orgName type="institution" key="instit2">Megvii Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Megvii Research Nanjing</orgName>
								<orgName type="institution" key="instit2">Megvii Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
							<email>peng.wang@adelaide.edu.au</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">The University of Adelaide</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwen</forename><surname>Guo</surname></persName>
							<email>ywguo@nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Label Image Recognition with Graph Convolutional Networks *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The task of multi-label image recognition is to predict a set of object labels that present in an image. As objects normally co-occur in an image, it is desirable to model the label dependencies to improve the recognition performance. To capture and explore such important dependencies, we propose a multi-label classification model based on Graph Convolutional Network (GCN). The model builds a directed graph over the object labels, where each node (label) is represented by word embeddings of a label, and GCN is learned to map this label graph into a set of inter-dependent object classifiers. These classifiers are applied to the image descriptors extracted by another sub-net, enabling the whole network to be end-to-end trainable. Furthermore, we propose a novel re-weighted scheme to create an effective label correlation matrix to guide information propagation among the nodes in GCN. Experiments on two multi-label image recognition datasets show that our approach obviously outperforms other existing state-of-the-art methods. In addition, visualization analyses reveal that the classifiers learned by our model maintain meaningful semantic topology.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-label image recognition is a fundamental and practical task in Computer Vision, where the aim is to predict a set of objects present in an image. It can be applied to many fields such as medical diagnosis recognition <ref type="bibr" target="#b6">[7]</ref>, human attribute recognition <ref type="bibr" target="#b18">[19]</ref> and retail checkout recognition <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30]</ref>. Comparing to multi-class image classification <ref type="bibr" target="#b20">[21]</ref>, the multi-label task is more challenging due to the <ref type="bibr">Figure 1</ref>. We build a directed graph over the object labels to model label dependencies in multi-label image recognition. In this figure, "LabelA → LabelB", means when LabelA appears, LabelB is likely to appear, but the reverse may not be true. combinatorial nature of the output space. As the objects normally co-occur in the physical world, a key for multi-label image recognition is to model the label dependencies, as shown in <ref type="figure">Fig. 1</ref>.</p><p>A Naïve way to address the multi-label recognition problem is to treat the objects in isolation and convert the multilabel problem into a set of binary classification problems to predict whether each object of interest presents or not. Benefited from the great success of single-label image classification achieved by deep Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b11">12]</ref>, the performance of the binary solutions has been greatly improved. However, these methods are essentially limited by ignoring the complex topology structure between objects. This stimulates research for approaches to capture and explore the label correlations in various ways. Some approaches, based on probabilistic graph model <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b16">17]</ref> or Recurrent Neural Networks (RNNs) <ref type="bibr" target="#b27">[28]</ref>, are proposed to explicitly model label dependencies. While the former formulates the multi-label classification problem as a structural inference problem which may suffer from a scalability issue due to high computational complexity, the latter predicts the labels in a sequential fashion, based on some orders either pre-defined or learned. Another line of works implicitly model the label correlations via attention mechanisms <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b28">29]</ref>. They consider the relations between attended regions of an image, which can be viewed as local correlations, but still ignore the global correlations between labels which require to be inferred from knowledge beyond a single image.</p><p>In this paper, we propose a novel GCN based model (aka ML-GCN) to capture the label correlations for multi-label image recognition, which properties with scalability and flexibility impossible for competing approaches. Instead of treating object classifiers as a set of independent parameter vectors to be learned, we propose to learn inter-dependent object classifiers from prior label representations, e.g., word embeddings, via a GCN based mapping function. In the following, the generated classifiers are applied to image representations generated by another sub-net to enable end-to-end training. As the embedding-to-classifier mapping parameters are shared across all classes (i.e., image labels), the gradients from all classifiers impact the GCN based classifier generation function. This implicitly models the label correlations. Furthermore, to explicitly model the label dependencies for classifier learning, we design an effective label correlation matrix to guide the information propagation among nodes in GCN. Specifically, we propose a re-weighted scheme to balance the weights between a node and its neighborhood for node feature update, which effectively alleviates overfitting and over-smoothing. Experiments on two multi-label image recognition datasets show that our approach obviously outperforms existing state-of-the-art methods. In addition, visualization analyses reveal that the classifiers learned by our model maintain meaningful semantic structures.</p><p>The main contributions of this paper are as follows:</p><p>• We propose a novel end-to-end trainable multi-label image recognition framework, which employs GCN to map label representations, e.g., word embeddings, to inter-dependent object classifiers. • We conduct in-depth studies on the design of correlation matrix for GCN and propose an effective re-weighted scheme to simultaneously alleviate the over-fitting and over-smoothing problems. • We evaluate our method on two benchmark multi-label image recognition datasets, and our proposed method consistently achieves superior performance over previous competing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The performance of image classification has recently witnessed a rapid progress due to the establishment of large-scale hand-labeled datasets such as ImageNet <ref type="bibr" target="#b3">[4]</ref>, MS-COCO <ref type="bibr" target="#b19">[20]</ref> and PASCAL VOC <ref type="bibr" target="#b4">[5]</ref>, and the fast development of deep convolutional networks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b31">32]</ref>. Many efforts have been dedicated to extending deep convolutional networks for multi-label image recognition.</p><p>A straightforward way for multi-label recognition is to train independent binary classifiers for each class/label. However, this method does not consider the relationship among labels, and the number of predicted labels will grow exponentially as the number of categories increase. For instance, if a dataset contains 20 labels, then the number of predicted label combination could be more than 1 million (i.e., 2 20 ). Besides, this baseline method is essentially limited by ignoring the topology structure among objects, which can be an important regularizer for the co-occurrence patterns of objects. For example, some combinations of labels are almost impossible to appear in the physical world.</p><p>In order to regularize the prediction space, many researchers attempted to capture label dependencies. Gong et al. <ref type="bibr" target="#b8">[9]</ref> used a ranking-based learning strategy to train deep convolutional neural networks for multi-label image recognition and found that the weighted approximated-ranking loss worked best. Additionally, Wang et al. <ref type="bibr" target="#b27">[28]</ref> utilized recurrent neural networks (RNNs) to transform labels into embedded label vectors, so that the correlation between labels can be employed. Furthermore, attention mechanisms were also widely applied to discover the label correlation in the multilabel recognition task. In <ref type="bibr" target="#b35">[36]</ref>, Zhu et al. proposed a spatial regularization network to capture both semantic and spatial relations of these multiple labels based on weighted attention maps. Wang et al. <ref type="bibr" target="#b28">[29]</ref> introduced a spatial transformer layer and long short-term memory (LSTM) units to capture the label correlation.</p><p>Compared with the aforementioned structure learning methods, the graph was proven to be more effective in modeling label correlation. Li et al. <ref type="bibr" target="#b17">[18]</ref> created a tree-structured graph in the label space by using the maximum spanning tree algorithm. Li et al. <ref type="bibr" target="#b16">[17]</ref> produced image-dependent conditional label structures base on the graphical Lasso framework. Lee et al. <ref type="bibr" target="#b14">[15]</ref> incorporated knowledge graphs for describing the relationships between multiple labels. In this paper, we leverage the graph structure to capture and explore the label correlation dependency. Specifically, based on the graph, we utilize GCN to propagate information between multiple labels and consequently learn inter-dependent classifiers for each of image labels. These classifiers absorb information from the label graph, which are further applied to the global image representation for the final multi-label prediction. It is a more explicit way for evaluating label co-occurrence. Experimental results validate our proposed approach is effective and our model can be trained in an end-to-end manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>In this part, we elaborate on our ML-GCN model for multi-label image recognition. Firstly, we introduce the moti-    vation for our method. Then, we introduce some preliminary knowledge of GCN, which is followed by the detailed illustration of the proposed ML-GCN model and the re-weighted scheme for correlation matrix construction.</p><formula xml:id="formula_0">V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i</formula><formula xml:id="formula_1">V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i</formula><formula xml:id="formula_2">V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Motivations</head><p>How to effectively capture the correlations between object labels and explore these label correlations to improve the classification performance are both important for multi-label image recognition. In this paper, we use a graph to model the inter dependencies between labels, which is a flexible way to capture the topological structure in the label space. Specifically, we represent each node (label) of the graph as word embeddings of the label, and propose to use GCN to directly map these label embeddings into a set of interdependent classifiers, which can be directly applied to an image feature for classification. Two factors motivated the design of our GCN based model. Firstly, as the embeddingto-classifier mapping parameters are shared across all classes, the learned classifiers can retain the weak semantic structures in the word embedding space, where semantic related concepts are close to each other. Meanwhile, the gradients of all classifiers can impact the classifier generation function, which implicitly models the label dependencies. Secondly, we design a novel label correlation matrix based on their co-occurrence patterns to explicitly model the label depen-dencies by GCN, with which the update of node features will absorb information from correlated nodes (labels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Graph Convolutional Network Recap</head><p>Graph Convolutional Network (GCN) was introduced in <ref type="bibr" target="#b13">[14]</ref> to perform semi-supervised classification. The essential idea is to update the node representations by propagating information between nodes.</p><p>Unlike standard convolutions that operate on local Euclidean structures in an image, the goal of GCN is to learn a function f (·, ·) on a graph G, which takes feature descriptions H l ∈ R n×d and the corresponding correlation matrix A ∈ R n×n as inputs (where n denotes the number of nodes and d indicates the dimensionality of node features), and updates the node features as H l+1 ∈ R n×d . Every GCN layer can be written as a non-linear function by</p><formula xml:id="formula_3">H l+1 = f (H l , A).<label>(1)</label></formula><p>After employing the convolutional operation of <ref type="bibr" target="#b13">[14]</ref>, f (·, ·) can be represented as</p><formula xml:id="formula_4">H l+1 = h( AH l W l ),<label>(2)</label></formula><p>where W l ∈ R d×d is a transformation matrix to be learned and A ∈ R n×n is the normalized version of correlation matrix A, and h(·) denotes a non-linear operation, which is acted by LeakyReLU <ref type="bibr" target="#b21">[22]</ref> in our experiments. Thus, we can learn and model the complex inter-relationships of the nodes by stacking multiple GCN layers. For more details, we refer interested readers to <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">GCN for Multi-label Recognition</head><p>Our ML-GCN is built upon GCN. GCN was proposed for semi-supervised classification, where the node-level output is the prediction score of each node. Different from that, we design the final output of each GCN node to be the classifier of the corresponding label in our task. In addition, the graph structure (i.e., the correlation matrix) is normally pre-defined in other tasks, which, however, is not provided in the multilabel image recognition task. Thus, we need to construct the correlation matrix from scratch. The overall framework of our approach is shown in <ref type="figure" target="#fig_3">Fig. 2</ref>, which is composed of two main modules, i.e., the image representation learning and GCN based classifier learning modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image representation learning</head><p>We can use any CNN base models to learn the features of an image. In our experiments, following <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b5">6]</ref>, we use ResNet-101 <ref type="bibr" target="#b9">[10]</ref> as the base model in experiments. Thus, if an input image I is with the 448 × 448 resolution, we can obtain 2048 × 14 × 14 feature maps from the "conv5 x" layer. Then, we employ global max-pooling to obtain the image-level feature x:</p><formula xml:id="formula_5">x = f GMP (f cnn (I; θ cnn )) ∈ R D ,<label>(3)</label></formula><p>where θ cnn indicates model parameters and D = 2048.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN based classifier learning</head><p>We learn inter-dependent object classifiers, i.e., W = {w i } C i=1 , from label representations via a GCN based mapping function, where C denotes the number of categories. We use stacked GCNs where each GCN layer l takes the node representations from previous layer (H l ) as inputs and outputs new node representations, i.e., H l+1 . For the first layer, the input is the Z ∈ R C×d matrix, where d is the dimensionality of the label-level word embedding. For the last layer, the output is W ∈ R C×D with D denoting the dimensionality of the image representation. By applying the learned classifiers to image representations, we can obtain the predicted scores aŝ</p><formula xml:id="formula_6">y = W x.<label>(4)</label></formula><p>We assume that the ground truth label of an image is y ∈ R C , where y i = {0, 1} denotes whether label i appears in the image or not. The whole network is trained using the traditional multi-label classification loss as follows L = C c=1 y c log(σ(ŷ c )) + (1 − y c ) log(1 − σ(ŷ c )), <ref type="bibr" target="#b4">(5)</ref> where σ(·) is the sigmoid function.  <ref type="figure">Figure 3</ref>. Illustration of conditional probability between two labels. As usual, when "surfboard" appears in the image, "person" will also occur with a high probability. However, in the condition of "person" appearing, "surfboard" will not necessarily occur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Correlation Matrix of ML-GCN</head><p>GCN works by propagating information between nodes based on the correlation matrix. Thus, how to build the correlation matrix A is a crucial problem for GCN. In most applications, the correlation matrix is pre-defined, which, however, is not provided in any standard multi-label image recognition datasets. In this paper, we build this correlation matrix through a data-driven way. That is, we define the correlation between labels via mining their co-occurrence patterns within the dataset.</p><p>We model the label correlation dependency in the form of conditional probability, i.e., P (L j |L i ) which denotes the probability of occurrence of label L j when label L i appears. As shown in <ref type="figure">Fig. 3</ref>, P (L j |L i ) is not equal to P (L i |L j ). Thus, the correlation matrix is asymmetrical.</p><p>To construct the correlation matrix, firstly, we count the occurrence of label pairs in the training set and get the matrix M ∈ R C×C . Concretely, C is the number of categories, and M ij denotes the concurring times of L i and L j . Then, by using this label co-occurrence matrix, we can get the conditional probability matrix by</p><formula xml:id="formula_7">P i = M i /N i ,<label>(6)</label></formula><p>where N i denotes the occurrence times of L i in the training set, and P ij = P (L j |L i ) means the probability of label L j when label L i appears. However, the simple correlation above may suffer from two drawbacks. Firstly, the co-occurrence patterns between a label and the other labels may exhibit a long-tail distribution, where some rare co-occurrences may be noise. Secondly, the absolute number of co-occurrences from training and test may not be completely consistent. A correlation matrix overfitted to the training set can hurt the generalization capacity. Thus, we propose to binarize the correlation P . Specifically, we use the threshold τ to filter noisy edges, and the operation can be written as</p><formula xml:id="formula_8">A ij = 0, if P ij &lt; τ 1, if P ij ≥ τ ,<label>(7)</label></formula><p>where A is the binary correlation matrix.</p><p>Over-smoothing problem From Eq. (2), we can conclude that after GCN, the feature of a node will be the weighted sum of its own feature and the adjacent nodes' features. Then, a direct problem for the binary correlation matrix is that it can result in over-smoothing. That is, the node features may be over-smoothed such that nodes from different clusters (e.g., kitchen related vs. living room related) may become indistinguishable <ref type="bibr" target="#b15">[16]</ref>. To alleviate this problem, we propose the following re-weighted scheme,</p><formula xml:id="formula_9">A ij =    p/ C j=1 i =j A ij , if i = j 1 − p, if i = j ,<label>(8)</label></formula><p>where A is the re-weighted correlation matrix, and p determines the weights assigned to a node itself and other correlated nodes. By doing this, when updating the node feature, we will have a fixed weight for the node itself and the weights for correlated nodes will be determined by the neighborhood distribution. When p → 1, the feature of a node itself will not be considered. While, on the other hand, when p → 0, neighboring information tends to be ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first describe the evaluation metrics and implementation details. Then, we report the empirical results on two benchmark multi-label image recognition datasets, i.e., MS-COCO <ref type="bibr" target="#b19">[20]</ref> and VOC 2007 <ref type="bibr" target="#b4">[5]</ref>. Finally, visualization analyses are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation Metrics</head><p>Following conventional settings <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b35">36]</ref>, we report the average per-class precision (CP), recall (CR), F1 (CF1) and the average overall precision (OP), recall (OR), F1 (OF1) for performance evaluation. For each image, the labels are predicted as positive if the confidences of them are greater than 0.5. For fair comparisons, we also report the results of top-3 labels, cf. <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b5">6]</ref>. In addition, we also compute and report the mean average precision (mAP). Generally, average overall F1 (OF1), average per-class F1 (CF1) and mAP are relatively more important for performance evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Without otherwise stated, our ML-GCN consists of two GCN layers with output dimensionality of 1024 and 2048, respectively. For label representations, we adopt 300-dim GloVe <ref type="bibr" target="#b24">[25]</ref> trained on the Wikipedia dataset. For the categories whose names contain multiple words, we obtain the label representation as average of embeddings for all words. For the correlation matrix, without otherwise stated, we set τ in Eq. (7) to be 0.4 and p in Eq. (8) to be 0.2. In the image representation learning branch, we adopt LeakyReLU <ref type="bibr" target="#b21">[22]</ref> with the negative slope of 0.2 as the non-linear activation function, which leads to faster convergence in experiments. We adopt ResNet-101 <ref type="bibr" target="#b9">[10]</ref> as the feature extraction backbone, which is pre-trained on ImageNet <ref type="bibr" target="#b3">[4]</ref>. During training, the input images are random cropped and resized into 448 × 448 with random horizontal flips for data augmentation. For network optimization, SGD is used as the optimizer. The momentum is set to be 0.9. Weight decay is 10 −4 . The initial learning rate is 0.01, which decays by a factor of 10 for every 40 epochs and the network is trained for 100 epochs in total. We implement the network based on PyTorch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experimental Results</head><p>In this part, we first present our comparisons with state-ofthe-arts on MS-COCO and VOC 2007, respectively. Then, we conduct ablation studies to evaluate the key aspects of the proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Comparisons with State-of-the-Arts</head><p>Results on MS-COCO Microsoft COCO <ref type="bibr" target="#b19">[20]</ref> is a widely used benchmark for multi-label image recognition. It contains 82,081 images as the training set and 40,504 images as the validation set. The objects are categorized into 80 classes with about 2.9 object labels per image. Since the ground-truth labels of the test set are not available, we evaluate the performance of all the methods on the validation set. The number of labels of different images also varies considerably, which makes MS-COCO more challenging.</p><p>Quantitative results are reported in <ref type="table">Table 1</ref>. We compare with state-of-the-art methods, including CNN-RNN <ref type="bibr" target="#b27">[28]</ref>, RNN-Attention <ref type="bibr" target="#b28">[29]</ref>, Order-Free RNN <ref type="bibr" target="#b0">[1]</ref>, ML-ZSL <ref type="bibr" target="#b14">[15]</ref>, SRN <ref type="bibr" target="#b35">[36]</ref>, Multi-Evidence <ref type="bibr" target="#b5">[6]</ref>, etc. For the proposed ML-GCN, we report the results based on the binary correlation matrix ("ML-GCN (Binary)") and the re-weighted correlation matrix ("ML-GCN (Re-weighted)"), respectively. It is obvious to see that our ML-GCN method based on the binary correlation matrix obtains worse classification performance, which may be largely due to the over-smoothing problem discussed in Sec. 3.4. The proposed re-weighted scheme can alleviate the over-smoothing issue and consequently obtains superior performance. Comparing with state-of-the-art methods, our approach with the proposed re-weighted scheme consistently performs better under almost all metrics, which shows the effectiveness of our proposed ML-GCN as well as its corresponding re-weighted scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on VOC 2007 PASCAL Visual Object Classes</head><p>Challenge (VOC 2007) <ref type="bibr" target="#b4">[5]</ref> is another popular dataset for multi-label recognition. It contains 9,963 images from 20 object categories, which is divided into train, val and test sets. Following <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b28">29]</ref>, we use the trainval set to train our model, and evaluate the recognition performance on the test set. In order to compare with other state-of-the-art methods, <ref type="table">Table 1</ref>. Comparisons with state-of-the-art methods on the MS-COCO dataset. The performance of the proposed ML-GCN based on two types of correlation matrices are reported."Binary" denotes that we use the binary correlation matrix, cf. Eq. <ref type="bibr" target="#b6">(7)</ref>. "Re-weighted" means the correlation matrix generated by the proposed re-weighted scheme is used, cf. Eq. (8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>All <ref type="table" target="#tab_1">Top-3  mAP  CP  CR  CF1  OP  OR  OF1  CP  CR  CF1  OP  OR  OF1  CNN-RNN [28]</ref> 61.  we report the results of average precision (AP) and mean average precision (mAP).</p><p>The results of VOC 2007 are presented in <ref type="table" target="#tab_1">Table 2</ref>. Because the results of many previous works on VOC 2007 are based on the VGG model <ref type="bibr" target="#b25">[26]</ref>. For fair comparisons, we also report the results using VGG models as the base model. It is apparent to see that, our proposed method observes improvements upon the previous methods. Concretely, the proposed ML-GCN with our re-weighted scheme obtains 94.0% mAP, which outperforms state-of-the-art by 2%. Even using VGG model as the base model, we can still achieve better results (+0.8%). Also, consistent with the results on MS-COCO, the re-weighed scheme enjoys better performance than the binary correlation matrix on VOC as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Ablation Studies</head><p>In this section, we perform ablation studies from four different aspects, including the sensitivity of ML-GCN to different types of word embeddings, effects of τ in correlation matrix binarization, effects of p for correlation matrix re-weighting, and the depths of GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ML-GCN under different types of word embeddings</head><p>By default, we use Glove <ref type="bibr" target="#b24">[25]</ref> as label representations, which serves as the inputs of the stacked GCNs for learning the object classifiers. In this part, we evaluate the performance of ML-GCN under other types popular word representations. Specifically, we investigate four different word embedding methods, including GloVe <ref type="bibr" target="#b24">[25]</ref>, Google-News <ref type="bibr" target="#b23">[24]</ref>, FastText <ref type="bibr" target="#b12">[13]</ref> and the simple one-hot word embedding. <ref type="figure">Fig. 4</ref> shows the results using different word embeddings on MS-COCO and VOC 2007. As shown, we can see that when using different word embeddings as GCN's inputs, the multi-label recognition accuracy will not be affected significantly. In addition, the observations (especially the results of one-hot) justify that the accuracy improvements achieved by our method do not absolutely come from the semantic meanings derived from word embeddings. Furthermore, using powerful word embeddings could lead to better performance. One possible reason may be that the word embeddings <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b12">13]</ref> learned from large text corpus maintain some semantic topology. That is, for semantic related concepts, their embeddings are close in the embedding space. Our model can employ these implicit dependencies, and further benefit multi-label image recognition.  <ref type="figure">Figure 4</ref>. Effects of different word embedding approaches. It is clear to see that, different word embeddings will hardly affect the accuracy, which reveals our improvements do not absolutely come from the semantic meanings derived from word embeddings, rather than our ML-GCN.  not filter any edges, the model will not converge. Thus, there is no result for τ = 0 in that figure. As shown, when filtering out the edges of small probabilities (i.e., noisy edges), the multi-label recognition accuracy is boosted. However, when too many edges are filtered out, the accuracy drops since correlated neighbors will be ignored as well. The optimal value of τ is 0.4 for both MS-COCO and VOC 2007.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of different threshold values τ</head><p>Effects of different p for correlation matrix re-weighting To explore the effects of different values of p in Eq. (8) on multi-label classification accuracy, we change the values of p in a set of {0, 0.1, 0.2, . . . , 0.9, 1}, as depicted in <ref type="figure">Fig. 6</ref>. Generally, this figure shows the importance of balancing the weights between a node itself and the neighborhood when updating the node feature in GCN. In experiments, we choose the optimal value of p by cross-validations. We can see that when p = 0.2, it can achieve the best performance on both MS-COCO and VOC 2007. If p is too small, nodes (labels) of the graph can not get sufficient information from correlated nodes (labels). While, if p is too large, it will lead to over-smoothing. Another interesting observation is that, when p = 0, we  <ref type="figure">Figure 6</ref>. Accuracy comparisons with different values of p. Note that, when p = 1, the model does not converge. can obtain mAPs of 81.67% on MS-COCO and 93.15% on VOC 2007, which still outperforms existing methods. Note that when p = 0, we essentially do not explicitly incorporate the label correlations. The improvement is benefited from that our ML-GCN model learns the object classifiers from the prior label representations through a shared GCN based mapping function, which implicitly models label dependencies as discussed in Sec. 3.1</p><p>The deeper, the better? We show the performance results with different numbers of GCN layers for our model in <ref type="table" target="#tab_2">Table 3</ref>. For the three-layer model, the output dimensionalities are 1024, 1024 and 2048 for the sequential layers, respectively. For the four-layer model, the dimensionalities are 1024, 1024, 1024 and 2048. As shown, when the number of graph convolution layers increases, multi-label recognition performance drops on both datasets. The possible reason for the performance drop may be that when using more GCN layers, the propagation between nodes will be accumulated, which can result in over-smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Classifier Visualization</head><p>The effectiveness of our approach has been quantitatively evaluated through comparisons to existing methods and detailed ablation studies. In this section, we visualize the learned inter-dependent classifiers to show if meaningful semantic topology can be maintained.</p><p>In <ref type="figure" target="#fig_12">Fig. 8</ref>, we adopt the t-SNE <ref type="bibr" target="#b22">[23]</ref> to visualize the classifiers learned by our proposed ML-GCN, as well the classifiers learned through vanilla ResNet (i.e., parameters of the last fully-connected layer). It is clear to see that, the classifiers learned by our method maintain meaningful semantic topology. Specifically, the learned classifiers exhibit cluster patterns. Classifiers (of "car" and "truck") within one super concept ("transportation"), tend to be close in the classifier space. This is consistent with common sense, which indicates that the classifiers learned by our approach may not be limited to the dataset where the classifiers are learned, but may enjoy generalization capacities. On the contrary, the classifiers learned through vanilla ResNet uniformly distribute in the space and do not shown any meaningful topology. This visualization further shows the effectiveness of our approach in modeling label dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Performance on image retrieval</head><p>Apart from analyzing the learned classifiers, we further evaluate if our model can learn better image representations. We conduct an image retrieval experiment to verify this. Specifically, we use the k-NN algorithm to perform contentbased image retrieval to validate the discriminative ability of image representations learned by our model. Still, we choose the features from vanilla ResNet as the baseline. We show the top-5 images returned by k-NN. The retrieval results are presented in <ref type="figure" target="#fig_9">Fig. 7</ref>. For each query image, the corresponding returned images are sorted in the ascending order according to the distance to the query image. We can clearly observe that our retrieval results are obviously better than the vanilla ResNet baseline. For example, in <ref type="figure" target="#fig_9">Fig. 7 (c)</ref>, the labels of the images returned by our approach almost exactly match the labels of the query image. It can demonstrate that our ML-GCN can not only effectively capture label dependencies to learn better classifiers, but can benefit image representation learning as well in multi-label recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Capturing label dependencies is one crucial issue for multi-label image recognition. In order to model and explore this important information, we proposed a GCN based model    to learn inter-dependent object classifiers from prior label representations, e.g., word embeddings. To explicitly model the label dependencies, we designed a novel re-weighted scheme to construct the correlation matrix for GCN by balancing the weights between a node and its neighborhood for node feature update. This scheme can effectively alleviate over-fitting and over-smoothing, which are two key factors hampering the performance of GCN. Both quantitative and qualitative results validated the advantages of our ML-GCN.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>h</head><label></label><figDesc>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u i c e R V J D Q q k i o 7 z N O P U v W g z L 7 S M = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L t h Z q k S S d t k O n S Z h M h F L 0 B 9 z q t 4 l / o H / h n X E K a h G d k O T M u f e c m X t v m A q e K c 9 7 L T g L i 0 v L K 8 X V 0 t r 6 x u Z W e X u n l S W 5 j F g z S k Q i 2 2 G Q M c F j 1 l R c C d Z O J Q v G o W D X 4 e h c x 6 / v m M x 4 E l + p S c q 6 4 2 A Q 8 z 6 P A k V U Y 3 h b r n h V z y x 3 H v g W V G B X P S m / 4 A Y 9 J I i Q Y w y G G I q w Q I C M n g 5 8 e E i J 6 2 J K n C T E T Z z h H i X S 5 p T F K C M g d k T f A e 0 6 l o 1 p r z 0 z o 4 7 o F E G v J K W L A 9 I k l C c J 6 9 N c E 8 + N s 2 Z / 8 5 4 a T 3 2 3 C f 1 D 6 z U m V m F I 7 F + 6 W e Z / d b o W h T 5 O T Q 2 c a k o N o 6 u L r E t u u q J v 7 n 6 p S p F D S p z G P Y p L w p F R z v r s G k 1 m a t e 9 D U z 8 z W R q V u 8 j m 5 v j X d + S B u z / H O c 8 a B 1 V f a / q N 4 4 r t T M 7 6 i L 2 s I 9 D m u c J a r h E H U 3 j / Y g n P D s X j n A y J / 9 M d Q p W s 4 t v y 3 n 4 A E U c j 2 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u i c e R V J D Q q k i o 7 z N O P U v W g z L 7 S M = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L t h Z q k S S d t k O n S Z h M h F L 0 B 9 z q t 4 l / o H / h n X E K a h G d k O T M u f e c m X t v m A q e K c 9 7 L T g L i 0 v L K 8 X V 0 t r 6 x u Z W e X u n l S W 5 j F g z S k Q i 2 2 G Q M c F j 1 l R c C d Z O J Q v G o W D X 4 e h c x 6 / v m M x 4 E l + p S c q 6 4 2 A Q 8 z 6 P A k V U Y 3 h b r n h V z y x 3 H v g W V G B X P S m / 4 A Y 9 J I i Q Y w y G G I q w Q I C M n g 5 8 e E i J 6 2 J K n C T E T Z z h H i X S 5 p T F K C M g d k T f A e 0 6 l o 1 p r z 0 z o 4 7 o F E G v J K W L A 9 I k l C c J 6 9 N c E 8 + N s 2 Z / 8 5 4 a T 3 2 3 C f 1 D 6 z U m V m F I 7 F + 6 W e Z / d b o W h T 5 O T Q 2 c a k o N o 6 u L r E t u u q J v 7 n 6 p S p F D S p z G P Y p L w p F R z v r s G k 1 m a t e 9 D U z 8 z W R q V u 8 j m 5 v j X d + S B u z / H O c 8 a B 1 V f a / q N 4 4 r t T M 7 6 i L 2 s I 9 D m u c J a r h E H U 3 j / Y g n P D s X j n A y J / 9 M d Q p W s 4 t v y 3 n 4 A E U c j 2 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u i c e R V J D Q q k i o 7 z N O P U v W g z L 7 S M = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L t h Z q k S S d t k O n S Z h M h F L 0 B 9 z q t 4 l / o H / h n X E K a h G d k O T M u f e c m X t v m A q e K c 9 7 L T g L i 0 v L K 8 X V 0 t r 6 x u Z W e X u n l S W 5 j F g z S k Q i 2 2 G Q M c F j 1 l R c C d Z O J Q v G o W D X 4 e h c x 6 / v m M x 4 E l + p S c q 6 4 2 A Q 8 z 6 P A k V U Y 3 h b r n h V z y x 3 H v g W V G B X P S m / 4 A Y 9 J I i Q Y w y G G I q w Q I C M n g 5 8 e E i J 6 2 J K n C T E T Z z h H i X S 5 p T F K C M g d k T f A e 0 6 l o 1 p r z 0 z o 4 7 o F E G v J K W L A 9 I k l C c J 6 9 N c E 8 + N s 2 Z / 8 5 4 a T 3 2 3 C f 1 D 6 z U m V m F I 7 F + 6 W e Z / d b o W h T 5 O T Q 2 c a k o N o 6 u L r E t u u q J v 7 n 6 p S p F D S p z G P Y p L w p F R z v r s G k 1 m a t e 9 D U z 8 z W R q V u 8 j m 5 v j X d + S B u z / H O c 8 a B 1 V f a / q N 4 4 r t T M 7 6 i L 2 s I 9 D m u c J a r h E H U 3 j / Y g n P D s X j n A y J / 9 M d Q p W s 4 t v y 3 n 4 A E U c j 2 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u i c e R V J D Q q k i o 7 z N O P U v W g z L 7 S M = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L t h Z q k S S d t k O n S Z h M h F L 0 B 9 z q t 4 l / o H / h n X E K a h G d k O T M u f e c m X t v m A q e K c 9 7 L T g L i 0 v L K 8 X V 0 t r 6 x u Z W e X u n l S W 5 j F g z S k Q i 2 2 G Q M c F j 1 l R c C d Z O J Q v G o W D X 4 e h c x 6 / v m M x 4 E l + p S c q 6 4 2 A Q 8 z 6 P A k V U Y 3 h b r n h V z y x 3 H v g W V G B X P S m / 4 A Y 9 J I i Q Y w y G G I q w Q I C M n g 5 8 e E i J 6 2 J K n C T E T Z z h H i X S 5 p T F K C M g d k T f A e 0 6 l o 1 p r z 0 z o 4 7 o F E G v J K W L A 9 I k l C c J 6 9 N c E 8 + N s 2 Z / 8 5 4 a T 3 2 3 C f 1 D 6 z U m V m F I 7 F + 6 W e Z / d b o W h T 5 O T Q 2 c a k o N o 6 u L r E t u u q J v 7 n 6 p S p F D S p z G P Y p L w p F R z v r s G k 1 m a t e 9 D U z 8 z W R q V u 8 j m 5 v j X d + S B u z / H O c 8 a B 1 V f a / q N 4 4 r t T M 7 6 i L 2 s I 9 D m u c J a r h E H U 3 j / Y g n P D s X j n A y J / 9 M d Q p W s 4 t v y 3 n 4 A E U c j 2 0 = &lt; / l a t e x i t &gt; w &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 q 0 O d U V N U B 1 X P s 0 o 5 M Z V r J H B 9 s M= " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z l U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F wu r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 0 9 1 v D X i M h V x d K X G C e + G 3 i A S f c E 8 R d T l X e m m X H G q j l n 2 L H B z U E G + 6 n H 5 B d f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q q 3 x P 6 l m 2 b + V 6 d r U e j j 2 N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O g 6 j p V 9 + K w U j v J R 1 3 E D n a x T / M 8 Q g 3 n q K N B 3 n 0 8 4 g n P 1 p k V W s o a f a Z a h V y z j W / L e v g A p r O P k A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 q 0 O d U V N U B 1 X P s 0 o 5 M Z V r J H B 9 s M= " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z l U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F wu r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 0 9 1 v D X i M h V x d K X G C e + G 3 i A S f c E 8 R d T l X e m m X H G q j l n 2 L H B z U E G + 6 n H 5 B d f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q q 3 x P 6 l m 2 b + V 6 d r U e j j 2 N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O g 6 j p V 9 + K w U j v J R 1 3 E D n a x T / M 8 Q g 3 n q K N B 3 n 0 8 4 g n P 1 p k V W s o a f a Z a h V y z j W / L e v g A p r O P k A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 q 0 O d U V N U B 1 X P s 0 o 5 M Z V r J H B 9 s M = " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z l U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F w u r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 0 9 1 v D X i M h V x d K X G C e + G 3 i A S f c E 8 R d T l X e m m X H G q j l n 2 L H B z U E G + 6 n H 5 B d f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q q 3 x P 6 l m 2 b + V 6 d r U e j j 2 N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O g 6 j p V 9 + K w U j v J R 1 3 E D n a x T / M 8 Q g 3 n q K N B 3 n 0 8 4 g n P 1 p k V W s o a f a Z a h V y z j W / L e v g A p r O P k A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 q 0 O d U V N U B 1 X P s 0 o 5 M Z V r J H B 9 s M = " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z l U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F w u r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 0 9 1 v D X i M h V x d K X G C e + G 3 i A S f c E 8 R d T l X e m m X H G q j l n 2 L H B z U E G + 6 n H 5 B d f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q q 3 x P 6 l m 2 b + V 6 d r U e j j 2 N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O g 6 j p V 9 + K w U j v J R 1 3 E D n a x T / M 8 Q g 3 n q K N B 3 n 0 8 4 g n P 1 p k V W s o a f a Z a h V y z j W / L e v g A p r O P k A = = &lt; / l a t e x i t &gt; ... &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; C &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; Generated classifiers C &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 J n B j P + a j 5 V V L W D v C K M v w N Y + 8 Z k = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 2 J B X L Z g H 1 C L J O m 0 D p 0 m Y T I R S t E f c K v f J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 h K n i m P O + 1 4 C w s L i 2 v F F f X 1 j c 2 t 7 Z L O 7 u t L M l l x J p R I h L Z C Y O M C R 6 z p u J K s E 4 q W T A O B W u H o 5 q O t + + Y z H g S X 6 l J y n r j Y B j z A Y 8 C R V S j d l M q e x X P L H c e + B a U Y V c 9 K b 3 g G n 0 k i J B j D I Y Y i r B A g I y e L n x 4 S I n r Y U q c J M R N n O E e a 6 T N K Y t R R k D s i L 5 D 2 n U t G 9 N e e 2 Z G H d E p g l 5 J S h e H p E k o T x L W p 7 k m n h t n z f 7 m P T W e + m 4 T + o f W a 0 y s w i 2 x f + l m m f / V 6 V o U B j g z N X C q K T W M r i 6 y L r n p i r 6 5 + 6 U q R Q 4 p c R r 3 K S 4 J R 0 Y 5 6 7 N r N J m p X f c 2 M P E 3 k 6 l Z v Y 9 s b o 5 3 f U s a s P 9 z n P O g d V z x v Y r f O C l X z + 2 o i 9 j H A Y 5 o n q e o 4 h J 1 N I 3 3 I 5 7 w 7 F w 4 w s m c / D P V K V j N H r 4 t 5 + E D 7 S 2 P S A = = &lt; / l a t e x i t &gt; D &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; D &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; ... &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l ml H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q G F K Y 8 X a m w i b o g c 7 E 6 T + P M 3 g + 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k I i g y 6 K b L i v a B 9 Q i y X R a h + Z F M l F K E f w B t / p p 4 h / o X 3 h n n I J a R C c k O X P u P W f m 3 h u k o c i l 6 7 6 W r L n 5 h c W l 8 v L K 6 t r 6 x m Z l a 7 u V J 0 X G e J M l Y Z J 1 A j / n o Y h 5 U w o Z 8 k 6 a c T 8 K Q t 4 O R m c q 3 r 7 l W S 6 S + F K O U 9 6 L / G E s B o L 5 k q g L x 3 G u K 1 X X c f W y Z 4 F n Q B V m N Z L K C 6 7 Q R w K G A h E 4 Y k j C I X z k 9 H T h w U V K X A 8 T 4 j J C Q s c 5 7 r F C 2 o K y O G X 4 x I 7 o O 6 R d 1 7 A x 7 Z V n r t W M T g n p z U h p Y 5 8 0 C e V l h N V p t o 4 X 2 l m x v 3 l P t K e 6 2 5 j + g f G K i J W 4 I f Y v 3 T T z v z p V i 8 Q A J 7 o G Q T W l m l H V M e N S 6 K 6 o m 9 t f q p L k k B K n c J / i G W G m l d M + 2 1 q T 6 9 p V b 3 0 d f 9 O Z i l V 7 Z n I L v K t b 0 o C 9 n + O c B a 1 D x 3 M d 7 / y o W j s 1 o y 5 j F 3 s 4 o H k e o 4 Y 6 G m i S 9 x C P e M K z V b d i q 7 D u P l O t k t H s 4 N u y H j 4 A 4 e i P o w = = &lt; / l a t e x i t &gt; d &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 k V D 1 b z t f l q X q y 6 u e 1 p P j T m 2 Y K 4 = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O a + g 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j y W y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G K U 9 F J w w k 4 3 H C m i p W n H U y w Y J x y F k 7 H J 3 r e P u O C R m n y Z W a Z K w 3 D o Z J P I i j Q B H V 6 N + U K 1 7 V M 8 u d B 7 4 F F d h V T 8 s v u E Y f K S L k G I M h g S L M E U D S 0 4 U P D x l x P U y J E 4 R i E 2 e 4 R 4 m 0 O W U x y g i I H d F 3 S L u u Z R P a a 0 9 p 1 B G d w u k V p H R x Q J q U 8 g R h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U 0 N M N W W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h I 0 7 j P s U F 4 c g o Z 3 1 2 j U a a 2 n V v A x N / M 5 m a 1 f v I 5 u Z 4 1 7 e k A f s / x z k P W k d V 3 6 v 6 j e N K 7 c y O u o g 9 7 O O Q 5 n m C G i 5 R R 9 N 4 P + I J z 8 6 F w x 3 p 5 J + p T s F q d v F t O Q 8 f O 5 y P a Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 k V D 1 b z t f l q X q y 6 u e 1 p P j T m 2 Y K 4 = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O a + g 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j y W y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G K U 9 F J w w k 4 3 H C m i p W n H U y w Y J x y F k 7 H J 3 r e P u O C R m n y Z W a Z K w 3 D o Z J P I i j Q B H V 6 N + U K 1 7 V M 8 u d B 7 4 F F d h V T 8 s v u E Y f K S L k G I M h g S L M E U D S 0 4 U P D x l x P U y J E 4 R i E 2 e 4 R 4 m 0 O W U x y g i I H d F 3 S L u u Z R P a a 0 9 p 1 B G d w u k V p H R x Q J q U 8 g R h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U 0 N M N W W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h I 0 7 j P s U F 4 c g o Z 3 1 2 j U a a 2 n V v A x N / M 5 m a 1 f v I 5 u Z 4 1 7 e k A f s / x z k P W k d V 3 6 v 6 j e N K 7 c y O u o g 9 7 O O Q 5 n m C G i 5 R R 9 N 4 P + I J z 8 6 F w x 3 p 5 J + p T s F q d v F t O Q 8 f O 5 y P a Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 k V D 1 b z t f l q X q y 6 u e 1 p P j T m 2 Y K 4 = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O a + g 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j y W y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G K U 9 F J w w k 4 3 H C m i p W n H U y w Y J x y F k 7 H J 3 r e P u O C R m n y Z W a Z K w 3 D o Z J P I i j Q B H V 6 N + U K 1 7 V M 8 u d B 7 4 F F d h V T 8 s v u E Y f K S L k G I M h g S L M E U D S 0 4 U P D x l x P U y J E 4 R i E 2 e 4 R 4 m 0 O W U x y g i I H d F 3 S L u u Z R P a a 0 9 p 1 B G d w u k V p H R x Q J q U 8 g R h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U 0 N M N W W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h I 0 7 j P s U F 4 c g o Z 3 1 2 j U a a 2 n V v A x N / M 5 m a 1 f v I 5 u Z 4 1 7 e k A f s / x z k P W k d V 3 6 v 6 j e N K 7 c y O u o g 9 7 O O Q 5 n m C G i 5 R R 9 N 4 P + I J z 8 6 F w x 3 p 5 J + p T s F q d v F t O Q 8 f O 5 y P a Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 k V D 1 b z t f l q X q y 6 u e 1 p P j T m 2 Y K 4 = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O a + g 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j y W y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G K U 9 F J w w k 4 3 H C m i p W n H U y w Y J x y F k 7 H J 3 r e P u O C R m n y Z W a Z K w 3 D o Z J P I i j Q B H V 6 N + U K 1 7 V M 8 u d B 7 4 F F d h V T 8 s v u E Y f K S L k G I M h g S L M E U D S 0 4 U P D x l x P U y J E 4 R i E 2 e 4 R 4 m 0 O W U x y g i I H d F 3 S L u u Z R P a a 0 9 p 1 B G d w u k V p H R x Q J q U 8 g R h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U 0 N M N W W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h I 0 7 j P s U F 4 c g o Z 3 1 2 j U a a 2 n V v A x N / M 5 m a 1 f v I 5 u Z 4 1 7 e k A f s / x z k P W k d V 3 6 v 6 j e N K 7 c y O u o g 9 7 O O Q 5 n m C G i 5 R R 9 N 4 P + I J z 8 6 F w x 3 p 5 J + p T s F q d v F t O Q 8 f O 5 y P a Q = = &lt; / l a t e x i t &gt; d 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 m y N i 8 R r Z U / l U 0 B 7 Z l F 1 N y A t W 6 M = " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V 0 V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z k U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F w u r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 8 9 0 v D X i M h V x d K 3 G C e + G 3 i A S f c E 8 R d R V b / + 2 X H G q j l n 2 L H B z U E G + 6 n H 5 B T f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q p 3 x P 6 l m 2 b + V 6 d r U e j j x N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O w 6 j p V 9 / K o U j v N R 1 3 E D n Z x Q P M 8 R g 0 X q K N B 3 n 0 8 4 g n P 1 r k V W s o a f a Z a h V y z j W / L e v g A v m C P m g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 m y N i 8 R r Z U / l U 0 B 7 Z l F 1 N y A t W 6 M = " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V 0 V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z k U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F w u r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 8 9 0 v D X i M h V x d K 3 G C e + G 3 i A S f c E 8 R d R V b / + 2 X H G q j l n 2 L H B z U E G + 6 n H 5 B T f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q p 3 x P 6 l m 2 b + V 6 d r U e j j x N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O w 6 j p V 9 / K o U j v N R 1 3 E D n Z x Q P M 8 R g 0 X q K N B 3 n 0 8 4 g n P 1 r k V W s o a f a Z a h V y z j W / L e v g A v m C P m g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 m y N i 8 R r Z U / l U 0 B 7 Z l F 1 N y A t W 6 M = " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V 0 V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z k U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F w u r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 8 9 0 v D X i M h V x d K 3 G C e + G 3 i A S f c E 8 R d R V b / + 2 X H G q j l n 2 L H B z U E G + 6 n H 5 B T f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q p 3 x P 6 l m 2 b + V 6 d r U e j j x N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O w 6 j p V 9 / K o U j v N R 1 3 E D n Z x Q P M 8 R g 0 X q K N B 3 n 0 8 4 g n P 1 r k V W s o a f a Z a h V y z j W / L e v g A v m C P m g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 m y N i 8 R r Z U / l U 0 B 7 Z l F 1 N y A t W 6 M = " &gt; A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V 0 V R I R d F l 0 o c s q 9 g G 1 S D K d 1 q F 5 M Z k U S h F / w K 3 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X g j U 3 v 7 C 4 V F w u r a y u r W + U N 7 e a a Z x J x h s s D m L Z 9 r 2 U B y L i D S V U w N u J 5 F 7 o B 7 z l D 8 9 0 v D X i M h V x d K 3 G C e + G 3 i A S f c E 8 R d R V b / + 2 X H G q j l n 2 L H B z U E G + 6 n H 5 B T f o I Q Z D h h A c E R T h A B 5 S e j p w 4 S A h r o s J c Z K Q M H G O e 5 R I m 1 E W p w y P 2 C F 9 B 7 T r 5 G x E e + 2 Z G j W j U w J 6 J S l t 7 J E m p j x J W J 9 m m 3 h m n D X 7 m / f E e O q 7 j e n v 5 1 4 h s Q p 3 x P 6 l m 2 b + V 6 d r U e j j x N Q g q K b E M L o 6 l r t k p i v 6 5 v a X q h Q 5 J M R p 3 K O 4 J M y M c t p n 2 2 h S U 7 v u r W f i b y Z T s 3 r P 8 t w M 7 / q W N G D 3 5 z h n Q f O w 6 j p V 9 / K o U j v N R 1 3 E D n Z x Q P M 8 R g 0 X q K N B 3 n 0 8 4 g n P 1 r k V W s o a f a Z a h V y z j W / L e v g A v m C P m g = = &lt; / l a t e x i t &gt; D &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; Dot product D &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O o B p Z x w o O 7 Q 2 1 G T d J t X z L S r 8 w Q w = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F l U x G U L 9 g F a J E m n d e g 0 C Z O J U I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 E z 5 X m v B W d u f m F x q b h c W l l d W 9 8 o b 2 6 1 s i S X E W t G i U h k J w w y J n j M m o o r w T q p Z M E o F K w d D k 9 1 v H 3 H Z M a T + F K N U 9 Y d B Y O Y 9 3 k U K K I a Z z f l i l f 1 z H J n g W 9 B B X b V k / I L r t F D g g g 5 R m C I o Q g L B M j o u Y I P D y l x X U y I k 4 S 4 i T P c o 0 T a n L I Y Z Q T E D u k 7 o N 2 V Z W P a a 8 / M q C M 6 R d A r S e l i j z Q J 5 U n C + j T X x H P j r N n f v C f G U 9 9 t T P / Q e o 2 I V b g l 9 i / d N P O / O l 2 L Q h / H p g Z O N a W G 0 d V F 1 i U 3 X d E 3 d 7 9 U p c g h J U 7 j H s U l 4 c g o p 3 1 2 j S Y z t e v e B i b + Z j I 1 q / e R z c 3 x r m 9 J A / Z / j n M W t A 6 q v l f 1 G 4 e V 2 o k d d R E 7 2 M U + z f M I N V y g j q b x f s Q T n p 1 z R z i Z k 3 + m O g W r 2 c a 3 5 T x 8 A O + N j 0 k = &lt; / l a t e x i t &gt;GCGC Overall framework of our ML-GCN model for multi-label image recognition. The object labels are represented by word embeddings Z ∈ R C×d (C is the number of categories and d is the dimensionality of word-embedding vector). A directed graph is built over these label representations, where each node denotes a label. Stacked GCNs are learned over the label graph to map these label representations into a set of inter-dependent object classifiers, i.e., W ∈ R C×D , which are applied to the image representation extracted from the input image via a convolutional network for multi-label image recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>We vary the values of the threshold τ in Eq.(7)for correlation matrix binarization, and show the results inFig. 5. Note that, if we do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Accuracy comparisons with different values of τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Top-5 returned images with the query image. The returned results on the left are based on our proposed ML-GCN, while the results on the right are vanilla ResNet. All results are sorted in the ascending order according to the distance from the query image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>t-SNE on the learned inter-dependent classifiers by our model. t-SNE on the classifiers by the vanilla ResNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 .</head><label>8</label><figDesc>Visualization of the learned inter-dependent classifiers by our model and vanillia classifiers of ResNet on MS-COCO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparisons of AP and mAP with state-of-the-art methods on the VOC 2007 dataset. The meanings of "Binary" and "Re-weighted" are the same asTable 1. 98.3 97.9 97.6 78.2 92.3 97.4 97.4 79.2 94.4 86.5 97.4 97.9 97.1 98.7 84.6 95.3 83.0 98.6 90.4 93.1 ML-GCN (Re-weighted) 99.5 98.5 98.6 98.1 80.8 94.6 97.2 98.2 82.3 95.7 86.4 98.2 98.4 96.7 99.0 84.7 96.7 84.3 98.9 93.7 94.0</figDesc><table><row><cell>Methods</cell><cell>aero bike bird boat bottle bus car cat chair cow table dog horse motor person plant sheep sofa train tv mAP</cell></row><row><cell>CNN-RNN [28]</cell><cell>96.7 83.1 94.2 92.8 61.2 82.1 89.1 94.2 64.2 83.6 70.0 92.4 91.7 84.2 93.7 59.8 93.2 75.3 99.7 78.6 84.0</cell></row><row><cell>RLSD [34]</cell><cell>96.4 92.7 93.8 94.1 71.2 92.5 94.2 95.7 74.3 90.0 74.2 95.4 96.2 92.1 97.9 66.9 93.5 73.7 97.5 87.6 88.5</cell></row><row><cell>VeryDeep [26]</cell><cell>98.9 95.0 96.8 95.4 69.7 90.4 93.5 96.0 74.2 86.6 87.8 96.0 96.3 93.1 97.2 70.0 92.1 80.3 98.1 87.0 89.7</cell></row><row><cell>ResNet-101 [10]</cell><cell>99.5 97.7 97.8 96.4 65.7 91.8 96.1 97.6 74.2 80.9 85.0 98.4 96.5 95.9 98.4 70.1 88.3 80.2 98.9 89.2 89.9</cell></row><row><cell>FeV+LV [33]</cell><cell>97.9 97.0 96.6 94.6 73.6 93.9 96.5 95.5 73.7 90.3 82.8 95.4 97.7 95.9 98.6 77.6 88.7 78.0 98.3 89.0 90.6</cell></row><row><cell>HCP [31]</cell><cell>98.6 97.1 98.0 95.6 75.3 94.7 95.8 97.3 73.1 90.2 80.0 97.3 96.1 94.9 96.3 78.3 94.7 76.2 97.9 91.5 90.9</cell></row><row><cell>RNN-Attention [29]</cell><cell>98.6 97.4 96.3 96.2 75.2 92.4 96.5 97.1 76.5 92.0 87.7 96.8 97.5 93.8 98.5 81.6 93.7 82.8 98.6 89.3 91.9</cell></row><row><cell>Atten-Reinforce [2]</cell><cell>98.6 97.1 97.1 95.5 75.6 92.8 96.8 97.3 78.3 92.2 87.6 96.9 96.5 93.6 98.5 81.6 93.1 83.2 98.5 89.3 92.0</cell></row><row><cell>VGG (Binary)</cell><cell>98.3 97.1 96.1 96.7 75.0 91.4 95.8 95.4 76.7 92.1 85.1 96.7 96.0 95.3 97.8 77.4 93.1 79.7 97.9 89.3 91.1</cell></row><row><cell>VGG (Re-weighted)</cell><cell>99.4 97.4 98.0 97.0 77.9 92.4 96.8 97.8 80.8 93.4 87.2 98.0 97.3 95.8 98.8 79.4 95.3 82.2 99.1 91.4 92.8</cell></row><row><cell>ML-GCN (Binary)</cell><cell>99.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparisons with different depths of GCN in our model.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>MS-COCO</cell><cell></cell><cell></cell><cell>VOC</cell></row><row><cell>Layer</cell><cell>mAP</cell><cell>All CF1</cell><cell>OF1</cell><cell cols="2">Top-3 CF1 OF1</cell><cell>All mAP</cell></row><row><cell>2-layer</cell><cell>83.0</cell><cell>78.0</cell><cell>80.3</cell><cell>74.6</cell><cell>76.7</cell><cell>94.0</cell></row><row><cell>3-layer</cell><cell>82.1</cell><cell>76.9</cell><cell>79.7</cell><cell>73.7</cell><cell>76.2</cell><cell>93.6</cell></row><row><cell>4-layer</cell><cell>81.1</cell><cell>76.4</cell><cell>79.4</cell><cell>72.5</cell><cell>75.8</cell><cell>93.0</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Order-Free RNN with visual attention for multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Chen</forename><surname>Shang-Fu Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Kuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recurrent attentional reinforcement learning for multi-label image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouxia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (VOC) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-evidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Chest X-rays classification: A multi-label and fine-grained problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dwarikanath</forename><surname>Mahapatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Sedai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajib</forename><surname>Chakravorty</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07247</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recognizing products: A per-exemplar multi-label image classification approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marian</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Floerkemeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="440" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Alexander Toshev, and Sergey Ioffe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4894</idno>
	</analytic>
	<monogr>
		<title level="m">Deep convolutional ranking for multilabel image annotation</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hérve</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fasttext</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03651</idno>
		<title level="m">zip: Compressing text classification models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-label zero-shot learning with structured knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Wei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Kuan</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3538" to="3545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Conditional graphical lasso for multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoying</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2977" to="2986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-label image classification with a probabilistic label enhancement model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feipeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Human attribute recognition by deep hierarchical contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="684" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Compositional model based fisher vector coding for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2335" to="2348" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">CNN-RNN: A unified framework for multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhua</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2285" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-label image recognition by recurrently discovering attentional regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouxia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07249</idno>
		<title level="m">RPC: A large-scale retail product checkout dataset</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">HCP: A flexible cnn framework for multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junshi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1901" to="1907" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploit bounding box annotations for multi-label object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bin-Bin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="280" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multi-label image classification with regional latent semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMM</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2801" to="2813" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ShuffleNet: an extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6848" to="6856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning spatial regularization with imagelevel supervisions for multi-label image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
