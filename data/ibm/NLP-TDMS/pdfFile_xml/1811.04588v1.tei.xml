<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differentiating Concepts and Instances for Knowledge Graph Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Hou</surname></persName>
							<email>houlei@</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
							<email>lijuanzi@</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Differentiating Concepts and Instances for Knowledge Graph Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Concepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Specifically, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e., instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classification tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation. Our codes and datasets can be obtained from https:// github.com/davidlvxin/TransC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) aim at semantically representing the world's truth in the form of machinereadable graphs composed of triple facts. Knowledge graph embedding encodes each element (entities and relations) in knowledge graph into a continuous low-dimensional vector space. The learned representations make the knowledge graph essentially computable and have been proved to be helpful for knowledge graph completion and information extraction <ref type="bibr" target="#b1">(Bordes et al., 2013;</ref><ref type="bibr" target="#b21">Wang et al., 2014;</ref><ref type="bibr" target="#b8">Lin et al., 2015b;</ref><ref type="bibr" target="#b6">Ji et al., , 2016</ref>. In recent years, various knowledge graph embedding methods have been proposed, among which the translation-based models are simple and effective with good performances. Inspired by word2vec <ref type="bibr" target="#b9">(Mikolov et al., 2013)</ref>, given a triple (h, r, t), TransE learns vector embeddings h, r and t which satisfy r ≈ t − h. Afterwards, TransH <ref type="bibr" target="#b21">(Wang et al., 2014)</ref>, TransR/CTransR <ref type="bibr" target="#b8">(Lin et al., 2015b)</ref> and TransD , etc are proposed to address the problem of TransE when modeling 1-to-N, N-to-1, and N-to-N relations. As extensions of RESCAL <ref type="bibr" target="#b12">(Nickel et al., 2011)</ref>, which is a bilinear model, HolE <ref type="bibr" target="#b11">(Nickel et al., 2016)</ref>, DistMult <ref type="bibr" target="#b26">(Yang et al., 2014)</ref> and ComplEx <ref type="bibr" target="#b18">(Trouillon et al., 2016)</ref> achieve the stateof-the-art performances. Meanwhile, there are also some different methods using a variety of external information such as entity types <ref type="bibr" target="#b25">(Xie et al., 2016)</ref>, textual descriptions , as well as logical rules to strengthen representations of knowledge graphs <ref type="bibr" target="#b20">(Wang et al., 2015;</ref><ref type="bibr" target="#b3">Guo et al., 2016;</ref><ref type="bibr" target="#b13">Rocktäschel et al., 2015)</ref>.</p><p>However, all these methods ignore to distinguish between concepts and instances, and regard both as entities to make a simplification. Actually, concepts and instances are organized differently in many real world datasets like <ref type="bibr">YAGO (Suchanek et al., 2007)</ref>, Freebase <ref type="bibr" target="#b0">(Bollacker et al., 2008)</ref>, and WordNet <ref type="bibr" target="#b10">(Miller, 1995)</ref>. Hierarchical concepts in these knowledge bases provide a natural way to categorize and locate instances. Therefore, the common simplification in previous work will lead to the following two drawbacks:</p><p>Insufficient concept representation: Concepts are essential information in knowledge graph. A concept is a fundamental category of existence <ref type="bibr" target="#b14">(Rosch, 1973)</ref> and can be reified by all of its actual or potential instances. <ref type="figure" target="#fig_0">Figure 1</ref> presents an example of concepts and instances about university staffs. Most knowledge embedding methods encode both concepts and instances as vectors, cannot explicitly represent the difference between concepts and instances.</p><p>Lack transitivity of both isA relations: instanceOf and subClassOf (generally known as isA) are two special relations in knowledge graph. Different from most other relations, isA relations exhibit transitivity, e.g., the dotted lines in <ref type="figure" target="#fig_0">Figure 1</ref> represent the facts inferred by isA transitivity. The indiscriminate vector representation for all relations in previous work cannot reserve this property well (see Section 5.3 for details).</p><p>To address these issues, we propose a novel translation embedding model named TransC in this paper. Inspired by <ref type="bibr" target="#b17">(Tenenbaum et al., 2011)</ref>, concepts in people's mind are organized hierarchically and instances should be close to concepts that they belong to. Hence in TransC, each concept is encoded as a sphere and each instance as a vector in the same semantic space, and relative positions are employed to model the relations between concepts and instances. More specifically, instanceOf relation is naturally represented by checking whether an instance vector is inside a concept sphere. For the subClassOf relation, we enumerate and quantify four possible relative positions between two concept spheres. We also define loss functions to measure the relative positions and optimize knowledge graph embeddings. Finally, we incorporate them into translationbased models to jointly learn the knowledge representations of concepts, instances and relations.</p><p>Experiments on real world datasets extracted from YAGO show that TransC outperforms previous work like TransE, TransD, HolE, DistMult and ComplEx in most cases. The contributions of this paper can be summarized as follows:</p><p>1. To the best of our knowledge, we are the first to propose and formalize the problem of knowledge graph embedding which differentiates between concepts and instances.</p><p>2. We propose a novel knowledge embedding method named TransC, which distinguishes between concepts and instances and deals with the transitivity of isA relations.</p><p>3. We construct a new dataset based on YAGO for evaluation. Experiments on link prediction and triple classification demonstrate that TransC successfully addresses the above problems and outperforms state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are a variety of models for knowledge graph embedding. We divide them into three kinds and introduce them respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Translation-based Models</head><p>TransE <ref type="bibr" target="#b1">(Bordes et al., 2013</ref>) regards a relation r as a translation from h to t for a triple (h, r, t) in training set. The vector embeddings of this triple should satisfy h + r ≈ t. Hence, t should be the nearest neighbor of h + r, and the loss function is</p><formula xml:id="formula_0">f r (h, t) = ||h + r − t|| 2 2 .<label>(1)</label></formula><p>TransE is suitable for 1-to-1 relations, but it has problems when handling 1-to-N, N-to-1, and Nto-N relations.</p><p>TransH <ref type="bibr" target="#b21">(Wang et al., 2014)</ref> attempts to alleviate the problems of TransE above. It regards a relation vector r as a translation on a hyperplane with w r as the normal vector. The vector embeddings will be first projected to the hyperplane of relation r and get h ⊥ = h − w r hw r and t ⊥ = t − w r tw r . The loss function of TransH is</p><formula xml:id="formula_1">f r (h, t) = ||h ⊥ + r − t ⊥ || 2 2 .<label>(2)</label></formula><p>TransR/CTransR <ref type="bibr" target="#b8">(Lin et al., 2015b)</ref> addresses the issue in TransE and TransH that some entities are similar in the entity space but comparably different in other specific aspects. It sets a transfer matrix M r for each relation r to map entity embedding to relation vector space. Its loss function is</p><formula xml:id="formula_2">f r (h, t) = ||M r h + r − M r t|| 2 2 .<label>(3)</label></formula><p>TransD  considers the different types of entities and relations at the same time. Each relation-entity pair (r, e) will have a mapping matrix M re to map entity embedding into relation vector space. And the projected vectors could be defined as h ⊥ = M rh h and t ⊥ = M rt t.</p><p>The loss function of TransD is</p><formula xml:id="formula_3">f r (h, t) = ||h ⊥ + r − t ⊥ || 2 2 .<label>(4)</label></formula><p>There are many other translation-based models in recent years. For example, TranSparse <ref type="bibr" target="#b6">(Ji et al., 2016)</ref> simplifies TransR by enforcing the sparseness on the projection matrix, PTransE <ref type="bibr" target="#b7">(Lin et al., 2015a)</ref> considers relation paths as translations between entities for representation learning, <ref type="bibr" target="#b23">(Xiao et al., 2016a)</ref> proposes a manifold-based embedding principle (ManifoldE) for precise link prediction, TransF <ref type="bibr" target="#b2">(Feng et al., 2016)</ref> regards relation as translation between head entity vector and tail entity vector with flexible magnitude, <ref type="bibr" target="#b24">(Xiao et al., 2016b)</ref> proposes a new generative model TransG, and KG2E  uses Gaussian embedding to model the data uncertainty. All these models can be seen in <ref type="bibr">(Wang et al.)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Bilinear Models</head><p>RESCAL <ref type="bibr" target="#b12">(Nickel et al., 2011)</ref> is the first bilinear model. It associates each entity with a vector to capture its latent semantics. Each relation is represented as a matrix which models pairwise interactions between latent factors.</p><p>Many extensions of RESCAL have been proposed by restricting bilinear functions in recent years. For example, DistMult <ref type="bibr" target="#b26">(Yang et al., 2014)</ref> simplifies RESCAL by restricting the matrices representing relations to diagonal matrices. HolE <ref type="bibr" target="#b11">(Nickel et al., 2016)</ref> combines the expressive power of RESCAL with the efficiency and simplicity of DistMult. It represents both entities and relations as vectors in R d . ComplEx <ref type="bibr" target="#b18">(Trouillon et al., 2016)</ref> extends DistMult by introducing complex-valued embeddings so as to better model asymmetric relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">External Information Learning Models</head><p>External information like textual information is significant for knowledge representation. TEKE  uses external context information in a text corpus to represent both entities and words into a joint vector space with alignment models. DKRL <ref type="bibr" target="#b25">(Xie et al., 2016)</ref> directly learns entity representations from entity descriptions. <ref type="bibr" target="#b20">(Wang et al., 2015;</ref><ref type="bibr" target="#b3">Guo et al., 2016;</ref><ref type="bibr" target="#b13">Rocktäschel et al., 2015)</ref> use logical rules to strengthen representations of knowledge graphs.</p><p>All models above do not differentiate between concepts and instances. To the best of our knowledge, our proposed TransC is the first attempt which represents concepts, instances, and relations differently in the same space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>In this section, we formulate the problem of knowledge graph embedding with concepts and instances. Before that, we first introduce the input knowledge graph.</p><p>Knowledge Graph KG describes concepts, instances, and the relations between them. It can be formalized as KG = {C, I, R, S}. C and I denote the sets of concepts and instances respectively. Relation set R can be formalized as R = {r e , r c } ∪ R l , where r e is an instanceOf relation, r c is a subClassOf relation, and R l is the instance relation set. Therefore, the triple set S can be divided into three disjoint subsets:</p><formula xml:id="formula_4">1. InstanceOf triple set S e = {(i, r e , c) k } ne k=1 , where i ∈ I is an in- stance, c ∈ C is a concept, and n e is the size of S e . 2. SubClassOf triple set S c = {(c i , r c , c j ) k } nc k=1 , where c i , c j ∈ C are concepts, c i is a sub-concept of c j , and n c is the size of S c . 3. Relational triple set S l = {(h, r, t) k } n l k=1</formula><p>, where h, r ∈ I are head instance and tail instance, r ∈ R l is an instance relation, and n l is the size of S l .</p><p>Given knowledge graph KG, knowledge graph embedding with concepts and instances aims at learning embeddings for instances, concepts, and relations in the same space R k . For each concept c ∈ C, we learn a sphere s(p, m) with p ∈ R k and m denoting the sphere center and radius. For each instance i ∈ I and instance relation r ∈ R l , we learn a low-dimensional vector i ∈ R k and r ∈ R k respectively. Specifically, the instanceOf and subClassOf representations are well-designed so that the transitivity of isA relations can be reserved, namely, instanceOf-subClassOf :</p><formula xml:id="formula_5">" " " # # # ≥ | " + # | | " − # | ≤ &lt; | " + # | &lt; | " − # | ∧ " ≥ # " # &lt; | " − # | ∧ " &lt; # ( )</formula><formula xml:id="formula_6">(i, r e , c 1 ) ∈ S e ∧ (c 1 , r c , c 2 ) ∈ S c → (i, r e , c 2 ) ∈ S e ,<label>(5)</label></formula><p>and subClassOf-subClassOf transitivity shown in Equation <ref type="formula">6</ref>:</p><formula xml:id="formula_7">(c 1 , r c , c 2 ) ∈ S c ∧ (c 2 , r c , c 3 ) ∈ S c → (c 1 , r c , c 3 ) ∈ S c . (6)</formula><p>Based on the definition, how to model concepts and isA relations is critical to solve this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>To differentiate between concepts and instances for knowledge graph embedding, we propose a novel method named TransC. We define different loss functions to measure the relative positions in embedding space, and then jointly learn the representations of concepts, instances, and relations based on the translation-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">TransC</head><p>We have three kinds of triples in our triple set S and define different loss function for them respectively.</p><p>InstanceOf Triple Representation. For a given instanceOf triple (i, r e , c), if it is a true triple, i should be inside the sphere s to represent the instanceOf relation between them. Actually, there is another relative position that i is outside the sphere s. In this condition, the embeddings still need to be optimized. The loss function is defined as</p><formula xml:id="formula_8">f e (i, c) = ||i − p|| 2 − m.<label>(7)</label></formula><p>SubClassOf Triple Representation. For a subClassOf triple (c i , r c , c j ), just like before, concepts c i , c j are encoded as spheres s i (p i , m i ) and s j (p j , m j ). We first denote the distance between the centers of the two spheres as</p><formula xml:id="formula_9">d = ||p i − p j || 2 .<label>(8)</label></formula><p>If (c i , r c , c j ) is a true triple, sphere s i should be inside sphere s j <ref type="figure" target="#fig_1">(Figure 2a</ref>) to represent the subClassOf relation between them. Actually, there are three other relative positions between sphere s i and s j (as shown in <ref type="figure" target="#fig_1">Figure 2</ref>). We also have three loss functions under these three conditions:</p><p>1. s i is separate from s j <ref type="figure" target="#fig_1">(Figure 2b)</ref>. The embeddings still need to be optimized. In this condition, the two spheres need to get closer in optimalization. Therefore, the loss function is defined as</p><formula xml:id="formula_10">f c (c i , c j ) = ||p i − p j || 2 + m i − m j .<label>(9)</label></formula><p>2. s i intersects with s j <ref type="figure" target="#fig_1">(Figure 2c</ref>). This condition is similar to condition 1. The loss function is defined as</p><formula xml:id="formula_11">f c (c i , c j ) = ||p i − p j || 2 + m i − m j .<label>(10)</label></formula><p>3. s j is inside s i <ref type="figure" target="#fig_1">(Figure 2d</ref>). It is different from our target and we should reduce m j and increase m i . Hence, the loss function is</p><formula xml:id="formula_12">f c (c i , c j ) = m i − m j .<label>(11)</label></formula><p>Relational Triple Representation. For a relational triple (h, r, t), TransC will learn lowdimensional vectors h, t, r ∈ R k for instances and relations. Just like TransE <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref>, the loss function of this kind of triples is defined as</p><formula xml:id="formula_13">f r (h, t) = ||h + r − t|| 2 2 .<label>(12)</label></formula><p>After having embeddings above, TransC can easily deal with the transitivity of isA relations. If we have true triples (i, r e , c i ) and (c i , r c , c j ), which means i is inside the sphere s i and s i is inside s j , we can get a result that i is also inside the sphere s j . It can be concluded that (i, r e , c j ) is a true triple and TransC can handle instanceOf-subClassOf transitivity. Similarly, if we have true triples (c i , r c , c j ) and (c j , r c , c k ), we can get a result that sphere s i is inside sphere s k . It means (c i , r e , c k ) is a true triple and TransC can deal with subClassOf-subClassOf transitivity.</p><p>In experiments, we enforce constrains as ||h|| 2 ≤ 1, ||r|| 2 ≤ 1, ||t|| 2 ≤ 1 and ||p|| 2 ≤ 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Method</head><p>For instanceOf triples, we use ξ and ξ to denote a positive triple and a negative triple. S e and S e are used to describe the positive triple set and negative triple set. Then we can define a marginbased ranking loss for instanceOf triples: <ref type="formula" target="#formula_0">(13)</ref> where [x] + max (0, x) and γ e is the margin separating positive triplets and negative triplets. Similarly, for subClassOf triples, we will have a ranking loss: <ref type="formula" target="#formula_0">(14)</ref> and for relational triples, we will have a ranking loss:</p><formula xml:id="formula_14">L e = ξ∈Se ξ ∈S e [γ e + f e (ξ) − f e (ξ )] + ,</formula><formula xml:id="formula_15">L c = ξ∈Sc ξ ∈S c [γ c + f c (ξ) − f c (ξ )] + ,</formula><formula xml:id="formula_16">L l = ξ∈S l ξ ∈S l [γ l + f r (ξ) − f r (ξ )] + .<label>(15)</label></formula><p>Finally, we define the overall loss function as linear combinations of these three functions:</p><formula xml:id="formula_17">L = L e + L c + L l .<label>(16)</label></formula><p>The goal of training TransC is to minimize the above function, and iteratively update embeddings of concepts, instances, and concepts. Every triple in our training set has a label to indicate whether the triple is positive or negative. But existing knowledge graph only contains positive triples. We need to generate negative triples by corrupting positive triples. For a relational triple (h, r, t), we replace h or t to generate a negative triple (h , r, t) or (h, r, t ). For example, we get h by randomly picking from a set M t = M 1 ∪ M 2 ∪ · · · ∪ M n , where n is the number of concepts that t belongs to and M i = {a|a ∈ I ∧ (a, r e , c i ) ∈ S e ∧ (t, r e , c i ) ∈ S e ∧ t = a}. For the other two kinds of triples, we follow the same policy to generate negative triples. We also use two strategies "unif" and "bern" described in <ref type="bibr" target="#b21">(Wang et al., 2014)</ref> to replace instances or concepts.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Analysis</head><p>We evaluate our method on two typical tasks commonly used in knowledge graph embedding: link prediction <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref> and triple classification <ref type="bibr" target="#b15">(Socher et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>Most previous work used FB15K and WN18 (Bordes et al., 2013) for evaluation. But these two datasets are not suitable for our model because FB15K mainly consists of instances and WN18 mainly contains concepts. Therefore, we use another popular knowledge graph <ref type="bibr">YAGO (Suchanek et al., 2007)</ref> for evaluation, which contains a lot of concepts from WordNet and instances from Wikipedia. We construct a subset of YAGO named YAGO39K for evaluation through the following steps:</p><p>(1) We randomly select some relational triples like (h, r, t) from the whole YAGO dataset as our relational triple set S l .</p><p>(2) For every instance and instance relation existed in our relational triples, we save it to construct instance set I and instance relation set R l respectively.</p><p>(3) For every instanceOf triple (i, r e , c) in YAGO, if i ∈ I, we save this triple to construct instanceOf triple set S e .</p><p>(4) For every concept existed in instanceOf triple set S e , we save it to construct concept set C.</p><p>(5) For every subClassOf triple (c i , r c , c j ) in YAGO, if c i ∈ C ∧ c j ∈ C, we save this triple to construct subClassOf triple set S c .</p><p>(6) Finally, we achieve our triple set S = S e ∪ S c ∪ S l and our relation set R = {r e , r c } ∪ R l .</p><p>To evaluate every model's performance in handling the transitivity of isA relations, we generate some new triples based on YAGO39K using the transitivity of isA relations. These new triples will  be added to valid and test datasets of YAGO39K to create a new dataset named M-YAGO39K. Specific steps are described as follows:</p><p>(1) For every instanceOf triple (i, r e , c) in valid and test dataset, if (c, r c , c j ) exists in training dataset, we save a new instanceOf triple (i, r e , c j ).</p><p>(2) For every subClassOf triple (c i , r c , c j ) in valid and test dataset, if (c j , r c , c k ) exists in training dataset, we save a new subClassOf triple (c i , r c , c k ).</p><p>(3) We add these new triples to valid and test dataset of YAGO39K to get M-YAGO39K.</p><p>The statistics of YAGO39K and M-YAGO39K are shown in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Link Prediction</head><p>Link Prediction aims to predict the missing h or t for a relational triple (h, r, t). In this task, we need to give a ranking list of candidate instances from the knowledge graph, instead of only giving one best result.</p><p>For every test relational triple (h, r, t), we remove the head or tail instance and replace it with all instances existed in knowledge graph, and rank these instances in ascending order of distances calculated by loss function f r . Just like <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref>, we use two evaluation metrics in this task: (1) the mean reciprocal rank of all correct instances (MRR) and (2) the proportion of correct instances that rank no larger than N <ref type="figure">(Hits@N)</ref>. A good embedding model should achieve a high MRR and a high Hits@N. We note that a corrupted triple may also exist in knowledge graph, which should also be regarded as a correct prediction. However, the above evaluations do not handle this issue and may underestimate the results. Hence, we filter out every triple appeared in our knowledge graph before getting the ranking list. The first evaluation setting is called "Raw" and the second one is called "Filter." We report the experiment results on both settings.</p><p>In this task, we use dataset YAGO39K for evaluation. We select learning rate λ for SGD among {0.1, 0.01, 0.001}, the three margins γ l , γ e and γ c among {0.1, 0.3, 0.5, 1, 2}, the dimension of instance vectors and relation vectors n among {20, 50, 100}. The best configurations are determined according to the Hits@10 in valid set. The optimal configurations are: γ l = 1, γ e = 0.1, γ c = 1, λ = 0.001, n = 100 and taking L 2 as dissimilarity. We train every model for 1000 rounds in this task.</p><p>Evaluation results on YAGO39K are shown in <ref type="table" target="#tab_3">Table 2</ref>. From the table, we can conclude that: (1) TransC significantly outperforms other models in terms of Hits@N. This indicates that TransC can use isA triples' information better than other models, which is helpful for instance representation learning. (2) TransC performs a little bit worse than DistMult in some settings. The reason may be that we determine the best configurations only according to the Hits@10, which may lead to a low MRR. (3) The "bern" sampling trick works well for TransC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Triple Classification</head><p>Triple Classification aims to judge whether a given triple is correct or not, which is a binary classification task. This triple can be a relational triple, an instanceOf triple or a subClassOf triple.</p><p>Negative triples are needed for evaluation of binary classification. Hence, we construct some negative triples following the same setting in <ref type="bibr" target="#b15">(Socher et al., 2013)</ref>. There are as many true triples as negative triples in both valid and test set.</p><p>For triple classification, we set a threshold δ r for every relation r. For a given test triple, if its   loss function is smaller than δ r , it will be classified as positive, otherwise negative. δ r is obtained by maximizing the classification accuracy on valid set.</p><p>In this task, we use dataset YAGO39K and M-YAGO39K for evaluation. Parameters are selected in the same way as in link prediction. The best configurations are determined by accuracy in valid set. The optimal configurations for YAGO39K are: γ l = 1, γ e = 0.1, γ c = 0.1, λ = 0.001, n = 100 and taking L 2 as dissimilarity. The optimal configurations for M-YAGO39K are: γ l = 1, γ e = 0.1, γ c = 0.3, λ = 0.001, n = 100 and taking L 2 as dissimilarity. For both datasets, we traverse all the training triples for 1000 rounds.</p><p>Our datasets have three kinds of triples. Hence, we do experiments on them respectively. Experimental results for relational triples, instanceOf triples, and subClassOf triples are shown in Table 2, <ref type="table" target="#tab_5">Table 3, and Table 4</ref> respectively. In <ref type="table" target="#tab_5">Table  3</ref> and <ref type="table" target="#tab_6">Table 4</ref>, a rising arrow means performance of this model have a promotion from YAGO39K to M-YAGO39K and a down arrow means a drop.</p><p>From <ref type="table" target="#tab_3">Table 2</ref>, we can learn that: (1) TransC outperforms all previous work in relational triple classification.</p><p>(2) The "bern" sampling trick works better than "unif" in TransC.</p><p>From <ref type="table" target="#tab_5">Table 3</ref> and <ref type="table" target="#tab_6">Table 4</ref>, we can conclude that: (1) On YAGO39K, some compared models perform better than TransC in instanceOf triple classification. This is because that instanceOf has most triples (53.5%) among all relations in YAGO39K. This relation is trained superabundant times and nearly achieves the best performance, which has an adverse effect on other triples. TransC can find a balance between them and all triples achieve a good performance. (2) On YAGO39K, TransC outperforms other models in subClassOf triple classification. As shown in <ref type="table" target="#tab_1">Table 1</ref>, subClassOf triples are much less than instanceOf triples. Hence, other models can not achieve the best performance under the bad influence of instanceOf triples. (3) On M-YAGO39K, TransC outperforms previous work in both instanceOf triple classification and subClassOf triple classification, which indicates that TransC can handle the transitivity of isA relations much better than other models. (4) After comparing experimental results in YAGO39K and M-YAGO39K, we can find that most previous work's performance suffers a big drop in instanceOf triple classification and a small drop in subClassOf triple classification. This shows that previous work can not deal with instanceOf-subClassOf transitivity well. (5) In TransC, nearly all performances have a significant promotion from YAGO39K to M-YAGO39K. Both instanceOf-subClassOf transitivity and subClassOf-subClassOf transitivity are solved well in TransC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Case Study</head><p>We have shown that TransC have a good performance for knowledge graph embedding and dealing with transitivity of isA relations. In this section, we present an example of finding new instanceOf triples and subClassOf triples using results of TransC.</p><p>As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, New York City is an instance and others are concepts. The solid lines represent the triples from our datasets and the dotted lines represent the facts inferred by our model. TransC can find two new instanceOf triples (New York City, instanceOf, City) and (New York City, instanceOf, Municipality). It can also find a new subClassOf triple (Port Cities, subClassOf, City). Following the transitivity of isA relations, we can know all these three new triples are right. Unfortunately, most previous work regards these three triples as wrong, which means they can not handle transitivity of isA relations well. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we propose a new knowledge embedding model named TransC. TransC embeds instances, concepts, and relations in the same space to deal with the transitivity of isA relations. We create a new dataset YAGO39K for evaluation. Experiment results show that TransC outperforms previous translation-based models in most cases. Besides, It can also handle the transitivity of isA relations much better than other models. In our future work, we will explore the following research directions: (1) Sphere is a simple model to represent a concept in semantic space, but it still have some limits since it is too naive. we will try to find a more expressive model instead of spheres to represent concepts.</p><p>(2) A concept may have different meanings in different triples. We will try to use several typical vectors of instances as a concept's centers to represent different meanings of a concept. Then a concept can have different embeddings in different triples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of concepts, instances, and isA transitivity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Four relative positions between sphere s i and s j . transitivity shown in Equation 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>An inference example of TransC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of YAGO39K and M-YAGO39K.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Experimental results on link prediction and triple classification for relational triples. Hits@N uses results of "Filter" evaluation setting.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Experimental results on instanceOf triple classification(%).</figDesc><table><row><cell>Datasets</cell><cell></cell><cell cols="2">YAGO39K</cell><cell></cell><cell></cell><cell cols="2">M-YAGO39K</cell><cell></cell></row><row><cell>Metric</cell><cell cols="8">Accuracy Precision Recall F1-Score Accuracy Precision Recall F1-Score</cell></row><row><cell>TransE</cell><cell>77.6</cell><cell>72.2</cell><cell>89.8</cell><cell>80.0</cell><cell>76.9↓</cell><cell>72.3↑</cell><cell>87.2↓</cell><cell>79.0↓</cell></row><row><cell>TransH</cell><cell>80.2</cell><cell>76.4</cell><cell>87.5</cell><cell>81.5</cell><cell>79.1↓</cell><cell>72.8↓</cell><cell>92.9↑</cell><cell>81.6↑</cell></row><row><cell>TransR</cell><cell>80.4</cell><cell>74.7</cell><cell>91.9</cell><cell>82.4</cell><cell>80.0↓</cell><cell>73.9↓</cell><cell>92.9↑</cell><cell>82.3↓</cell></row><row><cell>TransD</cell><cell>75.9</cell><cell>70.6</cell><cell>88.8</cell><cell>78.7</cell><cell>76.1↑</cell><cell>70.7↑</cell><cell>89.0↑</cell><cell>78.8↑</cell></row><row><cell>HolE</cell><cell>70.5</cell><cell>73.9</cell><cell>63.3</cell><cell>68.2</cell><cell>66.6↓</cell><cell>72.3↓</cell><cell>53.7↓</cell><cell>61.7↓</cell></row><row><cell>DistMult</cell><cell>61.9</cell><cell>68.7</cell><cell>43.7</cell><cell>53.4</cell><cell>60.7↓</cell><cell>71.7↑</cell><cell>35.5↓</cell><cell>47.7↓</cell></row><row><cell>ComplEx</cell><cell>61.6</cell><cell>71.5</cell><cell>38.6</cell><cell>50.1</cell><cell>59.8↓</cell><cell>65.6↓</cell><cell>41.4↑</cell><cell>50.7↑</cell></row><row><cell>TransC (unif)</cell><cell>82.9</cell><cell>77.1</cell><cell>93.7</cell><cell>84.6</cell><cell>83.0↑</cell><cell>77.5↑</cell><cell>93.1↓</cell><cell>84.7↑</cell></row><row><cell>TransC (bern)</cell><cell>83.7</cell><cell>78.1</cell><cell>93.9</cell><cell>85.2</cell><cell>84.4↑</cell><cell>80.7↑</cell><cell>90.4↓</cell><cell>85.3↑</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Experimental results on subClassOf triple classification(%).</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work is supported by NSFC key project (No. 61533018, U1736204, 61661146007), Ministry of Education and China Mobile Research Fund (No.  20181770250), and THUNUS NExT Co-Lab.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by flexible translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Jointly embedding knowledge graphs and logical rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to represent knowledge graphs with gaussian embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge graph completion with adaptive sparse transfer matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling relation paths for representation learning of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tomaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Injecting logical background knowledge into embeddings for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleanor</forename><forename type="middle">H</forename><surname>Rosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="350" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">How to grow a mind: Statistics, structure, and abstraction. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Joshua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah D</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="1279" to="1285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhendong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Knowledge base completion using embeddings and rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
		<editor>IJ-CAI</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Text-enhanced representation learning for knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan-Zi</forename><surname>Li</surname></persName>
		</author>
		<editor>IJ-CAI</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">From one point to a manifold: knowledge graph embedding for precise link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Transg: A generative model for knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Representation learning of knowledge graphs with entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
