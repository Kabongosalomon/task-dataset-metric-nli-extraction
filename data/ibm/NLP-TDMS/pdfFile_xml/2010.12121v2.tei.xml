<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge Graph Embedding with Atrous Convolution and Residual Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiliang</forename><surname>Ren</surname></persName>
							<email>renfeiliang@cse.neu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juchen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bochao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruicheng</forename><surname>Ming</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University Shenyang</orgName>
								<address>
									<postCode>110169</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge Graph Embedding with Atrous Convolution and Residual Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge graph embedding is an important task and it will benefit lots of downstream applications. Currently, deep neural networks based methods achieve state-of-the-art performance. However, most of these existing methods are very complex and need much time for training and inference. To address this issue, we propose a simple but effective atrous convolution based knowledge graph embedding method. Compared with existing state-of-the-art methods, our method has following main characteristics. First, it effectively increases feature interactions by using atrous convolutions. Second, to address the original information forgotten issue and vanishing/exploding gradient issue, it uses the residual learning method. Third, it has simpler structure but much higher parameter efficiency. We evaluate our method on six benchmark datasets with different evaluation metrics. Extensive experiments show that our model is very effective. On these diverse datasets, it achieves better results than the compared state-of-theart methods on most of evaluation metrics. The source codes of our model could be found at https://github.com/neukg/AcrE. Recently, deep neural networks (DNN) based KGE methods <ref type="bibr" target="#b41">(Dettmers, 2018;</ref><ref type="bibr" target="#b11">Nguyen et al. , 2018;</ref><ref type="bibr" target="#b25">Yao et al. , 2020;</ref> Vashishth et al. , 2020a; Vashishth et al. , 2020b)  push the performance of KGE to a soaring height. Compared with previous methods, this kind of methods can learn more effective embeddings mainly due to the powerful learning ability inherent in the DNN models. However, as pointed out arXiv:2010.12121v2 [cs.AI] 30 Oct 2020</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graph is a kind of valuable knowledge bases and it is important for many AI-related applications. Generally, a KG stores factual knowledge in the form of structural triplets like &lt;h, r, t&gt;, which means there is a kind of r relation from h (head entity) to t (tail entity). Nowadays, great achievements have been made in building large scale KGs. Usually a KG may contain millions of entities and billions of relational facts. However, there are still two major difficulties that prohibit the availability of KGs. First, although most existing KGs contain large amount of triplets, they are far from completeness. Second, most existing KGs are stored in symbolic and logical formations while applications often involve numerical computing in continuous spaces. To address these two issues, researchers proposed knowledge graph embedding (KGE) methods that aim to learn a kind of embedding representations for a KG's items (entities and relations) by projecting these items into some continuous low-dimensional spaces. Generally, different kinds of KGE methods mainly differ in how to view the role of relations in the projected spaces. For example, translation based methods (TransE <ref type="bibr" target="#b1">(Bordes et al. , 2013)</ref>, TransH <ref type="bibr" target="#b57">(Wang et al. , 2014)</ref>, TransR <ref type="bibr">(Lin et al. , 2015a)</ref>, TransD <ref type="bibr" target="#b14">(Ji et al. , 2015)</ref>, et al.) view the relation in a triplet as a translation operation from the head entity to the tail entity. Other KGE methods view relations as some kind of combination operators that link head entities and tail entities. For example, HolE <ref type="bibr" target="#b28">(Nickel et al. , 2016)</ref> employs a circular correlation function as the combination operator in the project space. ComplEx <ref type="bibr" target="#b42">(Trouillon et al. , 2016)</ref> makes use of complex valued embeddings and takes the matrix decomposition as the combination operator. RT uses Tucker decomposition for KGE. RotateE  use the rotation operation in the complex space as the combination operator. Experimental results show these existing methods have strong feasibility and robustness in solving the mentioned two issues.</p><p>by <ref type="bibr" target="#b45">Xu et al. (2020)</ref> that existing research did not make a proper trade-off between the model complexity (the number of parameters) and the model expressiveness (the performance in capturing semantic information). Thus deep convolutional neural networks (DCNN) based methods are achieving more and more research attention due to their simple but effective structure. However, <ref type="bibr" target="#b24">Chen et al. (2018)</ref> point out that the DCNN based methods usually suffer from the reduced feature resolution issue that is caused by the repeated combination of max-pooling and down-sampling("striding") performed at consecutive layers of DCNNs. This will result in feature maps with significantly reduced spatial resolution when DCNN is employed in a fully convolutional fashion.</p><p>To address this issue, we propose an atrous convolution based KGE method which allows the model to effectively enlarge the field of view of filters almost without increasing the number of parameters or the amount of computations. To address the vanishing/exploding gradient issue inherent in the DNN based learning frame and the original information forgotten issue when more convolutions used, we introduce residual learning in the our method. We propose two learning structures to integrate different kinds of convolutions together: one is a serial structure, and the other is a parallel structure. We evaluate our method on six diverse benchmark datasets. Extensive experiments show that our method achieves better result than the compared state-of-the-art baselines under most evaluation metrics on these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Translation based KGE methods view the relation in a triplet as a translation operation from the head entity to the tail entity. These methods usually define a score function (or energy function) that has a form like ||h + rt || to measure the plausibility of a triplet. During training, almost all of them minimize a margin based ranking loss function over the training data. TransE <ref type="bibr" target="#b1">(Bordes et al. , 2013</ref>) is a seminal work in this branch. It directly takes the embedding space as a translation space. Formally, it tries to let h + r ≈ t if &lt;h, r, t&gt; holds. TransH <ref type="bibr" target="#b57">(Wang et al. , 2014</ref>) models a relation as a hyperplane together with a translation operation on it. TransR <ref type="bibr">(Lin et al. , 2015a</ref>) models entities and relations in distinct spaces, i.e., the entity space and multiple relation spaces. TransD <ref type="bibr" target="#b14">(Ji et al. , 2015)</ref> models each entity or relation by two vectors. TranSparse <ref type="bibr" target="#b15">(Ji et al. , 2016)</ref> mainly considers the heterogeneity property and the imbalance property in KGs. PTransE <ref type="bibr">(Lin et al. , 2015b)</ref> integrates relation paths into a TransE model. ITransF <ref type="bibr" target="#b30">(Xie et al. , 2017</ref>) uses a sparse attention mechanism to discover hidden concepts of relations and to transfer knowledge through the sharing of concepts. Recently, researchers also employ the methods of combining different distance functions together for KGE. For example, <ref type="bibr" target="#b0">Sadeghi et al. (2019)</ref> proposed a multi distance embedding (MDE) model, which consists of several distances as objectives.</p><p>Bilinear KGE models use different kinds of combination operators other than the translation. For example, HolE <ref type="bibr" target="#b28">(Nickel et al. , 2016</ref>) employs a circular correlation as the combination operator. ComplEx <ref type="bibr" target="#b42">(Trouillon et al. , 2016)</ref> makes use of complex valued embedding and takes matrix decomposition as the combination operator. Similar to ComplEx, RotatE  also use a complex space where each relation is defined as a rotation from the source entity to the target entity. <ref type="bibr" target="#b8">Xu and Li (2019)</ref> proposed DihEdral for KG relation embedding. By leveraging the desired properties of dihedral group, their method could support many kinds of relations like symmetry, inversion, etc.  propose the Relational Tucker3(RT) decomposition for multi-relational link prediction in knowledge graphs.</p><p>Other work, KG2E  uses a density-based method to model the certainty of entities and relations in a space of multi-dimensional Gaussian distributions. TransG <ref type="bibr" target="#b16">(Xiao et al. , 2016)</ref> mainly addresses the issue of multiple relation semantics.</p><p>Recently, researchers begin to explore the DNN based methods for KGE and achieve state-of-the-art results. For example, ConvE (Dettmers, 2018) uses 2D convolution over embeddings and multiple layers of nonlinear features to model KGs. <ref type="bibr">ConvKB (Nguyen et al. , 2018)</ref> also use convolutional neural network for KGE. ConMask <ref type="bibr">(Shi and Weniger, 2018)</ref>uses relationship-dependent content masking, fully convolutional neural networks, and semantic averaging to extract relationship-dependent embeddings from the textual features of entities and relations in KGs. More recently, <ref type="bibr" target="#b26">Guo et al. (2019)</ref> studied the path-level KG embedding learning and proposed recurrent skipping networks(RSNs) to remedy the problems of using sequence models to learn relational paths. <ref type="bibr" target="#b25">Yao et al. (2020)</ref>   , 2019) into the KGE model.  propose CoKE which uses Transformer <ref type="bibr" target="#b2">(Vaswani et al. , 2017)</ref>. <ref type="bibr">Vashishth et al. (2020a)</ref> extend ConvE by increasing the interactions with feature permutation, feature reshaping, and circular convolution.</p><p>Most recently, graph based neural network(GNN) methods are achieving more and more attentions. <ref type="bibr" target="#b27">Schlichtkrull et al. (2018)</ref> propose R-GCN, which is a graph based DNN model that uses neighboring information of each entity. <ref type="bibr" target="#b44">Bansal et al. (2019)</ref> propose A2N, an attention-based model based on graph neighborhood. <ref type="bibr" target="#b9">Shang et al. (2019)</ref> propose a weighted graph convolutional network based method that mainly utilizes learnable relational specific scalar weights during GCN aggregation. <ref type="bibr" target="#b32">Ye et al. (2019)</ref> propose VR-GCN, which is an extention of graph convolutional networks for embedding both nodes and relations. <ref type="bibr" target="#b9">Shang et al. (2019)</ref> propose SACN that takes the benefit of both GCN and ConvE. <ref type="bibr">Vashishth et al. (2020b)</ref> propose CompGCN which jointly embeds both nodes and relations in a relational graph.</p><p>However, as pointed out by <ref type="bibr" target="#b45">Xu et al. (2020)</ref> that most of these existing DNN-based or GNN-based KGE methods are very complex and time-consuming, which prevents them be used in some on-line or real-time application scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">AcrE Model</head><p>We denote our model as AcrE (the abbreviation of Atrous Convolution and Residual Embedding). In this study, we design two structures to integrate the standard convolution and atrous convolutions together. One is a serial structure as shown in <ref type="figure" target="#fig_0">Figure 1 (a)</ref>, and the other is a parallel structure as shown in <ref type="figure" target="#fig_0">Figure  1</ref> (b). We will introduce them one by one in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Serial AcrE Model</head><p>In the Serial AcrE model, the standard convolution and atrous convolutions are organized in a serial manner. As shown in <ref type="figure" target="#fig_0">Figure 1 (a)</ref>, the output of one convolution will be taken as the input of its subsequent adjoining convolution. In this model, the embeddings of an entity and its relation are first reshaped into a 2-Dimension representation, then a standard convolution and several atrous convolutions are performed serially. Next, the outputted embeddings of the last atrous convolution and the initial embeddings are combined by a residual learning based method. The combined embeddings are flattened into a vector. This vector is then used as features to get the probability distributions for the entity candidates. 2D Embedding Representation For a triplet &lt;h, r, t&gt;, we denote h, r and t as their corresponding embedding representations. ConvE points out that a 2-Dimension (2D for short) convolution operation is better than a 1D-convolution operation because a 2D-convolution increases the expressiveness of a CNN model through additional points of interaction between embeddings. Thus follow ConvE, we also use a 2D convolution in our model. To this end, the embedding concatenation of an entity and its linked relation is reshaped into a 2D embedding representation.</p><p>Specifically, we use τ to denote a 2D reshaping function and use e to denote the embedding of an entity e. If e, r ∈ R m , τ ([e; r]) ∈ R n 1 ×n 2 where 2 × m = n 1 × n 2 . In this study, we use [e; r] to denote the concatenation of e and r. Standard Convolution based Learning After the 2D reshaping process, a standard convolution operation is performed with Equation 1.</p><formula xml:id="formula_0">C i 0 = ω i 0 τ ([e; r]) + b i 0 (1)</formula><p>where denotes convolution operation, ω i 0 ∈ R k×k is the i-th filter and b i 0 is the i-th bias vector. Then the outputs of these filters are stacked to form the output of the standard convolution learning. We denote the final output of this standard convolution learning as C 0 , which could be simply written as C 0 = C 1 0 : C 2 0 : C 3 0 : ... : C F 0 and F is the number of filters used. It should be noted that we don't perform a max-pooling operation that is often used in traditional CNN models. This is because the input of our model is always an entity and a relation. Thus the length of the convolution output is fixed. It is unnecessary to use a max-pooling to generate a new length-fixed representation. Our in-house experiments show that there is no obvious performance difference between with and without a max-pooling operation. Atrous Convolution based Learning Atrous convolution, also called as dilated convolution, inserts some holes (zeros) in the input during convolution. Given an input vector x with a filter vector w of length K, the output vector y of an atrous convolution is computed with Equation 2.</p><formula xml:id="formula_1">y i = K k=1 x i+l×k × w k<label>(2)</label></formula><p>Here l (the atrous rate parameter) means the stride with which we sample the input. Obviously, the standard convolution is a special case of the atrous convolution when l is set to 1.</p><p>Specifically, in the Serial AcrE model, an atrous convolution takes the output of its previous convolution as input, and output a new result with Equation 3.</p><formula xml:id="formula_2">C t = ω t C t−1 + b t<label>(3)</label></formula><p>where C t−1 is the output of previous convolution operation, ω t and b t are the filter and bias vector respectively in the i-th convolution. Feature Vector Generation In the Serial AcrE model, different kinds of convolutions are performed one by one. Each convolution will extract some interaction features from the output of its previous convolution. Thus the mined features would "forget" more and more original input information as convolutions performed. However, the original information is the foundation of all mined features, so "forget" them will increase the risk that the mined features are actually irrelevant to what are needed. We call this phenomenon as original information forgotten issue. Besides, there is an inherent vanishing/exploding gradient issue in the deep networks. Here we use the residual learning method  to add original input information back so as to address both issues. Then the result of residual learning is flattened into a feature vector. Specifically, the whole process is defined with Equation 4.</p><formula xml:id="formula_3">o = F latten(ReLU(C T + τ ([e; r])))<label>(4)</label></formula><p>where C T is the output of last atrous convolution, and T is the number of atrous convolutions. Score Function With the generated feature vector o, we define the following function to compute a score to measure the degree of an entity candidate t can form a correct triplet with the input &lt;h,r&gt;.</p><formula xml:id="formula_4">ψ(h, r, t) = (oW + b) t<label>(5)</label></formula><p>where W is a transformation matrix and b is a bias vector. Then a sigmoid function is used to get the probability distribution over all candidate entities. p (t|h, r) = sigmoid(ψ(h, r, t))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parallel AcrE Model</head><p>In the Parallel AcrE model, the standard convolution and atrous convolutions are organized in a parallel manner. As shown in <ref type="figure" target="#fig_0">Figure 1 (b)</ref>, different kinds of convolutions are performed simultaneously, then their results are combined and flattened into a vector. Similar to the Serial AcrE model, this vector is used as features to get the probability distributions for the entity candidates. Compared with the Serial AcrE model, most of the components in the Parallel AcrE model have the same definitions except for the results integration and feature vector generation. We will introduce these two differences in the following part. Results Integration Different from the serial structure, there will be multi results generated by different convolution operations. Accordingly, we need to integrate these results together. This process can be defined with following Equation <ref type="formula" target="#formula_6">7</ref>.</p><formula xml:id="formula_6">C = C 0 ⊕ C 1 ⊕ ... ⊕ C T<label>(7)</label></formula><p>where C 0 is the result of standard convolution and C i is the result of the i-th atrous convolution, and ⊕ means a result integration operation. There are different kinds of integration methods. In this study, we explore two widely used methods for this. One is an element-add operation based method, the other is a concatenation operation based method. Feature Vector Generation As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the final output of the whole convolution learning is followed by a transformation operation. Then the results are flattened into the feature vector. Specially, the process can be written with Equation 8, where W 1 is the transformation matrix. c = F latten(W 1 Relu(C + τ ([e; r]))) (8)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>Different from other KGE methods that often use a max-margin loss function for training, most neural networks based KGE methods (like ProjE, ConvE, etc.) often use the following two kinds of ranking loss functions. One is a kind of binary cross-entropy loss that the ranking scores are calculated independently (pointwise ranking method), and the other is a kind of softmax regression loss that considers the ranking scores collectively (listwise ranking method). Both ProjE and ConvE show that the latter one achieves better experimental results. In AcrE, we define a same listwise loss function as used in ConvE.</p><formula xml:id="formula_7">L = − 1 N N i=1 [t i log p (t i |h, r) + (1 − t i ) log (1 − p (t i |h, r))]<label>(9)</label></formula><p>where t is a label vector whose elements are ones for relationships that exist and zero otherwise, and N is the number of entities in a KG. This loss function takes one (h,r) pair and scores it against all entities simultaneously. Thus our model is very fast for both training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Analyses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Settings</head><p>Datasets We evaluate our method on six widely used benchmark datasets. The first two are WN18 <ref type="bibr" target="#b6">(Bordes et al. , 2014)</ref> and FB15k <ref type="bibr" target="#b6">(Bordes et al. , 2014)</ref>. The second two are WN18RR and FB15k-237 <ref type="bibr" target="#b41">(Dettmers, 2018)</ref>, which are two variant datasets for WN18 and FB15k to avoid test leakage. The rest two are Alyawarra Kinship <ref type="bibr" target="#b48">(Lin et al. , 2018)</ref> and DB100K <ref type="bibr" target="#b7">(Ding et al. , 2018)</ref>, both are new datasets proposed in recent years. Some statistics of these six datasets are shown in <ref type="table" target="#tab_2">Table 1</ref>. Evaluation Task We use link prediction, one of the most frequently used benchmark evaluation tasks for KGE methods, to evaluate our model. Link prediction is to predict the missing h or t for a correct triplet &lt;h, r, t&gt;, i.e., predict t given &lt;h, r&gt; or predict h given &lt;r, t&gt;. Rather than requiring one best answer, this task emphasizes more on ranking a set of candidate entities from the KG. Hits@k and MRR are often used as the evaluation metrics.    0.233 11.5 30.1 44.8 HolE <ref type="bibr" target="#b28">(Nickel et al. , 2016)</ref> 0.26 18.2 30.9 41.1 ComplEx <ref type="bibr" target="#b42">(Trouillon et al. , 2016)</ref> 0.242 12.6 31.2 44 Analogy  0.252 14.2 32.3 42.7 RUGE  0.246 12.9 32.5 43.3 ComplEx-NNE+AER <ref type="bibr" target="#b7">(Ding et al. , 2018)</ref>    <ref type="bibr" target="#b45">Xu et al. (2020)</ref>.</p><p>In experiments, all the parameters, including initial embeddings, transformation matrices, and bias vectors, are randomly initialized. Hyper-parameters are selected by a grid search on the validation set. All the results are reported when 3 atrous convolutions used for both learning structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>Overall Results <ref type="table" target="#tab_4">Table 2</ref> and 3 show the experimental results on different datasets under different evaluation metrics. It should be noted that not all models report their results on all these six datasets, so the compared baselines on different datasets are different in these two tables. In subsequent part, all the experimental results for the compared baselines are taken from some latest published papers or their original papers. From these results we can draw following two conclusions. First, our model is very robust and it significantly outperforms the compared state-of-the-art results under all the evaluation metrics on all datasets except for WN18RR. Especially on DB100K, FB15k, and Kinship, both AcrE (Serial) and AcrE (Parallem) outperform the compared baselines by a large margin under almost all the evaluation metrics. As for WN18RR, our model still achieves very competitive results. Especially when compared with other DCNN-based KGE methods like ConvE and ConvKB, we can see that both the Serial and the Parallel models perform much better.</p><p>Second, AcrE (Parallel) performs better than AcrE (Serial) in most cases. We think this is mainly due to the reason that the Serial structure based method suffers more from the original information forgotten issue than the Parallel structure based method. Detailed Results We conduct following two kinds of detailed experiments to further demonstrate the performance of our model. One is Head and Tail Prediction, and the other is Prediction by Categories.</p><p>In the first kind of detailed experiments, we compare the performance of our model with several representative state-of-the-art baselines on FB15k-237 for predicting missing head entities and predicting missing tail entities. The results are summarized into <ref type="table">Table 4</ref>, from which we can see that our model FB15K WN18 MRR H@1 H@3 H@10 MRR H@1 H@3 H@10 TransE <ref type="bibr" target="#b1">(Bordes et al. , 2013)</ref> 0.463 29.7 57.8 74.9 0.495 11.3 88.8 94.3 HolE <ref type="bibr" target="#b28">(Nickel et al. , 2016)</ref> 0.524 40.2 61.3 73.9 93.8 93.0 94.5 94.9 ComplEx <ref type="bibr" target="#b42">(Trouillon et al. , 2016)</ref> 0.692 59.9 75.9 84.0 0.941 93.6 94.5 94.7 SimplE <ref type="bibr" target="#b36">(Kazemi et al. , 2018)</ref> 0.727 66.0 77.3 83.8 0.942 93.9 94.4 94.7 D4-Gumbel <ref type="bibr" target="#b8">(Xu and Li, 2019)</ref> 0.728 64.8 78.2 86.4 0.728 64.8 78.2 86.4 D4-STE <ref type="bibr" target="#b8">(Xu and Li, 2019)</ref> 0.733 64.1 80.3 87.7 0.733 64.1 80.3 87.7 ConvE <ref type="bibr" target="#b41">(Dettmers, 2018)</ref> 0.657 55.8 72.3 83.1 0.942 93.5 94.7 95.5 R-GCN <ref type="bibr" target="#b27">(Schlichtkrull et al. , 2018)</ref> 0.696 60.1 76.0 84.2 0.696 60.1 76.0 84.2 RotatE  0.797 74.6 83.0 88.4 0.949 94.4 95.2 95.9 RSNs <ref type="bibr" target="#b26">(Guo et al. , 2019)</ref> 0.78 72.  <ref type="bibr" target="#b11">(Nguyen et al. , 2018)</ref> 0.243 15.5 37.1 42.1 0.249 0.057 41.7 52.4 R-GCN <ref type="bibr" target="#b27">(Schlichtkrull et al. , 2018)</ref> 0.164 10 18.1 30 0.123 8 13.7 20.7 RotatE  0.338 24.1 37.5 53.3 0.476 42.8 49.2 57.1 D4-STE <ref type="bibr" target="#b8">(Xu and Li, 2019)</ref> 0.320 23.0 35.3 50.2 0.480 45.2 49.1 53.6 SACN <ref type="bibr" target="#b9">(Shang et al. , 2019)</ref> 0.35 26.0 39.0 54.0 0.47 43.0 48.0 54.0 HypER <ref type="bibr">(Balazevic et al. , 2019b)</ref> 0.341 25.2 37.6 52.0 0.465 43.6 47.7 52.2 ConvR <ref type="bibr" target="#b47">(Jiang et al. , 2019)</ref> 0.350 26.1 38.5 52.8 0.475 44.3 48.9 53.7 VR-GCN <ref type="bibr" target="#b32">(Ye et al. , 2019)</ref> 0.248 15.9 27.2 43.2 ----RSNs <ref type="bibr" target="#b26">(Guo et al. , 2019)</ref> 0.280 20.2 -45.3 ----DK-STE <ref type="bibr" target="#b8">(Xu and Li, 2019)</ref> 0.320 23.0 35.3 50.2 0.480 45.2 49.1 53.6 CompGCN <ref type="bibr">(Vashishth et al. , 2020b)</ref>   <ref type="bibr" target="#b42">(Trouillon et al. , 2016)</ref> 0.823 73.3 89.9 97.1 ConvE <ref type="bibr" target="#b41">(Dettmers, 2018)</ref> 0.833 73.8 91.7 98.1 ConvKB <ref type="bibr" target="#b11">(Nguyen et al. , 2018)</ref> 0.614 43.6 75.5 95.3 R-GCN <ref type="bibr" target="#b27">(Schlichtkrull et al. , 2018)</ref> 0.109 3 8.8 23.9 SimplE <ref type="bibr" target="#b36">(Kazemi et al. , 2018)</ref> 0.752 62.6 85.4 97.2 RotatE  0.843 76.0 91.9 97.8 HAKE <ref type="bibr" target="#b56">(Zhang et al. , 2020)</ref> 0.852 76.9 92.8 98.0 InteractE <ref type="bibr">(Vashishth et al. , 2020a)</ref> 0.777 66.4 87.0 95.9 CompGCN <ref type="bibr">(Vashishth et al. , 2020b</ref><ref type="bibr">) 0.778 66.7 86.8 96.7 CoKE(Wang et al. , 2020</ref> 0   <ref type="bibr" target="#b41">(Dettmers, 2018)</ref> 0.211 13.2 23.1 36.8 0.416 32.3 45.7 60.1 SACN <ref type="bibr" target="#b9">(Shang et al. , 2019)</ref> 0.241 15.8 26.0 40.9 0.446 35.2 49.0 63.1 RotatE  0.239 14.9 26.5 42.4 0.432 32.9 47.7 63.9 InteractE <ref type="bibr">(Vashishth et al. , 2020a)</ref>   <ref type="table">Table 4</ref>: Head and Tail Predictions on FB15k-237. All the compared results are the best results we can achieve by running the source codes provided by the original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Prediction Head (Hits@10) Prediction Tail <ref type="formula">(Hits@10)</ref> 1-to-1 1-to-n n-to-1 m-to-n 1-to-1 1-to-n n-to-1 m-to-n  outperforms the compared baselines again under all the evaluation metrics.</p><p>In the second kind of detailed experiments, we compare the performance of our model with several representative state-of-the-art baselines on FB15k for predicting by different categories. The results are shown in <ref type="table" target="#tab_11">Table 5</ref>. We can see that ArcE does much better than other compared baselines on almost all types of relations except the 1-to-1 relations. This merit is much important for real application scenarios where the complexer relations often take up large proportions. For example, in FB15k, one of the largest available KGs, the triplets of 1-to-1 are about 1.4%, 1-to-n are about 8.9%, n-to-1 are about 14.6%, and m-to-n are about 75.1%. Ablation Results <ref type="table">Table 6</ref> shows the ablation experiments of our model on FB15k and FB15k-237. We can see that there is a large different between the performance of "with/without" residual learning in most cases. As analyzed above, the more serial convolutions used, the more original information would be forgotten. While a residual learning adds the original information back. Accordingly, the mentioned issue is alleviated greatly. Since AcrE (Serial) forgets more original information than AcrE (Parallel), it achieves more performance gains from residual learning.</p><p>From <ref type="table">Table 6</ref> we can also observe that the integration method plays important role in AcrE (Parallel). Usually, the concatenation based integration method is superior to an element-add based integration method in most cases. Here we do not use some complexer integration methods like gate control based methods for we do not want to make the model too complex.</p><p>Besides, the atrous rate and the number of atrous convolutions used also affect the performance. Here we do not report the performance under different settings of these two hyper-parameters due to space  <ref type="table">Table 6</ref>: Ablation experiments on FB15k and FB15k-237. "add" and "con" refer to the element-add and concatenation integration methods respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>ParaNum (Millions) ConvE <ref type="bibr" target="#b41">(Dettmers, 2018)</ref> ≈ 4.96 RotatE  ≈ 29.32 SACN <ref type="bibr" target="#b9">(Shang et al. , 2019)</ref> ≈ 9.63 InteractE <ref type="bibr">(Vashishth et al. , 2020a)</ref> ≈ 10.7 CompGCN <ref type="bibr">(Vashishth et al. , 2020b</ref>) ≈ 9.45 HAKE <ref type="bibr" target="#b56">(Zhang et al. , 2020)</ref> ≈ 29.79 CoKE  ≈ 10.19 AcrE (Serial) ≈ 5.61 AcrE(Parallel) ≈ 6.22 <ref type="table">Table 7</ref>: Parameter efficiency on FB15k-237 ("ParaNum" refers to the number of parameters).</p><p>limitation. In fact, both of these two parameters are easily selected due to their small search spaces. Parameter efficiency We also compare the parameter efficiency between our model and some stateof-the-art models on FB15k-237. For each method, we report the number of parameters associated with the optimal configuration that leads to the performance shown in <ref type="table" target="#tab_8">Table 3</ref>. The comparision results are shown in <ref type="table">Table 7</ref>, from which we can see that the number of parameters in AcrE is close with ConvE, but is far less than that in other compared baselines. This is in line with our expectation: using atrous convolutions would not increase the parameters greatly. These results show that our model is more parameter efficient, it achieves substantially better results with fewer parameters. Note that AcrE (Parallel) has more parameters than AcrE (Serial) because it has an extra transformation operation after the result integration.</p><p>Here we do not quantitatively compare the runtime of different models for it is difficult to provide a fair evaluation environment: coding tricks, hyper-parameter settings (like batch-size, learning rate), parallelization, lot of non-model factors affect the runtime. However, AcrE can be viewed as a variant of ConvE. Theoretically, it has the same time complexity as ConvE that has been proven to be faster than most existing state-of-the-art methods. Taking FB15k-237 as an example, when using a Titan XP GPU server, it takes about 220 and 100 seconds per epoch during training for AcrE (Serial) and AcrE (Parallel) respectively. As for inference, it only takes 14 and 6 seconds for AcrE (Serial) and AcrE (Parallel) respectively to finish the whole test set evaluation. While some latest GNN or DNN based methods often takes many hours even several days to complete the same work under the same experiment settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we propose AcrE, a simple but effective DNN-based KGE model. We make comprehensive comparisons between AcrE and many state-of-the-art baselines on sis diverse benchmark datasets. Extensive experimental results show that AcrE is very effective and it achieves better results than the compared baselines under most evaluation metrics on six benchmark datasets. The main contributions of our method are summarized as follows. First, to our best knowledge, this is the first work that uses different kinds of convolutions for the KGE task. Second, we propose two simple but effective learning structures to integrate different kinds of convolutions together. Third, the proposed model has much better parameter efficiency than the compared baselines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a): Structure of Serial AcrE; (b): Structure of Parallel AcrE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>integrate BERT (Devlin et al.</figDesc><table><row><cell></cell><cell></cell><cell>e1 rel</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Reshape</cell><cell cols="2">Conv Standard</cell><cell>Conv Atrous</cell><cell>... ...</cell><cell>Conv Atrous</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Residual</cell><cell>Flatten</cell><cell>Project to Embedding Space</cell></row><row><cell></cell><cell>e1-des1</cell><cell>CNN</cell><cell>α1</cell><cell></cell><cell>Reshape</cell><cell>(a)</cell></row><row><cell></cell><cell>…</cell><cell>…</cell><cell>∑</cell><cell>Stand</cell><cell></cell><cell>Atrous Conv Block</cell><cell>Flatten and Project to Embedding Space Reshape</cell></row><row><cell></cell><cell>e1-desk</cell><cell>e1 rel CNN</cell><cell>αk</cell><cell>Conv</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Atrous</cell><cell></cell><cell>Gate</cell><cell>Concat</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Conv</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>e1</cell><cell>rel</cell><cell></cell><cell>Concat</cell></row><row><cell></cell><cell></cell><cell>Reshape</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>...</cell><cell>...</cell><cell>...</cell><cell>Flatten</cell><cell>Embedding Space Project to</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Atrous</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Conv</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Residual</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stand</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Conv</cell><cell></cell></row><row><cell></cell><cell>e1 rel</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Reshape</cell><cell>Conv Standard</cell><cell>Conv Atrous</cell><cell></cell><cell>... ...</cell><cell>Conv Atrous</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Residual</cell><cell>Flatten</cell><cell>Project to Embedding Space</cell></row><row><cell>e1-des1</cell><cell>CNN</cell><cell>α1</cell><cell></cell><cell cols="2">Reshape</cell></row><row><cell>…</cell><cell>…</cell><cell>∑</cell><cell></cell><cell></cell><cell>Atrous Conv Block</cell><cell>Flatten and Project to Embedding Space</cell></row><row><cell>e1-desk</cell><cell>CNN</cell><cell>αk</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Gate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>e1</cell><cell>rel</cell><cell></cell><cell>Concat</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics.</figDesc><table><row><cell>Model</cell><cell cols="2">MRR H@1 H@3 H@10</cell></row><row><cell>TransE(Bordes et al. , 2013)</cell><cell>0.111 1.6</cell><cell>16.4 27</cell></row><row><cell>DistMult</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Experimental results on DB100k. All the compared results are taken from</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>Experimental results on the rest five benchmark datasets.</figDesc><table><row><cell>Predict Head</cell><cell>Predict Tail</cell></row><row><cell cols="2">MRR H@1 H@3 H@10 MRR H@1 H@3 H@10</cell></row><row><cell>ConvE</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>Predictions by Categories on FB15k. The compared results are taken from their original papers.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">MDE: Multi Distance Embeddings for Link Prediction in Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afshin</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Graux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shariat</forename><surname>Hamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Yazdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relation data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762v4</idno>
	</analytic>
	<monogr>
		<title level="j">Attention Is All You Need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ProjE: embedding projection for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Weninger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Open-World Knowledge Graph Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Weninger</surname></persName>
		</author>
		<idno>AAAI2018</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database or structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Asemantic matching energy function for learning with multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="259" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving knowledge graph embedding using simple constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="page" from="110" to="121" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Relation Embedding with Dihedral Group in Knowledge Graph. ACL2019</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijing</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">End-to-end structure-aware convolutional networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">STransE: a novel embedding model of entities and relationships in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Kairitsirts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="460" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A Novel Embedding Model for Knowledge Base Comple-tion Based on Convolutional Neural Network. NAACL2018</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="327" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A Capsule Network-based Embedding Model for Knowledge Graph Completion and Search Personalization. InNAACL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2180" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Improving neural net-works by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illy</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslanr</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">newblockarXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Knowledge graph completion with adaptive sparse transfer matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<idno>AAAI2016</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TransG: a generative model for knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2316" to="2325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">SSP: semantic space projection for knowledge graph embedding with text descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianmeng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<idno>AAAI2017</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analogical inference for multi-relational embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2168" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">TuckER: Tensor Factorization for Knowledge Graph Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balazevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09590v1</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hypernetwork knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balazevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Knowledge graph representation with jointly structural and textual encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1318" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno>CVPR2016</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">KG-BERT: BERT for Knowledge Graph Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengsheng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<idno>ICML2019</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Modeling Relational Data with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ESWC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Holo-graphic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1995" to="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An inter-pretable knowledge transfer model for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="950" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">CoKE: Contextualized Knowledge Graph Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pingping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songtai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A vectorized relational graph convolutional network for multi-relational network alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4135" to="4141" />
		</imprint>
	</monogr>
	<note>Yujie Fang, Hongyu Zang, and Mingzhong Wang</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Representation learning of knowledge graphs with entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Jiajia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2659" to="2665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Representation learning of knowledge graphs with hierarchical types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2965" to="2971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06103</idno>
		<title level="m">Modeling Relational Data with Graph Convolutional Networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SimplE Embedding for Link Prediction in Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Seyed Mehran Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">InteractE: Improving Convolution-based Knowledge Graph Embeddings by Increasing Feature Interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Vashishth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Nitin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nilesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Composition-based multi-relational graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Vashishth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Nitin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to Represent Knowledge Graph with Gaussian Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding with iterative guidance from soft rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4816" to="4823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Convolutional 2D Knowledge Graph Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Latent Features for Knowledge Base and Text Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compo-sitionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compo-sitionality</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
	<note>Observed Versus</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A2N: Attending to Neighbors for Knowledge Graph Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trapit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4387" to="4392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">SEEK: Segmented Embedding of Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00856v1</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Effective Deep Memory Networks for Distant Supervised Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjie</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4002" to="4008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adaptive convolution for multi-relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotian</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-hop knowledge graph reasoning with reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Modeling relation paths for representation learning of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="705" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Knowledge repre-sentation learning with entities, attributes and relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2866" to="2872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Neural Relation Extraction with Multi-lingual Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">A Relational Tucker Decomposition for Multi-Relational Link Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00898v1</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Embedding Entities and Relations for Learning and Inference in Knowledge Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Predicting Semantic Relations using Global Graph Properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Pinter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.08644v1</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanqiu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
