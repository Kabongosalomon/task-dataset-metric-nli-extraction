<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminatively Boosted Image Clustering with Fully Convolutional Auto-Encoders</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-03-24">March 24, 2017 23 Mar 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengfu</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Academy of Mathematics and Systems Science</orgName>
								<orgName type="department" key="dep2">School of Mathematical Sciences</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Qiao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">CAS Centre for Excellence in Brain Science and Intelligence Technology Shanghai</orgName>
								<address>
									<postCode>200031</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Academy of Mathematics and Systems Science</orgName>
								<orgName type="department" key="dep2">School of Mathematical Sciences</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyang</forename><surname>Xi</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discriminatively Boosted Image Clustering with Fully Convolutional Auto-Encoders</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-03-24">March 24, 2017 23 Mar 2017</date>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Elsevier</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>image clustering</term>
					<term>fully convolutional auto-encoder</term>
					<term>representation learning</term>
					<term>discriminatively boosted clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditional image clustering methods take a two-step approach, feature learning and clustering, sequentially. However, recent research results demonstrated that combining the separated phases in a unified framework and training them jointly can achieve a better performance. In this paper, we first introduce fully convolutional auto-encoders for image feature learning and then propose a unified clustering framework to learn image representations and cluster centers jointly based on a fully convolutional auto-encoder and soft k-means scores. At initial stages of the learning procedure, the representations extracted from the auto-encoder may not be very discriminative for latter clustering. We address this issue by adopting a boosted discriminative distribution, where high score assignments are highlighted and low score ones are de-emphasized. With the gradually boosted discrimination, clustering assignment scores are discriminated and cluster purities are enlarged. Experiments on several vision benchmark datasets show that our methods can achieve a state-of-the-art performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Clustering methods are very important techniques for exploratory data analysis with wide applications ranging from data mining <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, dimension reduction <ref type="bibr" target="#b2">[3]</ref>, segmentation <ref type="bibr" target="#b3">[4]</ref> and so on. Their aim is to partition data points into clusters so that data in the same cluster are similar to each other while data in different clusters are dissimilar. Approaches to achieve this aim include partitional methods such as k-means and k-medoids, hierarchical methods like agglomerative clustering and divisive clustering, methods based on density estimation such as DBSCAN <ref type="bibr" target="#b4">[5]</ref>, and recent methods based on finding density peaks such as CFSFDP <ref type="bibr" target="#b5">[6]</ref> and LDPS <ref type="bibr" target="#b6">[7]</ref>.</p><p>Image clustering <ref type="bibr" target="#b7">[8]</ref> is a special case of clustering analysis that seeks to find compact, object-level models from many unlabeled images. Its applications include automatic visual concept discovery <ref type="bibr" target="#b8">[9]</ref>, content-based image retrieval and image annotation. However, image clustering is a hard task mainly owning to the following two reasons: 1) images often are of high dimensionality, which will significantly affect the performance of clustering methods such as k-means <ref type="bibr" target="#b9">[10]</ref>, and 2) objects in images usually have twodimensional or three-dimensional local structures which should not be ignored when exploring the local structure information of the images.</p><p>To address these issues, many representation learning methods have been proposed for image feature extractions as a preprocessing step. Traditionally, various hand-crafted features such as SIFT <ref type="bibr" target="#b10">[11]</ref>, HOG <ref type="bibr" target="#b11">[12]</ref>, NMF <ref type="bibr" target="#b12">[13]</ref>, and (geometric) CW-SSIM similarity <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> have been used to encode the visual information. Recently, many approaches have been proposed to combine clustering methods with deep neural networks (DNN), which have shown a remarkable performance improvement over hand-crafted features <ref type="bibr" target="#b15">[16]</ref>. Roughly speaking, these methods can be categorized into two groups: 1) sequential methods that apply clustering on the learned DNN representations, and 2) unified approaches that jointly optimize the deep representation learning and clustering objectives.</p><p>In the first group, a kind of deep (convolutional) neural networks, such as deep belief network (DBN) <ref type="bibr" target="#b16">[17]</ref> and stacked auto-encoders <ref type="bibr" target="#b17">[18]</ref>, is first trained in an unsupervised manner to approximate the non-linear feature embedding from the raw image space to the embedded feature space (usually being low-dimensional). And then, either k-means or spectral clustering or agglomerative clustering can be applied to partition the feature space. However, since the feature learning and clustering are separated from each other, the learned DNN features may not be reliable for clustering.</p><p>There are a few recent methods in the second group which take the separation issues into consideration. In <ref type="bibr" target="#b18">[19]</ref>, the authors proposed deep embedded clustering that simultaneously learns feature representations with stacked auto-encoders and cluster assignments with soft k-means by minimizing a joint loss function. In <ref type="bibr" target="#b19">[20]</ref>, joint unsupervised learning was proposed to learn deep convolutional representations and agglomerative clustering jointly using a recurrent framework. In <ref type="bibr" target="#b20">[21]</ref>, the authors proposed an infinite ensemble clustering framework that integrates deep representation learning and ensemble clustering. The key insight behind these approaches is that good representations are beneficial for clustering and conversely clustering results can provide supervisory signals for representation learning. Thus, two factors, designing a proper representation learning model and designing a suitable unified learning objective will greatly affect the performance of these methods.</p><p>In this paper, we follow recent advances to propose a unified clustering method named Discriminatively Boosted Clustering (DBC) for image analysis based on fully convolutional auto-encoders (FCAE). See <ref type="figure" target="#fig_0">Fig. 1</ref> for a glance of the overall framework. We first introduce a fully convolutional encoder-decoder network for fast and coarse image feature extraction. We then discard the decoder part and add a soft k-means model on top of the encoder to make a unified clustering model. The model is jointly trained with gradually boosted discrimination where high score assignments are highlighted and low score ones are de-emphasized. The our main contributions are summarized as follows:</p><p>• We propose a fully convolutional auto-encoder (FCAE) for image feature learning. The FCAE is composed of convolution-type layers (convolution and de-convolution layers) and pool-type layers (pooling and un-pooling layers). By adding batch normalization (BN) layers to each of the convolution-type layers, we can train the FCAE in an end-toend way. This avoids the tedious and time-consuming layer-wise pretraining stage adopted in the traditional stacked (convolutional) autoencoders. To the best of our knowledge, this is the first attempt to learn a deep auto-encoder in an end-to-end manner.</p><p>• We propose a discriminatively boosted clustering (DBC) framework based on the learned FCAE and an additional soft k-means model.</p><p>We train the DBC model in a self-paced learning procedure, where deep representations of raw images and cluster assignments are jointly learned. This overcomes the separation issue of the traditional clustering methods that use features directly learned from auto-encoders.</p><p>• We show that the FCAE can learn better features for clustering than raw images on several image datasets include MNIST, USPS, COIL-20 and COIL-100. Besides, with discriminatively boosted learning, the FCAE based DBC can outperform several state-of-the-art analogous methods in terms of k-means and deep auto-encoder based clustering.</p><p>The remaining part of this paper is organized as follows. Some related work including stacked (convolutional) auto-encoders, deconvolutional neural networks, and joint feature learning and clustering are briefly reviewed in Section 2. Detailed descriptions of the proposed FCAE and DBC are presented in Section 3. Experimental results on several real datasets are given in Section 4 to validate the proposed methods. Conclusions and future works are discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Stacked auto-encoders <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> have been studied in the past years for unsupervised deep feature extraction and nonlinear dimension reduction. Their extensions for dealing with images are convolutional stacked auto-encoders <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. Most of these methods contain a two-stage training procedure <ref type="bibr" target="#b25">[26]</ref>: one is layer-wise pre-training and the other is overall finetuning. One of the significant drawbacks of this learning procedure is that the layer-wise pre-training is time-consuming and tedious, especially when the base layer is a Restricted Boltzmann Machine (RBM) rather than a traditional auto-encoder or when the overall network is very deep.</p><p>Recently, there is an attempt to discard the layer-wise pre-training procedure and train a deep auto-encoder type network in an end-to-end way. In <ref type="bibr" target="#b28">[29]</ref>, a deep deconvolution network is learned for image segmentation. The input of the architecture is an image and the output is a segmentation mask. The network achieves the state-of-the-art performance compared with analogous methods thanks to three factors: 1) introducing a deconvolution layer and a unpooling layer <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref> to recover the original image size of the segmentation mask, 2) applying the batch normalization <ref type="bibr" target="#b32">[33]</ref> to each convolution layer and each deconvolution layer to reduce the internal covariate shifts, which not only makes an end-to-end training procedure possible but also speeds up the process, and 3) adopting a pre-trained encoder on largescale datasets such as VGG-16 model <ref type="bibr" target="#b33">[34]</ref>. The success of the architecture motivates us that it is possible to design an end-to-end training procedure for fully convolutional auto-encoders.</p><p>Clustering has also been studied in the past years based on independent features extracted from auto-encoders (see, e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>). Recently, there are attempts to combine the auto-encoders and clustering in a unified framework <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b39">40]</ref>. In <ref type="bibr" target="#b18">[19]</ref>, the authors proposed Deep Embedded Clustering (DEC) that learns deep representations and cluster assignments jointly. DEC uses a deep stacked auto-encoder to initialize the feature extraction model and a Kullback-Leibler divergence loss to fine-tune the unified model. In <ref type="bibr" target="#b39">[40]</ref>, the authors proposed Deep Clustering Network (DCN), a joint dimensional reduction and k-means clustering framework. The dimensional reduction model is based on deep neural networks. Although these methods have achieved some success, they are not suitable for dealing with highdimensional images due to the use of stacked auto-encoders rather than convolutional ones. This motivates us to design a unified clustering framework based on convolutional auto-encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed methods</head><p>In this section, we propose a unified image clustering framework with fully convolutional auto-encoders and a soft k-means clustering model (see <ref type="figure" target="#fig_0">Fig. 1</ref>). The framework contains two parts: part I is a fully convolutional auto-encoder (FCAE) for fast and coarse image feature extraction, and part II is a discriminatively boosted clustering (DBC) method which is composed of a fully convolutional encoder and a soft k-means categorizer. The DBC takes an image as input and exports soft assignments as output. It can be jointly trained with a discriminatively boosted distribution assumption, which makes the learned deep representations more suitable for the top categorizer. Our idea is very similar to self-paces learning <ref type="bibr" target="#b8">[9]</ref>, where easiest instances are first focused and more complex objects are expanded progressively. In the following subsections, we will explain the detailed implementation of the idea. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Fully convolutional auto-encoder for image feature extraction</head><p>Traditional deep convolutional auto-encoders adopt a greedy layer-wise training procedure for feature transformations. This could be tedious and time-consuming when dealing with very deep neural networks. To address this issue, we propose a fully convolutional auto-encoder architecture which can be trained in an end-to-end manner. Part I of <ref type="figure" target="#fig_0">Fig. 1</ref> shows an example of FCAE on the MNIST dataset. It has the following features:</p><p>Fully Convolutional As pointed out in <ref type="bibr" target="#b26">[27]</ref>, the max-pooling layers are very crucial for learning biologically plausible features in the convolutional architectures. Thus, we adopt convolution layers along with max-pooling layers to make a fully convolutional encoder (FCE). Since the down-sampling operations in the FCE reduce the size of the output feature maps, we use an unpooling layer introduced in [29] to recover the feature maps. As a result, the unpooling layers along with deconvolution layers (see <ref type="bibr" target="#b28">[29]</ref>) are adopted to make a fully convolutional decoder (FCD).</p><p>Symmetric The overall architecture is symmetric around the feature layer. In practice, it is suggested to design layers of an odd number. Otherwise, it will be ambiguous to define the feature layer. Besides, fully connected layers (dense layers) should be avoided in the architecture since they destroy the local structure of the feature layer.</p><p>Normalized The depth of the whole network grows in log-magnitude as the input image size increases. This could make the network very deep if the original image has a very large width or height. To overcome this problem, we adopt the batch normalization (BN) <ref type="bibr" target="#b32">[33]</ref> strategy for reducing the internal covariate shift and speeding up the training. The BN operation is performed after each convolutional layer and each deconvolutional layer except for the last output layer. As pointed out in <ref type="bibr" target="#b28">[29]</ref>, BN is critical to optimize the fully convolutional neural networks.</p><p>FCAE utilizes the two-dimensional local structure of the input images and reduces the redundancy in parameters compared with stacked auto-encoders (SAEs). Besides, FCAE differs from conventional SAEs as its weights are shared among all locations within each feature map and thus preserves the spatial locality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Discriminatively boosted clustering</head><p>Once FCAE has been trained, we can extract features with the encoder part to serve as the input of a categorizer. This strategy is used in many clustering methods based on auto-encoders, such as GraphEncoder <ref type="bibr" target="#b17">[18]</ref>, deep embedding networks <ref type="bibr" target="#b34">[35]</ref>, and auto-encoder based clustering <ref type="bibr" target="#b35">[36]</ref>. These approaches treat the auto-encoder as a preprocessing step which is separately designed from the latter clustering step. However, the representations learned in this way could be amphibolous for clustering, and the clusters may be unclear (see the initial stage in <ref type="figure" target="#fig_1">Fig. 2)</ref>).</p><p>To address this issue, we propose a self-paced approach to make feature learning and clustering in a unified framework (see Part II in <ref type="figure" target="#fig_0">Fig. 1</ref>). We throw away the decoder of the FACE and add a soft k-means model on top of the feature layer. To train the unified model, we trust easier samples first and then gradually utilize new samples with the increasing complexity. Here, an easier sample (see the regions labelled 2, 3 and 4 in <ref type="figure" target="#fig_1">Fig. 2)</ref> is much certain to belong to a specific cluster, and a harder sample (see the region 1 in <ref type="figure" target="#fig_1">Fig.  2)</ref> is very likely to be categorized to multiple clusters. <ref type="figure" target="#fig_1">Fig. 2</ref> describes the difference between these samples at a different learning stage of DBC.</p><p>There are three challenging questions in the learning problem of DBC which will be answered in the following subsections: 1. How to choose a proper criterion to determine the easiness or hardness of a sample? 2. How to transform harder samples into easier ones? 3. How to learn from easier samples?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Easiness measurement with the soft k-means scores</head><p>We follow DEC <ref type="bibr" target="#b18">[19]</ref> to adopt the t-distribution-based soft assignment to measure the easiness of a sample. The t-distribution is investigated in <ref type="bibr" target="#b36">[37]</ref> to deal with the crowding problem of low-dimensional data distributions. Under the t-distribution kernel, the soft score (or similarity) between the feature z i (i ∈ 1, 2, . . . , m) and the cluster center µ j (j ∈ 1, 2, . . . , k) is</p><formula xml:id="formula_0">s ij ∝ 1 + ||z i − µ j || 2 v − v+1 2 (1) s.t. k j=1 s ij = 1</formula><p>Here, v is the degree of freedom of the t-distribution and set to be 1 in practice. The most important reason for choosing the t-distribution kernel is that it has a longer tail than the famous heat kernel (or the Gaussiandistribution kernel). Thus, we do not need to pay much attention to the parameter estimation (see <ref type="bibr" target="#b36">[37]</ref>), which is a hard task in unsupervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Boosting easiness with discriminative target distribution</head><p>We transform the harder examples to the easier ones by boosting the higher score assignments and, meanwhile, bring down those with lower scores. This can be achieved by constructing an underlying target distribution r ij from s ij as follows:</p><formula xml:id="formula_1">r ij ∝ s α ij , α &gt; 1 (2) s.t. k j=1 r ij = 1</formula><p>Suppose we can ideally learn from the soft scores (denoted as S) to the assumptive distribution (denoted as R) each time. Then we can generate a learning chain as follows:</p><formula xml:id="formula_2">S (0) → R (0) = S (1) → R (1) = S (2) → · · · .</formula><p>The following two properties can be observed from the chain:</p><formula xml:id="formula_3">Property 1 If s (0) ij = s (0)</formula><p>ij for any j and j , then s Proof Under the condition, and by <ref type="formula">(2)</ref> we can deduce that r</p><formula xml:id="formula_4">(0) ij ≡ r (0)</formula><p>ij . By the chain this is equivalent to the fact that s</p><formula xml:id="formula_5">(1) ij ≡ s (1) ij . Thus, the conclusion s (t) ij ≡ s (t)</formula><p>ij follows recursively for all t. Property 2 If there exists an l such that s</p><formula xml:id="formula_6">(0) il &gt; max j =l s (0) ij , then limit t→∞ s (t) ij = 1 if j = l 0 if j = l Proof By (2) we have s (t) ij s (t) il = s (t−1) ij s (t−1) il α = s (t−2) ij s (t−2) il α 2 = · · · = s (0) ij s (0) il α t .</formula><p>By the assumption s</p><formula xml:id="formula_7">(0) il &gt; max j =l s (0) ij , it is seen that s (0) ij /s (0)</formula><p>il &lt; 1 for any j = l. On the other hand, since α &gt; 1, we have limit</p><formula xml:id="formula_8">t→∞ α t = ∞. Thus, limit t→∞ s (t) ij s (t) il = limit α t →∞ s (0) ij s (0) il α t = 0, ∀j = l. Since s (t)</formula><p>il is finite, we have limit Property 1 tells us that the hardest sample (which has the equal probability to be assigned to different clusters) would always be the hardest one. However, in practical applications, there can hardly exist such examples. Property 2 shows that the initial non-discriminative samples could be boosted gradually to be definitely discriminative. As a result, we get the desired features for k-means clustering.</p><p>Note that the boosting factor α controls the speed of the learning process. A larger α can make the learning process more quickly than smaller ones. However, it may boost some falsely categorized samples too quickly at initial stages and thus makes their features irrecoverable at later stages.</p><p>Besides, it can be helpful to balance the data distribution at different learning stages. In <ref type="bibr" target="#b18">[19]</ref>, the authors proposed to normalize the boosted assignments to prevent large clusters from distorting the hidden feature space. This problem can be overcome by dividing a normalization factor n j = m i=1 r ij for each of the r ij .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Learning with the Kullback-Leibler divergence loss</head><p>In the last subsection, it was assumed that we could learn from s ij to the boosted target distribution r ij . This aim can be achieved with a joint Kullback-Leibler (KL) divergence loss, that is, <ref type="figure">Fig. 3</ref> gives an example of the joint loss when k = 2, where L ij = r ij log(r ij /s ij ) is the loss generated by the sample x i with respect to the jth cluster (j = 1 or 2). Regions marked in <ref type="figure">Fig. 3</ref> roughly correspond to the regions marked in <ref type="figure" target="#fig_1">Fig. 2</ref>. Intuitively, the loss has the following main features:</p><formula xml:id="formula_9">(θ * , µ * ) = arg min θ, µ L = KL(R||S) = m i=1 k j=1 r ij log r ij s ij .<label>(3)</label></formula><p>• For an ambiguous (or hard) sample (i.e., s ij ≈ s il , ∀j, l), its loss L i = k j=1 r ij log(r ij /s ij ) ≈ 0 according to Property 1. Therefore, it will not be seriously treated in the learning process. (Region 1)</p><p>• For a good categorized sample (i.e., there exists an l such that 1 s il &gt; max j =l s ij ), its loss will be much greater than zero, and thus it will be treated more seriously. (Regions 2 and 3) <ref type="figure">Figure 3</ref>: KL divergence loss with respect to the soft scores assigned to the first cluster.</p><p>Here we assume that there are 2 clusters, so 0.5 is a random guess probability.</p><p>• For a definitely well categorized sample (i.e., there exists an l such that 1 ≈ s il max j =l s ij ), its loss will be near zero. This means that its features do not need to be changed much more. (Region 4) By (1)-(3), the gradients of the KL divergence loss w.r.t. z i and µ j can be deduced as follows:</p><formula xml:id="formula_10">∂L ∂z i = 1 + v v k j=1 (r ij − s ij ) z i − µ j 1 + ||z i − µ j || 2 /v<label>(4)</label></formula><p>and</p><formula xml:id="formula_11">∂L ∂µ j = 1 + v v m i=1 (r ij − s ij ) µ j − z i 1 + ||µ j − z i || 2 /v<label>(5)</label></formula><p>The derivation of (4) and <ref type="formula" target="#formula_11">(5)</ref> can be found in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Training algorithm</head><p>In this section, we summarize the overall training procedure of the proposed method in Algorithm 1 and Algorithm 2. They implement the framework showed in <ref type="figure" target="#fig_0">Fig. 1</ref>. Here T is the maximum learning epochs, B is the maximum updating iterations in each epoch and m b is the mini-batch size. The encoder part of FCAE is f : x → z, which is parameterized by θ e and the decoder part of FCAE is g: z →x, which is parameterized by θ d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Discriminatively Boosted Clustering (DBC)</head><p>Require: X, T , B, m b , α, k Ensure: θ and µ //Stage I: Train a FCAE and clustering with its features 1: Train a deep fully convolutional auto-encoder</p><formula xml:id="formula_12">x i θe −→ z i (features) θ d −→x i (M1)</formula><p>with the Euclidian loss</p><formula xml:id="formula_13">(θ * e , θ * d ) = arg min θe, θ d m i=1 ||x i −x i || 2 2 = m i=1 ||x i − g θ d (f θe (x i ))|| 2 2</formula><p>by using the traditional error back-propagation algorithm. 2: Extract features: Z ← f θ * e (X) 3: Clustering with the features: µ z ← k-means centers</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we present experimental results on several real datasets to evaluate the proposed methods by comparing with several state-of-the-art methods. To this end, we first introduce several evaluation benchmarks and then present visualization results of the inner features, the learned FCAE weights, the frequency hist of soft assignments during the learning process and the features embedded in a low-dimensional space. We will also give some ablation studies with respect to the boosting factor α, the normalization factor n j and the FCAE initializations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation benchmarks</head><p>Datasets We evaluate the proposed FCAE and DBC methods on two hand-written digit image datasets (MNIST 1 and USPS 2 ) and two multi-view object image datasets (COIL-20 3 and COIL-100 4 ). The size of the datasets, Forward propagate (M2) and update the soft assignments</p><formula xml:id="formula_14">s ij ← (1 + ||z i − µ j || 2 ) −1 k j=1 (1 + ||z i − µ j || 2 ) −1 , where z i = f θ (x i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Update the target distribution</p><formula xml:id="formula_15">r ij ← s α ij /n j k j=1 s α ij /n j , where n j = m i=1</formula><p>s α ij .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>for b = 1 to B do 10:</p><p>Forward propagate (M2) with a mini-batch of m b samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Backward propagate (M2) from <ref type="formula" target="#formula_10">(4)</ref> and <ref type="formula" target="#formula_11">(5)</ref> to get ∂L/∂θ and ∂L/∂µ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>Update θ and µ with the gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>end for <ref type="bibr">14:</ref> Stop if hard assignments remain unchanged. <ref type="bibr" target="#b14">15</ref>: end for the number of categories, the image sizes and the number of channels are summarized in <ref type="table" target="#tab_0">Table 1</ref>. Evaluation metrics Two standard metrics are used to evaluate the experiment results explained as follows.</p><p>• Accuracy (ACC) <ref type="bibr" target="#b18">[19]</ref>. Given the ground truth labels {c i |1 ≤ i ≤ m} and the predicted assignments {ĉ i |1 ≤ i ≤ m}, ACC measures the average accuracy:</p><formula xml:id="formula_16">ACC(ĉ, c) = max g 1 m m i=1 1{c i = g(ĉ i )}</formula><p>where g ranges over all possible one-to-one mappings between the labels of the predicted clusters and the ground truth labels. The optimal mapping can be efficiently computed using the Hungarian algorithm <ref type="bibr" target="#b37">[38]</ref>.</p><p>• Normalized mutual information (NMI) <ref type="bibr" target="#b38">[39]</ref>. From the information theory point of view NMI can be interpreted as</p><formula xml:id="formula_17">NMI(ĉ, c) = MI(ĉ, c) max(H(ĉ), H(c))</formula><p>where H(c) is the entropy of c and NMI(ĉ, c) is the mutual information ofĉ and c. <ref type="table" target="#tab_1">Table 2</ref> shows the network architecture of the encoder parts with respect to different datasets. The decoder parts are totally reversed by the encoder parts. We use max-pooling in all the experiments. The size of all the feature layers is 1 × 1. No padding is used in the convolutional layers except for the USPS dataset whose padding size is 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network architectures</head><p>The comparing methods To validate the effectiveness of FCAE and DBC, we compare them with the following state-of-the-art methods in terms of the k-means and deep auto-encoders based clustering.</p><p>• KMS is the baseline method that applies the k-means algorithm on raw images.</p><p>• DAE-KMS <ref type="bibr" target="#b18">[19]</ref> uses deep auto-encoders for feature extraction and then applies k-means for later clustering.</p><p>• AEC <ref type="bibr" target="#b35">[36]</ref> is a variant of DAE-KMS that simultaneously optimizes the data reconstruction error and representation compactness. • IEC <ref type="bibr" target="#b20">[21]</ref> incorporates the deep representation learning and ensemble clustering.</p><p>• DEC <ref type="bibr" target="#b18">[19]</ref> simultaneously learns the feature representations and cluster centers using deep auto-encoders and soft k-means, respectively.</p><p>• DEN <ref type="bibr" target="#b34">[35]</ref> learns the clustering-oriented representations by utilizing deep auto-encoders and manifold constraints.</p><p>• DCN <ref type="bibr" target="#b39">[40]</ref> jointly applies dimensionality reduction and k-means clustering.</p><p>• FCAE-KMS (our algorithm) adopts FCAE for feature extraction and applies k-means for the latter clustering.</p><p>• DBC (our algorithm) uses Algorithm ?? for training a unified clustering method.  <ref type="table" target="#tab_2">Table 3</ref> summarizes the benchmark results on the MNIST dataset. The k-means method performs badly on raw images. However, based on the end-to-end trained FACE features, k-means can achieve comparative results compared with DAE-KMS which uses greedily layerwise trained deep auto-encoder features. Moreover, with an additional joint training, DBC outperforms FCAE-KMS and beats all the other comparing methods in terms of ACC and NMI. <ref type="table" target="#tab_3">Tables 4-6</ref> show the benchmarks on USPS, COIL-20 and COIL-100, respectively. Similarly to the observations on the MNIST hand-writeen digits dataset, DBC outperforms FCAE-KMS by a large margin on the USPS handwritten digits dataset. On the COIL sets, DBC obtained a little better results than FCAE-KMS did.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and analysis</head><p>On the hand-written digits datasets, the number of samples is much larger than the number of categories. This results in the distribution of the FCAE features to be closely related, and lots of ambiguous samples may occur. As a result, discriminatively boosting makes sense on these datasets. Thus, there is no doubt that DBC performs much better than FCAE-KMS. On the COIL sets, DBC takes little advantage of the discriminatively boosting procedure since the FCAE features are very helpful for clustering. Thus, there are very few ambiguous samples whose easiness needs to be boosted.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Visualization</head><p>One of the advantages of fully convolutional neural networks is that we can naturally visualize the inner activations (or features) and the trained weights (or filters) in a two-dimensional space <ref type="bibr" target="#b26">[27]</ref>. Besides, we can monitor the learning process of DBC by drawing frequency hists of assignment scores. In addition, t-SNE can be applied to the embedded features to visualize the manifold structures in a low-dimensional space. Finally, we show some typical falsely categorized samples generated by our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Visualization of the inner activations and learned filters</head><p>In <ref type="figure">Fig. 4</ref>, we visualize the inner activations of FCAE on the MNIST dataset with three digits: 1, 5, and 9. As shown in the figure, the activations in the feature layer are very sparse. Besides, the deconvolutional layer gradually recovers details of the pooled feature maps and finally gives a rough description of the original image. This indicates that FCAE can learn clustering-friendly features and keep the key information for image reconstruction. <ref type="figure">Fig. 5</ref> visualizes the learned filters of FCAE on the MNIST dataset. It is observed in <ref type="bibr" target="#b26">[27]</ref> that the stacked convolutional auto-encoders trained on noisy inputs (30% binomial noise) and a max-pooling layer can learn localized biologically plausible filters. However, even without adding noise, the learned deconvolutional filters in our architectures are non-trivial Gabor-like filters which are visually the nicest shapes. This is due to the use of max-pooling and unpooling operations. As discussed in <ref type="bibr" target="#b26">[27]</ref>, the max-pooling layers are elegant way of enforcing sparse codes which are required to deal with the over-complete representations of convolutional architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Monitoring the learning process</head><p>We use frequency hist of the soft assignment scores to monitor the learning process of DBC. <ref type="figure">Fig. 6</ref> shows the hists of scores on the MNIST test dataset  (a subset of the MNIST dataset with 10000 samples). The scores are assigned to the first cluster at different learning epochs. At early epochs (t ≤ 4), most of the scores are near 0.1. This is a random guess probability because there are 10 clusters. As the learning procedure goes on, some higher score samples are discriminatively boosted and their scores become larger than others. As a result, the cluster tends to "believe" in these higher score samples and consequently make scores of the others to be smaller (approximating zero). Finally, the scores assigned to the cluster become two-side polarized. Samples with very high scores (s ij ≈ 0.8) are thought to definitely belong to the first cluster and the others with very small scores (s ij ≈ 0.02) should belong to other clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Embedding learned features in a low dimensional space</head><p>We visualize the distribution of the learned features in a two-dimensional space with t-SNE <ref type="bibr" target="#b36">[37]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4.">Visualization of falsely categorized examples</head><p>In <ref type="figure" target="#fig_8">Fig. 8</ref>, we show the top 100 falsely categorized examples whose maximum soft assignment scores are over 0.6. It can be observed that it is very hard to distinguish between some ground truth digits 4, 7 and 9 even with human experience. Lots of digits 7 are written with transverse lines in their middle space and would be thought to be ambiguous for the clustering algorithm. Besides, some ground truth images are themselves confusing, such as those showed with the gray background. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussions</head><p>In this section, we make some ablation studies on the learning process with respect to different boosting factors (α), different normalization methods (n j ) and different initialization models generated by FCAE. <ref type="figure">Fig. 9(a)</ref> shows the ACC and NMI curves, where α equals to 1.5, 2, 4. With a small α (α = 1.5), the learning process is very slow and takes very long time to terminate. On the contrary, when the factor is set to be very large (α = 4), the learning process is very fast at the initial stages. However, this could result in falsely boosting some scores of the ambiguous samples. As a consequence, the model learned too much from some false information so the performance is not so satisfactory. With a moderate boosting factor (α = 2), the ACC and NMI curves grow reasonably and progressively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Impact of the boosting factor α</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Impact of the balance normalization</head><p>In DEC <ref type="bibr" target="#b18">[19]</ref>, the authors pointed out that the balance normalization plays an important role in preventing large clusters from distorting the hidden feature space. To address this issue, we compare three normalization strategies: 1) the constant normalization for comparison, that is, n j = 1, 2) the normalization by dividing the sum of the original soft assignment score per cluster, that is, n j = i s ij , which is adopted in DEC, and 3) the normalization by dividing the sum of the boosted soft assignment score per cluster, that is, n j = i s α ij . <ref type="figure">Fig. 9</ref>(b) presents the value curves of ACC and NMI against the epoch with these settings. Initially, the normalization does not affect ACC and NMI very much. However, the constant normalization can easily get stuck at early stages. The normalization by dividing n j = i s ij has certain power of preventing the distortion. Our normalization strategy gives the best performance compared with the previous methods. This is because our normalization directly reflects the changes of the boosted scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Impact of the FCAE initialization</head><p>To investigate the impact of the FCAE initialization on DBC, we compare the performance of DBC with three different initialization models: 1) the random initialization, 2) the initialization with a half-trained FCAE model, and 3) the initialization with a sufficiently trained FCAE model. The comparison results are shown in <ref type="figure">Fig. 9</ref>(c). As illustrated in the figure, DBC performs greatly based on all the models even when the initialization model is randomly distributed. However, if the FCAE model is not sufficiently trained, the resultant DBC model will be suboptimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and future works</head><p>In this paper, we proposed FCAE and DBC to deal with image representation learning and image clustering, respectively. Benchmarks on several visual datasets show that our methods can achieve superior performance than the analogous methods. Besides, the visualization shows that the proposed learning algorithm can implement the idea proposed in Section 3.2. Some : Ablation studies with respect to the boosting factor α, the balance normalization factor n j and the FCAE initialization models.</p><p>issues to be considered in the future include: 1) adding suitable constraints on FCAE to deal with natural images, and 2) scaling the algorithm to deal with large-scale datasets such as the ImageNet dataset. so</p><formula xml:id="formula_18">∂q ij ∂z i = ∂q ij ∂u ij · ∂u ij ∂z i = (− 1 + v 2 )u − 3+v 2 ij · 2 v (z i − µ j ) = (− 1 + v v )u −1 ij q ij · (z i − µ j ). (<label>.4)</label></formula><p>Further, let s ij = q ij j q ij .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(.5)</head><p>Then we have</p><formula xml:id="formula_19">∂s ij ∂z i = ∂q ij ∂z i · j q ij − q ij · j ∂q ij ∂z i ( j q ij ) 2 = (− 1+v v )u −1 ij q ij · (z i − µ j ) · j q ij − q ij · j (− 1+v v )u −1 ij q ij · (z i − µ j ) ( j q ij ) 2 = (− 1 + v v ) q ij j q ij u −1 ij · (z i − µ j ) · j q ij − j u −1 ij q ij · (z i − µ j ) j q ij = (− 1 + v v )s ij (u −1 ij · (z i − µ j ) − j u −1 ij s ij · (z i − µ j )). (<label>.6)</label></formula><p>Combine the above expressions to get the required result</p><formula xml:id="formula_20">∂L ∂z i = − j r ij s ij · ∂s ij ∂z i (.7) = 1 + v v j r ij − s ij u ij (z i − µ j ) = 1 + v v j (r ij − s ij ) z i − µ j 1 + ||z i − µ j || 2 /v (<label>.8)</label></formula><p>B. Derivation of (5).</p><p>(5) can be derived similarly by exchanging µ and z in the above derivations of (4).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A unified image clustering framework. Part I is a fully convolutional autoencoder (FCAE), and Part II is a discriminatively boosted clustering (DBC) framework based on the FCAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Learning procedure of DBC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>ij ≡ 1/k for all j and all time step t.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>ij = 0, ∀j = l. Finally, with the constrains</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 2 5 :</head><label>25</label><figDesc>DBC (Continued) //Stage II: Jointly learn the FCE and cluster centers 4: Construct a unified clustering model with encoder parameters θ and clus-Initialization: θ ← θ * e , µ ← µ z 6: for t = 1 to T do 7:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Visualization of the inner activations with respect to digits 1, 5 and 9. Visualization of the learned FCAE filters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 Figure 6 :Figure 7 :</head><label>767</label><figDesc>shows the embedded features of the MNIST test dataset at different epochs. At the initial epoch, the features learned Visualization of the soft score frequency hists with respect to the first cluster at different learning stages. with FCAE are not very discriminative for clustering. As shown in Fig. 7(a), the features of digits 3, 5, and 8 are closely related. The same thing happened with digits 4, 7, and 9. At the second epoch, the distribution of the learned features becomes much compact locally. Besides, the features of digit 7 become far away from those of digits 4 and 9. Similarly, the features of digit 8 get far away from those of digits 3 and 5. As the learning procedure goes on, the hardest digits (4 v.s. 9, 3 v.s. 5) for categorization are mostly well categorized after enough discriminative boosting epochs. The observation is consistent with the results showed in Subsection 4.2.2. Visualization of the embedded features in a two-dimensional space with t-SNE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Visualization of falsely categorized high score samples (top-100). The number in the top-left corner is the clustering label which is generated by the Hungarian algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 9: Ablation studies with respect to the boosting factor α, the balance normalization factor n j and the FCAE initialization models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Datasets used in our experiments.</figDesc><table><row><cell>Dataset</cell><cell cols="4">#Samples #Categories Image Size #Channels</cell></row><row><cell>MNIST</cell><cell>70000</cell><cell>10</cell><cell>28×28</cell><cell>1</cell></row><row><cell>USPS</cell><cell>11000</cell><cell>10</cell><cell>16×16</cell><cell>1</cell></row><row><cell>COIL-20</cell><cell>1440</cell><cell>20</cell><cell>128×128</cell><cell>1</cell></row><row><cell>COIL-100</cell><cell>7200</cell><cell>100</cell><cell>128×128</cell><cell>3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Detailed configuration of the network architecture of the convolutional encoder. The first rows are the filter sizes of the corresponding layer (filter size or pooling size, #filters). The second rows are the output sizes (feature map size, #channels).</figDesc><table><row><cell>datasets</cell><cell>conv1</cell><cell>pool1</cell><cell>conv2</cell><cell>pool2</cell><cell>conv3</cell><cell>pool3</cell><cell cols="3">conv4 pool4 features</cell></row><row><cell>MNIST</cell><cell>5, 6 24, 6</cell><cell>2, -12, 6</cell><cell>5, 16 8, 16</cell><cell>2, -4, 16</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>4, 120 1, 120</cell></row><row><cell>USPS</cell><cell>3, 20 16,20</cell><cell>2, -8, 20</cell><cell>3, 20 8, 20</cell><cell>2, -4, 20</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>4, 160 1, 160</cell></row><row><cell>COIL</cell><cell cols="6">9, 20 120, 20 60, 20 56, 20 28, 20 24, 20 12, 20 2, -5, 20 2, -5, 20 2, -</cell><cell>5,40 8, 40</cell><cell>2, -4, 40</cell><cell>4, 320 1, 320</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Clustering performance on MNIST.</figDesc><table><row><cell>Metric</cell><cell>KMS</cell><cell>DAE-KMS</cell><cell>AEC</cell><cell>IEC</cell><cell>DCN</cell><cell>DEC</cell><cell>FCAE-KMS</cell><cell>DBC</cell></row><row><cell>ACC</cell><cell>0.535</cell><cell>0.818</cell><cell cols="3">0.760 0.609 0.58 / 0.93 5</cell><cell>0.843</cell><cell>0.794</cell><cell>0.964</cell></row><row><cell>NMI</cell><cell>0.531</cell><cell>-</cell><cell cols="2">0.669 0.542</cell><cell>0.63 / 0.85</cell><cell>-</cell><cell>0.698</cell><cell>0.917</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Clustering performance on USPS.</figDesc><table><row><cell>Metric</cell><cell>KMS</cell><cell>AEC</cell><cell>IEC</cell><cell>FCAE-KMS</cell><cell>DBC</cell></row><row><cell>ACC</cell><cell cols="3">0.535 0.715 0.767</cell><cell>0.667</cell><cell>0.743</cell></row><row><cell>NMI</cell><cell cols="2">0.531 0.651</cell><cell>0.641</cell><cell>0.645</cell><cell>0.724</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Clustering performance on COIL-20.</figDesc><table><row><cell>Metric</cell><cell>KMS</cell><cell>DEN</cell><cell>FCAE-KMS</cell><cell>DBC</cell></row><row><cell>ACC</cell><cell cols="2">0.592 0.725</cell><cell>0.787</cell><cell>0.793</cell></row><row><cell>NMI</cell><cell cols="2">0.767 0.870</cell><cell>0.882</cell><cell>0.895</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Clustering performance on COIL-100.</figDesc><table><row><cell>Metric</cell><cell>KMS</cell><cell>IEC</cell><cell>FCAE-KMS</cell><cell>DBC</cell></row><row><cell>ACC</cell><cell cols="2">0.506 0.546</cell><cell>0.766</cell><cell>0.775</cell></row><row><cell>NMI</cell><cell cols="2">0.772 0.787</cell><cell>0.897</cell><cell>0.905</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://yann.lecun.com/exdb/mnist/ 2 http://www.cs.nyu.edu/ roweis/data.html 3 http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php 4 http://www.cs.columbia.edu/CAVE/software/softlib/coil-100.php</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">DCN with processed MNIST.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported in part by NNSF of China under grants 61379093, 61602483 and 61603389. We thank Shuguang Ding, Xuanyang Xi, Lu Qi and Yanfeng Lu for valuable discussions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>A. Derivation of (4).</p><p>We use the chain rule for the deduction. First, we set</p><p>Then it follows that</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m">Data Mining: Concepts and Techniques</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey of clustering data mining techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berkhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grouping Multidimensional Data</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="25" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Randomized dimensionality reduction for k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Boutsidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zouzias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mahaoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Drineas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1045" to="1062" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">34</biblScope>
			<biblScope unit="page" from="226" to="231" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Clustering by fast search and find of density peaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">344</biblScope>
			<biblScope unit="issue">6191</biblScope>
			<biblScope unit="page" from="1492" to="1496" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Effective deterministic initialization for kmeans-like methods via local density peaks searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06777</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recent review on image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1020" to="1032" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning the easy things first: Self-paced visual category discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1721" to="1728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive dimension reduction using discriminant analysis and k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th International Conference on Machine learning</title>
		<meeting>24th International Conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="521" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th International Conference on Computer Vision</title>
		<meeting>7th International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition</title>
		<meeting>Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Joint image clustering and labeling by matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feyereisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1411" to="1424" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Complex wavelet structural similarity: A new image similarity index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sampat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Markey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2385" to="2401" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new manifold distance for visual object categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 12th World Congress on Intelligent Control and Automation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2232" to="2236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd International Conference on Machine Learning</title>
		<meeting>33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Infinite ensemble for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1745" to="1754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stacked denoising auto-encoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<title level="m">Autoencoders, unsupervised learning, and deep architectures. ICML Workshop on Unsupervised and Transfer Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="37" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1789" to="1828" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th Annual International Conference on Machine Learning</title>
		<meeting>26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<title level="m">Visualizing and understanding convolutional networks. European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Deep deconvolutional networks for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.4101</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adaptive deconvolutional networks for mid and high level feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2018" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for largescale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Deep embedding network for clustering. ICPR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Auto-encoder based data clustering. Iberoamerican Congress on Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The Hungarian method for the assignment problem. 50 Years of Integer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuhn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958" />
			<biblScope unit="page" from="29" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Locally consistent concept factorization for document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="902" to="913" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Towards kmeans-friendly spaces: simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.04794</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
