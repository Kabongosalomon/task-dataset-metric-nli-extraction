<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MICE: MIXTURE OF CONTRASTIVE EXPERTS FOR UN- SUPERVISED IMAGE CLUSTERING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tsung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="department" key="dep2">Institute for AI</orgName>
								<orgName type="institution" key="instit1">BNRist Center Tsinghua-Bosch Joint ML Center</orgName>
								<orgName type="institution" key="instit2">THBI Lab</orgName>
								<orgName type="institution" key="instit3">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongxuan</forename><surname>Tsai</surname></persName>
							<email>chongxuanli1991@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="department" key="dep2">Institute for AI</orgName>
								<orgName type="institution" key="instit1">BNRist Center Tsinghua-Bosch Joint ML Center</orgName>
								<orgName type="institution" key="instit2">THBI Lab</orgName>
								<orgName type="institution" key="instit3">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="department" key="dep2">Institute for AI</orgName>
								<orgName type="institution" key="instit1">BNRist Center Tsinghua-Bosch Joint ML Center</orgName>
								<orgName type="institution" key="instit2">THBI Lab</orgName>
								<orgName type="institution" key="instit3">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Comp. Sci. &amp; Tech</orgName>
								<orgName type="department" key="dep2">Institute for AI</orgName>
								<orgName type="institution" key="instit1">BNRist Center Tsinghua-Bosch Joint ML Center</orgName>
								<orgName type="institution" key="instit2">THBI Lab</orgName>
								<orgName type="institution" key="instit3">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MICE: MIXTURE OF CONTRASTIVE EXPERTS FOR UN- SUPERVISED IMAGE CLUSTERING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results 1 than various previous methods and a strong contrastive learning baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Unsupervised clustering is a fundamental task that aims to partition data into distinct groups of similar ones without explicit human labels. Deep clustering methods <ref type="bibr" target="#b59">(Xie et al., 2016;</ref><ref type="bibr" target="#b57">Wu et al., 2019)</ref> exploit the representations learned by neural networks and have made large progress on high-dimensional data recently. Often, such methods learn the representations for clustering by reconstructing data in a deterministic <ref type="bibr" target="#b15">(Ghasedi Dizaji et al., 2017)</ref> or probabilistic manner <ref type="bibr" target="#b27">(Jiang et al., 2016)</ref>, or maximizing certain mutual information <ref type="bibr" target="#b23">(Hu et al., 2017;</ref><ref type="bibr" target="#b26">Ji et al., 2019</ref>) (see Sec. 2 for the related work). Despite the recent advances, the representations learned by existing methods may not be discriminative enough to capture the semantic similarity between images.</p><p>The instance discrimination task <ref type="bibr" target="#b58">(Wu et al., 2018;</ref><ref type="bibr" target="#b20">He et al., 2020)</ref> in contrastive learning has shown promise in pre-training representations transferable to downstream tasks through fine-tuning. Given that the literature <ref type="bibr" target="#b49">(Shiran &amp; Weinshall, 2019;</ref><ref type="bibr" target="#b40">Niu et al., 2020)</ref> shows improved representations can lead to better clustering results, we hypothesize that instance discrimination can improve the performance as well. A straightforward approach is to learn a classical clustering model, e.g. spherical k-means <ref type="bibr" target="#b12">(Dhillon &amp; Modha, 2001)</ref>, directly on the representations pre-trained by the task. Such a two-stage baseline can achieve excellent clustering results (please refer to Tab. 1). However, because of the independence of the two stages, the baseline may not fully explore the semantic structures of the data when learning the representations and lead to a sub-optimal solution for clustering.</p><p>To this end, we propose Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering method that utilizes the instance discrimination task as a stepping stone to improve clustering. In particular, to capture the semantic structure explicitly, we formulate a mixture of conditional models by introducing latent variables to represent cluster labels of the images, which is inspired by the mixture of experts (MoE) formulation. In MiCE, each of the conditional models, also called an expert, learns to discriminate a subset of instances, while an input-dependent gating function partitions the dataset into subsets according to the latent semantics by allocating weights among experts. Further, we develop a scalable variant of the Expectation-Maximization (EM) algorithm <ref type="bibr">(Dempster et al.,</ref> Published as a conference paper at ICLR 2021 1977) for the nontrivial inference and learning problems. In the E-step, we obtain the approximate inference of the posterior distribution of the latent variables given the observed data. In the M-step, we maximize the evidence lower bound (ELBO) of the log conditional likelihood with respect to all parameters. Theoretically, we show that the ELBO is bounded and the proposed EM algorithm leads to the convergence of ELBO. Moreover, we carefully discuss the algorithmic relation between MiCE and the two-stage baseline and show that the latter is a special instance of the former in a certain extreme case.</p><p>Compared with existing clustering methods, MiCE has the following advantages. (i) Methodologically unified: MiCE conjoins the benefits of both the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model within a unified probabilistic framework. (ii) Free from regularization: MiCE trained by EM optimizes a single objective function, which does not require auxiliary loss or regularization terms. (iii) Empirically effective: Evaluated on four widely adopted natural image datasets, MiCE achieves significantly better results than a strong contrastive baseline and extensive prior clustering methods on several benchmarks without any form of pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Deep clustering. Inspired by the success of deep learning, many researchers propose to learn the representations and cluster assignments simultaneously <ref type="bibr" target="#b59">(Xie et al., 2016;</ref><ref type="bibr" target="#b61">Yang et al., 2016;</ref> based on data reconstruction <ref type="bibr" target="#b59">(Xie et al., 2016;</ref><ref type="bibr" target="#b60">Yang et al., 2017)</ref>, pairwise relationship among instances <ref type="bibr" target="#b3">(Chang et al., 2017;</ref><ref type="bibr" target="#b17">Haeusser et al., 2018;</ref><ref type="bibr" target="#b57">Wu et al., 2019)</ref>, multi-task learning <ref type="bibr" target="#b49">(Shiran &amp; Weinshall, 2019;</ref><ref type="bibr" target="#b40">Niu et al., 2020)</ref>, etc. The joint training framework often ends up optimizing a weighted average of multiple loss functions. However, given that the validation dataset is barely provided, tuning the weights between the losses may be impractical <ref type="bibr" target="#b15">(Ghasedi Dizaji et al., 2017)</ref>.</p><p>Recently, several methods also explore probabilistic modeling, and they introduce latent variables to represent the underlying classes. On one hand, deep generative approaches <ref type="bibr" target="#b27">(Jiang et al., 2016;</ref><ref type="bibr" target="#b13">Dilokthanakul et al., 2016;</ref><ref type="bibr" target="#b6">Chongxuan et al., 2018;</ref><ref type="bibr" target="#b39">Mukherjee et al., 2019;</ref><ref type="bibr" target="#b62">Yang et al., 2019)</ref> attempt to capture the data generation process with a mixture of Gaussian prior on latent representations. However, the imposed assumptions can be violated in many cases, and capturing the true data distribution is challenging but may not be helpful to the clustering <ref type="bibr" target="#b31">(Krause et al., 2010)</ref>. On the other hand, discriminative approaches <ref type="bibr" target="#b23">(Hu et al., 2017;</ref><ref type="bibr" target="#b26">Ji et al., 2019;</ref><ref type="bibr" target="#b9">Darlow &amp; Storkey, 2020)</ref> directly model the mapping from the inputs to the cluster labels and maximize a form of mutual information, which often yields superior cluster accuracy. Despite the simplicity, the discriminative approaches discard the instance-specific details that can benefit clustering via improving the representations.</p><p>Besides, MIXAE <ref type="bibr" target="#b65">(Zhang et al., 2017)</ref>, DAMIC <ref type="bibr" target="#b4">(Chazan et al., 2019)</ref>, and MoE-Sim-VAE <ref type="bibr" target="#b30">(Kopf et al., 2019)</ref> combine the mixture of experts (MoE) formulation <ref type="bibr" target="#b25">(Jacobs et al., 1991)</ref> with the data reconstruction task. However, either pre-training, regularization, or an extra clustering loss is required.</p><p>Contrastive learning. To learn discriminative representations, contrastive learning <ref type="bibr" target="#b58">(Wu et al., 2018;</ref><ref type="bibr" target="#b41">Oord et al., 2018;</ref><ref type="bibr" target="#b20">He et al., 2020;</ref><ref type="bibr" target="#b52">Tian et al., 2019;</ref><ref type="bibr" target="#b5">Chen et al., 2020)</ref> incorporates various contrastive loss functions with different pretext tasks such as colorization , context autoencoding <ref type="bibr" target="#b44">(Pathak et al., 2016)</ref>, and instance discrimination <ref type="bibr" target="#b14">(Dosovitskiy et al., 2015;</ref><ref type="bibr" target="#b58">Wu et al., 2018)</ref>. The pre-trained representations often achieve promising results on downstream tasks, e.g., depth prediction, object detection <ref type="bibr" target="#b46">(Ren et al., 2015;</ref><ref type="bibr" target="#b19">He et al., 2017)</ref>, and image classification <ref type="bibr" target="#b29">(Kolesnikov et al., 2019)</ref>, after fine-tuning with human labels. In particular, InstDisc <ref type="bibr" target="#b58">(Wu et al., 2018)</ref> learns from instance-level discrimination using NCE <ref type="bibr" target="#b16">(Gutmann &amp; Hyvärinen, 2010)</ref>, and maintains a memory bank to compute the loss function efficiently. MoCo replaces the memory bank with a queue and maintains an EMA of the student network as the teacher network to encourage consistent representations. A concurrent work called PCL <ref type="bibr" target="#b33">(Li et al., 2020)</ref> also explores the semantic structures in contrastive learning. They add an auxiliary cluster-style objective function on top of the MoCo's original objective, which differs from our method significantly. PCL requires an auxiliary k-means <ref type="bibr" target="#b35">(Lloyd, 1982)</ref> algorithm to obtain the posterior estimates and the prototypes. Moreover, their aim of clustering is to induce transferable embeddings instead of discovering groups of data that correspond to underlying semantic classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY</head><p>We introduce the contrastive learning methods based on the instance discrimination task <ref type="bibr" target="#b58">(Wu et al., 2018;</ref><ref type="bibr" target="#b63">Ye et al., 2019;</ref><ref type="bibr" target="#b20">He et al., 2020;</ref><ref type="bibr" target="#b5">Chen et al., 2020)</ref>, with a particular focus on the recent state-of-the-art method, MoCo <ref type="bibr" target="#b20">(He et al., 2020)</ref>. Let X = {x n } N n=1 be a set of images without the ground-truth labels, and each of the datapoint x n is assigned with a unique surrogate label y n ∈ {1, 2, ..., N } such that y n = y j , ∀j = n 2 . To learn representations in an unsupervised manner, instance discrimination considers a discriminative classifier that maps the given image to its surrogate label. Suppose that we have two encoder networks f θ and f θ that generate 2 -normalized embeddings v yn ∈ R d and f n ∈ R d , respectively, given the image x n with the surrogate label y n . We show the parameters of the networks in the subscript, and images are transformed by a stochastic data augmentation module before passing to the networks (please see Appendix D). We can model the probability classifier with:</p><formula xml:id="formula_0">p(Y|X) = N n=1 p(y n |x n ) = N n=1 exp(v yn f n /τ ) N i=1 exp(v i f n /τ ) ,<label>(1)</label></formula><p>where τ is the temperature hyper-parameter controlling the concentration level <ref type="bibr" target="#b21">(Hinton et al., 2015)</ref> 3 .</p><p>The recent contrastive learning methods mainly differ in: (1) The contrastive loss used to learn the network parameters, including NCE <ref type="bibr" target="#b58">(Wu et al., 2018</ref><ref type="bibr">), InfoNCE (Oord et al., 2018</ref>, and the margin loss <ref type="bibr" target="#b47">(Schroff et al., 2015)</ref>. <ref type="formula" target="#formula_1">(2)</ref> The choice of the two encoder networks based on deep neural networks (DNNs) in which θ can be an identical <ref type="bibr" target="#b63">(Ye et al., 2019;</ref><ref type="bibr" target="#b5">Chen et al., 2020)</ref>, distinct <ref type="bibr" target="#b52">(Tian et al., 2019)</ref>, or an exponential moving average (EMA) <ref type="bibr" target="#b20">(He et al., 2020)</ref> version of θ.</p><p>In particular, MoCo <ref type="bibr" target="#b20">(He et al., 2020)</ref> learns by minimizing the InfoNCE loss:</p><formula xml:id="formula_1">log exp v yn f n /τ exp v yn f n /τ + ν i=1 exp q i f n /τ ,<label>(2)</label></formula><p>where q ∈ R ν×d is a queue of size ν ≤ N storing previous embeddings from f θ . While it adopts the EMA approach to avoid rapidly changing embeddings in the queue that adversely impacts the performance <ref type="bibr" target="#b20">(He et al., 2020)</ref>. For convenience, we refer f θ and f θ as the student and teacher network respectively <ref type="bibr" target="#b51">(Tarvainen &amp; Valpola, 2017;</ref><ref type="bibr" target="#b53">Tsai et al., 2019)</ref>. In the following, we propose a unified latent mixture model based on contrastive learning to tackle the clustering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MIXTURE OF CONTRASTIVE EXPERTS</head><p>Unsupervised clustering aims to partition a dataset X with N observations into K clusters. We introduce the latent variable z n ∈ {1, 2, ..., K} to be the cluster label of the image x n and naturally extend Eq. (1) to Mixture of Contrastive Experts (MiCE):</p><formula xml:id="formula_2">p(Y, Z|X) = N n=1 K k=1 p(y n , z n = k|x n ) 1(zn=k) = N n=1 K k=1 p(z n = k|x n ) 1(zn=k) p(y n |x n , z n = k) 1(zn=k) ,<label>(3)</label></formula><p>where 1(·) is an indicator function. The formulation explicitly introduces a mixture model to capture the latent semantic structures, which is inspired by the mixture of experts (MoE) framework <ref type="bibr" target="#b25">(Jacobs et al., 1991)</ref>. In Eq. (3), p(y n |x n , z n ) is one of the experts that learn to discriminate a subset of instances and p(z n |x n ) is a gating function that partitions the dataset into subsets according to the latent semantics by routing the given input to one or a few experts. With a divide-and-conquer principle, the experts are often highly specialized in particular images that share similar semantics, which improves the learning efficiency. Notably, MiCE is generic to the choice of the underlying contrastive methods <ref type="bibr" target="#b58">(Wu et al., 2018;</ref><ref type="bibr" target="#b20">He et al., 2020;</ref><ref type="bibr" target="#b5">Chen et al., 2020)</ref>, while in this paper, we focus on an instance based on MoCo. Also, please see <ref type="figure" target="#fig_0">Fig. 1</ref> for an illustration of MiCE with three experts.</p><p>In contrast to the original MoE used in the supervised settings <ref type="bibr" target="#b25">(Jacobs et al., 1991)</ref>, our experts learn from instance-wise discrimination instead of human labels. In addition, both gating and expert parts of MiCE are based on DNNs to fit the high-dimensional data. In the following, we will elaborate on how we parameterize the gating function and the experts to fit the clustering task. For simplicity, we omit the parameters in all probability distributions in this section.</p><p>Gating function. The gating function organizes the instance discrimination task into K simpler subtasks by weighting the experts based on the semantics of the input image. We define g ψ as an encoder network that outputs an embedding for each input image. We denote the output vector for image x n as g n ∈ R d . The gating function is then parameterized as:</p><formula xml:id="formula_3">p(z n |x n ) = exp(ω zn g n /κ) K k=1 exp(ω k g n /κ) ,<label>(4)</label></formula><p>where κ is the temperature, and ω = {ω k } K k=1 represent the gating prototypes. All prototypes and image embeddings are 2 -normalized in the R d space. Hence, the gating function performs a soft partitioning of the dataset based on the cosine similarity between the image embeddings and the gating prototypes. We can view it as a prototype-based discriminative clustering module, whereas we obtain the cluster labels using posterior inference to consider additional information in the experts.</p><p>Experts. In MiCE, every expert learns to solve the instance discrimination subtask arranged by the gating function. We define the expert in terms of the unnormalized model Φ(·) following <ref type="bibr" target="#b58">Wu et al. (2018)</ref>; <ref type="bibr" target="#b20">He et al. (2020)</ref>. Therefore, the probability of the image x n being recognized as the y n -th one by the z n -th expert is formulated as follows:</p><formula xml:id="formula_4">p(y n |x n , z n ) = Φ(x n , y n , z n ) Z(x n , z n ) ,<label>(5)</label></formula><p>where Z(x n , z n ) = N i=1 Φ(x n , y i , z n ) is a normalization constant that is often computationally intractable.</p><p>Similar to MoCo, we have the student network f θ that maps the image x n into K continuous embeddings f n = {f n,k } K k=1 ∈ R K×d . Likewise, the teacher network f θ outputs v yn = {v yn,k } K k=1 ∈ R K×d given x n . To be specific, f n,zn ∈ R d and v yn,zn ∈ R d are the student embedding and the teacher embedding for images x n under the z n -th expert, respectively. We then parameterize the unnormalized model as:</p><p>Φ(x n , y n , z n ) = exp v yn,zn (f n,zn + µ zn ) /τ ,</p><p>where τ is the temperature and µ = {µ k } K k=1 represent the cluster prototypes for the experts. In Eq. (6), the first instance-wise dot product explores the instance-level information to induce discriminative representations within each expert. The second instance-prototype dot product incorporates the class-level information into representation learning, encouraging a clear cluster structure around the prototype. Overall, the learned embeddings are therefore encoded with semantic structures while being discriminative enough to represent the instances. Eq. (6) is built upon MoCo with the EMA approach, while in principle, many other potential solutions exist to define the experts, which are left for future studies. Besides, the parameters θ and ψ are partially shared, please refer to the Appendix D for more details on the architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INFERENCE AND LEARNING</head><p>We first discuss the evidence lower bound (ELBO), the single objective used in MiCE, in Sec. 5.1. Then, we present a scalable variant of the Expectation-Maximization (EM) algorithm <ref type="bibr" target="#b10">(Dempster et al., 1977)</ref> to deal with the non-trivial inference and learning of MiCE in Sec. 5.2. Lastly, in Sec. 5.3, we show that a naïve two-stage baseline, in which we run a spherical k-means algorithm on the embeddings learned by MoCo, is a special case of MiCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">EVIDENCE LOWER BOUND (ELBO)</head><p>The parameters to update include the parameters θ, ψ of the student and gating network respectively, and the expert prototypes µ = {µ} K k=1 . The learning objective of MiCE is to maximize the evidence lower bound (ELBO) of the log conditional likelihood of the entire dataset. The ELBO of the datapoint n is given by:</p><formula xml:id="formula_6">log p(y n |x n ) ≥ L(θ, ψ, µ; x n , y n ) := E q(zn|xn,yn) [log p(y n |x n , z n ; θ, µ)] − D KL (q(z n |x n , y n ) p(z n |x n ; ψ)),<label>(7)</label></formula><p>where q(z n |x n , y n ) is a variational distribution to infer the latent cluster label given the observed data. The first term in Eq. (7) encourages q(z n |x n , y n ) to be high for the experts that are good at discriminating the input images. Intuitively, it can relief the potential degeneracy issue <ref type="bibr" target="#b2">(Caron et al., 2018;</ref><ref type="bibr" target="#b26">Ji et al., 2019)</ref>, where all images are assigned to the same cluster. This is because a degenerated posterior puts the pressure of discriminating all images on a single expert, which may result in a looser ELBO. The second term in Eq. <ref type="formula" target="#formula_6">(7)</ref> is the Kullback-Leibler divergence between the variational distribution and the distribution defined by the gating function. With this term, the gating function is refined during training and considers the capability of the experts when partitioning data. Notably, MiCE does not rely on auxiliary loss or regularization terms as many prior methods <ref type="bibr" target="#b17">(Haeusser et al., 2018;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019;</ref><ref type="bibr" target="#b57">Wu et al., 2019;</ref><ref type="bibr" target="#b40">Niu et al., 2020)</ref> do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">EM ALGORITHM</head><p>E-step. Inferring the posterior distribution of latent variables given the observations is an important step to apply MiCE to clustering. According to Bayes' theorem, the posterior distribution given the current estimate of the model parameters is: p(z n |x n , y n ; θ, ψ, µ) = p(z n |x n ; ψ)p(y n |x n , z n ; θ, µ) K k=1 p(k|x n ; ψ)p(y n |x n , k; θ, µ)</p><p>.</p><p>Comparing with the gating function p(z n |x n ; ψ), the posterior provides better estimates of the latent variables by incorporating the supplementary information of the experts. However, we cannot tractably compute the posterior distribution because of the normalization constants Z(x n , z n ; θ, µ).</p><p>In fact, given the image x n and the cluster label z n , Z(x n , z n ; θ, µ) sums over the entire dataset, which is prohibitive for large-scale image dataset. We present a simple and analytically tractable estimator to approximate them. Specifically, we maintain a queue q ∈ R ν×K×d that stores ν previous outputs of the teacher network, following MoCo closely. Formally, the estimatorẐ(·) is:</p><formula xml:id="formula_8">Z(x n , z n ; θ, µ) = exp v yn,z n (f n,zn + µ zn ) /τ + ν i=1 exp q i,zn (f n,zn + µ zn ) /τ .<label>(9)</label></formula><p>The estimator is biased, while its bias decreases as ν increases and we can get a sufficient amount of embeddings from the queue q efficiently 4 . With Eq. (9), we approximate the posterior as:</p><p>q(z n |x n , y n ; θ, ψ, µ) = p(z n |x n ; ψ)Φ (x n , y n , z n ; θ, µ)/Ẑ(x n , z n ; θ, µ) K k=1 p(k|x n ; ψ)Φ (x n , y n , k; θ, µ)/Ẑ(x n , k; θ, µ)</p><p>.</p><p>(10)</p><p>M-step. We leverage the stochastic gradient ascent to optimize ELBO with respect to the network parameters θ, ψ and the expert prototypes µ. We approximate the normalization constants appear in ELBO in analogy to the E-step, formulated as follows:</p><formula xml:id="formula_9">L(θ, ψ, µ; x n , y n ) = E q(zn|xn,yn;θ,ψ,µ) log Φ (x n , y n , z n ; θ, µ) Z(x n , z n ; θ, µ) − D KL (q(z n |x n , y n ; θ, ψ, µ) p(z n |x n ; ψ)).<label>(11)</label></formula><p>Sampling a mini-batch B of datapoints, we can construct an efficient stochastic estimator of ELBO over the full dataset to learn θ, ψ and µ:</p><formula xml:id="formula_10">L(θ, ψ, µ; X, Y) ≈ N |B| n∈B L(θ, ψ, µ; x n , y n ).<label>(12)</label></formula><p>It requires additional care on the update of the prototypes, as discussed in many clustering methods <ref type="bibr" target="#b48">(Sculley, 2010;</ref><ref type="bibr" target="#b59">Xie et al., 2016;</ref><ref type="bibr" target="#b60">Yang et al., 2017;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019)</ref>. Some of them carefully adjust the learning rate of each prototype separately <ref type="bibr" target="#b48">(Sculley, 2010;</ref><ref type="bibr" target="#b60">Yang et al., 2017)</ref>, which can be very different from the one used for the network parameters. Since evaluating different learning rate schemes on the validation dataset is often infeasible in unsupervised clustering, we employ alternative strategies which are free from using per-prototype learning rates in MiCE.</p><p>As for the expert prototypes, we observe that using only the stochastic update can lead to bad local optima. Therefore, at the end of each training epoch, we apply an additional analytical update derived from the ELBO as follows:μ</p><formula xml:id="formula_11">k = n:ẑn=k v yn,k , µ k =μ k μ k 2 , ∀k,<label>(13)</label></formula><p>where ∀n,ẑ n = arg max k q(k|x n , y n ; θ, ψ, µ) is the hard assignment of the cluster label. Please refer to Appendix A.2 for the detailed derivation. Intuitively, the analytical update in Eq. (13) considers all the teacher embeddings assigned to the k-th cluster, instead of only the ones in a mini-batch, to avoid bad local optima.</p><p>Beside, we fix the gating prototypes ω to a set of pre-defined embeddings to stabilize the training process. However, using randomly initialized prototypes may cause unnecessary difficulties in partitioning the dataset if some of them are crowded together. We address the potential issue by using the means of a Max-Mahalanobis distribution (MMD) <ref type="bibr" target="#b42">(Pang et al., 2018)</ref> which is a special case of the mixture of Gaussian distribution. The untrainable means in MMD provide the optimal inter-cluster dispersion <ref type="bibr">(Pang et al., 2020</ref>) that stabilizes the gating outputs. We provide the algorithm of MMD in Appendix B and a systematical ablation study in Tab. 3 to investigate the effect of the updates on ω and µ. Lastly, we provide the formal proof on the convergence of the EM algorithm in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">RELATIONS TO A TWO-STAGE BASELINE</head><p>The combination of a contrastive learning method and a clustering method is a natural baseline of MiCE. Our analysis reveals that MiCE is the general form of the two-stage baseline in which we learn the image embeddings with MoCo <ref type="bibr" target="#b20">(He et al., 2020)</ref> and subsequently run a spherical k-means algorithm <ref type="bibr" target="#b12">(Dhillon &amp; Modha, 2001</ref>) to obtain the cluster labels.</p><p>On one hand, in the extreme case where κ → ∞ (Assumption A3), the student embeddings f n,k and teacher embeddings v yn,k are identical for different k (Assumption A4), and the class-level Methods/Metrics (%) NMI ACC ARI NMI ACC ARI NMI ACC ARI NMI ACC ARI k-means <ref type="bibr" target="#b35">(Lloyd, 1982)</ref> 8.7 22.9 4.9 8.40 13.0 2.8 12.5 19.2 6.1 5.5 10.5 2.0 SC (Zelnik-Manor &amp; Perona, 2004) 10.3 24.7 8.5 9.0 13.6 2.2 9.8 15.9 4.8 3.8 11.1 1.3 AE † <ref type="bibr" target="#b1">(Bengio et al., 2006)</ref> 23.9 31.4 16.9 10.0 16. information in Eq. <ref type="formula" target="#formula_5">(6)</ref> is omitted (Assumption A5), we arrive at the same Softmax classifier (Eq. (1)) and the InfoNCE loss (Eq.</p><p>(2)) used by MoCo as a special case of our method. On the other hand, of particular relevance to the analytical update on expert prototypes (Eq. <ref type="formula" target="#formula_0">(13)</ref>) is the spherical k-means algorithm <ref type="bibr" target="#b12">(Dhillon &amp; Modha, 2001</ref>) that leverages the cosine similarity to cluster 2 -normalized data <ref type="bibr" target="#b22">(Hornik et al., 2012)</ref>. In addition to Assumptions A3 and A4, if we assume the unnormalized model is perfectly self-normalized (Assumption A2), using the hard assignment to get the cluster labels together with the analytical update turns out to be a single-iteration spherical k-means algorithm on the teacher embeddings. Please refer to the Appendix C for a detailed derivation.</p><p>The performance of the baseline is limited by the independence of the representation learning stage and the clustering stage. In contrast, MiCE provides a unified framework to align the representation learning and clustering objectives in a principled manner. See a comprehensive comparison in Tab. 1.  <ref type="bibr" target="#b3">(Chang et al., 2017)</ref>. The experiment settings follow the literature closely <ref type="bibr" target="#b3">(Chang et al., 2017;</ref><ref type="bibr" target="#b57">Wu et al., 2019;</ref><ref type="bibr" target="#b26">Ji et al., 2019;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019;</ref><ref type="bibr" target="#b9">Darlow &amp; Storkey, 2020)</ref> and the numbers of the clusters are known in advance. The statistics of the datasets are summarized in Tab. 2. We adopt three common metrics to evaluate the clustering performance, namely normalized mutual information (NMI), cluster accuracy (ACC), and adjusted rand index (ARI). All the metrics are presented in percentage (%). We use a 34-layer ResNet (ResNet-34) <ref type="bibr" target="#b18">(He et al., 2016)</ref> as the backbone for MiCE and MoCo following the recent methods <ref type="bibr" target="#b26">(Ji et al., 2019;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019)</ref> for fair comparisons. We set both temperatures τ and κ as 1.0, and the batch size as 256. The datasets, network, hyper-parameters, and training settings are discussed detailedly in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">MAIN CLUSTERING RESULTS</head><p>Comparison with existing deep clustering methods. As shown in Tab. 1, MiCE outperforms the previous clustering approaches by a significant margin on all datasets. The comparison highlights the importance of exploring the discriminative representations and the semantic structures of the dataset.</p><p>Comparison with the two-stage baseline. Compared to the straightforward combination of MoCo and spherical k-means, MiCE explores the semantic structures of the dataset that improve the clustering performance. From Tab. 1, we can see that MiCE consistently outperforms the baseline in terms of the mean performance, which agrees with the analysis in Sec. 5.3. Specifically, regarding ACC, we improve upon the strong baseline by 8.7%, 2.7%, and 8.2% on CIFAR-10, CIFAR-100, and ImageNet-Dog, respectively. Taking the measurement variance into consideration, our performance overlaps with MoCo only on STL-10. We conjecture that the small data size may limit the performance as each expert learns from a subset of data. Nevertheless, the comparison manifests the significance of aligning the representation learning and clustering objectives in a unified framework, and we believe that MiCE points out a promising direction for future studies in clustering.</p><p>Visualization of the learned embeddings. We visualize the image embeddings produced by the gating network using t-SNE <ref type="bibr" target="#b37">(Maaten &amp; Hinton, 2008)</ref> in <ref type="figure" target="#fig_1">Fig. 2</ref>. Different colors denote the different ground-truth class labels. At the beginning, the embeddings from distinct classes are indistinguishable. MiCE progressively refines its estimates and ends up with embeddings that show a clear cluster structure. The learned clusters align with the ground-truth semantics well, which verifies the effectiveness of our method. Additional visualizations and the comparisons with MoCo are in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">ABLATION STUDIES</head><p>Simplified model (Tab. 3 (left)). We investigate the gating function and the unnormalized model to understand the contributions of different components. Using a simpler latent variable model often deteriorates the performance.</p><p>(1) With a uniform prior, the experts would take extra efforts to become specialized in a set of images with shared semantics. (2 &amp; 3) The teacher embedding v yn is pushed to be close to all expert prototypes at the same time. It may be difficult for the simplified expert to encode the latent semantics while being discriminative. (4) The performance drop shows that the class-level information is essential for the image embeddings to capture the semantic structures of the dataset, despite the learned representations are still discriminative between instances. Without the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100</head><p>(1) A3 ( p(z n |x n ) = 1/K) 40.7 <ref type="formula" target="#formula_1">(2)</ref>  Prototypes update rules (Tab. 3 (right)). We also conduct ablation studies to gain insights into the different ways of handling the gating and expert prototypes. We see that (a) without Eq. <ref type="formula" target="#formula_0">(13)</ref>, we may be stuck in bad local optima. As mentioned in Sec. 5.2, a possible reason is that we are using the same learning rate for all network parameters and prototypes <ref type="bibr" target="#b48">(Sculley, 2010;</ref><ref type="bibr" target="#b60">Yang et al., 2017)</ref>, but tuning separate learning rates for each prototype is impractical for unsupervised clustering. Hence, we derive the analytical update to tackle the issue. As for (b), it shows that the current gradient update rule avoids the potential inconsistency between the expert prototypes and the teacher embeddings during the mini-batch training. Lastly, as discussed in Sec. 5.2, comparing to using (c) uniformly initiated gating prototypes projected onto the unit sphere, utilizing the means of MMD slightly improves performance. This also bypasses the potential learning rate issue that may appear in (d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We present a principled probabilistic clustering method that conjoins the benefits of the discriminative representations learned by contrastive learning and the semantic structures introduced by the latent mixture model in a unified framework. With a divide-and-conquer principle, MiCE comprises an input-dependent gating function that distributes subtasks to one or a few specialized experts, and K experts that discriminate the subset of images based on instance-level and class-level information. To address the challenging inference and learning problems, we present a scalable variant of Expectation-Maximization (EM) algorithm, which maximizes the ELBO and is free from any other loss or regularization terms. Moreover, we show that MoCo with spherical k-means, one of the two-stage baselines, is a special case of MiCE under various assumptions. Empirically, MiCE outperforms extensive prior methods and the strong two-stage baseline by a significant margin on several benchmarking datasets.</p><p>For future work, one may explore different learning pretext tasks that potentially fit the clustering task, other than the instance discrimination one. Also, it would be an interesting and important future work to include dataset with a larger amount clusters, such as ImageNet. Besides, being able to obtain semantically meaningful clusters could be beneficial to weakly supervised settings <ref type="bibr" target="#b68">(Zhou, 2018)</ref> where quality labels are scarce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A INFERENCE AND LEARNING</head><formula xml:id="formula_12">A.1 DERIVATION OF ELBO log p(Y|X; θ, ψ, µ) = E q(Z|X,Y) log p(Y, Z|X; θ, ψ, µ) q(Z|X, Y) + D KL (q(Z|X, Y) p(Z|X, Y; θ, ψ, µ) ≥ L(θ, ψ, µ; X, Y) := E q(Z|X,Y) log p(Y, Z|X; θ, ψ, µ) q(Z|X, Y) = E q(Z|X,Y) [log p(Y, Z|X; θ, ψ, µ)] − E q(Z|X,Y) [log q(Z|X, Y)] = N n=1 K k=1</formula><p>q(z n = k|x n , y n ) [log p(z n = k|x n ; ψ) + log p(y n |x n , z n = k; θ, µ) − log q(z n = k|x n , y n )] .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 DERIVATION OF EQ. (13)</head><p>Assumption A1. Under the hard assignment, the variational distribution is given by:</p><formula xml:id="formula_13">q(z n |x n , y n ) = 1, if z n = argmax k q(k|x n , y n ), 0, otherwise.</formula><p>Assumption A2. For all possible inputs, the unnormalized model Φ(x n , y n , z n ) is self-normalized similar to <ref type="bibr" target="#b58">(Wu et al., 2018)</ref>, i.e., Z(x n , z n ) equals to a constant c, such that there is no need to approximate the normalization constant as well.</p><p>Here, we derive the analytical update of the expert prototypes based on ELBO. Under the Assumptions A1 and A2, we can update µ k by solving the following problem:</p><formula xml:id="formula_14">µ k ← argmax µ k L(µ k ; X, Y) = argmax µ k N n=1q</formula><p>(z n = k|x n , y n ) [log p(k|x n ) + log p(y n |x n , k; µ k ) − logq(z n = k|x n , y n )] = argmax (z n = k|x n , y n )v yn,k µ k /τ, subjected to the constraint that µ k = 1. Introducing a Lagrange multiplier λ, we then solve the Lagrangian of the objective function:</p><formula xml:id="formula_15">argmax µ k λ(1 − µ k µ k ) + N n=1q (z n = k|x n , y n )v yn,k µ k /τ<label>(14)</label></formula><p>We can get the estimates of µ k and λ by differentiating the Lagrangian with regards to them and setting the derivatives to zero. To be specific, for µ k , we have:</p><formula xml:id="formula_16">∇ µ k λ(1 − µ k µ k ) + N n=1q (z n = k|x n , y n )v yn,k µ k /τ = −2λµ k + N n=1q (z n = k|x n , y n )v yn,k /τ = 0, such that µ k = N n=1q (z n = k|x n , y n )v yn,k 2λτ :=μ k 2λτ ,<label>(15)</label></formula><p>where we defineμ k := N n=1q (z n = k|x n , y n )v yn,k := n:ẑn=k v yn,k for simplicity. Similarly, by differentiating with respect to λ, we get:</p><formula xml:id="formula_17">µ k µ k = 1.<label>(16)</label></formula><p>Substituting Eq. (15) in Eq. (16), we have:</p><formula xml:id="formula_18">1 = 1 4τ 2 λ 2μ kμk = 1 4τ 2 λ 2 μ k 2 .</formula><p>Therefore, we obtain the analytical solutions:</p><formula xml:id="formula_19">λ = μ k 2τ , µ k =μ k 2τ λ =μ k μ k .</formula><p>The last expression is essentially the update for the prototypes of the experts, as presented in Eq. (13) in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 PSEUDOCODE OF MICE</head><p>Algorithm 1: Pseudocode of MiCE in a PyTorch-like style # encoder_s, encoder_t, encoder_g: student, teacher, and gating network respectively # K: number of clusters; D: embedding size # omega: gating prototypes that are fixed to the centers of MMD (KxD) # mu: expert prototypes (KxD) # queue: dictionary as a queue of V embeddings (VxKxD) # m: momentum # tau, kappa: temperatures for the experts and gating function respectively teacher.params = student.params # initialize mu_hat = zeros((K, D)) for x in loader: # load a mini-batch  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 CONVERGENCE OF THE PROPOSED EM ALGORITHM</head><p>Theorem 1 (Convergence of MiCE). Assume that the log conditional likelihood of the observed data log p(Y|X; θ, ψ, µ) has an upper bound, the approximated ELBO L(θ, ψ, µ; X, Y) of MiCE is then upper bounded and it will converge to a certain value L * with the proposed EM algorithm.</p><p>Proof. For any given variational distribution q(z n |x n , y n ), the approximated ELBO we optimize in Eq. (11) can be written as the original ELBO in Eq. (7) plus an additional term: L(θ, ψ, µ; x n , y n ) = E q(zn|xn,yn) log Φ (x n , y n , z n ; θ, µ)</p><p>Z(x n , z n ; θ, µ) − D KL (q(z n |x n , y n ) p(z n |x n ; ψ)) = E q(zn|xn,yn) log Φ (x n , y n , z n ; θ, µ) Z(x n , z n ; θ, µ) + log Z(x n , z n ; θ, µ)</p><p>Z(x n , z n ; θ, µ) − D KL (q(z n |x n , y n ) p(z n |x n ; ψ)) = L(θ, ψ, µ; x n , y n ) + E q(zn|xn,yn) log Z(x n , z n ; θ, µ)</p><p>Z(x n , z n ; θ, µ) .</p><p>Recall that the normalization constant is</p><formula xml:id="formula_20">Z(x n , z n ; θ, µ) = N i=1</formula><p>exp v yi,zn (f n,zn + µ zn ) /τ , and the approximated normalization constant iŝ Z(x n , z n ; θ, µ) = ν j=1 exp q j,zn (f n,zn + µ zn ) /τ , As in Eq. <ref type="formula" target="#formula_8">(9)</ref> where q is a queue that stores the outputs of the teacher network as described in the main text.</p><p>If we use the teacher embeddings of the entire dataset as the queue, then the two normalization constants cancel each other and we obtain the original ELBO. In such cases, the convergence can be proved following the standard EM algorithm <ref type="bibr" target="#b10">(Dempster et al., 1977;</ref><ref type="bibr" target="#b56">Wu, 1983)</ref>.</p><p>Otherwise, we can also bound the approximated ELBO. Since that all student and teacher embeddings and expert prototypes are 2 -normalized, we can bound the log ratio term independent of the choice of the queue:</p><formula xml:id="formula_21">−2 τ ≤ v yi,zn (f n,zn + µ zn ) /τ ≤ 2 τ , which implies Z(x n , z n ; θ, µ) ≤ N exp( 2 τ ),</formula><p>andẐ (x n , z n ; θ, µ) ≥ ν exp( −2 τ ).</p><p>Given that they are both positive, we can get log Z(x n , z n ; θ, µ)</p><p>Z(x n , z n ; θ, µ) ≤ log N − log ν + 4 τ Therefore, the approximated ELBO is bounded by:</p><p>L(θ, ψ, µ; x n , y n ) = L(θ, ψ, µ; x n , y n ) + E q(zn|xn,yn) log Z(x n , z n ; θ, µ)</p><p>Z(x n , z n ; θ, µ) ≤ log p(y n |x n ; θ, ψ, µ) + log N − log ν + 4 τ .</p><p>Similar to the proof of original EM <ref type="bibr" target="#b56">(Wu, 1983)</ref>, since the approximated ELBO will not decrease in expectation during training, the approximated ELBO of MiCE will converge to a certain value L * .</p><p>There are two remarks for Theorem 1: (1) The convergence of the proposed EM relies on similar assumptions of the standard EM algorithm.</p><p>(2) Due to the extra log ratio term in the approximated ELBO, it will need further analysis to know the exact convergent point comparing to MiCE learning with the standard EM algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B ALGORITHM FOR GENERATING THE CENTERS OF MMD</head><p>We provide the algorithm on generating the centers of the Max-Mahalanobis distribution (MMD) in Algorithm 2. The gating prototypes ω are fix to these centers during training. The algorithm closely follows the one proposed by <ref type="bibr">Pang et al. (2020)</ref>. For a dataset with K ground-truth classes, we will generate K centers which are all 2 -normalized in the R d space. Please kindly note that the algorithm requires K ≤ (d + 1) <ref type="bibr">(Pang et al., 2020)</ref>.</p><p>Algorithm 2: Algorithm to craft the gating prototypes ω as the centers of MMD Input: The dimension of each gating prototypes d and the number of the clusters K. Initialization: We initialize the first prototype ω 1 with the first unit basis vector e 1 ∈ R d . Rest of the prototypes ω i , i = 1, are initialized with the zero vector 0</p><formula xml:id="formula_22">d ∈ R d 1 for i = 2 to K do 2 for j = 1 to i − 1 do 3 ω ij = −[1/(K − 1) + ω i ω j ]/ω jj 4 end 5 ω ii = 1 − ω i 2 2 6 end Return: The gating prototypes ω = {ω i } K i=1 .</formula><p>C RELATIONS TO THE TWO-STAGE BASELINE C.1 CONTRASTIVE LEARNING Assumption A3. The gating temperature κ → ∞ such that for all k, the prior p(z n |x n ) = 1 K , ∀n.</p><p>Assumption A4. There is only a single output layer for both student network f θ and teacher network f θ respectively. The resulting embeddings are used across K expert, to be specific, for all possible cases,</p><formula xml:id="formula_23">Φ(x n , y n , k) = exp v yn (f n + µ k )/τ , where f n = f θ (x n ) ∈ R d , v yn = f θ (x n ) ∈ R d .</formula><p>Assumption A5. The unnormalized model Φ(·) considers only the instance-level information such that for all possible cases,</p><p>Φ(x n , y n , z n ) = exp v yn,zn f n,zn /τ .</p><p>Theorem 2. If Assumptions A3-A5 holds, the overall output of MiCE become</p><formula xml:id="formula_24">p(y n |x n ) = exp(v yn f n /τ ) N i=1 exp(v i f n /τ ) .</formula><p>Proof. Since we have the expert p(y n |x n , z n ) = Φ(x n , y n , z n )</p><formula xml:id="formula_25">Z(x n , z n ) = exp v yn (f n + µ zn )/τ N i=1 exp v i (f n + µ zn )/τ (Assumption A4) = exp(v yn f n /τ ) N i=1 exp(v i f n /τ )</formula><p>.</p><p>(Assumption A5)</p><p>The overall output of MiCE is then p(y n |x n ) = K k=1 p(z n = k|x n )p(y n |x n , z n = k)</p><formula xml:id="formula_26">= K k=1 1 K p(y n |x n , z n = k) (Assumption A3) = exp(v yn f n /τ ) N i=1 exp(v i f n /τ ) .</formula><p>The simplified model shown in Theorem 2 is essentially the non-parametric Softmax classifier used by MoCo and InstDisc, which is also related to some recent contrastive learning methods <ref type="bibr" target="#b63">(Ye et al., 2019;</ref><ref type="bibr" target="#b0">Bachman et al., 2019)</ref>. Note that InstDisc adopts a slightly different implementation in which the teacher network is identical to the student network and the loss function is based on NCE <ref type="bibr" target="#b16">(Gutmann &amp; Hyvärinen, 2010)</ref>. For detailed comparisons, please refer to <ref type="bibr" target="#b20">He et al. (2020)</ref>.</p><p>Lemma 1. If Assumptions A3-A5 hold, the posterior is uniformly distributed.</p><p>Proof.</p><p>p(z n |x n , y n ) = p(z n |x n )Φ (x n , y n , z n )/Z(x n , z n ) K k=1 p(k|x n )Φ (x n , y n , k)/Z(x n , k) = Φ (x n , y n , z n )/Z(x n , z n ) K k=1 Φ (x n , y n , k)/Z(x n , k)</p><formula xml:id="formula_27">(Assumption A3) = exp(v yn fn/τ ) N i=1 exp(v i fn/τ ) K k=1 exp(v yn fn/τ ) N i=1 exp(v i fn/τ ) (Theorem 2) = 1 K .</formula><p>Assumption A6. The normalization constant is computationally tractable such that we can have the variational distribution being identical to the posterior distribution. Proof.</p><p>L(θ, ψ, µ; x n , y n ) = E q(zn|xn,yn) [log Φ (x n , y n , z n )</p><p>Z(x n , z n ) ] − D KL (q(z n |x n , y n ) p(z n |x n ) = log Φ (x n , y n , z n )</p><p>Z(x n , z n ) (Lemma 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>= log</head><p>exp v yn f n /τ</p><formula xml:id="formula_28">exp v yn f n /τ + ν i=1 exp q i f n /τ . (<label>Theorem 2)</label></formula><p>According to Theorem 2 and 3, we see that MoCo can be viewed as a special case of the proposed MiCE. In other words, they are able to learn the same representations under the same experimental setting if the above assumptions are made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 SPHERICAL k-MEANS</head><p>Theorem 4. If Assumptions A1-A4 hold, the analytical update on the expert prototypes is equivalent to a single-iteration spherical k-means algorithm on the teacher embeddings.</p><p>Proof. Under the assumptions, the variational distribution reduces to q(z n |x n , y n ) = Φ (x n , y n , z n ) K k=1 Φ (x n , y n , k)</p><p>(Assumptions A2 and A3)</p><formula xml:id="formula_29">= exp v yn,z n f n,zn /τ + v yn,z n µ zn /τ K k=1 exp v y n,k f n,k /τ + v y n,k µ k /τ = exp v yn f n /τ + v yn µ zn /τ K k=1 exp v yn f n /τ + v yn µ k /τ (Assumption A4) = exp v yn µ zn /τ K k=1 exp v yn µ k /τ</formula><p>, such that the hard cluster assignment is determined by the cosine similarity between the teacher embedding and the expert prototypes:</p><p>q(z n |x n , y n ) = 1, if z n = argmax k q(k|x n , y n ) = argmax k v yn µ k , 0, otherwise.</p><p>With the simplified expert model, we follow the previous discussion on Eq. (14) and get the Lagrangian of the objective function:</p><formula xml:id="formula_30">argmax µ k λ(1 − µ k µ k ) + N n=1q (z n = k|x n , y n )v yn µ k /τ.</formula><p>The analytical solution is therefore:</p><formula xml:id="formula_31">µ k := N n=1q (z n = k|x n , y n )v yn , µ k =μ k μ k ,</formula><p>where the cluster assignment step and prototype update rule are the same as the spherical k-means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EXPERIEMENT SETTINGS</head><p>We mainly compare with the methods that are trained from scratch without using the pre-training model and the experiment settings follow the literature closely <ref type="bibr" target="#b3">(Chang et al., 2017;</ref><ref type="bibr" target="#b57">Wu et al., 2019;</ref><ref type="bibr" target="#b26">Ji et al., 2019;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019;</ref><ref type="bibr" target="#b9">Darlow &amp; Storkey, 2020)</ref>. For CIFAR-10, CIFAR-100, and STL-10, all the training and test images are jointly utilized, and the 20 superclasses of CIFAR-100 are used instead of the fine labels. The 15 classes of dog images are selected from the ILSVRC2012 1K <ref type="bibr" target="#b11">(Deng et al., 2009)</ref> dataset and resized to 96 × 96 × 3 to form the ImageNet-Dog dataset <ref type="bibr" target="#b3">(Chang et al., 2017;</ref><ref type="bibr" target="#b57">Wu et al., 2019)</ref>. Note that the numbers of the clusters are known in advance as in <ref type="bibr" target="#b3">Chang et al. (2017)</ref>; <ref type="bibr" target="#b26">Ji et al. (2019)</ref>; <ref type="bibr" target="#b57">Wu et al. (2019)</ref>; <ref type="bibr" target="#b49">Shiran &amp; Weinshall (2019)</ref>. The statistics of the datasets are summarized in Tab. 2. We adopt three common metrics to evaluate the clustering performance, namely normalized mutual information (NMI), cluster accuracy (ACC), and adjusted rand index (ARI). All the metrics are presented in percentage (%).</p><p>Regarding the network architecture, MiCE mainly use a ResNet-34 <ref type="bibr" target="#b18">(He et al., 2016)</ref> as the backbone following the recent methods <ref type="bibr" target="#b26">(Ji et al., 2019;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019)</ref> for fair comparisons. For the gating network, the output layer is replaced by a single fully connected layer that generates a 2 -normalized embeddings in R 128 . As for the student network, it uses the same ResNet-34 backbone as the gating network and includes K more fully connected layers which map the images to K embeddings. Therefore, the parameters of student and gating networks are shared except for the output layers. The teacher network f θ is the exponential moving average (EMA) version of the student network f θ , which stabilizes the learning process <ref type="bibr" target="#b20">(He et al., 2020;</ref><ref type="bibr" target="#b51">Tarvainen &amp; Valpola, 2017)</ref>. The update rule follows θ ← mθ + (1 − m)θ with m ∈ [0, 1) being the smoothing coefficient.</p><p>In practice, we let m = 0.999 following MoCo. Since the images of CIFAR-10 and CIFAR-100 are smaller than ImageNet images, following <ref type="bibr" target="#b5">(Chen et al., 2020)</ref>, we replace the first 7x7 Conv of stride 2 with a 3x3 Conv of stride 1 for all experiments on CIFAR-10 and CIFAR-100. The first max-pooling operation is removed as well <ref type="bibr" target="#b58">(Wu et al., 2018;</ref><ref type="bibr" target="#b5">Chen et al., 2020;</ref><ref type="bibr" target="#b63">Ye et al., 2019)</ref>. Please kindly note that if the first max-pooling operation is not removed, MiCE can still achieve 83.6% ACC on CIFAR-10. For fair comparisons, MoCo also uses a ResNet-34 with a 128-dimensional output and follows the same hyper-parameter settings as MiCE.</p><p>As it is often infeasible to tune the hyper-parameters with a validation dataset in real-world clustering tasks <ref type="bibr" target="#b15">(Ghasedi Dizaji et al., 2017)</ref>, we set both temperatures τ and κ as 1.0. The queue size ν is set to 12800 for STL-10 because of the smaller data size and 16384 for the other three datasets. The data augmentation follows MoCo closely. Specifically, before passing into any of the embedding networks, images are randomly resized and cropped to the same size, followed by random gray-scale, random color jittering, and random horizontal flip. For a fair comparison, MoCo in the two-stage baseline also uses a ResNet-34 backbone. For all datasets, we use a batch size equals to 256. Note that the data augmentation strategy is critical to contrastive learning methods and MiCE, and we follow the one used by MoCo for fairness.</p><p>In terms of the optimization details, we use stochastic gradient descent (SGD) as our optimizer on the negative ELBO. We set the SGD weight decay as 0.0001 and the SGD momentum as 0.9 <ref type="bibr" target="#b20">(He et al., 2020)</ref>. The learning rate is initiated as 1.0 and is multiplied by 0.1 at three different epochs. For different datasets, the number of training epochs is different to accommodate the data size to have a similar and reasonable training time. For CIFAR-10/100, we train for 1000 epochs in total and multiply the learning rate by 0.1 at 480, 640, and 800 epochs. For STL-10, the total epochs are 6000 and the learning rate is multiplied by 0.1 at 3000, 4000, and 5000 epochs. Lastly, for ImageNet-Dog, the total epochs are 3000 and the learning rate is multiplied by 0.1 at 1500, 2000, and 2500 epochs. Also, the learning rate for expert prototypes is the same as the one for network parameters. All the experiments are trained on a single GPU.</p><p>For all experiment settings in the main text, we follow the recent methods <ref type="bibr" target="#b57">(Wu et al., 2019;</ref><ref type="bibr" target="#b26">Ji et al., 2019;</ref><ref type="bibr" target="#b49">Shiran &amp; Weinshall, 2019)</ref> closely where the models are trained from scratch. The setting is different from some of the methods including VaDE <ref type="bibr" target="#b27">(Jiang et al., 2016)</ref>, DGG <ref type="bibr" target="#b62">(Yang et al., 2019)</ref>, and LTVAE  from two aspects. Firstly, we do not use any form of the pre-trained model. Secondly, we focus on a purely unsupervised setting. In contrast, VaDE <ref type="bibr" target="#b27">(Jiang et al., 2016)</ref> and DGG <ref type="bibr" target="#b62">(Yang et al., 2019)</ref> use a supervised pre-trained model on ImageNet for STL-10. For fairness, in the original submission, we compare to many previous methods that use the same settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E ADDITIONAL EXPERIMENTS AND VISUALIZATIONS</head><p>Posterior distribution and cluster predictions. From the left side of <ref type="figure" target="#fig_5">Fig. 3</ref>, we can see that in the initial stage (epoch 1), MiCE is yet certain about the cluster labels of any give images. At the end of the training (epoch 1000), the major values of the approximated posterior distribution fall in the [0, 0.1) interval, indicating that the model is confident that images do not belong to those clusters. Here, we train and evaluate the model using CIFAR-10 which has 10 classes and 60,000 images. We divide the probability distribution into 10 discrete bins. Best view in color.</p><p>After training, the learned model is able to generate sparse posterior distributions. The predicted cluster labels are also balanced across different clusters, which is shown on the right side of <ref type="figure" target="#fig_5">Fig. 3</ref>.</p><p>Visualization of embeddings of MiCE and MoCo. We present the t-SNE visualization of the embeddings learned by MiCE and MoCo in <ref type="figure">Fig. 4</ref> and <ref type="figure">Fig. 5</ref> to investigate whether the cluster structure and the latent semantics are captured by the models. The two figures differ in the way we color the datapoints.</p><p>In <ref type="figure">Fig. 4</ref>, different colors represent different cluster labels predicted by the clustering methods. We get the predicted cluster labels of MiCE based on the hard assignments using the posterior distributions. The cluster labels for MoCo are the outputs of the spherical k-means algorithm. MiCE can learn a distinct structure at the end of the training where each expert would mainly be responsible for one cluster. By comparing <ref type="figure">Fig. 4 (c)</ref> and (f), we can see that the boundaries between the clusters learned by spherical k-means do not match the structure learned by MoCo well. The divergence is caused by the independence of representation learning and clustering. MiCE solves the issue with a unified framework.</p><p>In <ref type="figure">Fig. 5</ref>, the datapoints are colored according to the ground-truth class labels that are unknown to the models. In <ref type="figure">Fig. 5(c)</ref>, the cluster structure is highly aligned with the underlying semantics. Most of the clusters are filled with images from the same classes while having some difficult ones lying mostly on the boundaries. This verifies that the gating network learns to divide the dataset based on the latent semantics and allocates each of the images to one or a few experts. Please kindly note that we use the embeddings from the gating network instead of the student network for simplicity since the embeddings are from the same output head. In contrast, the cluster structure learned by MoCo does not align the semantics well. For all the above t-SNE visualizations, we set the perplexity hyper-parameter to 200. Extra ablation studies on updating expert prototypes. A bad specification of the expert prototypes can lead to a bad result if it is not properly handled. Specifically, in Tab.</p><p>(3) (a), we see that the ACC on CIFAR-10 is only 21.3%. We empirically verify two principled methods that solve the issue: (1) extra end-of-epoch training only on µ with stochastic gradient ascent or (2) using Eq. (13).</p><p>The first method is used as follows. At the end of each epoch, we update µ while fixing the network parameters until the pre-defined convergence criteria are met. The convergence can be determined based on either the norm of the prototypes or the change of the objective function. To control the training time, we stop the update at the current epoch once we iterate through the entire dataset 20 times. We discover that with additional training, we can achieve 42.3% ACC. The result shows that with a proper update on µ, the proposed model can identify semantic clusters with stochastic gradient ascent alone. However, it requires more than 10 times of training time (around 394 hours).</p><p>The above discussions manifest the benefits of using the Eq. (13) which is derived based on the same objective function. With the prototypical update, we can achieve similar results with minimal computational overhead. On average, we can achieve 42.2% ACC on CIFAR-100 as shown in Sec. 6.   <ref type="bibr">, 2020)</ref> and MiCE on CIFAR-10. Following SCAN, we show the data augmentation strategy in the parenthesis if it is different from the one MiCE and MoCo use. "SimCLR" indicates the augmentation strategy used in <ref type="bibr" target="#b5">(Chen et al., 2020)</ref>, and "RA" is the RandAugment <ref type="bibr" target="#b8">(Cubuk et al., 2020)</ref>. For a fair comparison, the first sector compares MiCE to SCAN without the self-labeling step, and the second sector compares SCAN with self-labeling to MiCE with pre-training. Comparing MiCE to <ref type="bibr">SCAN (Van Gansbeke et al., 2020)</ref>. We provide additional experiment results to compare with SCAN (Van Gansbeke et al., 2020) that uses unsupervised pre-training under a comparable experiment setting. As SCAN adopts a three-step training procedure, we think that it will provide additional insights by comparing MiCE to SCAN at the steps after the pre-training step. The detail results on CIFAR-10 are presented in Tab. 4.</p><p>Firstly, we focus on SCAN with two steps of training. MiCE outperforms SCAN with two steps of training. SCAN obtains 78.7% and 81.8% on CIFAR-10 with the SimCLR augmentation and RandAugment, respectively. In contrast, MiCE can get 83.4% despite we are using a weaker augmentation strategy following MoCo <ref type="bibr" target="#b20">(He et al., 2020)</ref> and InstDisc <ref type="bibr" target="#b58">(Wu et al., 2018)</ref>.</p><p>Since SCAN involves pre-training using SimCLR <ref type="bibr" target="#b5">(Chen et al., 2020)</ref>, it takes additional advantages when directly comparing to other methods without pre-training. Thus, we fine-tune the MiCE model with the same training protocol described in Appendix D (except the learning rate can be smaller). We discover that MiCE can obtain higher results and outperforms SCAN, as shown in the second sector in Tab. 4. To be specific, in the fine-tuning stage, we load the network parameters from the pre-trained model and a smaller initial learning rate of 0.1 with all the other settings remain the same. We show the augmentation strategy in the parenthesis if we use a different one from the pre-training stage. For the RandAugment (Cubuk et al., 2020), we follow the implementation (and hyper-parameters) based on the public code provided by SCAN. As mentioned in <ref type="bibr" target="#b54">Van Gansbeke et al. (2020)</ref>, the self-labeling stage requires a shift in the augmentation, otherwise, it will lead to a degenerated solution. In contrast, MiCE with pre-training is not prone to degeneracy can get comparable or better performance than SCAN regardless of the choice of the augmentation strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F ADDITIONAL DISCUSSIONS</head><p>The number of the experts. In the cases where the number of the experts L differs from the number of ground-truth clusters K, the model will partition the datasets into L subsets instead of K. Even though the number of experts is currently tied with K, it is not a drawback and does not prevent us from applying to the common clustering settings. Also, MiCE does not use additional knowledge comparing to the baseline methods. If the ground-truth K is not known, we may treat K as a hyperparameter and decide K following the methods described in <ref type="bibr" target="#b50">Smyth (2000)</ref>; <ref type="bibr" target="#b38">McLachlan &amp; Peel (2004)</ref>, which is worth investigating in the future.</p><p>Overclustering. The overclustering technique <ref type="bibr" target="#b26">(Ji et al., 2019)</ref> is orthogonal to our methods and can be applied with minor adaptations. However, it may require additional hyper-parameter tuning to ensure overclustering improves the results. From the supplementary file provided by IIC <ref type="bibr" target="#b26">(Ji et al., 2019)</ref>, we see that the numbers of clusters (for overclustering) are set differently for different datasets.</p><p>Despite overclustering is an interesting technique, we would like to highlight the simplicity of the current version of MiCE.</p><p>Similarity between the two set of prototypes. We do not expect the two prototypes to be similar even though their dimensions are the same. In fact, they have different aims: the gating ones aim to divide the datasets into simpler subtasks for the experts, while the expert ones help the expert to solve the instance discrimination subtasks by introducing the class-level information. Therefore, the derived ELBO objective does not encourage the two sets of prototypes to be similar or maintaining a clear correspondence between them.</p><p>Empirically, we calculate the cosine similarity between any pair of µ and ω. The absolute values we get are less than 0.25, which showed that they are not similar. If we force them to be similar during training, the performance may be negatively affected due to the lack of flexibility.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An illustration of MiCE with three experts. Best view in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Visualization of the image embeddings of MiCE on CIFAR-10 with t-SNE. Different colors denote the different ground-truth class labels (unknown to the model). The cluster ACC is shown in the parenthesis. MiCE learns a clear cluster structure that matches the latent semantics well. Best view in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>learned embeddings are mixed up and scattered over the embedding space without a clear cluster structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>= k|x n , y n ) [log p(y n |x n , k;µ k )] = k|x n , y n ) [log Φ(x n , y n , k)] = k|x n , y n ) log exp v yn,k f n,k /τ + v yn,k µ k /τ = argmax µ k N n=1q (z n = k|x n , y n ) v yn,k f n,k /τ + v yn,k µ k /τ = argmax µ k N n=1q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>x with B samples x_f = aug(x) # a randomly augmented version x_v = aug(x) # another randomly augmented version x_g = aug(x) # the other randomly augmented version f = encoder_s.forward(x_f) # student embeddings: BxKxD v = encoder_t.forward(x_v) # teacher embeddings: BxKxD v = v.detach() # no gradient to teacher embeddings g = encoder_g.forward(x_g) # gating embeddings: BxD v_f = einsum("BKD,BKD-&gt;BK", [v, f]) # instance-level information v_mu = einsum("BKD,KD-&gt;BK", [v, l2normalize(mu)]) # class-level information l_pos = (v_f + v_mu) # positive logits: BxK queue_f = einsum("VKD,BKD-&gt;BKV", [queue.detach().clone(), f]) queue_mu = einsum("VKD,KD-&gt;KV", [queue, l2normalize(mu)] l_neg = queue_f + queue_mu.view(1, K, V) # BxKxV experts_logits = cat([l_pos.view(B, K, 1), l_neg], dim=2) / tau # BxKx(1+V) experts = Softmax(expert_logits, dim=2)[:, :, 0] # BxK gating = Softmax(einsum("KD,BD-&gt;BK", [omega.detach().clone(), g]) / kappa) # BxK variational_q = einsum("BK,BK-&gt;BK", [gating, experts]) variational_q /= variational_q.sum(dim=1) # BxK ELBO = sum(variational_q * (log(gating) + log(experts) -log(variational_q)) / B loss = -ELBO #</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 3 .</head><label>3</label><figDesc>Given that A3-A6 hold, p(y n |x n ) = exp(v yn f n /τ )/ N i=1 exp(v i f n /τ ),and the tractable version of ELBO is identical to the form of InfoNCE (Oord et al., 2018) loss used by MoCo.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>The histogram of (left) approximate posterior distributions of MiCE at the initial and final stage of training and (right) the predicted cluster labels obtained during testing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Visualization of the image embeddings of MiCE (upper row) and MoCo (lower row) on CIFAR-10 with t-SNE. Different colors correspond to various cluster labels obtained based on the posterior distribution (MiCE) or spherical k-means (MoCo). The embeddings of MiCE depict a clear cluster structure, as shown in (c). In contrast, the structure in (f) is ambiguous for a large portion of data and it does not match the cluster labels well. Visualization of the image embeddings of MiCE (upper row) and MoCo (lower row) on CIFAR-10 with t-SNE. Different colors denote the different ground-truth class labels (unknown to the model). Comparing to MoCo, the clusters learned by MiCE better correspond with the underlying class semantics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Unsupervised clustering performance of different methods on four datasets. The first sector presents the results from the literature, the later ones display the results of the baseline and the proposed MiCE. In the last two sectors, the bold results indicating the one with the highest values. Methods with the legend † are the ones that required post-processing by k-means to obtain the clusters since they do not learn the clustering function directly, except that we use spherical k-means for MoCo. We calculate the mean and standard deviation (Std.) of MiCE and MoCo based on five runs.</figDesc><table><row><cell>Datasets</cell><cell>CIFAR-10</cell><cell>CIFAR-100</cell><cell>STL-10</cell><cell>ImageNet-Dog</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Images Clusters Image Size</cell></row><row><cell>CIFAR-10</cell><cell>60,000</cell><cell>10</cell><cell>32 × 32 × 3</cell></row><row><cell>CIFAR-100</cell><cell>60,000</cell><cell>20</cell><cell>32 × 32 × 3</cell></row><row><cell>STL-10</cell><cell>13,000</cell><cell>10</cell><cell>96 × 96 × 3</cell></row><row><cell cols="2">ImageNet-Dog 19,500</cell><cell>15</cell><cell>96 × 96 × 3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablations of MiCE on the probabilistic model (left) and different ways of learning the gating and expert prototypes (right). Each row shows the ACC (%) on CIFAR-100 when applying the single change to MiCE. The assumptions are detailed in the Appendix C.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Training time. We present the training time of MiCE and MoCO on CIFAR-10. It takes around 17 and 30 hours to train MoCo and MiCE for 1000 epochs, respectively. For all four datasets, experiments are conducted on a single GPU (NVIDIA GeForce GTX 1080 Ti).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparing the cluster accuracy ACC (%) of SCAN (Van Gansbeke et al.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The value of the surrogate label can be regarded as the index of the image. 3 Due to summation over the entire dataset in the denominator term, it can be computationally prohibitive to get Maximum likelihood estimation (MLE) of the parameters<ref type="bibr" target="#b36">(Ma &amp; Collins, 2018)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Even though the bias does not vanish due to the use of queue, we find that the approximation works well empirically.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGEMENTS</head><p>The authors would like to thank Tianyu Pang and Zihao Wang for the discussion and the reviewers for the valuable suggestions. This work was supported by NSFC Projects (Nos. 62061136001, 61620106010, 62076145), Beijing NSF Project (No. JQ19016), Beijing Academy of Artificial Intelligence (BAAI), Tsinghua-Huawei Joint Research Program, a grant from Tsinghua Institute for Guo Qiang, Tiangong Institute for Intelligent Computing, and the NVIDIA NVAIL Program with GPU/DGX Acceleration. C. Li was supported by the fellowship of China postdoctoral Science Foundation (2020M680572), and the fellowship of China national postdoctoral program for innovative talents (BX20190172) and Shuimu Tsinghua Scholar.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><forename type="middle">R</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="15509" to="15519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep clustering based on a mixture of autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><forename type="middle">E</forename><surname>Chazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Gannot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 29th International Workshop on Machine Learning for Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graphical generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chongxuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6069" to="6080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Nicholas Darlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08821</idno>
		<title level="m">Dhog: Deep hierarchical object grouping</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald B</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Concept decompositions for large sparse text data using clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dharmendra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Modha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="143" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep unsupervised clustering with gaussian mixture variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nat</forename><surname>Dilokthanakul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Salimbeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shanahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02648</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with exemplar convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><forename type="middle">Jost</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1734" to="1747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirhossein</forename><surname>Kamran Ghasedi Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5736" to="5745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elie</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition (GCPR)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Spherical k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingo</forename><surname>Feinerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kober</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">050</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning discrete representations via information maximizing self-augmented training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichi</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1558" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep semantic clustering by partition confidence maximisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8849" to="8858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Variational deep embedding: An unsupervised and generative approach to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuxi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huachun</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangsheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05148</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Revisiting self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09005</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Vignesh Ram Somnath, and Manfred Claassen. Mixture-of-experts variational autoencoder for clustering and generating from similarity-based representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Fortuin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07763</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Discriminative clustering by regularized information maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan G</forename><surname>Gomes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="775" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04966</idno>
		<title level="m">Prototypical contrastive learning of unsupervised representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning latent superstructures in variational autoencoders for deep multidimensional clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhourong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Leonard Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Nevin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Least squares quantization in pcm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="137" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Noise contrastive estimation and negative sampling for conditional models: Consistency and statistical efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01812</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Finite mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Clustergan: Latent space clustering in generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipto</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Asnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sreeram</forename><surname>Kannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4610" to="4617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gatcluster: Self-supervised gaussian-attention network for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="735" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Max-mahalanobis linear discriminant analysis networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4016" to="4025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Rethinking softmax crossentropy loss for adversarial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Alexei</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Web-scale k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on World Wide Web (WWW)</title>
		<meeting>the 19th International Conference on World Wide Web (WWW)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1177" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Multi-modal deep clustering: Unsupervised partitioning of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Shiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02678</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Model selection for probabilistic clustering using cross-validated likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistics and Computing</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Countering noisy labels by learning from auxiliary clean labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongxuan</forename><surname>Tsung Wei Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13305</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">On the convergence properties of the em algorithm. The Annals of Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Cf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="page" from="95" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyu</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8150" to="8159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via nonparametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyi</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3861" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep clustering by gaussian mixture variational autoencoders with graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linxiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6440" to="6449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Unsupervised embedding learning via invariant and spreading instance feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6210" to="6219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihi</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Deep unsupervised clustering using mixture of autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Balzano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.07788</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Alexei</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02351</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Stacked what-where auto-encoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A brief introduction to weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Science Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
