<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Utilizing the Instability in Weakly Supervised Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxiao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochun</forename><surname>Ye</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haihang</forename><surname>You</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongrui</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Utilizing the Instability in Weakly Supervised Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weakly supervised object detection (WSOD) focuses on training object detector with only image-level annotations, and is challenging due to the gap between the supervision and the objective. Most of existing approaches model WSOD as a multiple instance learning (MIL) problem. However, we observe that the result of MIL based detector is unstable, i.e., the most confident bounding boxes change significantly when using different initializations. We quantitatively demonstrate the instability by introducing a metric to measure it, and empirically analyze the reason of instability. Although the instability seems harmful for detection task, we argue that it can be utilized to improve the performance by fusing the results of differently initialized detectors. To implement this idea, we propose an end-to-end framework with multiple detection branches, and introduce a simple fusion strategy. We further propose an orthogonal initialization method to increase the difference between detection branches. By utilizing the instability, we achieve 52.6% and 48.0% mAP on the challenging PASCAL VOC 2007 and 2012 datasets, which are both the new state-ofthe-arts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Weakly supervised object detection (WSOD) has attracted intensive attention recently <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b11">12]</ref>. Unlike fully supervised object detection, WSOD aims at training detectors with only image-level annotations, which cost much less human labor than bounding boxes annotations.</p><p>A popular solution for WSOD is to formulate it as a * Equally-contributed. † Corresponding author. multiple instance learning (MIL) problem. Training images are treated as labeled bags, which consist of multiple candidate bounding boxes. The learning procedure alternates between selecting the most confident proposals and using them to train a detector <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b15">16]</ref>. Recently, many works combine convolutional neural networks (CNN) with MIL and get promising results <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b11">12]</ref>. Bilen et al. <ref type="bibr" target="#b1">[2]</ref> propose a concise end-to-end Weakly Supervised Deep Detection Net-work (WSDDN), using two parallel branches to get classification and detection information. Based on WSDDN, some works propose to leverage regularization <ref type="bibr" target="#b1">[2]</ref>, online refinement <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> and curriculum learning <ref type="bibr" target="#b31">[32]</ref> to further improve the performance. Weakly supervised semantic segmentation is also introduced in WSOD to provide objectness information <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b11">12]</ref>. However, there is still a remarkable performance gap compared with fully supervised detectors <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b17">18]</ref>. We observe that the result of MIL-based detector is unstable. Specifically, detectors with different initializations may localize different regions on the same images. For example, the MIL-0 in the first column of <ref type="figure" target="#fig_0">Fig. 1 (a)</ref> can correctly localize the cat in the image of the second row, but converge to the head of cat in the first and the third rows. However, MIL-1 in the second column of <ref type="figure" target="#fig_0">Fig. 1 (a)</ref> succeeds to localize the cat in the first and third rows but fails in the second row. Also, if there are multiple objects in the image, detectors with different initial parameters may localize different one, <ref type="figure" target="#fig_0">Fig. 1(b)</ref>.</p><p>The instability of MIL-based detector seems notorious as it limits the performance and leads to a high variance of the result, but we propose to utilize it on the contrary. Our motivation is that, by fusing the results of detectors with different initializations, we can keep the good candidate proposal and suppress the bad ones, so as to improve the detection performance. To implement this idea, we introduce a novel end-to-end framework to utilize the instability. Specifically, we design a multi-branch network structure consisting of a classification branch and multiple detection branches, inspired by WSDDN. The results of detection branches are coupled with the classification branch and the coupled results are further processed by a fusion strategy, called Surrounded Candidate Suppression (SCS). We further refine the fused result by training instance classifiers, following the popular practice <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33]</ref>. Moreover, in order to further increase the difference between different detection results, we propose a novel category orthogonal parameter initialization method which makes the initialization parameters of the same category in different detection branches orthogonal.</p><p>To show the effectiveness of utilizing the instability, we conduct extensive experiments on the challenging PAS-CAL VOC 2007 and 2012 benchmarks. With the proposed framework, we obtain 52.6% and 48.0% mAP on VOC 2007 and VOC 2012 respectively, which are the new stateof-the-arts.</p><p>In summary, the contributions of this paper are listed as follows:</p><p>1. We analyze the instability of MIL based detector, providing quantitative evidence and empirical explanation. Based on the analysis, we propose to utilize the instability to improve detection performance by fusing the results of differently initialized detectors.</p><p>2. As training multiple detectors with different initialization is time consuming, we propose a simple but effective end-to-end framework and an online fusion strategy to utilize the instability. An orthogonal parameter initialization method is further proposed to increase the difference between detection branches.</p><p>3. The proposed framework significantly outperforms previous methods, and creates new state-of-the-arts both on PASCAL VOC2007 and VOC2012 datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The majority of existing methods formulate WSOD as an MIL <ref type="bibr" target="#b9">[10]</ref> problem. Under this formulation, a training image is seen as a bag of candidate proposals <ref type="bibr" target="#b4">[5]</ref>. Given the labels of bags, the objective of MIL is to train a classifier to correctly separate positive proposals from negative ones.</p><p>However, the loss function of MIL is non-convex, and the optimization of MIL is sensitive to initialization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b23">24]</ref>. In order to solve this issue, some works introduce better initialization methods. Deselaers et al. <ref type="bibr" target="#b6">[7]</ref> propose to initialize object locations based on the objectness score. Cinbis et al. <ref type="bibr" target="#b4">[5]</ref> propose to split the training data into multi folds to escape local optima. Beyond generating better initialization, some works propose to smooth the optimization of MIL to alleviate the non-convexity problem. Bilen et al. <ref type="bibr" target="#b0">[1]</ref> introduce a smoothed version of MIL that softly labels object instances. Song et al. <ref type="bibr" target="#b23">[24]</ref> propose to use Nesterov's smoothing technique in latent SVM model. The proposed method is also related to the non-convexity of MIL, but we propose to utilize the instability, which is partly caused by the non-convexity.</p><p>In recent years, many works combine deep convolutional neural networks with MIL and achieve promising results <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b11">12]</ref>. The pretrained CNN models provide generic visual feature representations and reliable initialization for MIL. Bilen et al. <ref type="bibr" target="#b1">[2]</ref> proposed a two-stream weakly supervised deep detection network (WSDDN), which can be trained with image-level labels in an end-to-end manner. Tang et al. <ref type="bibr" target="#b25">[26]</ref> add into WSDDN several instance classifiers, and propose an online instance classifier refinement method. Wan et al. <ref type="bibr" target="#b28">[29]</ref> focus on reducing the randomness of localization during the optimization of network. Also, some works propose to leverage weakly supervised semantic segmentation to improve detection performance. Diba et al. <ref type="bibr" target="#b8">[9]</ref> generate candidate proposals based on the segmentation result and perform MIL among them. Wei et al. <ref type="bibr" target="#b30">[31]</ref> introduce two metrics to select reliable candidate proposals by using segmentation result.</p><p>Moreover, some researchers propose to combine fully supervised detectors with MIL based ones <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b21">22]</ref>.  Wang et al. <ref type="bibr" target="#b29">[30]</ref> introduce a collaborative learning framework and a consistence-based loss to combine WSDDN and Faster-RCNN. Zhang et al. <ref type="bibr" target="#b32">[33]</ref> propose to mine better pseudo ground truths from the result of MIL based detector to train a fully supervised detector. Shen et al. <ref type="bibr" target="#b21">[22]</ref> use a generative adversarial learning framework to build the connection between fully and weakly supervised detectors.</p><p>The proposed framework consists of multiple detection branches and is related to <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b16">17]</ref> that also propose to use multi-branch network to improve detection result. Cheng et al. <ref type="bibr" target="#b3">[4]</ref> propose to add a decoupled classification refinement module to suppress hard false positive results. Li et al. <ref type="bibr" target="#b16">[17]</ref> use multiple branches with different dilated convolution layers. Our method is different to these methods because the branches in our method have the same structure. Also, the branches in the proposed framework have different initializations in order to utilize the instability, which is not involved in these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Analysis of Instability</head><p>We observe that the result of MIL based detector shows significant instability, i.e., detectors trained with different initializations often localize different regions in the same image. To quantitatively analyze the instability of MIL based detectors, we first introduce a metric, Inconsistent Detection Rate (IDR), representing the inconsistency between the results of two detectors. In an image, if the IoU of the top scoring bounding boxes of two detectors is less than 0.5, we say the results are inconsistent. IDR indicates <ref type="figure">Figure 3</ref>. The non-convexity of MIL. Differently initialized detectors may be trapped in different local minimum, leading to different detection results. By fusing the results of different detectors, we may get more accurate localization of object.</p><formula xml:id="formula_0">MIL-0 MIL-1 MIL-k ... Fusion</formula><p>the rate of images where the results of two detectors are inconsistent. Formally, the IDR on class c is defined as</p><formula xml:id="formula_1">IDR c = |{I c k , where IoU (b c 1,k , b c 2,k ) &lt; 0.5}| |{I c k }| ,<label>(1)</label></formula><p>where I c k denotes the kth training image with positive label on class c, b c 1,k and b c 2,k denote the top scoring bounding boxes of two detectors on the kth image. The mean IDR over all classes is defined as</p><formula xml:id="formula_2">mIDR = C c=1 IDR c C ,<label>(2)</label></formula><p>where C denotes the number of classes. We choose WSDDN, a popular MIL based detector, as a representative to show the instability problem. We train WSDDN for 10 times with different initial parameters. Then we randomly sample two detectors to compute IDR and mIDR for 10 times and show their averaged values. As shown in <ref type="figure" target="#fig_2">Fig. 2 (a)</ref>, the mIDR reaches 38.3% and the IDRs on some classes are even greater than 50%, which means the detection result in about a half of images changes significantly if we change initial parameters of a detector. Also, the instability is more serious on classes with poor localization performance. From <ref type="figure" target="#fig_2">Fig. 2</ref> (a) we can find that the class-specific IDR shows a negative relation with CorLoc.</p><p>We think the reasons of this instability are two folds. Firstly, MIL is inherently non-convex and may have many local optimum. Secondly, the proposals in the same image have strong spatial relationship, which is related to the detection task. Specifically, negative proposals that only contain part of object always appear together with the positive  proposals in the positive bags. However, such negative proposals never appear in a negative bag. Both of such negative proposals and positive proposals may correspond to local optimums of MIL, <ref type="figure">Fig. 3</ref>. For example, an image containing a bird always has a positive proposal that contains the entire bird and some negative proposals that only contain the head of the bird, but images that contain such negative proposals are never labeled as negative. Without instancelevel annotations, this spatial correlation between proposals usually makes the detector confused, leading to strong instability. It seems that the instability is notorious as it limits the detection performance and results in unreliable localization. However, we argue that the instability can be utilized to improve detection performance on the contrary. Considering different top scoring proposals generated by randomly initialized detectors, some of them may be tight bounding boxes while others may be not. If we can fuse these proposals, keep the good ones and discard the bad ones, the detection performance will be improved, <ref type="figure">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head><p>To utilize the instability of MIL based detector, we propose to fuse the results of differently initialized detectors. A natural way is to train the detector, such as WSDDN, for several times, and then fuse the results after all the training processes. However, this procedure is time-consuming. So we further propose a novel end-to-end network and an online fusion strategy to utilize the instability of MIL based detector. The overall network architecture is shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. The main part of the network is a multi-branch structure consisting of a classification branch and multiple detection branches, which are initialized with different pa-rameters. The results of all branches will be further fused and refined online. Moreover, in order to enlarge the difference between detection branches, we introduce an orthogonal initialization strategy for detection branches. We will elaborate the details of the proposed network, the online fusion strategy and the orthogonal initialization method in the rest of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Multi-branch Network Structure</head><p>To utilize the instability of MIL, we need to generate different sets of localization information and fuse them to get better detection results. Inspired by WSDDN, we design a multi-branch network structure to implement this idea. Formally, given a training image I and the corresponding candidate proposals B generated by selective search method <ref type="bibr" target="#b27">[28]</ref>, we feed I and B into a CNN backbone with ROI pooling, which is pretrained on ImageNet dataset. We use the output of FC7 as the features of candidate proposals. Then the network branch into a classification branch and K detection branches. Each branch consists of a fully connected layer and a softmax layer. In the classification branch, the fully connected layer maps the features of proposals into a matrix x c ∈ R C×|B| , where C is the number of categories. Then a softmax operation along the class-axis is performed to get the classification scores of proposals</p><formula xml:id="formula_3">[σ cls (x c )] ij = e x c ij C n=1 e x c nj .<label>(3)</label></formula><p>In the kth detection branch, the matrix after fully connected layer x d,k ∈ R C×|B| is passed through a softmax operator along proposal-axis, defined as:</p><formula xml:id="formula_4">[σ det (x d,k )] ij = e x d,k ij |B| n=1 e x d,k in .<label>(4)</label></formula><p>The detection scores of each detection branch will be further coupled with the classification scores of the same classification branch to get the final scores by an element-wise product, defined as:</p><formula xml:id="formula_5">σ k = σ cls (x c ) σ det (x d,k ).<label>(5)</label></formula><p>For each detection branch, we can compute the image classification score p c on class c with a summation over all proposals, defined as:</p><formula xml:id="formula_6">p k c = |B| n=1 σ k c,n .<label>(6)</label></formula><p>With the image label Y = {y 1 , y 2 , . . . , y C }, the loss for kth detection branch L k and the total loss L are defined as:</p><formula xml:id="formula_7">L k = − C c=1 {y c log p k c + (1 − y c ) log(1 − p k c )} (7) L = K k=1 L k<label>(8)</label></formula><p>Instead of fusing the results of different detectors after the training procedure, we propose a simple online fusion strategy. After forward propagation in each training step, we can get the final scores of detection branches, and then fuse the results of different detection branches based on these scores. The fused results will be further refined by training instance classifiers. Here we follow <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> to design the refinement module, which refines the fused results in a cascaded manner. For more details, please refer to <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Online Fusion Strategy</head><p>After getting the final scores of each detection branches, we introduce a simple online fusion strategy, called surrounded candidates suppression (SCS), to fuse the results of K detection branches in every training step. The proposed strategy is based on the observation that WSDDN tends to localize the discriminative object parts or the whole object, rather than selecting bounding boxes that contain multiple objects or too many background regions. Thus, if a top scoring bounding box of a detector is surrounded by that of another detector, it is very likely that the surrounded bounding box only contains part of object and should be discarded. Formally, we first get the set of top scoring proposals of all detection branches P = {P 1 , P 2 , . . . , P K }. Then we remove from P all proposals that are surrounded by another end if 17: end for proposal in P. Finally, a standard NMS with threshold 0.1 is performed among the remained proposals to get the fused result. With SCS, we can discard the bad candidate proposals and keep the good ones as many as possible. To make it clear, we summarize the process of SCS in Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Orthogonal Initialization</head><p>The detection branches in the proposed network is supposed to be different with each other, so the fused results can be better than the results of original branches. The difference of detection branches comes from the randomness of initialization, which is not reliable. We argue that the proposed method can benefit from more significant difference between the initial parameters of detection branches. So we propose an orthogonal initialization method, making sure that the parameters of the fully connected layers of different detection branches are orthogonal with each other on every class. Similar initialization methods have been proposed in <ref type="bibr" target="#b20">[21]</ref> to avoid the vanishment of gradient in recurrent neural networks. We follow the implementation in <ref type="bibr" target="#b20">[21]</ref> to design our orthogonal initialization method. For the kth detection branch, the parameters of the fully connected layer is denoted as a matrix m k ∈ R l×C , where l denotes the length of the feature vector of a proposal. For each class c, we construct get an orthogonal matrix q c ∈ R l×K by performing QR factorization on a random matrix. Then we assign the value of the kth column in q to the cth column of m k . - - - - </p><formula xml:id="formula_8">- - - - - - - - - - - - - - - - - - - 37.9 OICR [26] - - - - - - - - - - - - - - - - - - - -</formula><formula xml:id="formula_9">- - - - - - - - - - - - - - - - - - - 42.4 OICR+FRCNN [26] - - - - - - - - - - - - - - - - - - - - 42.</formula><formula xml:id="formula_10">- - - - - - - - - - - - - - - - - - -</formula><formula xml:id="formula_11">- - - - - - - - - - - - - - - - - - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets and Evaluation Metrics</head><p>We evaluate our method on two widely used datasets, PASCAL VOC 2007 and 2012 <ref type="bibr" target="#b10">[11]</ref>. For each dataset, we use the trainval set for training, and the test set for testing. Only image-level labels are used to train the network.</p><p>For evaluation, we choose two kinds of measurements: 1) Average Precision (AP) and the mean of AP (mAP) on the test set, following the standard PASCAL VOC protocol; 2) CorLoc <ref type="bibr" target="#b7">[8]</ref> on the trainval set to evaluate the localization accuracy. Based on the PASCAL criterion, a bounding box is considered to be positive if it has an IoU ≥ 0.5 with the ground-truth for both metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Implementation Details</head><p>We built our model on a VGG16 <ref type="bibr" target="#b22">[23]</ref> network pretrained on ImageNet <ref type="bibr" target="#b5">[6]</ref>. We remove the last fully connected layer, and replace the last max-pooling layer with an ROI pooling layer. The mini-batch for training is set to 2. The momentum and weight decay is set to 0.9 and 5×10 −4 respectively. The learning rate is 5×10 −4 for the first 10 epochs and then decrease to 5 × 10 −5 for the following 5 epochs.</p><p>The image proposals are generated by selective search <ref type="bibr" target="#b27">[28]</ref>. For data augmentation, we use five image scales {480, 576, 688, 864, 1200}, with horizontal flips for </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">The Effectiveness of Utilizing the Instability</head><p>To demonstrate the effectiveness of utilizing the instability, we choose WSDDN as the basic detector, and fuse - Method VOC 2012 WSDDN+context <ref type="bibr" target="#b14">[15]</ref> 54.8 ZLDN <ref type="bibr" target="#b31">[32]</ref> 61.5 OICR <ref type="bibr" target="#b25">[26]</ref> 63.5 TS2C <ref type="bibr" target="#b30">[31]</ref> 64.4 PCL <ref type="bibr" target="#b24">[25]</ref> 65.0 CL <ref type="bibr" target="#b29">[30]</ref> 65.2 OICR+FRCNN <ref type="bibr" target="#b25">[26]</ref> 65.6 WSRPN <ref type="bibr" target="#b26">[27]</ref> 67.2 PCL+FRCNN <ref type="bibr" target="#b24">[25]</ref> 68.0 WSRPN+FRCNN <ref type="bibr" target="#b26">[27]</ref> 69.3 Ours 67.4 the results of WSDDNs that are initialized with different parameters. We use the same fusion strategy introduced in Section 4.2, while we only keep the proposal with largest final score after NMS for the convenience of calculating CorLoc. As shown in <ref type="figure" target="#fig_4">Fig. 5</ref>, the CorLoc of the fused result increases monotonically as the number of fused detectors increases, and the instability of fused result decreases. Even by fusing two WSDDNs, the CorLoc increases from 42.54% to 46.27%, showing the effectiveness of utilizing the instability.</p><formula xml:id="formula_12">- - - - - - - - - - - - - - - - - - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Studies</head><p>We first compared the proposed method with the baseline model, which combines WSDDN and the refinement module. Then we discuss the influence of detection branch number and the class-specific orthogonal initialization strategy. Without loss generality, we only conduct the ablation experiments on VOC 2007.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Baseline</head><p>To show the effectiveness of the proposed framework, we compare the result of our method with a baseline framework containing a original WSDDN. As shown in <ref type="table">Table.</ref> 1, our method improves the mAP from 49.0% to 52.0%. The performance on almost all classes has been improved, such as aeroplane (mAP from 44.3% to 63.4%), cat (mAP from 47.0% to 69.6%) and chair (mAP from 21.8% to 27.2%). Our model can mine more complete object bounding boxes by the fusion of multiple detectors while WSDDN can only find object parts. Also, the fusion strategy has the capacity of generating multiple candidate proposals with high confidence for the refinement module, further improving the detection performance. <ref type="figure" target="#fig_5">Fig. 6</ref>, we illustrate the result of ablation study on different numbers of detection branches. Even adding one more detection branch can significantly boost the performance (mAP from 49.0% to 51.6%), which confirms the effectiveness of our method. With 3 detection branches, the performance achieve the peak. The detection performance decreases slightly as the number of branches further increases. We think the reason may be that the online fusion strategy introduce the risk of localizing too big bounding boxes and this risk outweighs the gain of adding more branches when the number of detection branches is greater than 3. Thus, we set the detection branch number K to 3 in other experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence of Detection Branch Number In</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence of Orthogonal Initialization</head><p>To validate the effectiveness of orthogonal initialization, we compare the proposed initialization method with a popular Gaussian ini- tialization method, which samples values from Gaussian distribution to initialize the parameters. As shown in <ref type="figure" target="#fig_5">Fig. 6</ref>, orthogonal initialization method significantly improves the detection performance. The effectiveness of orthogonal initialization further confirms the analysis in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Comparison with State-of-the-Art</head><p>In this subsection, we present the result of our framework compared with other state-of-the-art methods. <ref type="table" target="#tab_2">Table. 1 shows the result on VOC 2007 dataset, and Table.</ref> 2 shows the result on VOC 2012 dataset. On VOC 2007, our model obtains 52.0% mAP. On VOC 2012, our model obtains 48.0% mAP. Our method outperforms previous methods with a large margin on both datasets.</p><p>Many works propose to train a fully supervised detector by using the result of MIL based detector as pseudo ground-truth, and show significant improvement of performance. Following Tang et al. <ref type="bibr" target="#b25">[26]</ref>, we also use the topscoring proposals produced by the proposed framework as pseudo ground-truth to train a Fast-RCNN <ref type="bibr" target="#b12">[13]</ref>. As shown in <ref type="table">Table.</ref> 1, the detection performance on VOC 2007 is further improved to 52.6% in mAP, which is the new state-ofthe-art. The CorLoc results of ours on VOC 2007 and VOC 2012 are reported in <ref type="table">Table. 3 and Table.</ref> 4, which also show the same trend.</p><p>We illustrate some detection results of our framework in <ref type="figure" target="#fig_6">Fig. 7</ref>. Although our model creates the new state-of-the-art, the detection results on some classes, such as person, chair and bottle, are still undesirable. The main failure for person is that the proposed method only finds different parts of person, such as face and hand. Although the inconsistency between the multiply detection branches is large, they all con-verge to object parts. As for indoor objects such as chairs and bottles, the co-occurrence of objects and backgrounds, or of different objects, is more common and makes it difficult to separate objects from contexts or from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we analyze the instability of MIL-based detector and introduce a metric IDR to measure the instability. Although the instability seems harmful, we propose to utilize it to get more accurate localization result. We propose an end-to-end network architecture and introduce an online fusion strategy to reduce computation cost. Also, a novel orthogonal initialization method is introduced to increase the difference between detection branches. Combined with refinement module, the proposed framework surpasses all previous methods and creates new state-of-the-art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The instability of MIL-based detector. Each column corresponds to one MIL-based detector, and each row corresponds to one image. Green rectangles indicate the positive bounding boxes and red rectangles indicate the negative ones. (a) Images that contain only one object. (b) Images that contain multiple objects. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>(a) Averaged CorLoc of 10 randomly initialized WS-DDNs on each class. (b) Averaged IDR of each class, obtained by randomly sampling two WSDDNs 10 times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>The network architecture of our method. A CNN backbone with ROI pooling and two fully connected layers is used to get the feature vectors of proposals. Then the feature vectors are fed into a classification branch, K detection branches and several instance classifiers. Softmax 1 indicates softmax operation over the classes, and Softmax 2 indicates softmax operation over the proposals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Averaged CorLoc and mIDR of fused results with different fused detector numbers K, obtained by randomly sampling K WSDDNs 10 times. both training and testing. In each training step, we randomly choose a scale to resize the image and then the image is randomly flipped. For all experiments, an NMS of 0.3 is employed to get final detection result. The average score of 10 augmented images is used as the final proposal scores. Our experiments are implemented based on PyTorch deep learning framework, and are conducted on NVIDIA GTX TitanX GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Results of different settings of branch number K and initialization strategies. "Orthogonal" indicates the orthogonal initialization method. "Gaussian" indicates the Gaussian initialization method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Some detection results of the proposed method. The green rectangles denote the correct detections (IoU ≥ 0.5), and the red rectangles denote the failed ones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Algorithm 1 Surrounded Candidates Suppression (SCS) Input: The final score of K detection branches {σ 1 , σ 2 , . . . , σ K }; object proposals B; image label Y. Output: Fused detection result B f used .</figDesc><table><row><cell>3:</cell><cell>if y c = 1 then</cell></row><row><cell>4:</cell><cell>Set B top ← {}.</cell></row><row><cell>5:</cell><cell>for k = 1 to K do</cell></row><row><cell>6:</cell><cell>b k c ← arg max bn∈B σ k c,n .</cell></row><row><cell>7:</cell><cell>B top ← B top {b k c }.</cell></row><row><cell>8:</cell><cell>end for</cell></row><row><cell>9: 10: 11:</cell><cell>for b c k ∈ B top do if ∃b ∈ B top s.t. b c k is surrounded by b then B top ← B top \ {b c k }.</cell></row><row><cell>12:</cell><cell>end if</cell></row><row><cell>13:</cell><cell>end for</cell></row><row><cell>14: 15:</cell><cell>B c f used ← NMS(B top ). B f used ← B f used B c f used .</cell></row></table><note>1: Set B f used ← {}.2: for c = 1 to C do16:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>60.6 38.6 29.2 16.2 70.8 56.9 42.5 10.9 44.1 29.9 42.2 47.9 Detection average precision (AP %) on the PASCAL VOC 2007 test set. The upper part shows the results of weakly supervised detectors, and the second part shows the results of fully supervised detector trained by using the output of weakly supervised detectors as pseudo ground truth.</figDesc><table><row><cell>Method</cell><cell cols="2">aero bike bird boat bottle bus</cell><cell>car</cell><cell cols="6">cat chair cow table dog horse mbike person plant sheep sofa train</cell><cell>tv</cell><cell>mAP</cell></row><row><cell>WSDDN [2]</cell><cell cols="4">46.4 58.3 35.5 25.9 14.0 66.7 53.0 39.2</cell><cell>8.9</cell><cell>41.8 26.6 38.6 44.7</cell><cell>59.0</cell><cell>10.8</cell><cell>17.3</cell><cell>40.7 49.6 56.9 50.8</cell><cell>39.3</cell></row><row><cell>OICR [26]</cell><cell cols="4">58.5 63.0 35.1 16.9 17.4 63.2 60.8 34.4</cell><cell>8.2</cell><cell>49.7 41.0 31.3 51.9</cell><cell>64.8</cell><cell>13.6</cell><cell>23.1</cell><cell>41.6 48.4 58.9 58.7</cell><cell>42.0</cell></row><row><cell>WCCN [9]</cell><cell cols="7">49.5 64.1</cell><cell>13.8</cell><cell>23.5</cell><cell>45.9 54.1 60.8 54.5</cell><cell>42.8</cell></row><row><cell>TS2C [31]</cell><cell cols="6">59.3 57.5 43.7 27.3 13.5 63.9 61.7 59.9 24.1 46.9 36.7 45.6 39.9</cell><cell>62.6</cell><cell>10.3</cell><cell>23.6</cell><cell>41.7 52.4 58.7 56.6</cell><cell>44.3</cell></row><row><cell>PCL [25]</cell><cell cols="6">57.1 67.1 40.9 16.9 18.8 65.1 63.7 45.3 17.0 56.7 48.9 33.2 54.4</cell><cell>68:3</cell><cell>16:8</cell><cell>25.7</cell><cell>45.8 52.2 59.1 62.0</cell><cell>45.8</cell></row><row><cell>MLEM [29]</cell><cell cols="6">55.6 66.9 34.2 29.1 16.4 68.8 68.1 43.0 25.0 65.6 45.3 53.2 49.6</cell><cell>68.6</cell><cell>2.0</cell><cell>25.4</cell><cell>52.5 56.8 62.1 57.1</cell><cell>47.3</cell></row><row><cell>WSRPN [27]</cell><cell cols="4">60.3 66.2 45.0 19.6 26.6 68.1 68.4 49.4</cell><cell>8.0</cell><cell>56.9 55.0 33.6 62.5</cell><cell>68.2</cell><cell>20.6</cell><cell>29.0</cell><cell>49.0 54.1 58.8 58.4</cell><cell>47.9</cell></row><row><cell>OICR+FRCNN [26]</cell><cell cols="4">65.5 67.2 47.2 21.6 22.1 68.0 68.5 35.9</cell><cell>5.7</cell><cell>63.1 49.5 30.3 64.7</cell><cell>66.1</cell><cell>13.0</cell><cell>25.6</cell><cell>50.0 57.1 60.2 59.0</cell><cell>47.0</cell></row><row><cell>ZLDN [32]</cell><cell cols="4">55.4 68.5 50.1 16.8 20.8 62.7 66.8 56.5</cell><cell>2.1</cell><cell>57.8 47.5 40.1 69.7</cell><cell>68.2</cell><cell>21.6</cell><cell>27.2</cell><cell>53.4 56.1 52.5 58.2</cell><cell>47.6</cell></row><row><cell>CL [30]</cell><cell cols="6">61.2 66.6 48.3 26.0 15.8 66.5 65.4 53.9 24.7 61.2 46.2 53.5 48.5</cell><cell>66.1</cell><cell>12.1</cell><cell>22.0</cell><cell>49.2 53.2 66.2 59.4</cell><cell>48.3</cell></row><row><cell>PCL+FRCNN [25]</cell><cell cols="6">63.2 69.9 47.9 22.6 27.3 71.0 69.1 49.6 12.0 60.1 51.5 37.3 63.3</cell><cell>63.9</cell><cell>15.8</cell><cell>23.6</cell><cell>48.8 55.3 61.2 62.1</cell><cell>48.8</cell></row><row><cell>WSRPN+FRCNN [27]</cell><cell cols="6">63.0 69.7 40.8 11.6 27.7 70.5 74.1 58.5 10.0 66.7 60.6 34.7 75.7</cell><cell>70.3</cell><cell>25.7</cell><cell>26.5</cell><cell>55.4 56.4 55.5 54.9</cell><cell>50.4</cell></row><row><cell cols="7">Baseline(WSDDN+ODR) 44.3 71.0 45.6 24.2 15.4 70.0 69.5 47.0 21.8 65.9 37.5 59.8 52.7</cell><cell>70.4</cell><cell>7.2</cell><cell>26.4</cell><cell>59.8 60.5 67.5 64.4</cell><cell>49.0</cell></row><row><cell>Ours</cell><cell cols="6">63.4 70.5 45.1 28.3 18.4 69.8 65.8 69.6 27.2 62.6 44.0 59.6 56.2</cell><cell>71.4</cell><cell>11.9</cell><cell>26.2</cell><cell>56.6 59.6 69.2 65.4</cell><cell>52.0</cell></row><row><cell>Ours+FRCNN</cell><cell cols="6">62.7 69.1 43.6 31.1 20.8 69.8 68.1 72.7 23.1 65.2 46.5 64.0 67.2</cell><cell>66.5</cell><cell>10.7</cell><cell>23.8</cell><cell>55.0 62.4 69.6 60.31 52.6</cell></row><row><cell>Method</cell><cell cols="2">aero bike bird boat bottle bus</cell><cell>car</cell><cell cols="6">cat chair cow table dog horse mbike person plant sheep sofa train</cell><cell>tv</cell><cell>mAP</cell></row><row><cell>WSDDN+context[15]</cell><cell>64.0 54.9 36.4 8.1</cell><cell cols="3">12.6 53.1 40.5 28.4</cell><cell>6.6</cell><cell>35.3 34.4 49.1 42.6</cell><cell>62.4</cell><cell>19.8</cell><cell>15.2</cell><cell>27.0 33.1 33.0 50.0 35.3</cell></row><row><cell>WCCN [9]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Table 3. CorLoc on the trainval set of VOC 2007.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>61.4</cell></row><row><cell>WSRPN [27]</cell><cell>81.2 81.2 60.7 36.7 52.3 80.7 89.0 65.1 20.5 86.3 61.6 49.5 86.4</cell><cell>92.4</cell><cell>41.4</cell><cell>62.6</cell><cell>79.4 62.4 73.0 75.6</cell><cell>66.9</cell></row><row><cell>OICR+FRCNN [26]</cell><cell>85.8 82.7 62.8 45.2 43.5 84.8 87.0 46.8 15.7 82.2 51.0 45.6 83.7</cell><cell>91.2</cell><cell>22.2</cell><cell>59.7</cell><cell>75.3 65.1 76.8 78.1</cell><cell>64.3</cell></row><row><cell>ZLDN [32]</cell><cell>74.0 77.8 65.2 37.0 46.7 75.8 83.7 58.8 17.5 73.1 49.0 51.3 76.7</cell><cell>87.4</cell><cell>30.6</cell><cell>47.8</cell><cell>75.0 62.5 64.8 68.8</cell><cell>61.2</cell></row><row><cell>CL [30]</cell><cell>85.8 80.4 73.0 42.6 36.6 79.7 82.8 66.0 34.1 78.1 36.9 68.6 72.4</cell><cell>91.6</cell><cell>22.2</cell><cell>51.3</cell><cell>79.4 63.7 74.5 74.6</cell><cell>64.7</cell></row><row><cell>PCL+FRCNN [25]</cell><cell>83.8 85.1 65.5 43.1 50.8 83.2 85.3 59.3 28.5 82.2 57.4 50.7 85.0</cell><cell>92.0</cell><cell>27.9</cell><cell>54.2</cell><cell>72.2 65.9 77.6 82.1</cell><cell>66.6</cell></row><row><cell cols="2">WSRPN+FRCNN [27] 83.8 82.7 60.7 35.1 53.8 82.7 88.6 67.4 22.0 86.3 68.8 50.9 90.8</cell><cell>93.6</cell><cell>44.0</cell><cell>61.2</cell><cell>82.5 65.9 71.1 76.7</cell><cell>68.4</cell></row><row><cell>Baseline</cell><cell>64.2 83.5 63.1 45.2 38.5 82.2 86.7 57.6 35.5 83.6 41.8 69.5 69.0</cell><cell>90.4</cell><cell>20.1</cell><cell>56.8</cell><cell>83.5 66.9 78.3 79.6</cell><cell>64.8</cell></row><row><cell>Ours</cell><cell>84.2 84.7 59.5 52.7 37.8 81.2 83.3 72.4 41.6 84.9 43.7 69.5 75.9</cell><cell>90.8</cell><cell>18.1</cell><cell>54.9</cell><cell>81.4 60.8 79.1 80.6</cell><cell>66.9</cell></row><row><cell>Ours+FRCNN</cell><cell>86.7 85.9 63.4 55.3 42.0 84.8 85.2 78.2 47.2 88.4 49.0 73.3 84.0</cell><cell>92.8</cell><cell>20.5</cell><cell>56.8</cell><cell>84.5 62.9 82.1 78.1</cell><cell>70.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 .</head><label>4</label><figDesc>CorLoc on the trainval set of VOC 2012.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised object detection with posterior regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised deep detection networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2846" to="2854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Decoupled classification refinement: Hard false positive suppression for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04002</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Revisiting rcnn: On awakening the classification power of faster rcnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="453" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weakly supervised object localization with multifold multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Ramazan Gokberk Cinbis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="189" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Localizing objects while learning their appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="452" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Weakly supervised localization and learning with generic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="293" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Weakly supervised cascaded convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Diba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Pazandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="914" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-evidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1277" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep self-taught learning for weakly supervised object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1377" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contextlocnet: Context-aware deep network models for weakly supervised localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Kantorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="350" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Selfpaced learning for latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>M Pawan Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Scale-aware trident networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.01892</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6120</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generative adversarial learning towards fast weakly supervised detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5764" to="5773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">On learning to localize objects with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaid</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.1024</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Pcl: Proposal cluster learning for weakly supervised object detection. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">Loddon</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiple instance detection network with online instance classifier refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2843" to="2851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Weakly supervised region proposal network and object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angtian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongluan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="352" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jasper Rr Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Koen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold Wm</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="171" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Min-entropy latent model for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenjun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1297" to="1306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Collaborative learning for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="971" to="977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Ts2c: Tight box mining with surrounding segmentation context for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="434" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Zigzag learning for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4262" to="4270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">W2f: A weakly-supervised to fully-supervised framework for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yancheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="928" to="936" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
