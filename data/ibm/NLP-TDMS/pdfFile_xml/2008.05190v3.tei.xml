<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating the Impact of Knowl-edge Graph Context on Entity Disambiguation Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Virtual Event, Ireland. ACM</publisher>
				<availability status="unknown"><p>Copyright Virtual Event, Ireland. ACM</p>
				</availability>
				<date type="published" when="2020-10-19">2020. October 19-23, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaiah</forename><forename type="middle">Onando</forename><surname>Mulang&amp;apos;</surname></persName>
							<email>isaiah.mulang.onando@iais.fraunhofer.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
							<email>kuldeep.singh1@cerence.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cerence</forename><surname>Gmbh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zerotha</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germany</forename><forename type="middle">Chaitali</forename><surname>Prabhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Nadgeri</surname></persName>
							<email>abhishek22596@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
							<email>johannes.hoffart@gs.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goldman</forename><surname>Sachs</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Germany</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehmann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaiah</forename><forename type="middle">Onando</forename><surname>Mulang&amp;apos;</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitali</forename><surname>Prabhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Nadgeri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
							<email>jens.lehmann@cs.uni-bonn.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer IAIS and Zerotha Research</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating the Impact of Knowl-edge Graph Context on Entity Disambiguation Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th ACM International Conference on Information and Knowledge Man-agement (CIKM &apos;20)</title>
						<meeting>the 29th ACM International Conference on Information and Knowledge Man-agement (CIKM &apos;20) <address><addrLine>New York, NY, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Virtual Event, Ireland. ACM</publisher>
							<date type="published" when="2020-10-19">2020. October 19-23, 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3340531.3412159</idno>
					<note>ACM Reference Format:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual information from text to improve the performance of several NLP tasks. These models, albeit powerful, still require specialized knowledge in specific scenarios. In this paper, we argue that context derived from a knowledge graph (in our case: Wikidata) provides enough signals to inform pretrained transformer models and improve their performance for named entity disambiguation (NED) on Wikidata KG. We further hypothesize that our proposed KG context can be standardized for Wikipedia, and we evaluate the impact of KG context on state-of-the-art NED model for the Wikipedia knowledge base. Our empirical results validate that the proposed KG context can be generalized (for Wikipedia), and providing KG context in transformer architectures considerably outperforms the existing baselines, including the vanilla transformer models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Entity Linking (EL) generally consists of two subtasks namely: surface form extraction (mention detection) and named entity disambiguation (NED). A surface form is a contiguous span of text that refers to a named entity. The NED task aims to link the identified named entity to ground truth entities in a given knowledge base <ref type="bibr" target="#b34">[26]</ref>. For a long time, researchers focused on NED tasks over semi-structured knowledge repositories such as Wikipedia 1 or publicly available KGs such as DBpedia <ref type="bibr" target="#b29">[21]</ref>, Freebase <ref type="bibr" target="#b10">[2]</ref>, and YAGO <ref type="bibr" target="#b35">[27]</ref>. Wikidata <ref type="bibr" target="#b38">[30]</ref> has recently attracted the community's 1 https://www.wikipedia.org/ Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). CIKM '20, October 19-23, 2020, Virtual Event, Ireland Â© 2020 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-6859-9/20/10. https://doi.org/10.1145/3340531.3412159 attention as a rich source of knowledge, and new approaches have been developed to target NED over Wikidata <ref type="bibr" target="#b11">[3]</ref>.</p><p>Motivation: A peculiarity of Wikidata is that the contents are collaboratively edited. As at April 2020; Wikidata contains 83,151,903 items and a total of over 1.2B edits since the project launch 2 . Considering Wikidata is collaboratively edited, the user-created entities add additional noise and non standard labels ((e.g. labels have several numeric and special, non-alphanumeric ASCII characters, also contains multi word labels up to 62 words, etc)) [7] since users do not follow a strict naming convention. For instance, there are 17,88,134 labels in which each label matches with at least two different URIs. Hence, NED on Wikidata is quite challenging as pointed out by initial studies <ref type="bibr" target="#b15">[7,</ref><ref type="bibr" target="#b32">24]</ref>. For example, consider the sentence from Wikidata-Disamb <ref type="bibr" target="#b11">[3]</ref> dataset: "the short highway in New South Wales and the Australian Capital Territory in Australia, it is part of Sydney-Canberra National Highway link". The entity surface form National Highway matches four(4) different entities in Wikidata that share the same entity label (i.e., "National Highway") while 2,055 other entities contain the whole mention in their labels. The correct entity wikidata:Q1967298 3 refers to Highway System of Australia, whereas wikidata:Q1967342 refers to the highway system in India. Having these two entities as candidates may require extra information in addition to the surface form or the sentence context. Attention-based Neural Networks <ref type="bibr" target="#b37">[29]</ref> and pretrained transformer models <ref type="bibr" target="#b21">[13,</ref><ref type="bibr" target="#b24">16]</ref>, have provided an avenue for encoding the context within text, howbeit, in cases such as our example, pure textual context may not be sufficient <ref type="bibr" target="#b19">[11]</ref>. As such, a method to obtain matching contextual information from the KG itself could be beneficial to disambiguate in such close scenarios. Inspired by the work of <ref type="bibr" target="#b11">[3]</ref> and inherited Wikidata NED challenges (nonstandard multi-word, long, implicit, case-sensitive), we hypothesize that the performance of pretrained transformer models improves by considering further context from the KG. We investigate three research questions: RQ1:How does applying KG context impact the performance of transformer models on NED over Wikidata? RQ2: What is the performance of different configurations of KG context as new information signals on the NED task? RQ3: Can we generalize our proposed context in a state of the art NED model for other knowledge bases such as Wikipedia? The structure of the paper is follows: next section defines the task followed by related work in 3. Section 4 describes approach and we present experiments in section 5. We conclude in section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TASK DEFINITION</head><p>Given a sentence, a recognized entity surface form, a set of candidate entities, and a Knowledge Graph (KG), the objective is to select the entity within the KG that matches the surface form in the text. A sentence D = {w 1 , w 2 , ..., w n } is a set of tokens of length n. The set of entity surface forms S = {s 1 , s 2 , ..., s k } : s i = (w â² â D)+ contains recognized entities s.t. each s, spans one or more tokens in D. We view a KG as a labeled directed graph. A KG = (E, H + , R) is a 3-tuple where: i) set E of all entities represent the vertices. ii) set R is the set of all edges between the entity instances in the graph. And; iii) H + â E Ã R Ã E is the ordered set of all triples. The function â(a â E âª R) is defined that retrieves labels of any given entity or relation from the KG.</p><p>Candidate Entities : A set containing selected entities from the KG given as:</p><formula xml:id="formula_0">E â² = {e â² 1 , e â² 2 , ..., e â² m } where e â² j â E and E â² = Ï (s i â S)</formula><p>, is obtained by a semantic selection operation Ï on a given surface form. This paper addresses the problem of named entity disambiguation which selects an entity e c â E â² that matches the textual mention s â S . We view this task as a classification f = Classi f y(h(X )) on the conditional probability h(X ) = P(Y = 1|X ). Taking x â X = (s, e â² ; Î¸ ) we study configurations of the context parameters Î¸ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>There is a wide variety of approaches in the literature for Entity Linking (EL) ranging from graph traversal <ref type="bibr" target="#b36">[28]</ref>, rule-based <ref type="bibr" target="#b31">[23]</ref>, to Neural Network-based approaches <ref type="bibr" target="#b15">[7,</ref><ref type="bibr" target="#b27">19]</ref>. For detailed information on entity linking we refer to the surveys in <ref type="bibr" target="#b9">[1,</ref><ref type="bibr" target="#b33">25]</ref>. Herein, we restrict ourselves to very closely related recent literature. Advances in Neural Networks and the introduction of self-attention based techniques <ref type="bibr" target="#b37">[29]</ref> that allow for encoding of contextual meaning from text have advanced research in EL. Work in <ref type="bibr" target="#b26">[18]</ref> improved EL performance by proposing a new approach that combines deep learning with more traditional methods such as graphical models and probabilistic mention-entity maps. Research in <ref type="bibr" target="#b27">[19]</ref> aims to achieve an end-to-end EL through context-aware mention embeddings, entity embeddings, and a probabilistic mentions.</p><p>In the meantime, research on the learning of contextual data has advanced in two directions. On one hand, the powerful pretrained transformer models <ref type="bibr" target="#b21">[13,</ref><ref type="bibr" target="#b24">16]</ref> have emerged as state-of-the-art for representing context within text and have seen burgeoning reuse through fine-tuning for several NLP tasks <ref type="bibr" target="#b12">[4]</ref>. On the other hand, KGs are increasingly being seen as a source of additional knowledge for Neural Networks. For instance researchers in <ref type="bibr" target="#b14">[6]</ref> recently released an embedding library for the Wikidata KG while the work by <ref type="bibr" target="#b19">[11]</ref> introduced an extension of BERT (KBERT) in which KG triples are injected into the sentences as domain knowledge. Specific to the EL task, the work by <ref type="bibr" target="#b15">[7]</ref> employs information from a locally derived KG to improve the performance of end-to-end EL using attention-based Neural Networks. Researchers in <ref type="bibr" target="#b11">[3]</ref> fetched a significant amount (as high as 1500) of 2-hop KG triples and used Recurrent Neural Networks (RNN) to encode this information. In this paper, we argue that a slight amount of KG triple context is enough for a pretrained transformer. We study the different configuration of KG context on transformer models to target NED on Wikidata. <ref type="figure">Figure 1</ref> illustrates the overall approach. For the classification : f (h(s, e â² ; Î¸ )) = y such that s, the mentioned surface form, and e â² , the candidate entity, are known. A set of contextual parameters Î¸ is then provided to the model. By adding the original sentence as part of the input, we let the model learn source context. Our approach then models a set of information from the target KG in the form of KG triples Î¦ as context. The aim is to maximize both the true positives and true negatives such that, for every input, if y = 1 then the e c is the ground truth entity of s in the KG. The classifier employs the binary cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPROACH</head><p>Knowledge Graph Context: We use a SPARQL endpoint to fetch triples of the identified entity in the sentence. There are two sets of triple configurations considered in our experiments, depending on the hop counts from the head entity. The parameter Î¦ is therefore an ordered set of of triples (h e , r hp , t hp ) i such that h e , the head (subject) of any triple is the candidate entity to be classified whereas hp = 1|2 is the hop count. The i refers to the position of the triple in the set and can range between 1 and over 1000. To formulate our input, we consider the natural language labels of the retrieved triples l h e , l r , l t . A triple is therefore verbalized into it's natural language form: "l h e [whitespace]l r [whitespace]l t ". The sequence of these verbalized triples are appended to the original sentence and surface form delimited by the [SEP] token. <ref type="figure">Figure 1</ref> shows how the context input is handled such that the Segment Embeddings for every triple is different and provides a unique signal to the tokens at the embeddings layer of the network. When the total number of triples is too many, we use the maximum sequence length to limit the input where the final context representation Î¦ max â Î¦. The values of Î¦ max ,for entity: Q1967298 in figure 2, is given as: [National Highway description highway system in Australia </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>Datasets: The first dataset is Wikidata-Disamb <ref type="bibr" target="#b11">[3]</ref>, which aligns Wiki-Disamb30 <ref type="bibr" target="#b25">[17]</ref> to Wikidata entities, and adds closely matching entities as negative samples to every entity in the dataset. It consists of 200,000 Train and 20,000 Test samples. We also consider the ISTEX dataset introduced by <ref type="bibr" target="#b13">[5]</ref>, extracted from scientific publications and contains 1000 author-affiliation strings from research articles aligned to Wikidata. For generalizing the impact of KG context, we choose standard Wikipedia dataset: AIDA-CoNLL <ref type="bibr" target="#b17">[9]</ref>. We aligned its Wikipedia entities to corresponding Wikidata mentions to fetch the KG triples. Datasets are accompanied with a pre-computed candidate list. Baselines: We compare our results with three types of baselines. First is <ref type="bibr" target="#b11">[3]</ref>, which experimented with numerous configurations of KG context on Long Short Term Memory (LSTM) networks and reported an ablation of these configurations. These models were augmented with a massive amount of 1&amp;2-hop KG triples. We also <ref type="figure">Figure 1</ref>: Overall Approach : Î¦ refers to the ordered set of triples from the KG for a candidate entity while Î¦ max â Î¦, is the maximum number of triples that fits in the sequence length. For brevity: N â "National", H â "Highway", desc â "description" run the model on the ISTEX dataset to enable performance comparison. We create a second set of baselines by employing the vanilla transformer models of RoBERTa and XLNet(i.e., transformers without KG context) on Wikidata-Disamb and ISTEX. We fine-tuned vanilla models on Wikidata-Disamb training set. For AIDA-CoNLL, we chose <ref type="bibr" target="#b20">[12]</ref> as our underlying model which is the second peer reviewed SOTA on this dataset. Authors used Wikipedia descriptions as a context for candidate entities, and we replaced this context with our proposed 1-hop KG triple context fetched from Wikidata triples of corresponding Wikipedia entities. We verbalized the fetched triples, as described in our approach. Model Parameters: We chose two state of the art transformer architectures: RoBERTa <ref type="bibr" target="#b21">[13]</ref>, and XLNet <ref type="bibr" target="#b24">[16]</ref> and fine-tune them using Wikidata-Disamb30 training set. We report P,R,F values following the baseline of Wikidata-Disamb and ISTEX dataset. For each vanilla Transformer architecture, we add a classification head. The maximum sequence length for the inputs in both models is fixed at 512 tokens, and we use this to limit the amount of KG context to feed. We publicly release code, datasets, training details, and results for reusability and reproducibility. On AIDA-CoNLL, We use open source implementation of <ref type="bibr" target="#b20">[12]</ref> for feeding the KG context and report In-KB accuracy as prior work(s).</p><p>Results and Discussion: <ref type="table" target="#tab_0">Table 1</ref> shows the results from evaluating our approach against the baselines on the Wikidata-Disamb30 and table 2 indicates the performance of the models on the ISTEX dataset. The results in table 2 obtained by running the same model trained on the Wikidata-Disamb30 dataset (also for baseline) with context, but during testing, no more context is provided. Based on our results, we postulate that although the Transformer based language models are trained on huge corpus and possess context for the data, they show limited performance even against the RNN model. This RNN model <ref type="bibr" target="#b11">[3]</ref> uses GloVe embeddings together with task-specific context (cf.   . This signals that the further away we drift from the head entity, the noisier the signal provided by the context added. As such, we did not extend evaluation to higher triple hops. However, we can observe that XLNet shows a more stable behavior in cases when the excess context is provided as it can preserve already learned information. It is in contrast to RoBERTa, which loses necessary signals in an attempt to learn from the extra context. The amount of data fed as the context in our models is minimal (up to 15 1-hop triples). In contrast, the best performing model from work in <ref type="bibr" target="#b11">[3]</ref>, was fed up to 1500 1+2-hop triples. Our best performance can then be attributed to the quality of textual context learned by the transformers as well as the optimal choice of KG-triples context. Generalizing KG Context: We induced 1-hop KG context in DCA-SL model <ref type="bibr" target="#b20">[12]</ref> for candidate entities. The replacement of the unstructured Wikipedia description with structured KG triple context containing entity aliases, entity types, consolidated entity description, etc. has a positive impact on the performance. Our proposed change (DCA-SL + Triples) outperforms the baselines for Wikipedia entity disambiguation(cf. <ref type="table" target="#tab_3">Table 3</ref>). Please note, out of 207,544 total entities of AIDA-CoNLL datasets, 7591 entities have no corresponding Wikidata IDs. Even if we do not feed the KG context for 7591 entities, the performance increases. It validates our third research question (RQ3), and we conclude KG triple context can be standardized for the NED task for Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we study three closely related research questions. We demonstrate that pretrained Transformer models, although powerful, are limited to capturing context available purely on the texts concerning the original training corpus. We observe that an extra task-specific KG context improved the performance. However, there is a limit to the number of triples as the context that can improve performance. We note that 2-hop triples resulted in negative or little impact on transformer performance. Our triple context can be generalized (for Wikipedia) and observes a positive effect on the NED model for Wikipedia, leading into a new SOTA for AIDA-CoNLL dataset. For the future work, it would be interesting to understand which triples negatively impact the context and how to select the "optimal choice of KG-triples context, " considering we rely on the triple in the same order of the SPARQL endpoint returned results. As a viable next step, we plan to study independent effect of various KG attributes (entity properties such as aliases, descriptions, Instance-of, etc.) on NED models' performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>[</head><label></label><figDesc>SEP] National Highway label National Highway [SEP] National Highway date modified 31 May 2019 [SEP]]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>KG context : Top three 1-hop triples from Wikidata for the two entities with same label: National Highway.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 )</head><label>1</label><figDesc>. However, the transformer models</figDesc><table><row><cell>Model</cell><cell>Prec</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>LSTM + RNN-triplets [3]</cell><cell>90.1</cell><cell>92.0</cell><cell>91.1</cell></row><row><cell>LSTM+RNN-triplets+ATN[3]</cell><cell>90.2</cell><cell>93.0</cell><cell>91.6</cell></row><row><cell>RoBERTa -without KG context</cell><cell>89.09</cell><cell>84.67</cell><cell>86.23</cell></row><row><cell>XLNet-without KG context</cell><cell>89.32</cell><cell>87.62</cell><cell>88.46</cell></row><row><cell>Our Contextual models</cell><cell></cell><cell></cell><cell></cell></row><row><cell>RoBERTa + 1-hop KG Context</cell><cell>91.48</cell><cell>93.23</cell><cell>92.35</cell></row><row><cell>RoBERTa + 1&amp;2-hop KG Context</cell><cell>89.88</cell><cell>87.64</cell><cell>88.75</cell></row><row><cell>XLNet + 1-hop KG Context</cell><cell>91.55</cell><cell>93.14</cell><cell>92.34</cell></row><row><cell>XLNet + 1&amp;2-hop KG Context</cell><cell>91.93</cell><cell>92.36</cell><cell>92.14</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of our model against baselines on the Wikidata-Disamb dataset. Best results in dark bold</figDesc><table><row><cell cols="4">outperform the baseline models when fed with our proposed KG</cell></row><row><cell cols="4">context. For instance, (cf. Table 1), RoBERTa, with a 1-hop con-</cell></row><row><cell cols="4">text, can correctly link entities in additional 1127 sample sentences</cell></row><row><cell cols="4">in the test set (flipped from incorrect to the correct predictions)</cell></row><row><cell cols="4">compared to its vanilla setting. These samples have 997 unique</cell></row><row><cell cols="4">Wikidata IDs. These results also indicate that the transformer mod-</cell></row><row><cell>Model</cell><cell>Prec</cell><cell cols="2">Recall F1</cell></row><row><cell>LSTM + RNN of triplets + ATN [3]</cell><cell>86.32</cell><cell cols="2">96.38 90.97</cell></row><row><cell>RoBERTa + 1-hop Triples (Ours)</cell><cell>91.70</cell><cell>91.98</cell><cell>91.84</cell></row><row><cell>XLNet + 1-hop KG Context(Ours)</cell><cell cols="2">96.39 89.11</cell><cell>92.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Our models against baseline on ISTEX dataset els achieve better precision compared to recall; this is clear in table 2 and interpreted as follows: our model is more likely to classify an entity as the correct entity only when it is true (few false positives). For brevity, the detailed analysis of each experimental setup and corresponding data can be found in our Github 4 .Concerning RQ2, our results indicate that including triples from higher hop counts either exhibit an inverse impact on the performance or have minimal effect on overall model behavior (cf.Table 1 RoBERTa vs. XLNet 2-hop values)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Generalizability Study: Comparison of KG Context based model against baselines on the AIDA-CONLL dataset. Best value in bold and previous SOTA value is underline.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.wikidata.org/wiki/Wikidata:Statistics 3 wikidata:Q1967298 binds to https://www.wikidata.org/wiki/Q1967298 arXiv:2008.05190v3 [cs.CL] 30 Aug 2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/mulangonando/Impact-of-KG-Context-on-ED</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGMENTS</head><p>This work is co-funded by the Federal Ministry of Education and Research's (BMBF) Software Campus initiative under the Answer-KiNG Project.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganea&amp;amp;hofmann</surname></persName>
		</author>
		<idno>18] 92.22Â±0.14</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<idno>14] 93.0</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le&amp;amp;titov</surname></persName>
		</author>
		<idno>20] 93.07Â±0.27</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deeptype</surname></persName>
		</author>
		<idno>22] 94.88</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fang</surname></persName>
		</author>
		<idno>15] 94.3</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le&amp;amp;</forename><surname>Titov</surname></persName>
		</author>
		<idno>20] 89.66Â±0.16</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dca-Sl</surname></persName>
		</author>
		<idno>12] 94.64Â±0.2</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<idno>10] 93.54Â±0.12</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dca-Sl + Triples</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>ours) 94.94Â±0.2 REFERENCES</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer International</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Neural Approach to Entity Linking on Wikidata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Cetoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECIR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Improving Entity Linking by Modeling Latent Entity Type Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinpeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">OpenTapioca: Lightweight Entity Linking for Wikidata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonin</forename><surname>Delpeuch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">PyTorch-BigGraph: A Large-scale Graph Embedding System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">encoding knowledge graph entity aliases in attentive neural network for wikidata entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaiah</forename><surname>Mulang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>WISE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuya</forename><surname>Yamada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In CoNLL</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robust Disambiguation of Named Entities in Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Improving Entity Linking by Modeling Latent Entity Type Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">K-BERT: Enabling Language Representation with Knowledge Graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning Dynamic Context Augmentation for Global Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Collective Entity Disambiguation with Structured Gradient Tree Boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Joint Entity Linking with Deep Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Fang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">TAGME: on-the-fly annotation of short text fragments (by Wikipedia entities)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugo</forename><surname>Scaiella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep Joint Entity Disambiguation with Local Neural Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Octavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">End-to-End Neural Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octavian-Eugen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>In In CoNLL</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Boosting Entity Linking Performance by Leveraging Unlabeled Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web Journal</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">DeepType: Multilingual Entity Linking by Neural Type System Evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Raiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Old is gold: linguistic driven approach for entity and relation linking of short text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Sakor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaiah</forename><forename type="middle">Onando</forename><surname>Mulang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeedeh</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Esther</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">SÃ¶ren</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2336" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Falcon 2.0: An Entity and Relation Linking Tool over Wikidata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Sakor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anery</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria-Esther</forename><surname>Vidal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11270</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Why Reinvent the Wheel: Let&apos;s Build Question Answering Systems Together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Sethupat Radhakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Both</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeedeh</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioanna</forename><surname>Lytra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akhilesh</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akmal</forename><surname>Khikmatullaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharmen</forename><surname>Punjani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference</title>
		<meeting><address><addrLine>Maria-Esther Vidal, Jens Lehmann, and SÃ¶ren Auer</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Yago: A Core of Semantic Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th International Conference on the World Wide Web</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">AGDISTIS -Graph-Based Disambiguation of Named Entities Using Linked Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>RÃ¶der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><forename type="middle">Athaide</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">SÃ¶ren</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Both</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="457" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Attention Is All You Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>abs/1706.03762</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Wikidata: a new platform for collaborative data collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandecic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW (Companion Volume)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
