<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BiERU: Bidirectional Emotional Recurrent Unit for Conversational Sentiment Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoxiong</forename><surname>Ji</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Erik</forename><forename type="middle">Cambria</forename></persName>
						</author>
						<title level="a" type="main">BiERU: Bidirectional Emotional Recurrent Unit for Conversational Sentiment Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Conversational sentiment analysis</term>
					<term>emotional recurrent unit</term>
					<term>contextual encoding</term>
					<term>dialogue systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sentiment analysis in conversations has gained increasing attention in recent years for the growing amount of applications it can serve, e.g., sentiment analysis, recommender systems, and human-robot interaction. The main difference between conversational sentiment analysis and single sentence sentiment analysis is the existence of context information which may influence the sentiment of an utterance in a dialogue. How to effectively encode contextual information in dialogues, however, remains a challenge. Existing approaches employ complicated deep learning structures to distinguish different parties in a conversation and then model the context information. In this paper, we propose a fast, compact and parameter-efficient partyignorant framework named bidirectional emotional recurrent unit for conversational sentiment analysis. In our system, a generalized neural tensor block followed by a two-channel classifier is designed to perform context compositionality and sentiment classification, respectively. Extensive experiments on three standard datasets demonstrate that our model outperforms the state of the art in most cases.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>S ENTIMENT analysis and emotion recognition are of vital importance in dialogue systems and have recently gained increasing attention <ref type="bibr" target="#b0">[1]</ref>. They can be applied to a lot of scenarios such as mining the opinions of speakers in conversations, improving the feedback of robot agents, and so on. Moreover, sentiment analysis in live conversations can be used in generating talks with certain sentiments to improve human-machine interaction. Existing approaches to conversational sentiment analysis can be divided into party-dependent approaches, like DialogueRNN <ref type="bibr" target="#b1">[2]</ref>, and party-ignorant approaches, such as AGHMN <ref type="bibr" target="#b2">[3]</ref>. Party-dependent methods distinguish different parties in a conversation while party-ignorant methods do not. Both party-dependent and party-ignorant models are not limited to dyadic conversations. Nevertheless, party-ignorant models can be easily applied to multi-party scenarios without any adjustment. In this paper, we propose a fast, compact and parameter-efficient party-ignorant framework based on emotional recurrent unit (ERU), a recurrent neural network that contains a generalized neural tensor block (GNTB) and a two-channel feature extractor (TFE) to tackle conversational sentiment analysis.</p><p>Context information is the main difference between dialogue sentiment analysis and single sentence sentiment analysis Wei Li, Nanyang Technological University, Singapore Wei Shao (equal contribution), Peking University, China Shaoxiong Ji, Aalto University, Finland Corresponding Author: Erik Cambria (cambria@ntu.edu.sg), Nanyang Technological University, Singapore tasks. It sometimes enhances, weakens, or reverses the raw sentiment of an utterance <ref type="figure" target="#fig_0">(Fig. 1</ref>). There are three main steps for sentiment analysis in a conversation: obtaining the context information, capturing the influence of the context information for an utterance, and extracting emotional features for classification. Existing dialogue sentiment analysis methods like c-LSTM <ref type="bibr" target="#b3">[4]</ref>, CMN <ref type="bibr" target="#b4">[5]</ref>, DialogueRNN <ref type="bibr" target="#b1">[2]</ref>, and DialogueGCN <ref type="bibr" target="#b5">[6]</ref> make use of complicated deep neural network structures to capture context information and describe the influence of context information for an utterance.</p><p>We redefine the formulation of conversational sentiment analysis and provide a compact structure to better encode the context information, capture the influence of context information for an utterance, and extract features for sentiment classification. According to Mitchell and Lapata <ref type="bibr" target="#b6">[7]</ref>, the meaning of a complete sentence must be explained in terms of the meanings of its subsentential parts, including those of its singular elements. Compositionality allows language to construct complicated meanings from its simpler terms. This property is often expressed in a manner of principle: the meaning of a whole is a function of the meaning of the components <ref type="bibr" target="#b7">[8]</ref>. For conversation, the context of an utterance is composed of its historical utterances information. Similarly, context is a function of the meaning of its historical utterances. Therefore, inspired by the composition function in <ref type="bibr" target="#b7">[8]</ref>, we design GNTB to perform context compositionality in conversation, which obtains context information and incorporates the context into utterance representation simultaneously, then employ TFE to extract emotional features. In this case, we convert the previous three-step task into a two-step task. Meanwhile, the compact structure reduces computational cost. To the best of our knowledge, our proposed model is the first to perform context compositionality in conversational sentiment analysis.</p><p>The GNTB takes the context and current utterance as inputs, and is capable of modeling conversations with arbitrary turns. It outputs a new representation of current utterance with context information incorporated (named 'contextual utterance vector' in this paper). Then, the contextual utterance vector is further fed into TFE to extract emotional features. Here, we employ a simple two-channel model for emotion feature extraction.</p><p>The long short-term memory (LSTM) unit <ref type="bibr" target="#b8">[9]</ref> and onedimensional convolutional neural network (CNN) <ref type="bibr" target="#b9">[10]</ref> are utilized for extracting features from the contextual utterance vector. Extensive experiments on three standard datasets demonstrate that our model outperforms state-of-the-art methods with fewer parameters. To summarize, the main contributions of this paper are as follows:</p><p>• We propose a fast, compact and parameter-efficient partyignorant framework based on emotional recurrent unit. • We design generalized neural tensor block which is suitable for different structures, to perform context compositionality. • Experiments on three standard benchmarks indicate that our model outperforms the state of the art with fewer parameters. The remainder of the paper is organized as follows: related work is introduced in Section II; the mechanism of our model is explained in Section III; results of the experiments are discussed in Section IV; finally, concluding remarks are provided in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Sentiment analysis is one of the key NLP tasks that has drawn great attention from the research community in the last decade <ref type="bibr" target="#b10">[11]</ref>. Beside the basic task of binary polarity classification <ref type="bibr" target="#b11">[12]</ref>, sentiment analysis research has been carried out in many other related topics such as multimodal sentiment analysis <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, multilingual sentiment analysis <ref type="bibr" target="#b14">[15]</ref>, aspect-based sentiment analysis <ref type="bibr" target="#b15">[16]</ref>, domain adaptation <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, rumors and fake news detection <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, genderspecific sentiment analysis <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and multitask learning <ref type="bibr" target="#b22">[23]</ref>, including also applications of sentiment analysis in domains like healthcare <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, political forecasting <ref type="bibr" target="#b25">[26]</ref>, tourism <ref type="bibr" target="#b26">[27]</ref>, customer relationship management <ref type="bibr" target="#b27">[28]</ref>, stance classification <ref type="bibr" target="#b28">[29]</ref>, and dialogue systems <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>.</p><p>Sentiment analysis in dialogues, in particular, has become a new trend recently. Poria et al. <ref type="bibr" target="#b3">[4]</ref> proposed context-dependent LSTM network to capture contextual information for identifying sentiment over video sequences, and Ragheb et al. <ref type="bibr" target="#b31">[32]</ref> utilized self attention to prioritize important utterances. Memory networks <ref type="bibr" target="#b32">[33]</ref>, which introduce an external memory module, was applied to modeling historical utterances in conversations. For example, CMN <ref type="bibr" target="#b4">[5]</ref> modeled dialogue histories into memory cells, ICON <ref type="bibr" target="#b33">[34]</ref> proposed global memories for bridging self-and inter-speaker emotional influences, and AGHMN <ref type="bibr" target="#b2">[3]</ref> proposed hierarchical memory network as utterance reader. Ghosal et al. <ref type="bibr" target="#b34">[35]</ref> incorporated commonsense knowledge to enhance emotion recognition. Recent advances in deep learning were also introduced to conversational sentiment analysis like attentive RNN <ref type="bibr" target="#b1">[2]</ref>, adversarial training <ref type="bibr" target="#b35">[36]</ref>, and graph convolutional networks <ref type="bibr" target="#b5">[6]</ref>. Another emerging direction is to incorporate Transformer-based contextual embedding. Zhong et al. <ref type="bibr" target="#b36">[37]</ref> leveraged commonsense knowledge from external knowledge bases to enrich transformer encoder. Qin et al. <ref type="bibr" target="#b38">[38]</ref> built a co-interactive relation network to model feature interaction from bidirectional encoder representations from transformers (BERT) for joint dialogue act recognition and sentiment analysis.</p><p>Neural Tensor Networks (NTN) <ref type="bibr" target="#b39">[39]</ref> first proposed for reasoning over relational data are also related to our work. Socher et al. <ref type="bibr" target="#b40">[40]</ref> further extended NTN to capture semantic compositionality for sentiment analysis. The authors proposed a tensor-based composition function to learn sentence representation recursively, which solves the issue when words function as operators that change the meaning of another word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Definition</head><p>Given a multiple turns conversation C, the task is to predict the sentiment labels or sentiment intensities of the constituent utterances U 1 , U 2 , ..., U N . Taking the interactive emotional database IEMOCAP <ref type="bibr" target="#b41">[41]</ref> as an example, emotion labels include frustrated, excited, angry, neutral, sad, and happy. In general, the task is formulated as a multi-class classification problem over sequential utterances while in some scenarios, it is regarded as a regression problem given continuous sentiment intensity. In this paper, utterances are pre-processed and represented as u t using feature extractors described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Textual Feature Extraction</head><p>Following the tradition of DialogueRNN <ref type="bibr" target="#b1">[2]</ref>, utterances are first embedded into vector space and then fed into CNNs <ref type="bibr" target="#b9">[10]</ref> for feature extraction. N-gram features are obtained from each utterance by applying three different convolution filters of sizes 3, 4, and 5, respectively. Each filter has 50 features-maps. <ref type="bibr" target="#b1">[2]</ref> then use max-pooling followed by rectified linear unit (ReLU) activation <ref type="bibr" target="#b42">[42]</ref> to process the outputs of convolution operation.</p><p>These activation values are concatenated and fed to a 100 dimensional fully connected layer whose outputs serve as the textual utterance representation. This CNN-based feature extraction network is trained at utterance level supervised by the sentiment labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Our Model</head><p>Our ERU is illustrated in Note 1 of <ref type="figure" target="#fig_2">Fig. 2</ref>, which consists of two components GNTB and TFE. As mentioned in the introduction, there are three main steps for conversational sentiment analysis, namely obtaining the context representation, incorporating the influence of the context information into an utterance, and extracting emotional features for classification. In this paper, the ERU is employed in a bidirectional manner  T F E f , and GN T B f are forward contextual utterance vector, TFE, and GNTB, respectively. p b t and ERU b stand for backward contextual utterance vector and ERU, respectively.ŷ t is the predicted possibility vector of sentiment labels. T refers to textual modality in this paper. In our model, we only focus on textual modality. The detailed structures of GNTB and TFE are shown in <ref type="figure" target="#fig_3">Fig. 3</ref>.</p><p>(BiERU) to conduct the above sentiment analysis task, reducing some expensive computations and converting the previous three-step task into a two-step task as shown in <ref type="figure" target="#fig_2">Fig. 2</ref>.</p><p>Similar to bidirectional LSTM (BiLSTM) <ref type="bibr" target="#b43">[43]</ref>, two ERUs are utilized for forward and backward passing the input utterances. Outputs from the forward and backward ERUs are concatenated for sentiment classification or regression. More concretely, the GNTB is applied to encoding the context information and incorporating it into an utterance simultaneously; while TFE takes the output of GNTB as input and is used to obtain emotional features for classification or regression.</p><p>1) Generalized Neural Tensor Block: The utterance vector u t ∈ R d with the context information incorporated is named as contextual utterance vector p t ∈ R d in this paper, where d is the dimension of u t and p t . At time t, GNTB ( <ref type="figure" target="#fig_3">Fig. 3</ref>: (a)) takes u t and p t−1 as inputs and then outputs p t , a contextual utterance vector. In this process, GNTB first extracts the context information from p t−1 ; it then incorporates the context information into u t ; finally, contextual utterance vector p t is obtained. The first step is to capture the context information and the second step is to integrate the context information into current utterance. The combination of these two steps is regarded as context compositionality in this paper. To the best of our knowledge, this is the first work to perform context compositionality in conversational sentiment analysis. GNTB is the core part that achieves the context compositionality. The formulation of GNTB is described below:</p><formula xml:id="formula_0">p t = f (m T t T [1:k] m t + W m t ).<label>(1)</label></formula><formula xml:id="formula_1">m t = p t−1 ⊕ u t (2)</formula><p>where m t ∈ R 2d is the concatenation of p t−1 and u t ; f is an activation function, such as tanh, sigmoid and so on; the tensor T [1:k] ∈ R 2d×2d×k and the matrix W ∈ R k×2d are the parameters used to calculate p t . Each slice T [i] ∈ R 2d×2d can be interpreted as capturing a specific type of context compositionality. Each slice W [i] ∈ R 1×2d maps contextual utterance vector p t and utterance vector u t into the context compositionality space. Here we have k different context compositionality types, which constitutes k-dimensional context compositionality space. The main advantage over the previous neural tensor networks (NTN) <ref type="bibr" target="#b39">[39]</ref>, which is a special case of the GNTB when k is set to d, is that GNTB is suitable for different structures rather than only the recursive structure and the space complexity of GNTB is</p><formula xml:id="formula_2">O(kd 2 ) compared with O(d 3 ) in NTN.</formula><p>In order to further reduce the number of parameters, we employ the following low-rank matrix approximation for each slice T [i] :</p><formula xml:id="formula_3">T [i] = U V + diag(e)<label>(3)</label></formula><p>where U ∈ R 2d×r , V ∈ R r×2d , e ∈ R 2d and r d. 2) Two-channel Feature Extractor: We utilize TFE to refine the emotion features from contextual vector p t . As shown in <ref type="figure" target="#fig_3">Fig. 3: (b)</ref>, the TFE is a two-channel model, including a LSTM cell <ref type="bibr" target="#b8">[9]</ref> branch and a one-dimensional CNN <ref type="bibr" target="#b9">[10]</ref> branch. The two branches receive the same contextual utterance vector p t and produce outputs that may contain complementary information <ref type="bibr" target="#b44">[44]</ref>.</p><p>At time t, the LSTM cell takes hidden state h t−1 , cell state c t−1 and the contextual utterance vector p t as inputs, where h t−1 and c t−1 are obtained from the last time step t − 1. The outputs of the LSTM cell are updated hidden state h t and cell state c t . The hidden state h t is regarded as the emotion feature vector. The CNN receives p t as input and outputs the emotion feature vector l t . Finally, the outputs of LSTM cell branch h t and CNN branch l t are concatenated into an emotion feature vector e t which is also the output of ERU. The formulas of TFE are as follows:</p><formula xml:id="formula_4">h t , c t = LST M Cell(p t , (h t−1 , c t−1 ) (4) l t = CN N (p t ) (5) e t = h t ⊕ l t<label>(6)</label></formula><p>3) Sentiment Classification &amp; Regression: Taking emotion feature e t as input, we use a linear neural network W c ∈ R De×n class followed by a softmax layer to predict the sentiment labels, where n class is the number of sentiment labels.</p><p>Then, we obtain the probability distribution S t of the sentiment labels. Finally, we take the most possible sentiment class as the sentiment label of the utterance u t :</p><formula xml:id="formula_5">S t = Sof tmax(W T c e t )<label>(7)</label></formula><formula xml:id="formula_6">y t = arg max i (S t [i])<label>(8)</label></formula><p>For sentiment regression task, we use a linear neural network W r ∈ R De×1 to predict the sentiment intensity. Then, we obtain the predicted sentiment intensity q t :</p><formula xml:id="formula_7">q t = W T r e t<label>(9)</label></formula><p>where W s ∈ R De×n class , e t ∈ R De , S t ∈ R n class , q t is a scalar andŷ t is the predicted sentiment label for utterance u t . 4) Training: For classification task, we choose crossentropy as the measure of loss, and use L2-regularization to relieve overfitting. The loss function is:</p><formula xml:id="formula_8">L = − 1 N s=1 c(s) N i=1 c(i) j=1 log S i,j [y i,j ] + λ θ 2<label>(10)</label></formula><p>For regression task, we choose mean square error (MSE) to measure loss, and L2-regularization to relieve overfitting. The loss function is:</p><formula xml:id="formula_9">L = 1 N s=1 c(s) N i=1 c(i) j=1 (q i,j − z i,j ) 2 + λ θ 2<label>(11)</label></formula><p>where N is the number of samples/conversations, S i,j is the probability distribution of sentiment labels for utterance j of conversation i, y i,j is the expected class label of utterance j of conversation i, q i,j is the predicted sentiment intensity of utterance j of conversation i, z i,j is the expected sentiment intensity of utterance j of conversation i, c(i) is the number of utterances in sample i, λ is the L2-regularization weight, and θ is the set of trainable parameters. We employ stochastic gradient descent based Adam <ref type="bibr" target="#b45">[45]</ref> optimizer to train our network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Bidirectional Emotion Recurrent Unit Variants</head><p>Our model has two different forms according to the source of context information, namely bidirectional emotion recurrent unit with global context (BiERU-gc) and bidirectional emotion recurrent unit with local context (BiERU-lc). 1) BiERU-gc: According to equation <ref type="formula" target="#formula_0">(1)</ref>, GNTB extracts the context information from p t−1 , integrates the context information into u t , and thus obtains the contextual utterance vector p t . Based on the definition of contextual utterance vector, p t−1 is the utterance vector that contains information of u t−1 and p t−2 . In this case, the contextual utterance vector p t holds the context information from all the preceding utterances u 1 , u 2 , · · · , u t−1 in a recurrent manner. Bidirectional neural networks have empirically gained improved performance than its counterpart with only forward propagation <ref type="bibr" target="#b46">[46]</ref>. As shown in <ref type="figure" target="#fig_2">Fig. 2 : (a)</ref>, we utilize the bidirectional setting to capture context information from surrounding utterances. The BiERU in <ref type="figure" target="#fig_2">Fig. 2 :(a)</ref> is named as BiERU-gc.</p><p>2) BiERU-lc: Following equation <ref type="formula" target="#formula_0">(1)</ref>, GNTB extracts the context information from the contextual utterance vector p t−1 , and p t−1 contains the context information of all the preceding utterances u 1 , u 2 , · · · , u t−2 as mentioned above. If replacing p t−1 with u t−1 in equation <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula">(2)</ref>, p t contains the information of u t−1 and u t . In other words, u t−1 is not only an utterance vector, but also works as the context of u t . As shown in <ref type="figure" target="#fig_2">Fig. 2 : (b)</ref>, bidirectional ERU makes p t obtain the future information u t+1 . In this case, GNTB extracts the context information from u t−1 and u t+1 , which are the adjacent utterances of u t . We name this model as BiERU-lc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we conduct a series of comparative experiments to evaluate the performance of our proposed model (Codes are available on our GitHub 1 ) and perform a thorough analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>We use three datasets for experiments, i.e., AVEC <ref type="bibr" target="#b47">[47]</ref>, IEMOCAP <ref type="bibr" target="#b41">[41]</ref> and MELD <ref type="bibr" target="#b48">[48]</ref>, which are also used by some representative models such as DialogueRNN <ref type="bibr" target="#b1">[2]</ref> and DialogueGCN <ref type="bibr" target="#b5">[6]</ref>. We conduct the standard data partition rate (details in <ref type="table" target="#tab_1">Table I</ref>  Originally, these three datasets are multimodal datasets. Here, we focus on the task of textual conversational sentiment analysis, and only use the textual modality to conduct our experiments.</p><p>a) IEMOCAP: The IEMOCAP <ref type="bibr" target="#b41">[41]</ref> is a dataset of twoway conversations involved with ten distinct participators. It is recorded as videos where every video clip contains a single dyadic dialogue, and each dialogue is further segmented into utterances. Each utterance is labeled as one sentiment label from six sentiment labels, i.e., happy, sad, neutral, angry, excited and frustrated. The dataset includes three modalities: audio, textual and visual. Here, we only use textual modality data in experiments. b) AVEC: The AVEC dataset <ref type="bibr" target="#b47">[47]</ref> is a modified version of the SEMAINE database <ref type="bibr" target="#b49">[49]</ref> that contains interactions between human speakers and robots. Unlike IEMOCAP, each utterance in the AVEC dataset is given an annotation every 0.2 second with one of four real valued attributes, i.e., valence ([−1, 1]), arousal ([−1, 1]), expectancy ([−1, 1]), and power ([0, ∞]). Our experiments use the processed utterance-level annotation <ref type="bibr" target="#b1">[2]</ref>, and treat four affective attributes as four subsets for evaluation. c) MELD: The MELD <ref type="bibr" target="#b48">[48]</ref> is a multimodal and multiparty sentiment analysis/classification database. It contains textual, acoustic, and visual information for more than 13000 utterances from Friends TV series. The sentiment label of each utterance in a dialogue lies within one of the following seven sentiment classes: fear, neutral, anger, surprise, sadness, joy and disgust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Baselines and Settings</head><p>To evaluate performance of our model, we choose the following models as strong baselines including the state-ofthe-art methods.</p><p>a) c-LSTM <ref type="bibr" target="#b3">[4]</ref>: The c-LSTM uses bidirectional LSTM <ref type="bibr" target="#b8">[9]</ref> to learn contextual representation from the surrounding utterances. When combined with the attention mechanism, it becomes the c-LSTM+Att. <ref type="bibr" target="#b0">1</ref> https://github.com/Maxwe11y/BiERU b) CMN <ref type="bibr" target="#b4">[5]</ref>: This model utilizes memory network and two different GRUs <ref type="bibr" target="#b50">[50]</ref> for two speakers for representation learning of utterance context from dialogue history. c) DialogueRNN <ref type="bibr" target="#b1">[2]</ref>: It distinguishes different parties in a conversation interactively, with three GRUs representing the speaker states, context, and emotion. It has several variants including DialogueRNN+Att with attention mechanism and bidirectional BiDialgoueRNN. d) DialogueGCN <ref type="bibr" target="#b5">[6]</ref>: This model employs graph neural network based approach through which context propagation issue can be addressed, to detect sentiment in conversations. e) AGHMN <ref type="bibr" target="#b2">[3]</ref>: It utilizes hierarchical memory networks with BiGRUs for utterance reader and fusion, and attention mechanism for memory summarizing. f) Settings: All the experiments are performed using CNN extracted features as described in Method section. For fair comparison with the state-of-the-art DialogueRNN model, we use their utterance representation directly 2 .</p><p>To alleviate over-fitting, we employ Dropout <ref type="bibr" target="#b51">[51]</ref> over the outputs of GNTB and TFE. For the nonlinear activation function, we choose the sigmoid function for sentiment classification and the relu function for sentiment regression. Our model is optimized by an Adam optimizer <ref type="bibr" target="#b45">[45]</ref>. Hyperparameters are tuned manually. Batch size is set as 1. We set the rank for all the experiments to r = 10. Our model is implemented using PyTorch <ref type="bibr" target="#b52">[52]</ref>. In <ref type="table" target="#tab_1">Table II</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results</head><p>We compare our model with baselines on textual modality using three standard benchmarks. We run the experiment five times and report the average results. Overall, our model outperforms all the baseline methods including state-of-theart models like DialogueRNN, DialogueGCN and AGHMN on these datasets, and markedly exceeds in some indicators as the results show in <ref type="table" target="#tab_1">Table III</ref>.</p><p>For the IEMOCAP dataset as a classification problem, we use accuracy for each class, and weighted average of accuracy and f1-score for measuring the overall performance. As for the AVEC dataset, standard metrics for regression task including Pearson correlation coefficient (r) are used for evaluation. We use weighted average of accuracy as the measure of performance on MELD dataset.    <ref type="table" target="#tab_1">Table III</ref>, our proposed BiERU-gc model exceeds the best model DialogueGCN by 0.10% and 0.06% in terms of weighted average accuracy and f1-score, respectively. And the BiERU-lc model pushes up state-of-the-art results by 0.84% and 0.41% for weighted average accuracy and f1-score, respectively. For all 14 indicators on IEMOCAP dataset, our models outperform at 7 indicators and has more balanced performances over these six classes. In particular, accuracy of "happy" of our proposed BiERUlc is higher than the result of DialgoueGCN by 14.82%. In the DialogueGCN model, the authors employ a two-layer graph convolutional network to model the interactions between speakers within a sliding window. For dyadic conversations, there are 4 different relations and context information is scattered into each relation. In this case, however, the context information is incomplete and inadequate for each relation. Besides, window size is fixed, which makes it inflexible to different scenarios. Our proposed models, to some extent, is more capable of capturing adequate context information. To sum up, the experimental results indicate that BiERU models can effectively capture the contextual information and extract rich emotion features to boost the overall performance and achieve relatively balanced results. b) AVEC: Among these four attributes, our model outperforms DialogueRNN for "valence", "arousal" and "expectancy" attributes and obtains the same results on "power" attribute. The pearson correlation coefficient r of BiERU-gc is 0.04 higher than its counterpart in terms of "arousal" (Ta-ble IV). As for the BiERU-lc model, it is 0.05 higher in r. For the attributes "expectancy" and "valence", the BiERU-lc model is 0.01 higher in r. As for the attribute"power", although our best model does not outperform the state-of-the-art method, it surpasses most of the other baseline methods including CMN and c-LSTM. Overall, the BiERU-lc model works well on all the attributes, considering the benchmark performances are very high. As mentioned in part I of section IV, AVEC is composed of conversations between human speakers and robots. Robots are not good at identifying global information and tend to respond to adjacent queries from human speakers. This is one possible reason that our BiERU-lc model has better performances than baselines and BiERU-gc since it is skilled at capturing local context information. c) MELD: Three factors make it considerably harder to model sentiment analysis on MELD in comparison with IEMOCAP and AVEC datasets. First, the average number of turns in a MELD conversation is 10 while it is close to 50 on IEMOCAP. Second, there are more than 5 speakers in most of the MELD conversations, which means most of the speakers only utter one or two utterances per conversation. What's worse, sentiment expressions rarely exist in MELD utterances and the average length of MELD utterances is much shorter than it is in IEMOCAP and AVEC datasets. For a partydependent model like DialogueRNN, it is hard to model interdependency between speakers. We find that the performances of party-ignorant models such as c-LSTM and AGHMN are slightly better than party-dependent models on this dataset. Our BiERU models utilize GNTB to perform context compositionality and achieve the state-of-the-art average accuracy of 60.9%, outperforming AGHMN by 0.6% and DialogueRNN by 4.8%.</p><p>2) Comparison between BiERU-gc and BiERU-lc: The proposed two variants take different context inputs. The BiERUgc model takes the output of GNTB at last time step and current utterance as the input of GNTB at current time step. And the BiERU-lc model uses the last utterance and current utterance as input of GNTB at current time step. According to experimental results in Tables III and IV, the overall performance of BiERU-lc is better than BiERU-gc.</p><p>For IEMOCAP datasets, the BiERU-lc model surpasses the BiERU-gc model by 0.74% and 0.45% in terms of weighted average accuracy and f1-score, respectively. For the AVEC and MELD datasets, BiERU-lc also outperforms its counterpart.</p><p>One possible explanation is that context information of a contextual utterance vector in BiERU-gc comes from all utterances in the current conversation. However, in BiERU-lc, the context information comes from neighborhood utterances. In this case, context information of BiERU-gc contains redundant information and thus has a negative impact on emotion feature extraction. D. Case Study <ref type="figure" target="#fig_5">Figure 5</ref> illustrates a conversation snippet classified by our BiERU-lc method. In this snippet, person A is initially in a frustrated state while person B acts as a listener in the beginning. Then, person A changes his/her focus and questions person B on his/her job state. Person B tries to use his/her own experience to help person A get rid of the frustrating state. This snippet reveals that the sentiment of a speaker is relatively steady and the interaction between speakers may change the sentiment of a speaker. Our BiERU-lc method shows good ability in capturing the speaker's sentiment (turns <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14)</ref> and the interaction between speakers (turn 10). The sentiment in turn 13 is very subtle. Turn 13 contains a little bit of frustration since he/she is not satisfied with his/her job state. However, considering that person B attempts to help person A, turn 13 is more likely to be in a neutral stand. Besides, we also display the prediction results of baselines including the state of the art in <ref type="figure" target="#fig_5">Fig. 5</ref>. On the one hand, both the DialogueRNN and DialogueGCN models cannot successfully model the interaction between the two speakers in this dialogue snippet. On the other hand, the two baselines are more likely to classify a few consecutive utterances into the same emotion label, which indicates that they are insensitive to the context information. In contrast, our BiERU-gc model gets better results and detects the emotion shifting from frustrated to neutral and from frustrated to neutral. However, global context may contain noise information that is not related to the current utterance, which weakens the proportion of related information and makes the BiERU-gc model less sensitive to sentiment shifting. In this case, the BiERU-lc model obtains the best results on this dialogue snippet since it is more sensitive to the context information and has a better context compositionality ability in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Visualization</head><p>We use visualization to provide some insights of the proposed model. Firstly, we visualize the confusion matrix in the form of a heat map to describe the performance of our BiERUlc model. The heat maps of BiERU-lc on the IEMOCAP dataset are shown in <ref type="figure" target="#fig_4">Fig. 4</ref>. Our model has a balanced performance over all the sentiment classes.</p><p>Secondly, we perform deeper analysis of our proposed model and DialogueRNN by visualizing the learned emotion feature representations on IEMOCAP as shown in <ref type="figure" target="#fig_6">Fig. 6a</ref> and <ref type="figure" target="#fig_6">Fig. 6b</ref>. Vectors fed into the last dense layer followed by softmax for classification are regarded as emotion feature representations of utterances. We use principal component analysis <ref type="bibr" target="#b53">[53]</ref> to reduce the dimension of emotion representations from our model (BiERU-lc) and DialogueRNN. The emotion representation is reduced to be 3-dimensional. In <ref type="figure" target="#fig_6">Fig. 6a</ref> and <ref type="figure" target="#fig_6">Fig. 6b</ref>, each color represents a predicted sentiment label and the same color means the same sentiment label. The figures show that our model outperforms on extracting emotion features of utterances labeled "happy", which is consistent with the results in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Efficiency Analysis</head><p>We analyze the efficiency of our proposed BiERU model by comparing it with two recent strong baselines. Two variants of our model, i.e., BiERU-gc and BiERU-lc, are included. We choose DialogueRNN and DialogueGCN for comparison as these two are recent competitive methods with public source code. Our proposed model has advantages over DialogueRNN, in terms of convergence capacity, the number of trainable parameters, and training time. In the comparison with Dia-logueGCN, our models take much less training time. <ref type="figure" target="#fig_7">Figure 7a</ref> shows the training curve with training and testing loss plotted. We utilize the same loss function for all the compared models. Our BiERU-lc and BiERU-gc show comparable convergence speed with their counterparts, while DialogueRNN is prone to overfitting. We also compare our model with AGHMN. The AGHMN model uses different loss function, making its loss quite different from our model, DialogueRNN and DialogueGCN. Thus, we do not include the AGHMN model in the training curve illustration.</p><p>Our BiERU-gc has fewer trainable parameters and takes less training time than DialogueRNN and DialogueGCN. Moreover, BiERU-lc with low-rank matrix approximation has further reduced trainable parameters. For 100D feature input in the IEMOCAP dataset, our model has about 0.5M  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Ablation Study</head><p>To further explore our proposed BiERU model, we perform ablation study on its two main components, i.e., GNTB and TFE. We conduct experiments on the IEMOCAP dataset with individual GNTB and TFE modules separately, and their combination, i.e., the complete BiERU. Experimental results on the IEMOCAP dataset are illustrated in <ref type="table" target="#tab_9">Table V</ref>.</p><p>The performance of sole GNTB or TFE is low in terms of accuracy and f1-score. The reason is that outputs of GNTB mainly contain context information and outputs of TFE lack context information. However, when these two modules are combined together as the BiERU model, the accuracy and f1-score increase dramatically, which proves the effectiveness of our BiERU model. More importantly, the GNTB and TFE modules couple significantly well to enhance the performance. <ref type="bibr">GNTB</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we proposed a fast, compact and parameterefficient party-ignorant framework bidirectional emotional recurrent unit (BiERU) for sentiment analysis in conversations. Our proposed generalized neural tensor block (GNTB), skilled at context compositionality, reduced the number of parameters and was suitable for different structures. Additionally, our TFE is capable of extracting high-quality emotion features for sentiment analysis. We proved that it is feasible to both simplify the model structure and improve performance simultaneously.</p><p>Our model outperforms current state-of-the-art models on three standard datasets in most cases. In addition, our method has the ability to model conversations with arbitrary turns and speakers, which we plan to study further in the future. Finally, we also plan to adopt more recent emotion categorization models, e.g., the Hourglass of Emotions, to better distinguish between similar yet different emotions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Illustration of dialogue system and the interaction between talkers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>(a) Architecture of BiERU with global context. (b) Architecture of BiERU with local context. Here p f t ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>(a) GNTB when u t ∈ R 2 . (b) TFE. The input of LSTM and CNN is context utterance vector p t , and output is emotion features e t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Heat map of confusion matrix of BiERU-lc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Illustration of a conversation snippet from IEMOCAP dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Visualization of learned emotion features via dimensionality reduction. parameters, while DialogueRNN requires around 1M. For 600D MELD dataset, DialogueRNN has 2.9M parameters, and our BiERU-lc only has 0.6M. With much fewer parameters, our model consequently trains faster than its counterpart as shown in Fig. 7b, where training time is logged in a single NVIDIA Quadro M5000. Our BiERU model with either global or local context is more parameter-efficient and less time-consuming for training. When compared with AGHMN (UniF BiAGRU CNN), our model has slightly more trainable parameters. The number of trainable parameters of AGHMN is about 0.4M in both the IEMOCAP and MELD datasets. In terms of average training time per epoch, our model (34s per epoch) costs slightly more running time than AGHMN (19s per epoch) in the IEMOCAP dataset. Moreover, we find that in the MELD dataset, the AGHMN model (93s per epoch for BiF AGRU CNN and 180s per epoch for UniF BiAGRU CNN) requires much more running time than our BiERU-lc (65s per epoch) and BiERU-gc (77s per epoch) model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :</head><label>7</label><figDesc>Training curve and time consumption logged on a single GPU using the IEMOCAP dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>).</figDesc><table><row><cell>DATASET</cell><cell>Partition</cell><cell>Utterance Count</cell><cell>Dialogue Count</cell></row><row><cell>IEMOCAP</cell><cell>train + val test</cell><cell>5810 1623</cell><cell>120 31</cell></row><row><cell>AVEC</cell><cell>train + val test</cell><cell>4368 1430</cell><cell>63 32</cell></row><row><cell>MELD</cell><cell>train + val test</cell><cell>11098 2610</cell><cell>1153 280</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Statistical information and data partition of datasets used in this paper.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>, we display the hyper-parameters of our BiERU-lc model on the three standard datasets.</figDesc><table><row><cell>DATASET</cell><cell>Dropout Rate</cell><cell>Learning Rate</cell><cell>Regularization Weight</cell></row><row><cell>IEMOCAP</cell><cell>0.8</cell><cell>0.0001</cell><cell>0.001</cell></row><row><cell>AVEC.VALENCE</cell><cell>0.5</cell><cell>0.0001</cell><cell>0.0002</cell></row><row><cell>AVEC.AROUSAL</cell><cell>0.8</cell><cell>0.0001</cell><cell>0.0002</cell></row><row><cell>AVEC.EXPECTANCY</cell><cell>0.5</cell><cell>0.00005</cell><cell>0.0005</cell></row><row><cell>AVEC.POWER</cell><cell>0.8</cell><cell>0.0001</cell><cell>0.0001</cell></row><row><cell>MELD</cell><cell>0.7</cell><cell>0.0005</cell><cell>0.001</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc></figDesc><table /><note>Hyper-parameters of our BiERU-lc model on different datasets.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III :</head><label>III</label><figDesc>Comparison with baselines on IEMOCAP and MELD datasets using textual modality. Average score of accuracy and f1-score are weighted. "-" represents no results reported in original paper.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">AVEC</cell><cell></cell></row><row><cell>METHODS</cell><cell cols="2">Valence Arousal</cell><cell cols="2">Expectancy Power</cell></row><row><cell></cell><cell>r</cell><cell>r</cell><cell>r</cell><cell>r</cell></row><row><cell>c-LSTM</cell><cell>0.16</cell><cell>0.25</cell><cell>0.24</cell><cell>0.10</cell></row><row><cell>CMN</cell><cell>0.23</cell><cell>0.29</cell><cell>0.26</cell><cell>-0.02</cell></row><row><cell>DialogueRNN</cell><cell>0.35</cell><cell>0.59</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>BiERU-gc</cell><cell>0.30</cell><cell>0.63</cell><cell>0.36</cell><cell>0.36</cell></row><row><cell>BiERU-lc</cell><cell>0.36</cell><cell>0.64</cell><cell>0.38</cell><cell>0.37</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV :</head><label>IV</label><figDesc>Comparison with baselines on AVEC dataset using textual modality. r stands for Pearson correlation coefficient. We firstly compare our proposed BiERU with state-of-the-art methods Dia-logueGCN, DialogueRNN and AGHMN on IEMOCAP, AVEC and MELD, respectively.</figDesc><table /><note>1) Comparison with the State of the Art:a) IEMOCAP: As shown in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 .</head><label>2</label><figDesc>In detail, neutral is an intermediate emotion and every other emotion can smoothly transfer into neutral and vice versa. Therefore, in both our BiERU model and DialogueRNN model, neutral has more overlapping regions compared with other emotions. Compared with DialogueRNN, our model distinguishes happy &amp; excited, frustrated &amp; angry more clearly. Therefore, our model has the ability to learn better emotion features to some extent.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE V :</head><label>V</label><figDesc>Results of ablated BiERU on the IEMOCAP dataset. Accuracy and F1-score are weighted average.</figDesc><table><row><cell></cell><cell>16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>15</cell><cell></cell><cell></cell><cell cols="3">DialogueRNN train DialogueGCN train</cell><cell></cell><cell cols="2">DialogueRNN test DialogueGCN test</cell></row><row><cell></cell><cell>14</cell><cell></cell><cell></cell><cell cols="2">BiERU-lctrain BiERU-gc train</cell><cell></cell><cell></cell><cell cols="2">BiERU-lctest BiERU-gc test</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">UniF BiAGRU CNNtrain</cell><cell cols="3">UniF BiAGRU CNNtest</cell></row><row><cell></cell><cell>13</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>12</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>11</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Loss</cell><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell cols="2">0</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12</cell><cell>14</cell><cell>16</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Epochs</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(a) Training curve</cell><cell></cell></row><row><cell></cell><cell cols="2">120</cell><cell></cell><cell></cell><cell></cell><cell cols="2">DialogueGCN</cell><cell></cell><cell cols="2">BiERU-lc</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">DialogueRNN</cell><cell></cell><cell cols="2">BiERU-gc</cell></row><row><cell>Time Consumption (s)</cell><cell cols="2">40 60 80 100</cell><cell></cell><cell></cell><cell></cell><cell cols="3">UniF BiAGRU CNN</cell><cell></cell></row><row><cell></cell><cell cols="2">20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">0</cell><cell>0</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12</cell><cell>14</cell><cell>16</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Epochs</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) Time consumption</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Extracted features of two datasets are available at https://github.com/ senticnet/conv-emotion.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This research is supported by the Agency for Science, Technology and Research (A*STAR) under its AME Programmatic Funding Scheme (Project #A18A2b0046).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on empathetic dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="50" to="70" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DialogueRNN: An attentive rnn for emotion detection in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6818" to="6825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Real-time emotion recognition via attention gated hierarchical memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09075</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-dependent sentiment analysis in user-generated videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="873" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Conversational memory network for emotion recognition in dyadic dialogue videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.11540</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1388" to="1429" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">An invitation to cognitive science: Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Partee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="311" to="360" />
		</imprint>
	</monogr>
	<note>Lexical semantics and compositionality</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Guest editorial: Big social data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SenticNet 6: Ensemble application of symbolic and subsymbolic AI for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pincus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image polarity detection on resource-constrained devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ragusa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gianoglio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zunino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gastaldo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="50" to="57" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cross-lingual sentiment quantification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moreo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="106" to="114" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Aspect-based extraction and analysis of affective knowledge from social media streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weichselbraun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gindl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vakulenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Scharl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="80" to="88" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lexicon generation for emotion analysis from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bandhakavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wiratunga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Massie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Deepak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="102" to="108" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Instance-based domain adaptation via multiclustering logistic approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="88" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">No, that never happened!! investigating rumors on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="8" to="15" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Supervised learning for fake news detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Correia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Murai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veloso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="76" to="81" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What men say, what women hear: Finding gender-specific meaning shades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garimella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="62" to="67" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Type like a man! inferring gender from keystroke dynamics in live-chats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bukeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roffo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vinciarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Segment-level joint topic-sentiment model for online review analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="50" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Detecting personal intake of medicine from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="87" to="95" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multitask representation learning for multimodal estimation of depression level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasanuzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="45" to="52" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Challenges of sentiment analysis for dynamic events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hossein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="70" to="75" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sentiment analysis in tripadvisor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Valdivia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Luzon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="72" to="77" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Crowd intelligence: Conducting asymmetric impact-performance analysis based on online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-P</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="92" to="98" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Commonsense knowledge enhanced memory network for stance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="102" to="109" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning from personal longitudinal dialog data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Perez-Rosas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="16" to="23" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Intent classification for dialogue utterances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Frasincar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Attention-based modeling for emotion detection and classification in textual conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ragheb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Azé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bringay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07020</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">ICON: Interactive conversational memory network for multimodal emotion detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2594" to="2604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Cosmic: Commonsense knowledge for emotion identification in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02795</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Capturing emotion distribution for multimedia emotion tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Knowledge-enriched transformer for emotion detection in textual conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019</title>
		<meeting>the 2019</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<title level="m">Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dcr-net: A deep cointeractive relation network for joint dialog act recognition and sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8665" to="8672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">IEMOCAP: Interactive emotional dyadic motion capture database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language resources and evaluation</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">335</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">User reviews: Sentiment analysis using lexicon integrated two-channel cnn-lstm family models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page">106435</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">AVEC 2012: the continuous audio/visual emotion challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Valster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM international conference on Multimodal interaction</title>
		<meeting>the 14th ACM international conference on Multimodal interaction</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="449" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">MELD: A multimodal multi-party dataset for emotion recognition in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The semaine database: Annotated multimodal records of emotionally colored conversations between a person and a limited agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Valstar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schroder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="17" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Esbensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Geladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics and intelligent laboratory systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="37" to="52" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
