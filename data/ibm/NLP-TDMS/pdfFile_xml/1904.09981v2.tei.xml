<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GraphNAS: Graph Neural Architecture Search with Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yang</surname></persName>
							<email>hong.yang@student.uts.edu.au</email>
							<affiliation key="aff2">
								<orgName type="department">Centre for Artificial Intelligence</orgName>
								<orgName type="institution">University of Technology Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
							<email>zhangpeng04@gmail.com</email>
							<affiliation key="aff3">
								<orgName type="laboratory">Ant Financial Services Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Hu</surname></persName>
							<email>huyue@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GraphNAS: Graph Neural Architecture Search with Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Neural Networks (GNNs) have been popularly used for analyzing non-Euclidean data such as social network data and biological data. Despite their success, the design of graph neural networks requires a lot of manual work and domain knowledge. In this paper, we propose a Graph Neural Architecture Search method (GraphNAS for short) that enables automatic search of the best graph neural architecture based on reinforcement learning. Specifically, GraphNAS first uses a recurrent network to generate variable-length strings that describe the architectures of graph neural networks, and then trains the recurrent network with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation data set. Extensive experimental results on node classification tasks in both transductive and inductive learning settings demonstrate that Graph-NAS can achieve consistently better performance on the Cora, Citeseer, Pubmed citation network, and protein-protein interaction network. On node classification tasks, GraphNAS can design a novel network architecture that rivals the best humaninvented architecture in terms of test set accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph Neural Networks (GNNs) have been popularly used for analyzing graph data such as social network data and biological data. The basic idea of GNNs such as GraphSAGE <ref type="bibr" target="#b2">[Hamilton et al., 2017]</ref> is to propagate feature information between neighboring nodes so that nodes can learn feature representations by using locally connected graph structure information.</p><p>Although GNNs have achieved great success, one shorting is to tune many parameters of the graph neural architectures. Similar to CNNs that contain many manually setting parameters such as the sizes of filters, the types of pooling layers and residual connections, tuning the parameters of GNNs generally takes heavy manual work which requires domain knowledge as well.</p><p>Recently we observe that reinforcement learning has been successfully used to generate accurate neural architectures for CNNs and RNNs. The seminar work NAS ] uses a recurrent network as controller to generate CNN and RNN network descriptions (which are referred to as child networks), and then uses the validation results of the child networks as feedback of the controller to maximize the expected accuracy of the generated architectures of the CNNs and RNNs. According to the experimental reports, the NAS search algorithm can improve CNNs and RNNs on benchmark data by percentage of 0.09 on the CIFAR-10 data and 3.6 perplexity on the Penn Treebank data. Inspired by NAS, a large body of advanced neural architecture search algorithms based on reinforcement learning have been proposed to improve its efficient and accuracy, such as the Efficient neural architecture search algorithm <ref type="bibr">(ENAS [Pham et al., 2018]</ref>) and Stochastic Neural Architecture Search algorithm (SNAS) <ref type="bibr" target="#b8">[Xie et al., 2018]</ref>.</p><p>The promising results of using NAS to search neural architectures for CNNs and RNNs motivate us to use reinforcement learning to search graph neural architectures in this work. Our idea is similar to NAS for CNNs and RNNs that first uses a recurrent network as controller to generate the descriptions of GNNs and then compute the rewards of the GNNs as feedback of the controller to maximize the expected accuracy of the generated architectures of the GNNs. However, when using NAS for graph neural architecture search, the following new challenges need to be addressed:</p><p>• Challenge 1. How to design the search space of GNNs. Different from CNNs for processing regular grid-structural inputs, GNNs for processing graph data that are non-Euclidean and irregularly distributed in a feature space generally contain both spatial and convolutional descriptions <ref type="bibr" target="#b2">[Hamilton et al., 2017]</ref> and GCN <ref type="bibr" target="#b3">[Kipf and Welling, 2017]</ref> .</p><p>• Challenge 2. How to design an efficient reinforcement learning search algorithm. The search space of GNNs are generally very large. When generating the descriptions for GNNs by the controller, the training of reinforcement learning converges slowly. • Challenge 3. How to evaluate the performance of the algorithm in both transductive and inductive learning settings is the third challenge.</p><p>In this paper, we present an efficient Graph Neural Architecture Search algorithm GraphNAS that can automatically generate neural architecture for GNNs by using reinforcement learning. To solve Challenge 1, GraphNAS designs a search space covering sampling functions, aggregation functions and gated functions. To solve Challenge 2, Graph-NAS uses a new parameters sharing and architecture search algorithm that is more efficient than NAS for CNNs and RNNs. To solve Challenge 3, we validate the performance of GraphNAS on node classification tasks in both transductive and inductive learning settings. The results demonstrate that GraphNAS can achieve consistently better performance on the Cora, Citeseer, Pubmed citation network, and proteinprotein network. The contribution of the paper is fourfolder:</p><p>• We first study the problem of using reinforcement learning to search graph neural architectures, which has the potential to save a lot of manual work for designing graph neural architectures. Graph Neural Networks. The notation of graph neural networks was firstly outlined in the work <ref type="bibr" target="#b2">[Gori et al., 2005]</ref>. Inspired by the convolutional networks in computer vision, a large number of methods that re-define the notation of convolution filter for graph data have been proposed recently. convolution filters for graph data fall into two categories, spectral-based and spatial-based.</p><p>As spectral methods usually handle the whole graph simultaneously and are difficult to parallel or scale to large graphs, spatial-based graph convolutional networks have rapidly <ref type="bibr">developed recently [Hamilton et al., 2017;</ref><ref type="bibr">Monti et al., 2017;</ref><ref type="bibr" target="#b6">Niepert et al., 2016;</ref><ref type="bibr" target="#b2">Gao et al., 2018;</ref><ref type="bibr" target="#b7">Velickovic et al., 2017]</ref>. These methods directly perform the convolution in the graph domain by aggregating the neighbor nodes' information. Together with sampling strategies, the computation can be performed in a batch of nodes instead of the whole graph <ref type="bibr" target="#b2">[Hamilton et al., 2017;</ref><ref type="bibr" target="#b2">Gao et al., 2018]</ref>.</p><p>Recent graph neural architectures follow the neighborhood aggregation scheme that consists of three types of functions, i.e., neighbor sampling, correlation measurement, and information aggregation. Each layer of GNNs includes the combination of the three types of functions. For example, each layer of semi-GCN <ref type="bibr" target="#b3">[Kipf and Welling, 2017]</ref> consists of the firstorder neighbor sampling, correlation measured by node's degree and the aggregate function.</p><p>In this paper, we use reinforcement learning to search the best combination of these types of functions on each layer of GNNs, instead of manual settings in the previous work.</p><p>Neural architecture search. Neural architecture search (NAS) has been popularly used to design convolutional architectures for classification tasks with image and text streaming as input <ref type="bibr" target="#b6">Pham et al., 2018;</ref><ref type="bibr" target="#b8">Xie et al., 2018;</ref><ref type="bibr" target="#b1">Bello et al., 2017]</ref>.</p><p>The seminal work of using reinforcement learning for neural architecture search aims to automatically design deep neural architecture by using a recurrent network to generate structure description of CNNs and RNNs. Following the NAS, Evolution-based NAS such as work in <ref type="bibr" target="#b7">[Real et al., 2017;</ref><ref type="bibr" target="#b7">Real et al., 2018]</ref> employs evolution algorithm to simultaneously optimize topology alongside with parameters. However, evolution-based methods take enormous computational time and could not leverage the efficient gradient backpropagation. To achieve the state-of-the-art performance as human-designed architectures, the work <ref type="bibr" target="#b7">[Real et al., 2018]</ref> takes 3150 GPU days for the whole evolution.</p><p>In comparison, the work ENAS <ref type="bibr" target="#b6">[Pham et al., 2018]</ref> is endto-end for gradient back-propagation. To get rid of the architecture sampling process, DARTS <ref type="bibr" target="#b4">[Liu et al., 2018a]</ref> replace the feedback triggered by constant rewards in reinforcement learning with more efficient gradient feedback from generic loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>In this section, we first introduce the problem of searching graph neural architectures with reinforcement learning. Then, we establish the search space and we discuss an efficient search algorithm based on policy gradient descent and the parameter sharing method during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem formulation</head><p>Given the search space of a graph neural architecture M, we aim to find the best architecture m * ∈ M that maximizes the accuracy R of the network on a validation set D. Here we use reinforcement learning to obtain m * by sampling from feasible architectures in the space M based on the rewards R observed on D. <ref type="figure">Figure 1</ref> shows the entire reinforcement learning framework. First, the recurrent network generates network descriptions of GNNs. Then, the generated GNNs are tested on the given validate set D and the test results are used as feedback of the recurrent network. The iteration maximizes the expected accuracy of the generated GNNs on the set D.</p><p>Formally, during the learning process, the recurrent network as the controller maximizes the expected accuracy E P (m;θ) [R(m(w * , G))] on the validation set D, where P (m; θ) is the distribution of m parameterized by the choice of controller θ, and the shared weights w * describing the architecture. The learning is to minimize the training loss L train (m(w, G)) which can be represented as a bi-level optimization problem listed below,</p><formula xml:id="formula_0">maxw E[R(m(w * , G)))]</formula><p>s.t. : w * = argminw Ltrain(m(w, G)).</p><p>(1)</p><p>Layer 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>First-order gat Sum</head><p>Layer 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean</head><p>Layer <ref type="formula">3</ref> Layer 1 First-Order Sampler Gat Attention Sum Aggregator Layer 3 <ref type="figure">Figure 1</ref>: A simple illustration of GraphNAS. A recurrent network (the upper part) generates descriptions of graph neural architectures (the lower part), and then the validation results of the generated GNNs are used as feedback of the recurrent network (the upper part) to maximize the expected accuracy of the generated graph neural architecture (the lower part). The actions showed in current picture is not complete. All actions are described in Section 3.2 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>First-order</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention</head><p>Formula const e con ij = 1 gcn</p><formula xml:id="formula_1">e gcn ij = 1/ d i d j gat e gat ij = leaky relu((W l * h i + W r * h j )) sym-gat e sym ij = e gat ji + e gat ij cos e cos ij =&lt; W l * h i , W r * h j &gt; linear e lin ij = tanh(sum(W l * h j )) gene-linear e gat ij = W a * tanh(W l * h i + W r * h j )</formula><p>The training process of Eq.</p><p>(1) will be discussed in the remaining parts of this section. The goal of GraphNAS is to find m * that maximizes the expected validation accuracy E[R(m(G))].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Search Space</head><p>In GraphNAS, we use a controller network to generate the descriptions of GNNs. The controller network used in Graph-NAS is implemented as a recurrent neural network which requires a state space. In order to define the search space, we introduce a generalized framework of GNNs, where each layer can be described as follows,  <ref type="bibr" target="#b9">[Xu et al., 2018]</ref>. For each layer, one of the aggregation functions AGG is required. 5. Residual functions. Merge historical hidden representation H his as a part of the current embedding after a transform function. The merge function includes concatenation and adding. For each layer of GNNs, a previous layer's index I and the activation function ACT of the current layer are required to build a residual layer. 6. Gated functions. As in GeniePath <ref type="bibr" target="#b5">[Liu et al., 2018b]</ref>, the attention procedure learns the importance of neighbors with different sizes. Gated procedure extracts and filters signals aggregated from neighbors of distant hops. To sum up, we define the search space of GNNs M as follows: the sampling dimension SAM , the correlation measure dimension AT T , the aggregation dimension AGG, the numbers of multi-heads K, the output hidden embedding DIM, the previous layers' index I and the activation function ACT . As a result, GraphNAS can generate the architecture descriptions as a sequence of tokens. Each token represents one of the functions in the architecture space M.</p><p>Note that we do not predict training parameters such as the learning rates of GNNs and we also assume that the architectures without gated procedures bring large computation and improvement during the initial stage of training. It is possible to add those actions as one of the predictions. In our experiments, the process of generating an architecture stops if the number of layers exceeds a preset value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Search Algorithm</head><p>Training the controller parameters θ. In order to maximize the objective function given in Eq.(1), we describe a policy gradient method to update parameters θ so that the controller network generates better architectures over time.</p><p>The architecture descriptions (hyperparameters) of GNNs that the controller predicts can be viewed as a list of actions m 1:T . GNNs will achieve an accuracy of m(w, G) on a heldout dataset at convergence. We use the accuracy R as reward signal and use reinforcement learning to train the controller. Since the reward signal R is non-differentiable, we use a policy gradient method to iteratively update θ with a moving av-  <ref type="table" target="#tab_1">Table 1</ref> aggregation type "sum", "mean-pooling", "max pooling", "mlp" activation type "sigmoid", "tanh", "relu", "linear", "softplus", "leaky relu", "relu6", "elu" number of heads <ref type="bibr">1,2,4,6,8,16 hidden units 4, 8, 16, 32, 64, 128,256</ref> erage baseline for reward to reduce variance <ref type="bibr" target="#b8">[Williams, 1992]</ref> as follows,</p><formula xml:id="formula_2">∇ θ E P (m 1:T ;θ) [R(m(w, G))] (2) · = T t=1 E P (m 1:T ;θ) [∇ θ logP (mt|mt−1:1; θ)R(m(w, G))]</formula><p>Training the shared parameters w. In this step, we use stochastic gradient descent (SGD) with respect to w to minimize the training loss L train , where L train is the standard cross-entropy loss in node classification, obtained from a minibatch of training data with a model m sampled by the controller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Parameters Sharing</head><p>In most previous neural architecture search algorithms, generated models are trained from the scratch. However, training models from scratch to convergence brings heavy computation. Recently, ENAS <ref type="bibr" target="#b6">[Pham et al., 2018]</ref> forces all child models to share weights in order to improve the efficiency. Similarly, we introduce parameters sharing for GraphNAS.</p><p>Parameters sharing in ENAS are without conditions, ignoring the performance of the child models. This strategy does not suit for GNNs. As we found in experiments, parameters sharing between different GNNs does not work immediately, but can be observed after several iterations. Therefore we use a new strategy to share weights between different GNNs.</p><p>Sharing strategy. <ref type="figure" target="#fig_0">Figure 2</ref> shows the parameters from one layer. Solid arrows represent the transform weights in GNNs which are shared between different GNNs including W T , W l , W l and W res . However, GNNs constraints search dimensions such as the attention and aggregation dimensions. For instance, W l , W r listed in <ref type="table" target="#tab_1">Table 1</ref> are used to form correlation measures for the attention functions. In GraphNAS, we allow different GNNs sharing the transform weights. Parameters are only shared for specific combinations of attention and aggregation functions Update strategy. The parameters w are trained and updated during training child models. The parameter update is also different from ENAS. Parameters shared by GNNs stored in the form of dictionary. When training, GNNs obtain a copy of shared parameters. After training, the parameters of the current child model are merged into the shared parameters w when the reward is positive.</p><p>Reward generation. In ENAS <ref type="bibr" target="#b6">[Pham et al., 2018]</ref>, the reward is generated according to the shared parameters without training child models. Since there may be parameters untrained, the strategy may cause deviation during reward generation. In GraphNAS, we train the child models with shared parameters to obtain more precise reward. After then, we apply a moving average on rewards to generate the final reward. Exploration for shared parameters. Models with updated sharing parameters generally have large reward. Therefore, the controller has the potential to choose structures appearing at the beginning. In order to avoid this bias, we allow the GraphNAS to do exploration. During exploration, the parameters θ of the controller are fixed, while the shared parameters w are trained with novel structures.</p><p>Deriving architectures. We derive novel architectures from a trained GraphNAS model. We first sample several models under the distribution of P (m, θ). For each sampled model, we compute its reward on a single minibatch sampled from the validation set after a few iterations. We then take only the model with the highest reward to re-train from scratch. It is possible to improve the results by training all the sampled models from scratch and select the model with the highest accuracy on a separated validation set .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We test the performance of GraphNAS on both transductive and inductive learning scenarios. We use citation networks including Cora, Citeseer, and Pubmed for the transductive learning, and PPI for the inductive learning. On each dataset, we have a separated held-out validation set used to generate reward to compute the reward signal. The reported performance on the test set is computed only once for the network that achieves the best result on the held-out validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Transductive Learning Task We classify academic papers into different subjects using the Cora, Citeseer and Pubmed datasets. The data obtained from semi-GCN <ref type="bibr" target="#b3">[Kipf and Welling, 2017]</ref> has been preprocessed. We follow the same setting used in semi-GCN that allows 20 nodes per class for training, 500 nodes for validation and 1,000 nodes for testing.</p><p>Inductive Learning Task We use the protein-protein interaction (PPI) dataset, which contains 20 graphs for training, two graphs for validation, and two graphs for testing. Since the graphs for validation and testing are separated, the training process does not use them. There are 2,372 nodes in each graph on average. Each node has 50 features including positional, motif genes and signatures. Each node has multiple labels from 121 classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Methods</head><p>In order to evaluate the GNNs searched by GraphNAS, we choose the state-of-the-art GNNs for comparisons,</p><p>• Chebyshev <ref type="bibr" target="#b1">[Defferrard et al., 2016]</ref>. The method approximates the graph spectral convolutions by a truncated expansion in terms of Chebyshev polynomials up to T-th order. This method needs the graph Laplacian in advance, so that it only works in the transductive setting.</p><p>• Semi-GCN <ref type="bibr" target="#b3">[Kipf and Welling, 2017]</ref> is the same as Chebyshev, it works only in the transductive setting.</p><p>• GraphSAGE <ref type="bibr" target="#b2">[Hamilton et al., 2017]</ref> consists of a group of inductive graph representations with different aggregation functions. The GCN-mean with residual connections is equivalent to GraphSAGE using mean pooling.</p><p>• <ref type="bibr">GAT [Velickovic et al., 2017]</ref> introduces attention into GNN. Therefore, GAT archives good results in both transductive and inductive learning.</p><p>• LGCN <ref type="bibr" target="#b2">[Gao et al., 2018]</ref> enables regular convolutional operations on generic graphs which archives good results in both transductive and inductive learning.</p><p>All the tasks in transductive learning are single-label classification. We use accuracy as the measure for comparison. On the other hand, tasks in transductive learning are multi-label classification, and we use F1 score as the measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Architecture on Transductive learning</head><p>Search space.</p><p>Our search space consists of the functions listed in Section 3.2.</p><p>For each layer of GNNs, the controller has to sample actions m ∈ DIM, SAM, AT T , K, AGG, ACT which do not contain previous layer index I for skip connection. In experiments on the citation dataset, there are usually two layers for GNNs.</p><p>Training details. The controller is a one-layer LSTM with 100 hidden units. It is trained with the ADAM optimizer [Kingma and Ba, 2015] with a learning rate of 0.0035. The weights of the controller are initialized uniformly between -0.1 and 0.1. To prevent premature convergence, we also use a tanh of 2.5 and a temperature of 5.0 for the sampling logits <ref type="bibr" target="#b1">[Bello et al., 2017;</ref>, and add the controller's sample entropy to the reward, weighted by 0.0001.</p><p>Once the controller samples an architecture, a child model is constructed and trained for 200 epochs without parameter sharing. During training, we apply L2 regularization with λ = 0.0005 for Cora and Citeseer. Furthermore, dropout with p = 0.6 is applied to both layers' inputs, as well as to the normalized attention coefficients. For Pubmed, we set L2 regularization to λ = 0.001.</p><p>In all experiments, child models are initialized using the Glorot initialization <ref type="bibr" target="#b2">[Glorot and Bengio, 2010]</ref> and trained to minimize cross-entropy loss on the training nodes using the Adam SGD optimizer <ref type="bibr" target="#b2">[Kingma and Ba, 2015]</ref> with an initial learning rate of 0.01 for Pubmed, and 0.005 for all the  other datasets. In both cases we use an early stopping strategy according to the cross-entropy loss and accuracy on the validation nodes, with a patience of 100 epochs. During training the controller, we fix the number of child network layers to be two, because many GNNs obtain the best performance on these dataset with two layers. Besides, we do not force GNNs sharing parameters, because training GNNs to convergence are fast on these datasets and models are easy to over-fitting in a semi-supervision task.</p><p>Results. After the controller trains 1,000 architectures, we collect the top 5 architectures that achieve the best validation accuracy. Then, we compute the test accuracy and time for each epoch of such models and summarize their results in Table 3. The time reported here is the training time for running one epoch using a single 1080Ti GPU. As can be seen from the table, GraphNAS can design several promising architectures that perform as well as some of the best models on this dataset. Other experiments results on citation network are listed in <ref type="table" target="#tab_5">Table 4</ref>.</p><p>Random Search. Besides reinforcement learning, one can use random search to find the network. Although this baseline seems simple, it is often very hard to surpass. We report the number of GNNs model which has accuracy over 0.81 on validation set during search in <ref type="figure" target="#fig_1">Figure 3</ref>. And we list the best structure found by random search in Table3. The results show that GraphNAS trends to find better GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Architecture on Inductive Learning</head><p>Search space. We use the full search space defined in Section 3.2 . For skip-connection, we perform two sets of experi-  <ref type="figure">Figure 4</ref>: F1 score of the best GNNs on the ppi validation set during GraphNAS search. Blue is the best, Green is the average of top 5, Red is the average of top 10, Black is the best search in 600 structures which appears at the search 500 th . ments, where one fixes the input of residual layer with output of the last hidden layer and the other allows the controller to predict previous layer index to build skip-connection. Training details. The setting of training and the controller are the same as in transductive learning. We use parameter sharing to solve the huge computational resource requirements. The shared parameters of the child models are trained using the Adam SGD optimizer with a learning rate of 0.005. Before training the controller, the exploration process is executed at the first 20 epochs. After that the controller is trained for 50 epochs. During training of the child model, we apply no L2 regularization and dropout. During the process, each GNN model sampled by the controller is trained for five epochs with shared parameters.</p><p>During the training of the controller, we fix the number of child networks layers at three, because most GNNs obtain the best performance on this dataset are with three layers.</p><p>Results. After the controller trained for 1,000 time, we let the controller to output the best model from 200 sampled GNNs. And we then compute the micro-f1 score and the time for each epoch of the model and summarize the results in Table 5. The time reported here is the training time for running one epoch using a single 1080Ti GPU. As can be seen from the table, GraphNAS can design several promising architectures that perform as well as the best models on this dataset.</p><p>Effectiveness of parameters sharing. To evaluate the effectiveness of parameter sharing strategy during search, we  Comparison against Search strategy. We compare GraphNAS with other search strategies including random search, reinforcement learning without parameter sharing (NAS-like), and GraphNAS without iterations of GNNs during training the controller (ENAS-like). Each sampled GNN is trained for two epochs. We show the model's validation F1-score during training in <ref type="figure" target="#fig_2">Figure 5</ref>. The performance of the found best model are listed in Table5. The results show that GraphNAS trends to find a better GNN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we study a new problem of graph neural architecture search with reinforcement learning. We present a GraphNAS algorithm that can design accurate graph neural network architectures that rival the best human-invented architectures in terms of test set accuracy. Experiments on node classification tasks in both transductive and inductive learning settings demonstrate that GraphNAS can achieve consistently better performance on citation networks, and protein-protein interaction network. Comparisons with existing search strategies show that the new parameters sharing and search strategy used in GraphNAS are effective.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Parameters of each layer in GNNs. Circles represent hidden embeddings in each layer. Solid arrows represent the transform operation with parameters, dotted arrows indicate operations with no parameters, and hollow arrows with text represent the remaining functions such as Att for AT T , Agg for AGG).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The number of GNNs whose accuracy over 0.81 on the validation set during search. Red line stands for GraphNAS, blue line stands for random search. GraphNAS outperforms random search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>GraphNAS compares with random search, NAS-like GraphNAS, and ENAS-like GraphNAS on ppi dataset. GrpahNAS has the best F1 score. compare the F1 score of the best structure designed by Graph-NAS with parameters sharing and trained from scratch in Figure 4. Both of them are trained for five epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Attention functions</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>1 .</head><label>1</label><figDesc>Feature transform functions. The hidden embedding H i−1 (H 0 represents the initial input) is multiplied by a weight matrix W T , which is used to extract features and reduce feature dimensions. For each layer of GNNs, the output dimension DIM is required. 2. Sampling functions. Select the receptive field N (v) for a given target node. Many GNNs samples the first-order neighbors iteratively and collect messages globally. GraphSAGE and PinSAGE sample a fixed size neighbor to speed up for large graphs. FastGCN uses importance sampling while maintaining the performance of the algorithm. LGCN sorts the first-order neighbors' features and selects top-k features. For each layer, one of the sampling methods SAM is required. 3. Correlation measure functions. Calculate the correlation of node v with its neighbors N (v). GAT assigns neighborhood importance by using attention layers. Semi-GCN assigns neighborhood importance according to the degree of nodes. More choices are listed in Table 1. For each layer, we choose one correlation measurement method AT T and repeat times K. 4. Aggregation functions. Aggregate data from neighbors to generate an embedding for each node v. Most GNNs use the sum aggregator, Mean aggregator, LSTM aggregator and pooling aggregator. MLP aggregator are described in the work</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Action operators in search space</figDesc><table><row><cell>action</cell><cell>operators</cell></row><row><cell>sample method</cell><cell>"first-order"</cell></row><row><cell>attention type</cell><cell>listed in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance of GraphNAS and the state-of-the-art on Cora.</figDesc><table><row><cell>Models</cell><cell cols="4">Depth Params Time(s) Accuracy</cell></row><row><cell cols="2">Chebyshev 2</cell><cell>92K</cell><cell>0.49</cell><cell>81.2%</cell></row><row><cell>GCN</cell><cell>2</cell><cell>23K</cell><cell>0.08</cell><cell>81.5%</cell></row><row><cell>GAT</cell><cell>2</cell><cell>237K</cell><cell>0.62</cell><cell>83.0±0.7%</cell></row><row><cell>LGCN</cell><cell>2</cell><cell>56K</cell><cell>0.14</cell><cell>83.3±0.5%</cell></row><row><cell>random</cell><cell>2</cell><cell>364K</cell><cell>1.29</cell><cell>82.0±0.6%</cell></row><row><cell cols="2">GraphNAS 2</cell><cell>188K</cell><cell>0.13</cell><cell>84.2±1.0%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance of GraphNAS and the state-of-the-art models on Citeseer and Pubmed in term of accuracy.</figDesc><table><row><cell cols="2">Models</cell><cell cols="2">Citeseer</cell><cell>Pubmed</cell><cell></cell></row><row><cell cols="3">Chebyshev 69.8%</cell><cell></cell><cell>74.4%</cell><cell></cell></row><row><cell cols="2">GCN</cell><cell>70.3%</cell><cell></cell><cell>79.0%</cell><cell></cell></row><row><cell cols="2">GAT</cell><cell cols="4">72.5±0.7% 79.0±0.3%</cell></row><row><cell cols="2">LGCN</cell><cell cols="4">73.0±0.6% 79.5±0.2%</cell></row><row><cell cols="6">GraphNAS 73.1±0.9% 79.6±0.4%</cell></row><row><cell></cell><cell>0.725</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.700</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.675</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f1 score</cell><cell>0.625 0.650</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.600</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>top 1</cell></row><row><cell></cell><cell>0.575</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>top 5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>top 10</cell></row><row><cell></cell><cell>0.550</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>the best</cell></row><row><cell></cell><cell>0</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell>500</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Epoch of Search</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Performance of GraphNAS and the state-of-the-art on PPI.</figDesc><table><row><cell cols="2">Models</cell><cell></cell><cell cols="4">Depth Params micro-F1(%)</cell></row><row><cell cols="4">GraphSAGE(lstm) 2</cell><cell cols="2">0.26M 61.2</cell></row><row><cell cols="2">GeniePath</cell><cell></cell><cell>3</cell><cell cols="2">1.81M 97.9</cell></row><row><cell cols="2">GAT</cell><cell></cell><cell>3</cell><cell cols="3">3.64M 97.3±0.2</cell></row><row><cell cols="2">LGCN</cell><cell></cell><cell>-</cell><cell>-</cell><cell cols="2">77.2±0.2</cell></row><row><cell cols="4">GraphNAS( no sc) 3</cell><cell cols="3">3.95M 98.6±0.1</cell></row><row><cell cols="4">GraphNAS with sc 3</cell><cell cols="3">2.11M 97.7±0.2</cell></row><row><cell cols="3">NAS-like search</cell><cell>3</cell><cell cols="3">0.95M 95.7±0.2</cell></row><row><cell cols="3">ENAS-like search</cell><cell>3</cell><cell cols="3">1.38M 96.5±0.2</cell></row><row><cell></cell><cell>0.625</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.600</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.575</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f1 score</cell><cell>0.525 0.550</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.500</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.475</cell><cell></cell><cell></cell><cell></cell><cell cols="2">GraphNAS</cell></row><row><cell></cell><cell>0.450</cell><cell></cell><cell></cell><cell></cell><cell cols="2">NAS-like Random</cell></row><row><cell></cell><cell>0.425</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ENAS-like</cell></row><row><cell></cell><cell>0</cell><cell>25</cell><cell>50</cell><cell>75 Epoch of Search 100 125</cell><cell>150</cell><cell>175</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural combinatorial optimization with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bello</surname></persName>
		</author>
		<idno>abs/1611.09940</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering</title>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>NIPS</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks</title>
		<meeting><address><addrLine>Ba</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>NIPS. Adam: A method for stochastic optimization. CoRR, abs/1412.6980</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<idno>abs/1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search. CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<idno>abs/1802.00910</idno>
		<title level="m">Graph neural networks with adaptive receptive paths. CoRR</title>
		<meeting><address><addrLine>Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodolà</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niepert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geometric deep learning on graphs and manifolds using mixture model cnns. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<editor>Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov</editor>
		<meeting><address><addrLine>Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Quoc V</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5425" to="5434" />
		</imprint>
	</monogr>
	<note>ICML. Real et al.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<idno>abs/1802.01548</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Large-scale evolution of image classifiers. Graph attention networks. CoRR, abs/1710.10903</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams ; Xie</surname></persName>
		</author>
		<idno>abs/1812.09926</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<publisher>CoRR</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
	<note>Snas: Stochastic neural architecture search</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks?</title>
		<idno>abs/1810.00826</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1611.01578</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
