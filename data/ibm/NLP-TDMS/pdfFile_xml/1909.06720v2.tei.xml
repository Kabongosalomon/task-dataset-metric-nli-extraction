<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Vu</surname></persName>
							<email>thangvubk@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjun</forename><surname>Jang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><forename type="middle">X</forename><surname>Pham</surname></persName>
							<email>trungpx@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
							<email>cd_yoo@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN) for improving the region-proposal quality and detection performance by systematically addressing the limitation of the conventional RPN that heuristically defines the anchors and aligns the features to the anchors. First, instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a single anchor per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second, to attain alignment between the features and the anchors throughout the stages, adaptive convolution is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points higher than that of the conventional RPN, surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively. The code is made publicly available at https://github.com/thangvubk/Cascade-RPN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Object detection has received considerable attention in recent years for its applications in autonomous driving <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17]</ref>, robotics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref> and surveillance <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b22">23]</ref>. Given an image, object detectors aim to detect known object instances, each of which is assigned to a bounding box and a class label. Recent high-performing object detectors, such as Faster R-CNN [34], formulate the detection problem as a two-stage pipeline. At the first stage, a region proposal network (RPN) produces a sparse set of proposal boxes by refining and pruning a set of anchors, and at the second stage, a region-wise CNN detector (R-CNN) refines and classifies the proposals produced by RPN. Compared to R-CNN, RPN has received relatively less attention for improving its performance. This paper will focus on improving RPN by addressing its limitations that arise from heuristically defining the anchors and heuristically aligning the features to the anchors. An anchor is defined by its scale and aspect ratio, and a set of anchors with different scales and aspect ratios are required to obtain a sufficient number of positive samples that have high overlap with the target objects. Setting appropriate scales and aspect ratios is important in achieving high detection performance, and it requires a fair amount of tuning <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>An alignment rule is "implicitly" defined to set up a correspondence between the image features and the reference boxes. The input features of RPN and R-CNN should be well-aligned with the bounding boxes that are to be regressed. The alignment is guaranteed in R-CNN by the RoIPool <ref type="bibr" target="#b33">[34]</ref> or RoIAlign [18]  layer . The alignment in RPN is heuristically guaranteed: the anchor boxes are uniformly initialized, leveraging the observation that the convolutional kernel of the RPN uniformly</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>strides over the feature maps. Such a heuristic introduces limitations for further improving detection performance as described below.</p><p>A number of studies have attempted to improve RPN by iterative refinement <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b40">41]</ref>. Henceforth, this paper will refer to it as Iterative RPN. The motivation behind this idea is illustrated in <ref type="figure" target="#fig_0">Figure 1a</ref>. Anchor boxes which are references for regression are uniformly initialized, and the target ground truth boxes are arbitrarily located. Thus, RPN needs to learn a regression distribution of high variance, as shown in <ref type="figure" target="#fig_0">Figure 1a</ref>. If this regression distribution is perfectly learned, the regression distribution at stage 2 should be close to a Dirac Delta distribution. However, such a high-variance distribution at stage 1 is difficult to learn, requiring stage 2 regression. Stage 2 distribution has a lower variance compared to that of stage 1, and thus should be easier to learn but fails with Iterative RPN. The failure is implied by the observation in which the performance improvement of Iterative RPN is negligible compared to that of RPN, as shown in <ref type="figure" target="#fig_0">Figure 1b</ref>. It is explained intuitively in <ref type="figure" target="#fig_0">Figure 1c</ref>. Here, after stage 1, the anchor is regressed to be closer to the ground truth box; however, this breaks the alignment rule in detection. This paper proposes an architecture referred to as Cascade RPN to systematically address the aforementioned problem arising from heuristically defining the anchors and aligning the features to the anchors. First, instead of using multiple anchors with different scales and aspect ratios, Cascade RPN relies on a single anchor and incorporates both anchor-based and anchor-free criteria in defining positive boxes to achieve high performance. Second, to benefit from multi-stage refinement while maintaining the alignment between anchor boxes and features, Cascade RPN relies on the proposed adaptive convolution that adapts to the refined anchors after each stage. Adaptive convolution serves as an extremely light-weight RoIAlign layer <ref type="bibr" target="#b17">[18]</ref> to learn the features sampled within the anchors.</p><p>Cascade RPN is conceptually simple and easy to implement. Without bells and whistles, a simple two-stage Cascade RPN achieves AR 13.4 points improvement compared to RPN baseline on the COCO dataset <ref type="bibr" target="#b25">[26]</ref>, surpassing any existing region proposal methods by a large margin. Cascade RPN can also be integrated into two-stage detectors to improve detection performance. In particular, integrating Cascade RPN into Fast R-CNN and Faster R-CNN achieves 3.1 and 3.5 points mAP improvement, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Object Detection. Object detection can be roughly categorized into two main streams: one-stage and two-stage detection. Here, one-stage detectors are proposed to enhance computational efficiency. Examples falling in this stream are SSD <ref type="bibr" target="#b26">[27]</ref>, YOLO <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>, RetinaNet <ref type="bibr" target="#b24">[25]</ref>, and CornerNet <ref type="bibr" target="#b20">[21]</ref>. Meanwhile, two-stage detectors aim to produce accurate bounding boxes, where the first stage generates region proposals followed by region-wise refinement and classification at the second stage, e.g., R-CNN <ref type="bibr" target="#b14">[15]</ref>, Fast R-CNN <ref type="bibr" target="#b15">[16]</ref>, Faster R-CNN <ref type="bibr" target="#b33">[34]</ref>, Cascade R-CNN <ref type="bibr" target="#b3">[4]</ref>, and HTC <ref type="bibr" target="#b6">[7]</ref>.</p><p>Region Proposals. Region proposals have become the de-facto paradigm for high-quality object detectors <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>. Region proposals serve as the attention mechanism that enables the detector to produce accurate bounding boxes while maintaining computation tractability. Early methods are based on grouping super-pixel (e.g., Selective Search <ref type="bibr" target="#b35">[36]</ref>, CPMC <ref type="bibr" target="#b4">[5]</ref>, MCG <ref type="bibr" target="#b1">[2]</ref>) and window scoring (e.g., objectness in windows <ref type="bibr" target="#b0">[1]</ref>, EdgeBoxes <ref type="bibr" target="#b42">[43]</ref>). Although these methods dominate the field of object detection in classical computer vision, they exhibit limitations as they are external modules independent of the detector and not computationally friendly. To overcome these limitations, Shaoqing et al. <ref type="bibr" target="#b33">[34]</ref> propose Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, enabling nearly cost-free region proposals.</p><p>Multi-Stage RPN. There have been a number of studies attempting to improve the performance of RPN <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41]</ref>. The general trend is to perform multi-stage refinement that takes the output of a stage as the input of the next stage and repeats until accurate localization is obtained, as presented in <ref type="bibr" target="#b13">[14]</ref>. However, this approach ignores the problem that the regressed boxes are misaligned to the image features, breaking the alignment rule required for object detection. To alleviate this problem, recent advanced methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b36">37]</ref> rely on deformable convolution <ref type="bibr" target="#b9">[10]</ref> to perform feature spatial transformations and expect the learned transformations to align to the changes of anchor geometry. However, as there is no explicit supervision to learn the feature transformation, it is difficult to determine whether the improvement originates from conforming to the alignment rule or from the benefits of deformable convolution, thus making it less interpretable.</p><p>Anchor-based vs. Anchor-free Criterion for Sample Discrimination. As a bounding box usually includes an object with some amount of background, it is difficult to determine if the box is a positive or a negative sample. This problem is usually addressed by comparing the Intersection over Union (IoU) between an anchor and a ground truth box to a predefined threshold; thus, it is referred to as the anchor-based criterion. However, as the anchor is uniformly initialized, multiple anchors with different scales and aspect ratios are required at each location to ensure that there are enough positive samples <ref type="bibr" target="#b33">[34]</ref>. The hyperparameters, such as scales and aspect ratios, are usually heuristically tuned and have a large impact on the final accuracy <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b33">34]</ref>. Rather than relying on anchors, there have been studies that define positive samples by the distance between the prediction points and the center region of objects, referred to as anchor-free <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref>. This method is simple and requires fewer hyperparameters but usually exhibits limitations in dealing with complex scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Region Proposal Network and Variants</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Region Proposal Network</head><p>Given an image I of size W × H, a set of anchor boxes</p><formula xml:id="formula_0">A = {a ij |0 &lt; (i + 1 2 )s ≤ W, 0 &lt; (j + 1</formula><p>2 )s ≤ H} is uniformly initialized over the image, with stride s. Unless otherwise specified, i and j are omitted to simplify the notation. Each anchor box a is represented by a 4-tuple in the form of a = (a x , a y , a w , a h ), where (a x , a y ) is the center location of the anchor with the dimension of (a w , a h ). The regression branch aims to predict the transformation δ from the anchor a to the target ground truth box t represented as follows:</p><formula xml:id="formula_1">δ x = (t x − a x ) /a w , δ y = (t y − a y ) /a h , δ w = log (t w /a w ) , δ h = log (t h /a h ) .<label>(1)</label></formula><p>Here, the regressor f takes as input the image feature x to output a predictionδ = f (x) that minimizes the bounding box loss:</p><formula xml:id="formula_2">L(δ, δ) = k∈{x,y,w,h} smooth L1 δ k − δ k ,<label>(2)</label></formula><p>where smooth L1 (·) is the robust L 1 loss defined in <ref type="bibr" target="#b15">[16]</ref>. The regressed anchor is simply inferred based on the inverse transformation of (1) as follows: a x =δ x a w + a x , a y =δ y a h + a y ,  <ref type="figure">Figure 2</ref>: The architectures of different networks. "I", "H", "C", and "A" denote input image, network head, classifier, and anchor regressor, respectively. "Conv", "DefConv", "DilConv" and "AdaConv" indicate conventional convolution, deformable convolution <ref type="bibr" target="#b9">[10]</ref>, dilated convolution <ref type="bibr" target="#b38">[39]</ref> and the proposed adaptive convolution layers, respectively.</p><formula xml:id="formula_3">a w = a w exp(δ w ), a h = a h exp(δ h ).<label>(3)</label></formula><p>Then the set of regressed anchor A = {a } is filtered by non-maximum suppression (NMS) to produce a sparse set of proposal boxes P:</p><formula xml:id="formula_4">P = NMS(A , S),<label>(4)</label></formula><p>where S is the set of objectness scores learned by the classification branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Iterative RPN and Variants</head><p>Some previous studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b40">41]</ref> have proposed iterative refinement which is referred to as Iterative RPN, as shown in <ref type="figure">Figure 2b</ref>. Iterative RPN iteratively refines the anchors by treating A as the new initial anchor set for the next stage and repeats Eqs. (1) to (3) until obtaining accurate localization. However, this approach exhibits mismatch between anchors and their represented features as the anchor positions and shapes change after each iteration.</p><p>To alleviate this problem, recent advanced methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b36">37]</ref> use deformable convolution <ref type="bibr" target="#b9">[10]</ref> to perform spatial transformations on the features as shown in <ref type="figure">Figure 2c</ref> and 2d and expect transformed features to align to the change in anchor geometry. However, this idea ignores the problem that there is no constraint to enforce the features to align with the changes in anchors: it is difficult to determine whether the deformable convolution produces feature transformation leading to alignment. Instead, the proposed Cascade RPN systematically ensures the alignment rule by using the proposed adaptive convolution.</p><p>4 Cascade RPN</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Adaptive Convolution</head><p>Given a feature map x, in the standard 2D convolution, the feature map is first sampled using a regular grid R = {(r x , r y )}, and the samples are summed up with the weight w. Here, the grid R is defined by the kernel size and dilation. For example, R = {(−1, −1), (−1, 0), . . . , (0, 1), (1, 1)} corresponds to kernel size 3 × 3 and dilation 1. For each location p on the output feature y, we have:</p><formula xml:id="formula_5">y[p] = r∈R w[r] · x[p + r].<label>(5)</label></formula><p>In adaptive convolution, the regular grid R is replaced by the offset field O that is directly inferred from the input anchor. Letā denote the projection of anchor a onto the feature map. The offset o can be decoupled into center offset and shape offset (shown in <ref type="figure">Figure 2e)</ref>:</p><formula xml:id="formula_6">y[p] = o∈O w[o] · x[p + o].<label>(6)</label></formula><formula xml:id="formula_7">o = o ctr + o shp ,<label>(7)</label></formula><p>where o ctr = (ā x − p x ,ā y − p y ) and o shp is defined by the anchor shape and kernel size.</p><formula xml:id="formula_8">For example, if kernel size is 3 × 3, then o shp ∈ (−ā w 2 , −ā h 2 ), (−ā w 2 , 0), . . . , (0,ā h 2 ), (ā w 2 ,ā h 2 )</formula><p>. As the offsets are typically fractional, sampling is performed with bilinear interpolation analogous to <ref type="bibr" target="#b9">[10]</ref>.</p><p>Relation to other Convolutions. The illustrations of sampling locations in adaptive and other related convolutions are shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Conventional convolution samples the features at contiguous locations with a dilation factor of 1. The dilated convolution <ref type="bibr" target="#b38">[39]</ref> increases the dilation factor, aiming to enhance the semantic scope with unchanged computational cost. The deformable convolution <ref type="bibr" target="#b9">[10]</ref> augments the spatial sampling locations by learning the offsets. Meanwhile, the proposed adaptive convolution performs sampling within the anchors to ensure alignment between the anchors and features. Adaptive convolution is closely related to the others. Adaptive convolution becomes dilated convolution if the center offsets are zeros. Deformable convolution becomes adaptive convolution if the offsets are deterministically derived from the anchors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sample Discrimination Metrics</head><p>Instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a single anchor per location and performs multi-stage refinement. However, this reliance creates a new challenge in determining whether a training sample is positive or negative as the use of anchor-free or anchor-based metric is highly adversarial. The anchor-free metric establishes a loose requirement for positive samples in the second stage and the anchor-based metric results in an insufficient number of positive training examples at the first stage. To overcome this challenge, Cascade RPN progressively strengthens the requirements through the stages by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. In particular, at the first stage, an anchor is a positive sample if its center is inside the center region of an object. In the following stages, an anchor is a positive sample if its IoU with an object is greater than the IoU threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cascade RPN</head><p>The architecture of a two-stage Cascade RPN is illustrated in <ref type="figure">Figure 2e</ref>. Here, Cascade RPN relies on adaptive convolution to systematically align the features to the anchors. In the first stage, the adaptive convolution is set to perform dilated convolution since anchor center offsets are zeros. The features of the first stage are "bridged" to the next stages since the spatial order of the features is maintained by the dilated convolution. The pipeline of the proposed Cascade RPN can be described mathematically in Algorithm 1. The anchor set at the first stage A 1 is uniformly initialized over the image. At stage τ , the anchor offset o τ is computed and fed into the regressor f τ to produce the regression prediction δ τ . The predictionδ τ is used to produce regressed anchors a τ +1 . At the final stage, the objectness scores are derived from the classifier, followed by NMS to produce the region proposals. Algorithm 1. Cascade RPN 1 Input: sequence of regressors f τ , classifier g, feature x of image I. <ref type="bibr" target="#b1">2</ref> Output: proposal set P. <ref type="bibr" target="#b2">3</ref> Uniformly initialize anchor set A 1 = {a 1 } over image I. <ref type="bibr" target="#b3">4</ref> for τ ← 1 to T do <ref type="bibr" target="#b4">5</ref> Compute offset o τ of input anchor a τ on feature map using <ref type="bibr" target="#b6">(7)</ref>. <ref type="bibr" target="#b5">6</ref> Compute regression predictionδ τ = f τ (x, o τ ). <ref type="bibr" target="#b6">7</ref> Compute regressed anchor a τ +1 fromδ τ using (3). 8 end 9 Compute objectness score s = g(x, o T ). <ref type="bibr" target="#b9">10</ref> Derive proposals P from A τ +1 = {a τ +1 } and S = {s} using NMS (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Learning</head><p>Cascade RPN can be trained in an end-to-end manner using multi-task loss as follows:</p><formula xml:id="formula_9">L = λ T τ =1 α τ L τ reg + L cls .<label>(8)</label></formula><p>Here, L τ reg is the regression loss at stage τ with the weight of α τ , and L cls is the classification loss. The two loss terms are balanced by λ. In the implementation, binary cross entropy loss and IoU loss <ref type="bibr" target="#b39">[40]</ref> are used as the classification loss and regression loss, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setting</head><p>The experiments are performed on the COCO 2017 detection dataset <ref type="bibr" target="#b25">[26]</ref>. All the models are trained on the train split (115k images). The region proposal performance and ablation analysis are reported on val split (5k images), and the benchmarking detection performance is reported on test-dev split (20k images).</p><p>Unless otherwise specified, the default model of the experiment is as follows. The model consists of two stages, with ResNet50-FPN <ref type="bibr" target="#b23">[24]</ref> being its backbone. The use of two stages is to balance accuracy and computational efficiency. A single anchor per location is used with size of 32 2 , 64 2 , 128 2 , 256 2 , and 512 2 corresponding to the feature levels C 2 , C 3 , C 4 , C 5 , and C 6 , respectively <ref type="bibr" target="#b23">[24]</ref>. The first stage uses the anchor-free metric for sample discrimination with the thresholds of the center-region σ ctr and ignore-region σ ign , which are adopted from <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b36">37]</ref>, being 0.2 and 0.5. The second stage uses the anchor-based metric with the IoU threshold of 0.7. The multi-task loss is set with the stage-wise weight α 1 = α 2 = 1 and the balance term λ = 10. The NMS threshold is set to 0.8. In all experiments, the long edge and the short edge of the images are resized to 1333 and 800 respectively without changing the aspect ratio. No data augmentation is used except for standard horizontal image flipping. The models are implemented with PyTorch <ref type="bibr" target="#b28">[29]</ref> and mmdetection <ref type="bibr" target="#b7">[8]</ref>. The models are trained with 8 GPUs with a batch size of 16 (two images per GPU) for 12 epochs using SGD optimizer. The learning rate is initialized to 0.02 and divided by 10 after 8 and 11 epochs. It takes about 12 hours for the models to converge on 8 Tesla V100 GPUs.</p><p>The quality of region proposals is measured with Average Recall (AR), which is the average of recalls across IoU thresholds from 0.5 to 0.95 with a step of 0.05. The AR for 100, 300, and 1000 proposals per image are denoted as AR 100 , AR 300 , and AR 1000 . The AR for small, medium, and large objects computed at 100 proposals are denoted as AR S , AR M , and AR L , respectively. Detection results are evaluated with the standard COCO-style Average Precision (AP) measured at IoUs from 0.5 to 0.95. The runtime is measured on a single Tesla V100 GPU.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmarking Results</head><p>Region Proposal Performance. The performance of Cascade RPN is compared to those of recent state-of-the-art region proposal methods, including RPN <ref type="bibr" target="#b33">[34]</ref>, SharpMask <ref type="bibr" target="#b29">[30]</ref>, GCN-NS <ref type="bibr" target="#b27">[28]</ref>, AttractioNet <ref type="bibr" target="#b13">[14]</ref>, ZIP <ref type="bibr" target="#b21">[22]</ref>, and GA-RPN <ref type="bibr" target="#b36">[37]</ref>. In addition, Iterative RPN and Iterative RPN+, which are referred to in <ref type="figure">Figure 2</ref>, are also benchmarked. The results of Sharp Mask, GCN-NS, AttractioNet, ZIP are cited from the papers. The results of the remaining methods are reproduced using mmdetection <ref type="bibr" target="#b7">[8]</ref>. <ref type="table" target="#tab_0">Table 1</ref> summarizes the benchmarking results. In particular, Cascade RPN achieves AR 13.4 points higher than that of the conventional RPN. Cascade RPN consistently outperforms the other methods in terms of AR under different settings of proposal thresholds and object scales. The alignment rule is typically missing or loosely conformed to in the other methods; thus, their performance improvements are limited. The alignment rule in Cascade RPN is systematically ensured such that the performance gain is greater and more reliable.</p><p>Detection Performance. To investigate the benefit of high-quality proposals, Cascade RPN and the baselines are integrated into common two-stage object detectors, including Fast R-CNN and Faster R-CNN. Here, Fast R-CNN is trained on precomputed region proposals while Faster R-CNN is trained in an end-to-end manner. As studied in <ref type="bibr" target="#b36">[37]</ref>, despite high-quality region proposals, training a good detector is still a non-trivial problem, and simply replacing RPN by Cascade RPN without changes in the settings only brings limited gain. Following <ref type="bibr" target="#b36">[37]</ref>, the IoU threshold in R-CNN is increased and the number of proposals is decreased. In particular, the IoU threshold and the number of proposals are set to 0.65 and 300, respectively. The experimental results are reported in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Here, integrating RPN into Fast R-CNN and Faster R-CNN yields 37.0 and 37.1 mAP, respectively. From the results, the recall improvement is correlated with improvements in detection performance.</p><p>As it has the highest recall, Cascade RPN boosts the performance for Fast R-CNN and Faster R-CNN to 40.1 and 40.6 mAP, respectively.     <ref type="table" target="#tab_2">Table 3</ref>. Here, the baseline is RPN with 3 anchors per location yielding AR 1000 of 58.3. When the number of anchors per location is reduced to 1, the AR 1000 drops to 55.8, implying that the number of positive samples dramatically decreases. Even when the multi-stage cascade is added, the performance is 58.0, which is still lower than that of the baseline. However, when adaptive convolution is applied to ensure alignment, the performance surges to 67.8, showing the importance of alignment in multi-stage refinement. The incorporation of anchor-free and anchor-based metrics for sample discrimination incrementally improves AR 1000 to 68.6. The use of regression statistics (shown in <ref type="figure" target="#fig_0">Figure 1a</ref>) increases the performance to 71.5. Finally, applying IoU loss yields a slight improvement of 0.2 points. Overall, Cascade RPN achieves 16.5, 14.7, and 13.4 points improvement in terms of AR 100 , AR 300 , and AR 1000 respectively, compared to the conventional RPN.</p><p>Acquisition of Alignment. To demonstrate the effectiveness of the proposed adaptive convolution, the center and shape alignments, represented by the offsets in Eq. <ref type="formula" target="#formula_7">(7)</ref>, are progressively applied. Here, the center and shape offsets maintain the alignments in position and semantic scope, respectively. <ref type="table" target="#tab_3">Table 4</ref> shows that the AR 1000 improves from 58.0 to 64.1 using only the center alignment. When both the center and shape alignments are ensured, the performance increases to 67.8.   Sample Discrimination Metrics. The experimental results with different combinations of sample discrimination metrics are shown in <ref type="table" target="#tab_4">Table 5</ref>. Here, AF and AB denote that the anchor-free and anchor-based metrics are applied for all stages, respectively. Meanwhile, AFAB indicates that the anchor-free metric is applied at stage 1 followed by anchor-based metric at stage 2. Here, AF and AB yield the AR 1000 of 66.4 and 67.8 respectively, both of which are significantly less than that of AFAB. It is noted that the thresholds for each metric are already adapted through stages. The results imply that applying only one of either anchor-free or anchor-based metric is highly adversarial. The both metrics should be incorporated to achieve the best results.</p><p>Qualitative Evaluation. The examples of region proposal results at the first and second stages are illustrated in the first and second row of <ref type="figure">Figure 4</ref>, respectively. The results show that the output proposals at the second stage are more accurate and cover a larger number of objects. <ref type="table" target="#tab_5">Table 6</ref> shows the proposal performance on different number of stages. In the 3-stage Cascade RPN, an IoU threshold of 0.75 is used for the third stage. The 2-stage Cascade RPN achieves the best trade-off between AR 1000 and inference time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Stages.</head><p>Extension with Cascade R-CNN. <ref type="table" target="#tab_6">Table 7</ref> reports the detection results of the Cascade R-CNN <ref type="bibr" target="#b3">[4]</ref> with different proposal methods. The Cascade RPN improves AP by 0.8 points compared to RPN. The improvement is mainly from AP 75 , where the objects have high IoU with the ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper introduces Cascade RPN, a simple yet effective network architecture for improving region proposal quality and object detection performance. Cascade RPN systematically addresses the limitations that conventional RPN heuristically defines the anchors and aligns the features to the anchors. A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points higher than the baseline, surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Iterative RPN shows limitations in improving RPN performance. (a) The target regression distribution to be learned at stage 1 and 2. The stage 2 distribution represents the error after the stage 1 distribution is learned. (b) Iterative RPN fails in learning stage-2 distribution as the average recall (AR) improvement is marginal compared to the of RPN. (c) In Iterative RPN, the anchor at stage 2, which is regressed in stage 1, breaks the alignment rule in detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Illustrations of the sampling locations in different convolutional layers with 3 × 3 kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Stage 1 Stage 2 Figure 4 :</head><label>124</label><figDesc>Examples of region proposal results at stage 1 (first row) and stage 2 (second row) of Cascade RPN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>More examples of region proposal results of Cascade RPN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Region proposal results on COCO 2017 val.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell cols="7">AR100 AR300 AR1000 ARS ARM ARL Time (s)</cell></row><row><cell>SharpMask [30]</cell><cell>ResNet-50</cell><cell>36.4</cell><cell>-</cell><cell>48.2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.76</cell></row><row><cell>GCN-NS [28]</cell><cell>VGG-16 (Sync BN)</cell><cell>31.6</cell><cell>-</cell><cell>60.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.10</cell></row><row><cell>AttractioNet [14]</cell><cell>VGG-16</cell><cell>53.3</cell><cell>-</cell><cell>66.2</cell><cell>31.5</cell><cell>62.2</cell><cell>77.7</cell><cell>4.00</cell></row><row><cell>ZIP [22]</cell><cell>BN-inception</cell><cell>53.9</cell><cell>-</cell><cell>67.0</cell><cell>31.9</cell><cell>63.0</cell><cell>78.5</cell><cell>1.13</cell></row><row><cell>RPN [34]</cell><cell></cell><cell>44.6</cell><cell>52.9</cell><cell>58.3</cell><cell>29.5</cell><cell>51.7</cell><cell>61.4</cell><cell>0.04</cell></row><row><cell>Iterative RPN</cell><cell></cell><cell>48.5</cell><cell>55.4</cell><cell>58.8</cell><cell>32.1</cell><cell>56.9</cell><cell>65.4</cell><cell>0.05</cell></row><row><cell>Iterative RPN+</cell><cell>ResNet-50-FPN</cell><cell>54.0</cell><cell>60.4</cell><cell>63.0</cell><cell>35.6</cell><cell>62.7</cell><cell>73.9</cell><cell>0.06</cell></row><row><cell>GA-RPN [37]</cell><cell></cell><cell>59.1</cell><cell>65.1</cell><cell>68.5</cell><cell>40.7</cell><cell>68.2</cell><cell>78.4</cell><cell>0.06</cell></row><row><cell>Cascade RPN</cell><cell></cell><cell>61.1</cell><cell>67.6</cell><cell>71.7</cell><cell>42.1</cell><cell>69.3</cell><cell>82.8</cell><cell>0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Detection results on COCO 2017 test-dev</figDesc><table><row><cell>Method</cell><cell cols="2">Proposal method # proposals</cell><cell>AP</cell><cell cols="5">AP50 AP75 APS APM APL</cell></row><row><cell></cell><cell>RPN Cascade RPN</cell><cell>1000</cell><cell>37.0 40.1</cell><cell>59.5 59.5</cell><cell>39.9 43.7</cell><cell>21.1 22.8</cell><cell>39.4 42.4</cell><cell>47.0 50.9</cell></row><row><cell>Fast R-CNN</cell><cell>RPN</cell><cell></cell><cell>36.6</cell><cell>58.6</cell><cell>39.5</cell><cell>20.3</cell><cell>39.1</cell><cell>47.0</cell></row><row><cell></cell><cell>Iterative RPN+ GA-RPN</cell><cell>300</cell><cell>38.6 39.5</cell><cell>58.8 59.3</cell><cell>42.2 43.2</cell><cell>21.1 21.8</cell><cell>41.5 42.0</cell><cell>50.0 50.7</cell></row><row><cell></cell><cell>Cascade RPN</cell><cell></cell><cell>40.1</cell><cell>59.4</cell><cell>43.8</cell><cell>22.1</cell><cell>42.4</cell><cell>51.6</cell></row><row><cell></cell><cell>RPN Cascade RPN</cell><cell>1000</cell><cell>37.1 40.5</cell><cell>59.3 59.3</cell><cell>40.1 44.2</cell><cell>21.4 22.6</cell><cell>39.8 42.9</cell><cell>46.5 51.5</cell></row><row><cell>Faster R-CNN</cell><cell>RPN</cell><cell></cell><cell>36.9</cell><cell>58.9</cell><cell>39.9</cell><cell>21.1</cell><cell>39.6</cell><cell>46.5</cell></row><row><cell></cell><cell>Iterative RPN+ GA-RPN</cell><cell>300</cell><cell>39.2 39.9</cell><cell>58.2 59.4</cell><cell>43.0 43.6</cell><cell>21.5 22.0</cell><cell>42.0 42.6</cell><cell>50.4 50.9</cell></row><row><cell></cell><cell>Cascade RPN</cell><cell></cell><cell>40.6</cell><cell>58.9</cell><cell>44.5</cell><cell>22.0</cell><cell>42.8</cell><cell>52.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation analysis of Cascade RPN. Here, Align., AFAB, and Stats. denote the use of alignments, anchor-free and anchor-based metrics, and regression statistics, respectively.</figDesc><table><row><cell cols="4">Baseline 1 anchor Cascade Align. AFAB Stats. IoU loss AR100 AR300 AR1000</cell></row><row><cell></cell><cell>44.6</cell><cell>52.9</cell><cell>58.3</cell></row><row><cell></cell><cell>44.7</cell><cell>51.2</cell><cell>55.8</cell></row><row><cell></cell><cell>48.2</cell><cell>54.4</cell><cell>58.0</cell></row><row><cell></cell><cell>57.4</cell><cell>63.7</cell><cell>67.8</cell></row><row><cell></cell><cell>57.3</cell><cell>64.2</cell><cell>68.6</cell></row><row><cell></cell><cell>60.8</cell><cell>67.3</cell><cell>71.5</cell></row><row><cell></cell><cell>61.1</cell><cell>67.6</cell><cell>71.7</cell></row><row><cell>Overall Improvement</cell><cell>+16.5</cell><cell>+14.7</cell><cell>+13.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The effects of alignment</figDesc><table><row><cell cols="3">Center Shape AR100 AR300 AR1000</cell></row><row><cell>48.2</cell><cell>54.4</cell><cell>58.0</cell></row><row><cell>52.5</cell><cell>59.4</cell><cell>64.1</cell></row><row><cell>57.4</cell><cell>63.7</cell><cell>67.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>The effects of sample metrics To demonstrate the effectiveness of Cascade RPN, a comprehensive component-wise analysis is performed in which different components are omitted. The results are reported in</figDesc><table><row><cell cols="3">AF AB AR100 AR300 AR1000</cell></row><row><cell>55.2</cell><cell>61.8</cell><cell>66.4</cell></row><row><cell>57.4</cell><cell>63.7</cell><cell>67.8</cell></row><row><cell>57.3</cell><cell>64.2</cell><cell>68.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Ablation study on # stages.</figDesc><table><row><cell># stages</cell><cell>AR100</cell><cell>AR300</cell><cell>AR1000</cell><cell>Time (s)</cell></row><row><cell>1</cell><cell>56.0</cell><cell>62.2</cell><cell>66.3</cell><cell>0.04</cell></row><row><cell>2</cell><cell>61.1</cell><cell>67.6</cell><cell>71.7</cell><cell>0.06</cell></row><row><cell>3</cell><cell>60.9</cell><cell>67.9</cell><cell>72.2</cell><cell>0.08</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Detection results of Cascade R-CNN with RPN and Cascade RPN (denoted by CRPN).</figDesc><table><row><cell>Method</cell><cell>AP</cell><cell>AP50</cell><cell>AP75</cell><cell>AP75</cell><cell>AP S</cell><cell>AP M</cell></row><row><cell>RPN</cell><cell>40.8</cell><cell>59.3</cell><cell>44.3</cell><cell>22.0</cell><cell>44.2</cell><cell>54.2</cell></row><row><cell>CRPN</cell><cell>41.6</cell><cell>59.0</cell><cell>45.5</cell><cell>23.0</cell><cell>45.0</cell><cell>55.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Measuring the objectness of image windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Object detection techniques applied on mobile robot semantic navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Astua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Crespo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Jardon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cascade r-cnn: Delving into high quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Cpmc: Automatic object segmentation using constrained parametric min-cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Object-proposal evaluation protocol is &apos;gameable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neelima</forename><surname>Chavali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harsh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aroma</forename><surname>Mahendru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hybrid task cascade for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dazhi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">MMDetection: Open mmlab detection toolbox and benchmark</title>
		<editor>Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen Change Loy, and Dahua Lin</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Meeting the application requirements of intelligent video surveillance systems in moving object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donatello</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Foggia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Petretta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Vento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition and Image Analysis</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Segmenting unknown 3d objects from real depth images using mask r-cnn trained on synthetic point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Danielczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Matl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Mahler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05825</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Siamese cascaded region proposal networks for real-time visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Toward automated driving in cities using close-to-market sensors: An overview of the v-charge project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Furgale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Schwesinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Rufli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Derendarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Grimmett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Mühlfellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wonneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Timpner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Rottmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Attend refine repeat: Active box proposal generation via in-out localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04446</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Obstacle detection for self-driving cars using only monocular cameras and wheel odometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Häne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">What makes for effective detection proposals?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">How good are detection proposals, really?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.6962</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cornernet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hei</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Zoom out-and-in network with map attention decision for region proposal and object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IJCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Security event recognition for visual surveillance. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentong</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Ying</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Dollar. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Toward scale-invariance and position-sensitive region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsueh-Fu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping-Lin</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to refine object segments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Pedro O Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Yolo9000: Better, faster, stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">FCOS: fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jasper Rr Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Koen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold Wm</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smeulders</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>IJCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Region proposal by guided anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Craft objects from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unitbox: An advanced object detection network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th ACM international conference on Multimedia</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Cascade region proposal and global context for deep object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoyong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shicai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiliang</forename><surname>Pu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10749</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Feature selective anchor-free module for single-shot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
