<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lessons Learned from the Training of GANs on Artificial Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichang</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science &amp; Technology</orgName>
								<orgName type="institution">ShanghaiTech University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Institute of Microsystem and Information Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Lessons Learned from the Training of GANs on Artificial Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generative Adversarial Networks (GANs) have made great progress in synthesizing realistic images in recent years. However, they are often trained on image datasets with either too few samples or too many classes belonging to different data distributions. Consequently, GANs are prone to underfitting or overfitting, making the analysis of them difficult and constrained. Therefore, in order to conduct a thorough study on GANs while obviating unnecessary interferences introduced by the datasets, we train them on artificial datasets where there are infinitely many samples and the real data distributions are simple, high-dimensional and have structured manifolds. Moreover, the generators are designed such that optimal sets of parameters exist. Empirically, we find that under various distance measures, the generator fails to learn such parameters with the GAN training procedure. We also find that training mixtures of GANs leads to more performance gain compared to increasing the network depth or width when the model complexity is high enough. Our experimental results demonstrate that a mixture of generators can discover different modes or different classes automatically in an unsupervised setting, which we attribute to the distribution of the generation and discrimination tasks across multiple generators and discriminators. As an example of the generalizability of our conclusions to realistic datasets, we train a mixture of GANs on the CIFAR-10 dataset and our method significantly outperforms the state-of-the-art in terms of popular metrics, i.e., Inception Score (IS) and Fréchet Inception Distance (FID).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>The past few years have witnessed the arising popularity of generative models. As can be seen, image processing (e.g., image super-resolution and editing) and machine learning (e.g., reinforcement learning and semi-supervised learning) tasks are infused strong energy by generative models <ref type="bibr" target="#b0">[1]</ref>. Typically, a generative model learns a distribution P g to approximate the true distribution P r , given a set of observed samples.</p><p>Generative Adversarial Network <ref type="bibr" target="#b1">[2]</ref>, with no doubt, is the most prevailing generative model. It is composed of a generator G that maps random noise to synthesized data points, and a discriminator D which aims to tell whether its input comes from the real data distribution P r or generative distribution P g . During training, D and G are updated simultaneously or alternatingly. In a vanilla GAN, D gives an estimate of the Jensen-Shannon divergence between P r and P g while G tries to minimize it <ref type="bibr" target="#b1">[2]</ref>.</p><p>Unfortunately, the objective of G can get saturated when P g and P r do not have an non-negligible overlapping manifold, causing vanishing gradients to the generator <ref type="bibr" target="#b2">[3]</ref>. Let Z and X be the domain and codomain of G respectively. G(Z) is contained in a countable union of manifolds of dimension at most dim Z. Then, according to <ref type="bibr" target="#b2">[3]</ref>, if the dimension of Z is less than that of X , G(Z) will be a set of measure 0 in X , P r and P g can be distinguished with accuracy 1 by D and thus no gradient is provided to G. Besides, GANs suffer from mode collapse. Mode collapse refers to the phenomenon that the samples of the generator lacks the diversity exhibited in P r . <ref type="bibr" target="#b3">[4]</ref> prove that the generator can fool the discriminator by generating a limited number of images from the training set. In other cases of mode collapse, the generated samples are even meaningless as G needs only to fool D in the current iteration. When mode collapse happens, the model fails to generate diverse and realistic data.</p><p>To cope with these challenges, variants of GAN were proposed (e.g., <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b9">[10]</ref>). Limited by the fact that these methods are applied to high-dimensional realistic datasets with inadequate samples from each class, the behavior of GANs remains not completely understood. Another problem with realistic datasets is that the performance of GANs can degrade simply due to data scarcity or insufficient model complexity <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>Considering that we aim to study the behavior of GANs, conventional image datasets might not be good choices. Hence we train GANs on artificially constructed datasets (e.g., mixtures of Gaussians in high dimensional space), applying neural networks with sufficiently high capacity.</p><p>In this way, we can avoid the influence of the aforementioned factors and focus on the inherent problems of GAN training.</p><p>The contributions of this work can be summarized as follows:</p><p>• We propose a set of metrics for evaluating GANs trained on the artificial datasets. <ref type="bibr">•</ref> We designed controlled experiments where we can adjust the network width/depth, the mixture of networks, and the training set size, and then relate them to the performance of GANs.</p><p>• Our empirical study suggests that GANs may fail to learn the real data distribution, even if at least one set of optimal parameters exists for the generator by design. • In terms of model complexity, our experimental result demonstrates that when the networks are already reasonably large, training a mixture of GANs is more beneficial than increasing the complexity of standalone networks, as the generation task can be divided by multiple generators and the variance of the discrimination model is reduced when using an ensemble of discriminators. We further validate this conclusion on the CIFAR-10 dataset and achieve the state-of-theart Inception Score and Fréchet Inception Distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Related Work</head><p>There are attempts to make a GAN converge to an equilibrium <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>. However, even if a GAN reaches an equilibrium, it might fail to learn the desired real data distribution. To support this conjecture, <ref type="bibr" target="#b12">[13]</ref> adopt the Birthday Paradox to measure the diversity of the generative distribution. They present empirical evidence that P g has lower support than P r . However, it should be noted that this problem also might be due to the dimension of the manifold of the latent distribution being lower than the dimension of the manifold of P r <ref type="bibr" target="#b2">[3]</ref>. In order to rule out this possibility, we set the dimension of z to be no lower than the dimension of x in our experiments on the artificial datasets. Basically, we share a similar goal with <ref type="bibr" target="#b12">[13]</ref>, but we conduct experiments on artificial constructed datasets with infinite data samples.</p><p>Consistent with <ref type="bibr" target="#b12">[13]</ref>, our experiments reveal that even when a GAN converges to a diverse distribution, it still differs from the true distribution. Considering that the birthday paradox test in <ref type="bibr" target="#b12">[13]</ref> is rather restrictive on continuous data, we propose to use some other measures for validating whether GANs can learn the real data distribution.</p><p>Recently, large scale GAN training(e.g., <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b15">[16]</ref>) has proven effective on the ImageNet <ref type="bibr" target="#b16">[17]</ref> dataset. Their superiority over previous models is mainly due to high model complexity and large batch sizes. While current state-of-the-art GAN models on ImageNet are still subject to model complexity and batch size, our work focus on synthetic datasets that allows the batch size and model complexity to be sufficiently high, which enables us to explore the properties of GANs in ideal cases.</p><p>Some previous work has studied the feasibility of using multiple discrimiantors <ref type="bibr" target="#b17">[18]</ref>, multiple generators <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, or both <ref type="bibr" target="#b3">[4]</ref> to improve the performance of GANs. Our experiments on artificial datasets is based on MIX+GAN <ref type="bibr" target="#b3">[4]</ref> and we find it beneficial to use multiple generators and discriminators. Further, our experimental results unveil the relations between the number of generators and discriminators and the performance of GANs. As the computation of MIX+GAN is expensive or even infeasible, we modify it to allow larger mixtures and achieve stat-ofthe-art results on CIFAR-10. In our work, we also explore how factors such as network depth, network width and training set size affect the performance of GANs. <ref type="bibr" target="#b7">[8]</ref> has been gaining popularity (e.g., <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref>) for its stability, while MIX+GAN <ref type="bibr" target="#b3">[4]</ref> guarantees the existence of approximate equilibrium using a mixture of generators and discriminators. MIX+GAN is also effective in modeling multi-modal data which is common in realistic datasets. Therefore, we combine WGAN-GP and MIX+GAN for our experiments on the artificial datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WGAN-GP</head><p>In the following, we will first introduce Wasserstein GAN (WGAN) <ref type="bibr" target="#b6">[7]</ref> and WGAN-GP <ref type="bibr" target="#b7">[8]</ref>, then introduce MIX+GAN <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. WGAN-GP</head><p>In a vanilla GAN, the generator tries to minimize the approximate Jensen-Shannon divergence defined by the discriminator. Different from vanilla GAN, the discriminator in WGAN calculates an approximate Wasserstein distance between the real and fake data distributions. The discriminator in WGAN is also referred to as the "critic". We will use both terms interchangably in this paper.</p><p>The minimax game for WGAN is formulated as</p><formula xml:id="formula_0">W (P r , P g ) = min G max D E x∼Pr [D(x)] − Ex ∼Pg [D(x)] (1)</formula><p>where D is in the set of all 1-Lipschitz functions and P g is the model distribution implicitly defined by z ∼ p(z), x = G(z). Note that Eq. 1 can be reformulated as</p><formula xml:id="formula_1">W (P r , P g )= 1 k {min G max D E x∼Pr [D(x)] − Ex ∼Pg [D(x)]} (2)</formula><p>where D is in the set of all k-Lipschitz functions. WGAN <ref type="bibr" target="#b6">[7]</ref> adopts a weight clipping approach to enforce the Lipschitz constraint. However, it can lead to optimization problems and pathological behaviors. To overcome these problems, An improved version of WGAN was proposed in <ref type="bibr" target="#b7">[8]</ref>, introducing a new objective for the critic:</p><formula xml:id="formula_2">Ex ∼Pg [D(x)]−E x∼Pr [D(x)]+λEx ∼Px [( ∇xD(x) 2 −1) 2 ]<label>(3)</label></formula><p>wherex comes from the distribution Px whose samples are interpolated between samples from P g and P data . This choice is based upon the fact that the L2-norm of the gradient of the optimal D is 1 between the manifolds of P g and P data <ref type="bibr" target="#b7">[8]</ref>.</p><p>The last term can be interpreted as a regularizer that forces the gradient between the real and fake datasets to be at a moderate scale, so that P g is moved smoothly to the real data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MIX+GAN</head><p>A group of datasets that the GANs in this paper are tasked with is mixtures of Gaussians. A generator can learn any n-dimensional Gaussian distribution with n-dimensional isotropic Gaussian input noise by simply learning an affine transformation. However, this problem becomes less straightforward if P r is a mixture of Gaussians. Another problem is that different modes in the dataset can be discontinuous (which is common in realistic datasets) and thus cannot be learned by a continuous generator network, posing another challenge to GAN training. Therefore, we use MIX+GAN <ref type="bibr" target="#b3">[4]</ref> to model mixtures of Gaussians. In MIX+GAN, there are n G generators and n D discriminators. Each G i and each D j has a weight w i and v j respectively to indicate their relative importance. The weights are produced by the softmax function on the learnable log-probabilities, therefore</p><formula xml:id="formula_3">n D i=1 w i = 1 and n D j=1 v j = 1.</formula><p>In a MIX+GAN, both players play mixedstrategies: The generators' weighted probability density at point x is</p><formula xml:id="formula_4">p g (x) = n G i=1 w i p gi (x),<label>(4)</label></formula><p>and the discriminators' weighted output at point x is</p><formula xml:id="formula_5">D(x) = n D j=1 v j D j (x).<label>(5)</label></formula><p>To encourage the weights to get close to the discrete uniform distribution, entropy regularization terms,</p><formula xml:id="formula_6">− 1 n D n D j=1 log(v j ) and − 1 n G n G i=1 log(w i )</formula><p>, are added to the loss of the generators and the loss of discriminators respectively. Therefore, the overall loss for the discriminators is</p><formula xml:id="formula_7">L D = n D j=1 n G i=1 v j w i E x∼Pgi [L D,f ake (D j (x))]<label>(6)</label></formula><formula xml:id="formula_8">+ n D j=1 v j E x∼Pr L D,real (D j (x))] − 1 n D n D j=1 log(v j )<label>(7)</label></formula><p>and the overall loss for the generators is</p><formula xml:id="formula_9">L G = n D j=1 n G i=1 v j w i E x∼Pgi [L G (D j (x))]− 1 n G n G i=1 log(w i ) (8)</formula><p>where L D,real , L D,f ake and L G are functions of the outputs of the discriminators. For example, in a vanilla GAN,</p><formula xml:id="formula_10">L D,real (D j (x)) = −log(D j (x)), L D,f ake (D j (x)) = −log(1 − D j (x)) and L G (D j (x)) = −log(D j (x)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Experiments on the artificial datasets A. Datasets</head><p>Popular GANs usually focus on learning highdimensional and complicated datasets (e.g., realistic images and natural languages). As a result, the GAN models are sensitive to almost every hyperparameter. Furthermore, these datasets contain either too many categories or too few samples in each category, thus GAN models can easily underfit or overfit <ref type="bibr" target="#b23">[24]</ref>, i.e., generating samples of low visual quality or encountering mode collapse. In this paper, we conduct experiments on the following simple artificial datasets with infinite samples: 1) Mixture of Gaussians. In our experiments, a dataset of a mixture of Gaussians consists of samples from independent high-dimensional Gaussian components with equal prior probabilities. The Gaussian components have their centers lying on axes of a Cartesian coordinate system in 1024-dimensional space. Specifically, the coordinate of the i'th center is e i = (0, ..., 0, 1, 0, ...0) whose i'th entry is 1 and the other entries are 0; the covariance matrices are all 0.09I. 2) Output of a randomly initialized network. This dataset is from the output of a network R that has the same input noise as a generator. In the case of a single generator G, if R and G have the same arhitecture and G has learned the parameters of R, then no classifier can distinguish P r and P g .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Design of Model Architectures</head><p>In order to compare across different experimental settings, we design our model architectures following the rules below to reduce unnecessary interference and maintain simplicity:</p><p>• All neural networks consist of affine layers and LeakyReLU non-linearities only. • Each hidden affine layer is followed by a LeakyReLU activation layer. • The input dimension and output dimension of each generator is 1024. In addition to having LeakyReLU activations, each generator has no less than 1024 neurons in each of its hidden layers, so that it can be learned to be injective. • If a network has hidden layers, then all of its hidden layers contain the same number of neurons. • Throughout this session, the number of layers refers to the number of hidden affine layers plus one input layer and one output layer, excluding LeakyReLU layers, e.g., a 2-layer network is an affine transformation from the input space to the output space; a 5-layer network has 3 hidden layers. • Unless stated otherwise, each network has 5 layers and has 1024 neurons in each hidden layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation metrics</head><p>Evaluating different generative models accurately and objectively remains challenging. Currently, there are some reasonable and widely accepted metrics, i.e., Turing test, Inception Score <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, Fréchet Inception Distance <ref type="bibr" target="#b11">[12]</ref> and approximate Wasserstein distance <ref type="bibr" target="#b23">[24]</ref>. The evaluation metrics we use are detailed as follows:</p><p>1) Visualization and Turing test: This is perhaps the simplest way to evaluate a generative model. It is done by using human inspectors to check the quality of (the projection of) the generated data. If a human inspector cannot distinguish whether the generated data are real or fake, then one can conclude that the generative model is very successful. If the inspectors say that samples generated by one model are significantly better that those generated by another model, then it can also be concluded that one model is better than another. On the other hand, if a human inspector cannot tell a significant difference, then one may want to resort to more objective and more accurate metrics. To inspect the generated synthetic high dimensional samples manually, we project the generated samples onto a plane determined by a = (1, 0, 0, 0, ..., 0), b = (0, 1, 0, 0, ..., 0) and c = (0, 0, 1, 0, ..., 0). In the projection plane, the origin is a, The x-axis is in the same direction as − → ab, and the y-axis is in a direction that is perpendicular to the x-axis, as is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The projections of sample data can be seen in <ref type="figure" target="#fig_1">Figure 2</ref> and some other figures in this paper, where real data points are indicated by red dots, fake generated data points are indicated by blue dots. Background colors show the contour plot of the output of the discriminator(s): red corresponds to high values while blue corresponds to low values. 2) Fréchet Distance: <ref type="bibr" target="#b11">[12]</ref> proposed to use the Fréchet Inception Distance (FID) as a metric for evaluating generative models. The Fréchet Distance (FD, also known as the Wasserstein-2 distance) for two Gaussian distributions N (m 1 , C 1 ) and N (m 2 , C 2 ) is given by <ref type="bibr" target="#b26">[27]</ref>. During the computation of FID, images from the real and fake distributions are fed into the Inception model <ref type="bibr" target="#b27">[28]</ref> to get their activations in the last pooling layer. The distributions of the activations are approximately treated as Gaussian so that their means and covariances can be used to compute the FID. In this paper, since we are dealing with artificial data and the Inception model was intended for realistic data, we use the means and covariances of the artificial data directly without passing them through the Inception Network. 50,000 data points are sampled from P r and P g respectively for computing the Fréchet Distance.</p><formula xml:id="formula_11">m 1 −m 2 2 2 +tr(C 1 + C 2 − 2(C 1 C 2 ) 1/2 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Critic output:</head><p>As is noted in <ref type="bibr" target="#b6">[7]</ref>, the loss of the critic provides a meaningful estimate of the Wasserstein distance between P r and P g . We can log the average value of D(x r ) − D(x g ) during each iteration with almost no additional computation cost. If it is positive, then it tells us that P r is different from P g . Moreover, it is an indicator of the training dynamics of WGAN.</p><p>4) Wasserstein distance: The above estimate of the Wasserstein distance can be inaccurate due to adversarial training. Alternatively, one can train an independent critic to approximate the Wasserstein distance after training a GAN <ref type="bibr" target="#b23">[24]</ref>. Note that the gradient penalty term might be large than 0 and the critic may be a k-Lipschitz function, thus we normalized the estimated Wasserstein distance using Eq. 2.</p><p>For fair comparison, we train an independent critic with the same architecture across different experiments. Specifically, it has 5 layers and 1024 neurons in each hidden layer. In our experiments, we estimate the approximate Wasserstein distance W (P r , P g ) with 25,600 sample points from P r and P g respectively. 5) "Judge" accuracy: In all our experiments, an independent classifier called "Judge" is trained to distinguish samples from P g and P r . The accuracy of the Judge is an objective metric for evaluating all of our GANs. After the Judge is fully trained, its classification accuracy is expected to range between 0.5 and 1. If the generator(s) has learned the distribution, then the Judge should have an accuracy of around 0.5. Conversely, if the generator(s) produces a distribution different from P r , the Judge is expected to have an accuracy higher than 0.5. Following Theorem 2.2 of <ref type="bibr" target="#b2">[3]</ref>, given two distributions P g and P r that have support contained in two closed manifolds M and P that don't perfectly align and don't have full dimension, and assume that P g and P r are continuous in their respective manifolds, then there exists a perfect classifier that has accuracy 1.</p><p>One can show that the expected Judge accuracy is related to the total variation distance: Proposition 1. Let J be a deterministic classifier for samples from two distributions P r and P g with equal prior probabilities. Let δ(P r , P g ) be the total variation distance between P r and P g , then</p><formula xml:id="formula_12">δ(P r , P g ) ≥ 2E[J acc ] − 1<label>(9)</label></formula><p>The proof of Proposition 1 is provided in Appendix A. Proposition 1 is intuitive: If the total variation distance between two distributions is very low, then it is hard for any classifier to tell them apart and the accuracy of a classifier can hardly get above 0.5; if a classifier has an accuracy of 1, then the total variation distance between them is high. One can in turn show that the total variation distance is related to the Kullback-Leibler Divergence <ref type="bibr" target="#b28">[29]</ref>.</p><p>For fair comparison, we train an independent Judge with the same architecture across different experiments. Specifically, it has 5 layers and 1024 neurons in each layer.</p><p>In our experiments, we estimate J acc with 25,600 sample points from P r and P g respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Training</head><p>We follow some experimental setups of <ref type="bibr" target="#b7">[8]</ref> for toy data: The batch size is 256; there are 100,000 GAN iterations, each of which includes 1 generator update and 5 discriminator updates; After the training of GAN, we train the Judge and the independent critic for another 100,000 iterations respectively. Adam optimizers <ref type="bibr" target="#b29">[30]</ref> are used for optimizing all models.</p><p>Our experiments differ from <ref type="bibr" target="#b7">[8]</ref> in the following ways: In order to imitate the training of GANs on high-dimensional realistic data, the data points lie in 1024-dimensional space; motivated by <ref type="bibr" target="#b2">[3]</ref>, in order to allow the manifold of P g to have the same dimension as that of P r , the input noise z follows a 1024-dimensional Gaussian distribution and the activation layers are chosen to be LeakyReLU layers that are injective; in all the experiments, λ in WGAN-GP is set to 10 to improve stability; we adopt a "two time-scale update rule" (TTUR) <ref type="bibr" target="#b11">[12]</ref>: the learning rate of the Discriminators(s) is set to 1e − 4 and the learning rate of the Generator(s) is set to 1e−5 after some hyperparameter searching.</p><p>During each iteration of the training of GAN, the generator(s) and the discriminator(s) are updated in the following order: 1) Draw a batch of real data from the real data distribution. 2) Each generator generates n D batch(es) of fake data, which are distributed to the n D discriminator(s). 3) Compute the loss for the generator(s) as described in Eq. 8 and take an optimization step on the generator(s). 4) Compute the loss for the discriminators(s) as described in Eq. 6-7 and take an optimization step on the discriminator(s). 5) Repeat step 1), 2) and 4) for another 4 times. To stabilize GAN training, some tricks were proposed in <ref type="bibr" target="#b30">[31]</ref>. However, most of them are not necessary under the WGAN-GP's setting. Besides, we do not incorporate into our models other potentially beneficial techniques such as normalization techniques <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref> as they may limit the capacity of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results</head><p>In this part, we will report the experimental results on the artificial datasets.</p><p>1) Generation of Mixtures of Gaussians: In <ref type="figure" target="#fig_1">Figure 2</ref>, we present the qualitative results on the 3-Gaussians dataset. The projections of real data points and generated data points are indicated by red and blue dots, respectively. The contour plot shows that the output of the critic of WGAN-GP is quite smooth. In <ref type="figure" target="#fig_3">Figure 3</ref>, we compare MIX+GANs with different combinations of mixtures quantitatively using the aforementioned metrics.</p><p>In each experiment, MIX+GAN successfully learns a 3modal mixture, but it differs from the real distribution. Nevertheless, the generative distribution P g is closer to P r with larger mixtures.  Wasserstein distance There are at least two ways for the generator(s) to win the game. For one thing, Corollary 3.2 in <ref type="bibr" target="#b3">[4]</ref> states that low-capacity discriminators are unable detect lack of diversity, thus the generator(s) can memorize a large quantity of training data to win the game. For another, since the generator(s) can be learned to be injective with all the hidden dimensions being 1024, which is the same as the input dimension and the output dimension, a mixture of 3 generators can learn 3 individual Gaussian components perfectly. But in GAN training, the generator(s) does not win, as <ref type="figure" target="#fig_3">Figure 3b</ref> shows that the discriminator(s) can distinguish the real and generative data distributions.</p><formula xml:id="formula_13">1G1D 3G1D 1G3D 3G3D 5G1D 1G5D 5G5D 10G1D 1G10D 10G10D (d) Wasserstein distance</formula><p>An intriguing phenomenon is observed when the number of generators equals the number of Gaussian components. In <ref type="figure" target="#fig_4">Figure 4</ref>, 5 and 6, we show different fractions of samples generated by different generators in a MIX+GAN. The results in <ref type="figure" target="#fig_4">Figure 4</ref> and <ref type="figure" target="#fig_5">Figure 5</ref> show that when the number of generators equals the number of Gaussian components, MIX+GAN can roughly make each generator capture one Gaussian component. When the number of generators exceeds the number of Gaussian components, as is shown in <ref type="figure" target="#fig_8">Figure 7</ref>, we can see that each generator generates a small portion of data.  The above empirical results indicate that increasing the mixture size can improve the generative distribution, partly by means of dividing the generation and discrimination tasks across multiple generators and discriminators.</p><p>In <ref type="figure" target="#fig_9">Figure 8 and 9</ref>, we show the quantitative results of varying the depth or width of the networks. In these experiments, we use 1 generator and 1 discriminator for generating 3 Gaussians. We do not see any significant improvement when increasing the complexity of the networks compared to increasing the number of generators and discriminators. Increasing the depth does not help might be because the dataset is too simple and more layers do not give better modeling power. Also, training deep MLPs can be unstable. Increasing the width does not help might be because hidden dimensions of 1024 can preserve      For all the metrics, lower is better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Generation of datasets defined by neural networks:</head><p>In this part, we define the real data distribution as the distribution of the output of a neural network R that has the same input and architecture as the generator(s). The parameters of R is randomly initialized with the Glorot uniform initializer <ref type="bibr" target="#b34">[35]</ref> and fixed thereafter. There are also at least two ways in which the generator(s) can win the game: either memorize a large sample of the training data according to <ref type="bibr" target="#b3">[4]</ref>, or learn to have the same parameters as R (of course, there are other sets of parameters that enables the generator(s) to generate P r due to the symmetry and complexity of neural networks). We consider the simplest situation where R has only two layers, that is, it defines an affine transformation from R 1024 to R 1024 . Therefore, this dataset is in fact a 1024-dimension Gaussian distribution with randomly initialized mean and covariance. We plot the quantitative results in <ref type="figure" target="#fig_0">Figure 10</ref>. The results show that GAN training can have difficult in learning an affine transformation.  3) Varying the training set size: Now that we have access to infinite training data, we are able to study the influence the training set size has on the quantitative metrics and show the results in <ref type="figure" target="#fig_0">Figure 11</ref>. In this set of experiments, we have a MIX+GAN consisting of 3 generators and 3 discriminators, each of which has 5 layers and 1024 neurons in every hidden layer. There are infinite samples in the test set. The only factor of variation is the training set size. The results show that GANs perform worse with smaller training sets. On the contrary, the GAN trained on the largest training set preforms among the best in terms of all the metrics. We can see that the distances to the training set is larger with smaller training set size. This phenomenon is not straightforward as some would believe that it is easier for the generator(s) to overfit smaller training sets. A possible explanation is that with fewer training data, the discriminator(s) can memorized the training set and reject fake samples more easily, providing less informative feedbacks to the generator. This explanation is consistent with the one in Session 4.2 of <ref type="bibr" target="#b10">[11]</ref>.  Note that the dimension of our data is 1024 = 32 × 32, which is the same as the spatial dimension of the CIFAR-10 dataset <ref type="bibr" target="#b35">[36]</ref>. However, the CIFAR-10 dataset is more complex and consists of only 50,000 training images. Therefore, one can expect a performance boost when there are more training data for the training of GANs on CIFAR-10 or other small-scale image datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. extended experiments on CIFAR-10</head><p>In this section, we will show that the lessons we learned from artificial datasets apply to realistic datasets. Inspired by our empirical finding on the artificial datasets that increasing the mixture size can improve the performance of GANs, we modify MIX+GAN and train mixtures of GANs on the CIFAR-10 <ref type="bibr" target="#b35">[36]</ref> dataset. <ref type="figure" target="#fig_0">Fig. 12</ref>: Illustration of the generation and discrimination of fake samples when there are 5 generators and 5 discriminators distributed across 5 devices. The input noise to each generator is omitted.</p><formula xml:id="formula_14">D D D D D G G G G G V V V V V</formula><p>Since the time and space complexity of MIX+GAN is O(n G n D ), it is computationally infeasible to train very large mixtures of GANs. Thus, we propose to use a modified version of MIX+GAN. We assume that w i is uniformly distributed (which is true for the data distribution of CIFAR-10 and many other datasets). The batch generated by each G i is split into n D parts uniformly and fed to different discriminators. Therefore, the actual batch size for each generator and each discriminator remains unchanged, but each discriminator can receive samples from different generators. Inspired by the finding that different generators can capture different modes in a distribution, we do not make each generator generate samples for 10 classes, but max{10/n G , 1} classes, which can ease the difficulty of generation for each generator. In this way, the generators can be viewed as a mixture of experts <ref type="bibr" target="#b36">[37]</ref> and the discriminators can be viewed as an ensemble of discriminative models. We use a model-parallelism setting where generators and discriminators are distributed across different devices. If we have n GPU/TPU devices, then G i and D j are allocated to device (i−1 mod n)+1 and device (j −1 mod n)+1 respectively. In this way, there is no need to synchronize parameters across different devices and load balance can be achieved if both n G and n D are divisible by n. <ref type="figure" target="#fig_0">Figure 12</ref> illustrates the flow of the generation and discrimination of fake samples when there are 5 generators and 5 discriminators distributed across 5 devices.</p><p>For CIFAR-10, We use MHingeGAN <ref type="bibr" target="#b37">[38]</ref> as the base model. MHingeGAN is based on BigGAN <ref type="bibr" target="#b10">[11]</ref> but uses multi-class hinge losses. In a MHingeGAN, D is a (K + 1)class classifier where class 0 represents fake data and class 1 to class K represent the K classes in the dataset. The intuition behind the multi-class hinge loss is to make the affinity of D for the target class to be by a margin of at least 1 over the other classes. The loss for D is</p><formula xml:id="formula_15">L D = L real,M H + L f ake,M H (10) = E (x,y)∼Pr [max(0, 1 − D y (x) + D ¬y (x))]<label>(11)</label></formula><formula xml:id="formula_16">+ E (x,y)∼Pg [max(0, 1 − D 0 (x) + D ¬0 (x))]<label>(12)</label></formula><p>where D y (x) is the y-th element of the output vector D(x) and represents D's affinity for class y given input x, D ¬y (x) is D's highest affinity for any class that is not y, i.e., D ¬y (x) = max D k =y (x), k = 0, 1, 2, ..., K.</p><p>The loss for G is a combination of the multi-class hinge loss <ref type="bibr" target="#b12">(13)</ref> and a feature matching loss</p><formula xml:id="formula_17">L G,M H = E (x,y)∼Pg [max(0, 1 − D y (x) + D ¬y (x))]</formula><formula xml:id="formula_18">L G,F M = E x∼Pg [D f eat (x))]−E x∼Pr [D f eat (x))] 1 (14)</formula><p>where D f eat (x) is the feature of x after the last pooling layer of D. Different from <ref type="bibr" target="#b37">[38]</ref>, the loss we use for G is</p><formula xml:id="formula_19">L G = L G,M H + λL G,F M<label>(15)</label></formula><p>where λ = 0.05. Our network architectures are the same as <ref type="bibr" target="#b37">[38]</ref>. We use shared embedding, hierarchical input noise, and moving average of the weights for G as in BigGAN <ref type="bibr" target="#b10">[11]</ref>. The dimension of the input noise z is 80. The batch size for each generator and each discriminator is 50. We use the Adam optimizer <ref type="bibr" target="#b29">[30]</ref> with β 1 = 0, β 2 = 0.9 and a learning rate of 0.0002 for all Gs and Ds. The proposed models are trained for 100, 000 iterations. There are 4 discriminator updates and 1 generator update per iteration. The training of a mixture of 10 generators and 10 discriminators takes 1.5 days with 5 Nvidia GTX 1080Ti GPUs and 1 day with a TPU-V3. We show the supervised and unsupervised Inception Score and FID in <ref type="table" target="#tab_3">Table I and Table II</ref> respectively. We refer to our method as "MIX-GAN", to distinguish from MIX+GAN. Note that the "GAN" can be substituted by the name of a specific GAN model. We evaluate the Inception Score and the FID with 50,000 samples from each distribution. Since the test set of CIFAR-10 has only 10,000 samples, it is repeated 5 times (which does not change the moments used for calculating FID). Using 10 generators and 10 discriminators, we improve the state-ofthe-art IS and FID on CIFAR-10 significantly.</p><p>A random sample of a supervised MIX-MHingeGAN with 10 generators and 10 discriminators is shown in <ref type="figure" target="#fig_0">Figure 13</ref>.</p><p>Since the multi-class hinge loss is only applicable for conditional image generation, we use BigGAN <ref type="bibr" target="#b10">[11]</ref> as the   We show samples generated by an unsupervised MIX-BigGAN in <ref type="figure" target="#fig_0">Figure 14</ref>. To some extent, the 10 generators can learn different concepts automatically without label supervision, although they do not correspond to the 10 classes perfectly. VI. Conclusions and Future Work In this work, we explore different distance measures to investigate whether GAN training succeeds in learning the distribution. Our empirical results show that even when the distances between P g and P r are short, there exists a simple classifier with a model complexity similar to the discriminator that can distinguish P g and P r accurately. It suggests that P g and P r have little non-negligible overlapping manifold <ref type="bibr" target="#b2">[3]</ref>. Empirically, we also find that even when an optimal set of generator parameters exists, GAN training fails to find it. Therefore, it remains an open question whether GANs should be replaced by nonadversarial generative models (e.g., <ref type="bibr" target="#b44">[45]</ref>- <ref type="bibr" target="#b48">[49]</ref>).</p><p>In our experiments on the synthetic datasets, increasing the size of the training set can improve the performance of GANs, even when it is already very large. On the other hand, a small training set can negatively affect GANs. Therefore, current datasets might not be large enough to make GANs learn the real data distribution or even result in overfitting.</p><p>Our experimental results show that training a mixture of GANs is more beneficial than simply increasing the complexity of standalone networks (that are sufficiently complex) for modeling multi-modal data. It is an interesting topic to devise different ways to combine models in the mixtures. It is also promising to measure and promote the diversity of the ensemble <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref> of discriminators.</p><p>Finally, while current state-of-the-art GAN models such as BigGAN <ref type="bibr" target="#b10">[11]</ref>, CR-BigGAN <ref type="bibr" target="#b15">[16]</ref> and LOGAN <ref type="bibr" target="#b14">[15]</ref> use a number of TPU cores that is the same as the height or width of the images, we are not able to conduct such large-scale experiments. But we believe that with more computing power, a large mixture of GANs can be trained on datasets such as ImageNet 128 × 128 and improve current state-of-the-arts.</p><p>Appendix A Proof of Proposition 1 Proposition 1. Let J be a deterministic classifier for samples from two distributions P r and P g with equal prior probabilities. Let δ(P r , P g ) be the total variation distance between P r and P g , then</p><formula xml:id="formula_20">δ(P r , P g ) ≥ 2E[J acc ] − 1<label>(16)</label></formula><p>Proof. Without loss of generality, assume that the label y of a sample point x equals 1 if x is from P r and 0 otherwise. Let J opt be an optimal classifier with the highest expected accuracy. For all x such that p r (x) + p g (x) &gt; 0, we have P (y = 1|x) =  </p><p>It follows that δ(P r , P g ) ≥ 2E[J acc ] − 1.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>In our projection method, all the data points are projected from the 1024-dimensional space onto the plane that a, b and c lie in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Projections of real data (red dots) and samples (blue dots) generated by "MIX+GAN" with different mixtures of models. "nGmD" indicates that there are n generators and m discriminators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>D(x r ) − D(x g )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Comparisons of MIX+GANs with different components for generating mixtures of 3 Gaussians. We evalate the Fréchet distance during training and train the Judge and the independent critic after the training of WGAN-GP. For all the metrics, lower is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Projections of real data (red dots) and samples (blue dots) generated by different generators of a MIX+GAN with 2 generators and 2 discriminators trained on the 2-Gaussians dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Projections of real data (red dots) and samples (blue dots) generated by different generators of a MIX+GAN with 3 generators and 3 discriminators trained on the 3-Gaussians dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Projections of real data (red dots) and samples (blue dots) generated by different generators of a MIX+GAN with 4 generators and 4 discriminators trained on the 4-Gaussians dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 :</head><label>7</label><figDesc>Projections of real data (red dots) and samples generated by different generators (blue dots) of a MIX+GAN of 10 generators and 10 discriminators trained on the 3-Gaussians dataset. information about the input and do not need to be larger. D(x r ) − D(x g )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 :</head><label>8</label><figDesc>Quantitative results of varying the depth of the networks. "n layers" indicates that there are n layers in both the generator and the discriminator. For all the metrics, lower is better. D(x r ) − D(x g )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 :</head><label>9</label><figDesc>Quantitative results of varying the width of the networks. The numbers in the legends indicate the numbers of neurons in each hidden layer of and the discriminator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>D(x r ) − D(x g )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 :</head><label>10</label><figDesc>Results of the dataset generated by a network R. nG(l)mD indicates that there are n generators of l layers and m discriminators (of 5 layers by default). For all the metrics, lower is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 :</head><label>11</label><figDesc>D(x r ) − D(x g ) Results on the 3 Gaussians dataset when varying the training set size. The numbers in the legends indicate the training set sizes. For all the metrics, lower is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 14 :</head><label>14</label><figDesc>CIFAR-10 samples generated by our unsupervised model with 10 Gs and 10 Ds. Samples in different columns are generated by different generators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>pr(x)    pr(x)+pg(x)  and P (y = 0|x) = pg(x)pr(x)+pg(x) . Then there exists a J opt that predicts J(x) = 1 if p r (x) ≥ p g (x) and J(x) = 0 if p r (x) &lt; p g (x). Therefore, E[J acc ] ≤ E[J opt acc ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>−</head><label></label><figDesc>min{p r (x), p g (x)} dx + |p r (x) − p g (x)|dx + r , P g ) + 1 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE I :</head><label>I</label><figDesc>Supervised Inception Scores and FIDs from P g to the empirical distributions of the training set and the test set of CIFAR-10 Fig. 13: CIFAR-10 samples generated by our supervised model with 10 Gs and 10 Ds. Samples in different columns are generated by different generators.base model for unconditional image generation. We find that the performance of the unconditional MIX-BigGAN degrades after some iterations and thus report the IS and FID at iteration 60, 000 before it degrades.</figDesc><table><row><cell>Method</cell><cell cols="3">IS FID(train) FID(test)</cell></row><row><cell>PGGAN [21]</cell><cell>8.80±0.05</cell><cell>-</cell><cell>-</cell></row><row><cell>SN-GAN [9]</cell><cell>8.22±0.05</cell><cell>21.7</cell><cell>-</cell></row><row><cell>AutoGAN [44]</cell><cell>8.55</cell><cell>12.42</cell><cell>-</cell></row><row><cell>NCSN [45]</cell><cell>8.87±0.12</cell><cell>25.32</cell><cell>-</cell></row><row><cell>CR-GAN [16]</cell><cell>8.40</cell><cell>14.56</cell><cell>-</cell></row><row><cell>MIX-BigGAN,10G10D(ours)</cell><cell>9.67±0.08</cell><cell>8.17</cell><cell>10.26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE II :</head><label>II</label><figDesc>Unsupervised Inception Scores and FIDs from P g to the empirical distributions of the training set and the test set of CIFAR-10</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported with Cloud TPUs from Google's TensorFlow Research Cloud (TFRC). Special thanks go to Dr. Kun Huang who helped revise an early draft.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B Network architectures</head><p>In <ref type="table">Table III</ref> and IV, we list the network architectures we use for CIFAR-10.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">Nips 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2016 Workshop on Adversarial Training. In review for ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generalization and equilibrium in generative adversarial nets (gans)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="224" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stabilizing training of generative adversarial networks through regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2018" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Least squares generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Paul</forename><surname>Smolley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2794" to="2802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Wasserstein gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshida</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1QRgziT" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Which training methods for gans do actually converge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3478" to="3487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1xsqj09Fm" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Do gans actually learn the distribution? an empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08224</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Large scale adversarial representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02544</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Logan: Latent optimisation for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00953</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Consistency regularization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative multiadversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Byk-VI9eg" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-agent diverse generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kulharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8513" to="8521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MGAN: Training generative adversarial nets with multiple generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkmu5b0a" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hk99zCeAb" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multidomain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8789" to="8797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Comparison of maximum likelihood and gan-based training of real nvps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05263</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A note on the inception score</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01973</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The fréchet distance between multivariate normal distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dowson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Landau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of multivariate analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="450" to="455" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Csiszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Körner</surname></persName>
		</author>
		<title level="m">Information theory: coding theorems for discrete memoryless systems</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">How to train a gan? tips and tricks to make gans work</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<ptr target="https://github.com/soumith/ganhacks" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Layer normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="901" to="901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer, Tech. Rep</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kavalerov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Czaja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<idno>arXiv: Learning</idno>
		<title level="m">cgans with multihinge loss</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2642" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Stacked generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Poursaeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5077" to="5086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Classsplitting generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Grinblat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Uzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Granitto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07359</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">cGANs with projection discriminator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ByS1VpgRZ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving the improved training of wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJx9GQb0-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Autogan: Neural architecture search for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="215" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Generating diverse high-fidelity images with vq-vae-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00446</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Jacobsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02735</idno>
		<title level="m">Residual flows for invertible generative modeling</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Neural network ensembles, cross validation, and active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vedelsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="231" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="207" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
