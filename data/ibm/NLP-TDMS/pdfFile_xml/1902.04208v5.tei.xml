<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MaCow: Masked Convolutional Generative Flow</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
							<email>xuezhem@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Kong</surname></persName>
							<email>xiangk@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
							<email>shanghaz@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
							<email>hovy@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MaCow: Masked Convolutional Generative Flow</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Flow-based generative models, conceptually attractive due to tractability of the exact log-likelihood computation and latent-variable inference as well as efficiency in training and sampling, has led to a number of impressive empirical successes and spawned many advanced variants and theoretical investigations. Despite computational efficiency, the density estimation performance of flow-based generative models significantly falls behind those of state-of-the-art autoregressive models. In this work, we introduce masked convolutional generative flow (MACOW), a simple yet effective architecture for generative flow using masked convolution. By restricting the local connectivity to a small kernel, MACOW features fast and stable training along with efficient sampling while achieving significant improvements over Glow for density estimation on standard image benchmarks, considerably narrowing the gap with autoregressive models.</p><p>In their pioneering work, Dinh et al. (2014) first proposed Non-linear Independent Component Estimation (NICE) to apply flow-based models for modeling complex high-dimensional densities. RealNVP <ref type="bibr" target="#b5">(Dinh et al., 2016)</ref> extended NICE with a more flexible invertible transformation to experiment with natural images. However, these flow-based generative models resulted in worse density estimation performance compared to state-of-the-art autoregressive models, and are incapable of realistic synthesis of large images compared to GANs (Karras et al., 2018;<ref type="bibr" target="#b1">Brock et al., 2019)</ref>. Recently, <ref type="bibr" target="#b15">Kingma and Dhariwal (2018)</ref> proposed Glow as a generative flow with invertible 1 × 1 convolutions, which significantly improved the density estimation performance on natural images. Importantly, they demonstrated that flow-based generative models optimized towards the plain 33rd</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Unsupervised learning of probabilistic models is a central yet challenging problem. Deep generative models have shown promising results in modeling complex distributions such as natural images <ref type="bibr" target="#b26">(Radford et al., 2015)</ref>, audio  and text <ref type="bibr" target="#b0">(Bowman et al., 2015)</ref>. Multiple approaches emerged in recent years, including Variational Autoencoders (VAEs) <ref type="bibr" target="#b13">(Kingma and Welling, 2014)</ref>, Generative Adversarial Networks (GANs) <ref type="bibr" target="#b7">(Goodfellow et al., 2014)</ref>, autoregressive neural networks <ref type="bibr" target="#b17">(Larochelle and Murray, 2011;</ref>, and flow-based generative models <ref type="bibr" target="#b4">(Dinh et al., 2014</ref><ref type="bibr" target="#b5">(Dinh et al., , 2016</ref><ref type="bibr" target="#b15">Kingma and Dhariwal, 2018)</ref>. Among these, flow-based generative models gained popularity for this capability of estimating densities of complex distributions, efficiently generating high-fidelity syntheses, and automatically learning useful latent spaces.</p><p>Flow-based generative models typically warp a simple distribution into a complex one by mapping points from the simple distribution to the complex data distribution through a chain of invertible transformations with Jacobian determinants that are efficient to compute. This design guarantees that the density of the transformed distribution can be analytically estimated, making maximum likelihood learning feasible. Flow-based generative models have spawned significant interests for improving and analyzing its algorithms both theoretically and practically, and applying them to a wide range of tasks and domains.</p><p>likelihood-based objective are capable of generating realistic high-resolution natural images efficiently. <ref type="bibr" target="#b25">Prenger et al. (2018)</ref> investigated applying flow-based generative models to speech synthesis by combining Glow with WaveNet . Ziegler and Rush (2019) adopted variational inference to apply generative flows to discrete sequential data. Unfortunately, the density estimation performance of Glow on natural images remains behind autoregressive models, such as PixelRNN/CNN <ref type="bibr" target="#b29">Salimans et al., 2017)</ref>, Image Transformer <ref type="bibr" target="#b23">(Parmar et al., 2018)</ref>, PixelSNAIL  and SPN <ref type="bibr" target="#b20">(Menick and Kalchbrenner, 2019)</ref>. There is also some work <ref type="bibr" target="#b28">(Rezende and Mohamed, 2015;</ref><ref type="bibr" target="#b14">Kingma et al., 2016;</ref><ref type="bibr" target="#b35">Zheng et al., 2017)</ref> trying to apply flow to variational inference.</p><p>In this paper, we propose a novel architecture of generative flow, masked convolutional generative flow (MACOW), which leverages masked convolutional neural networks . The bijective mapping between input and output variables is easily established while the computation of the determinant of the Jacobian remians efficient. Compared to inverse autoregressive flow (IAF) <ref type="bibr" target="#b14">(Kingma et al., 2016)</ref>, MACOW offers stable training and efficient inference and synthesis by restricting the local connectivity in a small "masked" kernel as well as large receptive fields by stacking multiple layers of convolutional flows and using rotational ordering masks ( §3.1). We also propose a finegrained version of the multi-scale architecture adopted in previous flow-based generative models to further improve the performance ( §3.2). Experimenting with four benchmark datasets for images, CIFAR-10, ImageNet, LSUN, and CelebA-HQ, we demonstrate the effectiveness of MACOW as a density estimator by consistently achieving significant improvements over Glow on all the three datasets. When equipped with the variational dequantization mechanism <ref type="bibr" target="#b8">(Ho et al., 2019)</ref>, MACOW considerably narrows the gap of the density estimation with autoregressive models ( §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Flow-based Generative Models</head><p>In this section, we first setup notations, describe flow-based generative models, and review <ref type="bibr">Glow (Kingma and Dhariwal, 2018)</ref> as it is the foundation for MACOW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notations</head><p>Throughout the paper, uppercase letters represent random variables and lowercase letters for realizations of their corresponding random variables. Let X ∈ X be the random variables of the observed data, e.g., X is an image or a sentence for image and text generation, respectively.</p><p>Let P denote the true distribution of the data, i.e., X ∼ P , and D = {x 1 , . . . , x N } be our training sample, where x i , i = 1, . . . , N, are usually i.i.d. samples of X. Let P = {P θ : θ ∈ Θ} denote a parametric statistical model indexed by the parameter θ ∈ Θ, where Θ is the parameter space. p denotes the density of the corresponding distribution P . In the deep generative model literature, deep neural networks are the most widely used parametric models. The goal of generative models is to learn the parameter θ such that P θ can best approximate the true distribution P . In the context of maximum likelihood estimation, we minimize the negative log-likelihood of the parameters with:</p><formula xml:id="formula_0">min θ∈Θ 1 N N i=1 − log p θ (x i ) = min θ∈Θ E P (X) [− log p θ (X)],<label>(1)</label></formula><p>whereP (X) is the empirical distribution derived from training data D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Flow-based Models</head><p>In the framework of flow-based generative models, a set of latent variables Z ∈ Z are introduced with a prior distribution p Z (z), which is typically a simple distribution like a multivariate Gaussian.</p><p>For a bijection function f : X → Z (with g = f −1 ), the change of the variable formula defines the model distribution on X by</p><formula xml:id="formula_1">p θ (x) = p Z (f θ (x)) det ∂f θ (x) ∂x ,<label>(2)</label></formula><p>where ∂f θ (x) ∂x is the Jacobian of f θ at x.</p><p>The generative process is defined straightforwardly as the following:</p><formula xml:id="formula_2">z ∼ p Z (z) x = g θ (z).<label>(3)</label></formula><p>Flow-based generative models focus on certain types of transformations f θ that allow the inverse functions g θ and Jacobian determinants to be tractable to compute. By stacking multiple such invertible transformations in a sequence, which is also called a (normalizing) flow (Rezende and Mohamed, 2015), the flow is then capable of warping a simple distribution (p Z (z)) into a complex one (p(x)) through:</p><formula xml:id="formula_3">X f1 ←→ g1 H 1 f2 ←→ g2 H2 f3 ←→ g3 · · · f K ←→ g K Z,</formula><p>where f = f 1 • f 2 • · · · • f K is a flow of K transformations. For brevity, we omit the parameter θ from f θ and g θ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Glow</head><p>Recently, several types of invertible transformations emerged to enhance the expressiveness of flows, among which Glow (Kingma and Dhariwal, 2018) has stood out for its simplicity and effectiveness on both density estimation and high-fidelity synthesis. The following briefly describes the three types of transformations that comprise Glow.</p><p>Actnorm. <ref type="bibr" target="#b15">Kingma and Dhariwal (2018)</ref> proposed an activation normalization layer (Actnorm) as an alternative for batch normalization <ref type="bibr" target="#b10">(Ioffe and Szegedy, 2015)</ref> to alleviate the challenges in model training. Similar to batch normalization, Actnorm performs an affine transformation of the activations using a scale and bias parameter per channel for 2D images, such that</p><formula xml:id="formula_4">y i,j = s x i,j + b,</formula><p>where both x and y are tensors of shape [h × w × c] with spatial dimensions (h, w) and channel dimension c.</p><p>Invertible 1 × 1 convolution. To incorporate a permutation along the channel dimension, Glow includes a trainable invertible 1 × 1 convolution layer to generalize the permutation operation as:</p><formula xml:id="formula_5">y i,j = W x i,j ,</formula><p>where W is the weight matrix with shape c × c.</p><p>Affine Coupling Layers. Following <ref type="bibr" target="#b5">Dinh et al. (2016)</ref>, Glow includes affine coupling layers in its architecture of:</p><formula xml:id="formula_6">x a , x b = split(x) y a = x a y b = s(x a ) x b + b(x a ) y = concat(y a , y b )</formula><p>, where s(x a ) and b(x a ) are outputs of two neural networks with x a as input. The split() and concat() functions perform operations along the channel dimension.</p><p>From this designed architecture of Glow, we see that interactions between spatial dimensions are incorporated only in the coupling layers. The coupling layer, however, is typically costly for memory resources, making it infeasible to stack a significant number of coupling layers into a single model, especially when processing high-resolution images. The main goal of this work is to design a new type of transformation that simultaneously models the dependencies in both the spatial and channel dimensions while maintaining a relatively small memory footprint to improve the capacity of the generative flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Masked Convolutional Generative Flows</head><p>In this section, we describe the architectural components of the masked convolutional generative flow (MACOW). First, we introduce the proposed flow transformation using masked convolutions in §3.1. Then, we present a fine-grained version of the multi-scale architecture adopted by previous generative flows <ref type="bibr" target="#b5">(Dinh et al., 2016;</ref><ref type="bibr" target="#b15">Kingma and Dhariwal, 2018)</ref> in §3.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Flow with Masked Convolutions</head><p>Applying autoregressive models to normalizing flows has been previously explored in studies <ref type="bibr" target="#b14">(Kingma et al., 2016;</ref><ref type="bibr" target="#b22">Papamakarios et al., 2017)</ref>, with idea of sequentially modeling the input random variables in an autoregressive order to ensure the model cannot read input variables behind the current one:</p><formula xml:id="formula_7">y t = s(x &lt;t ) x t + b(x &lt;t ),<label>(4)</label></formula><p>where x &lt;t denotes the input variables in x positioned ahead of x t in the autoregressive order. s() and b() are two autoregressive neural networks typically implemented using spatial masks <ref type="bibr" target="#b6">(Germain et al., 2015;</ref>.</p><p>Despite effectiveness in high-dimensional space, autoregressive flows suffer from two crucial problems: (1) The training procedure is unstable when stacking multiple layers to increase the flow capacities for complex distributions.</p><p>(2) Inference and synthesis are inefficient, due to the nonparallelizable inverse function.</p><p>We propose to use masked convolutions to restrict the local connectivity in a small "masked" kernel to address these two problems. The two autoregressive neural networks, s() and b(), are implemented with one-layer masked convolutional networks with small kernels (e.g. 2 × 5 in <ref type="figure" target="#fig_0">Figure 1</ref>) to ensure they only read contexts in a small neighborhood based on:</p><formula xml:id="formula_8">s(x &lt;t ) = s(x t ), b(x &lt;t ) = b(x t ),<label>(5)</label></formula><p>where x t denotes the input variables, restricted in a small kernel, on which x t depends. By using masks in rotational ordering and stacking multiple layers of flows, the model captures a large receptive field (see <ref type="figure" target="#fig_0">Figure 1</ref>), and models dependencies in both the spatial and channel dimensions.</p><p>Efficient Synthesis. As discussed above, synthesis from autoregressive flows is inefficient since the inverse must be computed by sequentially traversing through the autoregressive order. In the context of 2D images with shape [h × w × c], the time complexity of synthesis is quadratic, i.e.  <ref type="figure" target="#fig_0">Figure 1)</ref>. ii) the Emerging Convolutional Flow, proposed as an alternative to the invertible 1 × 1 convolution in Glow, is basically a linear transformation with masked convolutions, which does not introduce "nonlinearity" to the random variables. MACOW, however, introduces such nonlinearity similar to the coupling layers. </p><formula xml:id="formula_9">O(h × w × NN(h, w, c)), where NN(h, w, c) is</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Fine-grained Multi-Scale Architecture</head><p>Dinh et al. <ref type="formula" target="#formula_0">(2016)</ref> proposed a multi-scale architecture using a squeezing operation, which has been demonstrated to be helpful for training very deep flows. In the original multi-scale architecture, the model factors out half of the dimensions at each scale to reduce computational and memory costs. In this paper, inspired by the size upscaling in subscale ordering <ref type="bibr" target="#b20">(Menick and Kalchbrenner, 2019</ref>) that generates an image as a sequence of sub-images with equal size, we propose a fine-grained multi-scale architecture to improve model performance further. In this fine-grained multi-scale architecture, each scale consists of M/2 blocks, and after each block, the model splits out 1/M dimensions of the input 1 . <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the graphical specification of the two architecture versions. Note that the fine-grained architecture reduces the number of parameters compared with the original architecture with the same number of flow layers. Experimental improvements demonstrate the effectiveness of the fine-grained multi-scale architecture ( §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our MACOW model on both low-resolution and high-resolution datasets. For a step of MACOW, we use T = 2 masked convolution units, and the Glow step is the same as that described in <ref type="bibr" target="#b15">Kingma and Dhariwal (2018)</ref> where an ActNorm is followed by an Invertible 1 × 1 convolution, which is followed by a coupling layer. Each coupling layer includes three convolution layers where the first and last convolutions are 3 × 3, while the center convolution is 1 × 1. For low-resolution images, we use affine coupling layers with 512 hidden channels, while for high-resolution images we use additive layers with 256 hidden channels to reduce memory cost. ELU <ref type="bibr" target="#b3">(Clevert et al., 2015)</ref> is used as the activation function throughout the flow architecture. For variational dequantization, the dequantization noise distribution q φ (u|x) is modeled with a conditional MACOW with shallow architecture. Additional details on architectures, results, and analysis of the conducted experiments are provided in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Low-Resolution Images</head><p>We begin our experiments with an evaluation of the density estimation performance of MACOW on two low-resolution image datasets that are commonly used to evaluate the deep generative models: CIFAR-10 with images of size 32 × 32 <ref type="bibr" target="#b16">(Krizhevsky and Hinton, 2009</ref>) and the 64 × 64 downsampled version of ImageNet .</p><p>We perform experiments to dissect the effectiveness of each component of our MACOW model with ablation studies. The Org model utilizes the original multi-scale architecture, while the +fine-grained model augments the original one with the fine-grained multi-scale architecture proposed in §3.2. The  <ref type="bibr" target="#b27">(Reed et al., 2017</ref><ref type="bibr">) -3.70 PixelRNN (Oord et al., 2016</ref> 3.00 3.63 Gated PixelCNN  3.03 3.57 MAE <ref type="bibr" target="#b19">(Ma et al., 2019)</ref> 2.95 -PixelCNN++ <ref type="bibr" target="#b29">(Salimans et al., 2017)</ref> 2.92 -PixelSNAIL  2.85 3.52 SPN <ref type="bibr" target="#b20">(Menick and Kalchbrenner, 2019)</ref> -3.52</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Flow-based</head><p>Real NVP <ref type="bibr" target="#b5">(Dinh et al., 2016)</ref> 3.49 3.98 Glow <ref type="bibr" target="#b15">(Kingma and Dhariwal, 2018)</ref> 3.35 3.81 Flow++: Unif <ref type="bibr" target="#b8">(Ho et al., 2019)</ref> 3.29 -Flow++: Var <ref type="bibr" target="#b8">(Ho et al., 2019)</ref> 3.09 3.69 MACOW: Org 3.31 3.78 MACOW: +fine-grained 3.28 3.75 MACOW: +var 3.16 3.69 +var model further implements the variational dequantization on the top of +fine-grained to replace the uniform dequantization (see Appendix A for details). For each ablation, we slightly adjust the number of steps in each level so that all the models have a similar number of parameters. <ref type="table" target="#tab_1">Table 1</ref> provides the density estimation performance for different variations of our MACOW model along with the top-performing autoregressive models (first section) and flow-based generative models (second section). First, on both datasets, fine-grained models outperform Org ones, demonstrating the effectiveness of the fine-grained multi-scale architecture. Second, with the uniform dequantization, MACOW combined with the fine-grained multi-scale architecture significantly improves the performance over Glow on both datasets, and obtains slightly better results than Flow++ on CIFAR-10. In addition, with variational dequantization, MACOW achieves comparable result in bits/dim with Flow++ on ImageNet 64 × 64. On CIFAR-10, however, the performance of MaCow is around 0.07 bits/dim behind Flow++.</p><p>Compared with the state-of-the-art autoregressive generative models PixelSNAIL  and SPN <ref type="bibr" target="#b20">(Menick and Kalchbrenner, 2019)</ref>, the performance of MACOW is approximately 0.31 bits/dim worse on CIFAR-10 and 0.14 worse on ImageNet 64 × 64. Further improving the density estimation performance of MACOW on natural images is left to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">High-Resolution Images</head><p>We next demonstrate experimentally that our MACOW model is capable of high fidelity samples at high-resolution. Following Kingma and Dhariwal (2018), we choose the CelebA-HQ dataset <ref type="bibr" target="#b11">(Karras et al., 2018)</ref>, which consists of 30,000 high-resolution images from the CelebA dataset <ref type="bibr" target="#b18">(Liu et al., 2015)</ref>, and the LSUN <ref type="bibr" target="#b34">(Yu et al., 2015)</ref> datasets including categories bedroom, tower and church. We train our models on 5-bit images with the fine-grained multi-scale architecture and both the uniform and variational dequantization. For each model, we adjust the number of steps in each level so that all the models have similar numbers of parameters with Glow for a fair comparison.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Density Estimation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Image Generation</head><p>Consistent with previous work on likelihood-based generative models <ref type="bibr" target="#b23">(Parmar et al., 2018;</ref><ref type="bibr" target="#b15">Kingma and Dhariwal, 2018)</ref>, we found that sampling from a reduced-temperature model often results in higher-quality samples. <ref type="figure" target="#fig_2">Figure 3</ref> showcases some random samples for 5-bit CelebA-HQ 256 × 256 with temperature 0.7 and LSUN 128 × 128 with temperature 0.9. The images are extremely high  <ref type="bibr" target="#b30">(Theis et al., 2016)</ref>. More samples of images, including samples of low-resolution ones, are provided in Appendix C 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison on Synthesis Speed</head><p>In this section, we compare the synthesis speed of MACOW at test time with that of Glow (Kingma and Dhariwal, 2018), Masked Autoregressive Flows (MAF) <ref type="bibr" target="#b22">(Papamakarios et al., 2017)</ref> and Emerging Convolutions <ref type="bibr" target="#b9">(Hoogeboom et al., 2019)</ref>. Following <ref type="bibr" target="#b9">Hoogeboom et al. (2019)</ref>, we measure the time to sample a datapoint when computed in mini-batchs with size 100. For fair comparison, we reimplemented Glow using PyTorch <ref type="bibr" target="#b24">(Paszke et al., 2017)</ref>, and all experiments are conducted on a single NVIDIA TITAN X GPU. <ref type="table" target="#tab_4">Table 3a</ref> shows the sampling speed of MACOW on CIFAR-10, together with that of the baselines. MACOW is 7.3 times slower than Glow, much faster than Emerging Convolution and MAF, whose factors are 360 and 600 respectively. The sampling speed of MACOW on datasets with different image sizes is shown in <ref type="table" target="#tab_4">Table 3b</ref>. We see that the time of synthesis increases approximately linearly with the increase of image resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a new type of generative flow, coined MACOW, which exploits masked convolutional neural networks. By restricting the local dependencies in a small masked kernel, MACOW boasts fast and stable training as well as efficient sampling. Experiments on both lowand high-resolution benchmark datasets of images show the capability of MACOW on both density estimation and high-fidelity generation, achieving state-of-the-art or comparable likelihood as well as its superior quality of samples compared to previous top-performing models 3 A potential direction for future work is to extend MACOW to other forms of data, in particular text, on which no attempt (to the best of our knowledge) has been made to apply flow-based generative models. Another exciting direction is to combine MACOW with variational inference to automatically learn meaningful (low-dimensional) representations from raw data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: MaCow: Masked Convolutional Generative Flow</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Dequantization</head><p>As described in §2, generative flows are defined on continuous random variables. Many real-world datasets, however, are recordings of discrete representations of signals, and fitting a continuous density model to discrete data produces a degenerate solution that places all probability mass on discrete datapoints <ref type="bibr" target="#b31">(Uria et al., 2013;</ref><ref type="bibr" target="#b8">Ho et al., 2019)</ref>. A common solution to this problem is "dequantization" that converts the discrete data distribution into a continuous one.</p><p>Specifically, in the context of natural images, each dimension (pixel) of the discrete data x takes on values in {0, 1, . . . , 255}. The dequatization process adds continuous random noise u to x, resulting a continuous data point of:</p><formula xml:id="formula_10">y = x + u,<label>(1)</label></formula><p>where u ∈ [0, 1) d is continuous random noise taking values from interval [0, 1). By modeling the density of Y ∈ Y with p θ (y), the distribution of X is defined as:</p><formula xml:id="formula_11">P θ (x) = Y p θ (y) dy = [0,1) d p θ (x + u) du.</formula><p>( <ref type="formula" target="#formula_1">2)</ref> By restricting the range of u in [0, 1), the mapping between y and a pair of x and u is bijective. Thus, we have p θ (y) = p θ (x + u) = p θ (x, u).</p><p>By introducing a dequantization noise distribution q(u|x), the training objective in <ref type="formula" target="#formula_0">(1)</ref> can be re-written as:</p><formula xml:id="formula_12">E P (X) − log P θ (X) = E P (X) − log [0,1) d p θ (X, u) du = E P (X) E q(u|X) − log p θ (X, u) q(u|X) − KL q(u|X)||p θ (u|X) ≤ E P (X) E q(u|X) − log p θ (X, u) + E q(u|X) log q(u|X) = E p(Y ) − log p θ (Y ) + E P (X) E q(u|X) log q(u|X) ,<label>(3)</label></formula><p>where p(y) = P (x)q(u|x) is the distribution of the dequantized variable Y under the dequantization noise distribution q(u|X).</p><p>Uniform Dequantization. The most common dequantization method in prior work is uniform dequantization where the noise u is sampled from the uniform distribution Unif(0, 1) such that q(u|x) ∼ Unif(0, 1), ∀x ∈ X .</p><p>From <ref type="formula" target="#formula_2">(3)</ref>, we have</p><formula xml:id="formula_13">E P (X) [− log P θ (X)] ≤ E p(Y ) [− log p θ (Y )] ,</formula><p>as log q(u|x) = 0, ∀x ∈ X .</p><p>Variational Dequantization. As discussed in <ref type="bibr" target="#b8">Ho et al. (2019)</ref>, uniform dequantization directs p θ (y) to assign uniform density to unit hypercubes [0, 1) d , which is difficult for smooth distribution approximators. They proposed a parametric dequantization noise distribution q φ (u|x) with a training objective to optimize the evidence lower bound (ELBO) provided in <ref type="formula" target="#formula_2">(3)</ref>:</p><formula xml:id="formula_14">min θ,φ E p φ (Y ) [− log p θ (Y )] + E P (X) E q φ (u|X) [log q φ (u|X)] ,<label>(4)</label></formula><p>where p φ (y) = P (x)q φ (u|x). In this paper, we implemented both these two dequantization methods for our MACOW, as is detailed in §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experimental Details</head><p>B.1 Model details </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Optimization</head><p>Parameter optimization is performed with the Adam optimizer (Kingma and Ba, 2014) with β = (0.9, 0.999) and = 1e − 8. Warmup training is applied to all the experiments: the learning rate linearly increases to for 500 updates to the initial learning rate 1e − 3. Then we use exponential decay to decrease the learning rate with decay rate is 0.999997.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More samples from our experiments</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Visualization of the receptive field of four masked convolutions with rotational ordering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The architecture of the proposed MACOW model, where each step (a) consists of T units of ActNorm followed by two masked convolutions with rotational ordering, and a Glow step. This flow is combined with either an original multi-scale (b) or a fine-grained architecture (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a) 5-bit 256 × 256 CelebA-HQ samples with temperature 0.7; (b)(c)(d) 5-bit 128 × 128 LSUN church, tower and bedroom samples, with temperature 0.9, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Samples from 5-bit, 128×128 LSUN bedrooms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Samples from 5-bit, 128×128 LSUN church.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Samples from 5-bit, 128×128 LSUN towers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Synthetic celebrities sampled from 5-bit 256×256 CelebA-HQ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Samples from 8-bit imagenet 64×64 with uniform dequantization Samples from 8-bit imagenet 64×64 with variational dequantization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>the time of computing the outputs from the neural network s() and b() with input shape [h × w × c]. In our proposed flow with masked convolutions, computation of x i,j begins as soon as all x t are available, contrary to the autoregressive requirement that all x &lt;i,j must have been already computed. Moreover, at each step we only need to feed a slice of the image (with shape [h × kw × c] or [kh × w × c] depending on the direction of the mask) into s() and b(). Here [kh × kw × c] is the shape of the kernel in the convolution. Thus, the time complexity reduces significantly from quadratic to linear, which is O(h×NN(kh, w , c)) or O(w ×NN(kw , h, c)) for horizontal and vertical masks, respectively.DiscussionThe previous work closely related to MACOW is the Emerging Convolutions proposed in<ref type="bibr" target="#b9">Hoogeboom et al. (2019)</ref>. There are two main differences. i) the pattern of the mask is different.</figDesc><table /><note>Emerging Convolutions use "causal masks" (Oord et al., 2016) whose inverse function falls into a complete autoregressive transformation. In contrast, MACOW achieves significantly more efficient inference and sampling ( §4.3), due to the carefully designed masks (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Density estimation performance on CIFAR-10 32 × 32 and ImageNet 64 × 64. Results are reported in bits/dim.</figDesc><table><row><cell>Model</cell><cell cols="2">CIFAR-10 ImageNet-64</cell></row><row><cell>IAF VAE (Kingma et al., 2016)</cell><cell>3.11</cell><cell>-</cell></row><row><cell>Parallel Multiscale</cell><cell></cell><cell></cell></row><row><cell>Autoregressive</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Negative log-likelihood scores for 5-bit LSUN and CelebA-HQ datasets in bits/dim.</figDesc><table><row><cell>LSUN</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>illustrates the negative log-likelihood scores in bits/dim of two versions of MACOW on the 5-bit 128 × 128 LSUN and 256 × 256 CelebA-HQ datasets. With uniform dequantization, MACOW improves the log-likelihood over Glow from 1.03 bits/dim to 0.95 bits/dim on CelebA-HQ dataset. Equipped with variational dequantization, MACOW obtains 0.67 bits/dim, which is 0.06 bits/dim behind the state-of-the-art autoregressive generative model SPN<ref type="bibr" target="#b20">(Menick and Kalchbrenner, 2019)</ref> and significantly narrows the gap. On the LSUN datasets, MACOW with uniform dequantization outperforms Glow with 0.4 bits/dim on the bedroom category. With variational dequantization, the model achieves further improvements on all the three categories of LSUN datasets,</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>(a) Image synthesis speed on CIFAR10. Glow re-implemented in PyTorch is masked with †. ‡ denotes results shown in<ref type="bibr" target="#b9">Hoogeboom et al. (2019)</ref>. (b) Image synthesis speed of MACOW on datasets with different image sizes. The time is measured in milliseconds to sample a datapoint when computed in mini-batchs with size 100.</figDesc><table><row><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell></row><row><cell>CIFAR10</cell><cell cols="2">time (ms) Slow-down</cell><cell>Dataset</cell><cell cols="2">image size time (ms)</cell></row><row><cell>Glow  ‡</cell><cell>5</cell><cell>1.0</cell><cell>CIFAR10</cell><cell>32 × 32</cell><cell>38.7</cell></row><row><cell>MAF  ‡</cell><cell>3000</cell><cell>600.0</cell><cell>ImageNet</cell><cell>64 × 64</cell><cell>104.7</cell></row><row><cell>Emerging  ‡ Glow  †</cell><cell>1800 5.3</cell><cell>360.0 1.0</cell><cell cols="2">LSUN CelebA-HQ 256 × 256 128 × 128</cell><cell>267.9 434.2</cell></row><row><cell>MACOW</cell><cell>38.7</cell><cell>7.3</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">quality for non-autoregressive likelihood models, despite that maximum likelihood is a principle that</cell></row><row><cell cols="4">values diversity over sample quality in a limited capacity setting</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Hyper-parameters for MACOW in our experiments.</figDesc><table><row><cell>DataSet</cell><cell cols="3">Dequant Batch Size Levels</cell><cell>Depths per Level</cell><cell cols="2"># Param # Param Glow</cell></row><row><cell>CIFAR-10</cell><cell>Unif Var</cell><cell>512 512</cell><cell>3 3</cell><cell>[[12, 12], [12, 12], 12] [[12, 12], [12, 12], 12]</cell><cell>41.2M 43.5M</cell><cell>44.2M</cell></row><row><cell>ImageNet</cell><cell>Unif Var</cell><cell>160 160</cell><cell>4 4</cell><cell>[[16, 16], [16, 16], [12, 12], 12] [[16, 16], [16, 16], [12, 12], 12]</cell><cell>117.2M 122.5M</cell><cell>111.6M</cell></row><row><cell>LSUN</cell><cell>Unif Var</cell><cell>160 160</cell><cell>5 5</cell><cell>[[32, 32], [32, 32], [16, 16], [12, 12], 6] [[32, 32], [32, 32], [16, 16], [12, 12], 6]</cell><cell>166.6M 171.9M</cell><cell>198.1M</cell></row><row><cell>CelebA-HQ</cell><cell>Unif Var</cell><cell>40 40</cell><cell>6 6</cell><cell cols="2">[[24, 24], [16, 16], [16, 16], [8, 8], [4, 4], 2] 171.9M [[24, 24], [16, 16], [16, 16], [8, 8], [4, 4], 2] 177.3M</cell><cell>170.8M</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In our experiments, we set M = 4. Note that the original multi-scale architecture is a special case of the fine-grained version with M = 2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The reduced-temperature sampling is only applied to LSUN and CelebA-HQ 5-bits images, where MACOW adopts additive coupling layers. For CIFAR-10 and ImageNet 8-bits images, we sample with temperature 1.0. 3 https://github.com/XuezheMax/macow</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06349</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pixelsnail: An improved autoregressive generative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09763</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djork-Arné</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nice: Non-linear independent components estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<title level="m">Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Made: Masked autoencoder for distribution estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="881" to="889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS-2014)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Flow++: Improving flowbased generative models with variational dequantization and architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2722" to="2730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Emerging convolutions for generative normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2771" to="2780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2th International Conference on Learning Representations (ICLR-2014)</title>
		<meeting>the 2th International Conference on Learning Representations (ICLR-2014)<address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4743" to="4751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10236" to="10245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS-2011</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS-2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="29" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MAE: Mutual posterior-divergence regularization for variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunting</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Generating high fidelity images with subscale pixel networks and multidimensional upscaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pixel recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning (ICML-2016)</title>
		<meeting>International Conference on Machine Learning (ICML-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2338" to="2347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05751</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Image transformer. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Autodiff Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Waveglow: A flow-based generative network for speech synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00002</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parallel multiscale autoregressive density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><forename type="middle">Gómez</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Belov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2912" to="2921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.05770</idno>
		<title level="m">Variational inference with normalizing flows</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pixelcnn++: A pixelcnn implementation with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bulatov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR 2016)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rnade: The real-valued neural autoregressive density-estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benigno</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2175" to="2183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lsun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<title level="m">Construction of a largescale image dataset using deep learning with humans in the loop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<idno>abs/1711.02255</idno>
		<title level="m">Convolutional normalizing flows. CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Latent normalizing flows for discrete sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning (ICML-2019)</title>
		<meeting>International Conference on Machine Learning (ICML-2019)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
