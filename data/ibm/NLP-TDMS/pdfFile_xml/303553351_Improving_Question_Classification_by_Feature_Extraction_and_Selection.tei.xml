<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T08:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Question Classification by Feature Extraction and Selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Van-Tu</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Anh-Cuong</surname></persName>
							<email>leanhcuong@tdt.edu.vn</email>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Information Technology, Ton Duc</orgName>
								<orgName type="institution">Thang University</orgName>
								<address>
									<settlement>Ho Chi Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">VNU University of Engineering and Technology</orgName>
								<address>
									<addrLine>Ha Noi City</addrLine>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Question Classification by Feature Extraction and Selection</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Indian Journal of Science and Technology</title>
						<imprint>
							<biblScope unit="volume">9</biblScope>
							<biblScope unit="issue">17</biblScope>
						</imprint>
					</monogr>
					<idno type="DOI">10.17485/ijst/2016/v9i17/93160</idno>
					<note>*Author for correspondence17485/ijst/2016/v9i17/93160, May 2016 ISSN (Print) : 0974-6846 ISSN (Online) : 0974-5645</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Question classification is the task of predicting the entity type of the answering sentence for a given question in natural language. It plays an important role in finding or constructing accurate answers and therefore helps to improve quality of automated question answering systems. Different lexical, syntactical and semantic features was extracted automatically from a question to serve the classification in previous studies. However, combining all those features doesn&apos;t always give the best results for all types of questions. Different from previous studies, this paper focuses on the problem of how to extract and select efficient features adapting to each different types of question. We first propose a method of using a feature selection algorithm to determine appropriate features corresponding to different question types. Secondly, we design a new type of features, which is based on question patterns. We tested our proposed approach on the benchmark dataset TREC and using Support Vector Machines (SVM) for the classification algorithm. The experiment shows obtained results with the accuracies of 95.2% and 91.6% for coarse grain and fine grain data sets respectively, which are much better in comparison with the previous studies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Automated Question Answering has become an important research direction in natural language processing <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> . Its purpose is to seek an accurate and concise answer to a free-form factual question from a large collection of text data, rather than a full document, judged relevant as in standard information retrieval tasks. Although different types of question answering systems have different architectures, most of them follow a framework in which question classification plays an important role <ref type="bibr" target="#b2">3</ref> . Furthermore, some studies have demonstrated that performance of question classification has significant influence on the overall performance of a question answering system 2,4,5 . The task of question classification is to predict the entity type of the answer of a natural language question <ref type="bibr" target="#b5">6</ref> . For example, for the question "Where is the Eiffel Tower?", the task of question classification is to return label "location", thus the answer to this question is a named entity of type "location". Since we predict the type of the answer, question classification is also referred as answer type prediction.</p><p>Many studies have addressed this problem, they belongs to the rule-based approach 7,8 or machine learningbased approach <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> . In this paper, we follow the machine learning approach and pay attension on the importance of feature extraction and selection. From the view of machine learning, we can easily formulate the this task as a classification problem. There are various supervised learning methods used such as Nearest Neighbors (NN), Naive Bayes (NB), Decision Tree (DT), Sparse Network of Winnows (SNoW), and Support Vector Machines (SVM). However, as expressed from experimental results in previous studies, feature sets affect much the quality of question classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keywords: Feature Extraction, Feature Selection, Question Answering Systems, Question Classification, Question Patterns</head><p>According to previous studies, various types of features have been investigated. The most common types are bag of words and n-grams which were used in all studies. Some other studies (e.g 12 ) tried to enrich the feature set by adding more linguistic information as part-of-speech tags or head words, or even semantic features. However, from our observation combining all features is not always the best solution for all questions. Therefore, in this paper we will give an experimental investigation for finding the best feature sets corresponding to different groups of questions. In addition, we also extract a new type of features based on question patterns. These new features are then integrated to the existed feature sets and receive better results of classification. We tested our proposed feature sets using a SVM classifier which is experimental shown to get best results in <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14</ref> . And like most previous studies, the TREC dataset is chosen for conducting experiments.</p><p>The rest of this paper is organized as follows: Section 2 presents the basic issues in question classification including question type taxonomy and feature extraction. Section 3 presents our proposal for feature selection. Section 4 presents the experiments. Conclusion and future works will be presented in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Basic Issues of Question Classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Question Type Taxonomy</head><p>The set of question categories (classes) are usually referred as question taxonomy. Different question taxonomies have been proposed in different works, but most of the recent studies used the two layer taxonomy proposed by <ref type="bibr" target="#b14">[15]</ref> 1 . This taxonomy consists of 6 coarse grained classes and 50 fine grained classes. <ref type="table" target="#tab_0">Table 1</ref> lists this taxonomy.</p><p>Whenever the entity of answering is determined we can combine it with other information to find correct answers. For example, if we know the question is asking about location (or more concrete, a city), it is easier to find the exact information for answering as well as to form the appropriate answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Classification Algorithms and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Machine Learning Approach</head><p>Most studies in question classification follow supervised machine learning approach. There are many different classification methods used such as: Support Vector Machine, Naive Bayesian classification, Maximum Entropy Models <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref> , Sparse Network of Winnows 12 . Among these methods, Support Vector Machine with linear kernel function is shown as the most effective method, according to <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14</ref> . Therefore, SVM is the machine learning method used in our system. We can easily search for a many documents introducing about SVM methods and applications, thus it is not necessary for presenting it in detail here.</p><p>A general framework in supervised machine learning method for question classification is briefly described in the following steps:</p><p>â€¢ First, we need to build a training dataset, it includes questions assigned with classification labels.</p><p>â€¢ Second, each labeled question in the training dataset is represented as a vector of features.</p><p>â€¢ Third, a machine learning method (here SVM) is used to learn on the training vectors and generate the classifier.</p><p>â€¢ Finally, for each a test question we represent it by a vector of features and use the learnt classifier to obtain a label (i.e. a question category). </p><formula xml:id="formula_0">q = {(t 1 , f 1 ), â€¦, (t p , f p )}</formula><p>where f i is the frequency of the term i th in the question q. These features are called bag-of-words features or unigrams features. Unigrams is a special case of the so-called n-gram. To extract n-gram features, any n consecutive words in a question is considered as a feature. <ref type="table" target="#tab_1">Table 2</ref> lists the lexical features of the sample question "Who was elected president of South Africa in 1994?" Note that some special cases of getting lexical information like question words (i.e: who, how, when, what) or wordshapes are put into the lexical feature set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Syntactic Features</head><p>Syntactic features are extracted from the syntactical structure of a question. There are two common kinds of syntactic features used for question classification, including tagged unigrams and head words. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tagged Unigrams</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Head Words</head><p>A head word is considered as the key word or the central word in a sentence, a clause or a phrase. This word is determined based on the syntactic parsed tree of the input sentence. As mentioned in 6 , Head Words contain important information for specifying the object that a question is seeking. Therefore, identifying the head word correctly can improve the classification accuracy since it is the most informative word in the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Evaluation</head><p>Performance in question classification is evaluated by the global accuracy of the classifier for all the coarse or fine classes <ref type="bibr" target="#b11">12</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy = #of correct predictions #of predictions</head><p>There is also the accuracy of a question classifier on a specific class precision. Precision in question classification on a specific class c is defined as follows:</p><p>Precision(c) = #of correct predictions of class c #of predictions of class c</p><p>For the systems in which a question can only have one class, a question is correctly classified if the predicted label is the same as the true label. But for the systems which allow a question to be classified in more than one class <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15</ref> , a question is correctly classified, if one of the predicted labels is the same as the true label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature Extraction</head><p>There are various types of features which are currently used for question classification. They can be grouped into three different categories based on the kinds of linguistic information: lexical, syntactical and semantic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Lexical Features</head><p>Lexical features are usually the context words appearing in the question. In question classification, a question is represented similarly to document representation in the vector space model, i.e., a question can be represented as the vector:</p><formula xml:id="formula_1">q = (q 1 , q 2 , â€¦, q N )</formula><p>where q i is defined as the frequency of term i th in question q and N is the total number of terms. Note that only nonzero valued features are kept in the feature vector. Then, a question q is represented in the form: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Space Features</head><p>Unigram {(Who, 1) (was, 1) (elected, 1) (president, 1) (of, 1) (South, 1) (Africa, 1) (in, 1) (1994, 1) (?, 1)} Bigram {(Who-was, 1), (was-elected, 1), (elected-president, 1), (president-of, 1), (of-South, 1), (South-Africa, 1), (Africa-in, 1), (in-1994, 1), (1994-?, 1)} Trigram {( Who-was-elected, 1), (was-elected-president, 1), â€¦, (in-1994-?, 1)} Wh-Word {(Who, 1)} Word-Shapes {(lowercase, 5) (mix, 3) (digit, 1) (other, 1)} For example, for the question "What is the oldest city in Spain?" the head word here is "city". The word "city" in this question can highly contribute to the classifier for classifying this question as "LOC:city". <ref type="table" target="#tab_2">Table 3</ref> lists sample questions from TREC dataset together with their class labels. The head words are identified by being underlined.</p><p>To determine the head word of a sentence, a syntactic parser is required. For sentences written in English language, people usually use the Stanford PCFG parser <ref type="bibr" target="#b17">18</ref> which is also used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Semantic Features</head><p>Semantic features are useful in the case of sparse data. From higher level semantic concept we can get the relationship (i.e. the semantic similarity) between different words. WordNet is a well-known resources used for determining semantic features. WordNet is a lexical database of English words providing a lexical hierarchy that associates a word with higher level semantic concepts namely hypernyms <ref type="bibr" target="#b5">6</ref> . For example a hypernym of the word "city" is "municipality".</p><p>There are three kinds of semantic features being used for question classification, as shown in 12 , as follows:</p><p>Question Category (QC) WordNet hierarchy is used to estimate the similarity of question's head word. The class with highest similarity is considered as a new feature and will be added to the feature vector. For example, the question "What American composer wrote the music for "West Side Story"?" has its head word "composer". To find the question category feature, the similarity of this word will be compared with the similarity of all question categories. The category with the highest similarity will be added to the feature vector. In this example the most similar category is "individual" and therefore the question category feature will be {(individual, 1)}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Expansion (QE)</head><p>Another semantic feature called query expansion which is basically very similar to hypernym features. As we explained before, we add hypernym of a head word to the feature vector with words from WordNet hierarchy. Instead of imposing this limitation, we defined a weight parameter which decreases by increasing the distance of a hypernym from the original word. For example for the question "What river flows between Fargo, North Dakota and Moorhead, Minnesota?". The head word of this question is "river". The query expansion features of this question will be as follows, given that the weight of "river" is considered as 1: {(river, 1) (stream, 0.6) (body-of-water, 0.36) (thing, 0.22) (physical-entity, 0.13) (entity, 0.08)}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Words (RW)</head><p>Another semantic feature that we also use in this work is the related words as presented in <ref type="bibr" target="#b11">12</ref> . In this study, the authors defined groups of words, each was represented by a category name. If a word in the question exists in one or more groups, its corresponding categories will be added to the feature vector. For example if any of the words {birthday, birthdate, day, decade, hour, week, month, year} exists in a question, then its category name, "date", will be added to the feature vector. <ref type="table" target="#tab_3">Table 4</ref> lists semantic features the question "What river flows between Fargo, North Dakota and Moorhead, Minnesota?".  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Proposal of Feature Selection and Adding more New Feature Type</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Combination of Different Feature Sets</head><p>Suppose that each feature type as mentioned in section 2.3 will generate a single set of features. A natural way for obtaining the final set of features to use in the question classification is to combine all the single sets. However, we found that the combination of all these feature sets is not efficient and doesn't always give the best results for all questions.</p><p>From our observation, we can recognize that each type of questions can be sensitive with particular types of features. Therefore, assigning different feature sets corresponding with different question types can be a solution. The question types here relate to the question words: "who", "when", "how", "why", "which", "where", and "what". It means each the question word defines one feature type. We reserve one type for the remaining questions which do not contain those question words.</p><p>We propose to use a simple feature selection for determining the best combination of single feature sets for each question types, as presented in the algorithm 1 below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extracting Features from Question Patterns</head><p>By studying TREC dataset we found some questions inherently do not have any head word. For example, the sentence "What is an atom?" has no suitable head word as the entity type of the only noun ("atom") in this question. It does not provide necessary information to classify this question as "definition". We recognize that by integrating lexical, syntactic and semantic information into an unique form, we can get richer features for determining correct labels of such questions. This new kind of features also bring advanced evidences to the classification and therefore may lead to a better result.</p><p>We first design some patterns (i.e. templates) for containing the integrated of lexical, syntactic, and semantic information. <ref type="table" target="#tab_5">Table 5</ref> shows some designed question patterns.</p><p>From these patterns which we call question patterns, we will generate corresponding features. For example, from the question "How is thalassemia defined?" we can be received the features (How-is, 1) and (How-is-defined, 1). We then combine these features with the existed feature sets to get the final feature sets for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Determining the feature set for each question type</head><p>Input: a training data and a development data set corresponding to the selected feature type; a learning machine method (e.g SVM here) Output: a set of single feature types which gives the best result on the development data set.</p><p>Step 1: extract all the single feature sets, denoted by SF 1 , SF 2 , â€¦, SF n set the remain feature sets SF = { SF 1 , SF 2 , â€¦, SF n } set the initial feature set F = { } set the intitial accuracy A = 0</p><p>Step 2: For each SFi in SF train a new classifier again with the new feature set F+{SF i } ; get the accuracy tested on the development test, denote it by A i Step 3: get A k to be the highest accuracy, corresponding to the feature set F+{SF k };   </p><formula xml:id="formula_2">If A k &gt; A set A = A k SF = SF\{SF k } F = F + { SF k } Else</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>The dataset we used for conducting our experiment was created by <ref type="bibr" target="#b14">15</ref> . They provided a question dataset which is widely used in question classification studies and known as UIUC or TREC 2 dataset. It consists of 5500 labeled questions which is used as training set and 500 indepen-dent labeled questions which is used as the test set. The 5500 training questions are split randomly into 5 different training sets with the size 1000, 2000, 3000, 4000 and 5500 respectively. We design different experiments as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment 1</head><p>For the first experiment we combine all the single feature sets for the task of classification, that includes: Unigram (U), Bigram (B), Wh-Word (WH), Word-Shapes (WS), Head-Word (H), Query-Expansion (QE), QuestionCategory (QC), Related-Words (R). <ref type="table" target="#tab_6">Table 6</ref> shows the results corresponding with different training data sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>In this experiment we would like to examine the contribution of the question pattern features by adding the these QP features to the feature set from the Experiment 1. Its results are shown in the <ref type="table" target="#tab_7">Table 7</ref>. Comparing results of experiment 1 and experiment 2, we can see that the QP feature set actually improves the accuracy of question classification for all the training data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experiment 3</head><p>This experiment implements the Algorithm 1 for feature selection. Note that the QP feature set is also considered as one single feature set which is used in the algorithm. <ref type="table" target="#tab_8">Table 8</ref> also shows the selected feature types for each kind of question. It is worth to emphasize that the QP feature set is selected for the questions containing Wh-words, but not for the other type of questions. It seems reasonable because the QP features are designed to contain Wh-words, therefore they don't affect the question without Wh-words.  <ref type="table" target="#tab_9">Table 9</ref> shows the accuracy of question classification when using result of the feature selection.  <ref type="figure" target="#fig_2">Figure 1</ref> and <ref type="figure" target="#fig_3">figure 2</ref> show the comparisons of the experiment 2 and experiment 3 for the coarse and fine grained question classes.  Comparing result from <ref type="table" target="#tab_9">Table 9</ref> with results from <ref type="table" target="#tab_6">Table 6</ref> and <ref type="table" target="#tab_7">Table 7</ref>, and as illustrated in <ref type="figure" target="#fig_2">Figure 1</ref> and <ref type="figure" target="#fig_3">Figure 2</ref> we can see that combining both solutions (using QP features and using feature selection) significantly improves the task of question classification.</p><p>Comparison with previous studies: In addition, we also make a comparison with well-known previous studies of this task which also used the same data set. The <ref type="table" target="#tab_0">Table 10</ref> shows the accuracy for the Coarse classes and the Fine grained classes. <ref type="table" target="#tab_0">Table 10</ref> shows that our proposal achieve the accuracies of 95.2% and 91.6% for coarse grain and fine grain respectively, which are much better in comparison with the previous studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper we have presented our proposal of feature extraction and feature selection for improving question classification. We have investigated various types of features including lexical, syntactic, and semantic features. We also proposed a new type of feature based on question pattern and then applying a feature selection algorithm to determine the most appropriate feature set for each type of questions. The experimental results shows that our proposal gives the best accuracies for both the Coarse classes and the Fine grained classes of questions, in comparison with using the conventional feature set, as well as in comparison with the previous studies.  <ref type="table" target="#tab_0">Table 10</ref>. Comparison with previous studies for the same task and the same data set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgments</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Tagged Unigrams indicate the part-of-speech tag of each word in a question like NN (Noun), NP (Noun Phrase), VP (Verb Phrase), JJ (adjective), and etc. The following example shows these features extracted from the sentence "Who was elected president of South Africa in 1994?" {Who_WP, was_VBD, elected_VBN, president_NN, of_ IN, South_NNP, Africa_NNP, in_IN, 1994_CD,?.}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Question patterns Explain the semantic information Wh-word + Tobe + word- shape Wh-word + weather-word weather word: hot, cold, warm, wet, â€¦ Wh-word + distance-word distance-word: far, long, â€¦ Wh-word + Tobe + distance-word distance-word: far, long, â€¦ Wh-word + money-word money-word: money, cost, rent, sell, spend, charge, pay, â€¦ Wh-word + place-word place-word: city, county, mountain, state,â€¦ Wh-word + reason-word reason-word: causes, used, known, â€¦</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Result for Coarse classes in the experiment 2 and the experiment 3.</figDesc><graphic url="image-1.png" coords="6,323.00,373.01,237.49,136.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Result for fine grained classes in the experiment 2 and the experiment 3.</figDesc><graphic url="image-2.png" coords="6,323.00,541.82,237.70,140.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . The coarse and fine grained question classes</head><label>1</label><figDesc></figDesc><table>Coarse 
Fine 

ABBREVIATION 
Abbreviation, expression 

ENTITY 
Animal, body, color, creative, currency, dis.med, event, food, instrument, lang, letter, other, plant, 
product, religion, sport, substance, symbol, technique, term, vehicle, word </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 . Example of lexical features</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 . A sample of questions with their headwords and appropriate categories</head><label>3</label><figDesc></figDesc><table>Question 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 . Example of semantic features</head><label>4</label><figDesc></figDesc><table>Feature Space 
Features 

Hypernyms 
{(river, 1) (stream, 1) (body-of-water, 1) 
(thing, 1) (physical-entity, 1) (entity, 1)} 

Related Words 
{(rel:What, 1) (rel:list.tar, 2) (rel:loca, 2)} 

Question Category {(other, 1)} 

Query Expansion {(river, 1) (stream, 0.6) (body-of-water, 
0.36) (thing, 0.22) (physical-entity, 
0.13) (entity, 0.08)} </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 . Example of question patterns</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 .</head><label>6</label><figDesc></figDesc><table>The accuracy of using SVM classifier with 
combining the feature kinds: U, B, WH, WS, H, QE, 
QC, R 

Training size 1000 
2000 
3000 
4000 
5500 

Coarse 1 
90.20% 91.20% 92.00% 92.60% 94.20% 

Fine 1 
79.00% 85.40% 86.60% 88.00% 90.40% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 .</head><label>7</label><figDesc></figDesc><table>Accuracy of using more Question-Pattern 
feature 

Training 
size 
1000 
2000 
3000 
4000 
5500 

Coarse 2 
90.40% 91.40% 92.80% 93.20% 95.00% 

Fine 2 
79.20% 86.00% 87.00% 88.60% 91.00% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><head>Table 8 . Result of feature selection</head><label>8</label><figDesc></figDesc><table>Question types 
Features 

How, Who, Why, 
When, Where, Which 
Unigram, Bigram, Word-Shapes, 
Question Pattern 

What 
Unigram, Bigram, Head word, 
Word-Shape, Related Words, 
Question Pattern, Query 
Expansion, Question Category 

Other questions 
Unigram, Bigram, Word-Shape, 
Related Words 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 9 .</head><label>9</label><figDesc></figDesc><table>Accuracy of using feature selection 
corresponding to question types 

Training size 1000 
2000 
3000 
4000 
5500 

Coarse 3 
90.40% 91.60% 93.20% 93.80% 95.20% 

Fine 3 
79.20% 86.60% 87.40% 89.00% 91.60% 

</table></figure>

			<note place="foot">Nguyen Van-Tu, Le Anh-Cuong Indian Journal of Science and Technology</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A conceptual theory of question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wendy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international joint conference on Artificial intelligence</title>
		<meeting>the 5th international joint conference on Artificial intelligence</meeting>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="158" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Performance issues and error analysis in an open-domain question answering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moldovan</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasca</forename><surname>Marius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harabagiu</forename><surname>Sanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surdeanu</forename><surname>Mihai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans, Inf. Syst</title>
		<imprint>
			<biblScope unit="page" from="133" to="54" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overview of the trec 2001 question answering track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Text REtrieval Conference (TREC)</title>
		<meeting>the Tenth Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="42" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automated question answering in webclopedia -a demonstration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermjakob</forename><surname>Ulf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hovy</forename><surname>Eduard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><forename type="middle">Chin</forename><surname>Yew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-02</title>
		<meeting>ACL-02</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">IBM&apos;s statistical question answering system. NIST</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratnaparkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mammone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Text Retrieval Conference</title>
		<meeting>the 9th Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Question classification using head words and their hypernyms. EMNLP &apos;08</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thint</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zengchang</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Xerox TREC-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Voorhees and Harman</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The use of predictive annotation for question answering in trec8</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prager</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radev</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brown</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coden</forename><surname>Anni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIST Special Publication 500-246: The Eighth Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="399" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Investigation of question classifier in question answering. EMNLP &apos;09</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thint</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Celikyilmaz</forename><surname>Asli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis of statistical question classification for fact-based questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Metzler</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="page" from="481" to="504" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">From symbolic to subsymbolic information in question classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silva</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coheur</forename><surname>LuÄ±sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mendes</forename><surname>Ana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wichert</forename><surname>Andreas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="page" from="137" to="54" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning question classifiers: The role of semantic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roth</forename><surname>Dan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc, International Conference on Computational Linguistics (COLING)</title>
		<meeting>International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="556" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Enhanced answer type inference from questions using sequential models. HLT &apos;05</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnan</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Das</forename><surname>Sujatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chakrabarti</forename><surname>Soumen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="315" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Question classification using support vector machines. SIGIR &apos;03</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee Wee</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 26th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning question classifiers. COLING &apos;02</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roth</forename><surname>Dan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on Computational linguistics</title>
		<meeting>the 19th international conference on Computational linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Question classification with loglinear odels. SIGIR &apos;06</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blunsom</forename><surname>Phil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kocik</forename><surname>Krystle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 29th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="615" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Question classification using multiple classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-De</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Asian Language Resources and First Symposium on Asian Language Resources Network</title>
		<meeting>the 5th Workshop on Asian Language Resources and First Symposium on Asian Language Resources Network</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improved inference for unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petrov</forename><surname>Slav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klein</forename><surname>Dan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="404" to="415" />
		</imprint>
	</monogr>
	<note>Proceedings of the Main Conference</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Question Classification Using Extreme Learning Machine on Semantic Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheah</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu-N</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ICT Res. Appl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="58" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
