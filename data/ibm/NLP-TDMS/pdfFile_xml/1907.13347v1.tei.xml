<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Multi-Object Tracking Framework with the GMPHD Filter and Occlusion Group Management</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Min</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwangjin</forename><surname>Yoon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Chul</forename><surname>Yoon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kin-Choong</forename><surname>Yow</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moongu</forename><surname>Jeon</surname></persName>
						</author>
						<title level="a" type="main">Online Multi-Object Tracking Framework with the GMPHD Filter and Occlusion Group Management</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-multiple object tracking</term>
					<term>GMPHD filter</term>
					<term>hierar- chical data association</term>
					<term>occlusion handling</term>
					<term>energy minimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose an efficient online multiobject tracking framework based on the Gaussian mixture probability hypothesis density (GMPHD) filter and occlusion group management scheme where the GMPHD filter utilizes hierarchical data association to reduce the false negatives caused by miss detection. The hierarchical data association consists of two steps: detection-to-track and track-to-track associations, which can recover the lost tracks and their switched IDs. In addition, the proposed framework is equipped with an object grouping management scheme which handles occlusion problems with two main parts. The first part is "track merging" which can merge the false positive tracks caused by false positive detections from occlusions, where the false positive tracks are usually occluded with a measure. The measure is the occlusion ratio between visual objects, sum-of-intersection-over-area (SIOA) we defined instead of intersection-over-union (IOU) metric. The second part is "occlusion group energy minimization (OGEM)" which prevents the occluded true positive tracks from false "track merging". We define each group of the occluded objects as an energy function and find an optimal hypothesis which makes the energy minimal. We evaluate the proposed tracker in benchmark datasets such as MOT15 and MOT17 which are built for multi-person tracking. An ablation study in training dataset shows that not only "track merging" and "OGEM" complement each other but also the proposed tracking method has more robust performance and less sensitive to parameters than baseline methods. Also, SIOA works better than IOU for various sizes of false positives. Experimental results show that the proposed tracker efficiently handles occlusion situations and achieves competitive performance compared to the state-of-theart methods. Especially, our method shows the best multi-object tracking accuracy among the online and real-time executable methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>while deep neural networks based detectors such as FR-CNN <ref type="bibr" target="#b10">[10]</ref>, SDP <ref type="bibr" target="#b12">[11]</ref>, and EB <ref type="bibr" target="#b13">[12]</ref> have shown breakthrough in object classification and detection.</p><p>Besides, MOT algorithms are categorized into two approaches: offline and online processes. The most different point between two approaches is that whereas the offline process can see the whole time sequences at once, the online process can see only the frames from initial time 1 to current processing time k. In other words, from the system user's perspective, whereas the offline method is suitable for postprocessing, the online process for real-time application.</p><p>Thus, many offline methods <ref type="bibr" target="#b29">[28]</ref>, <ref type="bibr" target="#b30">[29]</ref>, <ref type="bibr" target="#b32">[31]</ref>, <ref type="bibr" target="#b35">[34]</ref>, <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b48">[46]</ref> take advantage of the global optimization models. <ref type="bibr" target="#b30">[29]</ref>, <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b48">[46]</ref> exploit graphical models to solve MOT task. Pirsiavash et al. <ref type="bibr" target="#b37">[36]</ref> designed a min-cost flow network where the nodes and the directed edges indicating observations and tracklets' hypotheses, respectively form a directed acyclic graph (DAG). The DAG's shortest (min-cost) path can be found with Dijkstra's algorithm. Choi et al. <ref type="bibr" target="#b30">[29]</ref> divided the tracking problem into subgraphs and solved each subgraph as conditional random field inference in parallel. Keuper et al. <ref type="bibr" target="#b48">[46]</ref> applied vision-based perspective to the proposed graph optimization model. Feature points' trajectories and bounding boxes build low-level and high-level graph models, respectively, and then, they find the optimal association results between the two levels graph models. Rezatofighi et al. <ref type="bibr" target="#b32">[31]</ref> and Kim et al. <ref type="bibr" target="#b29">[28]</ref> considered all possible hypotheses for data association. Because it involves the exponentially increasing complexity with a tree structure, <ref type="bibr" target="#b32">[31]</ref> assumed m-best solutions and <ref type="bibr" target="#b29">[28]</ref> pruned out invalid hypotheses using their own rule. Besides, Milan et al. <ref type="bibr" target="#b35">[34]</ref> proposed a sophisticated energy minimization technique considering detection, appearance, dynamic model, mutual exclusion, and target persistence for MOT task in video. Those offline methods have strength to generate the accurate and refined tracking results but is not suitable for practical real-time application.</p><p>On the other hand, since the online approach cannot apply the global optimization models, intensive motion analysis and appearance feature learning have been popularly utilized with a hierarchical data association framework and the online Bayesian model <ref type="bibr" target="#b15">[14]</ref>, <ref type="bibr" target="#b16">[15]</ref>, <ref type="bibr" target="#b19">[18]</ref>, <ref type="bibr" target="#b22">[21]</ref>, <ref type="bibr" target="#b24">[23]</ref>, <ref type="bibr" target="#b26">[25]</ref>, <ref type="bibr" target="#b38">[37]</ref>, <ref type="bibr" target="#b43">[42]</ref>. Yoon et al. <ref type="bibr" target="#b24">[23]</ref> proposed a relative motion analysis between all objects in a frame, and then improved the work <ref type="bibr" target="#b24">[23]</ref> by adding the cost optimization function using context constraints in <ref type="bibr" target="#b22">[21]</ref>. Bae et al. <ref type="bibr" target="#b26">[25]</ref> exploited the incremental linear discriminant analysis (LDA) for appearance learning and presented a tracklet confidence based data association framework. Also, in <ref type="bibr" target="#b15">[14]</ref>, they improved their previous work <ref type="bibr" target="#b26">[25]</ref> by using the deep neural network (DNN) based appearance learning instead of the incremental LDA. As we addressed in the previous paragraph, DNN has given breakthrough in appearance learning i.e., object classification and detection. So, some online MOT algorithms have focused on how to adopt deep appearance learning into their tracking frameworks. Yoon et al. <ref type="bibr" target="#b16">[15]</ref> exploited the siamese convolutional neural networks (CNN) <ref type="bibr" target="#b53">[51]</ref> to train appearance model. They train the deep appearance networks selectively where only the detection responses matched with high confidence between the historical object queues in the recent few frames. Then, they combine the trained networks to a simple Bayesian tracking model with the Kalman filter. Chen et al. <ref type="bibr" target="#b38">[37]</ref> employed a re-identification (Re-ID) model <ref type="bibr" target="#b54">[52]</ref> to their tracking framework. They measure the similarity between detection and track by calculating the distance between Re-ID feature vectors of them. Then, they associate the pairs of detections and tracks which make the sum of the distances minimal. Both approaches <ref type="bibr" target="#b16">[15]</ref>, <ref type="bibr" target="#b38">[37]</ref> proposed online Bayesian tracking models with conventional DNN models to measure the similarity between the visual objects. Those online MOT methods have proposed successful solutions with excellent tracking accuracy but their intensive analysis and learning processes take heavy computing resource and time. Also, even if they just employ conventional DNN models through state-of-the-art GPU processing technique, the requirement for a lot of computing resource is inevitable and it makes the trackers difficult to achieve real-time speed.</p><p>Recently, the closed-form implementations <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> of the probability hypothesis density (PHD) filtering have been employed as an emerging theory for many online MOT methods <ref type="bibr" target="#b17">[16]</ref>- <ref type="bibr" target="#b19">[18]</ref>, <ref type="bibr" target="#b23">[22]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b42">[41]</ref>- <ref type="bibr" target="#b44">[43]</ref>. That is because Vo et al. <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> provided not only theoretically optimal approach to the online multi-target Bayes filtering but also approximate the original PHD recursions involving multiple integrals, which alleviate the computational intractability. Moreover, the PHD filter was originally designed for multi-target tracking in radar/sonar systems which receive uncountable false positive observations, i.e., clutters. So it is robust to deal with false positives errors but weak to handle false negatives. V. Eiselein et al. <ref type="bibr" target="#b44">[43]</ref> combined the feature-based label tree to the Gaussian mixture PHD (GMPHD) filter, which use visual features to help the GMPHD filter work sensibly in video data system. Song et al. <ref type="bibr" target="#b17">[16]</ref> extended the GMPHD filter based tracking with the two-stage hierarchical data association strategy and use simple motion estimation and appearance matching to recover lost tracks. T. Kutschbach et al. <ref type="bibr" target="#b43">[42]</ref> joined the GMPHD filter with the kernelized correlation filters (KCF) <ref type="bibr" target="#b55">[53]</ref> for online appearance update to overcome occlusion. Z. Fu et al. <ref type="bibr" target="#b19">[18]</ref> adopted an adaptive gating technique and an online group-structured dictionary (appearance) learning strategy into the GMPHD filter. They make the GMPHD filter be sophisticated and fit to video based MOT. Besides, various tracking methods <ref type="bibr" target="#b23">[22]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b42">[41]</ref> utilizing the PHD filters have been proposed.</p><p>These latest MOT research trends motivate our work in terms of the three main contributions. Also, it reminds us of the requirements for the practical MOT applications. Thus, in this paper, we propose an online multi-object tracking framework to resolve the practical tracking problems which are based on occlusion and the characteristics of video data system. First, we exploit the GMPHD filter for online MOT. To efficiently change the GMPHD filter's original domain, we define the tracking problems by miss detections in video data system. To deal with track loss by miss detection, we design a GMPHD filtering theory based hierarchical data association (HDA) strategy. Second, we assume that most of tracking problems are caused by occlusion in video data system. The occlusion between false positive tracks can cause ID-switch and the false positives, and the real occlusion between objects can make fragmented and miss tracks by miss detections. To handle these tracking problems, we propose a novel occlusion handling technique combined with HDA which is based on GMPHD filter tracking framework. Third, we consider that the proposed tracking framework should be implemented to run with realtime speed. That is because visual surveillance systems with higher intelligence require more immediate responses to the users with real-time speed. Also, immediate responses can help the systems' user and the machines to react abnormal situation rapidly. Finally, we evaluate the proposed method on the popular benchmark dataset. Our method shows the competitive performance against state-of-the-art methods in terms of "tracking accuracy versus speed". Our main contributions are described as follows: 1) To apply the GMPHD filter into video data system, we extended the conventional GMPHD filter based tracking process with a hierarchical data association (HDA) strategy. Also, we revised the equations of the GMPHD filter as a new cost function for HDA. HDA consists of detection-to-track association (D2TA) and track-to-track association (T2TA). Each cost matrix of each association stage is solved by the Hungarian method with the linear complexity O(n 3 ) (assignment problem). These D2TA and T2TA recovers lost tracks, while preserving real-time speed.</p><p>2) To handle occlusion in video-based tracking system, we devised "tracking merging" and "occlusion group energy minimization (OGEM)" which complement each other. "Tracking merging" relieves false positive tracks and "OGEM" recovers false "track merging" by using the occluded objects' group energy minimization. "Tracking merging" runs in trackinglevel so is different to detection-level merging such as nonmaximum-suppression. To measure overlapping ratio between occluded objects, we devise a new metric named as sum-ofintersection-over-area (SIOA). We use the SIOA metric instead of intersection-over-union (IOU) which is an extensively used metric. For "OGEM", we devise a new energy function to find the optimal state having the minimum energy in a group of occluded objects. "Tracking merging" and "OGEM" follow D2TA and T2TA, respectively. We name both techniques as occlusion group management (OGM).</p><p>3) Consequently, we propose an online multi-object tracking framework with the GMPHD filter and occlusion group management (GMPHD-OGM). In view of optimization techniques, the first and second contribution locally optimize tracking process which are the minimization of the association cost matrix and the occlusion group energy. We evaluate the proposed tracking framework on MOT15 <ref type="bibr" target="#b4">[5]</ref> and MOT17 <ref type="bibr" target="#b6">[6]</ref> benchmarks. The ablation study on training set shows that our method is more robust than the given baselines. The qualitative and quantitative evaluation results shows that GMPHD-OGM efficiently handle the defined tracking problems by occlusion. Moreover, the proposed method achieves competitive tracking performance against state-of-the-art online MOT algorithms in terms of CLEAR-MOT metrics <ref type="bibr" target="#b56">[54]</ref>.</p><p>The related works are described in Section II. In Section III and IV, we introduce the GMPHD filter based tracking framework with HDA and OGM in detail, respectively. In Section V, our method is evaluated compared to baseline methods and state-of-the-art methods on the popular benchmarks MOT15 <ref type="bibr" target="#b4">[5]</ref> and MOT17 <ref type="bibr" target="#b6">[6]</ref>. We conclude this paper with future work in Section VI. Some preliminary results of this work was presented in Song et al. <ref type="bibr" target="#b17">[16]</ref>, <ref type="bibr" target="#b18">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Our proposed tracking framework is influenced from the PHD filter based online multi-object tracking, and grouping approach (topology and relative motion analysis).</p><p>The PHD filter [1]- <ref type="bibr" target="#b2">[3]</ref> was originally designed to deal with radar/sonar data based multi-object tracking (MOT) systems. Mahler et al. <ref type="bibr" target="#b0">[1]</ref> proposed a recursive Bayes filter equations for the PHD filter which optimizes MOT process in radar/sonar systems with the random-finite set (RFS) of state and observations. Following this PHD filtering theory, Vo et al. <ref type="bibr" target="#b2">[3]</ref> implemented governing equations by using the Gaussian mixture model as closed-form recursions, named as the Gaussian mixture probability hypothesis density (GMPHD) filter. In the original domains the tracking algorithm should estimate true tracks (states) from a lot of observations as shown in <ref type="figure" target="#fig_3">Figure 1</ref>-(a). Whereas the radar/sonar sensors receive massive false positive but rarely missed observations, visual object detectors generate much less false positive and more missed observations than the radar/sonar sensors does as shown in <ref type="figure" target="#fig_3">Figure 1</ref>-(b). Thus, the GMPHD filter is efficient dealing with the false positive observations, but needs to be extended and improved by additional techniques for MOT in video data system.</p><p>As demand increases on online and real-time tracker in video-based tracking system, the PHD filter have been an emerging tracking model, recently. Song et al. <ref type="bibr" target="#b17">[16]</ref> extended the GMPHD filter based tracking with the two-stage hierarchical data association strategy to recover fragmented and lost tracks. They defined the affinity in the track-to-track association step by using tracks' linear motion and color histogram appearance. This approach is an intuitive implementation of the GMPHD filter to handle tracking problems, but cannot correct the false associations already made in the detectionto-track association. T. Kutschbach et al. <ref type="bibr" target="#b43">[42]</ref> added the kernelized correlation filters (KCF) <ref type="bibr" target="#b55">[53]</ref> for online appearance update to overcome occlusion with the naive GMPHD filtering process. They showed a robust online appearance learning to re-find the IDs of the lost tracks. However, updating appearance information of all objects at every frame requires heavy computing resources. R. Sanchez-Matilla et al. <ref type="bibr" target="#b23">[22]</ref> proposed a detection confidence based MOT model with the PHD filter.</p><p>Strong (high confidence) detections initiate and propagate tracks but weak (low confidence) detections only propagate existing tracks. This strategy works well when the detection results are reliable. However, the tracking performance is dependent on the detection performance, and especially weak to long-term missed detections. Z. Fu et al. <ref type="bibr" target="#b19">[18]</ref> adopted an adaptive gating technique and an online group-structured dictionary (appearance) learning strategy into the GMPHD filter. They made the GMPHD filter have a sophisticated tracking process and fit to video based MOT.</p><p>Grouping approach e.g., relative motion and topological model, already have been exploited in <ref type="bibr" target="#b22">[21]</ref>, <ref type="bibr" target="#b24">[23]</ref>. The key difference between their methods and ours is that <ref type="bibr" target="#b22">[21]</ref>, <ref type="bibr" target="#b24">[23]</ref> consider the relations between all objects in a scene but we only consider topological information in the group of occluded objects. Grouping only the occluded objects exclude trivial solutions (associations) which focuses on solving subproblems and reduces computing time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED ONLINE MULTI-OBJECT TRACKING FRAMEWORK</head><p>In this section, we briefly introduce the general tracking process of the Gaussian mixture probability hypothesis density (GMPHD) filter in Subsection III-A. In III-B, we address how to extend the GMPHD filter with the hierarchical data association strategy in video-based online MOT systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The GMPHD Filter</head><p>The Gaussian mixture model (GMM) of the GMPHD filter includes means, covariances, and weights which are propagated at every time stamp as follows; Initialization, Prediction, Update, and Pruning steps. We employ this basic process of the GMPHD filter but revise fit to the video-based MOT system.</p><formula xml:id="formula_0">X k = {x 1 k , ..., x I k k },<label>(1)</label></formula><formula xml:id="formula_1">Z k = {z 1 k , ..., z J k k },<label>(2)</label></formula><p>where X k and I k denote a set of objects' states and the number of them at time k, respectively. A state vector</p><formula xml:id="formula_2">x k is composed of (c x , c y , v x , v y ), where c x , c y , v x ,</formula><p>and v y indicate the x-axis center point of the bounding box, the y-axis center point of the bounding box, the x-axis velocity, and the y-axis velocity, respectively. Likewise, Z k and J k denote a set of observations (detection responses) and the number of them at time k, respectively. An observation z k is composed of (c x , c y ), where c x and c y indicate the x-axis and the y-axis center of the detection bounding box, respectively. Equation <ref type="formula" target="#formula_3">(3)</ref> and <ref type="formula" target="#formula_4">(4)</ref> describe the basic notations of state and observation.</p><formula xml:id="formula_3">x i k = {c x,k , c y,k , v x,k , v y,k } T ,<label>(3)</label></formula><formula xml:id="formula_4">z j k = {c x,k , c y,k } T .<label>(4)</label></formula><p>The tracking process of the GM-PHD filter is composed of four steps: Initialization, Prediction, Update, and Pruning as follows. <ref type="figure" target="#fig_3">Fig. 1</ref>: Comparison between (a) radar/sonar and (b) video system in terms of input and output, i.e., observations (detection) and states (tracking). The radar/sonar sensors receive a lot of clutters (false positive error) but rarely miss objects (false negative error), whereas the detector in video data tends to receive a few clutters around the objects and misses more objects than the radar/sonar senors do. Initialization:</p><formula xml:id="formula_5">I0 i=1 w i 0 N (x; m i 0 , P i 0 ),<label>(5)</label></formula><p>where the GMM is initialized by the initial observations from the detection responses. Besides, when an observation fails to find the association pair, i.e., updating object state, the observation initializes a new Gaussian model (a new state). Gaussian probability function N represents tracking objects with weight w, mean vector m, object state vector x, and covariance matrix P . At this step, we set the initial velocities of mean vector to zeros. Each weight is set to the normalized confidence value of the corresponding detection response.</p><p>Prediction:</p><formula xml:id="formula_6">I k−1 i=1 w i k−1 N (x; m i k−1 , P i k−1 ),<label>(6)</label></formula><formula xml:id="formula_7">m i k|k−1 = F m i k−1 ,<label>(7)</label></formula><formula xml:id="formula_8">P i k|k−1 = Q + F P i k−1 (F ) T ,<label>(8)</label></formula><p>where we assume that the GMM representing the objects' states was initialized or active at the previous frame k − 1 in (6). In <ref type="formula" target="#formula_7">(7)</ref> and <ref type="formula" target="#formula_8">(8)</ref>, F is the state transition matrix and Q is the process noise covariance matrix. F and Q are constants in our tracker. Then, we can predict the state at time k using the Kalman filtering. In <ref type="bibr" target="#b7">(7)</ref>, m i k|k−1 is derived by using the velocity of m i k−1 . Covariance P i k|k−1 is also predicted by the Kalman filtering method in <ref type="bibr" target="#b8">(8)</ref>.</p><p>Update:</p><formula xml:id="formula_9">I k|k−1 i=1 w i k (z)N (x; m i k|k , P i k|k ),<label>(9)</label></formula><formula xml:id="formula_10">q i k (z) = N (z; Hm i k|k−1 , R + HP i k|k−1 (H) T ),<label>(10)</label></formula><formula xml:id="formula_11">w i k (z) = w i k|k−1 q i k (z) I k|k−1 l=1 w l k|k−1 q l k (z) ,<label>(11)</label></formula><formula xml:id="formula_12">m i k|k (z) = m i k|k−1 + K i k (z − Hm i k|k−1 ),<label>(12)</label></formula><formula xml:id="formula_13">P i k|k = [I − K k i H]P i k|k−1 ,<label>(13)</label></formula><formula xml:id="formula_14">K i k = P i k|k−1 (H) T (HP i k|k−1 (H) T + R) −1 ,<label>(14)</label></formula><p>where the goal of update step is deriving <ref type="bibr" target="#b9">(9)</ref>. First, we should find an optimal observation z k at time k to update a Gaussian model. The optimal z makes q k be the maximum in <ref type="bibr" target="#b10">(10)</ref>. R denotes the observation noise covariance. H denotes the observation matrix to transit a state vector to an observation vector. Both R and H are constants in our application.</p><p>In the perspective of application, the update step involves data association. Updating the Gaussian state models follows finding the optimal observations updating the states through the data association. After finding the optimal z, the GMM is updated to (9) through (10), <ref type="bibr" target="#b12">(11)</ref>, and <ref type="formula" target="#formula_0">(14)</ref>, <ref type="formula" target="#formula_0">(13)</ref>, <ref type="bibr" target="#b13">(12)</ref>.</p><formula xml:id="formula_15">Pruning:X k = {m i k : w i k ≥ θ w , i = 1, ..., I k },<label>(15)</label></formula><formula xml:id="formula_16">W k = {w i k : m i k ∈X k , i = 1, ..., I k },<label>(16)</label></formula><formula xml:id="formula_17">W k = {w k,1 , ...,w k,Ĩ k },Ĩ k = |W k |,<label>(17)</label></formula><formula xml:id="formula_18">w i k =w i k Ĩ k l=1w l k ,<label>(18)</label></formula><formula xml:id="formula_19">X k =X k ,<label>(19)</label></formula><p>where the states with the weight under threshold θ w are pruned as in <ref type="bibr" target="#b16">(15)</ref>. We experimentally set θ w to 0.1. Then the weights of the surviving states are normalized as shown in <ref type="bibr" target="#b19">(18)</ref>. The pruning step handles the false positive tracks by the false positive detections. The GMPHD filter <ref type="bibr" target="#b2">[3]</ref> is specialized in handling false positives e.g., clutters and noise. However, tracking systems have the different problems, depending on their domains as shown in <ref type="figure" target="#fig_3">Figure 1</ref>, where input and output indicate detection results (observations) and tracking results (states), respectively. As presented in <ref type="bibr" target="#b3">[4]</ref> and <ref type="figure" target="#fig_3">Figure 1</ref>-(a), at radar/sonar systems, the senors receive uncountable detection responses with a lot of clutters but objects are rarely missed. On the other hand, as shown in <ref type="figure" target="#fig_3">Figure 1</ref>-(b), the video data based detectors observe less clutters and miss more objects than the radar/sonar senors do. The conventional GMPHD filter is effective to handle the clutters (false positive) but missed detctions cause the new tracking problems in video data system (false negative). Thus, we propose the GMPHD filtering based tracker with a hierarchical data association strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Hierarchical Data Association</head><p>Video-based tracking systems have inherent problems as shown in <ref type="figure" target="#fig_3">Figure 1-(b)</ref>. Generally, when objects are not detected, the objects' IDs are frequently changed and the tracks are fragmented if only detection-to-track association is employed. To prevent these problems by missing objects, we take advantage of a hierarchical data association (HDA) strategy which has been widely used in many online multiobject tracking methods <ref type="bibr" target="#b15">[14]</ref>, <ref type="bibr" target="#b17">[16]</ref>, <ref type="bibr" target="#b18">[17]</ref>, <ref type="bibr" target="#b23">[22]</ref>, <ref type="bibr" target="#b26">[25]</ref>. Thus, in this paper, we propose a simple HDA scheme with just two stages. The proposed HDA includes detection-to-track (D2T) and track-to-track (T2T) associations. We implement the both association methods with the GMPHD filtering process as given in III-A. Also, we derive a cost function from <ref type="formula" target="#formula_0">(11)</ref> of the GMPHD filtering process as follows:</p><formula xml:id="formula_20">Cost(x i k|k−1 , z j k ) = − ln w i k (z j k ),<label>(20)</label></formula><p>where w i k indicate the weight value, assuming that observation z j k updates state x i k|k−1 . We use − ln w i k (z j k ) as a cost between x i k|k−1 and z j k . Then, cost matrix C can be built by every pair between state set X k|k−1 and observation set Z k as follows:</p><formula xml:id="formula_21">C[i, j] = Cost(X k|k−1 [i], Z k [j]).<label>(21)</label></formula><p>When the cost matrix C is built, the Hungarian algorithm is used to solve it. Then, the optimal pairs between observations and states are found, and consequently state x k|k−1 is updated to x k in D2T and T2T associations. In III-B1and III-B2, we introduce the definition of observations and states in each association stage with more detail usage of the cost function.</p><p>1) Detection-to-Track Association (D2TA, Stage 1): In D2TA, observation set Z k is filled with detection responses at time k. We assume that state set X k−1 already exists from time k − 1, and then X k|k−1 is predicted by using the Kalman filtering as shown in <ref type="formula" target="#formula_6">(6)-(8)</ref>. Thus, the cost matrix C D2T is easily calculated with these sets X k|k−1 and Z k .</p><p>2) Track-to-Track Association (T2TA, Stage 2): In T2TA, a simple temporal analysis of tracklet is conduced. A tracklet means a fragment of the track, and becomes a calculation unit. Before T2TA, all tracklets are categorized into two types, according to success or failure of tracking at the present time k as follows:</p><formula xml:id="formula_22">T lost k ∪ T live k = T all k ,<label>(22)</label></formula><formula xml:id="formula_23">T lost k ∩ T live k = φ,<label>(23)</label></formula><formula xml:id="formula_24">T lost k = {τ lost 1,k , ..., τ lost i,k },<label>(24)</label></formula><formula xml:id="formula_25">τ lost i,k = {a i s , .., a i t }, 0 ≤ s &lt; t &lt; k,<label>(25)</label></formula><formula xml:id="formula_26">T live k = {τ live 1,k , ..., τ live j,k },<label>(26)</label></formula><formula xml:id="formula_27">τ live j,k = {a j s , .., a j t }, 0 ≤ s &lt; t, t = k,<label>(27)</label></formula><p>where "live" indicates that tracking succeeds at time k. "lost" indicates that tracking fails at time k. Then, for the T2TA, observation set Z k is filled with the first (oldest) elements a j s s of "live" tracklets. However, the state set X k|k−1 is not filled with the last (most recent) elements a i t s of "lost" tracklets. One prediction step is needed as follows:</p><formula xml:id="formula_28">a i s = {c x,s , c y,s , v x,s , v y,s } T ,<label>(28)</label></formula><formula xml:id="formula_29">a i t = {c x,t , c y,t , v x,t , v y,t } T ,<label>(29)</label></formula><formula xml:id="formula_30">x i t = {c x,t , c y,t , c x,t − c x,s t − s , c y,t − c y,s t − s } T ,<label>(30)</label></formula><formula xml:id="formula_31">x i k|k−1 = F T 2T x i t ,<label>(31)</label></formula><formula xml:id="formula_32">F T 2T =      1 0 d f 0 0 1 0 d f 0 0 1 0 0 0 0 1      ,<label>(32)</label></formula><p>d f (i, j) = frame difference between a i t and a j s .</p><p>In <ref type="formula" target="#formula_3">(30)</ref> cx,t−cx,s t−s and cy,t−cy,s t−s are the averaged velocities in terms of x-axis and y-axis, respectively. The velocities are calculated by subtracting the center position of the first object state a i s from that of the last state a i t , and dividing it by the frame difference t − s which is equivalent to the length of "lost" tracklet τ lost i,k . D2TA has the identical time interval "1" between states and observations in transition matrix F , whereas in T2TA , each cost of matrix C T 2T has different time interval (frame difference) between states and observations. Variable d f depends on which state of "lost" tracklet and observation of "live" tracklet are paired. (31) means the prediction process of state with linear motion analysis. Finally, the cost matrix C T 2T is filled by <ref type="bibr" target="#b32">(31)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OCCLUSION GROUP MANAGEMENT SCHEME</head><p>In Section III, we addressed that the proposed online multiobject tracking framework is based on the GMPHD filter- G k−1 , G k ; // a set of occlusion groups at time k-1 and k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>if k = 1 or l = 0 then 6:</p><p>Initialize states X k with Z k ; 7:</p><formula xml:id="formula_34">G k−1 = G k ; 8: X k = M ERGE(X k , σm, G k ); 9:</formula><p>return X k ; 10:</p><p>end if /* 1. Detection-to-Track Association (D2TA) */ 11:</p><formula xml:id="formula_35">C D2T [1 . . . l][1 . . . m];</formula><p>// for cost matrix 12:</p><p>P D2T [1 . . . l]; // for pairing observations' indices /*predict states X k−1 to be X k|k−1 */ 13:</p><p>for i = 1 to l do 14:</p><formula xml:id="formula_36">X k|k−1 [i] = P REDICT (X k−1 [i]); 15:</formula><p>end for /*calculate the GMPHD filter cost matrix C D2T */ 16:</p><p>for i = 1 to l do 17:</p><p>for j = 1 to m do 18:</p><formula xml:id="formula_37">C D2T [i][j] = COST D2T (X k|k−1 [i], Z k [j]); 19:</formula><p>end for 20:</p><p>end for /*find min-cost pairs by the Hungarian method*/ 21: P D2T = HungrianM ethod(C D2T ); /*update and birth states*/ /*update X k|k−1 with the min-costly observations*/ 22:</p><p>for i = 1 to l do 23:</p><formula xml:id="formula_38">X k [i] = U P DAT E(X k|k−1 [i], Z k [P D2T [i]]); 24:</formula><p>end for /*prune X k|k−1 with the weight under 0.1*/ 25:</p><p>for i = 1 to l do 26:</p><p>X ing theory with the two-stage hierarchical data association. However, the tracking results from that framework still give uncertainty to us, even if we effectively extend the conventional GMPHD filter to be suitable for video-based tracking system. Thus, to handle it, we define two types of tracking problems and provide a solution. One is an intrinsic occlusion and the other is an extrinsic occlusion. The intrinsic occlusion is defined when the number of detection responses on one /* 3. Track-to-Track Association (T2TA) */ 45: t 1 = |T lost |; // the number of lost tracklets 46: t 2 = |T live |; // the number of live tracklets 47:</p><formula xml:id="formula_39">C T 2T [1 . . . t 1 ][1 . . . t 2 ]</formula><p>; // for cost matrix 48:</p><formula xml:id="formula_40">P T 2T [1 . . . t 1 ]</formula><p>; // for pairing observations' indices /*calculate the GMPHD filter cost matrix C T 2T */ 49:</p><p>for i = 1 to t 1 do 50:</p><p>for j = 1 to t 2 do 51:</p><formula xml:id="formula_41">C T 2T [i][j] = COST T 2T (T lost [i], T live [j], τ T 2T , θ T 2T ); 52:</formula><p>end for 53:</p><p>end for /*find min-cost pairs by the Hungarian method*/ 54: P T 2T = HungrianM ethod(C T 2T ); /*update tracklets and manage tracklet pool after T2TA*/ 55:</p><p>for i = 1 to l do 56:</p><formula xml:id="formula_42">X k [i] = U P DAT E(X k|k−1 [i], Z k [P D2T ]); 57:</formula><p>end for 58: object is more than one. Generally, it makes the object ID switched and false positive tracks. The extrinsic occlusion is defined when the number of detection responses on objects, occluded each other, is less or more than the number of the occluded objects. That can cause false negative and positive tracks, respectively. <ref type="figure" target="#fig_8">Figure 8 and 9</ref> show the defined tracking issues well. The false positive detections made by intrinsic and extrinsic occlusions inevitably generate false tracks as shown in the second row <ref type="figure">Figure 9</ref> (D2TA), if appropriate techniques do not handle it. To resolve the two types of problems, we design a new occlusion group management (OGM) scheme. OGM consists of "Track Merging" and "Occlusion Group Energy Minimization (OGEM)" routines which execute just after D2TA and T2TA, respectively. <ref type="figure" target="#fig_0">Figure 2</ref> briefly shows the tracking pipeline with those two components of OGM. Consequently, our occlusion group management technique not only decreases false positive tracking results but also prevents occluded tracks from false "track merging". The effectiveness of the proposed OGM method is discussed in Section V in more detail.</p><formula xml:id="formula_43">for i = 1 to |X k | do 59: if X k [i] is</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Track Merging</head><p>Merging the neighboring objects' states with the distances under a threshold is proposed in <ref type="bibr" target="#b2">[3]</ref> already. However, it Algorithm 2 Track Merging using the SIOA Metric X k : a set of states at time k σm : threshold for merging G k : a set {key:id,value:states} of occlusion groups at time k 1: function MERGE(X k ,σm,G k ) 2: l = |X k |; // l : the number of states X k 3:</p><p>Let M [1 . . . l][1 . . . l] be the array set to all false; /* measure occlusion ratio between all states 4: by using the SIOA metric */ 5:</p><p>for i = 1 to l do 6:</p><p>for j = i + 1 to l do 7:</p><formula xml:id="formula_44">rocc = SIOA X k [i],X k [j]</formula><p>; // SIOA occlusion ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>if rocc &gt; σm then 9:</p><p>M [i][j] = true; // check to be merged 10:</p><p>M [j][i] = true; // double check 11:</p><p>else if rocc ≤ σm and rocc &gt; 0 then 12: can only reflect point-to-point distance without considering regional information e.g., overlapping ratio between visual objects (bounding boxes). To measure the overlapping ratio, the intersection-over-union (IOU) metric has been widely used which was originally designed to measure mAP in object detection research fields <ref type="bibr" target="#b57">[55]</ref>, <ref type="bibr" target="#b58">[56]</ref>. However, the IOU metric is nice to refine the detection bounding boxes but not adjustable to measure overlapping ratio for merging the objects. <ref type="figure" target="#fig_8">Figure 8</ref> explains that reason by a case study. The case study mainly assumes that the number of detection responses (observations) is larger than the number of real objects. When the observations most likely include false positive detections, the object states by those observations also most likely become the false positive states. So, to handle and consider the characteristic of those observations with the false positive errors, we propose a new metric named as sum-of-intersection-over-area (SIOA). The IOU and SIOA metrics are formulated as follows:</p><formula xml:id="formula_45">id i = X k [i].id, id j = X k [j].id; 13: if id i &lt; id j then 14: G k [id i ] = G k [id i ] ∪ {X k [i], X k [j]}; 15: else 16: G k [id j ] = G k [id j ] ∪ {X k [i], X</formula><formula xml:id="formula_46">IOU AB = area(A) ∩ area(B) area(A)∪area(B) ,<label>(34)</label></formula><formula xml:id="formula_47">SIOA AB = (35) 0.5 * ( area(A) ∩ area(B) area(A)) + area(A) ∩ area(B) area(B)) ),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Occlusion Group Energy Minimization</head><p>k : the current frame number G k−1 : a set of occlusion groups at time k − 1 X k : a set of states at time k 1: function OGEM(k,G k−1 ,X k ) 2: l = |G k−1 |; // l : the number of the groups G k−1 . 3: n = |X k |; // n : the number of the states X k . /*build the GMMs for all occlusion groups at time k-1*/ /*a GMM is used for the defined energy function in (36)*/ 4:</p><p>for i = 1 to l do 5:</p><formula xml:id="formula_48">p i = |G k−1 [i]| P 2</formula><p>//the number of topological vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>GM M [1 . . . p i ]; //the Gaussian mixture for a group. 7:</p><p>for j = 1 to p i do //iterate topologies in a group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Initialize a Gaussian mixture GM M [j] with 9:</p><p>the mean vectors m having topological info and 10:</p><p>the covariance matrix R as defined in <ref type="formula" target="#formula_3">(36)</ref>  where A and B indicate two different objects. area represent a bounding box (x, y, width, height). Algorithm 2 describes the proposed track merging method. Track merging with the SIOA metric follows after the D2T association as presented in Subsection III-B1 and <ref type="figure" target="#fig_0">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Occlusion Group Energy Minimization</head><p>The occlusion group energy minimization method is devised to prevent the true objects which are occluded to others from false merging. In other words, track merging after detectionto-track association (D2TA) may merge occluded objects with correct number of observations into the states with less number of real objects. That can cause tracking errors such as false negative and fragmented tracks.</p><p>Thus, we propose a new energy minimization model to prevent false merging, named as "Occlusion Group Energy Minimization (OGEM)". Each group of occluded objects has an energy function represented by a Gaussian mixture model (GMM) as follows:</p><formula xml:id="formula_49">E(h) = − ln N (t|m, R),<label>(36)</label></formula><p>where h, t, m, and R indicate hypothesis, topological vector, mean vector, and Gaussian covariance marix (noise), respectively. A Gaussian probability function N , i.e., component of the GMM, indicates a topological position vector between two objects in an occlusion group, which is given at time k − 1.</p><p>The Gaussian function has a mean vector m which denotes the topological position, i.e., relative position between the predicted center positions at time k of the objects in the group. Those objects are denoted by x k|k−1 and the notation k|k − 1 indicates the prediction at time k from position and velocity at time k − 1. If there are three occluded objects in a group, six hypotheses exists as shown in <ref type="figure" target="#fig_4">Figure 4</ref>. One hypothesis is a set of six topological vectors {t 1 , t 2 , t 3 , t 4 , t 5 , t 6 }. For example, m 1 is calculated by x 2 k|k−1 − x 1 k|k−1 and t 1 is calculated by x 2 k − x 1 k . In the case that an object state x d k becomes inactive by false merging in occlusion, we build a new hypothesis using a x d k|k−1 as a dummy. Then the dummy added hypothesis recovers the false merged object. If there are n occluded objects in a group, n(n−1) hypotheses exists with the condition 1 &lt; n &lt; 4. Then with these topological models, we can find an optimal one among all hypotheses making the group cost minimal.</p><p>Whereas track merging runs after the D2TA, the proposed occlusion group energy minimization follows Track-to-Track Association (T2TA) as described in <ref type="figure" target="#fig_0">Figure 2</ref>. <ref type="figure">Figure 9</ref> includes some examples to explain that the proposed group energy minimization complements track merging step. The tracking stage at frame 42 explains it.</p><p>In summary, both "Track Merging" and "Oclcusion Group Energy Minimization" procedures assume occlusion situations, and the GMPHD filtering is adopted as the main framework. The pseudo-code examples of proposed occlusion group management scheme are described in Algorithm 2 and 3. Also, both methods correspond to line 8, 35 and 67-78 in Algorithm 1 which represents the whole tracking framework. From now on we use GMPHD-OGM as the abbreviation for the proposed algorithm, online multi-object tracking with the GMPHD filter and occlusion group management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we present development environment including parameter settings, and also discuss evaluation results of the GMPHD-OGM tracker which include an ablation study with baselines and comparisons to state-of-the-art methods. The GMPHD-OGM tracker is implemented by Visual C++ with OpenCV3.4.1 and boost1.61.0 libraries, and without any GPU-accelerated libraries such as CUDA. All experiments are conducted on Windows 10 with Intel i7-7700K CPU @ 4.20GHz and DDR4 32.0GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Setting</head><p>Our proposed tracking framework involves several parameter settings. Parameter σ m indicates the threshold for "Track Merging" which is set to 0.5 in terms of the SIOA metric. 0.5 is set not only empirically set but by considering the occlusion cases between size-variant bounding boxes as shown in Case 4 and 5 of <ref type="figure" target="#fig_8">Figure 8</ref>. τ T 2T and θ T 2T are related to track-totrack association (T2TA) of the hierarchical data association, whose parameters are selected adaptively, scene-by-scene. The optimal values of τ T 2T and θ T 2T are gained from the ablation study presented in <ref type="figure" target="#fig_7">Figure 7</ref>. We use the optimal parameter settings from training to test sequences. These three parameters are summarized in <ref type="table" target="#tab_4">Table I</ref>.</p><p>The GMPHD filtering process has a set of static parameters. The matrices F , Q, P , R, and H are used in Prediction</p><p>Step and Update Step. Also, θ w is used in Pruning Step. Experimentally, we set the parameters for the GMPHD filter's tracking process as follows:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Results</head><p>In this section, we evaluated the propose method with state-of-the-art online <ref type="bibr" target="#b15">[14]</ref>- <ref type="bibr" target="#b17">[16]</ref>, <ref type="bibr" target="#b19">[18]</ref>- <ref type="bibr" target="#b26">[25]</ref>, <ref type="bibr" target="#b38">[37]</ref>- <ref type="bibr" target="#b44">[43]</ref> and offline <ref type="bibr" target="#b27">[26]</ref>- <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b45">[44]</ref>- <ref type="bibr" target="#b52">[50]</ref> MOT methods in terms of the CLEAR-MOT metrics <ref type="bibr" target="#b56">[54]</ref>. The CLEAR-MOT metrics gracefully measure multi-object tracking performance from the detailed perspectives such as multi-object tracking accuracy (MOTA), multi-object tracking precision (MOTP), mostly tracked objects (MT), mostly lost objects (ML), the total number of flase positives (FP), the total number of false negatives <ref type="figure">(missed tracks, FN)</ref>, the total number of identity switches (IDS), the total number of times that a trajectory is fragmented (Frag), and processing speed (frames per second, FPS). Among these metrics, MOTA is normally proposed as the key metric, because it considers three error sources including FP, FN, and IDS, comprehensively. The evaluation results contain not only the tracking results on the MOT15 and MOT17 test datasets but also an ablation study on the MOT15 training dataset.</p><p>First, in the ablation study, we employ the two baseline methods, to find optimal parameters settings and to prove the effectiveness of the proposed method. One is the GMPHD filter based tracker with the hierarchical data association (HDA) and without the occlusion group management (OGM). The other is the GMPHD filter based tracker with HDA and OGM by using the IOU metric for measuring occlusion ratio. We name these three methods as GMPHD-HDA, GMPHD-OGM (/w IOU), and GMPHD-OGM (/w SIOA) as shown in <ref type="table" target="#tab_4">Table II</ref> and <ref type="figure" target="#fig_7">Figure 7</ref>. The GMPHD-OGM (/w SIOA) method is our final tracking model. The scene-by-scene optimal parameter settings of those three methods are obtained by another ablation study as shown in <ref type="figure" target="#fig_7">Figure 7</ref>. The same τ T 2T and θ T 2T settings are applied to the whole training sequences with the range {1, 2, 3} and {5, 10, 20, 30, 50, 70, 100}, respectively. GMPHD-OGM (/w IOU) is improved over GMPHD-HDA in terms of the upper bound of tracking accuracy (the maximum MOTA). GMPHD-OGM (/w SIOA) shows that upper bound and lower bound of tracking accuracy increases. Besides, with θ T 2T over 20, the maximum and minimum values of MOTA increase on average. <ref type="figure" target="#fig_8">Figure 8</ref> shows the comparison results of "Track Merging" between using the IOU metric and the SIOA metric when the detection results with a lot of false positives are given. Also, through the case study on occlusion, we observe that the IOU metric cannot consider size-variant detections with false positives and too sensitive to be used for merging as shown in <ref type="figure" target="#fig_8">Figure 8</ref>. On the other hand, the SIOA metric can consider the size-variant detection and the optimal value of merging threshold σ m is decided to be 0.5 by the occlusion cases 4 and 5, empirically. <ref type="table" target="#tab_4">Table II</ref> provides the quantitative results on the MOT15 training dataset with the best performance results on each sequence and σ m = 0.5. GMPH-OGM (w/ IOU) does not show outstanding improvement compared to GMPHD-HDA even though GMPHD-OGM (w/ IOU) takes more processing time since the OGM scheme runs whereas it does not in GMPHD-HDA. GMPHD-OGM (w/ SIOA) shows meaningful improvements in terms of MOTA, The ablation study proves that GMPHD-OGM is not only overall improved but also more robust and less sensitive in parameters than baseline methods. <ref type="figure">Figure 9</ref> demonstrates some qualitative results of our tracking framework in view of overall process. Detection results (observations) initialize tracking objects (states). In the sequential tracking process, the states are associated with the proper observations by the detection-to-track association (D2TA) using the GMPHD filtering process. From false positive detections, false positive tracks can be generated and then "Track Merging" handles it. If objects are occluded and their IDs are switched, track-to-track association (T2TA) can recover their IDs. In the case that "Track Merging" merges true tracks (false merging), the occlusion group energy minimization (OGEM) process can recover it which optimizes energy of a group of occluded objects at current time by calculating the probability of the Gaussian mixture model as described in Subsection IV-B. <ref type="table" target="#tab_4">Table III</ref> and IV show the quantitative evaluations results on MOT15 and MOT17 test dataset, respectively. Those two benchmark datasets have crucial different characteristics. First, provided public detection results are different, MOT15 provides ACF <ref type="bibr" target="#b8">[8]</ref> detector based detections, and MOT17 provides three types of detections such as DPM <ref type="bibr" target="#b9">[9]</ref>, FRCNN <ref type="bibr" target="#b10">[10]</ref>, and SDP <ref type="bibr" target="#b12">[11]</ref>. Compared to the DNN based detectors FRCNN and SDP, ACF and DPM exploit hand-crafted features learning and models, and thus show relatively poor performance. DPM generates more false positives than FRCNN and SDP do, and especially ACF misses much more objects than others do. Thus, in MOT15, state-of-the-art trackers shows wider range of MOTA distribution than that in MOT17. Among online methods, the trackers with DNN <ref type="bibr" target="#b15">[14]</ref>, <ref type="bibr" target="#b38">[37]</ref> shows the top MOTA scores in MOT15 and MOT17, respectively. Our method achieves the second best MOTA 30.7 vs. the best speed 169.5 fps in MOT15, but we think that the performance is competitive and enough to consider real-time application. In <ref type="figure" target="#fig_6">Figure 5</ref>-(a), the proposed method is located in a distinguished spot in terms of tracking accuracy (MOTA) vs. speed (fps). That also proves effectiveness of our occlusion group based object analysis (OGM), compared to other relation analysis between all objects in the scene <ref type="bibr" target="#b22">[21]</ref>, <ref type="bibr" target="#b24">[23]</ref>. However, in MOT17, the speed of the proposed method decreases to 30.7 fps. That speed still belongs to real-time processing time but is not outstanding compared to other online methods. That is caused by the second different point between two datatsets. MOT15 includes 5783 frames with 721 tracks, 61440 bounding boxes, and 10.6 density i.e., the average number of objects a frame, whereas MOT17 includes 17757 frames with 2355 tracks, 564228 bounding boxes, and 31.8 density. Because MOT17 has the scenes not only with much higher density but also accurate detection results, those points increase tracking accuracy and processing time.  proves those facts where the performances of state-of-the-art methods are saturated on the spot with MOTA around 50 and speed under 5 fps. Even though our method achieves the second best MOTA and speed among online approaches in MOT17, the speed is drastically decreased compared to MOT15. <ref type="figure">Figure 6</ref> explains that reason. In MOT17-03, the speed is around 10 fps since many objects appear in the scene with 69.8 density which means the average number of objects per frame. That makes the number of track-totrack association greatly increase. The proposed method is still comparative and positioned at meaningful spot for realtime application as shown in <ref type="figure" target="#fig_6">Figure 5-(b)</ref>. In addition to our tracking algorithm (GMPHD-OGM), many PHD filter based online approaches <ref type="bibr" target="#b17">[16]</ref>, <ref type="bibr" target="#b19">[18]</ref>, <ref type="bibr" target="#b23">[22]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b42">[41]</ref>- <ref type="bibr" target="#b44">[43]</ref> have been proposed in the past decade. Against them, GMPHD-OGM achieves not only the best MOTA, MOTP, MT, ML, FN, and speed scores on MOT15 but also the second best MOTA, speed, and best MT, FN, and Frag scores in MOT17. Especially, against to state-of-the-art online approaches, the proposed method is distinguished in terms of tracking accuracy (MOTA) vs. speed (fps), even though we did not utilize any complex visual features except bounding boxes. Also, the proposed tracker (GMPHD-OGM) against state-of-the-art algorithms including online with DNN even including offline, GMPHD-OGM shows the competitive MOTA versus speed as <ref type="figure">Fig. 6</ref>: Speed comparison of the proposed tracking method on MOT17 test dataset which provides three types of detection results for each scene, including DPM <ref type="bibr" target="#b9">[9]</ref>, FRCNN <ref type="bibr" target="#b10">[10]</ref>, and SDP <ref type="bibr" target="#b12">[11]</ref>. described in <ref type="figure" target="#fig_6">Figure 5</ref>, <ref type="table" target="#tab_4">Table III, and Table IV</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND FUTURE WORK</head><p>In this paper, we proposed an efficient online multi-object tracking framework with the GMPHD filter and the occlusion group management (OGM) named as GMPHD-OGM. In the proposed framework, our first contribution is that the Gaussian mixture probability hypothesis density (GMPHD) filter <ref type="bibr" target="#b2">[3]</ref> is exploited to resolve MOT task. Since the GMPHD filter is originally designed to handle MOT in radar/sonar system, we should revise the filter to fit to video data system. To resolve missed tracks problem in the difference domain, we extended the conventional GMPHD filtering process with the hierarchical data association (HDA) strategy as explained in <ref type="figure" target="#fig_3">Figure 1</ref>. The second contribution is that to solve the occlusion problems, we proposed an occlusion group management (OGM) scheme. OGM is composed of "Track Merging" and "Occlusion Group Energy Minimization (OGEM)". "Track Merging" reduced the number of false positives by merging them. The OGEM prevents false merging between true tracks. Both modules complement each other, and also instead of the IOU metric, we designed a new metric named as sum-ofintersection-over-area (SIOA) to measure the occlusion ratio between visual objects. The third is that the effectiveness of our tracker (GMPHD-OGM) was introduced by the ablation study with the baselines and the evaluation results on MOT15 <ref type="bibr" target="#b4">[5]</ref> and MOT17 <ref type="bibr" target="#b6">[6]</ref> benchmarks with state-of-the-art MOT methods. The ablation study proves that GMPHD-OGM (w/ SIOA) is more efficient to solve the defined problems than the given baseline methods such as GMPHD-HDA and GMPHD-OGM (w/ IOU). GMPHD-OGM achieves the best MOTA scores in MOT15 and MOT17 datasets, respectively, in comparison with the PHD filter based online trackers <ref type="bibr" target="#b17">[16]</ref>, <ref type="bibr" target="#b19">[18]</ref>, <ref type="bibr" target="#b23">[22]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b42">[41]</ref>- <ref type="bibr" target="#b44">[43]</ref>. Finally, by the comprehensive evaluation, we conclude the proposed tracker (GMPHD-OGM) against state-of-the-art algorithms including online with DNN even including offline, GMPHD-OGM shows the competitive value in "MOTA versus speed". As a future work, we will develop an efficient real-time tracker even with the number of objects over hundred, simultaneously, achieving the state-ofthe-art level tracking accuracy. II: Quantitative evaluation results on MOT15 training dataset. The proposed method namely GMPHD-OGM (w/ SIOA) is compared to two baseline methods GMPHD-HDA and GMPHD-OGM (w/ IOU). GMPHD-HDA employs the GMPHD filtering with hierarchical data association (HDA). GMPHD-OGM is equal to GMPHD-HDA with the proposed occlusion group management (OGM). The IOU and SIOA metrics are used for "Track Merging" in GMPHD-OGM (w/ IOU) and (w/ SIOA), respectively. The optimal values of the merging threshold σ m are underlined and the best scores are in bold in terms of the CLEAR-MOT metrics.   IV: Quantitative evaluation results on MOT17 test dataset. The proposed method is compared to state-of-the-art in terms of the CLEAR-MOT metrics. For each mode, i.e, online and offline, the first and the second best scores are highlighted in red and blue in terms of each metric.   Under the different merging threshold σ m values 0.4 and 0.5, the IOU metric is more sensitive than the SIOA metric. The SIOA metric is more robust to merge size variant false positive bounding boxes than IOU metric. <ref type="figure">Fig. 9</ref>: Illustration of the proposed multi-object tracking process with the qualitative results on MOT17-08-DPM test sequence. The whole process consists of four components which are D2TA, Merge, T2TA, and OGEM. Qualitative tracking results at frame 42, 66, 184, and 190 present that all components are complementary to each other with handling tracking problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Flow chart of the proposed online multi-object tracking framework. The red dotted line divides the proposed hierarchical data association into two stages. Each stage and its states and observations are marked as blue and red, i.e., D2TA and T2TA, respectively. The key components of this chart, such as init, D2TA, Merge, T2TA, OGEM, live and lost tracklets are used inFigure 3andFigure 9, also.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>In the proposed tracking framework, an object with state S 1 : Init is transited within the defined states {S 2 , S 3 , S 4 , S 5 } by the state-transition functions {p 1 , p 2 , p 3 , p 4 , p 5 , p 6 , p 7 , p 8 , p 9 }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and the oldest element a j s of live tracklet τ live j,k . The pseudo-code in Algorithm 1 includes the procedures presented in this section. Initialization, Prediction, Costminimization, Update, and Pruning in D2TA correspond to each of line 5-10, 13-15, 16-21, 22-24, and 25-27 in Algorithm 1. Tracklet-categorization, Cost-minimization, Update in T2TA correspond to line 36-44, 49-54, and 55-66 in Algorithm 1, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1</head><label>1</label><figDesc>Proposed Online MOT Algorithm k : the current frame number X k−1 : a set of states at time k − 1 Z k : a set of observations at time k σm : threshold for track merging τ T 2T : the minimum track length for T2TA θ T 2T : the maximum frame interval for T2TA T live : a {key:id,value:tracklet} set of live tracklets T lost : a {key:id,value:tracklet} set of lost tracklets 1: procedure GMPHD OGM(k,X k−1 ,Z k ,σm,τ T 2T ,θ T 2T ,T live ,T lost ) 2: l = |X k−1 |; // the number of states 3: m = |Z k |; // the number of observations 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Illustration of the proposed occlusion group energy minimization represented by the Gaussian mixture model. Six hypotheses exist in the case of three occluded objects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Comparisons of tracking accuracy against speed with the state-of-the-art methods on the (a) MOT15 and (b) MOT17 test sequences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :</head><label>7</label><figDesc>Ablation study with the two baseline methods, i.e., GMPHD-HDA and GMPHD-OGM (with IOU) IOU. The final proposed method is GMPHD-OGM (with SIOA). Three graphs indicates the MOTA scores' distributions against (a) the minimum track length for T2TA (τ T 2T ) and the maximum frame interval for T2TA (θ T 2T ), (b) τ T 2T , and (c) θ T 2T . GMPHD-OGM (with SIOA) shows overall improvement in upper and lower bound of MOTA score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Case study about "Track Merging" with the qualitative results on MOT17-05-DPM training sequence at frame 254. For the same detection results, the overlapping ratios between the occluded objects are measured with IOU 0.4 and SIOA 0.6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I :</head><label>I</label><figDesc></figDesc><table><row><cell cols="2">Symbol Description</cell><cell>Value</cell></row><row><cell>σm</cell><cell>threshold for track merging.</cell><cell>0.5</cell></row><row><cell>τ T 2T</cell><cell>the minimum track length for T2TA</cell><cell>1, 2, 3</cell></row><row><cell>θ T 2T</cell><cell>the maximum frame interval for T2TA</cell><cell>5 to 100</cell></row></table><note>Parameter Settings for "Track Merging" and track- to-track association (T2TA).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE III :</head><label>III</label><figDesc>Quantitative evaluation results on MOT15 test dataset. The proposed method is compared to state-of-the-art in terms of the CLEAR-MOT metrics. For each mode, i.e, online and offline, the first and the second best scores are highlighted in red and blue in terms of each metric. The final proposed model is GMPHD-OGM (w/ SIOA).</figDesc><table><row><cell>Mode</cell><cell>Tracker</cell><cell>DNN</cell><cell>MOTA↑</cell><cell>MOTP↑</cell><cell>MT↑</cell><cell>ML↓</cell><cell>FP↓</cell><cell>FN↓</cell><cell>IDS↓</cell><cell>Frag↓</cell><cell>Speed↑</cell></row><row><cell></cell><cell>CDA DDAL [14]</cell><cell>O</cell><cell>32.8 %</cell><cell>70.7 %</cell><cell>9.7 %</cell><cell>42.2 %</cell><cell>4,983</cell><cell>35,690</cell><cell>614</cell><cell>1,583</cell><cell>2.3 fps</cell></row><row><cell></cell><cell>HAM SADF [15]</cell><cell>O</cell><cell>28.6 %</cell><cell>71.1 %</cell><cell>10.0 %</cell><cell>44.0 %</cell><cell>7,485</cell><cell>35,910</cell><cell>460</cell><cell>1,038</cell><cell>18.7 fps</cell></row><row><cell></cell><cell>Proposed*</cell><cell>X</cell><cell>30.7 %</cell><cell>71.6 %</cell><cell>11.5 %</cell><cell>38.1 %</cell><cell>6,502</cell><cell cols="2">35,030 1,034</cell><cell>1,351</cell><cell>169.5 fps</cell></row><row><cell></cell><cell>PHD GSDL [18]</cell><cell>X</cell><cell>30.5 %</cell><cell>71.2 %</cell><cell>7.6 %</cell><cell>41.2 %</cell><cell>6,534</cell><cell>35,284</cell><cell>879</cell><cell>2,208</cell><cell>8.2 fps</cell></row><row><cell>Online</cell><cell>MDP [19] TBSS [20] SCEA [21] EAMTT [22]</cell><cell>X X X X</cell><cell>30.3 % 29.2 % 29.1 % 22.3 %</cell><cell>71.3 % 71.3 % 71.1 % 69.6 %</cell><cell>14.0 % 6.8 % 8.9 % 5.4 %</cell><cell>38.4 % 43.8 % 47.3 % 52.7 %</cell><cell>9,717 6,068 6,060 7,924</cell><cell>32,422 36,779 36,912 38,982</cell><cell>680 649 604 833</cell><cell>1,500 1,508 1,182 1,485</cell><cell>1.1 fps 11.5 fps 6.8 fps 12.2 fps</cell></row><row><cell></cell><cell>RMOT [23]</cell><cell>X</cell><cell>18.6 %</cell><cell>69.6 %</cell><cell>5.3 %</cell><cell>53.3 %</cell><cell cols="2">12,473 36,835</cell><cell>684</cell><cell>1,282</cell><cell>7.9 fps</cell></row><row><cell></cell><cell>GMPHD HDA [16]</cell><cell>X</cell><cell>18.5 %</cell><cell>70.9 %</cell><cell>3.9 %</cell><cell>55.3 %</cell><cell>7,864</cell><cell>41,766</cell><cell>459</cell><cell>1,266</cell><cell>19.8 fps</cell></row><row><cell></cell><cell>GSCR [24]</cell><cell>X</cell><cell>15.8 %</cell><cell>69.4 %</cell><cell>1.8 %</cell><cell>61.0 %</cell><cell>7,597</cell><cell>43,633</cell><cell>514</cell><cell>1,010</cell><cell>28.1 fps</cell></row><row><cell></cell><cell>TC ODAL [25]</cell><cell>X</cell><cell>15.1 %</cell><cell>70.5 %</cell><cell>3.2 %</cell><cell>55.8 %</cell><cell cols="2">12,970 38,538</cell><cell>637</cell><cell>1,716</cell><cell>1.7 fps</cell></row><row><cell></cell><cell>MHT DAM [28]</cell><cell>O</cell><cell>32.4 %</cell><cell>71.8 %</cell><cell>16.0 %</cell><cell>43.8 %</cell><cell>9,064</cell><cell>32,060</cell><cell>435</cell><cell>826</cell><cell>0.7 fps</cell></row><row><cell></cell><cell>CNNTCM [26]</cell><cell>O</cell><cell>29.6 %</cell><cell>71.8 %</cell><cell>11.2 %</cell><cell>44.0 %</cell><cell>7,786</cell><cell>34,733</cell><cell>712</cell><cell>943</cell><cell>1.7 fps</cell></row><row><cell></cell><cell>SiameseCNN [27]</cell><cell>O</cell><cell>29.0 %</cell><cell>71.2 %</cell><cell>8.5 %</cell><cell>48.4 %</cell><cell>5,160</cell><cell>37,798</cell><cell>639</cell><cell>1,316</cell><cell>52.8 fps</cell></row><row><cell></cell><cell>NOMT [29]</cell><cell>X</cell><cell>33.7 %</cell><cell>71.9 %</cell><cell>12.2 %</cell><cell>44.6 %</cell><cell>7,762</cell><cell>32,547</cell><cell>442</cell><cell>823</cell><cell>11.5 fps</cell></row><row><cell>Offline</cell><cell>ELP [30] JPDA m [31] MotiCon [32]</cell><cell>X X X</cell><cell>25.0 % 23.8 % 23.1 %</cell><cell>71.2 % 68.2 % 70.9 %</cell><cell>7.5 % 5.0 % 4.7 %</cell><cell>43.8 % 58.1 % 52.0 %</cell><cell cols="3">7,345 6,373 10,404 35,844 1,018 37,344 1,396 70,084 365</cell><cell>1,804 869 1,061</cell><cell>5.7 fps 32.6 fps 1.4 fps</cell></row><row><cell></cell><cell>SegTrack [33]</cell><cell>X</cell><cell>22.5 %</cell><cell>71.7 %</cell><cell>5.8 %</cell><cell>63.9 %</cell><cell>7,890</cell><cell>39,020</cell><cell>697</cell><cell>737</cell><cell>0.2 fps</cell></row><row><cell></cell><cell>CEM [34]</cell><cell>X</cell><cell>19.3 %</cell><cell>70.7 %</cell><cell>8.5 %</cell><cell>46.5 %</cell><cell cols="2">14,180 34,591</cell><cell>813</cell><cell>1,023</cell><cell>1.1 fps</cell></row><row><cell></cell><cell>SMOT [35]</cell><cell>X</cell><cell>18.2 %</cell><cell>71.2 %</cell><cell>2.8 %</cell><cell>54.8 %</cell><cell>8,780</cell><cell cols="2">40,310 1,148</cell><cell>2,132</cell><cell>2.7 fps</cell></row><row><cell></cell><cell>DP NMS [36]</cell><cell>X</cell><cell>14.5 %</cell><cell>70.8 %</cell><cell>5.0 %</cell><cell>40.8 %</cell><cell cols="3">13,171 34,814 4,537</cell><cell>3,090</cell><cell>444.8 fps</cell></row><row><cell>*</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multitarget Bayes Filtering via First-Order Multitarget Moments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P S</forename><surname>Mahler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerosp. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1152" to="1178" />
			<date type="published" when="2003-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sequential Monte Carlo implementation of the PHD filter for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-N</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Information Fusion (ICIF)</title>
		<meeting>Int. Conf. Information Fusion (ICIF)</meeting>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="792" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Gaussian mixture probability hypothesis density filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-N</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4091" to="4104" />
			<date type="published" when="2006-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Random finite sets in multi-object filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-T</forename><surname>Vo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Perth, Australia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>School of Electrical, Electronic and Computer Engineering, The Univ. of Western Australia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">MOTChallenge 2015: Towards a benchmark for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<ptr target="http://arxiv.org/abs/1504.01942" />
		<title level="m">Available</title>
		<imprint>
			<date type="published" when="2015-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">MOT16: A Benchmark for Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1603.00831" />
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast feature pyramids for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Appel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1532" to="1545" />
			<date type="published" when="2014-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Int</title>
		<meeting>28th Int</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Conf. Neural Inf. Process. Syst. (NIPS)</title>
		<meeting><address><addrLine>Montréal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploit all the layers: Fast and accurate cnn object detector with scale dependent pooling and cascaded rejection classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="2129" to="2137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evolving boxes for fast vehicle detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Multi. Expo (ICME)</title>
		<meeting>IEEE Conf. Multi. Expo (ICME)</meeting>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="1135" to="1140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Real-Time Multiple Object Tracking -A Study on the Importance of Speed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Murray</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1709.03572" />
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Confidence-Based Data Association and Discriminative Deep Appearance Learning for Robust Online Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="595" to="610" />
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online Multi-Object Tracking with Historical Appearance Matching and Scene Adaptive Detection Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boragule</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</title>
		<meeting>IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</meeting>
		<imprint>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Online Multiple Object Tracking with the Hierarchically Adopted GM-PHD Filter using Motion and Appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Consumer Electronics-Asia (ICCE-Asia)</title>
		<meeting>IEEE Int. Conf. Consumer Electronics-Asia (ICCE-Asia)</meeting>
		<imprint>
			<date type="published" when="2016-10" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online and Real-Time Tracking with the GMPHD Filter using Group Management and Relative Motion Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</title>
		<meeting>IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</meeting>
		<imprint>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Particle phd filter based multiple human tracking using online group-structured dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Angelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Naqvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="14764" to="14778" />
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to Track: Online Multi-Object Tracking by Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="page" from="4705" to="4713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Online Multi-Object Tracking with Structural Invariance Constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf. (BMVC)</title>
		<meeting>Brit. Mach. Vis. Conf. (BMVC)</meeting>
		<imprint>
			<date type="published" when="2018-09" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online Multi-object Tracking via Structural Constraint Event Aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="1392" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-target tracking with strong and weak detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sanchez-Matilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Poiesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis. Workshops (ECCVW)</title>
		<meeting>Eur. Conf. Comput. Vis. Workshops (ECCVW)</meeting>
		<imprint>
			<date type="published" when="2016-10" />
			<biblScope unit="page" from="84" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bayesian Multi-Object Tracking Using Motion Context from Multiple Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV)</title>
		<meeting>IEEE Winter Conf. Appl. Comput. Vis. (WACV)</meeting>
		<imprint>
			<date type="published" when="2015-01" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Online multiperson tracking based on global sparse collaborative representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fagot-Bouquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Audigier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dhome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lerasle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Image Processing (ICIP)</title>
		<meeting>IEEE Conf. Image essing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="2414" to="2418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robust Online Multi-Object Tracking based on Tracklet Confidence and Online Discriminative Appearance Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="1218" to="1225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Joint Learning of Convolutional Neural Networks and Temporally Constrained Metrics for Tracklet Association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="386" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning by Tracking: Siamese CNN for Robust Target Association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Canton-Ferrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiple Hypothesis Tracking Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ciptadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="page" from="4696" to="4704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Near-Online Multi-target Tracking with Aggregated Local Flow Descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="page" from="3029" to="3037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enhancing Linear Programming with Motion Modeling for Multi-target Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M D</forename><surname>Rincon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV)</title>
		<meeting>IEEE Winter Conf. Appl. Comput. Vis. (WACV)</meeting>
		<imprint>
			<date type="published" when="2015-01" />
			<biblScope unit="page" from="71" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Joint Probabilistic Data Association Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="page" from="3047" to="3055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning an image-based motion context for multiple people tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fenzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="3542" to="3549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint Tracking and Segmentation of Multiple Targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="5397" to="5406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Continuous Energy Minimization for Multitarget Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="72" />
			<date type="published" when="2014-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The Way They Move: Tracking Targets with Similar Appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dicle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">I</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013-12" />
			<biblScope unit="page" from="2304" to="2311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Globally-Optimal Greedy Algorithms for Tracking a Variable Number of Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="1201" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Real-time Multiple People Tracking with Deeply Learned Candidate Selection and Person Reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haizhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zijie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Multi. Expo (ICME)</title>
		<meeting>IEEE Conf. Multi. Expo (ICME)</meeting>
		<imprint>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-Level Cooperative Fusion of GM-PHD Filters for Online Multiple Human Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Angelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Naqvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE trans. Multimedia</title>
		<imprint>
			<date type="published" when="2019-03" />
			<publisher>Early Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Online Multi-Object Tracking with Dual Matching Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Eur. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2019-02" />
			<biblScope unit="page" from="366" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning Discriminative Appearance Models for Online Multi-Object Tracking with Appearance Discriminability Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y.</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Bae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="67316" to="67328" />
			<date type="published" when="2018-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Development of a N-type GM-PHD filter for multiple target, multiple type visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Baisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sequential Sensor Fusion Combining Probability Hypothesis Density and Kernelized Correlation Filters for Multi-Object Tracking in Video Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kutschbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bochinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Eiselein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</title>
		<meeting>IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</meeting>
		<imprint>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Real-time Multi-Human Tracking using a Probability Hypothesis Density Filter and multiple detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Eiselein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pätzold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Adv. Video Signal Based Surveill. (AVSS)</title>
		<meeting>IEEE Int. Conf. Adv. Video Signal Based Surveill. (AVSS)</meeting>
		<imprint>
			<date type="published" when="2012-09" />
			<biblScope unit="page" from="325" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Heterogeneous Association Graph Fusion for Target Association in Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Early Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Fusion of Head and Full-Body Detectors for Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<title level="m">IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2018-06" />
			<biblScope unit="page" from="1428" to="1437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Motion Segmentation &amp; Multiple Object Tracking by Correlation Co-Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2018-10" />
			<publisher>Early Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Iterative Multiple Hypothesis Tracking with Tracklet-level Association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Early Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Enhancing Detection Model for Multiple Hypothesis Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">High-Speed Tracking-by-Detection Without Using Image Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bochinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Eiselein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</title>
		<meeting>IEEE Int. Workshop Traffic Street Surveill. Safety Secur. (AVSS)</meeting>
		<imprint>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Multi-object Tracking with Neural Gating Using Bilinear LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Eur. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018-09" />
			<biblScope unit="page" from="200" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning a Similarity Metric Discriminatively</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deeply-learned part-aligned representations for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="3239" to="3248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">High-Speed Tracking with Kernelized Correlation Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="583" to="596" />
			<date type="published" when="2015-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Image and Video Processing</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The Pascal Visual Object Classes Challenge: A Retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
