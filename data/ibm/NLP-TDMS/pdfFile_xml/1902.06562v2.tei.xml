<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/ 1 Intra-and Inter-epoch Temporal Context Network (IITNet) Using Sub-epoch Features for Automatic Sleep Scoring on Raw Single-channel EEG</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hogeon</forename><surname>Seo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghyeok</forename><surname>Back</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seongju</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deokhwan</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoobin</forename><surname>Lee</surname></persName>
						</author>
						<title level="a" type="main">-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/ 1 Intra-and Inter-epoch Temporal Context Network (IITNet) Using Sub-epoch Features for Automatic Sleep Scoring on Raw Single-channel EEG</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.bspc.2020.102037</idno>
					<note>Accepted manuscript for Biomedical Signal Processing and Control.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-deep learning</term>
					<term>classification</term>
					<term>single-channel EEG</term>
					<term>sleep scoring</term>
					<term>sequence</term>
					<term>temporal context</term>
					<term>end-to-end</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A deep learning model, named IITNet, is proposed to learn intra-and inter-epoch temporal contexts from raw single-channel EEG for automatic sleep scoring. To classify the sleep stage from half-minute EEG, called an epoch, sleep experts investigate sleep-related events and consider the transition rules between the found events. Similarly, IITNet extracts representative features at a sub-epoch level by a residual neural network and captures intra-and inter-epoch temporal contexts from the sequence of the features via bidirectional LSTM. The performance was investigated for three datasets as the sequence length (L) increased from one to ten. IITNet achieved the comparable performance with other state-of-the-art results. The best accuracy, MF1, and Cohen's kappa (κ) were 83.9%, 77.6%, 0.78 for SleepEDF (L=10), 86.5%, 80.7%, 0.80 for MASS (L=9), and 86.7%, 79.8%, 0.81 for SHHS (L=10), respectively. Even though using four epochs, the performance was still comparable. Compared to using a single epoch, on average, accuracy and MF1 increased by 2.48%p and 4.90%p and F1 of N1, N2, and REM increased by 16.1%p, 1.50%p, and 6.42%p, respectively. Above four epochs, the performance improvement was not significant. The results support that considering the latest two-minute raw single-channel EEG can be a reasonable choice for sleep scoring via deep neural networks with efficiency and reliability. Furthermore, the experiments with the baselines showed that introducing intra-epoch temporal context learning with a deep residual network contributes to the improvement in the overall performance and has the positive synergy effect with the interepoch temporal context learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Sleep scoring, also known as "sleep stage classification" and "sleep stage identification," is essential for diagnosis and treatment of sleep disorders <ref type="bibr" target="#b0">[1]</ref>. Many individuals suffering from sleep disorders are at risk of underlying health problems <ref type="bibr" target="#b1">[2]</ref>. Typical sleep disorders (e.g., sleep apnea, narcolepsy, and sleepwalking) can be diagnosed via polysomnography (PSG) <ref type="bibr" target="#b2">[3]</ref>, the gold standard of sleep scoring. PSG is based on the biosignals of body functions such as brain activity (electroencephalogram, EEG), eye movement (electrooculogram, EOG), heart rhythm (electrocardiogram, ECG), and muscle activity of the chin, face, or limbs (electromyogram, EMG). These recorded signals are analyzed by trained human experts, who label each 20-or 30-second segment of PSG data (an "epoch") with its corresponding sleep stage. The sleep stages are classified into wakefulness (W), rapid eye movement (REM), and non-REM (NREM) following the Rechtschaffen and Kales (R&amp;K) rules <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> or the American Academy of Sleep Medicine (AASM) rules <ref type="bibr" target="#b5">[6]</ref>. For the AASM rules, NREM is further divided into three stages, referred to as S1, S2, and S3 or N1, N2, and N3. To draw a whole-night hypnogram showing the sleep stage as a function of sleep time, experts must visually inspect all epochs and label their sleep stages. This manual sleep scoring is labor-intensive and time-consuming <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b8">[9]</ref>. Thus, automatic sleep scoring for healthcare and well-being is in high demand.</p><p>Many sleep scoring methods for automatic analysis of PSG data have been proposed. In particular, handcrafted feature extraction techniques have been widely used <ref type="bibr" target="#b9">[10]</ref>. The features can be extracted from time-domain signals <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, frequency/time-frequency domain data <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b15">[16]</ref>, or non-linear parameters <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b18">[19]</ref>, and have been analyzed using fuzzy classification <ref type="bibr" target="#b2">[3]</ref>, decision trees <ref type="bibr" target="#b16">[17]</ref>, random forest algorithms <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, and support vector machines <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b19">[20]</ref>. In some cases, multi-channel or multi-modality data have been used <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Such previous studies have shown that the application of machine learning to handcrafted features is effective for automatic sleep scoring. However, the associated approaches may require additional handcrafted tuning to analyze PSG data obtained from different recording environments, as the features are handengineered based on the specific PSG system and available datasets <ref type="bibr" target="#b20">[21]</ref>.</p><p>Deep learning has been adopted to score sleep stages from PSG data automatically. When human sleep experts score the sleep stage of an epoch, they generally find the sleeprelated event (such as a K-complex, sleep spindle, or frequency components: alpha, beta, delta, and theta activities) in the epoch. Then, they analyze the relations between the sleeprelated events and sleep stages in its neighboring epochs. Thus, they inspect the data at both intra-and inter-epoch levels. In <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b27">[28]</ref>, features were extracted by convolutional neural networks (CNNs). Some deep neural networks have learned features from multi-channel or multi-modality data to improve sleep scoring performance <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. Recently, recurrent neural networks (RNNs) are being adopted to consider transition rules such as those of the AASM manual and arXiv:1902.06562v2 <ref type="bibr">[cs.</ref>LG] 10 Jun 2020 to learn temporal information from the sequence of epochs <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>- <ref type="bibr" target="#b34">[35]</ref>. For instance, an epoch can be labeled N2 when K-complexes or sleep spindles exist in the last half of its preceding epoch. <ref type="bibr">Supratak et al. used</ref> RNNs to consider the inter-epoch temporal context between epoch-wise features individually extracted from each epoch by CNNs <ref type="bibr" target="#b20">[21]</ref>. Their results showed that consideration of the transition rules by analyzing the inter-epoch temporal context is essential for automatic sleep scoring. However, this model required two-step training and just considered the inter-epoch temporal context. Phan et al. <ref type="bibr" target="#b30">[31]</ref> introduced RNNs to analyze the temporal context of the representative features extracted from sub-epochs at both the intra-and inter-epoch levels.</p><p>Their results showed that considering both the intra-and interepoch temporal context is effective to improve the performance of sleep scoring. Though the model achieved the state-ofthe-art performance, the model used multi-channel signals and required data preprocessing via the short-time Fourier transform to extract the time-frequency domain data.</p><p>In this paper, intra-and inter-epoch temporal context network (IITNet) is proposed for automatic sleep scoring on raw single-channel EEG. IITNet encodes each sub-epoch of multiple EEG epochs into the corresponding representative feature and analyzes their temporal context at both intra-and interepoch levels. IITNet is an end-to-end deep learning model based on one-step training without data preprocessing such as short-time Fourier transform or filterbank processing. A modified deep residual neural network (ResNet-50) <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref> is used to extract representative features from each epoch (halfminute EEG) at a sub-epoch level. Two layers of bidirectional long short-term memory (BiLSTM) <ref type="bibr" target="#b37">[38]</ref> are used to learn the temporal context of the representative features in the forward and backward directions. The performance was investigated for three public datasets: SleepEDF, Montreal Archive of Sleep Studies (MASS), Sleep Heart Health Study (SHHS). Also, the influence of the number of input epochs, the sequence length (L), was investigated by increasing the sequence length from one to ten.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. IITNET: INTRA-AND INTER-EPOCH TEMPORAL CONTEXT NETWORK A. Model Overview</head><p>IITNet is designed to classify the time-series data by extracting representative features at the sub-epoch level and analyzing their temporal context. In this study, the model is applied to sleep stage classification from raw single-channel EEG. When human sleep experts label each half-minute PSG (target epoch) with its corresponding sleep stage, they visually inspect the frequency characteristics and the sleep-related events such as spindles and K-complexes. Besides, they consider the sleeprelated events in its neighboring epochs to check whether the relations of the events correspond to the transition rules <ref type="bibr" target="#b24">[25]</ref>. Similarly, IITNet learns the sleep-related events by extracting representative features at the sub-epoch level and scores the sleep stages of the target epoch by capturing the contextual information from the sequence of the features.</p><p>IITNet belongs to a convolutional recurrent neural network (CRNN) <ref type="bibr" target="#b38">[39]</ref> and consists of two main parts: CNN and RNN layers, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. The CNN layers learn the representative features associated with the sleep-related events from the EEG. To train the deep CNN effectively, a modified ResNet-50 <ref type="bibr" target="#b35">[36]</ref> is used since its skip connections ensure that the higher layers can perform as good as the lower layer <ref type="bibr" target="#b36">[37]</ref>. For this reason, the ResNet has been widely used in deep networks as a promising feature extractor <ref type="bibr" target="#b39">[40]</ref>- <ref type="bibr" target="#b41">[42]</ref>.</p><p>In the RNN layers, two layers of bidirectional LSTM (BiLSTM) are employed to capture the temporal context from the representative features in both the forward and backward directions <ref type="bibr" target="#b42">[43]</ref>- <ref type="bibr" target="#b44">[45]</ref>. At the top of the model, a softmax classifier is placed to output the most appropriate sleep stage. Specifically, IITNet disassembles each half-minute epoch into l overlapped sub-epochs and encodes each sub-epoch as its corresponding representative feature, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. In the CNN layers, the epoch is converted to feature maps. Each column of the feature maps represents the sub-epoch feature corresponding to its receptive field. These l sub-epoch features are stacked from left to right in chronological order, and then a feature sequence is created for each epoch. The RNN layers analyze the temporal relation between the sub-epoch features.</p><p>For IITNet, the input can be either single epoch or a series of successive epochs. Using only the target epoch as the input, the intra-epoch temporal context can be analyzed at the sub-epoch level. To consider both the intra-and inter-epoch temporal context, the sequence of the target epoch and its neighboring epochs should be fed at a time. In this study, the target epoch and its previous epochs are used as the input, which is practical for real-time sleep scoring in a smart bed or hospital bed because future epochs cannot be measured in advance. This is also clinically reasonable since human experts generally investigate the previous epochs to follow the AASM transition rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Intra-epoch Temporal Context Learning</head><p>For intra-epoch temporal context learning, IITNet takes a target epoch x as an input to model the conditional probability p(y|x), where y is the true sleep stage. In the CNN layers as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, IITNet extracts the representative features f from the sub-epochs and produces a feature sequence F, which contains the sub-epoch features in chronological order as follows:</p><formula xml:id="formula_0">F = {f 1 , f 2 , · · · , f l },<label>(1)</label></formula><p>where f i is the representative feature vector of the i-th sub epoch, and l is the number of the sub epochs. The length of a feature vector is u, which is the number of filters in the last CNN layer. Note that the learnable parameters of the CNN layers are shared. Through backpropagation in training, the parameters are updated with the average of the gradients computed for the sub-epochs.</p><p>In the RNN layers, the BiLSTM has hidden states of dimension u for each direction. The two BiLSTM layers process the feature vector with the previous hidden state in both the forward and backward directions, yielding the internal </p><formula xml:id="formula_1">− → h t = −−−−→ LST M (f t , −−→ h t−1 ),<label>(2)</label></formula><formula xml:id="formula_2">← − h t = ←−−−− LST M (f t , ←−− h t+1 ).<label>(3)</label></formula><p>To predict y, the last hidden states are concatenated to form the bidirectional context ← → h of size 2u. This concatenated vector is fed into the fully connected layer to output p(y|x) for the target epoch. Finally, the softmax classifier labels the epoch with the most likely sleep stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Intra-and Inter-epoch Temporal Context Learning</head><p>To consider the inter-epoch dependency at the sub-epoch level, IITNet takes the target epoch and its previous epochs as an input. The model scores the target epoch based on the temporal context in a series of feature sequences after encoding the target epoch and its previous L − 1 epochs at the sub-epoch level. Therefore, L is the number of epochs for the input. Formally, IITNet is trained to model the following conditional probability:</p><formula xml:id="formula_3">p(y L |x 1 , x 2 , x 3 , · · · , x L ),<label>(4)</label></formula><p>where X L = {x 1 , x 2 , · · · , x L } is a sequence of successive epochs, x L is the target epoch, x 1 , x 2 , · · · , x L−1 are the previous epochs, and y L is the true sleep stage of the target epoch. Since it is practical to predict the latest sleep stage in the view of real-time sleep scoring, the the sleep stage the latest epoch is chosen as the true label.</p><p>In the CNN layers, IITNet individually extracts the feature sequence for each epoch, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. In other words, the CNN layers take the i-th epoch x i and produce a corresponding feature sequence F i . At the top of the convolution layers, a series of feature sequences S L is created as follows: </p><formula xml:id="formula_4">S L = {F 1 , F 2 , · · · , F L }, = {f 1,1 , f 1,2 , · · · , f 1,l , f 2,1 , f 2,2 , · · · , f 2,l , · · · , f L,1 , f L,2 , · · · , f L,l },<label>(5)</label></formula><p>where f i,1 , · · · , f i,l are the sub-epoch feature vectors corresponding to F i . Accordingly, S L includes the entire representative features from the sub epochs in chronological order. Therefore, the RNN layers take the series of the feature sequence. The softmax classifier process S L in the same way as the intra-epoch temporal context learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>To evaluate the sleep scoring performance of IITNet, three public datasets containing PSG records and their corresponding sleep stages labeled by human sleep experts were used: SleepEDF <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, MASS <ref type="bibr" target="#b28">[29]</ref>, and SHHS <ref type="bibr" target="#b48">[49]</ref>. <ref type="table" target="#tab_1">Table I</ref> lists the number of epochs in the datasets for the sleep stages and <ref type="table" target="#tab_1">Table II</ref>   The SleepEDFx dataset (2013 version) contains two types of PSG record: SC for 20 healthy subjects without sleep-related disorders and ST for 22 subjects of a study on Temazepam effects on sleep. Each record includes two-channel EEGs from the Fpz-Cz and Pz-Oz channels, a single-channel EOG, and a single-channel EMG. Each halfminute epoch is labeled as one of eight classes (W, REM, N1, N2, N3, N4, MOVEMENT, UNKNOWN) according to R&amp;K rules. In this study, the single-channel EEGs (Fpz-Cz) in the SC (average subject age: 28.7 ± 2.9 years) were used since the Fpz-Cz has shown higher performance than Pz-Oz with deep-learning based approaches <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b24">[25]</ref>. As the class W group was quite large compared to the others, only sixty epochs (thirty minutes) before and after the sleep period were used <ref type="bibr" target="#b20">[21]</ref>.</p><p>2) MASS: The MASS dataset includes the PSG records of 200 subjects in five subsets: SS1, SS2, SS3, SS4, and SS5. These subsets are grouped according to the research and acquisition protocols. The dataset contains twenty-channel EEG, two-channel EOG, three-channel EMG, and singlechannel ECG. Each epoch is labeled as one of five classes (W, REM, N1, N2, N3) according to AASM rules. In this   3) SHHS: The SHHS dataset is a multi-center cohort study to investigate the effect of sleep-disordered breathing on cardiovascular diseases. The dataset consists of two rounds of PSG records: Visit 1 (SHHS-1) and Visit 2 (SHHS-2). Each record includes two-channel EEGs, two-channel EOGs, singlechannel EMG, single-channel ECG, two-channel respiratory inductance plethysmography, position sensor data, light sensor data, pulse oximeter data, and airflow sensor data. In this study, the single-channel EEGs (C4-A1) in 5,791 records of the SHHS-1 were used. Each epoch is scored as either W, REM, N1, N2, N3, N4 using R&amp;K rule. More details are described in <ref type="bibr" target="#b49">[50]</ref>. Note that some epochs in the datasets were labeled with MOVEMENT and UNKNOWN. They were excluded in this study because their prediction is beyond the scope of sleep stage classification. N3 and N4 stages were regarded as N3 stage according to AASM rules.</p><formula xml:id="formula_5">  × 3   1 × 1, 16 3 × 1, 16 1 × 1, 64   × 3 conv3 x   1 × 1, 128 3 × 3, 128 1 × 1, 512   × 4 28 × 28   1 × 1, 16 3 × 1, 16 1 × 1, 64   × 4 375 × 1 conv4 x   1 × 1, 256 3 × 3, 256 1 × 1, 1024   × 6 14 × 14 3 × 1 max pool, stride 2 94 × 1   1 × 1, 32 3 × 1, 32 1 × 1, 128   × 6 conv5 x   1 × 1, 512 3 × 3, 512 1 × 1, 2048   × 3 7 × 7   1 × 1, 32 3 × 1, 32 1 × 1, 128   × 3 47 × 1 out average pool, 1000 fc, softmax 1 × 1 dropout (p = 0.5) 47 × 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Baselines</head><p>Depending on the dataset processing methods, especially regarding whether using only in-bed or light-out parts of the dataset, a direct comparison between sleep scoring methods would not be a reasonably straightforward comparison; for example, including more segments with WAKE label can lead to high overall accuracy because the performance of sleep stage scoring methods on WAKE segments is usually better compared with the performance on other segments. On the other hand, a training method also affects performance. In order to fairly verify the effectiveness of the deep residual network <ref type="bibr" target="#b35">[36]</ref> and intra-epoch temporal context learning for sleep scoring, baseline experiments were conducted by modifying DeepSleepNet with an end-to-end (E2E) approach. First, E2E-DeepSleepNet was used to compare the performance in terms of model architecture, excluding the influence of a training method such as pre-training and fine-tuning. Secondly, E2E-IntraDeepSleepNet was used to confirm whether intra-epoch temporal context learning was effective in a shallow network. They were trained and evaluated on the same three datasets (SleepEDF, MASS, and SHHS) with the same pre-processing and training condition when sequence length (L) is 1, 4, 10, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) End-to-End DeepSleepNet (E2E-DeepSleepNet):</head><p>We used the DeepSleepNet as a deep learning baseline <ref type="bibr" target="#b20">[21]</ref> and implemented it with the same architecture and parameter used in the paper. DeepSleepNet, which showed a fine performance in sleep stage scoring of the target epoch from a sequence of single-channel EEG signals, utilizes two parallel CNNs of small and large filters to extract time-invariant features and uses bidirectional LSTM to consider the sleep-stage transitions. For the comparison under the same condition, the model was trained in an end-to-end manner, similar to IITNet, instead of using a two-step training algorithm that finetunes the model using the sequential whole-night epochs after pre-training the CNN parts. This end-to-end DeepSleepNet is similar to the model experimented in <ref type="bibr" target="#b30">[31]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Model Specifications</head><p>As described in <ref type="table" target="#tab_1">Table III</ref>, to handle one-dimensional time series EEGs, the one-dimensional operations of the modified ResNet-50 <ref type="bibr" target="#b35">[36]</ref> were used instead of the two-dimensional oper ations of convolution, max-pool, batch normalization. Furthermore, an additional max-pool was placed between the conv3 x and conv4 x layers to halve the feature sequence length. The global average pool layer was excluded, and a dropout layer (p = 0.5) was added to the end of the CNN layers to prevent overfitting. In the RNN layers, two BiLSTM layers were adopted. The hidden state size of the BiLSTM in each direction was set to u = 128, which corresponds to the number of last convolutional filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Input for IITNet</head><p>The sequence length (L), the number of epochs as an input for IITNet, can be adjustable in IITNet. To investigate the influence of the sequence length, training and evaluation were conducted by increasing the sequence length from one to ten in this study. The range was decided after considering the experimental result that there was no significant difference in the comparison of the sequence length of 10, 20, and 30 <ref type="bibr" target="#b30">[31]</ref>. Although some studies used multi channel input, this study only uses single channel EEG to consider versatile applications for time series data. Multi channel input is also possible via an ensemble model based on IITNet, which can show the sensitivity of each channel for each class. Since the channel characteristics is beyond the scope of this study, multi channel input is not dealt with in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Model Training</head><p>Without any preprocessing, Adam <ref type="bibr" target="#b50">[51]</ref> optimizer was used with parameters lr = 0.005, β 1 = 0.9, β 2 = 0.999, and = 10 −8 . To avoid overfitting, L2-weight regularization was applied with wr = 10 −6 . Any methods to balance out on data processing or model training were not used in this study although the state-of-the-art algorithms use balanced-class sampling <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b24">[25]</ref> or class-balanced loss <ref type="bibr" target="#b23">[24]</ref> for mitigating class imbalanced-problems. In all the experiments, the batch sizes were 256, 128, 256 for SleepEDF, MASS, and SHHS, respectively. Early stopping was implemented by tracking the validation cost, such that the training was stopped when there was no validation cost improvement for ten successive training steps. For each cross-validation, the model that achieved the best validation accuracy was used for evaluation in the test set. The training process was implemented in Python 3.5.0 and PyTorch 0.4.0 <ref type="bibr" target="#b51">[52]</ref>. On an RTX 2080 Ti, the training time of IITNet was, in total, approximately 10 h (SleepEDF) to 15 h (MASS), which was approximately 30 min for each fold. For the SHHS, the total training time was approximately 10 h. A single forward pass of IITNet took 11.7, 35.1, 79.4 ms when sequence length (L) is 1, 4, 10, respectively, which was calculated by averaging 2,000 trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Model Evaluation</head><p>For SleepEDF and MASS, k-fold cross-validation was conducted. When the number of subjects in a dataset was N s , the N s /k records were used for model evaluation, and the other records were split into training and validation data. The test-set subjects were sequentially changed by repeating this process k times so that the evaluation was performed over all subjects. To be specific, 20-fold cross-validation was conducted for SleepEDF. In each fold, the numbers of the subjects for training, validation, and evaluation were 15, 4, and 1, respectively. For MASS, 31-fold cross-validation was performed. In each fold, the records of two randomly selected subjects that did not overlap with the other folds were used as the test set, and the remaining records were divided into training (45 subjects) and validation (15 subjects) sets. For SHHS, the subjects were randomly divided into training, validation, and test sets in the ratio 5:2:3 as performed in <ref type="bibr" target="#b21">[22]</ref>.</p><p>The IITNet performance was assessed according to the following criteria: per-class precision (PR), per-class recall (RE), per-class F1 score (F1), overall accuracy (Acc.), macroaveraging F1 score (MF1), and Cohen's kappa coefficient (κ) <ref type="bibr" target="#b52">[53]</ref>  <ref type="bibr" target="#b53">[54]</ref>. In the case of a classification task,</p><formula xml:id="formula_6">PR i = e ii Nc j=1 e ij ,<label>(6)</label></formula><formula xml:id="formula_7">RE i = e ii Nc j=1 e ji ,<label>(7)</label></formula><p>where e ij is the element in the i-th row and j-th column of the confusion matrix and N c is the number of sleep stages (five in this study).</p><formula xml:id="formula_8">F1 i = 2 1 PRi + 1 REi = 2PR i RE i PR i + RE i ,<label>(8)</label></formula><formula xml:id="formula_9">OverallAccuracy = Nc i=1 e ii Nc i=1</formula><p>Nc</p><formula xml:id="formula_10">j=1 e ij ,<label>(9)</label></formula><formula xml:id="formula_11">κ = p o + p e 1 − p e = 1 − 1 − p o 1 − p e<label>(10)</label></formula><p>PR represents the precision with which the model distinguishes the sleep stage from the other stages. RE represents the accuracy with which the model predicts the sleep stage. Overall accuracy is the ratio of the correct predictions to the total predictions, which is an intuitive performance measure. Since F1 is calculated from the harmonic mean of the PE and RE, it can be more informative than overall accuracy, especially in the case of an imbalanced class distribution, i.e., sleep stages in PSG. The average of F1 corresponds to MF1 and κ indicates the agreement between human expert (truth) and IITNet (prediction) in sleep scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance Comparison to State-of-the-Art Models</head><p>A hypnogram predicted by IITNet for one of the subjects is presented in <ref type="figure" target="#fig_4">Fig. 4</ref>, in which the model predictions are in good agreement with human expert's scores. Specifically, <ref type="table" target="#tab_1">Table IV</ref> lists the performance of IITNet and the state-of-the-art models with the model architectures, approaches, input channel types, subject numbers, input types for the deep learning models, and the number of epochs simultaneously input for scoring the sleep stage of the target epoch. The baseline of IITNet is the case that the sequence length (L) is one. For all the datasets, IITNet achieved the performance comparable to the state-of-the-art models using the single-channel EEG although preprocessing was not used, the sequence length was shorter, and the target epoch and its previous epochs were only considered. The best overall accuracy, MF1, and κ are 83.9%, 77.6%, 0.78 for SleepEDF (L=10), 86.5%, 80.7%, 0.80 for MASS (L=9), 86.7%, 79.8%, 0.81 for SHHS (L=10), respectively. The differences of overall accuracy, MF1, and κ between the best of IITNet and other state-of-the-art models are +1.89%p, +0.73%p, +0.018 for SleepEDF, +0.28%p, −1.05%p, −0.004 for MASS, −0.06%p, +1.32%p, −0.003 for SHHS, respectively. According to <ref type="bibr" target="#b30">[31]</ref>, SeqSleepNet-30 used the spectrogram of three channels (EEG, EOG, EMG) as the input and its overall accuracy, MF1, and κ were 87.1%, 83.3%, 0.815 for MASS. Although IITNet used the raw EEG signals instead of the spectrogram images, the performance was observed to be similar. The modified ResNet-50 could learn effectively the representative features related to the sleep events at the sub-epoch level. The features could be analyzed by the RNN via the two-layered BiLSTM at both the intra-and inter-epoch levels, which contributed to learning the transition rules human experts considered.</p><p>Compared to the other state-of-the-art models, the main advantages of IITNet are efficiency and adjustability attributed to using single-channel raw EEG and controlling input length. The proposed model achieved comparable performance with state of the art by using raw single-channel EEG, although the other studies used multi-channel EEGs or spectrogram instead of the raw signal. Furthermore, the input length of the proposed algorithm can be adjustable according to diverse application purposes. This provides high feasibility compared to the other algorithm. Table IV supports these strong points of the proposed algorithm. It is also feasible to score the sleep stages automatically in real-time via IITNet with a single-channel EEG sensor, which can be one of the essential technologies for healthcare 4.0, especially for the next generation treatment and diagnosis of sleep disorders. Furthermore, IITNet can be directly applied to classify various kinds of time-series data since the model is the end-to-end architecture without pretraining or preprocessing. On the other hand, it should be noted that the sampling frequency of the input cannot be changeable after the model is trained. In order to score sleep stages from the signal of the different sampling frequency, preprocessing such as down or upsampling is required. The compared models of other studies have the same limitation.</p><p>To solve this, further study is necessary with the datasets of various sampling frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Influence of the Sequence Length (L)</head><p>The influence of sequence length (L) on the performance is shown in 5. For all the datasets, similar variation patterns can be seen. In Figs. 5a-5c, overall accuracy, MF1, and κ consistently increase until L is four. After that, they oscillate according to L. The smaller the fluctuation, the larger the dataset size (the number of subjects). The performance dropped in SleepEDF when the sequence length was 5 and 6. We think that the relatively small size of SleepEDF affected the drop since the models trained on a small dataset are more likely to result in high variance <ref type="bibr" target="#b54">[55]</ref>. Moreover, the features of previous sleep stages before 2 minutes (more than 4 epochs) may be more difficult to be characterized. With insufficient training data, it is also hard for the model to learn the long ago features that affect the current sleep stage. The results show that this difficulty can be overcome with longer sequence length or larger datasets. Using four epochs (two minutes) as an input, the performance was still comparable to the state-of-the-art results for three datasets (SleepEDF, MASS, and SHHS) with overall accuracy (Acc.: 83.6%, 86.2%, 86.3%), macro F1score (MF1: 76.5%, 80.0%, 78.8%), and Cohen's kappa (κ : 0.77, 0.79, 0.81). The differences of overall accuracy, MF1, and κ between IITNet (L) and the state-of-the-art models are +1.58%p, −0.41%p, +0.013 for SleepEDF, +0.01%p, −1.73%p, −0.007 for MASS, −0.46%p, +0.35%p, −0.009 for SHHS, respectively. When L increases from one to four, overall accuracy and MF1 improve by 2.99%p, 4.36%p for SleepEDF, 1.73%p, 3.32%p for MASS, and 2.74%p, 7.03%p for SHHS, respectively. However, when L increases from four   to ten, these two metrics increase by 0.32%p, 1.14%p for SleepEDF, 0.13%p, 0.51%p for MASS, and 0.39%p, 0.97%p for SHHS, respectively. This results support that considering last two-minute epochs can be a reasonable choice to predict the sleep stage with efficiency and reliability. According to SeqSleepNet using the spectrogram of multi-channel PSG <ref type="bibr" target="#b30">[31]</ref>, the performance showed no significant difference when the sequence length was set to 10, 20, and 30. Other state-ofthe-art models can be more compact, and their prediction can become faster by reducing the input length as recommended in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Per-class Performance Improvement</head><p>The F1 of N1, N2, and REM increases in a similar fashion to overall performance, whereas the enhancement in the F1 of W and N3 is not apparent. In Figs. 5d-5h, F1 of N1 and REM steadily increases until L is four. F1 of N2 also increases until L is four except for MASS L = 4. After that, they oscillate according to L. The confusion matrices for L of one, four, and ten are illustrated in <ref type="figure">Fig. 6</ref>. On average for three datasets, in four epochs compared to single epoch, accuracy and MF1 increased by 2.47%p and 4.93%p, respectively. Notably, MF1 of N1, N2, and REM increased by 16.1%p, 1.50%p, and 6.42%p, respectively. The results mean that the overall performance improvement was attributed to the enhanced prediction of N1, N2, and REM. The AASM recommends that sleep experts should consider the target and previous epochs, especially when labeling the sleep stage as N1 or REM. The results support that the transition rules were well trained in IITNet by the intra-and inter-epoch context learning at the sub-epoch level. On the other hand, no significant improvement in W and N3 indicates that they have less inter-epoch dependency than the other stages. According to the AASM, for the target epoch to be identified as W, N2, or N3, the sleep-related events or specific EEG signal activities of the target epoch should mainly be considered.</p><p>For further improvement in N1, adding a frequency-aware module on IITNet and increasing the sequence length can be included for the future work, as the mixed frequency in the range of 4-7.99 Hz is a characteristic of N1 <ref type="bibr" target="#b5">[6]</ref>. Modifying an IITNet into a sequence-to-sequence classification model with an multi-channel ensemble, as was accomplished in <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, is also possible for a more elaborate classification. However, introducing an intra-epoch temporal context learning with the deep residual network for sleep scoring is our main focus in this article, and the suggested modification will be included in the future work.</p><p>On the other hand, the results show that IITNet overcame the imbalanced nature of PSG datasets without any sampling method or learning technique. Typically, the PSG datasets have an imbalanced class distribution, e.g., the number of N1 is less than 10% as shown in <ref type="table" target="#tab_1">Table I</ref>. To account for this, costsensitive learning or class-balanced sampling has been applied   [7], <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. Although these kinds of methods improved the performance of certain classes; however, the overall performance became worse <ref type="bibr" target="#b21">[22]</ref>. IITNet shows that using the sequence of less than ten epochs as the input enhanced both the overall and class-wise performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Performance Comparison to the baselines</head><p>The performance comparison between IITNet, E2E-DeepSleepNet and E2E-IntraDeepSleepNet when the sequence length L is 1, 4, and 10 for SleepEDF, MASS, and SHHS dataset is shown in <ref type="table" target="#tab_8">Table V</ref>. It is worth noting that all experiments with the baselines were conducted using the same dataset and under the same condition. In SleepEDF and MASS, introducing our proposed intra-epoch temporal context learning on E2E-DeepSleepNet tend to improve the sleep scoring performance considerably in both cases when the input is a single epoch and multiple-epoch. E2E-IntraDeepSleepNet performed better than E2E-DeepSleepNet when the input is a single epoch (L=1) with the margin of overall accuracy, MF1, and κ between two models being +0.7%p, +0.7%p, +0.01 for SleepEDF, and +0.6%p, +0.2%p, +0.01 for MASS. Even for the multi-epoch input, the overall performance of E2E-IntraDeepSleepNet is better compared with that of E2E-DeepSleepNet, with the differences in overall accuracy being +0.6%p (L=4) and +0.9%p (L=10) for SleepEDF and −0.1%p (L=4) and +0.7%p (L=10) for MASS, respectively. In SHHS, the overall accuracy of E2E-IntraDeepSleepNet was similar, i.e., +0.0%p (L=1) and −0.2%p (L=4) or better with +0.7%p (L=10), in comparison to E2E-DeepSleepNet. This verifies that considering intra-epoch temporal context by learning with sub-epoch level features can lead to a performance gain in sleep scoring and introduces a synergistic effect with the inter-epoch temporal context learning.</p><p>In SHHS, exploiting a ResNet-50 for the representation learning was a key factor in the improvement of the sleep scoring performance. The overall accuracy of IITNet was significantly higher for all sequence lengths with a high margin +2.8%p, +2.8%p (L=1), +2.4%p, +2.6%p (L=4), +1.7%p, +1.0%p (L=10) comparing with those for E2E-DeepSleepNet and E2E-IntraDeepSleepNet. This shows that a deeper neural network (49 convolutional layers) with a residual connection can yield a better sleep scoring performance than the shallow network of DeepSleepNet (4 con-volutional layers) on a large scale dataset. However, for the SleepEDF and MASS, which are relatively small datasets compared with SHHS, employing a ResNet-50 did not always guarantee a performance improvement. Although IITNet in SleepEDF showed similar or higher overall accuracy compared with E2E-IntraDeepSleepNet with the margin of −1.0%p (L=1), +1.0%p (L=4), and +0.3%p (L=10), the overall accuracy of IITNet in MASS was lower than that of E2E-IntraDeepSleepNet's with −0.3%p (L=1), −0.5%p (L=4), and −0.9%p (L=10). This suggests that using ResNet-50 as a feature extractor can enhance the sleep scoring performance when a sufficient number of epochs per subject are given <ref type="bibr" target="#b1">(2,</ref><ref type="bibr">115</ref> in SleepEDF), while a shallow network can be sufficient to learn sleep-related features when the number of epochs per subject is small (926 in MASS). Thus, the number of epochs and subjects should be considered when designing the depth of CNN in the sleep scoring network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>Human sleep experts search the sleep-related events and consider the transition rules to score the sleep stage of an epoch. Motivated by this approach, a novel deep learning model named IITNet is proposed to score the sleep stage more accurately by considering the inter-and intra-epoch temporal contexts using raw single-channel EEG. The deep CNN based on a modified ResNet-50 extracts the sleep-related features and the RNN via two-layered BiLSTM learns the transition rules. Using ten epochs or less as an input, IITNet achieved the performance comparable to other state-of-the-art results for three public datasets: SleepEDF, MASS, and SHHS. The results show that the proposed temporal context learning at both the intra-and inter-epoch levels is effective to classify the time-series inputs. The overall performance was enhanced when the sequence length increased from one to four, which was attributed to the enhanced prediction of N1, N2, and REM. However, the improvement was not significant above four epochs. Using the target epoch and its three previous epochs, the overall performance was still comparable to state-of-theart results, which supports that considering last two-minute raw single-channel EEG can be a reasonable option to predict the sleep stage with efficiency and reliability. Other state-ofthe-art models can be more compact, and their training can become faster by reducing the input length. Moreover, IITNet can be directly applied to predict or classify various kinds of time-series data for healthcare and well-being applications since the model is based on the end-to-end architecture without pre-training or preprocessing tailored to sleep scoring.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The architecture of the proposed model, IITNet. The left shows IITNet of one-to-one configuration for intra-epoch temporal context learning. The right shows IITNet of many-to-one configuration for intra-and inter-epoch temporal context learning. Each green box indicates the representative feature extracted from sub-epoch (red dash box). These representative features are aggregated into a feature sequence (blue dash box) in intra-epoch temporal context learning or a series of feature sequences (yellow dash box) for both the intra-and inter-epoch temporal context learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Conversion from an epoch signal into feature sequences in the CNN layers. Each sub epoch is encoded to its corresponding feature vector with the dimension of u = 128. Total l feature vectors are extracted and stacked into a feature sequence to be fed into the RNN layers.representation of the forward − → h t and backward ← − h t contexts at time step t, where<ref type="bibr" target="#b45">[46]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Model comparison between E2E-DeepSleepNet, E2E-IntraDeepSleepNet baseline and our proposed IITNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 )</head><label>2</label><figDesc>End-to-End Intra-epoch Temporal Context DeepSleepNet (E2E-IntraDeepSleepNet): To evaluate the effectiveness of intra-epoch temporal context learning, we modified the endto-end DeepSleepNet baseline by introducing an intra-epoch temporal context learning, which was described in section II-B and II-C. This end-to-end intra-epoch temporal context DeepSleepNet first extracts the sleep-related features from two CNN branches. The interpolation is performed after the CNN branches with larger filters to make the number of the subepochs of two CNN branches equal. Thereafter, features from two branches are concatenated, and two convolutional layers are applied channel-wise to half the length of the feature vector to form a feature sequence. In this way, sleep-related features can be analyzed in the sub-epoch level in RNN layers. Whereas the IITNet consists of ResNet-50 with residual connection and 49 convolutional layers, IntraDeepSleepNetbaseline uses a relatively shallow network with two parallel CNNs of four convolutional layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Hypnogram comparison between human expert and IITNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>(a) Overall Accuracy[%]   (b) Macro-F1 [%] (c) Cohen's Kappa (κ) (d) F1 of W [%] (e) F1 of N1 [%] (f) F1 of N2 [%] (g) F1 of N3 [%] (h) F1 of REM [%]Performance of IITNet for SleepEDF, MASS, and SHHS according to the sequence length (L) Confusion matrix of IITNet for SleepEDF, MASS, and SHHS with the sequence length (L) of one, four, and ten</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>summarizes the demographic information of datasets, including gender distributions and age characteristics. Handcrafted feature extraction or signal processing was not employed for this study.</figDesc><table><row><cell>Dataset</cell><cell>W</cell><cell>N1</cell><cell>N2</cell><cell>N3</cell><cell>REM</cell><cell>Total</cell></row><row><cell>SleepEDF</cell><cell>8,285 (20%)</cell><cell>2,804 (7%)</cell><cell>17,799 (42%)</cell><cell>5,703 (13%)</cell><cell>7,717 (18%)</cell><cell>42,308</cell></row><row><cell>MASS</cell><cell>5,672 (10%)</cell><cell>4,524 (8%)</cell><cell>29,212 (51%)</cell><cell>7,567 (13%)</cell><cell>10,420 (18%)</cell><cell>57,395</cell></row><row><cell>SHHS</cell><cell>1,251,329 (23%)</cell><cell>217,508 (4%)</cell><cell>2,396,158 (44%)</cell><cell>739,212 (14%)</cell><cell>817,131 (15%)</cell><cell>5,421,338</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table I</head><label>I</label><figDesc></figDesc><table /><note>: The class-wise number of epochs in the datasets 1) SleepEDF:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table II :</head><label>II</label><figDesc>The demographic information of the datasets</figDesc><table><row><cell></cell><cell></cell><cell>ResNet-50</cell><cell></cell><cell cols="2">Modified ResNet-50 used in IITNet</cell></row><row><cell>Layer name</cell><cell></cell><cell>blocks</cell><cell>output size</cell><cell>blocks</cell><cell>output size</cell></row><row><cell>conv1</cell><cell cols="2">7 × 7, 64, stride 2</cell><cell>112 × 112</cell><cell>7 × 1, 64, stride 2</cell><cell>1500 × 1</cell></row><row><cell></cell><cell cols="2">3 × 3 max pool, stride 2</cell><cell></cell><cell>3 × 1 max pool, stride 2</cell></row><row><cell>conv2 x</cell><cell> </cell><cell>1 × 1, 64 3 × 3, 64</cell><cell>56 × 56</cell><cell></cell><cell>750 × 1</cell></row><row><cell></cell><cell cols="2">1 × 1, 256</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table III :</head><label>III</label><figDesc>Model comparison between ResNet-50 for ImageNet<ref type="bibr" target="#b35">[36]</ref> and the modified ResNet-50 used in IITNet. Down-sampling is performed by conv3 1, conv4 1, and conv5 1 with a stride of 2. The left values in bracket represent the filter size and the right value indicates the number of filters. Output size is calculated on the assumption the that input for ResNet-50 is an image of 224×224 and the input for IITNet is a 30-second EEG of 3000×1 (SleepEDF) study, F4-EOG (left) channel in the SS3 records (62 subjects, average subject age: 42.5 ± 18.9 years) was used.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table IV :</head><label>IV</label><figDesc>Performance comparison between IITNet and the state-of-the-art methods for automatic sleep scoring via deep learning. The underlined indicates the highest and the bold is the result of IITNet with the sequence length of 4.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table V :</head><label>V</label><figDesc>Performance comparison between IITNet, E2E-DeepSleepNet baseline, E2E-IntraDeepSleepNet baseline for SleepEDF, MASS, and SHHS datasets. Bold indicates the highest results for the specific dataset and sequence length.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENTS This work was supported by the Institute of Integrated Technology (IIT) Research Project through a grant provided by Gwangju Institute of Science and Technology (GIST) in 2019 (Project Code: GK11470).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sleep and circadian rhythm disruption in psychiatric and neurodegenerative disease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Wettstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">589</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Withstanding the obstructive sleep apnea syndrome at the expense of arousal instability, altered cerebral autoregulation and neurocognitive decline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Torabi-Nami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borhani-Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Derman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of integrative neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="169" to="193" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic analysis of single-channel sleep eeg: validation in healthy individuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Berthomier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Drouot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herman-Stoïca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berthomier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Prado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bokar-Thire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mattout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1587" to="1595" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects: A. rechtschaffen and a. kales (editors). (public health service, u.s. government printing office</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hobson</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/0013469469900212" />
	</analytic>
	<monogr>
		<title level="j">Electroencephalography and Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">644</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
	<note>58 p., 4.00</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A manual for standardized terminology, techniques and scoring system for sleep stages in human subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rechtschaffen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
	<note>Brain information service</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The aasm manual for the scoring of sleep and associated events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Gamaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vaughn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rules, Terminology and Technical Specifications</title>
		<imprint>
			<date type="published" when="2012" />
			<publisher>American Academy of Sleep Medicine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The use of neural networks in the analysis of sleep stages and the diagnosis of narcolepsy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Stephansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ambati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Carrillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hogl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stefani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.02094</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scoring accuracy of automated sleep staging from a bipolar electroocular recording compared to manual scoring by multiple raters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stepnowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Levendowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ayappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Rapoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep medicine</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1199" to="1207" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The american academy of sleep medicine inter-scorer reliability program: sleep stage scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Hout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of clinical sleep medicine</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="81" to="87" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sleep stage classification using eeg signal analysis: a comprehensive survey and new investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aboalayon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faezipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Almuhammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moslehpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">272</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hyclasss: A hybrid classifier for automatic sleep stage scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE journal of biomedical and health informatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="375" to="385" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An ensemble system for automatic sleep stage classification using single channel eeg signal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Koley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in biology and medicine</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1186" to="1195" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic sleep stages classification based on iterative filtering of electroencephalogram signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Pachori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Upadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2959" to="2978" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A decision support system for automatic sleep staging from eeg signals using tunable q-factor wavelet transform and spectral features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I H</forename><surname>Bhuiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neuroscience methods</title>
		<imprint>
			<biblScope unit="volume">271</biblScope>
			<biblScope unit="page" from="107" to="118" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sleep stage classification using unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Längkvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Artificial Neural Systems</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automated sleep stage identification system based on time-frequency analysis of a single eeg channel and random forest classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fraiwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lweesy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Khasawneh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dickhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer methods and programs in biomedicine</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="19" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Computer-aided sleep staging using complete ensemble empirical mode decomposition with adaptive noise and bootstrap aggregating</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I H</forename><surname>Bhuiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical Signal Processing and Control</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning machines and sleeping brains: automatic sleep stage classification using decision-tree multi-class support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lajnef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ruby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Aguera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Eichenlaub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kachouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jerbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neuroscience methods</title>
		<imprint>
			<biblScope unit="volume">250</biblScope>
			<biblScope unit="page" from="94" to="105" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic stage scoring of single-channel sleep eeg by using multiscale entropy and autoregressive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-E</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1649" to="1657" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Analysis and classification of sleep stages based on difference visibility graphs from a single-channel eeg signal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">REM</title>
		<imprint>
			<biblScope unit="volume">806</biblScope>
			<biblScope unit="page">803</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deepsleepnet: a model for automatic sleep stage scoring based on raw single-channel eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A convolutional neural network for sleep stage scoring from raw single-channel eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mirek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vercueil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Payen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical Signal Processing and Control</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="107" to="114" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Galtier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Arnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wainrib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep convolutional neural networks for interpretable analysis of eeg sleep stage scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilamala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.00633</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic sleep stage scoring using time-frequency analysis and stacked sparse autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsinalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1587" to="1597" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convolutional neural network for multicategory rapid serial visual presentation bci</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Geva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in computational neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling electroencephalography waveforms with semi-supervised deep belief nets: fast classification and anomaly measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wulsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Litt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neural engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">36015</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Classification of patterns of eeg synchronization for seizure prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kuzniecky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical neurophysiology</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1927" to="1940" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Montreal archive of sleep studies: an open-access resource for instrument benchmarking and exploratory research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of sleep research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="628" to="635" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recipes for the linear analysis of eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Gerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sajda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="326" to="341" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Seqsleepnet: End-to-end hierarchical recurrent neural network for sequenceto-sequence automatic sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Y</forename><surname>Chén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint classification and prediction cnn framework for automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Y</forename><surname>Chén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1285" to="1296" />
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mixed neural network approach for temporal sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="324" to="333" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Biswal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goparaju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08262</idno>
		<title level="m">Sleepnet: automated sleep staging system via deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic sleep stage recurrent neural classifier using energy features of eeg signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="105" to="114" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2298" to="2304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="318" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Hierarchical question-image co-attention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, speech and signal processing (icassp), 2013 ieee international conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning precise timing with lstm recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="115" to="143" />
			<date type="published" when="2002-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Zwinderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Kamphuisen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Oberye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1185" to="1194" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The sleep heart health study: design, rationale, and methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Iber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Kiley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Redline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1077" to="1085" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Sleep data -national sleep research resource -nsrr</title>
		<ptr target="https://sleepdata.org/.,accessed" />
		<imprint>
			<biblScope unit="page" from="2018" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A systematic analysis of performance measures for classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="427" to="437" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On the effect of data set size on bias and variance in classification learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Australian Knowledge Acquisition Workshop</title>
		<meeting>the Fourth Australian Knowledge Acquisition Workshop</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="117" to="128" />
		</imprint>
		<respStmt>
			<orgName>University of New South Wales</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
