<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Ke</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Pratama</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
							<affiliation key="aff1">
								<address>
									<settlement>Tencent</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
							<email>timcheng@ust.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>End-to-end deep representation learning has achieved remarkable accuracy for monocular 3D human pose estimation, yet these models may fail for unseen poses with limited and fixed training data. This paper proposes a novel data augmentation method that: (1) is scalable for synthesizing massive amount of training data (over 8 million valid 3D human poses with corresponding 2D projections) for training 2D-to-3D networks, (2) can effectively reduce dataset bias. Our method evolves a limited dataset to synthesize unseen 3D human skeletons based on a hierarchical human representation and heuristics inspired by prior knowledge. Extensive experiments show that our approach not only achieves state-of-the-art accuracy on the largest public benchmark, but also generalizes significantly better to unseen and rare poses. Code, pre-trained models and tools are available at this HTTPS URL 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Estimating 3D human pose from RGB images is critical for applications such as action recognition <ref type="bibr" target="#b35">[36]</ref> and human-computer interaction, yet it is challenging due to lack of depth information and large variation in human poses, camera viewpoints and appearances. Since the introduction of large-scale motion capture (MC) datasets <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b21">22]</ref>, learning-based methods and especially deep representation learning have gained increasing momentum in 3D pose estimation. Thanks to their representation learning power, deep models have achieved unprecedented high accuracy <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b64">65]</ref>.</p><p>Despite their success, deep models are data-hungry and vulnerable to the limitation of data collection. This problem is more severe for 3D pose estimation due to two factors. First, collecting accurate 3D pose annotation for RGB images is expensive and time-consuming. Second, the collected training data is usually biased towards indoor envi-1 https://github.com/Nicholasli1995/EvoSkeleton</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Image</head><p>Li et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Before Evolution (Ours)</head><p>After Evolution (Ours) <ref type="figure">Figure 1</ref>: Model trained on the evolved training data generalizes better than <ref type="bibr" target="#b27">[28]</ref> to unseen inputs. ronment and selected daily actions. Deep models can easily exploit these bias but fail for unseen cases in unconstrained environments. This fact has been validated by recent works <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b68">69]</ref> where cross-dataset inference demonstrated poor generalization of models trained with biased data.</p><p>To cope with the domain shift of appearance for 3D pose estimation, recent state-of-the-art (SOTA) deep models adopt the two-stage architecture <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>. The first stage locates 2D human key-points from appearance information, while the second stage lifts the 2D joints into 3D skeleton employing geometric information. Since 2D pose annotations are easier to obtain, extra in-the-wild images can be used to train the first stage model, which effectively reduces the bias towards indoor images during data collection. However, the second stage 2D-to-3D model can still be negatively influenced by geometric data bias, yet not studied before. We focus on this problem in this work and our research questions are: are our 2D-to-3D deep networks influenced by data bias? If yes, how can we improve network generalization when the training data is limited in scale or variation?</p><p>To answer these questions, we propose to analyze the training data with a hierarchical human model and represent human posture as collection of local bone orientations. We then propose a novel dataset evolution framework to cope with the limitation of training data. Without any extra annotation, we define evolutionary operators such as crossover and mutation to discover novel valid 3D skeletons in treestructured data space guided by simple prior knowledge. These synthetic skeletons are projected to 2D and form 2D-3D pairs to augment the data used for training 2D-to-3D networks. With an augmented training dataset after evolution, we propose a cascaded model achieving state-of-theart accuracy under various evaluation settings. Finally, we release a new dataset for unconstrained human pose in-thewild. Our contributions are summarized as follows:</p><p>• To our best knowledge, we are the first to improve 2Dto-3D network training with synthetic paired supervision.</p><p>• We propose a novel data evolution strategy which can augments an existing dataset by exploring 3D human pose space without intensive collection of extra data. This approach is scalable to produce 2D-3D pairs in the order of <ref type="bibr">10 7</ref> , leading to better model generalization of 2D-to-3D networks.</p><p>• We present TAG-Net, a deep architecture consisting of an accurate 2D joint detector and a novel cascaded 2D-to-3D network. It out-performs previous monocular models on the largest 3D human pose estimation benchmark in various aspects.</p><p>• We release a new labeled dataset for unconstrained human pose estimation in-the-wild. <ref type="figure">Fig. 1</ref> shows a 2D-to-3D network trained on our augmented dataset can handle rare poses while others such as <ref type="bibr" target="#b27">[28]</ref> may fail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Monocular 3D human pose estimation. Single-image 3D pose estimation methods are conventionally categorized into generative methods and discriminative methods. Generative methods fit parametrized models to image observations for 3D pose estimation. These approaches represent humans by PCA models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b74">75]</ref>, graphical models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b4">5]</ref> or deformable meshes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b25">26]</ref>. The fitting process amounts to non-linear optimization, which requires good initialization and refines the solution iteratively. Discriminative methods <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b5">6]</ref> directly learn a mapping from image observations to 3D poses. Recent deep neural networks (DNNs) fall into this category and employ two mainstream architectures: one-stage methods <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b17">18]</ref> and two-stage methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b72">73]</ref>. The former directly map pixel intensities to 3D poses, while the latter first extract intermediate representation such as 2D key-points and then lift them to 3D poses.</p><p>We adopt the discriminative approach and focus on the 2D-to-3D lifting network. Instead of using a fixed training dataset, we evolve the training data to improve the performance of the 2D-to-3D network. Weakly-supervised 3D human pose estimation. Supervised training of DNNs demands massive data while 3D annotation is difficult. To address this problem, weaklysupervised methods explore other potential supervision to improve network performance when only few training data is available <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b29">30]</ref>. Multi-view consistency <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b11">12]</ref> is proposed and validated as useful supervisory signal when training data is scarce, yet a minimum of two views are needed. In contrast, we focus on effective utilization of scarce training data by synthesizing new data from existing ones and uses only single view. Data augmentation for pose estimation. New images can be synthesized to augment indoor training dataset <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b67">68]</ref>. In <ref type="bibr" target="#b67">[68]</ref> new images were rendered using MC data and human models. Domain adaption was performed in <ref type="bibr" target="#b10">[11]</ref> during training with synthetic images. Adversarial rotation and scaling were used in <ref type="bibr" target="#b49">[50]</ref> to augment data for 2D pose estimation. These works produce synthetic images while we focus on data augmentation for 2D-to-3D networks and produce synthetic 2D-3D pairs. Pose estimation dataset. Most large-scale human pose estimation datasets <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b2">3]</ref> only provide 2D pose annotations. Accurate 3D annotations <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b60">61]</ref> require MC devices and these datasets are biased due to the limitation of data collection process. Deep models are prone to overfit to these biased dataset <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b28">29]</ref>, failing to generalize in unseen situations. Our method can synthesize for free without human annotation large amount of valid 3D poses with larger coverage in human pose space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset Evolution</head><p>From a given input image x i containing one human subject, we aim to infer the 3D human posep i given the image observation φ(x i ). To encode geometric information as other 2D-to-3D approaches <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b27">28]</ref>, we represent φ(x) as the 2D coordinates of k human key-points (x i , y i ) k i=1 on the image plane. As a discriminative approach, we seek a regression function F parametrized by Θ that outputs 3D pose asp i = F(φ(x i ), Θ). This regression function is implemented as a DNN. Conventionally this DNN is trained on a dataset collected by MC devices <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b21">22]</ref>. This dataset consists of paired images and 3D pose ground truths {(x i , p i )} N i=1 and the DNN can be trained by gradi-ent descent based on a loss function defined over the train-</p><formula xml:id="formula_0">ing dataset L = N i=1 E(p i ,p i )</formula><p>where E is the error measurement between the ground truth p i and the prediction</p><formula xml:id="formula_1">p i = F(φ(x i ), Θ).</formula><p>Unfortunately, sampling bias exists during the data collection and limits the variation of the training data. Human 3.6M (H36M) <ref type="bibr" target="#b21">[22]</ref>, the largest MC dataset, only contains 11 subjects performing 15 actions under 4 viewpoints, leading to insufficient coverage of the training 2D-3D pairs (φ(x i ), p i ). A DNN can overfit to the dataset bias and become less robust to unseen φ(x). For example, when a subject starts street dancing, the DNN may fail since it is only trained on daily activities such as sitting and walking. This problem is even exacerbated for the weakly-supervised methods <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b11">12]</ref> where a minute quantity of training data is used to simulate the difficulty of data collection.</p><p>We take a non-stationary view toward the training data to cope with this problem. While conventionally the collected training data is fixed and the trained DNN is not modified during its deployment, here we assume the data and model can evolve during their life-time. Specifically, we synthesize novel 2D-3D pairs based on an initial training dataset and add them into the original dataset to form the evolved dataset. We then re-train the model with the evolved dataset. As shown in <ref type="figure">Fig. 2</ref>, model re-trained on the evolved dataset has consistently lower generalization error, comparing to a model trained on the initial dataset.</p><p>%0.1 S1 (245) %1 S1 (2.42k) %5 S1 (12.4k) %10 S1 <ref type="bibr">(</ref>  <ref type="figure">Figure 2</ref>: Generalizing errors (MPJPE using ground truth 2D key-points as inputs) on H36M before and after dataset evolution with varying size of initial population.</p><p>In the following we show that by using a hierarchical representation of human skeleton, the synthesis of novel 2D-3D pairs can be achieved by evolutionary operators and camera projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Hierarchical Human Representation</head><p>We represent a 3D human skeleton by a set of bones organized hierarchically in a kinematic tree as shown in  <ref type="figure">Figure 4</ref>: Examples of evolutionary operation. Crossover and mutation take two and one random samples respectively to synthesize novel human skeletons. In this example the right arms are selected for crossover while the left leg is mutated. <ref type="figure" target="#fig_0">Fig. 3</ref>. This representation captures the dependence of adjacent joints with tree edges. Each 3D pose p corresponds to a set of bone vectors {b 1 , b 2 , · · · , b w } and a bone vector is defined as</p><formula xml:id="formula_2">b i = p child(i) − p parent(i)<label>(1)</label></formula><p>where p j is the jth joint in the 3D skeleton and parent(i) gives the parent joint index of the ith bone vector. A local coordinate system 2 is attached at each parent node. For a parent node p parent(i) , its local coordinate system is represented by the rotation matrix defined by three basis vectors</p><formula xml:id="formula_3">R i = [i i , j i , k i ].</formula><p>The global bone vector is transformed into this local coordinate system as</p><formula xml:id="formula_4">b i local = R i T b i global = R i T (p child(i) − p parent(i) ) (2)</formula><p>For convenience, this local bone vector is further converted into spherical coordinates b i local = (r i , θ i , φ i ). The posture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Data evolution</head><p>Input:</p><formula xml:id="formula_5">Initial set of 3D skeletons D old = {p i } N i=1 , noise level σ, number of generations G Output: Augmented set of skeletons Dnew = {p i } M i=1 1: Dnew = D old 2: for i=1:G do 3: Parents = Sample(Dnew) 4:</formula><p>Children = NaturalSelection(Mutation(Crossover(Parents))) 5:</p><p>Dnew = Dnew ∪ Children 6: end for 7: return Dnew of the skeleton is described by the collection of bone orien-</p><formula xml:id="formula_6">tations {(θ i , φ i )} w i=1 while the skeleton size is encoded into {r i } w i=1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Synthesizing New 2D-3D Pairs</head><p>We first synthesize new 3D skeletons</p><formula xml:id="formula_7">D new = {p j } M j=1 with an initial training dataset D old = {p i } N i=1 and project 3D skeletons to 2D given camera intrinsics K to form 2D- 3D pairs {(φ(x j ), p j )} M i=1 where φ(x j ) = Kp j .</formula><p>When adopting the hierarchical representation, a dataset of articulated 3D objects is a population of tree-structured data in nature. Evolutionary operators <ref type="bibr" target="#b19">[20]</ref> have constructive property <ref type="bibr" target="#b61">[62]</ref> that can be used to synthesize new data <ref type="bibr" target="#b15">[16]</ref> given an initial population. The design of operators is problem-dependent and our operators are detailed as follows. Crossover Operator Given two parent 3D skeletons represented by two kinematic trees, crossover is defined as a random exchange of sub-trees. This definition is inspired by the observation that an unseen 3D pose might be obtained by assembling limbs from known poses. Formally, we denote the set of bone vectors for parent A and B as</p><formula xml:id="formula_8">S A = {b 1 A , b 2 A , . . . , b w A } and S B = {b 1 B , b 2 B , . . . , b w B }.</formula><p>A joint indexed by q is selected at random and the bones rooted at it are located for the two parents. These bones form the chosen sub-tree set S chosen</p><formula xml:id="formula_9">{b j : parent(j) = q ∨ IsOff (parent(j), q)}<label>(3)</label></formula><p>where IsOff (parent(j), q) is True if joint parent(j) is an offspring of joint q in the kinematic tree. The parent bones are split into the chosen and the remaining ones as S X = S X chosen ∪ S X rem where S X rem = S X − S X chosen and X is A or B. Now the crossover operator gives two sets of children bones as</p><formula xml:id="formula_10">S C = S A chosen ∪ S B rem and S D = S B chosen ∪ S A rem (4)</formula><p>These two new sets are converted into two new 3D skeletons. The example in <ref type="figure">Fig. 4</ref> shows the exchange of the right arms when the right shoulder joint is selected. Mutation Operator As the motion of human limbs is usually continuous, a perturbation of one limb of an old 3D skeleton may result in a valid new 3D pose. To implement this perturbation, our mutation operator modifies the local orientation of one bone vector to get a new pose. One bone vector b i = (r i , θ i , φ i ) for an input 3D pose is selected at random and its orientation is mutated by adding noise (Gaussian in this study):</p><formula xml:id="formula_11">θ i = θ i + g θ , φ i = φ i + g φ<label>(5)</label></formula><p>where g ∼ N (0, σ) and σ is a pre-defined noise level. One example of mutating the left leg is shown in <ref type="figure">Fig. 4</ref>. We also mutate the global orientation and bone length of the 3D skeletons to reduce the data bias of viewpoints and subject sizes, which is detailed in our supplementary material. Natural Selection We use a fitness function to evaluate the goodness of synthesized data for selection as v(p) which indicates the validity of the new pose. v(p) can be any function that describes how anatomically valid a skeleton is, and we implement it by utilizing the binary function in <ref type="bibr" target="#b1">[2]</ref>. We specify v(p) = −∞ if p is not valid to rule out all invalid poses. Evolution Process The above operators are applied to D old to obtain a new generation D new by synthesizing new poses and merge with the old poses. This evolution process repeats G generations and is depicted in Algorithm 1. Finally, D new are projected to 2D key-points to obtain paired 2D-3D supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model Architecture</head><p>We propose a two-stage model as shown in <ref type="figure" target="#fig_1">Fig. 5</ref>. We name it TAG-Net, as the model's focus transits from appearance to geometry. This model can be represented as a functionp</p><formula xml:id="formula_12">= TAG(x) = G(A(x))<label>(6)</label></formula><p>Given an input RGB image x, A(x) (the appearance stage) regresses k = 17 high-resolution probability heat-maps H k i=1 for k 2D human key-points and map them into 2D</p><formula xml:id="formula_13">coordinates c = (x i , y i ) k i=1 . G(c) (the geometry stage) in- fers 3D key-point coordinates 3 p = (x i , y i , z i ) k i=1</formula><p>in the camera coordinate system from input 2D coordinates. Key designs are detailed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">High-resolution Heatmap Regression</head><p>Synthesized 2D key-points are projected from 3D points and can be thought as perfect detections while real detections produced by heat-map regression models are more noisy. We hope this noise can be small since we need to merge these two types of data as described in Section 3. To detect 2D key-points as accurate as possible, we decide to obtain feature maps with high spatial resolution and </p><formula xml:id="formula_14">+ (1, d) (1, d) (1, d) + (1, d) (1, d) (1, d) + . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Later blocks</head><p>.</p><p>(1  use HR-Net <ref type="bibr" target="#b63">[64]</ref> as our backbone for feature extraction. While the original model predicts heat-maps of size 96 by 72, we append a pixel shuffle super-resolution layer <ref type="bibr" target="#b59">[60]</ref> to the end and regress heat-maps of size 384 by 288. The original model <ref type="bibr" target="#b63">[64]</ref> uses hard arg-max to predict 2D coordinates, which results in rounding errors in our experiments. Instead, we use soft arg-max <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b64">65]</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Cascaded Deep 3D Coordinate Regression</head><p>Since the mapping from 2D coordinates to 3D joints can be highly-nonlinear and difficult to learn, we propose a cascaded 3D coordinate regression model aŝ</p><formula xml:id="formula_16">p = G(c) = T t=1 D t (i t , Θ t )<label>(7)</label></formula><p>where D t is the tth deep learner in the cascade parametrized by Θ t and takes input i t . As shown in the top of <ref type="figure" target="#fig_1">Fig. 5</ref>, the first learner D 1 in the cascade directly predicts 3D coordinates while the later ones predict the 3D refinement</p><formula xml:id="formula_17">δp = (δx i , δy i , δz i ) k i=1</formula><p>. While cascaded coordinate regression has been adopted for 2D key-points localization <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b51">52]</ref>, hand-crafted image feature and classical weak learners such as linear regressors were used. In contrast, our geometric model G(c) only uses coordinates as input and each learner is a fully-connected (FC) DNN with residual connections <ref type="bibr" target="#b18">[19]</ref>.</p><p>The bottom of <ref type="figure" target="#fig_1">Fig. 5</ref> shows the detail for each deep learner. One deep learner first maps the input 2D coordinates into a representation vector of dimension d = 1024, after which R = 3 residual blocks are used. Finally the representation is mapped into 3D coordinates. After each FC layer we add batch normalization <ref type="bibr" target="#b20">[21]</ref> and dropout <ref type="bibr" target="#b62">[63]</ref> with dropout rate 0.5. The capacity of each deep learner can be controlled by R. This cascaded model is trained sequentially by gradient descent and the training algorithm is included in our supplementary material. Despite the number of parameters increase linearly with the cascade length, we found that the cascaded model is robust to over-fitting for this 3D coordinate prediction problem, which is also shared by the 2D counterparts <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b51">52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Implementation Details</head><p>The camera intrinsics provided by H36M are used to project 3D skeletons. We train A(x) and G(c) sequentially. The input size is 384 by 288 and our output heat-map has the same high resolution. The back-bone of A(x) is pretrained on COCO <ref type="bibr" target="#b31">[32]</ref> and we fine-tune it on H36M with Adam optimizer using a batch size of 24. The training is performed on two NVIDIA Titan Xp GPUs and takes 8 hours for 18k iterations. We first train with learning rate 0.001 for 3k iterations, after which we multiply it by 0.1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>To validate our data evolution framework, we evolve from the training data provided in H36M and investigate how data augmentation may affect the generalization ability of 2D-to-3D networks. We conduct both intra-and crossdataset evaluation. Intra-dataset evaluation is performed on H36M and demonstrates the model performance in an indoor environment similar to the training data. Cross-dataset evaluation is conducted on datasets not seen during training to simulate a larger domain shift. Considering the availability of MC data may vary in different application scenarios, We vary the size of initial population starting from scarce training data. These experiments help comparison with other weakly/semi-supervised methods that only use very few 3D annotation but do not consider data augmentation. Finally we present an ablation study to analyze the influences of architecture design and choice of hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets and Evaluation Metrics</head><p>Human 3.6M (H36M) is the largest 3D human pose estimation benchmark with accurate 3D labels. We denote a collection of data by appending subject ID to S, e.g., S15 denotes data from subject 1 and 5. Previous works fix the training data while our method uses it as our initial population and evolves from it. We evaluate model performance with Mean Per Joint Position Error (MPJPE) measured in millimeters. Two standard evaluation protocols are adopted. Protocol 1 (P1) directly computes MPJPE while Protocol 2 (P2) aligns the ground-truth 3D poses with the predictions with a rigid transformation before calculating it. Protocol P1 * uses ground truth 2D key-points as inputs and removes the influence of the first stage model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MPI-INF-3DHP</head><p>(3DHP) is a benchmark that we use to evaluate the generalization power of 2D-to-3D networks in unseen environments. We do not use its training data and conduct cross-dataset inference by feeding the provided key-points to G(c). Apart from MPJPE, Percentage of Correct Keypoints (PCK) measures correctness of 3D joint predictions under a specified threshold, while Area Under the Curve (AUC) is computed for a range of PCK thresholds.</p><p>Unconstrained 3D Poses in the Wild (U3DPW) We collect by ourselves a new small dataset consisting of 300 challenging in-the-wild images with rare human poses, where 150 of them are selected from Leeds Sports Pose dataset <ref type="bibr" target="#b22">[23]</ref>. The annotation process is detailed in our supplementary material. This dataset is used for qualitatively validating model generalization for unseen rare poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with state-of-the-art methods</head><p>Comparison with weakly-supervised methods. Here we compare with weakly/semi-supervised methods, which only use a small number of training data to simulate scarce data scenario. To be consistent with others, we utilize S1 as our initial population. While others fix S1 as the training dataset, we evolve from it to obtain an augmented training set. The comparison of model performance is shown in Tab. 2, where our model significantly out-performs others and demonstrates effective use of the limited training data. While other methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b24">25]</ref> use multi-view consistency as extra supervision, we achieve comparable performance with only a single view by synthesizing useful supervision. <ref type="figure">Fig. 2</ref> validates our method when the training data is extremely scarce, where we start with a small fraction of S1 and increase the data size by 2.5 times by evolution. Note that the model performs consistently better after dataset evolution. Compared to the temporal convolution model proposed in <ref type="bibr" target="#b48">[49]</ref>, we do not utilize any temporal information and achieve comparable performance. This indicates our approach can make better use of extremely limited data. <ref type="bibr">Method</ref>   Comparison with fully-supervised methods. Here we compare with fully-supervised methods that uses the whole training split of H36M. We use S15678 as our initial population and Tab. 3 shows the performance comparison. Under this setting, our model also achieves competitive performance compared with other SOTA methods, indicating that our approach is not limited to scarce data scenario.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Cross-dataset Generalization</head><p>To validate the generalization ability of our 2D-to-3D network in unknown environment, Tab. 4 compares with other methods on 3DHP. In this experiment we evolve from S15678 in H36M to obtain an augmented dataset consisting of 8 million 2D-3D pairs. Without utilizing any training data of 3DHP, G(c) achieves competitive performance in this benchmark. We obtain clear improvements comparing with <ref type="bibr" target="#b27">[28]</ref>, which also uses S15678 as the training data but fix it without data augmentation. The results indicate that our data augmentation approach improves model generalization effectively despite we start with the same biased training dataset. As shown in <ref type="figure" target="#fig_3">Fig. 7</ref>, the distribution of the augmented dataset indicates less dataset bias. Qualitative results on 3DHP and LSP are shown in <ref type="figure" target="#fig_2">Fig. 6</ref>. Note that these unconstrained poses are not well-represented in the original training dataset yet our model still gives good inference results. Qualitative comparison with <ref type="bibr" target="#b27">[28]</ref> on some difficult poses in U3DPW is shown in <ref type="figure">Fig. 8</ref> and our G(c) generalizes better for these rare human poses.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Study</head><p>Effect of data evolution. Our ablation study is conducted on H36M and summarized in Tab. 5. The baseline (B) uses T =1. Note that adding cascade (B+C) and dataset evolution (B+C+E) consistently out-performs the baseline. Discussion on the evolution operators is included in our supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of cascade length T.</head><p>Here we train our model on various subsets of H36M and plot MPJPE over cascade length as shown in <ref type="figure">Fig. 9</ref>. Here R is fixed as 2. Note that the training error increases as the training set becomes more complex and the testing errors decreases accordingly. The gap between these two errors indicate insufficient training data. Note that with increasing number of deep learners, the training error is effectively reduced but the model does not overfit. This property is brought by the ensemble effect <ref type="figure">Figure 8</ref>: Cross-dataset inference results on U3DPW comparing with <ref type="bibr" target="#b27">[28]</ref>. Video is included in our supplementary material.</p><p>of multiple deep learners. Effect of block number R. Here we fix T =1, d=512 and vary R. S15678 in H36M and its evolved version are used. The datasets before (BE) and after evolution (AE) are randomly split into training and testing subsets for simplicity. The training and testing MPJPEs are shown in <ref type="figure" target="#fig_5">Fig. 10</ref>. Note that the training error is larger after evolution with the same R=7. This means our approach increases the variation of training data, which can afford a deeper architecture with larger R (e.g. R=9). Training MPJPE (mm) under P1* S1 S15 S156 Testing MPJPE (mm) under P1* <ref type="figure">Figure 9</ref>: Training and testing errors with varying number of cascade length and training data. S156 indicates using 3D annotations from subjects 1, 5 and 6. The cascade effectively reduces training error and is robust to over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper presents an evolutionary framework to enrich the 3D pose distribution of an initial biased training set. This approach leads to better intra-dataset and cross-dataset generalization of 2D-to-3D network especially when available 3D annotation is scarce. A novel cascaded 3D human pose estimation model is trained achieving state-ofthe-art performance for single-frame 3D human pose esti-   <ref type="table">Table 5</ref>: Ablation study on H36M. B: baseline. C: add cascade. E: add data evolution. Evolve() represents the data augmentation operation. Same P1 and P1* as in <ref type="table" target="#tab_6">Table 2</ref>.</p><p>Error reduction compared with the baseline follows the ↓ signs.</p><p>mation. There are many fruitful directions remaining to be explored. Extension to temporal domain, multi-view setting and multi-person scenarios are three examples. In addition, instead of being fixed, the operators can also evolve during the data generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>This supplementary material includes implementation details and extended experimental analysis that are not included in the main text due to space limit. The detailed MPJPE under different settings are shown Tab. 6 and Tab. 7. Other contents are organized in separate sections as follows:</p><p>• Section 7 includes the implementation details of the hierarchal human representation.</p><p>• Section 8 elaborates the model training, which includes the training algorithm of the cascaded model and describes details of data pre-processing.</p><p>• Section 9 gives ablation study on data generation and the evolutionary operators.</p><p>• Section 10 describes the new dataset U3DPW and its collection process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Hierarchical Human Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Choice of Local Coordinate System</head><p>As mentioned at equation 2 in section 3.1, each global bone vector is transformed into a local bone vector with respect to a coordinate system attached at a parent joint. In general, the choice of the coordinate system is arbitrary and our evolutionary operators do not depend on it. In implementation, we adopt the coordinate system proposed in <ref type="bibr" target="#b1">[2]</ref>, where the computation of basis vectors depends on the 3D joint position. For the bone vectors representing upper limbs (left shoulder to left elbow, right shoulder to right elbow, left hip to left knee, right hip to right knee), the basis vectors are computed based on several joints belonging to the human torso. For the bone vectors representing lower limbs (left elbow to left wrist, right elbow to right wrist, left knee to left ankle, right knee to right ankle), the basis vectors are computed from the parent bone vectors.</p><p>Algorithm 2 is adapted from <ref type="bibr" target="#b1">[2]</ref> and details the process of computing basis vectors and performing coordinate transformation. Bold name such as rightShoulder denotes the global position of the 3D skeleton joint. We define a bone vector's parent bone vector as the bone vector whose end point is the starting point of it. An index mapping function M (i) is introduced here that maps bone vector index i to the index of its parent bone vector. Consistent with the notations of the main text, we have child(M (i)) = parent(i). In implementation, we found that the joints used in <ref type="bibr" target="#b1">[2]</ref> have slightly different semantic meaning compared to the data provided by H36M. Thus we use the bone vector connecting the spine and thorax joints to approximate the backbone vector used in in <ref type="bibr" target="#b1">[2]</ref> (backBone in algorithm 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Computation of local bone vector</head><p>Input: ith global bone vector bg = b i global , constant 3D vector a Output: ith local bone vector b l = b i local with its local coordinate system R i 1: backBone = Spine -Thorax 2: if bg is upper limb then 3:</p><formula xml:id="formula_18">v 1 = rightShoulder -leftShoulder 4: v 2 = backBone 5: else if bg is lower limb then 6: v 1 = rightHip -leftHip 7: v 2 = backBone 8: else 9: v 1 = b M (i) g 10: v 2 = R M (i) a × v 1 11: end if 12: R i = GramSchmidt(v 1 , v 2 , v 1 × v 2 ) 13: b l = R i T bg 14: return b l</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Validity Function</head><p>To implement v(p), local bone vectors are first computed by Algorithm 2 and converted into spherical coordinates as b i local = (r i , θ i , φ i ). A pose p is then considered as the collection of bone orientations</p><formula xml:id="formula_19">(θ i , φ i ) w i=1</formula><p>. A function is provided by <ref type="bibr" target="#b1">[2]</ref> to decide the validity of each tuple (θ i , φ i ). We define a pose p to be anthropometrically valid if every</p><formula xml:id="formula_20">tuple (θ i , φ i ) is valid: v(p) = 0, if (θ i , φ i ) is valid for i=1,2,...,w, −∞, else.</formula><p>The original code released by <ref type="bibr" target="#b1">[2]</ref> was implemented by MATLAB and we provide a Python implementation on our project website.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Model Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.">Training Procedure of the Cascaded Model</head><p>We train each deep learner in the cascade sequentially as depicted by algorithm 3. The T rainN etwork is a routine representing the training process of a single deep learner, which consists of forward pass, backward pass and network parameter update using Adam optimizer. Starting from the second deep learner, the inputs can also be concatenated with the current estimates as {φ(x i ),p i } N i=1 , which results in slightly smaller training errors while the change of testing errors is not obvious in our experiments on H36M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.">Data Pre-processing</head><p>To train the heatmap regression model A(x), we download training videos from the official website of H36M. We crop the persons with the provided bounding boxes and pad the cropped images with zeros in order to fix the aspect ratio as 4:3. We then resize the padded images to 384 by 288.   </p><formula xml:id="formula_21">- - - - - - - - - - - - - - - 65.3 Pavllo et al. (CVPR'19) [49] - - - - - - - - - - - - - - -</formula><formula xml:id="formula_22">- - - - - - - - - - - - - - - 64.6 Kocabas et al. (CVPR'19) [25] - - - - - - - - - - - - - - - 57.2 Li et al. (ICCV'19) [30] - - - - - - - - - - - - - - - 66.5</formula><p>Ours: Evolve(S1) 40.  <ref type="table">Table 7</ref>: Quantitative comparisons with the state-of-the-art weakly/semi-supervised methods on Human3.6M under protocol #1 and protocol #2. Best performance is indicated by bold font.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Cascaded Deep Networks Training</head><p>Input:</p><formula xml:id="formula_23">Training set {φ(x i ), p i } N i=1 , cascade length T Output: G(c) = T t=1 Dt(it, Θt) 1: Current estimate {p i } N i=1 = 0 2: Cascade G(c) = 0 3: for t=1:T do 4: Inputs it = {φ(x i )} N i=1 5: Regression targets = {p i −p i } N i=1 6: Dt = T rainN etwork(Inputs, Regression targets) 7: G(c) = G(c) + Dt 8:</formula><p>for i=1:N do 9:p i =p i + Dt(φ(x i )) 10:</p><p>end for 11: end for 12: return G(c)</p><p>The target heatmaps have the same size as the input images and we draw a Gaussian dot for each human key-point φ(x) k i=1 . The Gaussian dot's mean is the ground truth 2D location of the key-point and it has a standard deviation of 8 pixels.</p><p>To train the cascaded 3D pose estimation model G(c) on H36M, we download the pre-processed human skeletons released by the authors of <ref type="bibr" target="#b36">[37]</ref> in their github repository. Each deep learner in the cascaded model is trained with L2 loss. The evaluation set MPI-INF-3DHP is downloaded from the official website and we use the provided 2D keypoints as inputs to evaluate the trained cascaded 2D-to-3D model, which is consistent with and comparable to recent works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b14">15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Ablation Study on Data Evolution</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.">Effect of Number of Generation G</head><p>To study how the model performance improves with increasing number of synthetic data, we start with S1 data in Human 3.6M and synthesize training datasets with different size by varying the number of generations G. We train one model for each evolved dataset. All models have the save architecture and in this study where we fix T =1 and R=2. These models' performance (MPJPE under P1*) are shown in <ref type="figure" target="#fig_6">Fig. 11</ref>. Number of generations and the corresponding number of 2D-3D pairs are indicated on the x-axis by (G, N). We observe that the testing errors decrease steadily with larger G (more synthetic data) while the training errors have the opposite trend. This indicates that our data evolution approach indeed synthesizes novel supervision to augment the original dataset. The changing performance of the model can be seen as it is evolving along with the growing training dataset, where the model generalization power is significantly improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.">Effect of Evolutionary Operators</head><p>There has been debates on the individual function of crossover and mutation operators <ref type="bibr" target="#b61">[62]</ref>. In <ref type="bibr" target="#b61">[62]</ref> the author shows theoretically that the mutation operator has stronger disruptive property while the crossover operator has stronger constructive property. Here we conduct empirical experiments to study the effectiveness of these evolutionary operators applied on our problem. Here we compare between data evolution with crossover along and using both operators. The same initial population and model hyper-parameters as in Section 9.1 are adopted. The training and testing MPJPEs are shown in <ref type="figure" target="#fig_7">Fig. 12</ref>. We observe that adding mutation (+M) slightly increases training errors but decreases testing errors just like adding more data in Section 9.1. Despite the difference is not huge, this indicates that using both operators is beneficial for our problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Details for U3DPW</head><p>In this section, we describe how we collect and annotate the images for our new dataset U3DPW. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1.">Image Selection</head><p>We start by collecting 300 in-the-wild images that contain humans whose pose is not constrained to daily actions. We select 150 images from the existing LSP dataset <ref type="bibr" target="#b22">[23]</ref> and the remaining 150 high-resolution images are gathered from the Internet. To choose from the LSP dataset, we run SMPLify <ref type="bibr" target="#b6">[7]</ref> on all available images and manually select 150 images with large fitting errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2.">2D Annotation</head><p>We annotate 17 semantic 2D key-points for each image in U3DPW. These key-points are: right ankle, right knee, right hip, left hip, left knee, left ankle, right wrist, right elbow, right shoulder, left shoulder, left elbow, left wrist, neck, head top, spine, thorax and nose. Example new images (not in LSP) with 2D annotations are shown in <ref type="figure" target="#fig_1">Fig. 15</ref>. These images include large variation of human poses, camera viewpoints and illumination. Although we focus on 3D pose estimation in this work, these 2D annotations can also be used to evaluate 2D pose estimation models for unconstrained scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3.">3D Annotation</head><p>Using a subset of 2D key-points we run SMPLify <ref type="bibr" target="#b6">[7]</ref> to obtain fitted 3D human poses.</p><p>We provide an annotation tools that can be used after running SMPLify. The annotation tool displays the 3D skeleton after SMPLify fitting, current image and the projected 2D key-points (calculated with the camera intrinsics from the SMPLify fitting results). The fitted skeleton is converted into a hierarchical human representation, and the user can interactively modify the global pose orientation and the local bone vector orientation by keyboard inputs. With the user feeding inputs, new positions of the 2D human keypoints are updated in real-time so that the user can align the 2D projections with some reference key-points. One video demo of operating the annotation tool is placed at  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Others</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.1.">Video for Qualitative Comparison</head><p>The qualitative comparison with <ref type="bibr" target="#b27">[28]</ref>  <ref type="figure">(Fig. 8)</ref> is included as video for better visualization. The file can be found at root/videos/annotation/qualitative.mkv</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.2.">Failure Cases</head><p>Some individual cases are included as videos in root/ videos/. Projection ambiguity is hard to resolve in some cases and image features should be incorporated instead of only using key-points as inputs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Hierarchical human representation. Left: 3D keypoints organized in a kinematic tree where red arrows point from parent joints to children joints. Right: Zoom-in view of a local coordinate system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Our cascaded 3D pose estimation architecture. Top: our model is a two-stage model where the first stage is a 2D landmark detector and the second stage is a cascaded 3D coordinate regression model. Bottom: each learner in the cascade is a feed-forward neural network whose capacity can be adjusted by the number of residual blocks. To fit an evolved dataset with plenty 2D-3D pairs, we use 8 layers (3 blocks) for each deep learner and have 24 layers in total with a cascade of 3 deep learners.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Cross-dataset inferences of G(c) on MPI-INF-3DHP (first row) and LSP (next two rows). after every 3k iterations. To train G(c), we train each deep learner in the cascade using Adam optimizer with learning rate 0.001 for 200 epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Dataset distribution for the bone vector connecting right shoulder to right elbow. Top: distribution before (left) and after (right) dataset augmentation. Bottom: distribution overlaid with valid regions (brown) taken from<ref type="bibr" target="#b1">[2]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>MPJPE (P1*) before (BE) and after evolution (AE) with varying number of blocks R. Evolved training data can afford a deeper network. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 :</head><label>11</label><figDesc>Training and testing MPJPE under P1* with varying number of generation (amount of training 2D-3D pairs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 :</head><label>12</label><figDesc>Training and testing errors under P1* with and without adding mutation. C: crossover, M: mutation. Using crossover and mutation together out-performs using crossover alone in our experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 13 :</head><label>13</label><figDesc>3D annotation examples for U3DPW shown in two different viewpoints.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 14 :</head><label>14</label><figDesc>A snapshot of the annotation process. Left: 3D human skeleton. Right: image and 2D projections. root/videos/annotation_tool.mkv. Here root refers to the directory of the unzipped supplementary material folder. Some exemplar 3D annotations are shown in Fig. 13.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 15 :</head><label>15</label><figDesc>Exemplar images of U3DPW with 2D annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Stage 2C...</figDesc><table><row><cell></cell><cell></cell><cell>.</cell><cell>.</cell><cell>.</cell><cell></cell><cell>C</cell><cell>.</cell><cell>.</cell><cell>.</cell><cell>.</cell></row><row><cell>Heatmap Regression Model</cell><cell>2D Joints</cell><cell cols="3">3D Pose Regression Model (Stage 2A)</cell><cell>3D Joints</cell><cell cols="3">3D Pose Refinement Model (Stage 2B)</cell></row><row><cell>(Stage 1)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Input/Output Coordinates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3D Pose Representation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fully Connected Layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Skip Connection</cell><cell>(1, 2*k)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>k: Number of human keypoints</cell><cell>(1, d)</cell><cell>(1, d) (1, d)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>d: Representation dimension</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Offsets + ..</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>to obtain 2D coordinates. The average 2D key-point localization errors for H36M testing images are shown in Tab. 1. Our design choice improves the previous best model and achieves the highest key-point localization accuracy on H36M to date. The extensions add negligible amount of parameters and computation.</figDesc><table><row><cell>Backbone</cell><cell>Extension</cell><cell>#Params</cell><cell>FLOPs</cell><cell>Error↓</cell></row><row><cell>CPN [13]</cell><cell>-</cell><cell>-</cell><cell>13.9G</cell><cell>5.40</cell></row><row><cell>HRN [64]</cell><cell>-</cell><cell>63.6M</cell><cell>32.9G</cell><cell>4.98 ↓7.8%</cell></row><row><cell>HRN</cell><cell>+ U</cell><cell>63.6M</cell><cell>32.9G</cell><cell>4.64 ↓14.1%</cell></row><row><cell>HRN</cell><cell>+ U + S</cell><cell>63.6M</cell><cell>32.9G</cell><cell>4.36 ↓19.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Average 2D key-point localization errors for H36M testing set in terms of pixels. U: Heat-map up-sampling. S: use soft-argmax. Error reduction compared with the previous best model<ref type="bibr" target="#b12">[13]</ref> used in<ref type="bibr" target="#b48">[49]</ref> follows the ↓ signs.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>Comparison with SOTA weakly-supervised meth-</cell></row><row><cell>ods. Average MPJPE over all 15 actions for H36M under</cell></row><row><cell>two protocols (P1 and P2) is reported. P1* refers to proto-</cell></row><row><cell>col 1 evaluated with ground truth 2d key-points. Best per-</cell></row><row><cell>formance is marked with bold font. Error for each action</cell></row><row><cell>can be found in Tab. 7.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Comparison with SOTA methods under fully- supervised setting. Same P1, P1* and P2 as in Tab. 2. Error for each action can be found in Tab. 6.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>Testing results for the MPI-INF-3DHP dataset. A higher value is better for PCK and AUC while a lower value is better for MPJPE. MPJPE is evaluated without rigid transformation. CE denotes cross-dataset evaluation and the training data in MPI-INF-3DHP is not used.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Protocol #1Dir. Disc Eat Greet Phone Photo Pose Purch. Sit SitD. Smoke Wait WalkD. Walk WalkT. Avg.</figDesc><table><row><cell>Martinez et al. (ICCV'17)[37]</cell><cell>51.8 56.2 58.1 59.0</cell><cell>69.5</cell><cell>78.4</cell><cell>55.2</cell><cell>58.1</cell><cell cols="2">74.0 94.6</cell><cell>62.3</cell><cell>59.1</cell><cell>65.1</cell><cell>49.5</cell><cell>52.4</cell><cell>62.9</cell></row><row><cell>Fang et al. (AAAI'18) [17]</cell><cell>50.1 54.3 57.0 57.1</cell><cell>66.6</cell><cell>73.3</cell><cell>53.4</cell><cell>55.7</cell><cell cols="2">72.8 88.6</cell><cell>60.3</cell><cell>57.7</cell><cell>62.7</cell><cell>47.5</cell><cell>50.6</cell><cell>60.4</cell></row><row><cell>Yang et al. (CVPR'18) [71]</cell><cell>51.5 58.9 50.4 57.0</cell><cell>62.1</cell><cell>65.4</cell><cell>49.8</cell><cell>52.7</cell><cell cols="2">69.2 85.2</cell><cell>57.4</cell><cell>58.4</cell><cell>43.6</cell><cell>60.1</cell><cell>47.7</cell><cell>58.6</cell></row><row><cell cols="2">Pavlakos et al. (CVPR'18) [46] 48.5 54.4 54.4 52.0</cell><cell>59.4</cell><cell>65.3</cell><cell>49.9</cell><cell>52.9</cell><cell cols="2">65.8 71.1</cell><cell>56.6</cell><cell>52.9</cell><cell>60.9</cell><cell>44.7</cell><cell>47.8</cell><cell>56.2</cell></row><row><cell>Lee et al. (ECCV'18) [27]</cell><cell>40.2 49.2 47.8 52.6</cell><cell>50.1</cell><cell>75.0</cell><cell>50.2</cell><cell>43.0</cell><cell cols="2">55.8 73.9</cell><cell>54.1</cell><cell>55.6</cell><cell>58.2</cell><cell>43.3</cell><cell>43.3</cell><cell>52.8</cell></row><row><cell>Zhao et al. (CVPR'19) [73]</cell><cell>47.3 60.7 51.4 60.5</cell><cell>61.1</cell><cell>49.9</cell><cell>47.3</cell><cell>68.1</cell><cell cols="2">86.2 55.0</cell><cell>67.8</cell><cell>61.0</cell><cell>42.1</cell><cell>60.6</cell><cell>45.3</cell><cell>57.6</cell></row><row><cell>Sharma et al. (ICCV'19) [59]</cell><cell>48.6 54.5 54.2 55.7</cell><cell>62.6</cell><cell>72.0</cell><cell>50.5</cell><cell>54.3</cell><cell cols="2">70.0 78.3</cell><cell>58.1</cell><cell>55.4</cell><cell>61.4</cell><cell>45.2</cell><cell>49.7</cell><cell>58.0</cell></row><row><cell>Moon et al. (ICCV'19) [41]</cell><cell>51.5 56.8 51.2 52.2</cell><cell>55.2</cell><cell>47.7</cell><cell>50.9</cell><cell>63.3</cell><cell cols="2">69.9 54.2</cell><cell>57.4</cell><cell>50.4</cell><cell>42.5</cell><cell>57.5</cell><cell>47.7</cell><cell>54.4</cell></row><row><cell>Liu et al. (ECCV'20) [33]</cell><cell>46.3 52.2 47.3 50.7</cell><cell>55.5</cell><cell>67.1</cell><cell>49.2</cell><cell>46.0</cell><cell cols="2">60.4 71.1</cell><cell>51.5</cell><cell>50.1</cell><cell>54.5</cell><cell>40.3</cell><cell>43.7</cell><cell>52.4</cell></row><row><cell>Ours: Evolve(S15678)</cell><cell>47.0 47.1 49.3 50.5</cell><cell>53.9</cell><cell>58.5</cell><cell>48.8</cell><cell>45.5</cell><cell cols="2">55.2 68.6</cell><cell>50.8</cell><cell>47.5</cell><cell>53.6</cell><cell>42.3</cell><cell>45.6</cell><cell>50.9</cell></row><row><cell>Protocol #2</cell><cell cols="5">Dir. Disc Eat Greet Phone Photo Pose Purch.</cell><cell>Sit</cell><cell cols="7">SitD. Smoke Wait WalkD. Walk WalkT. Avg.</cell></row><row><cell cols="2">Martinez et al. (ICCV'17) [37] 39.5 43.2 46.4 47.0</cell><cell>51.0</cell><cell>56.0</cell><cell>41.4</cell><cell>40.6</cell><cell cols="2">56.5 69.4</cell><cell>49.2</cell><cell>45.0</cell><cell>49.5</cell><cell>38.0</cell><cell>43.1</cell><cell>47.7</cell></row><row><cell>Fang et al. (AAAI'18) [17]</cell><cell>38.2 41.7 43.7 44.9</cell><cell>48.5</cell><cell>55.3</cell><cell>40.2</cell><cell>38.2</cell><cell cols="2">54.5 64.4</cell><cell>47.2</cell><cell>44.3</cell><cell>47.3</cell><cell>36.7</cell><cell>41.7</cell><cell>45.7</cell></row><row><cell cols="2">Pavlakos et al. (CVPR'18) [46] 34.7 39.8 41.8 38.6</cell><cell>42.5</cell><cell>47.5</cell><cell>38.0</cell><cell>36.6</cell><cell cols="2">50.7 56.8</cell><cell>42.6</cell><cell>39.6</cell><cell>43.9</cell><cell>32.1</cell><cell>36.5</cell><cell>41.8</cell></row><row><cell>Yang et al. (CVPR'18) [71]</cell><cell>26.9 30.9 36.3 39.9</cell><cell>43.9</cell><cell>47.4</cell><cell>28.8</cell><cell>29.4</cell><cell cols="2">36.9 58.4</cell><cell>41.5</cell><cell>30.5</cell><cell>29.5</cell><cell>42.5</cell><cell>32.2</cell><cell>37.7</cell></row><row><cell>Sharma et al. (ICCV'19) [59]</cell><cell>35.3 35.9 45.8 42.0</cell><cell>40.9</cell><cell>52.6</cell><cell>36.9</cell><cell>35.8</cell><cell cols="2">43.5 51.9</cell><cell>44.3</cell><cell>38.8</cell><cell>45.5</cell><cell>29.4</cell><cell>34.3</cell><cell>40.9</cell></row><row><cell>Cai et al. (ICCV'19) [9]</cell><cell>35.7 37.8 36.9 40.7</cell><cell>39.6</cell><cell>45.2</cell><cell>37.4</cell><cell>34.5</cell><cell cols="2">46.9 50.1</cell><cell>40.5</cell><cell>36.1</cell><cell>41.0</cell><cell>29.6</cell><cell>33.2</cell><cell>39.0</cell></row><row><cell>Liu et al. (ECCV'20) [33]</cell><cell>35.9 40.0 38.0 41.5</cell><cell>42.5</cell><cell>51.4</cell><cell>37.8</cell><cell>36.0</cell><cell cols="2">48.6 56.6</cell><cell>41.8</cell><cell>38.3</cell><cell>42.7</cell><cell>31.7</cell><cell>36.2</cell><cell>41.2</cell></row><row><cell>Ours: Evolve(S15678)</cell><cell>34.5 34.9 37.6 39.6</cell><cell>38.8</cell><cell>45.9</cell><cell>34.8</cell><cell>33.0</cell><cell cols="2">40.8 51.6</cell><cell>38.0</cell><cell>35.7</cell><cell>40.2</cell><cell>30.2</cell><cell>34.8</cell><cell>38.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 6 :</head><label>6</label><figDesc>Quantitative comparisons with the state-of-the-art fully-supervised methods on Human3.6M under protocol #1 and protocol #2. Best performance is indicated by bold font.</figDesc><table><row><cell>Protocol #1</cell><cell>Dir. Disc Eat Greet Phone Photo Pose Purch.</cell><cell>Sit</cell><cell>SitD. Smoke Wait WalkD. Walk WalkT. Avg.</cell></row></table><note>Kocabas et al. (CVPR'19) [25]</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The coordinate system is detailed in our supplementary material.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Relative to the root joint.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recovering 3d human pose from monocular images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="44" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pose-conditioned joint angle limits for 3d human pose reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">2d human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scape: shape completion and animation of people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM transactions on graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="408" to="416" />
			<date type="published" when="2005" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bernt Schiele, Nassir Navab, and Slobodan Ilic. 3d pictorial structures for multiple human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1669" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Structured outputassociative regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2403" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Keep it smpl: Automatic estimation of 3d human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">3d pictorial structures for multiple view articulated pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Burenius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3618" to="3625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploiting spatial-temporal relationships for 3d pose estimation via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Jen</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><forename type="middle">Magnenat</forename><surname>Thalmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2272" to="2281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Face alignment by explicit shape regression. International Journal of Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Synthesizing training images for boosting human 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhe</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 Fourth International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="479" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weakly-supervised discovery of geometry-aware representation for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Yee</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cascaded pyramid network for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7103" to="7112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Occlusion-aware networks for 3d human pose estimation in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wending</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing network structure for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evolutionary data augmentation in deep face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Correia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Penousal</forename><surname>Machado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
		<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="163" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning pose grammar to encode human body configuration for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">In the wild human pose estimation using explicit 2d features and intermediate 3d representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikhsanul</forename><surname>Habibie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10905" to="10914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">Henry</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Clustered pose and nonlinear appearance models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<idno type="DOI">10.5244/C.24.12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7122" to="7131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Selfsupervised learning of 3d human pose using multi-view geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salih</forename><surname>Karagoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Akbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to reconstruct 3d human pose and shape via model-fitting in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Propagating lstm: 3d pose estimation based on joint interdependency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoungoh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inwoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghoon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="119" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generating multiple hypotheses for 3d human pose estimation with mixture density network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Repair: Removing representation bias by dataset resampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9572" to="9581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On boosting single-frame 3d human pose estimation via monocular videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recurrent 3d pose sequence machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mude</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="810" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A comprehensive study of weight sharing in graph networks for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenkun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongqi</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="318" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Smpl: A skinned multiperson linear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">248</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Orinet: A fully convolutional network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.04989</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">2d/3d pose estimation and action recognition using multitask deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Diogo C Luvizon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tabia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5137" to="5146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Conference on 3D Vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="506" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Single-shot multi-person 3d pose estimation from monocular rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on 3D Vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="120" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Vnect: Real-time 3d human pose estimation with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shafiei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">44</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Camera distance-aware top-down approach for 3d multiperson pose estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juyong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">3d human pose estimation from a single image via distance matrix regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2823" to="2832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aiden</forename><surname>Nibali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Prendergast</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07372</idno>
		<title level="m">Numerical coordinate regression with convolutional neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation by predicting depth on joints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Bruce Xiaohan Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3467" to="3475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Expressive body capture: 3d hands, face, and body from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10975" to="10985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ordinal depth supervision for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7307" to="7316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Coarse-to-fine volumetric prediction for single-image 3d human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7025" to="7034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Harvesting multiple views for marker-less 3d human pose annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">3d human pose estimation in video with temporal convolutions and semi-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rogerio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2226" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Exploiting temporal information for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Mir Rayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="68" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Face alignment at 3000 fps via regressing local binary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1685" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised geometry-aware representation for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="750" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning monocular 3d human pose estimation from multi-view images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Spörri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mocap-guided data augmentation for 3d pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3108" to="3116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Lcr-net: Localization-classification-regression for human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3433" to="3441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning body pose via specialized maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rómer</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1263" to="1270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation by generation and ordinal ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation by generation and ordinal ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2325" to="2334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1874" to="1883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alexandru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Crossover or mutation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of genetic algorithms</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1993" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A deeper look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Domain adaptation in computer vision applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="37" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2011 IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Learning from synthetic humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gul</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7782" to="7791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">3d human pose estimation in the wild by adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">From actemes to action: A strongly-supervised representation for detailed action understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos G</forename><surname>Derpanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2248" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Semantic graph convolutional networks for 3d human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Towards 3d human pose estimation in the wild: a weakly-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="398" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Sparseness meets deepness: 3d human pose estimation from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyridon</forename><surname>Leonardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4966" to="4975" />
		</imprint>
	</monogr>
	<note>Konstantinos G Derpanis, and Kostas Daniilidis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
