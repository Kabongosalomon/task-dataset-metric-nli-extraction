<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Novel Cascade Binary Tagging Framework for Relational Triple Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhepei</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Symbolic Computation and Knowledge Engineering</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Su</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Shenzhen Zhuiyi Technology Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
							<email>wangyue@email.unc.edu</email>
							<affiliation key="aff4">
								<orgName type="department">School of Information and Library Science</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Tian</surname></persName>
							<email>yuantian@jlu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Symbolic Computation and Knowledge Engineering</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
							<email>yichang@jlu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Symbolic Computation and Knowledge Engineering</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">International Center of Future Science</orgName>
								<orgName type="institution">Jilin University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Novel Cascade Binary Tagging Framework for Relational Triple Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CASREL) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CAS-REL framework already outperforms state-ofthe-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online 1 . * Joint Corresponding Author 1 https://github.com/weizhepei/CasRel Normal The [United States] President [Trump] has a meet with [Tim Cook], the CEO of [Apple Inc]. EPO [Quentin Tarantino] played a nobody in his directed film [Django Unchained]. SEO [Jackie R. Brown] was born in [Washington], the capital city of [United States of America].</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The key ingredient of a knowledge graph is relational facts, most of which consist of two entities connected by a semantic relation. These facts are in the form of (subject, relation, object), or (s, r, o), referred to as relational triples. Extracting relational triples from natural language text is a crucial step towards constructing large-scale knowledge graphs. Early works in relational triple extraction took a pipeline approach <ref type="bibr">(Zelenko et al., 2003;</ref><ref type="bibr">Zhou et al., 2005;</ref><ref type="bibr">Chan and Roth, 2011)</ref>. It first recognizes all entities in a sentence and then performs relation classification for each entity pair. Such an approach tends to suffer from the error propagation problem since errors in early stages cannot be corrected in later stages. To tackle this problem, subsequent works proposed joint learning of entities and relations, among them are feature-based models <ref type="bibr">(Yu and Lam, 2010;</ref><ref type="bibr">Li and Ji, 2014;</ref><ref type="bibr">Miwa and Sasaki, 2014;</ref><ref type="bibr">Ren et al., 2017)</ref> and, more recently, neural network-based models <ref type="bibr">(Gupta et al., 2016;</ref><ref type="bibr">Katiyar and Cardie, 2017;</ref><ref type="bibr">Zheng et al., 2017;</ref><ref type="bibr">Zeng et al., 2018;</ref><ref type="bibr">Fu et al., 2019)</ref>. By replacing manually constructed features with learned representations, neural network-based models have achieved considerable success in the triple extraction task.</p><p>However, most existing approaches cannot efficiently handle scenarios in which a sentence contains multiple relational triples that overlap with each other. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates these scenarios, where triples share one or two entities in a sentence. This overlapping triple problem directly challenges conventional sequence tagging schemes that assume each token bears only one tag <ref type="bibr">(Zheng et al., 2017)</ref>. It also brings significant difficulty to relation classification approaches where an entity pair is assumed to hold at most one relation <ref type="bibr">(Miwa and Bansal, 2016)</ref>. <ref type="bibr">Zeng et al. (2018)</ref> is among the first to consider the overlapping triple problem in relational triple extraction. They introduced the categories for different overlapping patterns as shown in <ref type="figure" target="#fig_0">Figure 1</ref> and proposed a sequence-to-sequence (Seq2Seq) model with copy mechanism to extract triples. Based on the Seq2Seq model, they further investigate the impact of extraction order <ref type="bibr">(Zeng et al., 2019)</ref> and gain considerable improvement with reinforcement learning. <ref type="bibr">Fu et al. (2019)</ref> also studied the overlapping triple problem by modeling text as relational graphs with a graph convolutional networks (GCNs) based model.</p><p>Despite their success, previous works on extracting overlapping triples still leave much to be desired. Specifically, they all treat relations as discrete labels to be assigned to entity pairs. This formulation makes relation classification a hard machine learning problem. First, the class distribution is highly imbalanced. Among all pairs of extracted entities, most do not form valid relations, generating too many negative examples. Second, the classifier can be confused when the same entity participates in multiple valid relations (overlapping triples). Without enough training examples, the classifier can hardly tell which relation the entity participates in. As a result, the extracted triples are usually incomplete and inaccurate.</p><p>In this work, we start with a principled formulation of relational triple extraction right at the triple level. This gives rise to a general algorithmic framework that handles the overlapping triple problem by design. At the core of the framework is the fresh perspective that instead of treating relations as discrete labels on entity pairs, we can model relations as functions that map subjects to objects. More precisely, instead of learning relation classifiers f (s, o) → r, we learn relation-specific taggers f r (s) → o, each of which recognizes the possible object(s) of a given subject under a specific relation; or returns no object, indicating that there is no triple with the given subject and relation. Under this framework, triple extraction is a two-step process: first we identify all possible subjects in a sentence; then for each subject, we apply relationspecific taggers to simultaneously identify all possible relations and the corresponding objects.</p><p>We implement the above idea in CASREL, an end-to-end cascade binary tagging framework. It consists of a BERT-based encoder module, a sub-ject tagging module, and a relation-specific object tagging module. Empirical experiments show that the proposed framework outperforms state-of-theart methods by a large margin even when the BERT encoder is not pre-trained, showing the superiority of the new framework itself. The framework enjoys a further large performance gain after adopting a pre-trained BERT encoder, showing the importance of rich prior knowledge in triple extraction task.</p><p>This work has the following main contributions:</p><p>1. We introduce a fresh perspective to revisit the relational triple extraction task with a principled problem formulation, which implies a general algorithmic framework that addresses the overlapping triple problem by design.</p><p>2. We instantiate the above framework as a novel cascade binary tagging model on top of a Transformer encoder. This allows the model to combine the power of the novel tagging framework with the prior knowledge in pretrained large-scale language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Extensive experiments on two public datasets</head><p>show that the proposed framework overwhelmingly outperforms state-of-the-art methods, achieving 17.5 and 30.2 absolute gain in F1-score on the two datasets respectively. Detailed analyses show that our model gains consistent improvement in all scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Extracting relational triples from unstructured natural language texts is a well-studied task in information extraction (IE). It is also an important step for the construction of large scale knowledge graph (KG) such as DBpedia <ref type="bibr" target="#b0">(Auer et al., 2007)</ref>, Freebase <ref type="bibr">(Bollacker et al., 2008)</ref> and Knowledge Vault <ref type="bibr">(Dong et al., 2014)</ref>. Early works <ref type="bibr">(Mintz et al., 2009;</ref><ref type="bibr">Gormley et al., 2015)</ref> address the task in a pipelined manner. They extract relational triples in two separate steps: 1) first run named entity recognition (NER) on the input sentence to identify all entities and 2) then run relation classification (RC) on pairs of extracted entities. The pipelined methods usually suffer from the error propagation problem and neglect the relevance between the two steps. To ease these issues, many joint models that aim to learn entities and relations jointly have been proposed. Traditional joint models <ref type="bibr">(Yu and Lam, 2010;</ref><ref type="bibr">Li and Ji, 2014;</ref><ref type="bibr">Miwa and Sasaki, 2014;</ref><ref type="bibr">Ren et al., 2017)</ref> are feature-based, which heavily rely on feature engineering and require intensive manual efforts. To reduce manual work, recent studies have investigated neural network-based methods, which deliver state-of-the-art performance. However, most existing neural models like (Miwa and Bansal, 2016) achieve joint learning of entities and relations only through parameter sharing but not joint decoding. To obtain relational triples, they still have to pipeline the detected entity pairs to a relation classifier for identifying the relation of entities. The separated decoding setting leads to a separated training objective for entity and relation, which brings a drawback that the triple-level dependencies between predicted entities and relations cannot be fully exploited. Different from those works, <ref type="bibr">Zheng et al. (2017)</ref> achieves joint decoding by introducing a unified tagging scheme and convert the task of relational triple extraction to an end-to-end sequence tagging problem without need of NER or RC. The proposed method can directly model relational triples as a whole at the triple level since the information of entities and relations is integrated into the unified tagging scheme.</p><p>Though joint models (with or without joint decoding) have been well studied, most previous works ignore the problem of overlapping relational triples. <ref type="bibr">Zeng et al. (2018)</ref> introduced three patterns of overlapping triples and try to address the problem via a sequence-to-sequence model with copy mechanism. <ref type="bibr">Recently, Fu et al. (2019)</ref> also study the problem and propose a graph convolutional networks (GCNs) based method. Despite their initial success, both methods still treat the relations as discrete labels of entity pairs, making it quite hard for the model to learn overlapping triples.</p><p>Our framework is based on a training objective that is carefully designed to directly model the relational triples as a whole like (Zheng et al., 2017), i.e., to learn both entities and relations through joint decoding. Moreover, we model the relations as functions that map subjects to objects, which makes it crucially different from previous works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The CASREL Framework</head><p>The goal of relational triple extraction is to identify all possible (subject, relation, object) triples in a sentence, where some triples may share the same entities as subjects or objects. Towards this goal, we directly model the triples and design a training objective right at the triple level. This is in contrast to previous approaches like <ref type="bibr">(Fu et al., 2019)</ref> where the training objective is defined separately for entities and relations without explicitly modeling their integration at the triple level.</p><p>Formally, given annotated sentence x j from the training set D and a set of potentially overlapping triples T j = {(s, r, o)} in x j , we aim to maximize the data likelihood of the training set D: (1) (3)</p><formula xml:id="formula_0">= |D| j=1   s∈T j p(s|xj) (r,o)∈T j |s p((r, o)|s, xj)   (2) = |D| j=1   s∈T j p(s|xj)</formula><p>Here we slightly abuse the notation T j . s ∈ T j denotes a subject appearing in the triples in T j . T j |s is the set of triples led by subject s in T j .</p><p>(r, o) ∈ T j |s is a (r, o) pair in the triples led by subject s in T j . R is the set of all possible relations.</p><p>R\T j |s denotes all relations except those led by s in T j . o ∅ denotes a "null" object (explained below). Eq.</p><p>(2) applies the chain rule of probability. Eq. (3) exploits the crucial fact that for a given subject s, any relation relevant to s (those in T j |s) would lead to corresponding objects in the sentence, and all other relations would necessarily have no object in the sentence, i.e. a "null" object.</p><p>This formulation provides several benefits. First, since the data likelihood starts at the triple level, optimizing this likelihood corresponds to directly optimizing the final evaluation criteria at the triple level. Second, by making no assumption on how multiple triples may share entities in a sentence, it handles the overlapping triple problem by design. Third, the decomposition in Eq. (3) inspires a novel tagging scheme for triple extraction: we learn a subject tagger p(s|x j ) that recognizes subject entities in a sentence; and for each relation r, we learn an object tagger p r (o|s, x j ) that recognizes relationspecific objects for a given subject. In this way we can model each relation as a function that maps subjects to objects, as opposed to classifying relations for (subject, object) pairs.</p><p>Indeed, this novel tagging scheme allows us to extract multiple triples at once: we first run the subject tagger to find all possible subjects in the sentence, and then for each subject found, apply relation-specific object taggers to find all relevant relations and the corresponding objects.</p><p>The key components in the above general framework, i.e., the subject tagger and relation-specific object taggers, can be instantiated in many ways. In this paper, we instantiate them as binary taggers on top of a deep bidirectional Transformer <ref type="bibr">BERT (Devlin et al., 2019)</ref>. We describe its detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BERT Encoder</head><p>The encoder module extracts feature information x j from sentence x j , which will feed into subsequent tagging modules 2 . We employ a pre-trained BERT model <ref type="bibr">(Devlin et al., 2019)</ref> to encode the context information.</p><p>Here we briefly review BERT, a multi-layer bidirectional Transformer based language representation model. It is designed to learn deep representations by jointly conditioning on both left and right context of each word, and it has recently been proven surprisingly effective in many downstream tasks <ref type="bibr">(Zhong et al., 2019)</ref>. Specifically, it is composed of a stack of N identical Transformer blocks. We denote the Transformer block as T rans(x), in which x represents the input vector. The detailed operations are as follows:</p><formula xml:id="formula_1">h 0 = SW s + W p (4) h α = T rans(h α−1 ), α ∈ [1, N ]<label>(5)</label></formula><p>where S is the matrix of one-hot vectors of subwords 3 indices in the input sentence, W s is the sub-words embedding matrix, W p is the positional embedding matrix where p represents the position index in the input sequence, h α is the hidden state vector, i.e., the context representation of input sentence at α-th layer and N is the number of Transformer blocks. Note that in our work the input is a single text sentence instead of sentence pair, hence the segmentation embedding as described in original BERT paper was not taken into account in Eq. (4). For a more comprehensive description of the Transformer structure, we refer readers to <ref type="bibr">(Vaswani et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cascade Decoder</head><p>Now we describe our instantiation of the novel cascade binary tagging scheme inspired by the previous formulation. The basic idea is to extract triples in two cascade steps. First, we detect subjects from the input sentence. Then for each candidate subject, we check all possible relations to see if a relation can associate objects in the sentence with that subject. Corresponding to the two steps, the cascade decoder consists of two modules as illustrated in <ref type="figure">Figure 2</ref>: a subject tagger; and a set of relationspecific object taggers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subject Tagger</head><p>The low level tagging module is designed to recognize all possible subjects in the input sentence by directly decoding the encoded vector h N produced by the N -layer BERT encoder. More precisely, it adopts two identical binary classifiers to detect the start and end position of subjects respectively by assigning each token a binary tag (0/1) that indicates whether the current token corresponds to a start or end position of a subject. The detailed operations of the subject tagger on each token are as follows:</p><formula xml:id="formula_2">p start s i = σ(W start x i + b start ) (6) p end s i = σ(W end x i + b end )<label>(7)</label></formula><p>where p start s i and p end s i represent the probability of identifying the i-th token in the input sequence as the start and end position of a subject, respectively. The corresponding token will be assigned with a tag 1 if the probability exceeds a certain threshold or with a tag 0 otherwise. x i is the encoded representation of the i-th token in the input sequence, i.e., x i = h N [i], where W (·) represents the trainable weight, and b (·) is the bias and σ is the sigmoid activation function.</p><p>The subject tagger optimizes the following likelihood function to identify the span of subject s given a sentence representation x:</p><formula xml:id="formula_3">p θ (s|x) = t∈{start s,end s} L i=1 p t i I{y t i =1} 1 − p t i I{y t i =0} .<label>(8)</label></formula><p>where L is the length of the sentence. I{z} = 1 if z is true and 0 otherwise. y start s i is the binary tag of subject start position for the i-th token in x, and y end s i indicates the subject end position. The parameters θ = {W start , b start , W end , b end }. <ref type="figure">Figure 2</ref>: An overview of the proposed CASREL framework. In this example, there are three candidate subjects detected at the low level, while the presented 0/1 tags at high level are specific to the first subject Jackie R. Brown, i.e., a snapshot of the iteration state when k = 1 is shown as above. For the subsequent iterations (k = 2, 3), the results at high level will change, reflecting different triples detected. For instance, when k = 2, the high-level orange (green) blocks will change to 0 (1), respectively, reflecting the relational triple (Washington, Capital of, United States Of America) led by the second candidate subject Washington.</p><p>For multiple subjects detection, we adopt the nearest start-end pair match principle to decide the span of any subject based on the results of the start and end position taggers. For example, as shown in <ref type="figure">Figure 2</ref>, the nearest end token to the first start token "Jackie" is "Brown", hence the detected result of the first subject span will be "Jackie R. Brown". Notably, to match an end token for a given start token, we don't consider tokens whose position is prior to the position of the given token. Such match strategy is able to maintain the integrity of any entity span if the start and end positions are both correctly detected due to the natural continuity of any entity span in a given sentence.</p><p>Relation-specific Object Taggers The high level tagging module simultaneously identifies the objects as well the involved relations with respect to the subjects obtained at lower level. As <ref type="figure">Figure 2</ref> shows, it consists of a set of relation-specific object taggers with the same structure as subject tagger in low level module for all possible relations. All object taggers will identify the corresponding object(s) for each detected subject at the same time.</p><p>Different from subject tagger directly decoding the encoded vector h N , the relation-specific object tagger takes the subject features into account as well. The detailed operations of the relation-specific object tagger on each token are as follows:</p><formula xml:id="formula_4">p start o i = σ(W r start (x i + v k sub ) + b r start ) (9) p end o i = σ(W r end (x i + v k sub ) + b r end ) (10)</formula><p>where p start o i and p end o i represent the probability of identifying the i-th token in the input sequence as the start and end position of a object respectively, and v k sub represents the encoded representation vector of the k-th subject detected in low level module.</p><p>For each subject, we iteratively apply the same decoding process on it. Note that the subject is usually composed of multiple tokens, to make the additions of x i and v k sub in Eq. (9) and Eq. (10) possible, we need to keep the dimension of two vectors consistent. To do so, we take the averaged vector representation between the start and end tokens of the k-th subject as v k sub . The object tagger for relation r optimizes the following likelihood function to identify the span of object o given a sentence representation x and a subject s:</p><formula xml:id="formula_5">p φr (o|s, x) = t∈{start o,end o} L i=1 p t i I{y t i =1} 1 − p t i I{y t i =0} .<label>(11)</label></formula><p>where y start o i is the binary tag of object start position for the i-th token in x, and y end o i is the tag of object end position for the i-th token. For a "null" object o ∅ , the tags y</p><formula xml:id="formula_6">start o∅ i = y end o∅ i = 0 for all i. The parameters φ r = {W r start , b r start , W r end , b r end }.</formula><p>Note that in the high level tagging module, the relation is also decided by the output of object taggers. For example, the relation "Work in" does not hold between the detected subject "Jackie R. Brown" and the candidate object "Washington". Therefore, the object tagger for relation "Work in" will not identify the span of "Washington", i.e., the output of both start and end position are all zeros as shown in <ref type="figure">Figure 2</ref>. In contrast, the relation "Birth place" holds between "Jackie R. Brown" and "Washington", so the corresponding object tagger outputs the span of the candidate object "Washington". In this setting, the high level module is capable of simultaneously identifying the relations and objects with regard to the subjects detected in low level module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Log-likelihood Objective</head><p>Taking log of Eq. (3), the objective J(Θ) is:    <ref type="bibr">, 2019)</ref>. The reported results for the above baselines are directly copied from the original published literature. Note that we instantiate the CASREL framework on top of a pre-trained BERT model to combine the power of the proposed novel tagging scheme and the pre-learned prior knowledge for better performance. To evaluate the impact of introducing the Transformer-based BERT model, we conduct a set of ablation tests. CASREL random is the framework where all parameters of BERT are randomly initialized; CASREL LST M is the framework instantiated on a LSTM-based structure as in <ref type="bibr">(Zheng et al., 2017)</ref> with pre-trained Glove embedding <ref type="bibr">(Pennington et al., 2014)</ref>; CASREL is the full-fledged framework using pre-trained BERT weights. <ref type="table" target="#tab_2">Table 2</ref> shows the results of different baselines for relational triple extraction on two datasets. The CASREL model overwhelmingly outperforms all the baselines in terms of all three evaluation metrics and achieves encouraging 17.5% and 30.2% improvements in F1-score over the best state-of-the-art method (Zeng et al., 2019) on NYT and WebNLG datasets respectively. Even without taking advantage of the pre-trained BERT, CAS-REL random and CASREL LST M are still competitive to existing state-of-the-art models. This validates the utility of the proposed cascade decoder that adopts a novel binary tagging scheme. The performance improvements from CASREL random to CASREL highlight the importance of the prior knowledge in a pre-trained language model. We can also observe from the table that there is a significant gap between the performance on NYT and WebNLG datasets for existing models, and we believe this gap is due to their drawbacks in dealing with overlapping triples. More precisely, as presented in <ref type="table" target="#tab_1">Table 1</ref>, we can find that NYT dataset is mainly comprised of Normal class sentences while the majority of sentences in WebNLG dataset belong to EPO and SEO classes. Such inconsistent data distribution of two datasets leads to a comparatively better performance on NYT and a worse performance on WebNLG for all the baselines, exposing their drawbacks in extracting overlapping relational triples. In contrast, the CASREL model and its variants (i.e., CASREL random and CAS-REL LST M ) all achieve a stable and competitive performance on both NYT and WebNLG datasets, demonstrating the effectiveness of the proposed framework in solving the overlapping problem.</p><formula xml:id="formula_7">|D| j=1   s∈T j log p θ (s|x j ) + r∈T j |s log p φr (o|s, x j ) + r∈R\T j |s log p φr (o ∅ |s, x j )   .<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Results</head><p>Detailed Results on Different Types of Sentences To further study the capability of the proposed CASREL framework in extracting overlapping relational triples, we conduct two extended experiments on different types of sentences and compare the performance with previous works.</p><p>The detailed results on three different overlapping patterns are presented in <ref type="figure">Figure 3</ref>. It can be seen that the performance of most baselines on Normal, EPO and SEO presents a decreasing trend, reflecting the increasing difficulty of extracting relational triples from sentences with different overlapping patterns. That is, among the three overlapping patterns, Normal class is the easiest pattern while EPO and SEO classes are the relatively harder ones for baseline models to extract. In contrast, the proposed CASREL model attains consistently strong performance over all three overlapping patterns, es-  pecially for those hard patterns. We also validate the CASREL's capability in extracting relational triples from sentences with different number of triples. We split the sentences into five classes and <ref type="table" target="#tab_4">Table 3</ref> shows the results. Again, the CASREL model achieves excellent performance over all five classes. Though it's not surprising to find that the performance of most baselines decreases with the increasing number of relational triples that a sentence contains, some patterns still can be observed from the performance changes of different models. Compared to previous works that devote to solving the overlapping problem in relational triple extraction, our model suffers the least from the increasing complexity of the input sentence. Though the CAS-REL model gain considerable improvements on all five classes compared to the best state-of-the-art method CopyR RL <ref type="figure" target="#fig_0">(Zeng et al., 2019)</ref>, the greatest improvement of F1-score on the two datasets both come from the most difficult class (N≥5), indicating that our model is more suitable for complicated scenarios than the baselines.</p><p>Both of these experiments validate the superiority of the proposed cascade binary tagging framework in extracting multiple (possibly overlapping) relational triples from complicated sentences compared to existing methods. Previous works have to explicitly predict all possible relation types con-tained in a given sentence, which is quite a challenging task, and thus many relations are missing in their extracted results. In contrast, our CASREL model side-steps the prediction of relation types and tends to extract as many relational triples as possible from a given sentence. We attribute this to the relation-specific object tagger setting in high level tagging module of the cascade decoder that considers all the relation types simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we introduce a novel cascade binary tagging framework (CASREL) derived from a principled problem formulation for relational triple extraction. Instead of modeling relations as discrete labels of entity pairs, we model the relations as functions that map subjects to objects, which provides a fresh perspective to revisit the relational triple extraction task. As a consequent, our model can simultaneously extract multiple relational triples from sentences, without suffering from the overlapping problem. We conduct extensive experiments on two widely used datasets to validate the effectiveness of the proposed CASREL framework. Experimental results show that our model overwhelmingly outperforms state-of-theart baselines over different scenarios, especially on the extraction of overlapping relational triples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Error Analysis</head><p>To explore the factors that affect the extracted relational triples of the CASREL model, we analyze the performance on predicting different elements of the triple (E1, R, E2) where E1 represents the subject entity, E2 represents the object entity and R represents the relation between them. An element like (E1, R) is regarded as correct only if the subject and the relation in the predicted triple (E1, R, E2) are both correct, regardless of the correctness of the predicted object. Similarly, we say an instance of E1 is correct as long as the subject in the extracted triple is correct, so is E2 and R. <ref type="table" target="#tab_7">Table 4</ref> shows the results on different relational triple elements. For NYT, the performance on E1 and E2 are consistent with that on (E1, R) and (R, E2), demonstrating the effectiveness of our proposed framework in identifying both subject and object entity mentions. We also find that there is only a trivial gap between the F1-score on (E1, E2) and (E1, R, E2), but an obvious gap between (E1, R, E2) and (E1, R)/(R, E2). It reveals that most relations for the entity pairs in extracted triples are correctly identified while some extracted entities  fail to form a valid relational triple. In other words, it implies that identifying relations is somehow easier than identifying entities for our model. In contrast to NYT, for WebNLG, the performance gap between (E1, E2) and (E1, R, E2) is comparatively larger than that between (E1, R, E2) and (E1, R)/(R, E2). It shows that misidentifying the relations will bring more performance degradation than misidentifying the entities. Such observation also indicates that it's more challenging for the proposed CASREL model to identify the relations than entities in WebNLG, as opposed to what we observed in NYT. We attribute such difference to the different number of relations contained in the two datasets (i.e., 24 in NYT and 246 in WebNLG), which makes the identification of relation much harder in WebNLG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Supplemental Experiments</head><p>In addition to validating the effectiveness of the proposed CASREL framework in handling the overlapping triple problem, we also conduct a set of supplemental experiments to show the generalization capability in more general cases on four widely used datasets, namely, ACE04, NYT10-HRL, NYT11-HRL and Wiki-KBP. Unlike the datasets we adopt in the main experiment, most test sentences in these datasets belong to the Normal class where no triples overlap with each other. <ref type="table" target="#tab_9">Table 5</ref> shows the result of a comprehensive comparison with recent stateof-the-art methods.</p><p>Notably, there are two different evaluation metrics selectively adopted among previous works:</p><p>(1) The widely used one is Partial Match as we described in Section 4.1, i.e., an extracted relational triple (subject, relation, object) is regarded as correct only if the relation and the heads of both subject and object are all correct <ref type="bibr">(Li and Ji, 2014;</ref><ref type="bibr">Miwa and Bansal, 2016;</ref><ref type="bibr">Katiyar and Cardie, 2017;</ref><ref type="bibr">Zheng et al., 2017;</ref><ref type="bibr">Zeng et al., 2018;</ref><ref type="bibr">Takanobu</ref>    <ref type="bibr">, 2019;</ref><ref type="bibr">Li et al., 2019;</ref><ref type="bibr">Fu et al., 2019)</ref>; <ref type="formula">(2)</ref> The stricter but less popular one is Exact Match adopted by <ref type="bibr">Dai et al. (2019)</ref>, where an extracted relational triple (subject, relation, object) is regarded as correct only if the relation and the heads and tails of both subject and object are all correct.</p><p>Since some works like <ref type="bibr">(Zeng et al., 2018)</ref> can't handle multi-word entities and can only be evaluated under the Partial Match metric and some works like <ref type="bibr">(Dai et al., 2019)</ref> are not open-source, it's hard to use a unified metric to compare our model with existing models. To properly compare our model with various baselines, we adopt the Partial Match metric for ACE04, NYT10-HRL and NYT11-HRL, and adopt the Exact Match metric for Wiki-KBP.</p><p>ACE04 We follow the same 5-fold crossvalidation setting as adopted in previous works <ref type="bibr">(Li and Ji, 2014;</ref><ref type="bibr">Miwa and Bansal, 2016;</ref><ref type="bibr">Li et al., 2019)</ref> and use the code 6 released by <ref type="bibr">(Miwa and Bansal, 2016)</ref> to preprocess the raw XML-style data for fair comparison. Eventually, it has 2,171 valid sentences in total and each sentence contains at least one relational triple.</p><p>NYT10-HRL &amp; NYT11-HRL NYT corpus has two versions: (1) the original version of which both the training set and test set are produced via distant supervision by <ref type="bibr">Riedel et al. (2010)</ref> and (2) a smaller version with fewer relation types, where the training set is produced by distant supervision while the test set is manually annotated by Hoffmann et al. <ref type="bibr">(2011)</ref>. Here we denote the original one and the smaller one as NYT10 and NYT11, respectively. 6 https://github.com/tticoin/LSTM-ER These two versions have been selectively adopted and preprocessed in many different ways among various previous works, which may be confusing sometimes and lead to incomparable results if not specifying the version. To fairly compare these models, HRL (Takanobu et al., 2019) adopted a unified preprocessing for both NYT10 and NYT11, and provided a comprehensive comparison with previous works using the same datasets. Here we denote the preprocessed two versions as NYT10-HRL and NYT11-HRL.</p><p>For fair comparison, we use the preprocessed datasets released by <ref type="bibr">Takanobu et al. (2019)</ref>, where NYT10-HRL contains 70,339 sentences for training and 4,006 sentences for test and NYT11-HRL contains 62,648 sentences for training and 369 sentences for test. We also create a validation set by randomly sampling 0.5% data from the training set for each dataset as in <ref type="bibr">(Takanobu et al., 2019)</ref>.</p><p>Wiki-KBP We use the same version as Dai et al.</p><p>(2019) adopted, where the training set is from <ref type="bibr">(Liu et al., 2017)</ref> and the test set is from <ref type="bibr">(Ren et al., 2017)</ref>. It has 79,934 sentences for training and 289 sentences for test. We also create a validation set by randomly sampling 10% data from the test set as <ref type="bibr">Dai et al. (2019)</ref> suggested.</p><p>Dataset Study As stated beforehand, these datasets are not suitable for testing the overlapping problem. To further explain this argument, we analyze the datasets in detail and the statistics are shown in <ref type="table">Table 6</ref>. We find that the test data in these datasets suffer little from the so-called overlapping triple problem since the sentences contain few overlapping triples. Even worse, we also find that the</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Examples of Normal, EntityPairOverlap (EPO) and SingleEntityOverlap (SEO) overlapping patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>where parameters Θ = {θ, {φ r } r∈R }. p θ (s|x) is defined in Eq. (8) and p φr (o|s, x) is defined in Eq. (11). We train the model by maximizing J(Θ) through Adam stochastic gradient descent (Kingma and Ba, 2014) over shuffled mini-batches.</figDesc><table><row><cell>Category</cell><cell>NYT</cell><cell></cell><cell cols="2">WebNLG</cell></row><row><cell></cell><cell>Train</cell><cell>Test</cell><cell cols="2">Train Test</cell></row><row><cell>Normal</cell><cell cols="4">37013 3266 1596 246</cell></row><row><cell>EPO</cell><cell>9782</cell><cell>978</cell><cell>227</cell><cell>26</cell></row><row><cell>SEO</cell><cell cols="4">14735 1297 3406 457</cell></row><row><cell>ALL</cell><cell cols="4">56195 5000 5019 703</cell></row><row><cell>4 Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4.1 Experimental Setting</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Datasets and Evaluation Metrics We evaluate</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>the framework on two public datasets NYT (Riedel</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets. Note that a sentence can belong to both EPO class and SEO class.Fu et al., 2019), an extracted relational triple (subject, relation, object) is regarded as correct only if the relation and the heads of both subject and object are all correct. For fair comparison, we report the standard micro Precision (Prec.), Recall (Rec.) and F1-score as in line with baselines. Details The hyper-parameters are determined on the validation set. More implementation details are described in Appendix A.</figDesc><table><row><cell>et al., 2010) and WebNLG (Gardent et al., 2017).</cell></row><row><cell>NYT dataset was originally produced by distant</cell></row><row><cell>supervision method. It consists of 1.18M sentences</cell></row><row><cell>with 24 predefined relation types. WebNLG dataset</cell></row><row><cell>was originally created for Natural Language Gen-</cell></row><row><cell>eration (NLG) tasks and adapted by (Zeng et al.,</cell></row><row><cell>2018) for</cell></row></table><note>relational triple extraction task. It con- tains 246 predefined relation types. The sentences in both datasets commonly contain multiple rela- tional triples, thus NYT and WebNLG datasets suit very well to be the testbed for evaluating model on extracting overlapping relational triples 4 . We use the datasets released by (Zeng et al., 2018), in which NYT contains 56195 sentences for training, 5000 sentences for validation, and 5000 sentences for test, and WebNLG contains 5019 sentences for training, 500 sentences for validation and 703 sentences for test. According to different over- lapping patterns of relational triples, we split the sentences into three categories, namely, Normal, EntityPairOverlap (EPO) and SingleEntityOverlap (SEO) for detailed experiments on different types of overlapping relational triples. The statistics of the two datasets are described in Table 1. Following previous work (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results of different methods on NYT and WebNLG datasets. Our re-implementation is marked by *.</figDesc><table /><note>4.2 Experimental Result Compared Methods We compare our model with several strong state-of-the-art models, namely, NovelTagging (Zheng et al., 2017), CopyR (Zeng et al., 2018), GraphRel (Fu et al., 2019) and CopyR RL (Zeng et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>F1-score of extracting relational triples from sentences with different number (denoted as N) of triples.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Results on relational triple elements.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Relational triple extraction results of different methods under Partial Match and Exact Match metrics.</figDesc><table /><note>et al.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This paper uses boldface letters to denote vectors and matrices.3  We use WordPiece embeddings(Wu et al., 2016)  to represent words in vector space as inBERT (Devlin et al., 2019). Each word in the input sentence will be tokenized to finegrained tokens, i.e., sub-words.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Datasets such as ACE, Wiki-KBP have few overlapping triples in the sentences hence are not suitable for evaluating the performance of overlapping triple extraction. Nonetheless, to validate the generality of the proposed framework, we also conduct supplemental experiments on these datasets along with the comparison of 12 recent strong baselines. The results of the comprehensive comparison, which show consistent superiority of our model over most compared methods, can be found in Appendix C.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous referees for their valuable comments. This work is supported by the National Natural Science Foundation of China (No.61976102, No.U19A2065).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Implementation Details</head><p>We adopt mini-batch mechanism to train our model with batch size as 6; the learning rate is set to 1e −5 ; the hyper-parameters are determined on the validation set. We also adopt early stopping mechanism to prevent the model from over-fitting. Specifically, we stop the training process when the performance on validation set does not gain any improvement for at least 7 consecutive epochs. The number of stacked bidirectional Transformer blocks N is 12 and the size of hidden state h N is 768. The pre-trained BERT model we used is [BERT-Base, Cased] 5 ,which contains 110M parameters.</p><p>For fair comparison, the max length of input sentence to our model is set to 100 words as previous works <ref type="bibr">(Zeng et al., 2018;</ref><ref type="bibr">Fu et al., 2019)</ref> suggest. We did not tune the threshold for both start and end position taggers to predict tag 1, but heuristically set the threshold to 0.5 as default. The performance might be better after carefully tuning the threshold, however it is beyond the research scope of this paper.  However, the output of our model has three triples:</p><p>{(Paris, /location/administrative division/country, France), (France, /location/country/administrative divisions, Paris), (France, /location/location/contains, Paris)}. The last two triples should have been annotated in the sentence but were omitted, which will significantly affect the values of both precision and recall when quantifying the performance of our model. This observation demonstrates that our CASREL model could extract more relational triples than the manually annotated ones in some cases due to the imperfect annotation. For this reason, the performance on such dataset like NYT11-HRL can only partially reflect the potential of the proposed model and probably underestimate the real value. Nonetheless, the CASREL model still achieves a competitive performance, showing the effectiveness of the proposed novel cascade binary tagging framework in relational triple extraction.</p><p>We also note that there is a significant gap (from 53.9 to 89.6 in terms of F1-score) between the performance on NYT11-HRL that preprocessed by is that the manually annotated data contains few overlapping triples and thus not suitable for testing the overlapping triple problem; <ref type="bibr">Second, Zeng et al. (2018)</ref> only annotated the last word of an entity in both training and test sets because their model can not handle multi-word entities. Hence, any entity in their dataset is taken as a single-word entity, leading to that the Partial Match and Exact Match evaluation metrics make no difference. Moreover, such setting makes it much easier for our CASREL model to detect the span of an entity since the start and end positions are actually the same. We attribute the significant gap to these different settings between the above two versions. Noticeably, multiword entities are common in real-world scenarios, so evaluating on a more proper dataset like NYT10-HRL (which also contains overlapping triples in test set) may better reveal the model's real value in relational triple extraction than on the ad-hoc one.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International The Semantic Web and 2nd Asian Conference on Asian Semantic Web Conference</title>
		<meeting>the 6th International The Semantic Web and 2nd Asian Conference on Asian Semantic Web Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
