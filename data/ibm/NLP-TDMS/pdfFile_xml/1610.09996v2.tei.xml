<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yu</surname></persName>
							<email>yu@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Watson</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
							<email>zhangwei@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Watson</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazi</forename><surname>Hasan</surname></persName>
							<email>kshasan@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Watson</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Watson</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Watson</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
							<email>zhou@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM Watson</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes dynamic chunk reader (DCR), an end-toend neural reading comprehension (RC) model that is able to extract and rank a set of answer candidates from a given document to answer questions. DCR is able to predict answers of variable lengths, whereas previous neural RC models primarily focused on predicting single tokens or entities. DCR encodes a document and an input question with recurrent neural networks, and then applies a word-by-word attention mechanism to acquire question-aware representations for the document, followed by the generation of chunk representations and a ranking module to propose the top-ranked chunk as the answer. Experimental results show that DCR achieves stateof-the-art exact match and F1 scores on the SQuAD dataset <ref type="bibr" target="#b19">(Rajpurkar et al. 2016</ref>).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Reading comprehension-based question answering (RCQA) is the task of answering a question with a chunk of text taken from related document(s). A variety of neural models have been proposed recently either for extracting a single entity or a single token as an answer from a given text (Hermann et al. <ref type="bibr">2015</ref>  <ref type="bibr" target="#b5">Cui et al. 2016a)</ref>; or for selecting the correct answer by ranking a small set of human-provided candidates <ref type="bibr" target="#b31">(Yin, Ebert, and Schütze 2016;</ref><ref type="bibr" target="#b25">Trischler et al. 2016a)</ref>. In both cases, an answer boundary is either easy to determine or already given. Different from the above two assumptions for RCQA, in the real-world QA scenario, people may ask questions about both entities (factoid) and non-entities such as explanations and reasons (non-factoid) (see <ref type="table" target="#tab_1">Table 1</ref> for examples). In this regard, RCQA has the potential to complement other QA approaches that leverage structured data (e.g., knowledge bases) for both the above question types. This is because RCQA can exploit the textual evidences to ensure increased answer coverage, which is particularly helpful for non-factoid answers. However, it is also challenging for RCQA to identify answer in arbitrary position in the passage with arbitrary length, especially for nonfactoid answers which might be clauses or sentences. As a result, apart from a few exceptions <ref type="bibr" target="#b19">(Rajpurkar et al. 2016;</ref><ref type="bibr" target="#b28">Wang and Jiang 2016)</ref>, this research direction has not been fully explored yet.</p><p>Compared to the relatively easier RC task of predicting single tokens/entities 1 , predicting answers of arbitrary lengths and positions significantly increase the search space complexity: the number of possible candidates to consider is in the order of O(n 2 ), where n is the number of passage words. In contrast, for previous works in which answers are single tokens/entities or from candidate lists, the complexity is in O(n) or the size of candidate lists l (usually l ≤5), respectively. To address the above complexity, Rajpurkar et al. <ref type="bibr">(2016)</ref> used a two-step chunk-and-rank approach that employs a rule-based algorithm to extract answer candidates from a passage, followed by a ranking approach with hand-crafted features to select the best answer. The rule-based chunking approach suffered from low coverage (≈ 70% recall of answer chunks) that cannot be improved during training; and candidate ranking performance depends greatly on the quality of the hand-crafted features. More recently, <ref type="bibr" target="#b28">Wang and Jiang (2016)</ref> proposed two endto-end neural network models, one of which chunks a candidate answer by predicting the answer's two boundary indices and the other classifies each passage word into answer/notanswer. Both models improved significantly over the method proposed by Rajpurkar et al. <ref type="bibr">(2016)</ref>.</p><p>Our proposed model, called dynamic chunk reader (DCR), not only significantly differs from both the above systems in the way that answer candidates are generated and ranked, but also shares merits with both works. First, our model uses deep networks to learn better representations for candidate answer chunks, instead of using fixed feature representations as in <ref type="bibr" target="#b19">(Rajpurkar et al. 2016)</ref>. Second, it represents answer candidates as chunks, as in (Rajpurkar et al. <ref type="bibr">2016</ref>), instead of word-level representations <ref type="bibr" target="#b28">(Wang and Jiang 2016)</ref>, to make the model aware of the subtle differences among candidates (importantly, overlapping candidates).</p><p>The contributions of this paper are three-fold. (1) We pro- (2) we propose a new question-attention mechanism to enhance passage word representation, which is subsequently used to construct chunk representations.</p><p>(3) We also propose several simple but effective features to strengthen the attention mechanism, which fundamentally improves candidate ranking, with the by-product of higher exact boundary match accuracy. The experiments on the Stanford Question Answering Dataset (SQuAD) <ref type="bibr" target="#b19">(Rajpurkar et al. 2016)</ref>, which contains a variety of human-generated factoid and non-factoid questions, have shown the effectiveness of above three contributions. Our paper is organized as follows. We formally define the RCQA problem first. Next, we describe our baseline with a neural network component. We present the end-to-end dynamic chunk reader model next. Finally, we analyze our experimental results and discuss the related work. <ref type="table" target="#tab_1">Table 1</ref> shows an example of our RC setting where the goal is to answer a question Q i , factoid (Q1) or non-factoid (Q2 and Q3), based on a supporting passage P i , by selecting a continuous sequence of text A i ⊆ P i as answer. Q i , P i , and A i are all word sequences, where each word is drawn from a vocabulary, V . The i-th instance in the training set is a triple in the form of (P i , Q i , A i ), where P i = (p i1 , . . . , p i|Pi| ), Q i = (q i1 , . . . , q i|Qi| ), and A i = (a i1 , . . . , a i|Ai| ) (p i· , q i· , a i· ∈ V ). Owing to the disagreement among annotators, there could be more than one correct answer for the same question; and the k-th answer to Q i is denoted by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Definition</head><formula xml:id="formula_0">A k i = {a k i1 , . . . , a k i|A k i | }.</formula><p>An answer candidate for the i-th training example is defined as c m,n i , a sub-sequence in P i , that spans from position m to n (1 ≤ m ≤ n ≤ |P i |). The ground truth answer A i could be included in the set of all candidates C i = {c m,n i |∀m, n ∈ N + , subj(m, n, P i ) and 1 ≤ m ≤ n ≤ |P i |}, where subj(m, n, P i ) is the constraint put on the candidate chunk for P i , such as, "c m,n i can have at most 10 tokens", or "c m,n i must have a pre-defined POS pattern". To evaluate a system's performance, its top answer to a question is matched against the corresponding gold standard answer(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark: Categories of RC Tasks</head><p>Other simpler variants of the aforementioned RC task were explored in the past. For example, quiz-style datasets (e.g., MCTest (Richardson, Burges, and Renshaw 2013), MovieQA <ref type="bibr" target="#b24">(Tapaswi et al. 2015)</ref>) have multiple-choice questions with answer options. Cloze-style datesets <ref type="bibr" target="#b12">Hill et al. 2015;</ref><ref type="bibr" target="#b17">Onishi et al. 2016)</ref>, usually automatically generated, have factoid "question"s created by replacing the answer in a sentence from the text with blank. For the answer selection task this paper focuses on, several datasets exist, e.g. TREC-QA for factoid answer extraction from multiple given passages, bAbI (Weston, Chopra, and Bordes 2014) designed for inference purpose, and the SQuAD dataset <ref type="bibr" target="#b19">(Rajpurkar et al. 2016)</ref> used in this paper. To the best of our knowledge, the SQuAD dataset is the only one for both factoid and nonfactoid answer extraction with a question distribution more close to real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline: Chunk-and-Rank Pipeline with</head><p>Neural RC</p><p>In this section we modified a state-of-the-art RC system for cloze-style tasks for our answer extraction purpose, to see how much gap we have for the two type of tasks, and to inspire our end-to-end system in the next section. In order to make the cloze-style RC system to make chunk-level decision, we use the RC model to generate features for chunks, which are further used in a feature-based ranker like in (Rajpurkar et al. <ref type="bibr">2016</ref>). As a result, this baseline can be viewed as a deep learning based counterpart of the system in (Rajpurkar et al. <ref type="bibr">2016</ref>). It has two main components: 1) a standalone answer chunker, which is trained to produce overlapping candidate chunks, and 2) a neural RC model, which is used to score each word in a given passage to be used thereafter for generating chunk scores. Answer Chunking To reduce the errors generated by the rule-based chunker in <ref type="bibr" target="#b19">(Rajpurkar et al. 2016)</ref>, first, we capture the part-of-speech (POS) pattern of all answer subsequences in the training dataset to form a POS pattern trie tree, and then apply the answer POS patterns to passage P i to acquire a collection of all subsequences (chunk candidates) C i whose POS patterns can be matched to the POS pattern trie. This is equivalent to putting an constraint subj(m, n, P i ) to candidate answer chunk generation process that only choose the chunk with a POS pattern seen for answers in the training data. Then the sub-sequences C i are used as answer candidates for P i . Note that overlapping chunks could be generated for a passage, and we rely on the ranker to choose the best candidate based on features from the cloze-style RC system. Experiments showed that for &gt; 90% of the questions on the development set, the ground truth answer is included in the candidate set constructed in such manner. Feature Extraction and Ranking For chunk ranking, we (1) use neural RCQA model to annotate each p ij in passage P i to get score s ij , then (2) for every chunk c m,n i in passage i, collect scores (s im , . . . , s in ) for all the (p im , ..., p in ) contained within c m,n i , and (3) extract features on the sequence of scores (s im , . . . , s in ) to characterize its scale and distribution information, which serves as the feature representation of c m,n i . In step (1) to acquire s ij we train and apply a word-level single-layer Gated Attention Reader 2 (Dhingra et al. <ref type="bibr">2016</ref>), which has state-of-the-art performance on CNN/DailyMail cloze-style RC task. In step (3) for chunk c m,n i , we designed 5 features, including 4 statistics on (s im , . . . , s in ): maximum, minimum, average and sum; as well as the count of matched POS pattern within the chunk, which serves as an answer prior. We use these 5 features in a state-of-the-art ranker (Ganjisaffar, Caruana, and Lopes 2011).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamic Chunk Reader</head><p>The dynamic chunk reader (DCR) model is presented in <ref type="figure" target="#fig_0">Figure 1</ref>. Inspired by the baseline we built, DCR is deemed to be superior to the baseline for 3 reasons. First, each chunk has a representation constructed dynamically, instead of having a set of pre-defined feature values. Second, each passage word's representation is enhanced by word-by-word attention that evaluates the relevance of the passage word to the question. Third, these components are all within a single, end-to-end model that can be trained in a joint manner. DCR works in four steps. First, the encoder layer encodes passage and question separately, by using bidirectional recurrent neural networks (RNN). Second, the attention layer calculates the relevance of each passage word to the question. Third, the chunk representation layer dynamically extracts the candidate chunks from the given passage, and create chunk representation that encodes the contextual information of each chunk. Fourth, the ranker layer scores the relevance between the representations of a chunk and the given question, and ranks all candidate chunks using a softmax layer. We describe each step in details below. Encoder Layer We use bi-directional RNN encoder to encode P i and Q i of example i, and get hidden state for each word position p ij and q ik . 3 As RNN input, a word is represented by a row vector x ∈ R n . x can be the concatenation of word embedding and word features (see <ref type="figure" target="#fig_0">Fig.  1</ref>). The word vector for the t-th word is x t . A word sequence is processed using an RNN encoder with gated recurrent units (GRU) <ref type="bibr" target="#b2">(Bengio, Goodfellow, and Courville 2015)</ref>, which was proved to be effective in RC and neural machine translation tasks (Bahdanau, Cho, and <ref type="bibr" target="#b13">Kadlec et al. 2016;</ref><ref type="bibr" target="#b7">Dhingra et al. 2016)</ref>. For each position t, GRU computes h t with input x t and previous state h t−1 , as:</p><formula xml:id="formula_1">r t = σ(W r x t + U r h t−1 ) (1) u t = σ(W u x t + U u h t−1 ) (2) h t = tanh(W x t + U (r t h t−1 )) (3) h t = (1 − u t ) · h t−1 + u t ·h t</formula><p>(4) where h t , r t , and u t ∈ R d are d-dimensional hidden state, reset gate, and update gate, respectively; W {r,u} , W ∈ R n×d and U {r,u} , U ∈ R d×d are the parameters of the GRU; σ is the sigmoid function, and denotes elementwise production. For a word at t, we use the hidden state − → h t from the forward RNN as a representation of the preceding context, and the ← − h t from a backward RNN that encodes text reversely, to incorporate the context after t. Next,</p><formula xml:id="formula_2">h t = [ − → h t ; ← − h t ]</formula><p>, the bi-directional contextual encoding of x t , is formed. [·; ·] is the concatenation operator. To distinguish hidden states from different sources, we denote the h j of jth word in P and the h k of k-th word in Q as h p j and h q k respectively. Attention Layer Attention mechanism in previous RC tasks </p><formula xml:id="formula_3">α jk = h p j · h q k ,<label>(5)</label></formula><formula xml:id="formula_4">β j = |Q| k=1 α jk h q k (6) v j = [h p j ; β j ]<label>(7)</label></formula><p>where h p j and h q k are hidden states from the bi-directional RNN encoders (see <ref type="figure" target="#fig_0">Figure 1</ref>). An inner product, α jk , is calculated between h p j and every question word h q k . It indicates how well the passage word p j matches with every question word q k . β j is a weighted pooling of |Q| question hidden states, which serves as a p j -aware question representation. The concatenation of h p j and β j leads to a passage-question joint representation, v j ∈ R 4d . 4 Next, we apply a second bi-GRU layer taking the v j s as inputs, and obtain forward and backward representations − → γ j and ← − γ j ∈ R d , and in turn their</p><formula xml:id="formula_5">concatenation, γ j = [ − → γ j ; ← − γ j ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chunk Representation</head><p>Layer A candidate answer chunk representation is dynamically created given attention layer output. We first decide the text boundary for the candidate chunk, and then form a chunk representation using all or part of those γ j outputs inside the chunk. To decide a candidate chunk (boundary): we tried two ways: (1) adopt the POS trie-based approach used in our baseline, and (2) enumerate all possible chunks up to a maximum number of tokens. For (2), we create up to N (max chunk length) chunks starting from any position j in P j . Approach (1) can generate candidates with arbitrary lengths, but fails to recall candidates whose POS pattern is unseen in training set; whereas approach (2) considers all possible candidates within a window and is more flexible, but over-generates invalid candidates.</p><p>For a candidate answer chunk c m,n spanning from position m to n inclusively, we construct chunk representation γ m,n ∈ R 2d using every γ j within range [m, n], with a function g(·). Formally, γ m,n = g(γ m , . . . , γ n ) We experimented with several pooling functions (e.g., max, average) for g(·), and found out that, instead of pooling, the best function is to concatenate the hidden state of the first word in a chunk in forward RNN and that of the last word in backward RNN. Formally, γ m,n = g(γ m , . . . , γ n ) = [ − → γ m ; ← − γ n ] (8) We hypothesize that the hidden states at that two ends can better represent the chunk's contexts, which is critical for this task, than the states within the chunk. This observation also agrees with <ref type="bibr" target="#b15">(Kobayashi et al. 2016)</ref>. Ranker Layer Each chunk c m,n is evaluated on its context similarity to the question, by taking the cosine similarity between the chunk context representationγ m,n acquired from chunk representation layer, and the question representation which is the concatenation of the last hidden state in forward RNN and the first hidden state in backward RNN. Thus, for training example i, we have the probability of the chunk c m,n i as</p><formula xml:id="formula_6">P(c m,n i |P i , Q i ) = sof tmax(γ i m,n · [ −−→ h Qi |Qi| ; ← − − h Qi 1 ])<label>(9)</label></formula><p>, − − → h Qi k or ← − − h Qi k is the k-th hidden state output from question Q i 's forward and backward RNN encoder, respectively. In runtime, the chunk with the highest probability is taken as the answer. In training, the following negative log likelihood is minimized:</p><formula xml:id="formula_7">L = − N i=1 log P(A i |P i , Q i )<label>(10)</label></formula><p>Note that the i-th training instance is only used when A i is included in the corresponding candidate chunk set C i , i.e. ∃ m,n A i = c m,n i . The softmax in the final layer serves as the list-wise ranking module similar in spirit to <ref type="bibr" target="#b3">(Cao et al. 2007</ref>). (4) if the lemma form of w is the same to any word in the question; and (5) if w is caplitalized. Feature (3) and (4) are designed to help the model align the passage text with question. Note that some types of questions (e.g., "who", "when" questions) have answers that have a specific POS/NE tag pattern. For instance, "who" questions mostly have proper nouns/persons as answers and "when" questions may frequently have numbers/dates (e.g., a year) as answers. Thus, we believe that the model could exploit the co-relation between question types and answer POS/NE patterns easier with POS and NE tag features. Implementation Details We pre-processed the SQuAD dataset using Stanford CoreNLP tool 5  with its default setting to tokenize the text and obtain the POS and NE annotations. To train our model, we used stochastic gradient descent with the ADAM optimizer (Kingma and Ba 2014), with an initial learning rate of 0.001. All GRU weights were initialized from a uniform distribution between (-0.01, 0.01). The hidden state size, d, was set to 300 for all GRUs. The question bi-GRU shared parameters with the passage bi-GRU, while the attention-based passage bi-GRU had its own parameters. We shuffled all training examples at the beginning of each epoch and adopted a   <ref type="bibr" target="#b1">2009</ref>), by sorting training instances by length in every 10 batches, to enable the model start learning from relatively easier instances and to harder ones. We also applied dropout of rate 0.2 to the embedding layer of input bi-GRU encoder, and gradient clipping when the norm of gradients exceeded 10. We trained in mini-batch style (mini-batch size is 180) and applied zero-padding to the passage and question inputs in each batch. We also set the maximum passage length to be 300 tokens, and pruned all the tokens after the 300-th token in the training set to save memory and speed up the training process. This step reduced the training set size by about 1.6%. During test, we test on the full length of passage, so that we don't prune out the potential candidates. We trained the model for at most 30 epochs, and in case the accuracy did not improve for 10 epochs, we stopped training. For the feature ranking-based system, we used jforest ranker (Ganjisaffar, Caruana, and Lopes 2011) with LambdaMART-RegressionTree algorithm and the ranking metric was NDCG@10. For the Gated Attention Reader in baseline system, we replicated the method and use the same configurations as in <ref type="bibr" target="#b7">(Dhingra et al. 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Results <ref type="table" target="#tab_2">Table 2</ref> shows our main results on the SQuAD dataset. Compared to the scores reported in (Wang and Jiang 2016), our exact match (EM) and F1 on the development set and EM score on the test set are better, and F1 on the test set is comparable. We also studied how each component in our model contributes to the overall performance. <ref type="table" target="#tab_3">Table 3</ref> shows the details as well as the results of the baseline ranker. As the first row of <ref type="table" target="#tab_3">Table 3</ref> shows, our baseline system improves 10% (EM) over <ref type="bibr" target="#b19">Rajpurkar et al. (2016)</ref>  <ref type="table" target="#tab_2">(Table 2</ref>, row 1), the feature-based ranking system. However when compared to our DCR model <ref type="table" target="#tab_3">(Table 3</ref>, row 2), the baseline (row 1) is more than 12% (EM) behind even though it is based on the state-of-the-art model for cloze-style RC tasks. This can be attributed to the advanced model structure and end-to-end manner of DCR.</p><p>We also did ablation tests on our DCR model. First, replacing the word-by-word attention with Attentive Reader style attention  decreases the EM score by about 4.5%, showing the strength of our proposed attention mechanism. Second, we remove the features in input to see the contribution of each feature. The result shows that POS feature (1) and question-word feature (3) are the two most important features. Finally, combining the DCR model with the proposed POS-trie constraints yields a score similar to the one obtained using the DCR model with all possible n-gram chunks. The result shows that (1) our chunk representations are powerful enough to differentiate even a huge amount of chunks when no constraints are applied; and (2) the proposed POS-trie reduces the search space at the cost of a small drop in performance. Analysis To better understand our system, we calculated the accuracy of the attention mechanism of the gated attention reader used in our deep learning-based baseline. We found that it is 72% accurate i.e., 72% of the times a word with the highest attention score is inside the correct answer span. This means that, if we could accurately detect the boundary around the word with the highest attention score to form the answer span, we could achieve an accuracy close to 72%. In addition, we checked the answer recall of our candidate chunking approach. When we use a window size of 10, 92% of the time, the ground truth answer will be included in the extracted Candidate chunk set. Thus the upper bound of the exact match score of our baseline system is around 66% (92% (the answer recall) × 72%). From the results, we see our DCR system's exact match score is at 62%. This shows that DCR is proficient at differentiating answer spans dynamically.</p><p>To further analyze the system's performance while predicting answers of different lengths, we show the exact match (EM) and F1 scores for answers with lengths up to 10 tokens in <ref type="figure" target="#fig_3">Figure 2(a)</ref>. From the graph, we can see that, with the increase of answer length, both EM and F1 drops, but in different speed. The gap between F1 and exact match also widens as answer length increases. However, the model still yields a decent accuracy when the answer is longer than a single word. Additionally, <ref type="figure" target="#fig_3">Figure 2(b)</ref> shows that the system is better at "when" and "who" questions, but performs poorly on "why" questions. The large gap between exact match and F1 on "why" questions means that perfectly identifying the span is harder than locating the core of the answer span.</p><p>Since "what", "which", and "how" questions contain a broad range of question types, we split them further based on the bigram a question starts with, and <ref type="figure" target="#fig_4">Figure 3</ref> shows the breakdown for "what" questions. We can see that "what" questions asking for explanations such as "what happens" and "what happened" have lower EM and F1 scores. In contrast, "what" questions asking for year and numbers have much higher scores and, for these questions, exact match scores are close to F1 scores, which means chunking for these questions are easier for DCR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Attentive Reader was the first neural model for factoid RCQA  Zaremba and Sutskever 2015) were also potential candidates for the task, and Gulcehre et al. <ref type="bibr">(2016)</ref> reported results on the bAbI task, which is worse than memory networks. Similarly, sequence-to-sequence models were also used <ref type="bibr" target="#b11">Hermann et al. 2015)</ref>, but they did not yield better results either.</p><p>Recently, several models have been proposed to enable more complex inference for RC task. For instance, gated attention model <ref type="bibr" target="#b7">(Dhingra et al. 2016</ref>) employs a multi-layer architecture, where each layer encodes the same document, but the attention is updated from layer to layer. EpiReader <ref type="bibr" target="#b26">(Trischler et al. 2016b</ref>) adopted a joint training model for answer extractor and reasoner, where the extractor proposes top candidates, and the reasoner weighs each candidate by examining entailment relationship between question-answer representation and the document. An iterative alternating attention mechanism and gating strategies were proposed in (Sordoni, Bachman, and  to optimize the attention through several hops. In contrast, <ref type="bibr" target="#b5">Cui et al. (2016a;</ref> introduced fine-grained document attention from each question word and then aggregated those attentions from each question token by summation with or without weights. This system achieved the state-of-the-art score on the CNN dataset. Those different variations all result in roughly 3-5% improvement over attention sum reader, but none of those could achieve higher than that. Other methods include using dynamic entity representation with maxpooling <ref type="bibr" target="#b15">(Kobayashi et al. 2016</ref>) that aims to change entity representation with context, and Weissenborn's (2016) system, which tries to separate entity from the context and then matches the question to context, scoring an accuracy around 70% on the CNN dataset.</p><p>However, all of those models assume that the answers are single tokens. This limits the type of questions the models can answer. <ref type="bibr" target="#b28">Wang and Jiang (2016)</ref> proposed a matchlstm and achieved good results on SQuAD. However, this approach predicts a chunk boundary or whether a word is part of a chunk or not. In contrast, our approach explicitly constructs the chunk representations and similar chunks are compared directly to determine correct answer boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper we proposed a novel neural reading comprehension model for question answering. Different from the previously proposed models for factoid RCQA, the proposed model, dynamic chunk reader, is not restricted to predicting a single named entity as an answer or selecting an answer from a small, pre-defined candidate list. Instead, it is capable of answering both factoid and non-factoid questions as it learns to select answer chunks that are suitable for an input question. DCR achieves this goal with a joint deep learning model enhanced with a novel attention mechanism and five simple yet effective features. Error analysis shows that the DCR model achieves good performance, but still needs to improve on predicting longer answers, which are usually non-factoid in nature.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The main components in dynamic chunk reader model (from bottom to top) are bi-GRU encoders for passage and question, a word-by-word attention bi-GRU for passage, dynamic chunk representations that are transformed from pooled dynamic chunks of hidden states, the question attention on every chunk representation and final answer chunk prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>Kadlec et al. 2016; Hermann et al. 2015; Sordoni, Bachman, and Bengio 2016; Dhingra et al. 2016; Cui et al. 2016a; Cui et al. 2016b) enables question-aware passage representations. We propose a novel attention mechanism inspired by word-by-word style attention methods (Rocktäschel et al. 2015; Wang and Jiang 2015; Santos et al. 2016). For each p j , a question-attended representation v j is computed as follows (example index i is omitted for simplicity):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Dataset</head><label></label><figDesc>We used the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al. 2016) for the experiment. SQuAD came into our sight because it is a mix of factoid and non-factoid questions, a real-world data (crowd-sourced), and of large scale (over 100K question-answer pairs collected from 536 Wikipedia articles). Answers range from single words to long, variable-length phrase/clauses. It is a relaxation of assumptions by the cloze-style and quiz-style RC datasets in the Problem Definition section. Features The input vector representation of each word w to encoder RNNs has six parts including a pre-trained 300dimensional GloVe embedding (Pennington, Socher, and Manning 2014) and five features (see Figure 1): (1) a onehot encoding (46 dimensions) for the part-of-speech (POS) tag of w; (2) a one-hot encoding (14 dimensions) for named entity (NE) tag of w; (3) a binary value indicating whether w's surface form is the same to any word in the quesiton;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>(a) Variations of DCR performance on ground truth answer length (up to 10) in the development set. The curve with diamond knots also shows the percentage of answers for each length in the development set. (b) Performance comparisons for different question head word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Development set performance comparisons for different types of "what" questions (considering the types with more than 20 examples in the development set).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>;</head><label></label><figDesc>Kadlec et al. 2016; Trischler et al. 2016b; Dhingra et al. 2016; Chen, Bolton, and Manning 2016; Sordoni, Bachman, and</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Example of questions (with answers) which can be potentially answered with RC on a Wikipedia passage. The first question is factoid, asking for an entity. The second and third are non-factoid.The United Kingdom (UK) intends to withdraw from the European Union (EU), a process commonly known as Brexit, as a result of a June 2016 referendum in which 51.9% voted to leave the EU. The separation process is complex, causing political and economic changes for the UK and other countries. As of September 2016, neither the timetable nor the terms for withdrawal have been established: in the meantime, the UK remains a full member of the European Union.</figDesc><table><row><cell>The term</cell></row></table><note>pose a novel neural network model for joint candidate an- swer chunking and ranking, where the candidate answer chunks are dynamically constructed and ranked in an end- to-end manner.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on the SQuAD dataset. 8% 51.0% 40.4% 51.0% Wang 2016 59.1% 70.0% 59.5% 70.3% DCR 62.5% 71.2% 62.5% 71.0%</figDesc><table><row><cell></cell><cell>Dev</cell><cell></cell><cell>Test</cell><cell></cell></row><row><cell>Models</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell cols="2">Rajpurkar 2016 39.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Detailed system experiments on the SQuAD development set.</figDesc><table><row><cell>Models</cell><cell>EM</cell><cell>F1</cell></row><row><cell>Chunk-and-Rank Pipeline Baseline</cell><cell cols="2">49.7% 64.9%</cell></row><row><cell>DCR</cell><cell cols="2">62.0% 71.2%</cell></row><row><cell>DCR w/o Word-by-Word Attention</cell><cell cols="2">57.6% 68.7%</cell></row><row><cell>DCR w/o POS feature (1)</cell><cell cols="2">59.2% 68.8%</cell></row><row><cell>DCR w/o NE feature (2)</cell><cell cols="2">60.4% 70.2%</cell></row><row><cell>DCR w/o Question-word feature (3)</cell><cell cols="2">59.5% 69.0%</cell></row><row><cell cols="3">DCR w/o Question-lemma feature (4) 61.2% 69.9%</cell></row><row><cell>DCR w/o Capitalized feature (5)</cell><cell cols="2">61.5% 70.6%</cell></row><row><cell>DCR w POS-trie</cell><cell cols="2">62.1% 70.8%</cell></row></table><note>curriculum learning approach (Bengio et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>). It uses Bidirectional RNN (Cho et al., 2014; Chung et al.,2014) to encode document and query respectively, and use query representation to match with every token from the document. Attention Sum Reader (Kadlec et al. 2016) simplifies the model to just predicting positions of correct answer in the document and the training speed and test accuracy are both greatly improved on the CNN/Daily Mail dataset. (Chen, Bolton, and Manning 2016) also simplified Attentive Reader and reported higher accuracy. Window-based Memory Networks (MemN2N) is introduced along with the CBT dataset (Hill et al. 2015), which does not use RNN encoders, but embeds contexts as memory and matches questions with embedded contexts. Those models' mechanism is to learn the match between answer context with question/query representation. In contrast, memory enhanced neural networks like Neural Turing Machines (Graves, Wayne, and Danihelka 2014) and its variants (Zhang, Yu, and Zhou 2015; Gulcehre et al. 2016;</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">State-of-the-art RC models have a decent accuracy of ∼70% on the widely used CNN/DailyMail dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We tried using more than one layers in Gated Attention Reader, but no improvement was observed.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We can have separated parameters for question and passage encoders but a single shared encoder for both works better in the experiments.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We tried another word-by-word attention methods as in (Santos et al.2016), which has similar passage representation input to question side. However, this does not lead to improvement due to the confusion caused by long passages in RC. Consequently, we used the proposed simplified version of word-by-word attention on passage side only. whereγ i m,n denotes representation of the chunk c m,n i</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">stanfordnlp.github.io/CoreNLP/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep learning. An MIT Press book in preparation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://www.iro.umontreal.ca/ben-gioy/dlbook" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Draft chapters available at</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A thorough examination of the cnn/daily mail reading comprehension task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Attention-over-attention neural networks for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04423</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.02250</idno>
		<title level="m">Consensus attention-based neural networks for chinese reading comprehension</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Gated-attention readers for text comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01549</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Bagging gradient-boosted trees for high precision, low variance ranking models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganjisaffar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lopes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Dynamic neural turing machine with soft and hard addressing schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.00036</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The goldilocks principle: Reading children&apos;s books with explicit memory representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02301</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Text understanding with the attention sum reader network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bajgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleindienst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Dynamic entity representations with max-pooling improves machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NAACL-HLT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Who did What: A large-scale personcentered cloze dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Onishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kočiskỳ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.06664</idno>
		<title level="m">Reasoning about entailment with neural attention</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03609</idno>
		<title level="m">Attentive pooling networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Iterative alternating neural attention for machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02245</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.02902</idno>
		<title level="m">Movieqa: Understanding stories in movies through question-answering</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A parallel-hierarchical model for machine comprehension on sparse data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08884</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02270</idno>
		<title level="m">Natural language comprehension with the epireader</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.08849</idno>
		<title level="m">Learning natural language inference with lstm</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Machine comprehension using match-lstm and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07905</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Separating answers from queries for neural reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.03316</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<idno>abs/1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Attentionbased convolutional neural network for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.04341</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.07526</idno>
		<title level="m">Empirical study on deep learning models for question answering</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00521362</idno>
		<title level="m">Reinforcement learning neural turing machines</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03931</idno>
		<title level="m">Structured memory for neural turing machines</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
