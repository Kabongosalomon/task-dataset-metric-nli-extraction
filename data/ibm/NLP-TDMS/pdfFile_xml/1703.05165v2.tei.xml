<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic skin lesion segmentation with fully convolutional-deconvolutional networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-09-28">28 Sep 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yading</forename><surname>Yuan</surname></persName>
							<email>yading.yuan@mssm.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiation Oncology Icahn School of Medicine at Mount Sinai New York</orgName>
								<address>
									<postCode>10029</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic skin lesion segmentation with fully convolutional-deconvolutional networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-09-28">28 Sep 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes our method and validation results for the ISBI Challenge 2017 -Skin Lesion Analysis Towards Melanoma Detection -Part 1: Lesion Segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MATERIALS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Database</head><p>We participated the part I of ISBI Challenge 2017 -Skin Lesion Analysis Towards Melanoma</p><p>The lesion types involved include nevus, seborrhoeic keratosis and malignant melanoma. The goal is to produce accurate binary masks of various skin lesions against a variety of background. Besides training set, the organizers provide a validation dataset that includes 150 images. The participants can submit the binary masks of these 150 images and evaluate the segmentation performance online.</p><p>Additional test dataset with 600 images is provided for final evaluation. The final rank is based on Jaccard index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Architecture</head><p>We train a CDNN to map from input dermoscopic image to a posterior probability map. The network contains 29 layers with about 5M trainable parameters. <ref type="table" target="#tab_0">Table I describes the architectural</ref> details. We fixed the stride as 1 and use Rectified Linear Units (ReLUs) as the activation function for each convolutional/deconvolutional layer. For output layer, we use sigmoid as the activation function. Pixel-wise classification is performed and CDNN is essentially served as a filter that projects the entire input image to a map where each element represents the probability that the corresponding input pixel belongs to the tumor. In order to address the conflict between multiscale information aggregation and full-resolution pixel-wise classification, we implement a strategy of using upsampling and deconvolutional layers to recover lost resolution while carrying over the global perspective from pooling layers <ref type="bibr" target="#b2">[3]</ref>. Batch normalization is added to the output of every convolutional/deconvolutional layer to reduce the internal covariate shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Pre-processing</head><p>A simple pre-processing is employed to facilitate the following learning procedure while preserving the original image information. Besides the original RGB channels, we also include the three channels in Hue-Saturation-Value color space, as well as the L channel (lightness) in CIELAB space. Each channel is rescaled to [0, 1]. By observing most of images in the training set have a height-to-width ratio of 3 : 4, we resize the images to 192 × 256.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Training</head><p>We train the network using Adam optimization <ref type="bibr" target="#b3">[4]</ref>with batch size of 16 to adjust the learning rate based on the first and the second-order moments of the gradient at each iteration. The initial learning rate is set as 0.003. In order to reduce overfitting, we use dropout with p = 0.5 before </p><formula xml:id="formula_0">conv-1-1 3 × 3 16 decv-1 3 × 3 256 conv-1-2 3 × 3 32 ups-1 2 × 2 256 pool-1 2 × 2 32 decv-2-1 3 × 3 256 conv-2-1 3 × 3 64 decv-2-2 3 × 3 128 conv-2-2 3 × 3 64 ups-2 2 × 2 128 pool-2 2 × 2 64 decv-3-1 4 × 4 128 conv-3-1 3 × 3 128 decv-3-2 3 × 3 128 conv-3-2 4 × 4 128 ups-3 2 × 2 128 pool-3 2 × 2 128 decv-4-1 3 × 3 64 conv-4-1 3 × 3 256 decv-4-2 3 × 3 32 conv-4-2 3 × 3 256 ups-4 2 × 2 32 pool-4 2 × 2 256 decv-5-1 3 × 3 16 conv-5 3 × 3 512 output 3 × 3 1</formula><p>conv-4-1 and decv-5-1 in <ref type="table" target="#tab_0">Table I,</ref>  We design a loss function based on Jaccard distance in this study:</p><formula xml:id="formula_1">L d J = 1 − i,j (t ij p ij ) i,j t 2 ij + i,j p 2 ij − i,j (t ij p ij ) ,<label>(1)</label></formula><p>where t ij and p ij are target and the output of pixel (i, j), respectively. As compared to conventionally used cross-entropy, the proposed loss function is directly related to image segmentation task because Jaccard index is a common metric to assess medical image segmentation accuracy, especially in this challenge. Meanwhile, this loss function is well adapted to the problems with high imbalance between foreground and background classes as it doesn't require any class re-balancing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Post-processing</head><p>We use a dual-thresholds method to generate a binary tumor mask from the CDNN output. A relatively high threshold (th H = 0.8) is firstly applied to determine the tumor center, which is calculated as the centroid of the region that has the largest mass among the candidates from thresholding. Then a lower threshold th L = 0.5 is applied to the output map. After filling small holes with morphological dilation, the final tumor mask is determined as the region that embraces the tumor center. Finally, a bagging-type ensemble strategy is implemented to combine outputs of 6 CDNNs to further improve the image segmentation performance on the testing images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation</head><p>Our method was implemented with Python based on Theano <ref type="bibr" target="#b4">[5]</ref> and Lasagne 1 . The experiments were conducted on a Dell XPS 8900 desktop with Intel (R) i7-6700 3.4 GHz GPU and a GPU of Nvidia GeForce GTX 1060 with 6GB GDDR5 memory. The total number of epochs was set as 500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULTS</head><p>Our method yielded an average Jaccard index of 0.784 on the online validation dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and employ two types of image augmentations to further improve the robustness of the proposed model under a wide variety of image acquisition conditions. One consists of a series of geometric transformations, including randomly flipping, shifting, rotating as well as scaling. The other type focuses on randomly normalizing the contrast of each channels in the training images. Note that these augmentations only require little extra computation, so the transformed images are generated from the original images for every mini-batch within each iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table I :</head><label>I</label><figDesc>Architectural details of the proposed CDNN model (Abbrevations: conv: convolutional layer; pool: max-pooling layer; decv: deconvolutional layer, ups: upsampling layer). Conv Filter size No. of features Deconv Filter size No. of features</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://github.com/Lasagne/Lasagne</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A state-of-the-art survey on lesion border detection in dermoscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Iyatomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schaefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dermoscopy Image Analysis</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR 2015</title>
		<meeting>CVPR 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV 2015</title>
		<meeting>ICCV 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Theano: A python framework for fast computation of mathematical expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Angermueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Belikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
