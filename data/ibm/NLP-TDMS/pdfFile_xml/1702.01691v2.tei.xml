<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CALIBRATING ENERGY-BASED GENERATIVE ADVER- SARIAL NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Maluuba Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CALIBRATING ENERGY-BASED GENERATIVE ADVER- SARIAL NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we propose equipping Generative Adversarial Networks with the ability to produce direct energy estimates for samples. Specifically, we develop a flexible adversarial training framework, and prove this framework not only ensures the generator converges to the true data distribution, but also enables the discriminator to retain the density information at the global optimum. We derive the analytic form of the induced solution, and analyze its properties. In order to make the proposed framework trainable in practice, we introduce two effective approximation techniques. Empirically, the experiment results closely match our theoretical analysis, verifying that the discriminator is able to recover the energy of data distribution.</p><p>Published as a conference paper at ICLR 2017 relationship to the specific form of the training objective. We also discuss the connection between the proposed formulation and existing alternatives such as the approach of <ref type="bibr" target="#b4">Kim &amp; Bengio (2016)</ref>. Finally, for a specific instantiation of the general formulation, we investigate two approximation techniques to optimize the training objective, and verify our results empirically.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Generative Adversarial Networks (GANs) <ref type="bibr" target="#b2">(Goodfellow et al., 2014)</ref> represent an important milestone on the path towards more effective generative models. GANs cast generative model training as a minimax game between a generative network (generator), which maps a random vector into the data space, and a discriminative network (discriminator), whose objective is to distinguish generated samples from real samples. Multiple researchers <ref type="bibr" target="#b7">Radford et al. (2015)</ref>; <ref type="bibr" target="#b8">Salimans et al. (2016)</ref>; <ref type="bibr" target="#b10">Zhao et al. (2016)</ref> have shown that the adversarial interaction with the discriminator can result in a generator that produces compelling samples. The empirical successes of the GAN framework were also supported by the theoretical analysis of <ref type="bibr">Goodfellow et al.,</ref> who showed that, under certain conditions, the distribution produced by the generator converges to the true data distribution, while the discriminator converges to a degenerate uniform solution.</p><p>While GANs have excelled as compelling sample generators, their use as general purpose probabilistic generative models has been limited by the difficulty in using them to provide density estimates or even unnormalized energy values for sample evaluation.</p><p>It is tempting to consider the GAN discriminator as a candidate for providing this sort of scoring function. Conceptually, it is a trainable sample evaluation mechanism that -owing to GAN training paradigm -could be closely calibrated to the distribution modeled by the generator. If the discriminator could retain fine-grained information of the relative quality of samples, measured for instance by probability density or unnormalized energy, it could be used as an evaluation metric. Such data-driven evaluators would be highly desirable for problems where it is difficult to define evaluation criteria that correlate well with human judgment. Indeed, the real-valued discriminator of the recently introduced energy-based GANs <ref type="bibr" target="#b10">Zhao et al. (2016)</ref> might seem like an ideal candidate energy function. Unfortunately, as we will show, the degenerate fate of the GAN discriminator at the optimum equally afflicts the energy-based GAN of <ref type="bibr">Zhao et al..</ref> In this paper we consider the questions: (i) does there exists an adversarial framework that induces a non-degenerate discriminator, and (ii) if so, what form will the resulting discriminator take? We introduce a novel adversarial learning formulation, which leads to a non-degenerate discriminator while ensuring the generator distribution matches the data distribution at the global optimum. We derive a general analytic form of the optimal discriminator, and discuss its properties and their 2 RELATED WORK Following a similar motivation, the field of Inverse Reinforcement Learning (IRL) <ref type="bibr" target="#b5">(Ng &amp; Russell, 2000)</ref> has been exploring ways to recover the "intrinsic" reward function (analogous to the discriminator) from observed expert trajectories (real samples). Taking this idea one step further, apprenticeship learning or imitation learning <ref type="bibr" target="#b0">(Abbeel &amp; Ng, 2004;</ref><ref type="bibr" target="#b11">Ziebart et al., 2008)</ref> aims at learning a policy (analogous to the generator) using the reward signals recovered by IRL. Notably, Ho &amp; Ermon draw a connection between imitation learning and GAN by showing that the GAN formulation can be derived by imposing a specific regularization on the reward function. Also, under a special case of their formulation, Ho &amp; Ermon provide a duality-based interpretation of the problem, which inspires our theoretical analysis. However, as the focus of <ref type="bibr" target="#b3">(Ho &amp; Ermon, 2016)</ref> is only on the policy, the authors explicitly propose to bypass the intermediate IRL step, and thus provide no analysis of the learned reward function.</p><p>The GAN models most closely related to our proposed framework are energy-based GAN models of <ref type="bibr" target="#b10">Zhao et al. (2016)</ref> and <ref type="bibr" target="#b4">Kim &amp; Bengio (2016)</ref>. In the next section, We show how one can derive both of these approaches from different assumptions regarding regularization of the generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALTERNATIVE FORMULATION OF ADVERSARIAL TRAINING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BACKGROUND</head><p>Before presenting the proposed formulation, we first state some basic assumptions required by the analysis, and introduce notations used throughout the paper.</p><p>Following the original work on GANs <ref type="bibr" target="#b2">(Goodfellow et al., 2014)</ref>, our analysis focuses on the nonparametric case, where all models are assumed to have infinite capacities. While many of the nonparametric intuitions can directly transfer to the parametric case, we will point out cases where this transfer fails. We assume a finite data space throughout the analysis, to avoid technical machinery out of the scope of this paper. Our results, however, can be extended to continuous data spaces, and our experiments are indeed performed on continuous data. Let X be the data space under consideration, and P = {p | p(x) ≥ 0, ∀x ∈ X , x∈X p(x) = 1} be the set of all proper distributions defined on X . Then, p data ∈ P : X → R and p gen ∈ P : X → R will denote the true data distribution and the generator distribution. E x∼p f (x) denotes the expectation of the quantity f (x) w.r.t. x drawn from p. Finally, the term "discriminator" will refer to any structure that provides training signals to the generator based on some measure of difference between the generator distribution and the real data distribution, which which includes but is not limited to f -divergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PROPOSED FORMULATION</head><p>In order to understand the motivation of the proposed approach, it is helpful to analyze the optimization dynamics near convergence in GANs first.</p><p>When the generator distribution matches the data distribution, the training signal (gradient) w.r.t. the discriminator vanishes. At this point, assume the discriminator still retains density information, and views some samples as more real and others as less. This discriminator will produce a training signal (gradient) w.r.t. the generator, pushing the generator to generate samples that appear more real to the discriminator. Critically, this training signal is the sole driver of the generator's training. Hence, the generator distribution will diverge from the data distribution. In other words, as long as the discriminator retains relative density information, the generator distribution cannot stably match the data distribution. Thus, in order to keep the generator stationary as the data distribution, the discriminator must assign flat (exactly the same) density to all samples at the optimal. From the analysis above, the fundamental difficulty is that the generator only receives a single training signal (gradient) from the discriminator, which it has to follow. To keep the generator stationary, this single training signal (gradient) must vanish, which requires a degenerate discriminator. In this work, we propose to tackle this single training signal constraint directly. Specifically, we introduce a novel adversarial learning formulation which incorporates an additional training signal to the generator, such that this additional signal can</p><p>• balance (cancel out) the discriminator signal at the optimum, so that the generator can stay stationary even if the discriminator assigns non-flat density to samples</p><p>• cooperate with the discriminator signal to make sure the generator converges to the data distribution, and the discriminator retains the correct relative density information</p><p>The proposed formulation can be written as the following minimax training objective,</p><formula xml:id="formula_0">max c min pgen∈P E x∼pgen c(x) − E x∼pdata c(x) + K(p gen ),<label>(1)</label></formula><p>where c(x) : X → R is the discriminator that assigns each data point an unbounded scalar cost, and K(p gen ) : P → R is some (functionally) differentiable, convex function of p gen . Compared to the original GAN, despite the similar minimax surface form, the proposed fomulation has two crucial distinctions.</p><p>Firstly, while the GAN discriminator tries to distinguish "fake" samples from real ones using binary classification, the proposed discriminator achieves that by assigning lower cost to real samples and higher cost to "fake" one. This distinction can be seen from the first two terms of Eqn. (1), where the discriminator c(x) is trained to widen the expected cost gap between "fake" and real samples, while the generator is adversarially trained to minimize it. In addition to the different adversarial mechanism, a calibrating term K(p gen ) is introduced to provide a countervailing source of training signal for p gen as we motivated above. For now, the form of K(p gen ) has not been specified. But as we will see later, its choice will directly decide the form of the optimal discriminator c * (x).</p><p>With the specific optimization objective, we next provide theoretical characterization of both the generator and the discriminator at the global optimum.</p><p>Define L(p gen , c) = E x∼pgen c(x) − E x∼pdata c(x) + K(p gen ), then L(p gen , c) is the Lagrange dual function of the following optimization problem</p><formula xml:id="formula_1">min pgen∈P K(p gen ) s.t. p gen (x) − p data (x) = 0, ∀x ∈ X<label>(2)</label></formula><p>where c(x), ∀x appears in L(p gen , c) as the dual variables introduced for the equality constraints. This duality relationship has been observed previously in <ref type="bibr">(Ho &amp; Ermon, 2016, equation</ref>  <ref type="formula" target="#formula_6">(7)</ref>) under the adversarial imitation learning setting. However, in their case, the focus was fully on the generator side (induced policy), and no analysis was provided for the discriminator (reward function).</p><p>In order to characterize c * , we first expand the set constraint on p gen into explicit equality and inequality constraints: min pgen K(p gen )</p><formula xml:id="formula_2">s.t. p gen (x) − p data (x) = 0, ∀x − p gen (x) ≤ 0, ∀x x∈X p gen (x) − 1 = 0.</formula><p>(3)</p><p>Notice that K(p gen ) is a convex function of p gen (x) by definition, and both the equality and inequality constraints are affine functions of p gen (x). Thus, problem (2) is a convex optimization problem. What's more, since (i) dom K is open, and (ii) there exists a feasible solution p gen = p data to (3), by the refined Slater's condition <ref type="bibr">(Boyd &amp; Vandenberghe, 2004, page 226)</ref>, we can further verify that strong duality holds for (3). With strong duality, a typical approach to characterizing the optimal solution is to apply the Karush-Kuhn-Tucker (KKT) conditions, which gives rise to this theorem:</p><p>Proposition 3.1. By the KKT conditions of the convex problem (3), at the global optimum, the optimal generator distribution p * gen matches the true data distribution p data , and the optimal discriminator c * (x) has the following form:</p><formula xml:id="formula_3">c * (x) = − ∂K(p gen ) ∂p gen (x) pgen=p data − λ * + µ * (x), ∀x ∈ X , where µ * (x) = 0, p data (x) &gt; 0 u x , p data (x) = 0 , λ * ∈ R, is an under-determined real number independent of x, u x ∈ R + , is an under-determined non-negative real number.<label>(4)</label></formula><p>The detailed proof of proposition 3.1 is provided in appendix A.1. From (4), we can see the exact form of the optimal discriminator depends on the term K(p gen ), or more specifically its gradient. But, before we instantiate K(p gen ) with specific choices and show the corresponding forms of c * (x), we first discuss some general properties of c * (x) that do not depend on the choice of K.</p><p>Weak Support Discriminator. As part of the optimal discriminator function, the term µ * (x) plays the role of support discriminator. That is, it tries to distinguish the support of the data distribution, i.e. SUPP(p data ) = {x ∈ X | p data (x) &gt; 0}, from its complement set with zeroprobability, i.e. SUPP(p data ) = {x ∈ X | p data (x) = 0}. Specifically, for any x ∈ SUPP(p data ) and x ∈ SUPP(p data ) , it is guaranteed that µ * (x) ≤ µ * (x ). However, because µ * (·) is underdetermined, there is nothing preventing the inequality from degenerating into an equality. Therefore, we name it the weak support discriminator. But, in all cases, µ * (·) assigns zero cost to all data points within the support. As a result, it does not possess any fine-grained density information inside of the data support. It is worth pointing out that, in the parametric case, because of the smoothness and the generalization properties of the parametric model, the learned discriminator may generalize beyond the data support.</p><p>Global Bias. In (4), the term λ * is a scalar value shared for all x. As a result, it does not affect the relative cost among data points, and only serves as a global bias for the discriminator function.</p><p>Having discussed general properties, we now consider some specific cases of the convex function K, and analyze the resulting optimal discriminator c * (x) in detail.</p><p>1. First, let us consider the case where K is the negative entropy of the generator distribution, i.e. K(p gen ) = −H(p gen ). Taking the derivative of the negative entropy w.r.t. p gen (x), we have</p><formula xml:id="formula_4">c * ent (x) = − log p data (x) − 1 − λ * + µ * (x), ∀x ∈ X ,<label>(5)</label></formula><p>where µ * (x) and λ * have the same definitions as in <ref type="formula" target="#formula_3">(4)</ref>. Up to a constant, this form of c * ent (x) is exactly the energy function of the data distribution p data (x). This elegant result has deep connections to several existing formulations, which include max-entropy imitation learning <ref type="bibr" target="#b11">(Ziebart et al., 2008)</ref> and the directed-generator-trained energybased model <ref type="bibr" target="#b4">(Kim &amp; Bengio, 2016)</ref>. The core difference is that these previous formulations are originally derived from maximum-likelihood estimation, and thus the minimax optimization is only implicit. In contrast, with an explicit minimax formulation we can develop a better understanding of the induced solution. For example, the global bias λ * suggests that there exists more than one stable equilibrium the optimal discriminator can actually reach. Further, µ * (x) can be understood as a support discriminator that poses extra cost on generator samples which fall in zero-probability regions of data space. 2. When K(p gen ) = 1 2 x∈X p gen (x) 2 = 1 2 p gen 2 2 , which can be understood as posing 2 regularization on p gen , we have <ref type="bibr">∂K(pgen)</ref> ∂pgen(x) pgen=pdata = p data (x), and it follows</p><formula xml:id="formula_5">c * 2 (x) = −p data (x) − λ * + µ * (x), ∀x ∈ X ,<label>(6)</label></formula><p>with µ * (x), λ * similarly defined as in <ref type="formula" target="#formula_3">(4)</ref>. Surprisingly, the result suggests that the optimal discriminator c * 2 (x) directly recovers the negative probability −p data (x), shifted by a constant. Thus, similar to the entropy solution (5), it fully retains the relative density information of data points within the support.</p><p>However, because of the under-determined term µ * (x), we cannot recover the distribution density p data exactly from either c * 2 or c * ent if the data support is finite. Whether this ambiguity can be resolved is beyond the scope of this paper, but poses an interesting research problem. 3. Finally, let's consider consider a degenerate case, where K(p gen ) is a constant. That is, we dont provide any additional training signal for pgen at all. With K(p gen ) = const, we simply have</p><formula xml:id="formula_6">c * cst (x) = λ * + µ * (x), ∀x ∈ X ,<label>(7)</label></formula><p>whose discriminative power is fully controlled by the weak support discriminator µ * (x). Thus, it follows that c * cst (x) won't be able to discriminate data points within the support of p data , and its power to distinguish data from SUPP(p data ) and SUPP(p data ) is weak. This closely matches the intuitive argument in the beginning of this section. Note that when K(p gen ) is a constant, the objective function (1) simplifies to:</p><formula xml:id="formula_7">max c min pgen∈P E x∼pgen c(x) − E x∼pdata c(x) ,<label>(8)</label></formula><p>which is very similar to the EBGAN objective <ref type="bibr">(Zhao et al., 2016, equation</ref>  <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_3">(4)</ref>). As we show in appendix A.2, compared to the objective in <ref type="formula" target="#formula_7">(8)</ref>, the EBGAN objective puts extra constraints on the allowed discriminator function. In spite of that, the EBGAN objective suffers from the single-training-signal problem and does not guarantee that the discriminator will recover the real energy function (see appendix A.2 for detailed analysis).</p><p>As we finish the theoretical analysis of the proposed formulation, we want to point out that simply adding the same term K(p gen ) to the original GAN formulation will not lead to both a generator that matches the data distribution, and a discriminator that retains the density information (see appendix A.3 for detailed analysis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PARAMETRIC INSTANTIATION WITH ENTROPY APPROXIMATION</head><p>While the discussion in previous sections focused on the non-parametric case, in practice we are limited to a finite amount of data, and the actual problem involves high dimensional continuous spaces. Thus, we resort to parametric representations for both the generator and the discriminator. In order to train the generator using standard back-propagation, we do not parametrize the generator distribution directly. Instead, we parametrize a directed generator network that transforms random noise z ∼ p z (z) to samples from a continuous data space R n . Consequently, we don't have analytical access to the generator distribution, which is defined implicitly by the generator network's noise→data mapping. However, the regularization term K(p gen ) in the training objective (1) requires the generator distribution. Faced with this problem, we focus on the max-entropy formulation, and exploit two different approximations of the regularization term K(p gen ) = −H(p gen ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">NEAREST-NEIGHBOR ENTROPY GRADIENT APPROXIMATION</head><p>The first proposed solution is built upon an intuitive interpretation of the entropy gradient. Firstly, since we construct p gen by applying a deterministic, differentiable transform g θ to samples z from a fixed distribution p z , we can write the gradient of H(p gen ) with respect to the generator parameters θ as follows:</p><formula xml:id="formula_8">− ∇ θ H(p gen ) = E z∼pz [∇ θ log p gen (g θ (z))] = E z∼pz ∂g θ (z) ∂θ ∂ log p gen (g θ (z)) ∂g θ (z) ,<label>(9)</label></formula><p>where the first equality relies on the "reparametrization trick". Equation 9 implies that, if we can compute the gradient of the generator log-density log p gen (x) w.r.t. any x = g θ (z), then we can directly construct the Monte-Carlo estimation of the entropy gradient ∇ θ H(p gen ) using samples from the generator.</p><p>Intuitively, for any generated data x = g θ (z), the term ∂ log pgen(x) ∂x essentially describes the direction of local change in the sample space that will increase the log-density. Motivated by this intuition, we propose to form a local Gaussian approximation p i gen of p gen around each point x i in a batch of samples {x 1 , ..., x n } from the generator, and then compute the gradient ∂ log pgen(xi) ∂xi based on the Gaussian approximation. Specifically, each local Gaussian approximation p i gen is formed by finding the k nearest neighbors of x i in the batch {x 1 , ..., x n }, and then placing an isotropic Gaussian distribution at their mean (i.e. maximimum likelihood). Based on the isotropic Gaussian approximation, the resulting gradient has the following form</p><formula xml:id="formula_9">∂ log p gen (x i ) ∂x i ≈ µ i − x i , where µ i = 1 k x ∈KNN(xi)</formula><p>x is the mean of the Gaussian <ref type="formula" target="#formula_0">(10)</ref> Finally, note the scale of this gradient approximation may not be reliable. To fix this problem, we normalize the approximated gradient into unit norm, and use a single hyper-parameter to model the scale for all x, leading to the following entropy gradient approximation</p><formula xml:id="formula_10">− ∇ θ H(p gen ) ≈ α 1 k xi=g θ (zi) µ i − x i µ i − x i 2<label>(11)</label></formula><p>where α is the hyper-parameter and µ i is defined as in equation <ref type="formula" target="#formula_0">(10)</ref>.</p><p>An obvious weakness of this approximation is that it relies on Euclidean distance to find the k nearest neighbors. However, Euclidean distance is usually not the proper metric to use when the effective dimension is very high. As the problem is highly challenging, we leave it for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">VARIATIONAL LOWER BOUND ON THE ENTROPY</head><p>Another approach we consider relies on defining and maximizing a variational lower bound on the entropy H(p gen (x)) of the generator distribution. We can define the joint distribution over observed data and the noise variables as p gen (x, z) = p gen (x | z)p gen (z), where simply p gen (z) = p z (z) is a fixed prior. Using the joint, we can also define the marginal p gen (x) and the posterior p gen (z | x).</p><p>We can also write the mutual information between the observed data and noise variables as:</p><formula xml:id="formula_11">I(p gen (x); p gen (z)) = H(p gen (x)) − H(p gen (x | z)) = H(p gen (z)) − H(p gen (z | x)),<label>(12)</label></formula><p>where H(p gen (. | .)) denotes the conditional entropy. By reorganizing terms in this definition, we can write the entropy H(p gen (x)) as:</p><formula xml:id="formula_12">H(p gen (x)) = H(p gen (z)) − H(p gen (z | x)) + H(p gen (x | z))<label>(13)</label></formula><p>We can think of p gen (x | z) as a peaked Gaussian with a fixed, diagonal covariance, and hence its conditional entropy is constant and can be dropped. Furthermore, H(p gen (z)) is also assumed to be fixed a priori. Hence, we can maximize H(p gen (x)) by minimizing the conditional entropy:</p><formula xml:id="formula_13">H(p gen (z | x)) = E x∼pgen(x) E z∼pgen(z|x) [− log p gen (z | x)]<label>(14)</label></formula><p>Optimizing this term is still problematic, because (i) we do not have access to the posterior p gen (z | x), and (ii) we cannot sample from it. Therefore, we instead minimize a variational upper bound defined by an approximate posterior q gen (z | x):</p><formula xml:id="formula_14">H(p gen (z | x)) = E x∼pgen(x) E z∼pgen(z|x) [− log q gen (z | x)] − KL(p gen (z | x) q gen (z | x)) ≤ E x∼pgen(x) E z∼pgen(z|x) [− log q gen (z | x)] = U(q gen ).<label>(15)</label></formula><p>We can also rewrite the variational upper bound as:</p><formula xml:id="formula_15">U(q gen ) = E x,z∼pgen(x,z) [− log q gen (z | x)] = E z∼pgen(z) E x∼pgen(x|z) [− log q gen (z | x)] ,<label>(16)</label></formula><p>which can be optimized efficiently with standard back-propagation and Monte Carlo integration of the relevant expectations based on independent samples drawn from the joint p gen (x, z). By minimizing this upper bound on the conditional entropy H(p gen (z | x)), we are effectively maximizing a variational lower bound on the entropy H(p gen (x)). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we verify our theoretical results empirically on several synthetic and real datasets. In particular, we evaluate whether the discriminator obtained from the entropy-regularized adversarial training can capture the density information (in the form of energy), while making sure the generator distribution matches the data distribution. For convenience, we refer to the obtained models as EGAN-Ent. Our experimental setting follows closely recommendations from <ref type="bibr" target="#b7">Radford et al. (2015)</ref>, except in Sec. 5.1 where we use fully-connected models (see appendix B.1 for details). 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">SYNTHETIC LOW-DIMENSIONAL DATA</head><p>First, we consider three synthetic datasets in 2-dimensional space, which are drawn from the following distributions: (i) Mixture of 4 Gaussians with equal mixture weights, (ii) Mixture of 200 Gaussians arranged as two spirals (100 components each spiral), and (iii) Mixture of 2 Gaussians with highly biased mixture weights, P (c 1 ) = 0.9, P (c 2 ) = 0.1. We visualize the ground-truth energy of these distributions along with 100K training samples in <ref type="figure" target="#fig_0">Figure 1</ref>. Since the data lies in 2-dimensional space, we can easily visualize both the learned generator (by drawing samples) and the discriminator for direct comparison and evaluation. We evaluate here our EGAN-Ent model using both approximations: the nearest-neighbor based approximation (EGAN-Ent-NN) and the variational-inference based approximation (EGAN-Ent-VI), and compare them with two baselines: the original GAN and the energy based GAN with no regularization (EGAN-Const).</p><p>Experiment results are summarized in <ref type="figure" target="#fig_1">Figure 2</ref> for baseline models, and <ref type="figure">Figure 3</ref> for the proposed models. As we can see, all four models can generate perfect samples. However, for the discriminator, both GAN and EGAN-Const lead to degenerate solution, assigning flat energy inside the empirical data support. In comparison, EGAN-Ent-VI and EGAN-Ent-NN clearly capture the density information, though to different degrees. Specifically, on the equally weighted Gaussian mixture and the two-spiral mixture datasets, EGAN-Ent-NN tends to give more accurate and fine-grained solutions compared to EGAN-Ent-VI. However, on the biased weighted Gaussian mixture dataset, EGAN-Ent-VI actually fails to captures the correct mixture weights of the two modes, incorrectly assigning lower energy to the mode with lower probability (smaller weight). In contrast, EGAN-Ent-NN perfectly captures the bias in mixture weight, and obtains a contour very close to the ground truth.</p><p>To better quantify these differences, we present detailed comparison based on KL divergence in appendix B.2. What's more, the performance difference between EGAN-Ent-VI and EGAN-Ent-NN on biased Gaussian mixture reveals the limitations of the variational inference based approximation, i.e. providing inaccurate gradients. Due to space consideratiosn, we refer interested readers to the appendix B.3 for a detailed discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">RANKING NIST DIGITS</head><p>In this experiment, we verify that the results in synthetic datasets can translate into data with higher dimensions. While visualizing the learned energy function is not feasible in high-dimensional space, we can verify whether the learned energy function learns relative densities by inspecting the ranking of samples according to their assigned energies. We train on 28 × 28 images of a single handwritten  <ref type="figure">Figure 3</ref>: Learned energies and samples from proposed models whose discriminator can retain density information at the optimal. Blue dots are generated samples, and red dots are real ones.</p><p>digit from the NIST dataset. <ref type="bibr">2</ref> We compare the ability of EGAN-Ent-NN with both EGAN-Const and GAN on ranking a set of 1,000 images, half of which are generated samples and the rest are real test images. <ref type="figure">Figures 4 and 5</ref> show the top-100 and bottom-100 ranked images respectively for each model, after training them on digit 1. We also show in <ref type="figure">Figure 7</ref> the mean of all training samples, so we can get a sense of what is the most common style (highest density) of digit 1 in NIST. We can notice that all of the top-ranked images by EGAN-Ent-NN look similar to the mean sample. In addition, the lowest-ranked images are clearly different from the mean image, with either high (clockwise or counter-clockwise) rotation degrees from the mean, or an extreme thickness level. We do not see such clear distinction in other models. We provide in the appendix B.4 the ranking of the full set of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">SAMPLE QUALITY ON NATURAL IMAGE DATASETS</head><p>In this last set of experiments, we evaluate the visual quality of samples generated by our model in two datasets of natural images, namely CIFAR-10 and CelebA. We employ here the variationalbased approximation for entropy regularization, which can scale well to high-dimensional data. <ref type="figure">Figure 6</ref> shows samples generated by EGAN-Ent-VI. We can see that despite the noisy gradients provided by the variational approximation, our model is able to generate high-quality samples. We futher validate the quality of our model's samples on CIFAR-10 using the Inception score proposed by <ref type="bibr">(Salimans et al., 2016) 3</ref> . <ref type="table" target="#tab_0">Table 1</ref> shows the scores of our EGAN-Ent-VI, the best GAN model from <ref type="bibr" target="#b8">Salimans et al. (2016)</ref> which uses only unlabeled data, and an EGAN-Const model which has the same architecture as our model. We notice that even without employing suggested techniques in <ref type="bibr" target="#b8">Salimans et al. (2016)</ref>, energy-based models perform quite similarly to the GAN model. Furthermore, the fact that our model scores higher than EGAN-Const highlights the importance of entropy regularization in obtaining good quality samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper we have addressed a fundamental limitation in adversarial learning approaches, which is their inability of providing sensible energy estimates for samples. We proposed a novel adversarial learning formulation which results in a discriminator function that recovers the true data energy. We provided a rigorous characterization of the learned discriminator in the non-parametric setting, and proposed two methods for instantiating it in the typical parametric setting. Our experimental results verify our theoretical analysis about the discriminator properties, and show that we can also obtain samples of state-of-the-art quality.</p><p>(a) CIFAR-10 (b) CelebA <ref type="figure">Figure 6</ref>: Samples generated from our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Our model Improved GAN † EGAN-Const Score ± std. 7.07 ± .10 6.86 ± .06 6.7447 ± 0.09  (17) where c(x) ∈ R, ∀x, µ(x) ∈ R + , ∀x, and λ ∈ R are the dual variables. The KKT conditions for the optimal primal and dual variables are as follows</p><formula xml:id="formula_16">∂K(p gen ) ∂p gen (x) pgen=pdata + c * (x) − µ * (x) + λ * = 0, ∀x (stationarity) µ * (x)p * gen (x) = 0, ∀x (complement slackness) µ * (x) ≥ 0, ∀x (dual feasibility) p * gen (x) ≥ 0, p * gen (x) = p data (x), ∀x (primal feasibility) x∈X p gen (x) = 1 (primal feasibility)<label>(18)</label></formula><p>Rearranging the conditions above, we get p * gen (x) = p data (x), ∀x ∈ X as well as equation <ref type="formula" target="#formula_3">(4)</ref>, which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 OPTIMAL CONDITIONS OF EBGAN</head><p>In <ref type="bibr" target="#b10">(Zhao et al., 2016)</ref>, the training objectives of the generator and the discriminator cannot be written as a single minimax optimization problem since the margin structure is only applied to the objective of the discriminator. In addition, the discriminator is designed to produce the mean squared reconstruction error of an auto-encoder structure. This restricted the range of the discriminator output to be non-negative, which is equivalent to posing a set constraint on the discriminator under the non-parametric setting.</p><p>Thus, to characterize the optimal generator and discriminator, we adapt the same analyzing logic used in the proof sketch of the original GAN <ref type="bibr" target="#b2">(Goodfellow et al., 2014)</ref>. Specifically, given a specific generator distribution p gen , the optimal discriminator function given the generator distribution c * (x; p gen ) can be derived by examining the objective of the discriminator. Then, the conditional optimal discriminator function is substituted into the training objective of p gen , simplifying the "adversarial" training as a minimizing problem only w.r.t. p gen , which can be well analyzed.</p><p>Firstly, given any generator distribution p gen , the EBGAN training objective for the discriminator can be written as the following form</p><formula xml:id="formula_17">c * (x; p gen ) = arg max c∈C − E pgen max(0, m − c(x)) − E pdata c(x) = arg max c∈C E pgen min(0, c(x) − m) − E pdata c(x)<label>(19)</label></formula><p>where C = {c : c(x) ≥ 0, ∀x ∈ X } is the set of allowed non-negative discriminator functions. Note this set constraint comes from the fact the mean squared reconstruction error as discussed above.</p><p>Since the problem (19) is independent w.r.t. each x, the optimal solution can be easily derived as</p><formula xml:id="formula_18">c * (x; p gen ) =        0, p gen (x) &lt; p data (x) m, p gen (x) &gt; p data (x) α x , p gen (x) = p data (x) &gt; 0 β x , p gen (x) = p data (x) = 0<label>(20)</label></formula><p>where α x ∈ [0, m] is an under-determined number, a β x ∈ [0, ∞) is another under-determined nonnegative real number, and the subscripts in m, α x , β x reflect that fact that these under-determined values can be distinct for different x. </p><p>where the second term of the first line is implicitly defined as the problem is an adversarial game between p gen and c. Proposition A.1. The global optimal of the EBGAN training objective is achieved if and only if p gen = p data . At that point, c * (x) is fully under-determined.</p><p>Proof. The proof is established by showing contradiction.</p><p>Firstly, assume the optimal p * gen = p data . Thus, there must exist a non-equal set X = = {x | p data (x) = p * gen (x)}, which can be further splitted into two subsets, the greater-than set X &gt; = {x | p * gen (x) &gt; p data (x)}, and the less-than set X &lt; = {x | p * gen (x) &lt; p data (x)}. Similarly, we define the equal set</p><formula xml:id="formula_20">X = = {x : p * gen (x) = p data (x)}. Obviously, X &gt; X &lt; X = = X .</formula><p>Let L(p gen ) = x∈X p gen (x) − p data (x) c * (x; p gen ), substituting the results from equation <ref type="formula" target="#formula_1">(20)</ref> into <ref type="formula" target="#formula_0">(21)</ref>, the L(p gen ) * can be written as</p><formula xml:id="formula_21">L(p * gen ) = x∈X&lt; X&lt; X= p * gen (x) − p data (x) c * (x; p * gen ) = x∈X&lt; p * gen (x) − p data (x) c * (x; p * gen ) + x∈X&gt; p * gen (x) − p data (x) c * (x; p * gen ) = m x∈X&gt; p * gen (x) − p data (x) &gt; 0<label>(22)</label></formula><p>However, when p gen = p data , we have L(p gen ) = 0 &lt; L(p * gen )</p><p>which contradicts the optimal (miminum) assumption of p * gen . Hence, the contradiction concludes that at the global optimal, p * gen = p data . By equation <ref type="formula" target="#formula_1">(20)</ref>, it directly follows that c * (x; p * gen ) = α x , which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 ANALYSIS OF ADDING ADDITIONAL TRAINING SIGNAL TO GAN FORMULATION</head><p>To show that simply adding the same training signal to GAN will not lead to the same result, it is more convenient to directly work with the formulation of f -GAN <ref type="bibr">(Nowozin et al., 2016, equation (6)</ref>) family, which include the original GAN formulation as a special case.</p><p>Specifically, the general f -GAN formulation takes the following form</p><formula xml:id="formula_23">max c min pgen∈P E x∼pgen f (c(x)) − E x∼pdata c(x) ,<label>(24)</label></formula><p>where the f (·) denotes the convex conjugate <ref type="bibr" target="#b1">(Boyd &amp; Vandenberghe, 2004</ref>) of the f -divergence function. The optimal condition of the discriminator can be found by taking the variation w.r.t. c, which gives the optimal discriminator</p><formula xml:id="formula_24">c * (x) = f ( p data (x) p gen (x) )<label>(25)</label></formula><p>where f (·) is the first-order derivative of f (·). Note that, even when we add an extra term L(p gen ) to equation (24), since the term K(p gen ) is a constant w.r.t. the discriminator, it does not change the result given by equation <ref type="formula" target="#formula_1">(25)</ref> about the optimal discriminator. As a consequence, for the optimal discriminator to retain the density information, it effectively means p gen = p data . Hence, there will be a contradiction if both c * (x) retains the density information, and the generator matches the data distribution.</p><p>Intuitively, this problem roots in the fact that f -divergence is quite "rigid" in the sense that given the p gen (x) it only allows one fixed point for the discriminator. In comparison, the divergence used in our proposed formulation, which is the expected cost gap, is much more flexible. By the expected cost gap itself, i.e. without the K(p gen ) term, the optimal discriminator is actually under-determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SUPPLEMENTARY MATERIALS FOR SECTION 5 B.1 EXPERIMENT SETTING</head><p>Here, we specify the neural architectures used for experiements presented in Section 5.</p><p>Firstly, for the Egan-Ent-VI model, we parameterize the approximate posterior distribution q gen (z | x) with a diagonal Gaussian distribution, whose mean and covariance matrix are the output of a trainable inference network, i.e.</p><formula xml:id="formula_25">q gen (z | x) = N (µ, Iσ 2 ) µ, log σ = f infer (x)<label>(26)</label></formula><p>where f infer denotes the inference network, and I is the identity matrix. Note that the Inference Network only appears in the Egan-Ent-VI model.</p><p>For experiments with the synthetic datasets, the following fully-connected feed forward neural networks are employed where FC and BN denote fully-connected layer and batch normalization layer respectively. Note that since the input noise to the generator has dimension 4, the Inference Net output has dimension 4 * 2, where the first 4 elements correspond the inferred mean, and the last 4 elements correspond to the inferred diagonal covariance matrix in log scale.</p><p>For the handwritten digit experiment, we closely follow the DCGAN <ref type="bibr" target="#b7">(Radford et al., 2015)</ref> architecture with the following configuration Here, LRec is the leaky rectified non-linearity recommended by <ref type="bibr" target="#b7">Radford et al. (2015)</ref>. In addition, CV(128,256,4c2s) denotes a convolutional layer with 128 input channels, 256 output channels, and kernel size 4 with stride 2. Similarly, DC(256,128,4c2s) denotes a corresponding transposed convolutional operation. Compared to the original DCGAN architecture, the discriminator under our formulation does not have the last sigmoid layer which squashes a scalar value into a probability in [0, 1].</p><p>For celebA experiment with 64 × 64 color images, we use the following architecture Given the chosen architectures, we follow <ref type="bibr" target="#b7">Radford et al. (2015)</ref> and use Adam as the optimization algorithm. For more detailed hyper-parameters, please refer to the code.  In order to quantify the quality of recovered distributions, we compute the pairwise KL divergence of the following four distributions:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 QUANTITATIVE COMPARISON OF DIFFERENT MODELS</head><p>• The real data distribution with analytic form, denoted as p data • The empirical data distribution approximated from the 100K training data, denoted as p emp • The generator distribution approximated from 100K generated data, denoted as p gen • The discriminator distribution re-normalized from the learned energy, denoted as p disc</p><p>Since the synthetic datasets are two dimensional, we approximate both the empirical data distribution and the generator distribution using the simple histogram estimation. Specifically, we divide the canvas into a 100-by-100 grid, and assign each sample into its nearest grid cell based on euclidean distance. Then, we normalize the number of samples in each cell into a proper distribution. When recovering the discriminator distribution from the learned energy, we assume that µ * (x) = 0 (i.e. infinite data support), and discretize the distribution into the same grid cells p disc (x) = exp(−c * (x))</p><p>x ∈Grid exp(−c * (x ))</p><p>, ∀x ∈ Grid Based on these approximation, <ref type="table" target="#tab_2">Table 2</ref> summarizes the results. For all measures related to the discriminator distribution, EGAN-Ent-VI and EGAN-Ent-NN significantly outperform the other two baseline models, which matches our visual assessment in <ref type="figure" target="#fig_1">Figure 2 and 3</ref>. Meanwhile, the generator distributions learned from our proposed framework also achieve relatively lower divergence to both the empirical data distribution and the true data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 COMPARISON OF THE ENTROPY (GRADIENT) APPROXIMATION METHODS</head><p>In order to understand the performance difference between EGAN-Ent-VI and EGAN-Ent-NN, we analyze the quality of the entropy gradient approximation during training. To do that, we visualize some detailed training information in <ref type="figure">Figure 8</ref>.  <ref type="figure">Figure 8</ref>: For convenience, we will use <ref type="figure">Fig. (i,j)</ref> to refer to the subplot in row i, column j. <ref type="figure" target="#fig_0">Fig. (1,1)</ref>: current energy plot. <ref type="figure" target="#fig_0">Fig. (1,2)</ref>: frequency map of generated samples in the current batch. <ref type="figure" target="#fig_0">Fig. (1,3)</ref>: frequency map of real samples in the current batch. <ref type="figure" target="#fig_0">Fig-(1,4)</ref>: frequency difference between real and generated samples. <ref type="figure" target="#fig_0">Fig. (2,1)</ref> comparison between more generated from current model and real sample. <ref type="figure" target="#fig_1">Fig. (2,2)</ref>: the discriminator gradient w.r.t. each training sample. <ref type="figure" target="#fig_1">Fig. (2,3)</ref>: the entropy gradient w.r.t. each training samples. <ref type="figure" target="#fig_1">Fig. (2,4)</ref>: all gradient (discriminator + entropy) w.r.t. each training sample.</p><p>As we can see in <ref type="figure">figure 8a</ref>, the viarational entropy gradient approximation w.r.t. samples is not accurate:</p><p>• It is inaccurate in terms of gradient direction. Ideally, the direction of the entropy gradient should be pointing from the center of its closest mode towards the surroundings, with the direction orthogonal to the implicit contour in <ref type="figure" target="#fig_0">Fig. (1,2)</ref>. However, the direction of gradients in the <ref type="figure" target="#fig_1">Fig. (2,3)</ref> does not match this. • It is inaccurate in magnitude. As we can see, the entropy approximation gradient ( <ref type="figure" target="#fig_1">Fig.  (2,3)</ref>) has much larger norm than the discriminator gradient ( <ref type="figure" target="#fig_1">Fig. (2,2)</ref>). As a result, the total gradient ( <ref type="figure" target="#fig_1">Fig. (2,4)</ref>) is fully dominated by the entropy approximation gradient. Thus, it usually takes much longer for the generator to learn to generate rare samples, and the training also proceeds much slower compared to the nearest neighbor based approximation.</p><p>In comparison, the nearest neighbor based gradient approximation is much more accurate as shown in 8b. As a result, it leads to more accurate energy contour, as well as faster training. What's more, from <ref type="figure" target="#fig_1">Figure 8b Fig. (2,4)</ref>, we can see the entropy gradient does have the cancel-out effect on the discriminator gradient, which again matches our theory.</p><p>B.4 RANKING NIST DIGITS <ref type="figure">Figure 9</ref> shows the ranking of all 1000 generated and real images (from the test set) for three models: EGAN-Ent-NN, EGAN-Const, and GAN. We can clearly notice that in EGAN-Ent-NN the topranked digits look very similar to the mean digit. From the upper-left corner to the lower-right corner, the transition trend is: the rotation degree increases, and the digits become increasingly thick or thin compared to the mean. In addition, samples in the last few rows do diverge away from the mean image: either highly diagonal to the right or left, or have different shape: very thin or thick, or typewriter script. Other models are not able to achieve a similar clear distinction for high versus low probability images. Finally, we consistently observe the same trend in modeling other digits, which are not shown in this paper due to space constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 CLASSIFIER PERFORMANCE AS A PROXY MEASURE</head><p>As mentioned in Section 5, evaluating the proposed formulation quantitatively on high-dimensional data is extremely challenging. Here, in order to provide more quantitative intuitions on the learned discriminator at convergence, we adopt a proxy measure. Specifically, we take the last-layer activation of the converged discriminator network as fixed pretrained feature, and build a linear classifier upon it. Hypothetically, if the discriminator does not degenerate, the extracted last-layer feature should maintain more information about the data points, especially compared to features from degenerated discriminators. Following this idea, we first train EGAN-Ent-NN, EGAN-Const, and GAN on the MNIST till convergence, and then extract the last-layer activation from their discriminator networks as fixed feature input. Based on fixed feature, a randomly initialized linear classifier is trained to do classification on MNIST. Based on 10 runs (with different initialization) of each of the three models, the test classification performance is summarized in <ref type="table" target="#tab_4">Table 3</ref>. For comparison purpose, we also include a baseline where the input features are extracted from a discriminator network with random weights.  Based on the proxy measure, EGAN-Ent-NN seems to maintain more information of data, which suggests that the discriminator from our proposed formulation is more informative. Despite the positive result, it is important to point out that maintaining information about categories does not necessarily mean maintaining information about the energy (density). Thus, this proxy measure should be understood cautiously.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>True energy functions and samples from synthetic distributions. Green dots in the sample plots indicate the mean of each Gaussian component.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Learned energies and samples from baseline models whose discriminator cannot retain density information at the optimal. In the sample plots, blue dots indicate generated samples, and red dots indicate real ones.(a) Entropy regularized Energy GAN with variational inference approximation (EGAN-Ent-VI) (b) Entropy regularized Energy GAN with nearest neighbor approximation (EGAN-Ent-NN)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>100 highest-ranked images out of 1000 generated and reals (bounding box) samples. 100 lowest-ranked images out of 1000 generated and reals (bounding box) samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure</head><label></label><figDesc>DISCRIMINATOR FORM UNDER THE PROPOSED FORMULATION Proof of proposition 3.1. Refining the Lagrange L(p gen , c) by introducing additional dual variables for the probability constraints (the second and third), the new Lagrange function has the form L(p gen , c, µ, λ) = K(p gen ) + x∈X c(x) p gen (x) − p data (x) − x∈X µ(x)p gen (x) + λ( x∈X p gen (x) − 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>This way, the overall training objective can be cast into a minimization problem w.r.t. p gen , p * gen = arg min pgen∈P E x∼pgen c * (x; p gen ) − E x∼pdata c * (x; p gen ) = arg min pgen∈P x∈X p gen (x) − p data (x) c * (x; p gen )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>•</head><label></label><figDesc>Generator: FC(4,128)-BN-ReLU-FC(128,128)-BN-ReLU-FC(128,2) • Discriminator: FC(2,128)-ReLU-FC(128,128)-ReLU-FC(128,1) • Inference Net: FC(2,128)-ReLU-FC(128,128)-ReLU-FC(128,4 * 2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>•</head><label></label><figDesc>Generator: FC(10,512 * 7 * 7)-BN-ReLU-DC(512,256;4c2s)-BN-ReLU -DC(256,128;4c2s)-BN-ReLU-DC(128,1;3c1s)-Sigmoid • Discriminator: CV(1,64;3c1s)-BN-LRec-CV(64,128;4c2s)-BN-LRec -CV(128,256;4c2s)-BN-LRec-FC(256 * 7 * 7,1) • Inference Net: CV(1,64;3c1s)-BN-LRec-CV(64,128;4c2s)-BN-LRec -CV(128,256;4c2s)-BN-LRec-FC(256 * 7 * 7,10 * 2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>•</head><label></label><figDesc>Generator: FC(10,512 * 4 * 4)-BN-ReLU-DC(512,256;4c2s)-BN-ReLU-DC(256,128;4c2s) -BN-ReLU-DC(256,128;4c2s)-BN-ReLU-DC(128,3;4c2s)-Tanh • Discriminator: CV(3,64;4c2s)-BN-LRec-CV(64,128;4c2s)-BN-LRec-CV(128,256;4c2s) -BN-LRec-CV(256,256;4c2s)-BN-LRec-FC(256 * 4 * 4,1) • Inference Net: CV(3,64;4c2s)-BN-LRec-CV(64,128;4c2s)-BN-LRec-CV(128,256;4c2s) -BN-LRec-CV(256,256;4c2s)-BN-LRec-FC(256 * 4 * 4,10 * 2) For Cifar10 experiment, where the image size is 32 × 32, similar architecture is used • Generator: FC(10,512 * 4 * 4)-BN-ReLU-DC(512,256;4c2s)-BN-ReLU-DC(256,128;3c1s) -BN-ReLU-DC(256,128;4c2s)-BN-ReLU-DC(128,3;4c2s)-Tanh • Discriminator: CV(3,64;3c1s)-BN-LRec-CV(64,128;4c2s)-BN-LRec-CV(128,256;4c2s) -BN-LRec-CV(256,256;4c2s)-BN-LRec-FC(256 * 4 * 4,1) • Inference Net: CV(3,64;3c1s)-BN-LRec-CV(64,128;4c2s)-BN-LRec-CV(128,256;4c2s) -BN-LRec-CV(256,256;4c2s)-BN-LRec-FC(256 * 4 * 4,10 * 2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) Training details under variational inference entropy approximation (b) Training details under nearest neighbor entropy approximation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Inception scores on CIFAR-10. † As reported in Sali- mans et al. (2016) without using labeled data.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Two-spiral Gaussian Mixture: KL(pdata pemp) = 0.3892, KL(pemp pdata) = 1.2349 KL Divergence pgen pemp pemp pgen pgen pdata pdata pgen pdisc pemp pemp pdisc pdisc pdata pdata pdisc pgen pdisc pdisc pgen</figDesc><table><row><cell></cell><cell></cell><cell cols="7">Gaussian Mixture: KL(pdata pemp) = 0.0291, KL(pemp pdata) = 0.0159</cell><cell></cell><cell></cell></row><row><cell cols="11">KL Divergence pgen pemp pemp pgen pgen pdata pdata pgen pdisc pemp pemp pdisc pdisc pdata pdata pdisc pgen pdisc pdisc pgen</cell></row><row><cell>GAN</cell><cell>0.3034</cell><cell>0.5024</cell><cell>0.2498</cell><cell>0.4807</cell><cell>6.7587</cell><cell>2.0648</cell><cell>6.2020</cell><cell>2.0553</cell><cell>2.4596</cell><cell>7.0895</cell></row><row><cell>EGAN-Const</cell><cell>0.2711</cell><cell>0.4888</cell><cell>0.2239</cell><cell>0.4735</cell><cell>6.7916</cell><cell>2.1243</cell><cell>6.2159</cell><cell>2.1149</cell><cell>2.5062</cell><cell>7.0553</cell></row><row><cell>EGAN-Ent-VI</cell><cell>0.1422</cell><cell>0.1367</cell><cell>0.0896</cell><cell>0.1214</cell><cell>0.8866</cell><cell>0.6532</cell><cell>0.7215</cell><cell>0.6442</cell><cell>0.7711</cell><cell>1.0638</cell></row><row><cell>EGAN-Ent-NN</cell><cell>0.1131</cell><cell>0.1006</cell><cell>0.0621</cell><cell>0.0862</cell><cell>0.0993</cell><cell>0.1356</cell><cell>0.0901</cell><cell>0.1187</cell><cell>0.1905</cell><cell>0.1208</cell></row><row><cell></cell><cell></cell><cell cols="8">Biased Gaussian Mixture: KL(pdata pemp) = 0.0273, KL(pemp pdata) = 0.0144</cell><cell></cell></row><row><cell cols="11">KL Divergence pgen pemp pemp pgen pgen pdata pdata pgen pdisc pemp pemp pdisc pdisc pdata pdata pdisc pgen pdisc pdisc pgen</cell></row><row><cell>GAN</cell><cell>0.0788</cell><cell>0.0705</cell><cell>0.0413</cell><cell>0.0547</cell><cell>7.1539</cell><cell>2.5230</cell><cell>6.4927</cell><cell>2.5018</cell><cell>2.5205</cell><cell>7.1140</cell></row><row><cell>EGAN-Const</cell><cell>0.1545</cell><cell>0.1649</cell><cell>0.1211</cell><cell>0.1519</cell><cell>7.1568</cell><cell>2.5269</cell><cell>6.4969</cell><cell>2.5057</cell><cell>2.5860</cell><cell>7.1995</cell></row><row><cell>EGAN-Ent-VI</cell><cell>0.0576</cell><cell>0.0668</cell><cell>0.0303</cell><cell>0.0518</cell><cell>3.9151</cell><cell>1.3574</cell><cell>2.9894</cell><cell>1.3365</cell><cell>1.4052</cell><cell>4.0632</cell></row><row><cell>EGAN-Ent-NN</cell><cell>0.0784</cell><cell>0.0574</cell><cell>0.0334</cell><cell>0.0422</cell><cell>0.8505</cell><cell>0.3480</cell><cell>0.5199</cell><cell>0.3299</cell><cell>0.3250</cell><cell>0.7835</cell></row><row><cell>GAN</cell><cell>0.5297</cell><cell>0.2701</cell><cell>0.3758</cell><cell>0.7240</cell><cell>6.3507</cell><cell>1.7180</cell><cell>4.3818</cell><cell>1.0866</cell><cell>1.6519</cell><cell>5.7694</cell></row><row><cell>EGAN-Const</cell><cell>0.7473</cell><cell>1.0325</cell><cell>0.7152</cell><cell>1.6703</cell><cell>5.9930</cell><cell>1.5732</cell><cell>3.9749</cell><cell>0.9703</cell><cell>1.8380</cell><cell>6.0471</cell></row><row><cell>EGAN-Ent-VI</cell><cell>0.2014</cell><cell>0.1260</cell><cell>0.4283</cell><cell>0.8399</cell><cell>1.1099</cell><cell>0.3508</cell><cell>0.3061</cell><cell>0.4037</cell><cell>0.4324</cell><cell>0.9917</cell></row><row><cell>EGAN-Ent-NN</cell><cell>0.1246</cell><cell>0.1147</cell><cell>0.4475</cell><cell>1.2435</cell><cell>0.1036</cell><cell>0.0857</cell><cell>0.4086</cell><cell>0.7917</cell><cell>0.1365</cell><cell>0.1686</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Pairwise KL divergence between distributions. Bold face indicate the lowest divergence within group.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Test performance of linear classifiers based on last-layer discriminator features.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For more details, please refer to https://github.com/zihangdai/cegan_iclr2017.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.nist.gov/srd/nist-special-database-19, which is an extended version of MNIST with an average of over 74K examples per digit.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Using the evaluation script released in https://github.com/openai/improved-gan/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGEMENTS</head><p>We would like to thank the developers of Theano (Theano Development Team, 2016) for developing such a powerful tool for scientific computing. Amjad Almahairi was supported by funding from Maluuba Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Apprenticeship learning via inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03476</idno>
		<title level="m">Generative adversarial imitation learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Deep directed generative models with energy-based probability estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03439</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithms for inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Icml</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka. F-Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00709</idno>
		<title level="m">Training generative neural samplers using variational divergence minimization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03498</idno>
		<title level="m">Improved techniques for training gans</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theano</forename><surname>Development Team</surname></persName>
		</author>
		<idno>abs/1605.02688</idno>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Energy-based generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03126</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Maximum entropy inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anind K</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1433" to="1438" />
		</imprint>
		<respStmt>
			<orgName>EGAN-Ent-NN (b) EGAN-Const (c) GAN</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Figure 9: 1000 generated and test images (bounding box) ranked according their assigned energies</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
