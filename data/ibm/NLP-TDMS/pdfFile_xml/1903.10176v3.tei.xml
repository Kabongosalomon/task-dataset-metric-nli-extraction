<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DeepRED: Deep Image Prior Powered by RED</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="201924-10-25">October 25, 2019 24 Oct 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Mataev</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Computer Science Department</orgName>
								<orgName type="institution">the Technion</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
							<email>melad@google.com.</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Google Research and Machine Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Milanfar</surname></persName>
							<email>milanfar@google.com.</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Google Research and Machine Intelligence</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DeepRED: Deep Image Prior Powered by RED</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="201924-10-25">October 25, 2019 24 Oct 2019</date>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Inverse problems in imaging are extensively studied, with a variety of strategies, tools, and theory that have been accumulated over the years. Recently, this field has been immensely influenced by the emergence of deep-learning techniques. One such contribution, which is the focus of this paper, is the Deep Image Prior (DIP) work by Ulyanov, Vedaldi, and Lempitsky (2018). DIP offers a new approach towards the regularization of inverse problems, obtained by forcing the recovered image to be synthesized from a given deep architecture. While DIP has been shown to be quite an effective unsupervised approach, its results still fall short when compared to state-of-the-art alternatives.</p><p>In this work, we aim to boost DIP by adding an explicit prior, which enriches the overall regularization effect in order to lead to better-recovered images. More specifically, we propose to bring-in the concept of Regularization by Denoising (RED), which leverages existing denoisers for regularizing inverse problems. Our work shows how the two (DIP and RED) can be merged into a highly effective unsupervised recovery process while avoiding the need to differentiate the chosen denoiser, and leading to very effective results, demonstrated for several tested problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Inverse problems in imaging center around the recovery of an unknown image x based on given corrupted measurement y. These problems are typically posed as energy minimization tasks, drawing their mathematical formulation from a statistical (Bayesian) modeling of the posterior distribution, P (x|y). As inverse problems tend to be ill-posed, a key in the success of the recovery process is the choice of the regularization, which serves as the image prior that stabilizes the degradation inversion, and directs the outcome towards a more plausible image.</p><p>The broad field of inverse problems in imaging has been extensively explored in the past several decades. This vast work has covered various aspects, ranging from the formulation of such problems, through the introduction of diverse ways to pose and use the regularization, and all the way to optimization techniques for minimizing the obtained energy function.</p><p>This massive research effort has led to one of the most prominent fields in the broad arena of imaging sciences, and to many success stories in applications, treating problems such as denoising, deblurring, inpainting, super-resolution, tomographic reconstruction, and more.</p><p>The emergence of deep-learning a decade ago brought a revolution to the way machine learning is practiced. At first, this feat mostly focused on supervised classification tasks, leading to state-of-the-art results in challenging recognition applications. However, this revolution found its way quite rapidly to inverse problems in imaging, due to the ability to consider these as specific regression problems. The practiced rationale in such schemes is as follows: Given many examples of pairs of an original image and its corrupted version, one could learn a deep network to match the degraded image to its source. This became a commonly suggested and very effective path to the above-described classical Bayesian alternative, see e.g., <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>The recent work by Ulyanov et. al. <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> is an exceptional contribution in the intersection between inverse problems and deep-learning. This work presents the Deep Image Prior (DIP) method, a new strategy for handling the regularization task in inverse problems. Rather than taking the supervised avenue, as most earlier methods do, DIP suggests to use the deep network itself as the regularizer to the inverse problem. More specifically, DIP removes the explicit regularization, and replaces it by the assumption that the unknown image x should be a generated image from a learned network. DIP fits the network's parameters for the corrupted image, this way adapting it per each image to be treated. Our special interest in this work stems from the brilliant idea of implicitly using the structure of a network 1 to obtain a regularization effect in recovering x.</p><p>While DIP has been shown to be quite effective, and demonstrated successfully on several inverse problems (denoising, JPEG artifact removal, inpainting, and super-resolution), its results still fall short when compared to unsupervised state-of-the-art alternatives. This brings up the idea to offer an extra boost to DIP by returning the explicit regularization, so as to enrich the implicit one, and this way lead to better recovered images. The natural question is, of-course, which regularization to use, as there are so many options available.</p><p>Interestingly, the need to bring back an extra regularization came up quite recently in the work reported in <ref type="bibr" target="#b14">[15]</ref>, where Total-Variation <ref type="bibr" target="#b16">[16]</ref> has been used and shown to lead to improved recovery results. Another relevant work along these lines is <ref type="bibr" target="#b17">[17]</ref>, in which Stein's Unbiased Risk Estimator (SURE) is leveraged to yield an effective regularization expression for boosting DIP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions:</head><p>In this work we propose to bring in the recently introduced concept of Regularization by Denoising (RED) <ref type="bibr" target="#b18">[18]</ref> and merge it with DIP. The special appeal of RED is threefold: (i) RED produces a wide family of regularization options, each with its own strengths; (ii) RED can use any denoiser 2 ; and (iii) RED is superior to many other regularization schemes. In this work we use NLM <ref type="bibr" target="#b19">[19]</ref> and BM3D <ref type="bibr" target="#b20">[20]</ref> as the two denoisers within RED. Both bring an extra force that does not exist in DIP, due to their reliance on the self-similarity property. This adds a non-locality flavor to our overall recovery algorithm, 1 ... and possibly the optimization strategy as well. <ref type="bibr" target="#b1">2</ref> And this includes a TV-based denoising, implying that the work reported in <ref type="bibr" target="#b14">[15]</ref> can be considered as a special case of our approach. Deep-learning based denoisers, e.g. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref> can be used as well.</p><p>which complements the DIP architecture regularization effect.</p><p>A special challenge in our work is finding a way to train the new compound objective, DIP+RED, while avoiding an explicit differentiation of the denoising function. This is achieved using the Alternating Directions Methods of Multipliers (ADMM) <ref type="bibr" target="#b21">[21]</ref>, which enjoys an extra side-benefit: a stable recovery with respect to the stopping rule employed.</p><p>The proposed scheme, termed DeepRED, is tested on image denoising, single image superresolution, and image deblurring, showing the clear benefit that RED provides. The obtained results exhibit marked improvements, both with respect to the native RED as reported in <ref type="bibr" target="#b18">[18]</ref>, and DIP itself. Indeed, DeepRED shows state-of-the-art results among unsupervised methods for the image deblurring task (when compared to <ref type="bibr" target="#b22">[22]</ref>).</p><p>This paper is organized as follows: The next section presents background material on the inverse problems we target in this work, as well as describing DIP and RED, the two pillars of this work. In Section 3 we present the combined DeepRED scheme, and develop the ADMM algorithm for its training. Section 4 presents our experimental results, validating the benefits of the additional explicit regularization on a series of inverse problems. We conclude the paper in Section 5 by summarizing its message and results and proposing potential future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we give more details on the inverse problems we target, and briefly present both the Deep Image Prior (DIP) approach and the concept of Regularization by Denoising (RED).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Inverse Problems of Interest</head><p>Within the broad field of inverse problems, our work considers the case where the measurement y is given by y = Hx + v, where H is any known linear degradation matrix, and v is an Additive White Gaussian Noise (AWGN). The recovery of x from y could be obtained by solving</p><formula xml:id="formula_0">min x 1 2 Hx − y 2 2 + λρ(x),<label>(1)</label></formula><p>where ρ(x) serves as the chosen regularization term. By modifying the operator H, we can switch between several popular problems in image recovery:</p><p>• Denoising is obtained for H = I,</p><p>• Deblurring (deconvolution) assumes that H is a convolution filter,</p><p>• Inpainting is obtained when H is built as the identity matrix with missing rows referring to missing samples,</p><p>• Super-resolution refers to a matrix H that represents both a blur followed by a sub-sampling, and</p><p>• Tomographic reconstruction assumes that H applies the Radon projections or portion thereof.</p><p>We stress that the paradigm presented in this paper could be easily extended to handle other types of noise (e.g., Laplace, Poisson, Gamma, or other models). This should be done by replacing the expression Hx − y 2 2 by the minus log-likelihood of the appropriate distribution, as done in <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b25">25]</ref> in the context of the Poisson noise. Note that our view on this matter is somewhat different from the view of the authors of <ref type="bibr" target="#b12">[13]</ref>, who suggest to handle other types of noise while still using the L 2 penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Image Prior (DIP)</head><p>DIP embarks from the formulation posed in Equation (1), and starts by removing the regularization term ρ(x). The idea is to find the minimizer of the first term, Hx − y 2 2 . However, this amounts to the Maximum-Likelihood Estimate (MLE), which is known to perform very poorly for the inverse problem cases considered in this paper. DIP overcomes this weakness by assuming that the unknown, x, should be the output of a deep network,</p><formula xml:id="formula_1">x = T Θ (z),</formula><p>where z is a fixed random vector, and Θ stands for the network's parameters to be learned. Thus, DIP suggests to solve</p><formula xml:id="formula_2">min Θ ||HT Θ (z) − y|| 2 2 ,<label>(2)</label></formula><p>and presents T Θ (z) as the recovered image.</p><p>Observe that the training of Θ itself serves also as the inference, i.e., this raining is the recovery process, and this should be done for each input image separately and independently.</p><p>This procedure is "unsupervised" in the sense that no ideal outcome (label) is presented to the learning. Rather, the training is guided by the attempt to best match the output of the network to the measured and corrupted image. Over-fitting in this case amounts to a recovery of x that minimizes the above L 2 expression while being of poor visual quality. This is avoided due to the implicit regularization imposed by the architecture of the network T Θ (z) and the early stopping. <ref type="bibr" target="#b2">3</ref> Indeed, the fact that DIP operates well and recovers high quality images could be perceived as a manifestation of the "correctness" of the chosen architecture to represent image synthesis.</p><p>In practice, DIP performs very well. The work in <ref type="bibr" target="#b12">[13]</ref> reports several sets of experiments on (i) image denoising -leading to performance that is little bit weaker than CBM3D <ref type="bibr" target="#b20">[20]</ref> and better than NLM <ref type="bibr" target="#b19">[19]</ref>; (ii) Single Image Super-Resolution -leading to substantially better results than bicubic interpolation and TV-based restoration, but inferior to the learning based methods <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b27">27]</ref>; and (iii) Inpainting -in which the results are shown to be much better than CSC-based ones <ref type="bibr" target="#b28">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Regularization by Denoising (RED)</head><p>The quest for an effective regularization for inverse problems in imaging has played a central role in the vast progress of this field. Various ideas were brought to serve the construction of ρ(x) in Equation <ref type="formula" target="#formula_0">(1)</ref>, all aiming to identify sources of inner structure in visual data.</p><p>These may rely on piecewise spatial smoothness (e.g., <ref type="bibr" target="#b16">[16]</ref>), self-similarity across different positions and scales (e.g., <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b29">29]</ref>), sparsity with respect to a properly chosen transform or representation (e.g. <ref type="bibr" target="#b20">[20]</ref>), and more.</p><p>Among the various inverse problems mentioned above, denoising has gained a unique position due to its relative simplicity. This problem has become the de-facto testbed for exploring new regularization ideas. As a consequence, many highly effective and trustworthy denoising algorithms were developed in the past two decades. This brought a surprising twist in the evolution of regularizers, turning the table and seeking a way to construct a regularization by using denoising algorithms. The plug-and-play-prior <ref type="bibr" target="#b30">[30]</ref> and the Regularization by Denoising (RED) <ref type="bibr" target="#b18">[18]</ref> are two prime such techniques for turning a denoiser into a regularization. RED suggests to use the following as the regularization function:</p><formula xml:id="formula_3">ρ(x) = 1 2 x T (x − f (x)),<label>(3)</label></formula><p>where f (·) is a denoiser of choice. We will not dwell on the rationale of this expression, beyond stating its close resemblance to a spatial smoothness term. Amazingly, under mild conditions 4 on f (·), two key and highly beneficial properties are obtained: (i) The gradient of ρ(·) w.r.t. x is simple and given by ∇ρ(x) = x − f (x), which avoids differentiating the denoiser function; and (ii) ρ(·) is a convex functional. The work reported in <ref type="bibr" target="#b18">[18]</ref> introduced the concept of RED and showed how to leverage these two properties in order to obtain an effective regularization for various inverse problems. Our goal in this work is to bring this method to DIP, with the hope to boost its performance.</p><p>3 The Proposed DeepRED Scheme</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Algorithm Derivation</head><p>Merging DIP 5 and RED, our objective function becomes</p><formula xml:id="formula_4">min x,Θ 1 2 HT Θ (z) − y 2 2 + λ 2 x T (x − f (x)) (4) s.t. x = T Θ (z).</formula><p>Note that a simple strategy is to avoid the use of x and define the whole optimization w.r.t.</p><p>the unknowns Θ. This calls for solving</p><formula xml:id="formula_5">min Θ 1 2 HT Θ (z) − y 2 2 + λ 2 [T Θ (z)] T ([T Θ (z)] − f ([T Θ (z)])) .</formula><p>While this may seem simpler, it is in fact leading to a near dead-end, since back-propagating over T calls for the differentiation of the denoising function f (·). For most denoisers this would be a daunting task that must be avoided. As we have explained above, under mild conditions, RED enjoys the benefit of avoiding such a direct differentiation, and we would like to leverage this property here.</p><p>The remedy to this problem comes in the form of the Alternating Directions Method of Multipliers (ADMM) <ref type="bibr" target="#b21">[21]</ref>. Starting with Equation <ref type="formula">(4)</ref>, we turn the constraint into a penalty using the Augmented Lagrangian (AL) <ref type="bibr" target="#b32">[32]</ref>:</p><formula xml:id="formula_6">min x,Θ 1 2 HT Θ (z) − y 2 2 + λ 2 x T (x − f (x))<label>(5)</label></formula><formula xml:id="formula_7">+ µ 2 x − T Θ (z) 2 2 − µu T (x − T Θ (z)) .</formula><p>In this expression u stands for the Lagrange multipliers vector for the set of equality constraints, and µ is a free parameter to be chosen. Merging the last two terms, we get the 5 Note that all the derivations and algorithms proposed in this paper are applicable just as well to</p><p>Deep-Decoder <ref type="bibr" target="#b31">[31]</ref>, an appealing followup work to DIP that promotes a simpler architecture for T Θ (z).</p><p>scaled form of the AL <ref type="bibr" target="#b32">[32]</ref>,</p><formula xml:id="formula_8">min x,Θ 1 2 HT Θ (z) − y 2 2 + λ 2 x T (x − f (x))<label>(6)</label></formula><formula xml:id="formula_9">+ µ 2 x − T Θ (z) − u 2 2 .</formula><p>The ADMM algorithm amounts to a sequential update of the three unknowns in this expression: Θ, x, and u. Fixing x and u, the update of Θ is done by solving</p><formula xml:id="formula_10">min Θ 1 2 HT Θ (z) − y 2 2 + µ 2 x − T Θ (z) − u 2 2 ,<label>(7)</label></formula><p>which is very close in spirit to the optimization done in DIP (using back-propagation), modified by a proximity regularization that forces T Θ (z) to be close to x−u. This proximity term provides as an additional stabilizing and robustifying effect to the DIP minimization.</p><p>Fixing Θ and u, x should be updated by solving</p><formula xml:id="formula_11">min x λ 2 x T (x − f (x)) + µ 2 x − T Θ (z) − u 2 2 .<label>(8)</label></formula><p>This is a classic RED objective <ref type="bibr" target="#b18">[18]</ref>, representing a denoising of the image T Θ (z) + u, and we suggest solving it in one of two ways: The first option is using the fixed-point strategy by zeroing the derivative of the above w.r.t. x, and exploiting the fact that ∇ρ(x) = x − f (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This leads to</head><p>λ</p><formula xml:id="formula_12">(x − f (x)) + µ (x − T Θ (z) − u) = 0.<label>(9)</label></formula><p>Assigning indices to the above equation,</p><formula xml:id="formula_13">λ (x j+1 − f (x j )) + µ (x j+1 − T Θ (z) − u) = 0<label>(10)</label></formula><p>leads to the update formula</p><formula xml:id="formula_14">x j+1 = 1 λ + µ (λf (x j ) + µ(T Θ (z) + u)) .<label>(11)</label></formula><p>Applying this iterative update several times provides the needed update for x. An alternative approach for updating x is a simpler steepest-descent, using the above described gradient.</p><p>Thus, the update equation would be</p><formula xml:id="formula_15">x j+1 = x j − c [λ (x j − f (x j )) + µ (x j − T Θ (z) − u)] ,<label>(12)</label></formula><p>and c should be chosen so as to guarantee a descent.</p><p>As for the Lagrange multipliers vector u, its update is much easier, given by u k+1 = u k − x + T Θ (z), as emerging from the AL method <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b32">32]</ref>. Algorithm 1 summarizes the steps to be taken to apply this overall algorithm for handling the DeepRED objective minimization.</p><p>Algorithm 1: ADMM Minimization of the DeepRED objective (Equation <ref type="formula">(4)</ref>).</p><p>Result: Obtain the restored image x Parameters:</p><p>• λ -the RED regularization strength</p><p>• µ -the ADMM free parameter </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>The original DIP algorithm <ref type="bibr" target="#b12">[13]</ref> offers three features that influence the output quality of the restored images. The first is an early stopping, which prevents the network from overfitting to the measurements. The second is a smoothing applied on the outcome of the last iterations, and the third is an averaging over separate runs with a different random vector z. Our tests implement all these as well, but we emphasize that the early stopping is relevant in our DeepRED scheme only for saving computations, as the explicit regularization robustifies the recovery from the risk of overfitting.</p><p>Due to the involvement of a highly non-linear system T Θ (z) in our overall optimization, no convergence guarantees can be provided. In addition, when using denoisers that violate the conditions posed in <ref type="bibr" target="#b18">[18]</ref>, the denoising residual x − f (x) is no longer the exact derivative of the RED prior. Nevertheless, as we show in the experimental results, tendency for a consistent descent and a convergence are obtained empirically.</p><p>In our tests we have chosen J = 1, which means that the denoiser f (·) is applied once in each ADMM round of updates. The heaviest loads in our algorithm are both the update of Θ and the activation of the denoiser. Fortunately, we can speed the overall run of the algorithm by adopting the following two measures: (i) The denoiser and the update of Θ can be run in parallel, as shown in <ref type="figure" target="#fig_2">Figure 1</ref>; and (ii) We apply the denoiser once every few outer iterations of the ADMM in order to save run-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We now present a series of experiments in which we test the proposed DeepRED scheme.</p><p>We consider three applications: image denoising and Single Image Super-Resolution (SISR), which were also studied in <ref type="bibr" target="#b12">[13]</ref>, and image deblurring, following the experiments reported in <ref type="bibr" target="#b18">[18]</ref> and <ref type="bibr" target="#b22">[22]</ref>. Our aim in all these experiments is to show that (i) DeepRED behaves well numerically; (ii) it is better than both DIP and RED; (iii) it performs better than DIP+TV <ref type="bibr" target="#b11">[12]</ref>; and (iv) DeepRED is the among the best unsupervised restoration algorithms, taking the lead in image deblurring.</p><p>In all the reported tests the same network as in <ref type="bibr" target="#b12">[13]</ref> is used with an i.i.d. uniform  rate (LR), the employed denoiser and the noise level fed to it σ f , the values of λ and µ (see <ref type="bibr" target="#b0">1)</ref>, and the number of iterations. All the reported results for DIP are obtained by directly running the released code. We note that there are slight changes between the values we get and the ones reported in <ref type="bibr" target="#b12">[13]</ref>.</p><p>When using DeepRED, we employ the Fixed-Point Strategy as described in 1, and apply the denoiser once (J = 1) every 10 iterations. Following <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b33">[33]</ref>, in the deblurring and super-resolution experiments, the results are compared on the luminance channel, whereas the denoising results are evaluated with all three channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Image Denoising</head><p>In this experiment, which follows the one in <ref type="bibr" target="#b12">[13]</ref>, the goal is to remove a white additive Gaussian noise with σ = 25 from the given images. We evaluate our results on 9 color Comparing our results to the ones in <ref type="bibr" target="#b14">[15]</ref> poses some difficulties, since their performance is given in SNR and not PSNR. Also, we suspect that DIP is poorly functioning in their tests due to the excessive number of iterations used. Disregarding these reservations, we may state that <ref type="bibr" target="#b14">[15]</ref> reports of an 0.24dB improvement over DIP in image denoising with σ = 25, whereas our gain stands on 0.71dB. We should mention <ref type="bibr" target="#b34">[34]</ref> -another recent improvement over DIP that relies on stochastic gradient Langevin. They report an average of 30.81dB, a 0.43dB behind our result. This again shows the effectiveness and need of RED.</p><p>We use this experiment to briefly discuss run-time of the involved algorithms. Both DIP and DeepRED are quite demanding optimization processes. When used with the same number of iterations (1800), DeepRED is clearly slower due to the additional denoising computations. In this case, the average run-time 7 of DIP on the 9 test images is 6.6 minutes per image, whereas DeepRED requires 9.5 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Single Image Super-Resolution (SISR)</head><p>This experiment follows <ref type="bibr" target="#b12">[13]</ref> as well. Given a low-resolution image, the goal is to recover it's scaled-up version. We test scaling factors of 4 and 8 and compare our results to both DIP <ref type="bibr" target="#b12">[13]</ref> and RED <ref type="bibr" target="#b18">[18]</ref> on two datasets. These results are summarized in <ref type="table" target="#tab_2">Tables 2 and 3</ref>.</p><p>As can be seen, RED+DIP is consistently better than both DIP or RED alone. <ref type="figure" target="#fig_3">Figure 2</ref> presents two visual results taken from these experiments to illustrate the recovery obtained.    Interestingly, DeepRED gets close to the recent supervised SISR methods reported in <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b27">27]</ref>. <ref type="table" target="#tab_5">Table 4</ref> presents these average results, and as can be seen, DeepRED is on par with <ref type="bibr" target="#b26">[26]</ref> for a scale factor of 8 : 1.</p><p>We use this experiment to have a closer look at the numerical behavior of the proposed algorithm. For the image head from Set5, we present in <ref type="figure" target="#fig_6">Figure 3</ref> the loss of DeepRED as given in Equation (4) as a function of the iteration number. As can be seen, there is a consistent descent. However, notice in the zoomed-in version of this graph the small fluctuations around this general descent behavior, which are due to the additional noise   <ref type="bibr" target="#b27">[27]</ref> and Lap <ref type="bibr" target="#b26">[26]</ref>).</p><p>injected in each iteration. The same figure also shows the ADMM equality constraint gap (again, see Equation <ref type="formula">(4)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Image Deblurring</head><p>The next experiments follow similar ones in <ref type="bibr" target="#b18">[18]</ref> and <ref type="bibr" target="#b22">[22]</ref>, in which we are given a blurred and noisy image with a known degradation operator H, and the goal is to restore the original image. We consider two cases: (i) A 9 × 9 uniform blur, and (ii) A 25 × 25 Gaussian blur of width σ = 1.6. In both cases, the blurry image is further contaminated by white additive Gaussian noise with σ n = √ 2. We present two comparisons, one using color images (Table    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>DIP is a deep-learning-based unsupervised restoration algorithm of great appeal. This work offers a way to further boost its performance. Our solution relies on RED -the concept of regularizing inverse problems using an existing denoising algorithm. As demonstrated in this paper, DeepRED is a very effective machine for handling various inverse problems.</p><p>Further work is required in order to better understand and improve this scheme: (i) Both DIP and DeepRED should be sped-up in order to make them more practical and appealing.</p><p>This may be within reach with alternative optimization strategies; (ii) Incorporating better denoisers within the RED scheme (perhaps deep-learning based ones) may lead to further boost in performance; (iii) A more thorough study of the regularization effect that DIP introduces may help in devising a complementary explicit regularization to add via RED, thereby getting a stronger effect and better performance; and (iv) The DIP approach (with or without RED) has an important advantage over supervised regression methods:  <ref type="table" target="#tab_6">Table 6</ref>: Gray-scale image deblurring results (Set5).</p><p>Whereas the latter aims for a Minimum-Mean-Squared-Error estimation, DIP(+RED) is a Maximum-A'posteriori Probability estimate by definition, a fact that implies a better expected perceptual quality at the cost of a reduced PSNR. A more in-depth study of this matter is central to the understanding of both these restoration strategies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>Steepest-descent parameters for updating Θ • c -Step-size in the SD update of x • J -number of inner iterations for the update of x Init: Set k = 0, u 0 = 0, x 0 = y, and set Θ 0 randomly while not converged do Update Θ k+1 : Solve Equation (7) using steepest descent and back-propagation Update x k+1 : Apply either the fixed point (Eq.(11)) or the SD (Eq.(12)) for J iterations Update u k+1 : u k+1 = u k − x k+1 + T Θ k+1 (z) k=k+1 end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>∼ [0, 0.1]) random input tensor of size 32 × W × H, where W × H is the size of the output image to synthesize. Table 1 summarizes the various parameters used for each application. These include the additional noise perturbation standard-deviation (σ noise ), the learning Initialize x, Θ and u = 0 Compute the denoised image f (x) Update Θ Update x Update u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>The denoiser can be applied in parallel to the update of Θ in order to speed-up the overall algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Super resolution results. Top: Flowers (Set14) with scale-factor 4. Bottom: Zebra (Set14) with scale-factor 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>). Clearly, this gap is narrowing, getting very close to the satisfaction of the constraint x = T Θ (z). The last graph shows the PSNR of the output image over the iterations. RED's regularization tends to robustify the overall recovery algorithm against overfitting, which stands in contrast to the behavior of DIP alone. Similar qualitative graphs are obtained for various other images and applications, showing the same tendencies, and thus are omitted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>The numerical behavior obtained in the SISR test on head (Set5): (a) and (b) show the loss as a function of the iteration; (c) presents the output PSNR; and (d) shows the ADMM constraint gap. 5) and the other with gray-scale ones (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Parameters used in the experiments.</figDesc><table><row><cell>Parameters</cell></row></table><note>images 6 . The regularization denoiser we use is Python's scikit-image fast version of Non- Local-Means [19]. The average PSNR (Peak Signal-to-Noise Ratio) of this NLM filter stands on 29.13dB. When plugged into RED, the performance improves to 29.3dB. Turning to DIP and its boosted version, DIP's best result is obtained using both averaging strategies (sliding window and average over two runs) getting to 30.53dB, whereas DeepRED obtains 31.24dB -a 0.71dB improvement.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Super-resolution results for Set5. 25.76 26.00 22.74 32.37 27.29 29.70 31.62 30.76 31.10 24.97 26.78 27.63 RED [FP-BM3D] 22.55 25.76 25.88 22.57 32.60 26.96 29.38 31.56 29.33 31.05 24.50 26.17 27.36 DIP [Our Run] 22.21 25.53 25.82 22.46 31.48 26.55 29.38 30.86 30.27 30.52 24.75 26.04 27.16 DeepRED 21.33 24.02 23.98 20.05 29.95 23.51 25.38 28.12 25.34 27.91 20.69 21.03 24.28 RED [FP-BM3D] 21.29 23.94 23.51 19.84 29.90 23.19 24.62 27.69 24.39 27.45 20.23 20.61 23.89 DIP [Our Run] 21.18 24.01 23.74 19.95 29.65 23.32 25.00 27.92 24.85 27.99 20.59 20.98 24.10</figDesc><table><row><cell></cell><cell>Set14 8 Super-Resolution Results (4:1)</cell></row><row><cell>Algorithm</cell><cell>baboonbarbaracoastgrd comic face flowersforeman lenna monarch pepperppt3 zebra average</cell></row><row><cell>DeepRED</cell><cell>22.51 Set14 Super-Resolution Results (8:1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Super-resolution results for Set14.</figDesc><table><row><cell>Original</cell><cell>Bicubic [25.82dB]</cell><cell>DIP [26.55dB]</cell><cell>DeepRED [27.29dB]</cell></row><row><cell>Original</cell><cell>Bicubic [24.61dB]</cell><cell>DIP [26.04dB]</cell><cell>DeepRED [26.78dB]</cell></row></table><note>8 We use the 12 color images from this data-set.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Average SISR results of DIP and DeepRED versus two leading supervised methods (SRR</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 )</head><label>6</label><figDesc>. In the first, 4 color images 9 are used, and DeepRED is compared with with DIP<ref type="bibr" target="#b12">[13]</ref>, RED<ref type="bibr" target="#b18">[18]</ref> and NCSR Deblur<ref type="bibr" target="#b33">[33]</ref>. In the second experiment 5 gray-scale images from Set5 are tested, and the comparison is with MSWNN<ref type="bibr" target="#b22">[22]</ref>, IRCNN<ref type="bibr" target="#b9">[10]</ref>, RED<ref type="bibr" target="#b18">[18]</ref>, NCSR<ref type="bibr" target="#b33">[33]</ref>, IDD-BM3D<ref type="bibr" target="#b35">[35]</ref>, and EPLL<ref type="bibr" target="#b36">[36]</ref>.Figures 4 and 5 present two sets of inputs and results from the color experiment, showing clearly the benefit of the RED regularization effect. Looking at Tables 5 and 6, DeepRED performs very well, outperforming all the other alternative methods. The blurred images Butterfly and Leaves. Butterfly, Bottom -Leaves.</figDesc><table><row><cell></cell><cell>[19.07dB]</cell><cell>[18.28dB]</cell><cell></cell></row><row><cell cols="2">Figure 4: Original NCSR [29.68dB]</cell><cell>DIP [30.26dB]</cell><cell>DeepRED [31.44dB]</cell></row><row><cell>Original</cell><cell>NCSR [29.98dB]</cell><cell>DIP [30.38dB]</cell><cell>DeepRED [31.21dB]</cell></row><row><cell cols="3">Figure 5: Uniform Deblurring Results: Top -</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Color image deblurring results.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The number of iterations is bounded so as to avoid overfitting.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The function f (·) should be differentiable, have a symmetric Jacobian, satisfy a local homogeneity condition, and be passive.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">http://www.cs.tut.fi/~foi/GCF-BM3D/.<ref type="bibr" target="#b6">7</ref> All the reported simulations are run on Intel (R) Xeon (R) CPU E5-2620 v4 @ 2.10Ghz with a GeForce RTX 2080 Ti GPU.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">http://www4.comp.polyu.edu.hk/~cslzhang/NCSR.htm</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ffdnet: Toward a fast and flexible solution for cnn-based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4608" to="4622" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Universal denoising networks: A novel cnn architecture for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Lefkimmiatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3204" to="3213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep class-aware image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on sampling theory and applications (SampTA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural nearest neighbors networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Plötz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1095" to="1106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Non-local recurrent network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bihan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1680" to="1689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Srfeat: Single image super-resolution with feature discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong-Jin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeongseok</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ki-Sang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungyong</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="439" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image super-resolution using very deep residual channel attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="286" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A fully progressive approach to singleimage super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="864" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning deep cnn denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scale-recurrent network for deep image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8174" to="8182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep multi-scale convolutional neural network for dynamic scene deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjun</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3883" to="3891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Submitted to IJCV</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image restoration using total variation regularized deep image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulugbek S</forename><surname>Kamilov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<biblScope unit="page" from="7715" to="7719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Leonid I Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: nonlinear phenomena</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unsupervised learning with stein&apos;s unbiased risk estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">G</forename><surname>Heckel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baraniuk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10531</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The little engine that could: Regularization by denoising (red)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1804" to="1844" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neal</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-scale weighted nuclear norm image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Yair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Michaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3165" to="3174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Poisson noise reduction with non-local pca</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harmany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Deledalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="279" to="294" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Poisson inverse problems by the plug-and-play scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="96" to="108" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sparsity-based poisson denoising with dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5057" to="5069" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep laplacian pyramid networks for fast and accurate super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional dictionary learning via local processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Vardan Papyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremias</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5306" to="5314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Single image interpolation via adaptive nonlocal sparsity-based modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Protter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3085" to="3098" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Plug-andplay priors for model based reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singanallur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">A</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendt</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Conference on Signal and Information Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="945" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep decoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Heckel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Concise image representations from untrained non-convolutional networks. International conference on learning representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fast image recovery using variable splitting and constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manya V Afonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mário</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2345" to="2356" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weisheng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A bayesian perspective on the deep image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezhou</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matheus</forename><surname>Gadelha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sheldon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5443" to="5451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Image restoration by sparse 3d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing: Algorithms and Systems VI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">6812</biblScope>
			<biblScope unit="page">681207</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
