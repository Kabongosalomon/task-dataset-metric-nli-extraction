<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ADVERSARIAL LIPSCHITZ REGULARIZATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dávid</forename><surname>Terjék</surname></persName>
							<email>david.terjek@hu.bosch.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bosch</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Hungary</roleName><forename type="first">Kft</forename><surname>Budapest</surname></persName>
						</author>
						<title level="a" type="main">ADVERSARIAL LIPSCHITZ REGULARIZATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generative adversarial networks (GANs) are one of the most popular approaches when it comes to training generative models, among which variants of Wasserstein GANs are considered superior to the standard GAN formulation in terms of learning stability and sample quality. However, Wasserstein GANs require the critic to be 1-Lipschitz, which is often enforced implicitly by penalizing the norm of its gradient, or by globally restricting its Lipschitz constant via weight normalization techniques. Training with a regularization term penalizing the violation of the Lipschitz constraint explicitly, instead of through the norm of the gradient, was found to be practically infeasible in most situations. Inspired by Virtual Adversarial Training, we propose a method called Adversarial Lipschitz Regularization, and show that using an explicit Lipschitz penalty is indeed viable and leads to competitive performance when applied to Wasserstein GANs, highlighting an important connection between Lipschitz regularization and adversarial training. arXiv:1907.05681v3 [cs.LG] 3 Jan 2020</p><p>Published as a conference paper at ICLR 2020 Our contributions are as follows:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, Generative adversarial networks (GANs) <ref type="bibr" target="#b11">(Goodfellow et al., 2014)</ref> have been becoming the state-of-the-art in several generative modeling tasks, ranging from image generation <ref type="bibr" target="#b19">(Karras et al., 2018)</ref> to imitation learning <ref type="bibr" target="#b17">(Ho and Ermon, 2016)</ref>. They are based on an idea of a two-player game, in which a discriminator tries to distinguish between real and generated data samples, while a generator tries to fool the discriminator, learning to produce realistic samples on the long run. Wasserstein GAN (WGAN) was proposed as a solution to the issues present in the original GAN formulation. Replacing the discriminator, WGAN trains a critic to approximate the Wasserstein distance between the real and generated distributions. This introduced a new challenge, since Wasserstein distance estimation requires the function space of the critic to only consist of 1-Lipschitz functions.</p><p>To enforce the Lipschitz constraint on the WGAN critic,  originally used weight clipping, which was soon replaced by the much more effective method of Gradient Penalty (GP) <ref type="bibr" target="#b15">(Gulrajani et al., 2017)</ref>, which consists of penalizing the deviation of the critic's gradient norm from 1 at certain input points. Since then, several variants of gradient norm penalization have been introduced <ref type="bibr" target="#b25">(Petzka et al., 2018;</ref><ref type="bibr" target="#b29">Wei et al., 2018;</ref><ref type="bibr" target="#b0">Adler and Lunz, 2018;</ref><ref type="bibr" target="#b33">Zhou et al., 2019b)</ref>.</p><p>Virtual Adversarial Training (VAT) <ref type="bibr" target="#b23">(Miyato et al., 2019</ref>) is a semi-supervised learning method for improving robustness against local perturbations of the input. Using an iterative method based on power iteration, it approximates the adversarial direction corresponding to certain input points. Perturbing an input towards its adversarial direction changes the network's output the most.</p><p>Inspired by VAT, we propose a method called Adversarial Lipschitz Regularization (ALR), enabling the training of neural networks with regularization terms penalizing the violation of the Lipschitz constraint explicitly, instead of through the norm of the gradient. It provides means to generate a pair for each input point, for which the Lipschitz constraint is likely to be violated with high probability. In general, enforcing Lipschitz continuity of complex models can be useful for a lot of applications. In this work, we focus on applying ALR to Wasserstein GANs, as regularizing or constraining Lipschitz continuity has proven to have a high impact on training stability and reducing mode collapse. Source code to reproduce the presented experiments is available at https://github.com/dterjek/adversarial_lipschitz_regularization.</p><p>• We propose Adversarial Lipschitz Regularization (ALR) and apply it to penalize the violation of the Lipschitz constraint directly, resulting in Adversarial Lipschitz Penalty (ALP).</p><p>• Applying ALP on the critic in WGAN (WGAN-ALP), we show state-of-the-art performance in terms of Inception Score and Fréchet Inception Distance among non-progressive growing methods trained on CIFAR-10, and competitive performance in the high-dimensional setting when applied to the critic in Progressive Growing GAN trained on CelebA-HQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND 2.1 WASSERSTEIN GENERATIVE ADVERSARIAL NETWORKS</head><p>Generative adversarial networks (GANs) provide generative modeling by a generator network g that transforms samples of a low-dimensional latent space Z into samples from the data space X, transporting mass from a fixed noise distribution P Z to the generated distribution P g . The generator is trained simultaneously with another network f called the discriminator, which is trained to distinguish between fake samples drawn from P g and real samples drawn from the real distribution P r , which is often represented by a fixed dataset. This network provides the learning signal to the generator, which is trained to generate samples that the discriminator considers real. This iterative process implements the minimax game</p><formula xml:id="formula_0">min g max f E x∼Pr log(f (x)) + E z∼P Z log(1 − f (g(z)))<label>(1)</label></formula><p>played by the networks f and g. This training procedure minimizes the approximate Jensen-Shannon divergence (JSD) between P r and P g <ref type="bibr" target="#b11">(Goodfellow et al., 2014)</ref>. However, during training these two distributions might differ strongly or even have non-overlapping supports, which might result in gradients received by the generator that are unstable or zero .</p><p>Wasserstein GAN (WGAN)  was proposed as a solution to this instability. Originating from Optimal Transport theory <ref type="bibr" target="#b28">(Villani, 2008)</ref>, the Wasserstein metric provides a distance between probability distributions with much better theoretical and practical properties than the JSD. It provides a smooth optimizable distance even if the two distributions have non-overlapping supports, which is not the case for JSD. It raises a metric d X from the space X of the supports of the probability distributions P 1 and P 2 to the space of the probability distributions itself. For these purposes, the Wasserstein-p distance requires the probability distributions to be defined on a metric space and is defined as</p><formula xml:id="formula_1">W p (P 1 , P 2 ) = inf π∈Π(P1,P2) E (x1,x2)∼π d X (x 1 , x 2 ) p 1 p ,<label>(2)</label></formula><p>where Π(P 1 , P 2 ) is the set of distributions on the product space X × X whose marginals are P 1 and P 2 , respectively. The optimal π achieving the infimum in (2) is called the optimal coupling of P 1 and P 2 , and is denoted by π * . The case of p = 1 has an equivalent formulation</p><formula xml:id="formula_2">W 1 (P 1 , P 2 ) = sup f L ≤1 E x∼P1 f (x) − E x∼P2 f (x),<label>(3)</label></formula><p>called the Kantorovich-Rubinstein formula <ref type="bibr" target="#b28">(Villani, 2008)</ref>, where f : X → R is called the potential function, f L ≤ 1 is the set of all functions that are 1-Lipschitz with respect to the ground metric d X , and the Wasserstein-1 distance corresponds to the supremum over all 1-Lipschitz potential functions. The smallest Lipschitz constant for a real-valued function f with the metric space (X, d X ) as its domain is given by</p><formula xml:id="formula_3">f L = sup x,y∈X;x =y |f (x) − f (y)| d X (x, y) .<label>(4)</label></formula><p>Based on (3), the critic in WGAN  implements an approximation of the Wasserstein-1 distance between P g and P r . The minimax game played by the critic f and the generator g becomes min</p><formula xml:id="formula_4">g max f L ≤1 E z∼P Z f (g(z)) − E x∼Pr f (x),<label>(5)</label></formula><p>a formulation that proved to be superior to the standard GAN in practice, with substantially more stable training behaviour and improved sample quality , although recent GAN variants do not always use this objective <ref type="bibr" target="#b5">(Brock et al., 2019)</ref>. With WGAN, the challenge became effectively restricting the smallest Lipschitz constant of the critic f , sparking the birth of a plethora of Lipschitz regularization techniques for neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">LIPSCHITZ FUNCTION APPROXIMATION</head><p>A general definition of the smallest Lipschitz constant of a function f :</p><formula xml:id="formula_5">X → Y is f L = sup x,y∈X;x =y d Y (f (x), f (y)) d X (x, y) ,<label>(6)</label></formula><p>where the metric spaces (X, d X ) and (Y, d Y ) are the domain and codomain of the function f , respectively. The function f is called Lipschitz continuous if there exists a real constant</p><formula xml:id="formula_6">K ≥ 0 for which d Y (f (x), f (y)) ≤ K · d X (x, y)</formula><p>for any x, y ∈ X. Then, the function f is also called K-Lipschitz. Theoretical properties of neural networks with low Lipschitz constants were explored in <ref type="bibr" target="#b24">Oberman and Calder (2018)</ref>, <ref type="bibr" target="#b4">Bartlett (1998)</ref> and <ref type="bibr" target="#b7">Drucker and LeCun (1992)</ref>, showing that it induces better generalization.</p><p>Learning mappings with Lipschitz constraints became prevalent in the field of deep learning with the introduction of WGAN . Enforcing the Lipschitz property on the critic was first done by clipping the weights of the network. This approach achieved superior results compared to the standard GAN formulation, but still sometimes yielded poor quality samples or even failed to converge. While clipping the weights enforces a global Lipschitz constant, it also reduces the function space, which might not include the optimal critic any more. Soon this method has been replaced by a softened one called Gradient Penalty (GP) <ref type="bibr" target="#b15">(Gulrajani et al., 2017)</ref>. Motivated by the fact that the optimal critic should have unit gradient norm on lines connecting the coupled points (x 1 , x 2 ) ∼ π * according to (2), they proposed a regularizer that enforces unit gradient norm along these lines, which not only enforces the Lipschitz constraint, but other properties of the optimal solution as well. However, π * is not known in practice, which is why <ref type="bibr" target="#b15">Gulrajani et al. (2017)</ref> proposed to apply GP on samples of the induced distribution P i , by interpolating samples from the marginals P 1 and P 2 . The critic in the WGAN-GP formulation is regularized with the loss</p><formula xml:id="formula_7">λE x∼Pi ( ∇ x f (x) 2 − 1) 2<label>(7)</label></formula><p>where P i denotes the distribution of samples obtained by interpolating pairs of samples drawn from P r and P g , and λ is a hyperparameter acting as a Lagrange multiplier.</p><p>Theoretical arguments against GP were pointed out by <ref type="bibr" target="#b25">Petzka et al. (2018)</ref> and <ref type="bibr" target="#b10">Gemici et al. (2018)</ref>, arguing that unit gradient norm on samples of the distribution P i is not valid, as the pairs of samples being interpolated are generally not from the optimal coupling π * , and thus do not necessarily need to match gradient norm 1. Furthermore, they point out that differentiability assumptions of the optimal critic are not met. Therefore, the regularizing effect of GP might be too strong. As a solution, <ref type="bibr" target="#b25">Petzka et al. (2018)</ref> suggested using a loss penalizing the violation of the Lipschitz constraint either explicitly with</p><formula xml:id="formula_8">λE x,y∼Pτ |f (x) − f (y)| x − y 2 − 1 2 + (8) or implicitly with λE x∼Pτ ( ∇ x f (x) 2 − 1) 2 +<label>(9)</label></formula><p>where in both cases (a) + denotes max(0, a). The first method has only proved viable when used on toy datasets, and led to considerably worse results on relatively more complex datasets like CIFAR-10, which is why <ref type="bibr" target="#b25">Petzka et al. (2018)</ref> used the second one, which they termed Lipschitz Penalty (LP). Compared to GP, this term only penalizes the gradient norm when it exceeds 1. As P τ they evaluated the interpolation method described above, and also sampling random local perturbations of real and generated samples, but found no significant improvement compared to P i . <ref type="bibr" target="#b29">Wei et al. (2018)</ref> proposed dropout in the critic as a way for creating perturbed input pairs to evaluate the explicit Lipschitz penalty <ref type="formula">(8)</ref>, which led to improvements, but still relied on using GP simultaneously.</p><p>A second family of Lipschitz regularization methods is based on weight normalization, restricting the Lipschitz constant of a network globally instead of only at points of the input space. One such technique is called spectral normalization (SN) proposed in <ref type="bibr" target="#b22">Miyato et al. (2018)</ref>, which is a very efficient and simple method for enforcing a Lipschitz constraint with respect to the 2-norm on a per-layer basis, applicable to neural networks consisting of affine layers and K-Lipschitz activation functions. <ref type="bibr" target="#b13">Gouk et al. (2018)</ref> proposed a similar approach, which can be used to enforce a Lipschitz constraint with respect to the 1-norm and ∞-norm in addition to the 2-norm, while also being compatible with batch normalization and dropout. <ref type="bibr" target="#b1">Anil et al. (2019)</ref> argued that any Lipschitzconstrained neural network must preserve the norm of the gradient during backpropagation, and to this end proposed another weight normalization technique (showing that it compares favorably to SN, which is not gradient norm preserving), and an activation function based on sorting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">VIRTUAL ADVERSARIAL TRAINING</head><p>VAT <ref type="bibr" target="#b23">(Miyato et al., 2019</ref>) is a semi-supervised learning method that is able to regularize networks to be robust to local adversarial perturbation. Virtual adversarial perturbation means perturbing input sample points in such a way that the change in the output of the network induced by the perturbation is maximal in terms of a distance between distributions. This defines a direction for each sample point called the virtual adversarial direction, in which the perturbation is performed. It is called virtual to make the distinction with the adversarial direction introduced in Goodfellow et al. <ref type="formula" target="#formula_0">(2015)</ref> clear, as VAT uses unlabeled data with virtual labels, assigned to the sample points by the network being trained. The regularization term of VAT is called Local Distributional Smoothness (LDS). It is defined as</p><formula xml:id="formula_9">L LDS = D (p(y|x), p(y|x + r vadv )) ,<label>(10)</label></formula><p>where p is a conditional distribution implemented by a neural network, D(p, p ) is a divergence between two distributions p and p , for which <ref type="bibr" target="#b23">Miyato et al. (2019)</ref> chose the Kullback-Leibler divergence (KLD), and</p><formula xml:id="formula_10">r vadv = arg max r 2≤ D (p(y|x), p(y|x + r))<label>(11)</label></formula><p>is the virtual adversarial perturbation, where is a hyperparameter. VAT is defined as a training method with the regularizer (10) applied to labeled and unlabeled examples. An important detail is that (10) is minimized by keeping p(y|x) fixed and optimizing p(y|x + r vadv ) to be close to it.</p><p>The adversarial perturbation is approximated by the power iteration r vadv ≈ r k , where</p><formula xml:id="formula_11">r i+1 ≈ ∇ r D (p(y|x), p(y|x + r)) r=ξri ∇ r D (p(y|x), p(y|x + r)) r=ξri 2 ,<label>(12)</label></formula><p>r 0 is a randomly sampled unit vector and ξ is another hyperparameter. This iterative scheme is an approximation of the direction at x that induces the greatest change in the output of p in terms of the divergence D. <ref type="bibr" target="#b23">Miyato et al. (2019)</ref> found that k = 1 iteration is sufficient in practical situations.</p><p>3 ADVERSARIAL LIPSCHITZ REGULARIZATION <ref type="bibr" target="#b0">Adler and Lunz (2018)</ref> argued that penalizing the norm of the gradient as in <ref type="formula" target="#formula_8">(9)</ref> is more effective than penalizing the Lipschitz quotient directly as in <ref type="formula">(8)</ref>, as the former penalizes the slope of f in all spatial directions around x, unlike the latter, which does so only along (x − y). We hypothesize that using the explicit Lipschitz penalty in itself is insufficient because if one takes pairs of samples x, y randomly from P r , P g or P i (or just one sample and generates a pair for it with random perturbation), the violation of the Lipschitz penalty evaluated at these sample pairs will be far from its maximum, hence a more sophisticated strategy for sampling pairs is required. As we will show, a carefully chosen sampling strategy can in fact make the explicit penalty favorable over the implicit one.</p><p>Consider the network f as a mapping from the metric space (X, d X ) to the metric space (Y, d Y ). Let us rewrite (6) with y = x + r to get</p><formula xml:id="formula_12">f L = sup x,x+r∈X;0&lt;d X (x,x+r) d Y (f (x), f (x + r)) d X (x, x + r) .<label>(13)</label></formula><p>A given mapping f is K-Lipschitz if and only if for any given x ∈ X, taking the supremum over r in (13) results in a value K or smaller. Assuming that this supremum is always achieved for some r, we can define a notion of adversarial perturbation with respect to the Lipschitz continuity for a given x ∈ X as</p><formula xml:id="formula_13">r adv = arg max x+r∈X;0&lt;d X (x,x+r) d Y (f (x), f (x + r)) d X (x, x + r) ,<label>(14)</label></formula><p>and the corresponding maximal violation of the K-Lipschitz constraint as</p><formula xml:id="formula_14">L ALP = d Y (f (x), f (x + r adv )) d X (x, x + r adv ) − K + .<label>(15)</label></formula><p>We define Adversarial Lipschitz Regularization (ALR) as the method of adding (15) as a regularization term to the training objective that penalizes the violation of the Lipschitz constraint evaluated at sample pairs obtained by adversarial perturbation. We call this term Adversarial Lipschitz Penalty (ALP).</p><p>To put it in words, ALP measures the deviation of f from being K-Lipschitz evaluated at pairs of sample points where one is the adversarial perturbation of the other. If added to the training objective, it makes the learned mapping approximately K-Lipschitz around the sample points it is applied at. We found that in the case of the WGAN critic it is best to minimize (15) without keeping f (x) fixed. See Appendix A.1 for the semi-supervised case and Appendix A.2 for how VAT can be seen as a special case of Lipschitz regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">APPROXIMATION OF r adv</head><p>In general, computing the adversarial perturbation <ref type="formula" target="#formula_0">(14)</ref> is a nonlinear optimization problem. A crude and cheap approximation is</p><formula xml:id="formula_15">r adv ≈ r k , where r i+1 ≈ ∇ r d Y (f (x), f (x + r)) r=ξri ∇ r d Y (f (x), f (x + r)) r=ξri 2 ,<label>(16)</label></formula><p>is the approximated adversarial direction with r 0 being a randomly sampled unit vector. The derivation of this formula is essentially the same as the one described in <ref type="bibr" target="#b23">Miyato et al. (2019)</ref>, but is included in Appendix A.3 for completeness. Unlike in VAT, we do not fix , but draw it randomly from a predefined distribution P over R + to apply the penalty at different scales.</p><p>Theoretically, ALR can be used with all kinds of metrics d X and d Y , and any kind of model f , but the approximation of r adv imposes a practical restriction. It approximates the adversarial perturbation of x as a translation with length with respect to the 2-norm in the adversarial direction, which is only a perfect approximation if the ratio in <ref type="formula" target="#formula_0">(15)</ref> is constant for any &gt; 0. This idealized setting is hardly ever the case, which is why we see the search for other approximation schemes as an important future direction. There is a large number of methods for generating adversarial examples besides the one proposed in VAT <ref type="bibr" target="#b27">(Shafahi et al., 2019;</ref><ref type="bibr" target="#b30">Wong et al., 2019;</ref><ref type="bibr" target="#b20">Khrulkov and Oseledets, 2018)</ref>, which could possibly be combined with ALR either to improve the approximation performance or to make it possible with new kinds of metrics. The latter is important since one of the strengths of the Wasserstein distance is that it can be defined with any metric d X , a fact that <ref type="bibr" target="#b0">Adler and Lunz (2018)</ref> and <ref type="bibr" target="#b8">Dukler et al. (2019)</ref> built on by extending GP to work with metrics other than the Euclidean distance. <ref type="bibr" target="#b0">Adler and Lunz (2018)</ref> emphasized the fact that through explicit Lipschitz penalties one could extend WGANs to more general metric spaces as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">HYPERPARMETERS</head><p>In practice, one adds the Monte Carlo approximation of the expectation (averaged over a minibatch of samples) of either (15) or the square of (15) (or both) to the training objective, multiplied by a Lagrange multiplier λ. While VAT adds the expectation of (10) to the training objective, for WGAN we have added the square of the expectation of (15). To train the Progressive GAN, we have added both the expectation and its square. In the semi-supervised setting, we added only the expectation similarly to VAT. We have found these choices to work best in these scenarios, but a principled answer to this question is beyond the scope of this paper. The target Lipschitz constant K can be tuned by hand, or in the presence of labeled data it is possible to calculate the Lipschitz constant of the dataset <ref type="bibr" target="#b24">(Oberman and Calder, 2018)</ref>. The hyperparameters of the approximation scheme are k, ξ and those of P .</p><p>Choosing the right hyperparameters can be done by monitoring the number of adversarial perturbations found by the algorithm for which the Lipschitz constraint is violated (and hence contribute a nonzero value to the expectation of (15)), and tuning the hyperparameters in order to keep this number balanced between its maximum (which is the minibatch size) and its minimum (which is 0). If it is too high, it means that either K is too small and should be increased, or the regularization effect is too weak, so one should increase λ. If it is too low, then either the regularization effect is too strong, or ALR is parametrized in a way that it cannot find Lipschitz constraint violations efficiently.</p><p>In the former case, one should decrease λ.</p><p>In the latter, one should either decrease K, tune the parameters of P , or increase the number of power iterations k for the price of increased runtime. We have not observed any significant effect when changing the value of ξ in any of the tasks considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">COMPARISON WITH OTHER LIPSCHITZ REGULARIZATION TECHNIQUES</head><p>In terms of efficiency when applied to WGANs, ALR compares favorably to the implicit methods penalizing the gradient norm, and to weight normalization techniques as well, as demonstrated in the experiments section. See Appendix A.4 for a showcase of the differences between weight normalization methods, implicit penalty methods and explicit penalty methods, represented by SN, LP and ALR, respectively. The key takeaways are that</p><p>• penalty methods result in a softer regularization effect than SN,</p><p>• ALR is preferable when the regularized network contains batch normalization (BN) layers, and • ALR gives more control over the regularization effect, which also means there are more hyperparameters to tune.</p><p>The performance of ALR mostly depends on the speed of the approximation of r adv . The current method requires 1 step of backpropagation for each power iteration step, which means that running time will be similar to that of LP and GP with k = 1. SN is much cheaper computationally than each penalty method, although we believe ALR has the potential to become relatively cheap as well by adopting new techniques for obtaining adversarial examples <ref type="bibr" target="#b27">(Shafahi et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">WGAN-ALP</head><p>We specialize the ALP formula (15) with f being the critic, d X (x, y) = x − y 2 , d Y (x, y) = |x − y| and K = 1, and apply it to the WGAN objective to arrive at a version with the explicit penalty, which uses adversarial perturbations as a sampling strategy. It is formulated as</p><formula xml:id="formula_16">E z∼P Z f (g(z)) − E x∼Pr f (x) + λE x∼Pr,g |f (x) − f (x + r adv )| r adv 2 − 1 2 + ,<label>(17)</label></formula><p>where P r,g is a combination of the real and generated distributions (meaning that a sample x can come from both), λ is the Lagrange multiplier, and the adversarial perturbation is defined as</p><formula xml:id="formula_17">r adv = arg max r;0&lt; r 2 |f (x) − f (x + r)| r 2 .<label>(18)</label></formula><p>This formulation of WGAN results in a stable explicit Lipschitz penalty, overcoming the difficulties experienced when one tries to apply it to random sample pairs as shown in <ref type="bibr" target="#b25">Petzka et al. (2018)</ref>.</p><p>To evaluate the performance of WGAN-ALP, we trained one on CIFAR-10, consisting of 32 × 32 RGB images, using the residual architecture from <ref type="bibr" target="#b15">Gulrajani et al. (2017)</ref>, implemented in TensorFlow. Closely following <ref type="bibr" target="#b15">Gulrajani et al. (2017)</ref>, we used the Adam optimizer <ref type="bibr" target="#b21">(Kingma and Ba, 2015)</ref> with parameters β 1 = 0, β 2 = 0.9 and an initial learning rate of 2 × 10 −4 decaying linearly to 0 over 100000 iterations, training the critic for 5 steps and the generator for 1 per iteration with minibatches of size 64 (doubled for the generator). We used <ref type="formula" target="#formula_0">(17)</ref> as a loss function to optimize the critic. K = 1 was an obvious choice, and we found λ = 100 to be optimal (the training diverged for λ = 0.1, and was stable but performed worse for λ = 10 and 1000). The hyperparameters of the approximation of r adv were set to ξ = 10, P being the uniform distribution over [0.1, 10], and k = 1 power iteration. Both batches from P r and P g were used for regularization.</p><p>We used Inception Score <ref type="bibr" target="#b26">(Salimans et al., 2016)</ref> and FID <ref type="bibr" target="#b16">(Heusel et al., 2017)</ref> as our evaluation metrics. The former correlates well with human judgment of image quality and is the most widely used among GAN models, and the latter has been shown to capture model issues such as mode collapse, mode dropping and overfitting, while being a robust and efficient metric <ref type="bibr" target="#b31">(Xu et al., 2018)</ref>. We monitored the Inception Score and FID during training using 10000 samples every 1000 iteration, and evaluated them at the end of training using 50000 samples. We ran the training setting described above 10 times with different random seeds, and calculated the mean and standard deviation of the final Inception Scores and FIDs, while also recording the maximal Inception Score observed during training. We report these values for WGAN-ALP and other relevant GANs <ref type="bibr" target="#b15">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b25">Petzka et al., 2018;</ref><ref type="bibr" target="#b32">Zhou et al., 2019a;</ref><ref type="bibr" target="#b29">Wei et al., 2018;</ref><ref type="bibr" target="#b22">Miyato et al., 2018;</ref><ref type="bibr" target="#b0">Adler and Lunz, 2018;</ref><ref type="bibr" target="#b19">Karras et al., 2018)</ref> in <ref type="table" target="#tab_0">Table 1</ref>. We did not run experiments to evaluate competing models, but included the values reported in the corresponding papers (with the exception of the FID for WGAN-GP, which was taken from <ref type="bibr" target="#b32">Zhou et al. (2019a)</ref>). They used different methods to arrive at the cited results, from which that of <ref type="bibr" target="#b0">Adler and Lunz (2018)</ref> is the one closest to ours. We show some generated samples in <ref type="figure">Figure 1a</ref>.  <ref type="figure">Figure 1</ref>: Generated CIFAR-10 samples</p><p>We also trained WGAN-LP in our implementation. During training, the best observed Inception Score and FID were 8.13 and 18.49, while at the end of training the best final Inception Score and FID were 8.01 and 15.42. To see that ALR indeed restricts the Lipschitz constant of the critic, we monitored the gradient norms during training, which converged to ≈ 5 with λ = 100. This was also the case using LP with λ = 0.1, but the number of Lipschitz constraint violations found by the algorithm were much higher in this case than with ALR.</p><p>Our toy example in Appendix A.4 showed that when the regularized network contains BN layers, ALR seems to work better than competing methods. In order to see if this still applies in more complex settings, we have trained a variant of WGAN in which the critic <ref type="figure">contains BN layers (WGAN-BN)</ref>. <ref type="bibr" target="#b15">Gulrajani et al. (2017)</ref> did not use BN in the critic as they argued that GP is not valid in that setting, and indeed when we trained WGAN-BN with GP, the best Inception Score observed during training was only 6.29. When we applied ALP to WGAN-BN, the results were nearly on par with the original setting without BN, producing an even better maximal Inception Score of 8.71. We leave the question of how BN affects Lipschitz continuity for future work. Generated samples are shown in <ref type="figure">Figure 1b</ref>. <ref type="bibr" target="#b15">Gulrajani et al. (2017)</ref> made the distinction between one-sided and two-sided penalties, represented by <ref type="formula" target="#formula_8">(9)</ref> and <ref type="formula" target="#formula_7">(7)</ref>. The latter is based on the fact that in WGAN, the optimal critic has unit gradient norm on lines connecting points from the optimal coupling π * . <ref type="bibr" target="#b25">Petzka et al. (2018)</ref> showed that since π * is not known in practice, one should use the one-sided penalty, while <ref type="bibr" target="#b10">Gemici et al. (2018)</ref> proposed a method to approximate π * with an auto-encoding scheme. In the limit r 2 → 0 the expression inside the arg max operator in <ref type="formula" target="#formula_0">(18)</ref> is equivalent to the directional derivative of f along r, and the vector r adv corresponding to the maximum value of the directional derivative at x is equivalent to ∇ x f (x).</p><p>Since the critic f corresponds to the potential function in the dual formulation of the optimal transport problem, at optimality its gradient at x points towards its coupling y, where (x, y) ∼ π * . From this perspective, sampling pairs (x, x + r adv ) using (18) can be seen as an approximation of the optimal coupling π * . To test how reasonable this approximation is, we have trained a WGAN variant with the two-sided explicit penalty formulated as</p><formula xml:id="formula_18">E z∼P Z f (g(z)) − E x∼Pr f (x) + λE x∼Pr,g |f (x) − f (x + r adv )| r adv 2 − 1 2 ,<label>(19)</label></formula><p>which performed similarly to the one-sided case with λ = 10, but was less stable for other values of λ. The findings of <ref type="bibr" target="#b25">Petzka et al. (2018)</ref> were similar for the case of the implicit penalty. Improving the approximation scheme of r adv might render the formulation using the two-sided penalty (19) preferable in the future.</p><p>To show that ALR works in a high-dimensional setting as well, we trained a Progressive GAN on the CelebA-HQ dataset <ref type="bibr" target="#b19">(Karras et al., 2018)</ref>, consisting of 1024 × 1024 RGB images. We took the official TensorFlow implementation and replaced the loss function of the critic, which originally used GP, with a version of ALP. Using (17) as the training objective was stable until the last stage of progressive growing, but to make it work on the highest resolution, we had to replace it with</p><formula xml:id="formula_19">E z∼P Z f (g(z)) − E x∼Pr f (x) + λE x∼Pr,g |f (x) − f (x + r adv )| r adv 2 − 1 2 + + |f (x) − f (x + r adv )| r adv 2 − 1 + ,<label>(20)</label></formula><p>meaning that we used the sum of the absolute and squared values of the Lipschitz constraint violation as the penalty. The optimal hyperparameters were λ = 0.1, P being the uniform distribution over [0.1, 100], ξ = 10 and k = 1 step of power iteration. The best FID seen during training with the original GP version was 8.69, while for the modified ALP version it was 14.65. The example shows that while ALP did not beat GP in this case (possibly because the implementation was fine-tuned using GP), it does work in the high-dimensional setting as well. For samples generated by the best performing ALR and GP variants see Appendix A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>Inspired by VAT, we proposed ALR and shown that it is an efficient and powerful method for learning Lipschitz constrained mappings implemented by neural networks. Resulting in competitive performance when applied to the training of WGANs, ALR is a generally applicable regularization method. It draws an important parallel between Lipschitz regularization and adversarial training, which we believe can prove to be a fruitful line of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>A.1 SEMI-SUPERVISED LEARNING Since VAT is a semi-supervised learning method, it is important to see how ALR fares in that regime. To show this, we have replicated one of the experiments from <ref type="bibr" target="#b23">Miyato et al. (2019)</ref>. We trained the ConvLarge architecture to classify images from CIFAR-10 with the same setting as described in <ref type="bibr" target="#b23">Miyato et al. (2019)</ref>, except that we did not decay the learning rate, but kept it fixed at 3 × 10 −4 . We split the 50000 training examples into 4000 samples for the classification loss, 45000 samples for regularization and 1000 for validation, with equally distributed classes. Test performance was evaluated on the 10000 test examples. We have found that unlike in the unsupervised setting, here it was important to assume f (x) fixed when minimizing the regularization loss, and also to complement the smoothing effect with entropy minimization <ref type="bibr" target="#b14">(Grandvalet and Bengio, 2004)</ref>. The baseline VAT method was ALR specialized with K = 0, d X being the Euclidean metric, d Y being the KL divergence, fixed = 8 and λ = 1. This setting achieved maximal validation performance of 84.2% and test performance 82.46%. After some experimentation, the best performing choice was K = 0, d X being the l 2 metric, d Y the mean squared difference over the logit space (which parametrize the categorical output distribution over which the KL divergence is computed in the case of VAT), P being the uniform distribution over <ref type="bibr">[1,</ref><ref type="bibr">10]</ref> and λ = 1. This way the maximal validation performance was 85.3% and test performance 83.54%. Although this ≈ 1% is improvement is not very significant, it shows that ALR can be a competitive choice as a semi-supervised learning method as well.</p><p>A.2 VIRTUAL ADVERSARIAL TRAINING AS LIPSCHITZ REGULARIZATION VAT was defined by considering neural networks implementing conditional distributions p(y|x), where the distribution over discrete labels y was conditioned on the input image x <ref type="bibr" target="#b23">Miyato et al. (2019)</ref>. To see why LDS (10), the regularization term of VAT, can be seen as special kind of Lipschitz continuity, we will use a different perspective. Consider a mapping f : X → Y with domain X and codomain Y , where X is the space of images and Y is the probability simplex (the space of distributions over the finite set of labels).</p><p>Since a divergence is in general a premetric (prametric, quasi-distance) on the space of probability measures <ref type="bibr" target="#b6">(Deza and Deza, 2009)</ref>, and Lipschitz continuity is defined for mappings between metric spaces, let us restrict the divergence D from the VAT formulation to be a metric d Y . <ref type="bibr" target="#b23">Miyato et al. (2019)</ref> used KLD in their experiments, which is not a metric, but one can use e.g. the square root of JSD or the Hellinger distance, which are metrics. Let us metrize the space of images X with d X being the Euclidean metric. From this perspective, the network f is a mapping from the metric space (X, d X ) to the metric space (Y, d Y ). Let us also assume that we aim to learn a mapping f with the smallest possible f L by setting K to 0.</p><p>To enforce the condition x + r ∈ X in <ref type="formula" target="#formula_0">(14)</ref>, we bound the Euclidean norm of r from above by some predefined &gt; 0. If we make the additional assumption that the supremum is always achieved with an r of maximal norm , the denominator in (14) will be constant, hence the formulas with and without it will be equivalent up to a scaling factor. With these simplifications, <ref type="formula" target="#formula_0">(14)</ref> and <ref type="formula" target="#formula_0">(15)</ref> reduce to</p><formula xml:id="formula_20">r V AT adv = arg max 0≤ r 2≤ d Y (f (x), f (x + r))<label>(21)</label></formula><p>and</p><formula xml:id="formula_21">L V AT ALP = d Y (f (x), f (x + r adv )),<label>(22)</label></formula><p>which are equivalent to (11) and (10), respectively. Let us consider the question of keeping f (x) fixed when minimizing (22) an implementation detail. With this discrepancy aside, we have recovered VAT as a special case of Lipschitz regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 DERIVATION OF THE APPROXIMATION OF r adv</head><p>We assume that f and d Y are both twice differentiable with respect to their arguments almost everywhere, the latter specifically at x = y. Note that one can easily find a d Y for which the last assumption does not hold, for example the l1 distance. If d Y is translation invariant, meaning that d Y (x, y) = d Y (x + u, y + u) for each u ∈ Y , then its subderivatives at x = y will be independent of x, hence the method described below will still work. Otherwise, one can resort to using a proxy metric in place of d Y for the approximation, for example the l2 distance.</p><p>We denote d Y (f (x), f (x + r)) by d(r, x) for simplicity. Because d(r, x) ≥ 0 and d(0, x) = 0, it is easy to see that</p><formula xml:id="formula_22">∇ r d(r, x) r=0 = 0,<label>(23)</label></formula><p>so that the second-order Taylor approximation of d(r, x) is d(r, x) ≈ 1 2 r T H(x)r, where H(x) = ∇∇ r d(r, x) r=0 is the Hessian matrix. The eigenvector u of H(x) corresponding to its eigenvalue with the greatest absolute value is the direction of greatest curvature, which is approximately the adversarial direction that we are looking for. The power iteration <ref type="bibr" target="#b18">(Householder, 1964)</ref> defined by</p><formula xml:id="formula_23">r i+1 := H(x)r i H(x)r i 2 ,<label>(24)</label></formula><p>where r 0 is a randomly sampled unit vector, converges to u if u and r 0 are not perpendicular. Calculating H(x) is computationally heavy, which is why H(x)r i is approximated using the finite differences method as</p><formula xml:id="formula_24">H(x)r i ≈ ∇ r d(r, x) r=ξri − ∇ r d(r, x) r=0 ξ = ∇ r d(r, x) r=ξri ξ<label>(25)</label></formula><p>where the equality follows from (23). The hyperparameter ξ = 0 is introduced here. In summary, the adversarial direction is approximated by the iterative scheme</p><formula xml:id="formula_25">r i+1 := ∇ r d(r, x) r=ξri ∇ r d(r, x) r=ξri 2 ,<label>(26)</label></formula><p>of which one iteration is found to be sufficient and necessary in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 TOY EXAMPLE</head><p>To showcase the differences between weight normalization methods, implicit penalty methods and explicit penalty methods, represented by SN, LP and ALR, respectively, we devised the following toy example. Suppose that we want to approximate the following real-valued mapping on the 2-dimensional interval [−4, 4] 2 :</p><p>f (x, y) = 0 if 1 ≤ x 2 + y 2 ≤ 2, 1 otherwise <ref type="formula" target="#formula_1">(27)</ref> for −4 ≤ x, y ≤ 4. In addition, we want the approximation to be 1-Lipschitz. It is easy to see that the optimal approximation with respect to the mean squared error iŝ</p><formula xml:id="formula_26">f opt (x, y) =          1 if x 2 + y 2 ≤ 0.5, 1.5 − x 2 + y 2 if 0.5 &lt; x 2 + y 2 ≤ 1.5, x 2 + y 2 − 1.5 if 1.5 &lt; x 2 + y 2 ≤ 2.5, 1 otherwise. .<label>(28)</label></formula><p>This example has connections to WGAN, as the optimal critic is 1-Lipschitz, and its approximation will provide the learning signal to the generator in the form of gradients. Therefore, it is important to closely approximate the gradient of the optimal critic, which is achieved indirectly by Lipschitz regularization. In this example, we will see how closely the different Lipschitz regularization methods can match the gradient of the optimal approximationf opt .</p><p>We implemented the example in PyTorch. For the approximationf , we use an MLP with 3 hidden layers containing 20, 40 and 20 neurons, respectively, with ReLU activations after the hidden layers, and a variant which also has batch normalization (BN) before the activations, since it has been found that BN hurts adversarial robustness <ref type="bibr" target="#b9">(Galloway et al., 2019)</ref>, and hence it should also hurt Lipschitz continuity. We trained the networks for 2 14 iterations, with batches consisting of an input, a corresponding output, and an additional input for regularization. The inputs are drawn uniformly at random from [−4, 4] 2 and the output is defined by <ref type="formula" target="#formula_1">(27)</ref>. The minibatch size was 64 for input-output pairs, and 1024 for regularization inputs. We used heatmaps to visualize the gradient norm surfaces of the optimal and learned mappings, with the color gradient going from black at 0 to white at 1, see <ref type="figure">Figure 2</ref>. This example is not intended to rank the competing Lipschitz regularization methods, as it always depends on the particular application which one is the best suited, but to show that they are fundamentally different and competent in their own way.</p><p>(a) colormap (b) ∇xfopt 2 (c) ∇xf 2 (no regularization) (d) ∇xfSN 2 (e) ∇xf LP,λ=0.1 2 (f) ∇xf LP,λ=1 2 (g) ∇xf LP,λ=10 2 (h) ∇xf ALP,λ=0.1,k=0 2 (i) ∇xf ALP,λ=1,k=0 2 (j) ∇xf ALP,λ=10,k=0 2 (k) ∇xf ALP,λ=0.1,k=1 2 (l) ∇xf ALP,λ=1,k=1 2 (m) ∇xf ALP,λ=10,k=1 2 (n) ∇xf ALP,λ=0.1,k=5 2 (o) ∇xf ALP,λ=1,k=5 2 (p) ∇xf ALP,λ=10,k=5 2 <ref type="figure">Figure 2</ref>: Gradient norm surfaces of optimal and learned approximations of f Without any kind of regularization, the network learned to approximate the target function very well, but its gradients look nothing like that off opt , although somehow it is a better match with BN.</p><p>When we apply SN to the MLP layers, the result without BN will be a very smooth mapping with maximum gradient norm far below 1. SN is not compatible with BN, the result being only slightly better than the unregularized case. A detail not visible here is that because SN considers weight matrices as linear maps from R n to R m and normalizes them layer-wise, it regularizes globally instead of around actual data samples. In this case, on the whole of R 2 instead of just [−4, 4] 2 . For WGANs trained on CIFAR-10, the input space consists of 32 × 32 RGB images with pixel values in [−1, 1], but the trained mapping is regularized on R 32×32×3 instead of just [−1, 1] 32×32×3 (which contains the supports of the real and fake distributions). This can hurt performance if the optimal mapping implemented by a particular network architecture is K-Lipschitz inside these supports, but not in some other parts of R 32×32×3 .</p><p>When the network is regularized using LP (9), the regularization strength can be controlled by tuning the value of λ. We trained with λ = 0.1, 1 and 10. Without BN, the highest of these values seems to work the best. With BN, the resulting mapping is visibly highly irregular.</p><p>With ALR, in addition to λ, we have additional control over the regularization by the hyperparameters of the approximation scheme of r adv . After some experimentation, we have found the best P for this case was the uniform distribution over [10 −6 , 10 −5 ]. We trained with λ = 0.1, 1 and 10, and k = 0, 1 and 5 power iterations. Arguably, both with and without BN the λ = 1 and k = 5 case seems like the best choice. Without BN, the results are quite similar to the LP case, but when BN is introduced, the resulting mappings are much smoother than the ones obtained with LP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Inception Scores and FIDs on CIFAR-10</figDesc><table><row><cell></cell><cell cols="2">Inception Score</cell><cell></cell></row><row><cell>Method</cell><cell>Average</cell><cell>Best</cell><cell>FID</cell></row><row><cell>WGAN-GP</cell><cell>7.86 ± .07</cell><cell></cell><cell>18.86 ± .13</cell></row><row><cell>WGAN-LP</cell><cell>8.02 ± .07</cell><cell></cell><cell></cell></row><row><cell>LGAN</cell><cell>8.03 ± .03</cell><cell></cell><cell>15.64 ± .07</cell></row><row><cell>CT-GAN</cell><cell>8.12 ± .12</cell><cell></cell><cell></cell></row><row><cell>SN-GAN</cell><cell>8.22 ± .05</cell><cell></cell><cell>21.70 ± .21</cell></row><row><cell>BWGAN</cell><cell>8.31 ± .07</cell><cell></cell><cell>16.43</cell></row><row><cell>Progressive GAN</cell><cell cols="2">8.56 ± .06 8.80</cell><cell></cell></row><row><cell cols="4">WGAN-ALP (ours) 8.34 ± .06 8.59 12.96 ± .35</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The author would like to thank Michael Herman from Bosch Center for Artificial Intelligence (BCAI) for the fruitful discussions, and the Advanced Engineering team in Budapest, especially Géza Velkey.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Banach wasserstein GAN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lunz</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7909-banach-wasserstein-gan" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-08" />
			<biblScope unit="page" from="6755" to="6764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sorting out lipschitz function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/anil19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="291" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hk4_qw5xe" />
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/arjovsky17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The sample complexity of pattern classification with neural networks: The size of the weights is more important than the size of the network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<idno type="DOI">10.1109/18.661502</idno>
		<ptr target="https://doi.org/10.1109/18.661502" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="525" to="536" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1xsqj09Fm" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Encyclopedia of Distances. Encyclopedia of Distances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Deza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">9783642002342</biblScope>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving generalization performance using double backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="DOI">10.1109/72.165600</idno>
		<ptr target="https://doi.org/10.1109/72.165600" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="991" to="997" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wasserstein of wasserstein loss for learning generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dukler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montúfar</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/dukler19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="1716" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Batch normalization is a cause of adversarial vulnerability. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galloway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Golubeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tanay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moussa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1905.02161" />
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gemici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1805.09575</idno>
		<ptr target="http://arxiv.org/abs/1805.09575" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5423-generative-adversarial-nets" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6572" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Regularisation of neural networks by enforcing lipschitz continuity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Cree</surname></persName>
		</author>
		<idno>abs/1804.04368</idno>
		<ptr target="http://arxiv.org/abs/1804" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/2740-semi-supervised-learning-by-entropy-minimization" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 17 [Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-12-13" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-09" />
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7240-gans-trained-by-a-two-time-scale-update-rule-converge-to-a-local-nash-equilib" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-09" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative adversarial imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="4565" to="4573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The Theory of Matrices in Numerical Analysis. A Blaisdell book in pure and applied sciences : introduction to higher mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Householder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<publisher>Blaisdell Publishing Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hk99zCeAb" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Art of singular vectors and universal adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Khrulkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Oseledets</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2018.00893</idno>
		<ptr target="http://openaccess.thecvf.com/content_cvpr_2018/html/Khrulkov_Art_of_Singular_CVPR_2018_paper.html" />
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="8562" to="8570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshida</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1QRgziT-" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: A regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2018.2858821</idno>
		<ptr target="https://doi.org/10.1109/TPAMI.2018.2858821" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Lipschitz regularized deep neural networks converge and generalize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Oberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Calder</surname></persName>
		</author>
		<idno>abs/1808.09540</idno>
		<ptr target="http://arxiv.org/abs/1808.09540" />
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the regularization of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Petzka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lukovnikov</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1hYRMbCW" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="2226" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adversarial training for free! CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shafahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1904.12843" />
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Villani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">9783540710509</biblScope>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improving the improved training of wasserstein gans: A consistency term and its dual effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJx9GQb0-" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wasserstein adversarial examples via projected sinkhorn iterations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/wong19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="6808" to="6817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">An empirical study on evaluation metrics of generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>abs/1806.07755</idno>
		<ptr target="http://arxiv.org/abs/1806.07755" />
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Lipschitz generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/zhou19c.html" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7584" to="7593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards efficient and unbiased implementation of lipschitz continuity in gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1904.01184</idno>
		<ptr target="http://arxiv.org/abs/1904.01184" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
