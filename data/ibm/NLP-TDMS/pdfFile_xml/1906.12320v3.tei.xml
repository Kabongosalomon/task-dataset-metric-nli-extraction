<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guandao</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Cornell Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Cornell Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Hao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Cornell Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Cornell Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: Our model transforms points sampled from a simple prior to realistic point clouds through continuous normalizing flows. The videos of the transformations can be viewed on our project website: https://www.guandaoyang.com/ PointFlow/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>As 3D point clouds become the representation of choice for multiple vision and graphics applications, the ability to synthesize or reconstruct high-resolution, high-fidelity point clouds becomes crucial. Despite the recent success of deep learning models in discriminative tasks of point clouds, generating point clouds remains challenging. This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions. Specifically, we learn a two-level hierarchy of distributions where the first level is the distribution of shapes and the second level is the distribution of points given a shape. This formulation allows us to both sample shapes and sample an arbitrary number of points from a shape. Our generative model, named PointFlow, learns each level of the distribution with a continuous normalizing flow. The invertibility of normalizing flows enables the computation of the likelihood during training and * Equal contribution. allows us to train our model in the variational inference framework. Empirically, we demonstrate that PointFlow achieves state-of-the-art performance in point cloud generation. We additionally show that our model can faithfully reconstruct point clouds and learn useful representations in an unsupervised manner. The code is available at https: //github.com/stevenygd/PointFlow.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Point clouds are becoming popular as a 3D representation because they can capture a much higher resolution than voxel grids and are a stepping stone to more sophisticated representations such as meshes. Learning a generative model of point clouds could benefit a wide range of point cloud synthesis tasks such as reconstruction and super-resolution, by providing a better prior of point clouds. However, a major roadblock in generating point clouds is the complexity of the space of point clouds. A cloud of points corresponding to a chair is best thought of as sam-ples from a distribution that corresponds to the surface of the chair, and the chair itself is best thought of as a sample from a distribution of chair shapes. As a result, in order to generate a chair according to this formulation, we need to characterize a distribution of distributions, which is underexplored by existing generative models.</p><p>In this paper, we propose PointFlow, a principled generative model for 3D point clouds that learns a distribution of distributions: the former being the distribution of shapes and the latter being the distribution of points given a shape.</p><p>Our key insight is that instead of directly parametrizing the distribution of points in a shape, we model this distribution as an invertible parameterized transformation of 3D points from a prior distribution (e.g., a 3D Gaussian). Intuitively, under this model, generating points for a given shape involves sampling points from a generic Gaussian prior, and then moving them according to this parameterized transformation to their new location in the target shape, as illustrated in <ref type="figure">Figure 1</ref>. In this formulation, a given shape is then simply the variable that parametrizes such transformation, and a category is simply a distribution of this variable. Interestingly, we find that representing this distribution too as a transformation of a prior distribution leads to a more expressive model of shapes. In particular, we use the recently proposed continuous normalizing flow framework to model both kinds of transformations <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>This parameterization confers several advantages. The invertibility of these transformations allows us to not just sample but also estimate probability densities. The ability to estimate probability densities in turn allows us to train these models in a principled manner using the variational inference framework <ref type="bibr" target="#b26">[27]</ref>, where we maximize a variational lower bound on the log-likelihood of a training set of point clouds. This probabilistic framework for training further lets us avoid the complexities of training GANs or handcrafting good distance metrics for measuring the difference between two sets of points. Experiments show that Point-Flow outperforms previous state-of-the-art generative models of point clouds, and achieves compelling results in point cloud reconstruction and unsupervised feature learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Deep learning for point clouds. Deep learning has been introduced to improve performance in various point cloud discriminative tasks including classification <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55]</ref>, segmentation <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b42">43]</ref>, and critical points sampling <ref type="bibr" target="#b9">[10]</ref>. Recently, substantial progress has been made in point cloud synthesis tasks such as auto-encoding <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b16">17]</ref>, singleview 3D reconstruction <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b12">13]</ref>, stereo reconstruction <ref type="bibr" target="#b44">[45]</ref>, and point cloud completion <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b52">53]</ref>. Many point cloud synthesis works convert a point distribution to a N × 3 matrix by sampling N (N is pre-defined) points from the distribution so that existing generative models are readily applicable. For example, Gadelha et al. <ref type="bibr" target="#b12">[13]</ref> apply variational auto-encoders (VAEs) <ref type="bibr" target="#b26">[27]</ref> and Zamorski et al. <ref type="bibr" target="#b55">[56]</ref> apply adversarial auto-encoders (AAEs) <ref type="bibr" target="#b33">[34]</ref> to point cloud generation. Achlioptas et al. <ref type="bibr" target="#b0">[1]</ref> explore generative adversarial networks (GANs) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b18">19]</ref> for point clouds in both raw data space and latent space of a pretrained auto-encoder. In the above methods, the autoencoders are trained with heuristic loss functions that measure the distance between two point sets, such as Chamfer distance (CD) or earth mover's distance (EMD). Sun et al. <ref type="bibr" target="#b43">[44]</ref> apply auto-regressive models <ref type="bibr" target="#b46">[47]</ref> with a discrete point distribution to generate one point at a time, also using a fixed number of points per shape.</p><p>However, treating a point cloud as a fixed-dimensional matrix has several drawbacks. First, the model is restricted to generate a fixed number of points. Getting more points for a particular shape requires separate up-sampling models such as <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b51">52]</ref>. Second, it ignores the permutation invariance property of point sets, which might lead to suboptimal parameter efficiency. Heuristic set distances are also far from ideal objectives from a generative modeling perspective since they make the original probabilistic interpretation of VAE/AAE no longer applicable when used as the reconstruction objective. In addition, exact EMD is slow to compute while approximations could lead to biased or noisy gradients. CD has been shown to incorrectly favor point clouds that are overly concentrated in the mode of the marginal point distribution <ref type="bibr" target="#b0">[1]</ref>.</p><p>Some recent works introduce sophisticated decoders consisting of a cascade <ref type="bibr" target="#b50">[51]</ref> or a mixture <ref type="bibr" target="#b16">[17]</ref> of smaller decoders to map one (or a mixture of) 2-D uniform distribution(s) to the target point distribution, overcoming the shortcomings of using a fixed number of points. However, they still rely on heuristic set distances that lack a probabilistic guarantee. Also, their methods only learn the distribution of points for each shape, but not the distribution of shapes. Li et al. <ref type="bibr" target="#b29">[30]</ref> propose a "sandwiching" reconstruction objective that combines a variant of WGAN <ref type="bibr" target="#b1">[2]</ref> loss with EMD. They also train another GAN in the latent space to learn shape distribution, similar to Achlioptas et al. <ref type="bibr" target="#b0">[1]</ref>. In contrast, our method is simply trained end-to-end by maximizing a variational lower bound on the log-likelihood, does not require multi-stage training, and does not have any instability issues common for GAN-based methods.</p><p>Generative models. There are several popular frameworks of deep generative models, including generative adversarial networks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b22">23]</ref>, variational auto-encoders <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41]</ref>, auto-regressive models <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b46">47]</ref>, and flow-based models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b24">25]</ref>. In particular, flow-based models and auto-regressive models can both perform exact likelihood evaluation, while flow-based models are much more efficient to sample from. Flow-based models have been successfully applied to a variety of generation tasks such as image generation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b7">8]</ref>, video generation <ref type="bibr" target="#b27">[28]</ref>, and voice synthesis <ref type="bibr" target="#b36">[37]</ref>. Also, there has been recent work that combines flows with other generative models, such as GANs <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b6">7]</ref>, auto-regressive models <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b25">26]</ref>, and VAEs <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Most existing deep generative models aim at learning the distribution of fixed-dimensional variables. Learning the distribution of distributions, where the data consists of a set of sets, is still underexplored. Edwards and Storkey <ref type="bibr" target="#b10">[11]</ref> propose a hierarchical VAE named Neural Statistician that consumes a set of sets. They are mostly interested in the few-shot case where each set only has a few samples. Also, they are focused on classifying sets or generating new samples from a given set. While our method is also applicable to these tasks, our focus is on learning the distribution of sets and generating new sets (point clouds in our case). In addition, our model employs a tighter lower bound on the log-likelihood, thanks to the use of normalizing flow in modeling both the reconstruction likelihood and the prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview</head><p>Consider a set of shapes X = {X i } N i=1 from a particular class of object, where each shape is represented as a set of 3D points X i = {x i j } Mi j=1 . As discussed in Section 1, each point x i j ∈ R 3 is best thought of as being sampled from a point distribution Q i (x), usually a uniform distribution over the surface of an object X i . Each shape X i is itself a sample from a distribution over shapes Q(X) that captures what shapes in this category look like.</p><p>Our goal is to learn the distribution of shapes, each shape itself being a distribution of points. In other words, our generative model should be able to both sample shapes and sample an arbitrary number of points from a shape.</p><p>We propose to use continuous normalizing flows to model the distribution of points given a shape. A continuous normalizing flow can be thought of as a vector field in the 3-D Euclidean space, which induces a distribution of points through transforming a generic prior distribution (e.g., a standard Gaussian). To sample points from the induced distribution, we simply sample points from the prior and move them according to the vector field. Moreover, the continuous normalizing flow is invertible, which means we can move data points back to the prior distribution to compute the exact likelihood. This model is highly intuitive and interpretable, allowing a close inspection of the generative process as shown in <ref type="figure">Figure 1</ref>.</p><p>We parametrize each continuous normalizing flow with a latent variable that represents the shape. As a result, modeling the distribution of shapes can be reduced to modeling the distribution of the latent variable. Interestingly, we find continuous normalizing flow also effective in modeling the latent distribution. Our full generative model thus consists of two levels of continuous normalizing flows, one modeling the shape distribution by modeling the distribution of the latent variable, and the other modeling the point distribution given a shape.</p><p>In order to optimize the generative model, we construct a variational lower bound on the log-likelihood by introducing an inference network that infers a latent variable distribution from a point cloud. Here, we benefit from the fact that the invertibility of the continuous normalizing flow enables likelihood computation. This allows us to train our model end-to-end in a stable manner, unlike previous work based on GANs that requires two-stage training <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref>. As a side benefit, we find the inference network learns a useful representation of point clouds in an unsupervised manner.</p><p>In Section 4 we introduce some background on continuous normalizing flows and variational auto-encoders. We then describe our model and training in detail in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Continuous normalizing flow</head><p>A normalizing flow <ref type="bibr" target="#b39">[40]</ref> is a series of invertible mappings that transform an initial known distribution to a more complicated one. Formally, let f 1 , . . . , f n denote a series of invertible transformations we want to apply to a latent variable y with a distribution P (y).</p><formula xml:id="formula_0">x = f n • f n−1 • · · · • f 1 (y)</formula><p>is the output variable. Then the probability density of the output variable is given by the change of variables formula:</p><formula xml:id="formula_1">log P (x) = log P (y) − n k=1 log det ∂f k ∂y k−1 ,<label>(1)</label></formula><p>where y can be computed from x using the inverse flow:</p><formula xml:id="formula_2">y = f −1 1 • · · · • f −1 n (x).</formula><p>In practice, f 1 , . . . , f n are usually instantiated as neural networks with an architecture that makes the determinant of the Jacobian det ∂f k ∂y k−1 easy to compute. The normalizing flow has been generalized from a discrete sequence to a continuous transformation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref> by defining the transformation f using a continuous-time dynamic ∂y(t) ∂t = f (y(t), t), where f is a neural network that has an unrestricted architecture. The continuous normalizing flow (CNF) model for P (x) with a prior distribution P (y) at the start time can be written as:</p><formula xml:id="formula_3">x = y(t 0 ) + t1 t0 f (y(t), t)dt, y(t 0 ) ∼ P (y) log P (x) = log P (y(t 0 )) − t1 t0</formula><p>Tr ∂f ∂y(t) dt <ref type="bibr" target="#b1">(2)</ref> and y(t 0 ) can be computed using the inverse flow y(t 0 ) = x+ t0 t1 f (y(t), t)dt. A black-box ordinary differential equation (ODE) solver can been applied to estimate the outputs and the input gradients of a continuous normalizing flow <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Variational auto-encoder</head><p>Suppose we have a random variable X that we are building generative models for. The variational auto-encoder (VAE) is a framework that allows one to learn P (X) from a dataset of observations of X <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41]</ref>. The VAE models the data distribution via a latent variable z with a prior distribution P ψ (z), and a decoder P θ (X|z) which captures the (hopefully simpler) distribution of X given z. During training, it additionally learns an inference model (or encoder) Q φ (z|X). The encoder and decoder are jointly trained to maximize a lower bound on the log-likelihood of the observations</p><formula xml:id="formula_4">log P θ (X) ≥ log P θ (X) − DKL(Q φ (z|X)||P θ (z|X)) = E Q φ (z|x) [log P θ (X|z)] − DKL (Q φ (z|X)||P ψ (z)) L(X; φ, ψ, θ) ,<label>(3)</label></formula><p>which is also called the evidence lower bound (ELBO). One can interpret ELBO as the sum of the negative reconstruction error (the first term) and a latent space regularizer (the second term). In practice, Q φ (z|X) is usually modeled as a diagonal Gaussian N (z|µ φ (X), σ φ (X)) whose mean and standard deviation are predicted by a neural network with parameters φ. To efficiently optimize the ELBO,</p><formula xml:id="formula_5">sampling from Q φ (z|X) is done by reparametrizing z as z = µ φ (X) + σ φ (X) · , where ∼ N (0, I ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Model</head><p>We now have the paraphernalia needed to define our generative model of point clouds. Using the terminology of the VAE, we need three modules: the encoder Q φ (z|X) that encodes a point cloud into a shape representation z, a prior P ψ (z) over shape representations, and a decoder P θ (X|z) that models the distribution of points given the shape representation. We use a simple permutation-invariant encoder to predict Q φ (z|X), following the architecture in Achlioptas et al. <ref type="bibr" target="#b0">[1]</ref>. We use continuous normalizing flows for both the prior P ψ (z) and the generator P θ (X|z), which are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Flow-based point generation from shape representations</head><p>We first decompose the reconstruction log-likelihood of a point set into the sum of log-likelihood of each point</p><formula xml:id="formula_6">log P θ (X|z) = x∈X log P θ (x|z) .<label>(4)</label></formula><p>We propose to model P θ (x|z) using a conditional extension of CNF. Specifically, a point x in the point set X is the result of transforming some point y(t 0 ) in the prior distribution P (y) = N (0, I ) using a CNF conditioned on z:</p><p>where g θ defines the continuous-time dynamics of the flow G θ conditioned on z. Note that the inverse of G θ is given by</p><formula xml:id="formula_7">G −1 θ (x; z) = x + t0 t1 g θ (y(t), t, z)dt with y(t 1 ) = x.</formula><p>The reconstruction likelihood of follows equation <ref type="formula">(2)</ref>:</p><formula xml:id="formula_8">log P θ (x|z) = log P (G −1 θ (x; z)) − t1 t0</formula><p>Tr ∂g θ ∂y(t) dt .</p><p>(5) Note that log P (G −1 θ (x; z)) can be computed in closed form with the Gaussian prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Flow-based prior over shapes</head><p>Although it is possible to use a simple Gaussian prior over shape representations, it has been shown that a restricted prior tends to limit the performance of VAEs <ref type="bibr" target="#b5">[6]</ref>. To alleviate this problem, we use another CNF to parametrize a learnable prior. Formally, we rewrite the KL divergence term in <ref type="table" target="#tab_3">Equation 3</ref> as</p><formula xml:id="formula_9">DKL(Q φ (z|x)||P ψ (z)) = −E Q φ (z|x) [log P ψ (z)] − H[Q φ (z|X)] ,<label>(6)</label></formula><p>where H is the entropy and P ψ (z) is the prior distribution with learnable parameters ψ, obtained by transforming a simple Gaussian P (w) = N (0, I ) with a CNF:</p><formula xml:id="formula_10">z = F ψ (w(t0)) w(t0) + t 1 t 0 f ψ (w(t), t)dt, w(t0) ∼ P (w) ,</formula><p>where f ψ defines the continuous-time dynamics of the flow F ψ . Similarly as described above, the inverse of F ψ is given by</p><formula xml:id="formula_11">F −1 ψ (z) = z + t0 t1 f ψ (w(t), t)dt with w(t 1 ) = z.</formula><p>The log probability of the prior distribution can be computed by:</p><formula xml:id="formula_12">log P ψ (z) = log P F −1 ψ (z) − t1 t0</formula><p>Tr ∂f ψ ∂w(t) dt .</p><p>(7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Final training objective</head><p>Plugging Equation 4, 5, 6, 7 into Equation 3, the ELBO of a point set X can be finally written as</p><formula xml:id="formula_13">L(X; φ, ψ, θ) = E Q φ (z|x) [log P ψ (z) + log P θ (X|z)] + H[Q φ (z|X)] = E Q φ (z|X) [log P F −1 ψ (z) − t 1 t 0 Tr ∂f ψ ∂w(t) dt + x∈X (log P (G −1 θ (x; z)) − t 1 t 0 Tr ∂g θ ∂y(t) dt)] + H[Q φ (z|X)] .<label>(8)</label></formula><p>Our model is trained end-to-end by maximizing the ELBO of all point sets in the dataset</p><formula xml:id="formula_14">φ * , ψ * , θ * = arg max φ,ψ,θ X∈X L(X; φ, ψ, θ).<label>(9)</label></formula><p>We can interpret this objective as the sum of three parts:</p><formula xml:id="formula_15">Figure 2: Model architecture. (a)</formula><p>At training time, the encoder Q φ infers a posterior over shape representations given an input point cloud X, and samples a shape representation z from it. We then compute the probability of z in the prior distribution (L prior ) through a inverse CNF F −1 ψ , and compute the reconstruction likelihood of X (L recon ) through another inverse CNF G −1 θ conditioned on z. The model is trained end-to-end to maximize the evidence lower bound (ELBO), which is the sum of L prior , L recon , and L ent (the entropy of the posterior Q φ (z|X)). (b) At test time, we sample a shape representatioñ z by samplingw from a Gaussian prior and transforming it with F ψ . To sample points from the shape represented byz, we first sample points from the 3-D Gaussian prior and then move them according to the CNF parameterized byz.</p><p>1. Prior: L prior (X; ψ, φ) E Q φ (z|x) [log P ψ (z)] encourages the encoded shape representation to have a high probability under the prior, which is modeled by a CNF as described in Section 5.2. We use the reparameterization trick <ref type="bibr" target="#b26">[27]</ref> to enable a differentiable Monte Carlo estimate of the expectation:</p><formula xml:id="formula_16">E Q φ (z|x) [log P ψ (z)] ≈ 1 L L l=1 log P ψ (µ + l σ) ,</formula><p>where µ and σ are mean and standard deviation of the isotropic Gaussian posterior Q φ (z|x) and L is simply set to 1. i is sampled from the standard Gaussian distribution N (0, I ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Reconstruction likelihood:</head><formula xml:id="formula_17">L recon (X; θ, φ) E Q φ (z|x) [log P θ (X|z)]</formula><p>is the reconstruction loglikelihood of the input point set, computed as described in Section 5.1. The expectation is also estimated using Monte Carlo sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Posterior Entropy</head><formula xml:id="formula_18">: L ent (X; φ) H[Q φ (z|X)]</formula><p>is the entropy of the approximated posterior:</p><formula xml:id="formula_19">H[Q φ (z|X)] = d 2 (1 + ln (2π)) + d i=1 ln σ i .</formula><p>All the training details (e.g., hyper-parameters, model architectures) are included in Section B of the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Sampling</head><p>To sample a shape representation, we first draww ∼ N (0, I ) then pass it through F ψ to getz = F ψ (w). To generate a point given a shape representationz, we first sample a pointỹ ∈ R 3 from N (0, I ), then passỹ through G θ conditioned onz to produce a point on the shape :x = G θ (w; z). To sample a point cloud with sizeM , we simply repeat it for M times. Combining these two steps allows us to sample a point cloud withM points from our model:</p><formula xml:id="formula_20">X = {G θ (ỹj; F ψ (w))} 1≤j≤M ,w ∼ N (0, I ), ∀j,ỹj ∼ N (0, I ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this section, we first introduce existing metrics for evaluating point cloud generation, discuss their limitations, and introduce a new metric that overcomes these limitations. We then compare the proposed method with previous state-of-the-art generative models of point clouds, using both previous metrics and the proposed one. We additionally evaluate the reconstruction and representation learning ability of the auto-encoder part of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Evaluation metrics</head><p>Following prior work, we use Chamfer distance (CD) and earth mover's distance (EMD) to measure the similarity between point clouds. Formally, they are defined as follows:</p><formula xml:id="formula_21">CD(X, Y ) = x∈X min y∈Y x − y 2 2 + y∈Y min x∈X x − y 2 2 , EMD(X, Y ) = min φ:X→Y x∈X x − φ(x) 2 ,</formula><p>where X and Y are two point clouds with the same number of points and φ is a bijection between them. Note that most previous methods use either CD or EMD in their training objectives, which tend to be favored if evaluated under the same metric. Our method, however, does not use CD or EMD during training. Let S g be the set of generated point clouds and S r be the set of reference point clouds with |S r | = |S g |. To evaluate generative models, we first consider the three metrics introduced by Achlioptas et al. <ref type="bibr" target="#b0">[1]</ref>:</p><p>• Jensen-Shannon Divergence (JSD) are computed between the marginal point distributions:</p><formula xml:id="formula_22">JSD(P g , P r ) = 1 2 D KL (P r ||M ) + 1 2 D KL (P g ||M ) ,</formula><p>where M = 1 2 (P r + P g ). P r and P g are marginal distributions of points in the reference and generated sets, approximated by discretizing the space into 28 3 voxels and assigning each point to one of them. However, it only considers the marginal point distributions but not the distribution of individual shapes. A model that always outputs the "average shape" can obtain a perfect JSD score without learning any meaningful shape distributions.</p><p>• Coverage (COV) measures the fraction of point clouds in the reference set that are matched to at least one point cloud in the generated set. For each point cloud in the generated set, its nearest neighbor in the reference set is marked as a match:</p><formula xml:id="formula_23">COV(S g , S r ) = |{arg min Y ∈Sr D(X, Y )|X ∈ S g }| |S r | ,</formula><p>where D(·, ·) can be either CD or EMD. While coverage is able to detect mode collapse, it does not evaluate the quality of generated point clouds. In fact, it is possible to achieve a perfect coverage score even if the distances between generated and reference point clouds are arbitrarily large.</p><p>• Minimum matching distance (MMD) is proposed to complement coverage as a metric that measures quality. For each point cloud in the reference set, the distance to its nearest neighbor in the generated set is computed and averaged:</p><formula xml:id="formula_24">MMD(S g , S r ) = 1 |S r | Y ∈Sr min X∈Sg D(X, Y ) ,</formula><p>where D(·, ·) can be either CD or EMD. However, MMD is actually very insensitive to low-quality point clouds in S g , since they are unlikely to be matched to real point clouds in S r . In the extreme case, one can imagine that S g consists of mostly very low-quality point clouds with one additional point cloud in each mode of S r , yet has a reasonably good MMD score.</p><p>As discussed above, all existing metrics have their limitations. As will be shown later, we also empirically find all these metrics sometimes give generated point clouds even better scores than real point clouds, further casting doubt on whether they can ensure a fair model comparison. We therefore introduce another metric that we believe is better suited for evaluating generative models of point clouds:</p><p>• 1-nearest neighbor accuracy (1-NNA) is proposed by Lopez-Paz and Oquab <ref type="bibr" target="#b31">[32]</ref> for two-sample tests, assessing whether two distributions are identical. It has also been explored as a metric for evaluating GANs <ref type="bibr" target="#b49">[50]</ref>. Let S −X = S r ∪ S g − {X} and N X be the nearest neighbor of X in S −X . 1-NNA is the leave-one-out accuracy of the 1-NN classifier:</p><formula xml:id="formula_25">1-NNA(S g , S r ) = X∈Sg I[N X ∈ S g ] + Y ∈Sr I[N Y ∈ S r ] |S g | + |S r | ,</formula><p>where I[·] is the indicator function. For each sample, the 1-NN classifier classifies it as coming from S r or S g according to the label of its nearest sample. If S g and S r are sampled from the same distribution, the accuracy of such a classifier should converge to 50% given a sufficient number of samples. The closer the accuracy is to 50%, the more similar S g and S r are, and therefore the better the model is at learning the target distribution. In our setting, the nearest neighbor can be computed using either CD or EMD. Unlike JSD, 1-NNA considers the similarity between shape distributions rather than between marginal point distributions. Unlike COV and MMD, 1-NNA directly measures distributional similarity and takes both diversity and quality into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Generation</head><p>We compare our method with three existing generative models for point clouds: raw-GAN <ref type="bibr" target="#b0">[1]</ref>, latent-GAN <ref type="bibr" target="#b0">[1]</ref>, and PC-GAN <ref type="bibr" target="#b29">[30]</ref>, using their official implementations that are either publicly available or obtained by contacting the authors. We train each model using point clouds from one of the three categories in the ShapeNet <ref type="bibr" target="#b2">[3]</ref> dataset: airplane, chair, and car. The point clouds are obtained by sampling points uniformly from the mesh surface. All points in each category are normalized to have zero-mean per axis <ref type="table">Table 1</ref>: Generation results. ↑: the higher the better, ↓: the lower the better. The best scores are highlighted in bold. Scores of the real shapes that are worse than some of the generated shapes are marked in gray. MMD-CD scores are multiplied by 10 3 ; MMD-EMD scores are multiplied by 10 2 ; JSDs are multiplied by 10 2 . and unit-variance globally. Following prior convention <ref type="bibr" target="#b0">[1]</ref>, we use 2048 points for each shape during both training and testing, although our model is able to sample an arbitrary number of points. We additionally report the performance of point clouds sampled from the training set, which is considered as an upper bound since they are from the target distribution.</p><p>In <ref type="table">Table 1</ref>, we report the performance of different models, as well as their number of parameters in total (full) or in the generative pathways (gen). We first note that all the previous metrics (JSD, MMD, and COV) sometimes assign a better score to point clouds generated by models than those from the training set (marked in gray). The 1-NNA metric does not seem to have this problem and always gives a better score to shapes from the training set. Our model outperforms all baselines across all three categories according to 1-NNA and also obtains the best score in most cases as evaluated by other metrics. Besides, our model has the fewest parameters among compared models. In Section C of the appendix, we perform additional ablation studies to show the effectiveness of different components of our model. <ref type="figure" target="#fig_0">Figure 3</ref> shows some examples of novel point clouds generated by our model. <ref type="figure" target="#fig_1">Figure 4</ref> shows examples of point clouds reconstructed from given inputs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Auto-encoding</head><p>We further quantitatively compare the reconstruction ability of our flow-based auto-encoder with l-GAN <ref type="bibr" target="#b0">[1]</ref> and AtlasNet <ref type="bibr" target="#b16">[17]</ref>. Following the setting of AtlasNet, the stateof-the-art in this task, we train our auto-encoder on all shapes in the ShapeNet dataset. The auto-encoder is trained with the reconstruction likelihood objective L recon only. At  75.5 79.9 T-L Network <ref type="bibr" target="#b13">[14]</ref> 74.4 -VConv-DAE <ref type="bibr" target="#b41">[42]</ref> 75.5 80.5 3D-GAN <ref type="bibr" target="#b47">[48]</ref> 83.3 91.0 l-GAN (EMD) <ref type="bibr" target="#b0">[1]</ref> 84.0 95.4 l-GAN (CD) <ref type="bibr" target="#b0">[1]</ref> 84.5 95.4 PointGrow <ref type="bibr" target="#b43">[44]</ref> 85.7 -MRTNet-VAE <ref type="bibr" target="#b12">[13]</ref> 86.4 -FoldingNet <ref type="bibr" target="#b50">[51]</ref> 88.4 94.4</p><p>l-GAN (CD) <ref type="bibr">[</ref> test time, we sample 4096 points per shape and split them into an input set and a reference set, each consisting of 2048 points. We then compute the distance (CD or EMD) between the reconstructed input set and the reference set 1 . Although our model is not directly trained with EMD, it obtains the best EMD score, even higher than l-GAN trained with EMD and AtlasNet which has more than 40 times more parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Unsupervised representation learning</head><p>We finally evaluate the representation learning ability of our auto-encoders. Specifically, we extract the latent representations of our auto-encoder trained in the full ShapeNet dataset and train a linear SVM classifier on top of it on Mod-elNet10 or ModelNet40 <ref type="bibr" target="#b48">[49]</ref>. Only for this task, we normalize each individual point cloud to have zero-mean per axis and unit-variance globally, following prior works <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b0">1]</ref>. We also apply random rotations along the gravity axis when training the auto-encoder. A problem with this task is that different authors have been using different encoder architectures with a different number of parameters, making it hard to perform an apples-to-apples comparison. In addition, different authors may use different pre-processing protocols (as also noted by Yang et al. <ref type="bibr" target="#b50">[51]</ref>), which could also affect the numbers.</p><p>In <ref type="table" target="#tab_1">Table 2</ref>, we still show the numbers reported by previous papers, but also include a comparison with l-GAN <ref type="bibr" target="#b0">[1]</ref> trained using the same encoder architecture and the exact same data as our model. On ModelNet10, the accuracy of our model is 1.5% and 0.9% higher than l-GAN (EMD) and l-GAN (CD), respectively. On ModelNet40, the performance of the three models is very close.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and future works</head><p>In this paper, we propose PointFlow, a generative model for point clouds consisting of two levels of continuous normalizing flows trained with variational inference. Future work includes applications to other tasks such as point cloud reconstruction from a single image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>In the appendix, we first describe the detailed hyperparameters and model architectures for our experiments in Section B. We then compare our model with additional baselines to understand the effect of different model components in Section C. Limitations and typical failure cases are discussed in Section D. Finally, additional visualizations of latent space t-SNE, interpolations and flow transformations are presented in Section E, Section F, and Section G respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training details</head><p>In this section, we provide details about our network architectures and training hyper-parameters. We will release the code to reproduce our experiments. Please refer to algorithm 1 for the detailed training procedure.</p><p>Encoder. The architecture of our encoder follows that of Achlioptas et al. <ref type="bibr" target="#b0">[1]</ref>. Specifically, we first use 1D Convolution with filter size 128, 128, 256, and 512 to process each point independently and then use max pooling to create a 512-dimension feature as done in PointNet <ref type="bibr" target="#b37">[38]</ref>. Such a feature is invariant to the permutation of points due to the maxpooling. Finally, we apply a three-layer MLP with 256 and 128 hidden dimensions to convert the permutation invariant feature to a D z -dimension one. For the unsupervised representation learning experiment, we set D z = 512 following convention. For all other experiments, D z is set to 128.</p><p>CNF prior. The CNF prior models the distribution P ψ (z). We follow FFJORD <ref type="bibr" target="#b15">[16]</ref>'s released code to use three concatsquash layers to model the dynamics f ψ . A concatsquash layer is defined as:</p><formula xml:id="formula_26">CS(x, t) = (W x x + b x )σ(W t t + b t ) + (W b t + b b t),<label>(10)</label></formula><p>where W x , b x , W t , b t , W b , and b b are all trainable parameters and σ(·) is the sigmoid function. f ψ uses three concatsquash layers with a hidden dimension 256.</p><p>Tanh is used as the non-linearity between layers. We use a Moving Batch Normalization layer to learn the scale of each dimension before and after the CNF, following FFJORD's released code <ref type="bibr" target="#b15">[16]</ref>. Specifically, Moving Batch Normalization is defined as</p><formula xml:id="formula_27">MBN(x) = x − µ σ γ + β,<label>(11)</label></formula><p>where γ and β are trainable parameters, Different from batch normalization proposed by Ioffe and Szegedy <ref type="bibr" target="#b20">[21]</ref>, µ and σ are running averages of the batch mean and standard deviation. MovingBatchNorm is invertible : MBN −1 (y) = y−β γ σ + µ. Its log determinant is given as:</p><formula xml:id="formula_28">log det ∂ MBN(x) ∂x = i log |γ i | − log |σ i |.<label>(12)</label></formula><p>CNF decoder. The CNF decoder models the reconstruction likelihood P θ (X|z). We extend the concatsquash layer to condition on the latent vector z:</p><formula xml:id="formula_29">CCS(x, z, t) = (W x x + b x )σ(W tt t + W tz z + b t ) + (W bt t + W bz z + b b t),<label>(13)</label></formula><p>where W x , W tt , W tz , W bt , W bz , b t , b b are all learnable parameters.</p><p>The CNF decoder uses four conditional concatsquash layers with a hidden dimension 512 to model the dynamic g θ . The non-linearity between layers is Tanh. Similar to the CNF prior model, we also add a Moving Batch Normalization layer before and after the CNF. In this case, all 3D points (from different shapes) from a batch are used to compute the batch statistics.</p><p>Hyper-parameters. We use an Adam optimizer with an initial learning rate 0.002, β 1 = 0.9, and β 2 = 0.999. The learning rate decays linearly to 0 starting at the 2000 th epoch and ends at the 4000 th epoch. We do not use any weight decay. We also learn the integration time t 1 during training by back-propogation <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional comparisons</head><p>In this section, we compare our model to more baselines to show the effectiveness of the model design. The first baseline is Neural Statistician (NS) <ref type="bibr" target="#b10">[11]</ref>, a state-of-the-art generative model for sets. We modify its official code for generating 2D spatial coordinates of MNIST digits to make it work with 3D point cloud coordinates. We use the same encoder architecture as our model, and use the VAE decoder provided by authors with the input dimension changed from 2 to 3. It differs from our model mainly in 1) using VAEs instead of CNFs to model the reconstruction likelihood, and 2) using a simple Gaussian prior instead of a flow-based one. The second baseline is VAECNF, where we use the CNF to model the reconstruction likelihood but not prior. Specifically, the VAECNF optimizes ELBO in the following form:</p><formula xml:id="formula_30">L(X; φ, θ) = x∈X log P (G −1 θ (x; z)) − t 1 t 0 Tr ∂g θ ∂y(t) dt + DKL(Q φ (z|X)||P (z)) ,<label>(14)</label></formula><p>where P (z) is a standard Gaussian N (0, I) and D KL is the KL-divergence. As another baseline, we follow l-GAN <ref type="bibr" target="#b0">[1]</ref> to train a WGAN <ref type="bibr" target="#b18">[19]</ref> in the latent space of our pretrained auto-encoder. Both the discriminator and the generator are MLP with batch normalization between layers. The generator has three layers with hidden dimensions 256. The discriminator has three layers with hidden dimensions 512. The results are presented in <ref type="table">Table 4</ref>. Neural Statistician <ref type="bibr" target="#b10">[11]</ref> is able to learn the marginal point distribution but fails to learn the correct shape distribution, as it obtains the best marginal JSD but very poor scores according to metrics that measure similarities between shape distributions. Also, <ref type="table">Table 4</ref>: Ablation studies. ↑: the higher the better, ↓: the lower the better. The best scores are highlighted in bold. MMD-CD scores are multiplied by 10 3 ; MMD-EMD scores are multiplied by 10 2 ; JSDs are multiplied by 10 2 . </p><formula xml:id="formula_31">d i=1 ln σ i z ← σ + µ {Reparameterization.} w ← F −1 ψ (z) L prior = log N (w; 0, I) − t1 t0 Tr ∂f ψ (w(t)) ∂w(t) dt L ← 0 for x i ∈ X t do do y i ← G −1 θ (x i ; z) L i ← log N (y i ; 0, I) − t1 t0</formula><p>Tr ∂g θ (yi(t)) ∂yi(t) dt L ← L + L i end for L recon = L |Xt| L = L recon + L prior + L ent φ, ψ, θ ← Adam(L, φ, ψ, θ) end for return Q φ , G θ , F ψ using a flexible prior parameterized by a CNF (PointFlow) is better than using a simple Gaussian prior (VAECNF) or a prior learned with a latent GAN (WGAN-CNF) that requires two-stage training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Limitation and failure cases</head><p>In this section, we discuss the limitation of our model and present visualizations of difficult cases where our model fails. As mentioned in FFJORD <ref type="bibr" target="#b15">[16]</ref>, each integration requires evaluating the neural networks modeling the dynamics multiple times. The number of function evaluations tends to increase as the training proceeds since the dynamic becomes more complex and more function evaluations are needed to achieve the same numerical precision. This issue limits our model size and makes the convergence slow. Grathwohl et al. indicate that using regularization such as weight decay could alleviate such an issue, but we empirically find that using regularization tends to hurt performance. Future advances in invertible models like CNF might help improve this issue. Typical failure case appears when reconstructing or generating the rare shape or shapes with many thin structures as presented in <ref type="figure" target="#fig_2">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Latent space visualizations</head><p>We provide visualization of the sampled latent vectors z ∈ R 128 in <ref type="figure" target="#fig_3">Figure 6</ref>. We sample 1000 latent vectors and run t-SNE <ref type="bibr" target="#b32">[33]</ref> to visualize these latent vectors in 2D. Shapes with similar styles are close in the latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Interpolation</head><p>In this section, we present interpolation between two different shapes using our model. For two shapes X 1 and X 2 , we first compute the mean of the posterior distribution using Q θ (z|X). Let µ 1 and µ 2 be the means of the posterior distribution for X 1 and X 2 respectively. We use µ 1 and µ 2 as the latent representation for these two shapes. We then use the inverse prior flow F −1 ψ to transform µ 1 and µ 2 back to the prior space. Let w 1 = F −1 ψ (µ 1 ) and w 2 = F −1 ψ (µ 2 ) be the corresponding vectors for µ 1 and µ 2 in the prior space. We use spherical interpolation between w 1 and w 2 to retrieve a series of vectors w i . For each w i , we use the CNF prior F ψ and the CNF decoder G θ to generate the corresponding shape X i . <ref type="figure" target="#fig_5">Figure 7</ref> contains examples of the interpolation.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. More flow transformation</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Examples of point clouds generated by our model. From top to bottom: airplane, chair, and car.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Examples of point clouds reconstructed from inputs. From top to bottom: airplane, chair, and car. On each side of the figure we show the input point cloud on the left and the reconstructed point cloud on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Difficult cases for our model. Rare shapes or shapes that contain many thin structures are usually hard to reconstruct in high quality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Visualization of latent space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8</head><label>8</label><figDesc>presents more examples of flow transformations from the Gaussian prior to different shapes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Feature space interpolation. The left-most and the right-most shapes are sampled from scratch. The shapes in between are generated by interpolating the two shapes in the prior space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Additional visualizations on the process of transforming prior to point cloud.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Unsupervised feature learning. Models are first trained on ShapeNet to learn shape representations, which are then evaluated on ModelNet40 (MN40) and Model-Net10 (MN10) by comparing the accuracy of off-the-shelf SVMs trained using the learned representations.</figDesc><table><row><cell>Method</cell><cell cols="2">MN40 (%) MN10 (%)</cell></row><row><cell>SPH [24]</cell><cell>68.2</cell><cell>79.8</cell></row><row><cell>LFD [4]</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Auto-encoding performance evaluated by CD and EMD. AtlasNet is trained with CD and l-GAN is trained on CD or EMD. Our method is not trained on CD or EMD. CD scores are multiplied by 10 4 ; EMD scores are multiplied by 10 2 .</figDesc><table><row><cell>Model</cell><cell cols="2"># Parameters (M) CD EMD</cell></row><row><cell>l-GAN (CD) [1]</cell><cell>1.77</cell><cell>7.12 7.95</cell></row><row><cell>l-GAN (EMD) [1]</cell><cell>1.77</cell><cell>8.85 5.26</cell></row><row><cell>AtlasNet [17]</cell><cell>44.9</cell><cell>5.13 5.97</cell></row><row><cell>PointFlow (ours)</cell><cell>1.30</cell><cell>7.54 5.18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Point cloud encoder Q φ ; CNFs G θ and F ψ , whose dynamics are defined by g θ and f ψ , respectively; Integration time interval [t 0 , t 1 ]; Learning rate α; Total number of training iterations T ; Data samples X t .for t = 1, 2, . . . , T do do µ, σ ← Q φ (X t ) {d is the dimension of µ} L</figDesc><table><row><cell></cell><cell></cell><cell cols="2"># Parameters (M)</cell><cell>JSD (↓)</cell><cell cols="2">MMD (↓)</cell><cell cols="2">COV (%, ↑)</cell><cell cols="2">1-NNA (%, ↓)</cell></row><row><cell cols="2">Category Model</cell><cell>Full</cell><cell>Gen</cell><cell></cell><cell>CD</cell><cell>EMD</cell><cell>CD</cell><cell>EMD</cell><cell>CD</cell><cell>EMD</cell></row><row><cell></cell><cell>NS [11]</cell><cell>2.29</cell><cell>1.00</cell><cell>1.74</cell><cell>0.655</cell><cell>4.51</cell><cell>7.81</cell><cell>4.51</cell><cell>99.61</cell><cell>99.61</cell></row><row><cell></cell><cell>VAECNF</cell><cell>1.47</cell><cell>0.92</cell><cell>6.30</cell><cell>0.261</cell><cell>3.35</cell><cell>41.98</cell><cell>46.17</cell><cell>88.64</cell><cell>82.72</cell></row><row><cell>Airplane</cell><cell>WGAN-CNF PointFlow (ours)</cell><cell>1.75 1.61</cell><cell>1.06 1.06</cell><cell>4.29 4.92</cell><cell>0.254 0.217</cell><cell>3.23 3.24</cell><cell>42.47 46.91</cell><cell>48.40 48.40</cell><cell>75.80 75.68</cell><cell>75.68 75.06</cell></row><row><cell></cell><cell>Training set</cell><cell>-</cell><cell>-</cell><cell>6.61</cell><cell>0.226</cell><cell>3.08</cell><cell>42.72</cell><cell>49.14</cell><cell>70.62</cell><cell>67.53</cell></row><row><cell cols="3">Algorithm 1 PointFlow training.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Require:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>ent = d 2 (1 + ln (2π)) +</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">x = G θ (y(t0); z) y(t0)+ t 1 t 0 g θ (y(t), t, z)dt, y(t0) ∼ P (y) ,</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† We run the official code of l-GAN on our preprocessed dataset using the same encoder architecture as our model.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use a separate reference set because we expect the auto-encoder to learn the point distribution. Exactly reproducing the input points is acceptable behavior, but should not be given a higher score than randomly sampling points from the underlying point distribution.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgment</head><p>This work was supported in part by a research gift from Magic Leap. Xun Huang was supported by NVIDIA Graduate Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations and generative models for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panos</forename><surname>Achlioptas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Diamanti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note>Ioannis Mitliagkas, and Leonidas Guibas</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">ShapeNet: An Information-Rich 3D Model Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pat</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zimo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Stanford University -Princeton University -Toyota Technological Institute at Chicago</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>cs.GR</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On visual similarity based 3d model retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding-Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Pei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yu-Te Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ouhyoung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="223" to="232" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tian Qi Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Comparison of maximum likelihood and gan-based training of real nvps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benigno</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05263</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Nice: Non-linear independent components estimation. CoRR, abs/1410</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8516</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Density estimation using real nvp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Dovrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itai</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Avidan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01659</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Learning to sample. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards a neural statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A point set generation network for 3d object reconstruction from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multiresolution tree networks for 3d point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matheus</forename><surname>Gadelha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning a predictable and generative vector representation for objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ffjord: Free-form continuous dynamics for scalable reversible generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Groueix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Aubry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Flow-gan: Combining maximum likelihood and adversarial learning in generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manik</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural autoregressive flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gal: Geometric adversarial loss for single-view 3d-object reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rotation invariant spherical harmonic representation of 3d shape descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szymon</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rusinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improving variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Babaeizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Durk</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.01434</idno>
		<title level="m">Videoflow: A flow-based generative model for video</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deformnet: Free-form deformation network for 3d shape reconstruction from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Kurenkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animesh</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viraj</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In WACV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Barnabas Poczos, and Ruslan Salakhutdinov</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05795</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Point cloud gan. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient dense point cloud object reconstruction using deformation vector fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kejie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huangying</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Revisiting classifier two-sample tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Oquab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pixel recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Waveglow: A flow-based generative network for speech synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno>abs/1811.00002</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Vconvdae: Deep volumetric shape learning without object labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshops</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Pointwise: An unsupervised point-wise feature learning network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Shoef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04544</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Pointgrow: Autoregressively learned point cloud generation with self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">E</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay E</forename><surname>Sarma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05591</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Reconstructing street-scenes in real-time from a driving car</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladyslav</forename><surname>Usenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Stückler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sylvester normalizing flows for variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><forename type="middle">M</forename><surname>Hasenclever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In UAI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">An empirical study on evaluation metrics of generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiantong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07755</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Foldingnet: Point cloud auto-encoder via deep grid deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Yifan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.11286</idno>
		<title level="m">Patch-based progressive 3d point set upsampling</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ec-net: an edge-aware point set consolidation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Pu-net: Point cloud upsampling network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnabas</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Adversarial autoencoders for generating 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Zamorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Zieba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafał</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Stokowiec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Trzciński</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.07605</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
