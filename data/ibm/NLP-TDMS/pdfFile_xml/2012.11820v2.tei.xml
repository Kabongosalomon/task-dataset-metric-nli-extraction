<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recognizing Emotion Cause in Conversations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Bhardwaj</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><forename type="middle">Bai</forename><surname>Samson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romila</forename><surname>Ghosh</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">Independent researcher</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niyati</forename><surname>Chhaya</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Adobe Research</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">CIC</orgName>
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recognizing Emotion Cause in Conversations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recognizing the cause behind emotions in text is a fundamental yet under-explored area of research in NLP. Advances in this area hold the potential to improve interpretability and performance in affect-based models. Identifying emotion causes at the utterance level in conversations is particularly challenging due to the intermingling dynamic among the interlocutors. To this end, we introduce the task of recognizing emotion cause in conversations with an accompanying dataset named RECCON. Furthermore, we define different cause types based on the source of the causes and establish strong transformer-based baselines to address two different sub-tasks of RECCON: 1) Causal Span Extraction and 2) Causal Emotion Entailment. The dataset is available at https: //github.com/declare-lab/RECCON.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Emotions are intrinsic to humans; consequently, emotion understanding is a key part of human-like artificial intelligence (AI). Language is often indicative of one's emotions. Hence, emotion recognition has attracted much attention in the field of natural language processing (NLP) <ref type="bibr" target="#b18">(Kratzwald et al., 2018;</ref><ref type="bibr" target="#b7">Colneriĉ and Demsar, 2018)</ref>, due to its wide range of applications in opinion mining, recommender systems, healthcare, and other areas.</p><p>Substantial progress has been made in the detection and classification of emotions, expressed in text or videos, according to emotion taxonomies <ref type="bibr" target="#b10">(Ekman, 1993;</ref><ref type="bibr" target="#b26">Plutchik, 1982)</ref>. However, further reasoning about emotions, such as understanding the cause of an emotion expressed by a speaker, has been less explored so far. For example, consider the following review of a smartphone, "I hate the touchscreen as it freezes after 2-3 touches". * Equal contribution. Randomly ordered.  Understanding this text implies not only detecting the expressed negative emotion, specifically DIS-GUST, but also spotting its cause <ref type="bibr" target="#b22">(Liu, 2012</ref>)-in this case, "it freezes after 2-3 touches." Of a wide spectrum of emotion-reasoning tasks <ref type="bibr" target="#b11">(Ellsworth and Scherer, 2003)</ref>, in this work, we focus on identifying the causes (also called antecedents, triggers, or stimuli) of emotions expressed specifically in conversations. In particular, we look for events, situations, opinions, or experiences in the conversational context that is primarily responsible for an elicited emotion in the target utterance. Apart from event mentions, the cause could also be a speaker's counterpart reacting towards an event cared for by the speaker (interpersonal emotional influence).</p><p>We introduce the task of recognizing emotion cause in conversations, which refers to the extraction of such stimuli behind an emotion in a conversational utterance. The cause could be present in the same or contextual utterances (conversational history). We formally define this task in §4.2.</p><p>In <ref type="figure" target="#fig_0">Fig. 1</ref>, we exemplify this task. In the first example, we are interested in knowing the cause of person B's (P B ) emotion <ref type="bibr">(HAPPY)</ref>. It can be seen that P A is happy due to the event-"getting married", and similarly, P B also reacts positively to this event. Here, we could infer that P B 's emotion is caused either by the reference of the first utterance to the event of getting married, or by the fact that P A is happy about getting married-both of which can be considered as stimulus for P B 's emotion. In the second conversation, the cause of P A 's emotion is the event "football match" and a negative emotion DISGUST indicates P A 's unsatisfied experience of the match. In contrast, P B takes pleasure of the match-sharing the same cause with P A -with HAPPINESS emotion. These examples demonstrate the challenging problem of recognizing emotion causes in conversations, which to the best of our knowledge, is one of the first attempts in this area of research.</p><p>We can summarize our contributions as follows:</p><p>1. We introduce a new task, recognizing emotion cause in conversations, and dive into many unique characteristics of this task that is peculiar to conversations. In particular, we define the relevant types of emotion causes ( §5).</p><p>2. We describe a new annotated dataset for this task, RECCON 1 , including both acted and realworld conversations ( §4).</p><p>3. Further, we introduce two challenging sub-tasks that demand complex reasoning ( §8), and provide the corresponding baselines ( §6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Initial works in emotion analysis and opinion mining explored different aspects of affect beyond polarity prediction, such as identifying the opinion/emotion-feeler (or holder, source) <ref type="bibr" target="#b8">(Das and Bandyopadhyay, 2010;</ref><ref type="bibr" target="#b6">Choi et al., 2005)</ref>. However, the task of emotion cause extraction was studied later initially by . Such initial works involved extracting cause events in a ruledriven manner . <ref type="bibr" target="#b15">Gui et al. (2016)</ref> constructed an emotion cause extraction dataset by identifying events that trigger emotions. To avoid the latent emotions and implicit emotion causes associated with the informal text, the authors used news articles as the target corpus for cause extraction. Choosing news articles as the source data for cause extraction helped them reduce reasoning complexity for the annotators while extracting emotion causes. <ref type="bibr" target="#b13">Ghazi et al. (2015)</ref> and <ref type="bibr" target="#b12">Gao et al. (2017)</ref> are other notable works on Emotion Cause Extraction (ECE).</p><p>Modifying the ECE task, <ref type="bibr" target="#b29">Xia and Ding (2019)</ref> proposed Emotion-Cause Pair Extraction (ECPE) that jointly identifies both emotions and their corresponding causes <ref type="bibr" target="#b4">(Chen et al., 2018)</ref>. Further,  recently proposed the conditional Emotion Cause Pair (ECP) identification task, where they highlight the causal relationship to be valid only in particular contexts. We incorporate this property in our dataset construction, as we annotate multiple spans in the conversational history that sufficiently indicate the cause. Similar to , we also provide negative examples of context that does not contain the causal span.</p><p>Our work is a natural extension of these works. We propose a new dataset on conversations, which is more difficult to annotate and the associated task of recognizing emotion cause in conversations poses a greater hitch to solve due to numerous challenges mentioned in the following sections (see §8), for example: 1) expressed emotions are not always explicit in the conversations; 2) conversations can be very informal where the phrase connecting emotion with its cause can often be implicit and thus needs to be inferred; 3) the stimuli of the elicited emotions can be located far from the target utterance in the conversation history and detecting it requires complex reasoning and co-reference often using commonsense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Definiton of the Task</head><p>We distinguish between emotion evidence and emotion cause:</p><p>• Emotion evidence is a part of the text that indicates the presence of an emotion in the speaker's emotional state. It acts in the real world between the text and the reader or the system. Identifying and interpreting the emotion evidence is the underlying process of the well-known emotion detection task.</p><p>• Emotion cause is a part of the text expressing the reason for the speaker to feel the emotion given by the emotion evidence. It acts in the described world between the (described) circumstances and the (described) speaker's emotional state. Identifying the emotion cause constitutes the task we consider in this paper.</p><p>For instance, in <ref type="figure" target="#fig_0">Fig. 1</ref>, P B 's turn contains evidence of P B 's emotion, while P A 's turn contains its cause.</p><p>The same text span can be both emotion evidence and cause, but generally this is not the case.</p><p>Defining the notion of emotion cause is, in a way, the main goal of this paper. However, short of a formal definition, we will explain this notion on numerous examples and, in computational terms, via the labeled dataset. Note that a text part can be both emotion evidence and cause.</p><p>We use the following terminologies throughout the paper. The target utterance U t is the t th utterance of a conversation, whose emotion label E t is known and whose emotion cause we want to identify. The conversational history H(U t ) is the set of all utterances from the beginning of the conversation till the utterance U t , including U t . A causal span for an utterance U is a maximal sub-string, of an utterance from H(U ), that is a part of U 's emotion cause; we will denote the set of the causal spans by CS(U ). A causal utterance is an utterance containing a causal span; we denote the set of all causal utterances for U by C(U ) ⊆ H(U ). An utterance-causal span (UCS) pair is a pair (U, S), where U is an utterance and S ∈ CS(U ).</p><p>Thus, recognizing emotion cause is the task of identifying all (correct) UCS pairs in a given text.</p><p>In the context of our training procedure, we will refer to <ref type="formula">(</ref> We consider two popular conversational datasets IEMOCAP <ref type="bibr" target="#b1">(Busso et al., 2008)</ref> and <ref type="bibr">DailyDialog (Li et al., 2017)</ref>, both equipped with utterancelevel emotion labels.</p><p>IEMOCAP is a dataset of two-person conversations annotated with six emotions classes HAPPY, SAD, NEUTRAL, ANGER, EXCITED, and FRUS-TRATED. The dialogues in this dataset span across sixteen unique conversational situations. To avoid redundancy, we handpick only one dialogue from each of these situations. We denote the subset of RECCON comprising these dialogues as RECCON-IE.</p><p>DailyDialog is a natural human communication dataset covering various topics about our daily lives. All utterances are labeled with emotion categories: ANGER, DISGUST, FEAR, HAPPY, NEU-TRAL, SAD, and SURPRISE. The dataset has over 83% NEUTRAL labels. Due to this skewness, we randomly selected dialogues which has at least four non-neutral utterances. We denote this subset of RECCON, comprising the dialogues from DailyDialog, as RECCON-DD. Some statistics about the annotated dataset is shown in <ref type="table" target="#tab_4">Table 2</ref>.</p><p>Need for sampling from two different datasets. Although both IEMOCAP and DailyDialog are annotated with utterance-level emotions, they differ in many aspects. Firstly, the average number of utterances per dialogue in IEMOCAP is more than 50, whereas DailyDialog has a shorter average length of 8. Secondly, the shifts between non-neutral emotions (e.g., sad to anger, happy to excited) are more frequent in IEMOCAP compared to DailyDialog (see <ref type="bibr">(Ghosal et al., 2020)</ref>). Consequently, both cause detection and causal reasoning in IEMOCAP are more interesting as well as difficult. Lastly, in <ref type="table" target="#tab_4">Table 2</ref>, we can see that in our annotated IEMO-CAP split, almost 40.5% utterances have their emotion cause in utterances at least 3 timestamps distant in the contextual history. On the contrary, this percentage is just 13% in our annotated DailyDialog dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Annotation Process</head><p>Annotation guidelines. Given an utterance U t labeled with an emotion E t , the annotators were asked to extract the set of causal spans CS(U t ) that sufficiently represent the causes of the emotion E t . If the cause of E t was latent, i.e., there was no explicit causal span in the dialog, the annotators wrote down the assumed causes that they inferred from the text. Each utterance was annotated by two human experts-graduate students with reasonable knowledge of the task.</p><p>In fact, the annotators were asked to look for the casual spans of U t in the whole dialog and not only in the past history H(U t ). We show one such case in <ref type="figure" target="#fig_4">Fig. 2b</ref> where the causal span of the emotion FEAR in utterance 1 is recognized in utterance 3 -"someone is stalking me". However, they flagged only seven instances of the utterances with explicit emotion causal spans that occur in the conversational future with respect to U t in the whole dataset. As such, we discarded those spans and made a decision to consider only causal spans in H(U t ); hence the definition in §3.</p><p>Emotional expression. An utterance can contain 1) a description of the triggers or stimuli of the expressed emotion, and / or 2) a reactionary emotional expression. In our setup, by following the discrimination among emotion evidence and cause as explained in §3, we instructed the annotators to look beyond just emotional expressions and identify the emotion cause. We can illustrate this with <ref type="figure" target="#fig_4">Fig. 2c</ref>, where P A explains the cause for HAPPI-NESS; the same cause evokes the emotion EXCITED in P B . Meanwhile, the utterance 2 by P B is merely an emotional expression (evidence).</p><p>Emotion cause can also corroborate in generating an emotional expression, e.g., in <ref type="figure" target="#fig_4">Fig. 2c</ref>, the event "winning the prize" causes EXCITED emotion in P B which directs P B to utter the expression "Wow! Incredible". This type of generative reasoning will be very important in our future work.</p><p>Why span detection? Firstly, emotion-cause extraction has historically been defined as an information extraction task of identifying spans within the emotion-bearing sentences <ref type="bibr" target="#b29">(Xia and Ding, 2019;</ref><ref type="bibr" target="#b13">Ghazi et al., 2015)</ref>. The core assumption is that such spans are good descriptors of the underlying causes towards the generated emotions <ref type="bibr" target="#b28">(Talmy, 2000)</ref>. We extend this popular formalism into a multi-span framework. Secondly, while recognizing emotion cause is driven by multiple controlling variables (see Appendix A), we adopt this setup as these spans can often represent or allude to these controlling variables. A more elaborate setup would require explaining how the spans can be combined to form the trigger and consequently evoke the emotion <ref type="figure" target="#fig_5">(Fig. 7)</ref>; we leave such emotion causal reasoning in conversations to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Annotation Aggregation</head><p>Following <ref type="bibr" target="#b15">Gui et al. (2016)</ref>, we aggregate the annotations in two stages: utterance-level and span-level aggregation.</p><p>Stage 1: Utterance-level aggregation. Here, we decide whether an utterance is causal by majority voting: a third expert annotator is brought in as the tie breaker.</p><p>Stage 2: Span-level aggregation. Within each causal utterance (selected in the previous step), for spans that share some sub-string across annotators, we take the union of the spans as the final causal span. In other words, for overlapping annotated spans, we take the larger boundary as the final causal span. If they do not share a sub-span, a third annotator is brought in to determine the final span from the existing spans. This third annotator is also instructed to prefer the shorter spans over the longer ones when they can sufficiently represent the cause   without losing any information. The third annotator could not break the tie for 34 causal utterances, which we discarded from the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Dataset Statistics</head><p>We have measured two types of inter-annotator agreement scores: 1) at the utterance level and 2) at the span level. Following <ref type="bibr" target="#b15">Gui et al. (2016)</ref>, we measured the inter-annotator agreement (IAA) at the utterance level, resulting in a kappa score of 0.7928. However, as pointed out by <ref type="bibr" target="#b0">Brandsen et al. (2020)</ref>, macro F1 score is a more appropriate approach for span extraction-type tasks. Hence, at the utterance level, we also compute the pairwise macro F1 score between all possible pairs of annotators and then average them. This gives us a 0.8839 macro F1 score. <ref type="bibr" target="#b0">Brandsen et al. (2020)</ref> also suggest the removal of negative examples-in our case, the ut-  terances in the conversational history containing no causal span for the emotion of the target utterancefor macro F1 calculation, since such examples are usually very frequent, which may lead to a skewed F1 score. As expected, adopting this yields a lower F1 score of 0.8201. At span level, the F1 score, as explained in <ref type="bibr" target="#b27">Rajpurkar et al. (2016)</ref>, is calculated for all possible pairs of annotators followed by taking their average. Overall, we obtain an F1 score of 0.8035 at span level. In <ref type="table" target="#tab_3">Table 1</ref>, we compare our dataset with the existing datasets in terms of size, data sources, and language. The remaining statistics of RECCON are consolidated in <ref type="table" target="#tab_4">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Types of Emotion Causes</head><p>In our dataset, RECCON, we observe five predominant types of emotion causes that are based on the source of the stimuli (events / situations / acts) in the conversational context, responsible for the target emotion. The annotators were asked to flag the utterances with latent emotion cause or emotion cause of type 2b, as explained below. The distribution of these cause types is given in <ref type="table" target="#tab_4">Table 2</ref>.</p><p>Type 1: No Context. The cause is present within the target utterance itself. The speaker feeling the emotion explicitly mentions its cause in the target utterance (see <ref type="figure" target="#fig_4">Fig. 2a</ref>).</p><p>Type 2: Inter-Personal Emotional Influence. The emotion cause is present in the other speaker's utterances. We observe two possible sub-types of such influences: 2a) Trigger Events / Situations. The emotion cause lies within an event or concept mentioned by the other speaker.</p><p>2b) Emotional Dependency. The emotion of the target speaker is induced from the emotion of the other speaker over some event / situation.</p><p>Type 3: Self-Contagion. In many cases, we observe that the cause of the emotion is primarily due to a stable mood of the speaker that was induced in some previous dialogue turns. For example, in a dialogue involving cordial greetings, there is a tendency for a HAPPY mood to persist across several turns for a speaker. <ref type="figure" target="#fig_1">Fig. 3a</ref> presents an example where such self-influences can be observed. Utterance 1 establishes that P A likes winter. This concept triggers a HAPPY mood for the future utterances, as observed in utterances 3 and 5. In <ref type="figure" target="#fig_1">Fig. 3b</ref>, similarly, the trigger of emotion EXCITED in utterance 3 is mentioned by the same speaker in his or her previous utterance.</p><p>Type 4: Hybrid. Emotion causes of type 2 and 3 can jointly cause the emotion of an utterance, as illustrated by <ref type="figure" target="#fig_1">Fig. 3c</ref>.</p><p>Type 5: Unmentioned Latent Cause. There are instances in the dataset where no explicit span in the target utterance or the conversational history can be identified as the emotion cause. <ref type="figure" target="#fig_4">Fig. 2b</ref> shows such a case. Here, in first utterance, P A speaks of being terrified and fearful without indicating the cause. We annotate such cases as latent causes. Sometimes the cause is revealed in future utterances, e.g., "someone is stalking me" as the reason of being fearful. However, as online settings would not have access to the future turns, we refrain from treating future spans as causes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We formulate two distinct subtasks of recognizing emotion cause in conversations: 1) causal span extraction and 2) causal emotion entailment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Compiling Dataset Splits</head><p>RECCON-DD is the subset of our dataset that contains dialogues from DailyDialog. For this subset, we created the training, validation, and testing examples based on the original splits in <ref type="bibr" target="#b21">(Li et al., 2017)</ref>. However, this resulted in the validation and testing sets to be quite small, so we moved some dialogues to them from the original training set. The subset RECCON-IE consists of dialogues from the IEMOCAP dataset. This subset is quite small as it contains only sixteen unique dialogues (situations). So, we consider the entire RECCON-IE as another testing set, emulating an out-ofdistribution generalization test. We report results on this dataset based on models trained on RECCON-DD. In our experiments, we ignore the utterances with only latent emotion causes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Generating Negative Examples</head><p>The annotated dataset, RECCON (consisting of subsets RECCON-DD and RECCON-IE) only contains positive examples, where an emotioncontaining target utterance is annotated with a causal span extracted from its conversational historical context. However, to train a model for the recognizing emotion cause in conversations task, we need negative examples, i.e., the instances which are not cause of the utterance. In the sequel, we use the terminology introduced in §3; the reader should refer to that section for clearer understanding.</p><p>We adopt the following strategy to create the negative examples: </p><formula xml:id="formula_0">(U t , U i ) | U i ∈ H(U t ) \ C(U t )}, where H(U t )</formula><p>is the conversational history and C(U t ) is the set of causal utterances for U t .</p><p>We discuss building Fold 2 and Fold 3 in §7. The statistics of the final dataset are shown in <ref type="table" target="#tab_7">Table 3</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Subtask 1: Causal Span Extraction</head><p>Causal Span Extraction is the task of identifying the causal span (emotion cause) for a target nonneutral utterance. In our experimental setup, we formulate Causal Span Extraction as a Machine Reading Comprehension (MRC) task similar to the task in Stanford Question Answering Dataset <ref type="bibr" target="#b27">(Rajpurkar et al., 2016)</ref>. We propose two different span extraction settings: 1) With Conversational Context and 2) Without Conversational Context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Subtask Description</head><p>With Conversational Context (w/ CC) We believe that the presence of conversational context would be key to the span extraction algorithms. To evaluate this hypothesis, we design this subtask, where the conversational history is available to the model. In this setup, for a target utterance U t , the causal utterance U i ∈ C(U t ), and a causal span S ∈ CS(U t ) from U i , we construct the context, question, and answer as follows: 2 Context: The context of a target utterance U t is the conversational history, i.e., a concatenation of all utterances from H(U t ). Similarly, for a negative example</p><formula xml:id="formula_1">(U t , U i ), where U i / ∈ C(U t ), conversa- tional history of U t is used as context. Question:</formula><p>The question is framed as follows: "The target utterance is &lt; U t &gt;. The evidence utterance is &lt; U i &gt;. What is the causal span from evidence in the context that is relevant to the target utterance's emotion &lt; E t &gt;?".</p><formula xml:id="formula_2">Answer: The causal span S ∈ CS(U t ) appearing in U i if U i ∈ C(U t ).</formula><p>For negative examples, S is assigned an empty string.</p><p>If a target utterance has multiple causal utterances and causal spans, then we create separate (Context, Question, Answer) instances for them. Unanswerable questions are also created from invalid (cause, utterance) pairs following the same approaches explained in §6.1.</p><p>Without Conversational Context (w/o CC) In this formulation, we intend to identify whether the Causal Span Extraction task is feasible when we only have information about the target utterance and the causal utterance. Given a target utterance U t with emotion label E t , its causal utterance U i where U i ∈ C(U t ), and the causal span S ∈ CS(U t ), the question is framed as framed as follows: "The target utterance is &lt; U t &gt;. What is the causal span from context that is relevant to the target utterance's emotion &lt; E t &gt;?". The task is to extract answer S ∈ CS(U t ) from context U i . For negative examples, S is assigned an empty string.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Models</head><p>We use the following two pretrained transformerbased models to benchmark the Causal Span Extraction task:</p><p>RoBERTa Base : We use the roberta-base model <ref type="bibr" target="#b23">(Liu et al., 2019)</ref> and add a linear layer on top of the hidden-states output to compute span start and end logits. Scores of candidate spans are computed following <ref type="bibr" target="#b9">Devlin et al. (2019)</ref>, and the span with maximum score is selected as the answer.</p><p>SpanBERT Fine-tuned on SQuAD : We use SpanBERT <ref type="bibr" target="#b17">(Joshi et al., 2020)</ref> as the second baseline model. SpanBERT follows a different pretraining objective compared to RoBERTa (e.g. predicting masked contiguous spans instead of tokens) and performs better on question answering tasks. In this work we are using the SpanBERT base model fine-tuned on SQuAD 2.0 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Evaluation Metrics</head><p>EM P os (Exact Match): EM represents, with respect to the gold standard data, how many causal spans are exactly extracted by the model.   standard data. Here, for a target utterance U t , the ground truth are empty spans. F 1 : This metric is similar to F1 P os but calculated for every positive and negative example followed by an average over them. While all the above metrics are important for evaluation, we stress that future works should particularly consider performances for EM P os , F1 P os , and F 1 .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Subtask 2: Causal Emotion Entailment</head><p>The Causal Emotion Entailment is a simpler version of the span extraction task. In this task, given a target non-neutral utterance (U t ), the goal is to predict which particular utterances in the conversation history H(U t ) are responsible for the non-neutral emotion in the target utterance. Following the earlier setup, we formulate this task with and without historical conversational context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Subtask Description</head><p>With Conversational Context (w/ CC) : We consider the historical conversational context H(U t ) of the target utterance U t , and posit the problem as a triplet classification task. Here the tuple (U t , U i , H(U t )) is aimed to be classified as positive, U i ∈ C(U t ). For the negative example, the tuple (U t , U i , H(U t )) should be classified as negative as U i / ∈ C(U t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Without Conversational Context (w/o CC) :</head><p>We posit this problem as a binary sentence pair classification task, where (U t , U i ) should be classified as positive as</p><formula xml:id="formula_3">U i ∈ C(U t ). For the negative example (U t , U i ) where U i / ∈ C(U t ),</formula><p>the classification output should be negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Models</head><p>Similar to Subtask 1, we use transformer-based models to benchmark this task. We use a &lt;CLS&gt; token and the emotion label &lt; E t &gt; of the target utterance U t in front, and join the pair or triplet elements with &lt;SEP&gt; in between to create the input. The classification is performed from the corresponding final layer vector of the &lt;CLS&gt; token. We use the following models:</p><p>RoBERTa Base / Large : We use the roberta-base/-large models from <ref type="bibr" target="#b23">(Liu et al., 2019)</ref> as the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Evaluation Metrics</head><p>We use F1 score for both positive and negative examples, denoted as Pos. F1 and Neg. F1 respectively. We also report the overall macro F1. <ref type="table" target="#tab_9">Table 4</ref> reports the experimental results of the causal span extraction task where SpanBERT obtains the best performance in both RECCON-DD and RECCON-IE. SpanBERT outperforms RoBERTa Base in EM P os , and F1 P os metrics. However, the performance of SpanBERT is worse for negative examples, which consequently results in a lower F1 score compared to RoBERTa Base model in both the datasets under "w/o CC" setting. Contrary to this, the performance of the SpanBERT in the presence of context (w/ CC) is consistently higher than RoBERTa Base with respect to all the metrics in RECCON-DD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Main Results</head><p>In <ref type="table" target="#tab_11">Table 5</ref>, we report the performance of the Causal Emotion Entailment task. Under the "w/o CC" setting, in Fold 1, RoBERTa Base outperforms RoBERTa Large by 2% in RECCON-DD. In contrast to this, in RECCON-IE, RoBERTa Large performs better and beats RoBERTa Base by 5.5% in Fold 1. On the other hand, RoBERTa Large outperforms RoBERTa Base in both RECCON-DD and RECCON-IE under the "w/ CC" setting. The performance in RECCON-IE is consistently worse than in RECCON-DD under various settings in both subtask 1 and 2. We reckon this can be due to multiple reasons mentioned in §4.1, making the task harder on the IEMOCAP split.</p><p>We have also analyzed the performance of the baseline models on the utterances having one or multiple causes. The models consistently perform better for the utterances having only one causal span compared to the ones having multiple causes (+7% on an average calculated over all the settings and models).</p><p>In the test data of Fold 1, approximately 38% of the UCS pairs (which we call as Fold 1 ) have their causal spans lie within the target utterances. In <ref type="table" target="#tab_9">Table 4</ref> and 5, we report the results on Fold 1. According to these results, the models perform significantly better on such UCS pairs under all the settings in both the subtasks.</p><p>The models leverage contextual information for both the subtasks in the "w/ CC" setting which substantially improves the performance of the noncontextual (refer to the "w/o CC" setting) counterpart. In this setting, SpanBERT obtains the best performance for positive examples in both RECCON-DD, and RECCON-IE. On the other hand, in the same setting, RoBERTa Large outperforms RoBERTa Base and achieves the best performance in subtask 2.</p><p>The low scores of the models in the subtask 1 and 2 depicts the difficulty of the tasks. As such, we see a significant room for model improvement in these two subtasks of recognizing emotion cause in conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analyses And Discussions</head><p>To further analyze the performance obtained by the models, besides Fold 1, we adopt two more strategies to create the negative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Fold 2:</head><p>In this scheme, we randomly sample the non-causal utterance U i along with the corresponding historical conversational context H(U i ) from another dialogue in the dataset to create a negative example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Fold 3:</head><p>This is similar to Fold 2 with a constraint. In this case, a non-causal utterance U i along with its historical conversational context H(U i ) from the other dialogue is only sampled when its emotion matches the emotion of the target utterance U t to construct a negative example.  Note that unlike Fold 1, a negative example in Fold 2 and 3 comprising a non-causal utterance U i and a target utterance U t belong to different dialogues. For the cases where the causal spans do not lie in the target utterance, we remove the target utterance from its historical context when creating a positive example in Fold 2 and 3. As a result, it helps to prevent the models from learning any trivial patterns. The statistics of Fold 2 and 3 are shown in <ref type="table" target="#tab_7">Table 3</ref>. The use of context (w/ CC) in the baseline models improves the results (see <ref type="table" target="#tab_13">Table 6</ref> and 7) in Fold 2 and 3 as it highlights the contextual discrepancy or coherence between the target utterance and context which should strongly aid in identifying randomly generated negative samples from the rest. For the positive examples, we achieve a much better score in Fold 2 and 3 as compared to Fold 1 (see <ref type="table" target="#tab_9">Table 4</ref> and <ref type="table" target="#tab_11">Table 5</ref>) for both "w/o CC" and "w/ CC" constraints. However, this does not validate Fold 2 and 3 as better training datasets than Fold 1. We confirm this by training the models on Fold 2 and 3 and evaluating them on Fold 1. These two experiments are denoted with Fold 2 − → Fold 1 and Fold 3 − → Fold 1, respectively, and the corresponding results are reported in <ref type="table" target="#tab_13">Table 6</ref> and 7. The outcomes of these experiments, as shown in <ref type="table" target="#tab_13">Table 6</ref> and 7, show abysmal performance by the baseline models on the negative examples in Fold 1. This may be ascribed to the fundamental difference between Fold 1 and Fold 2, 3. Negative samples in Fold 2, 3 are easily identifiable, as compared to Fold 1, as all the model needs to do to judge the absence of a causal span in the context is to detect the contextual incoherence of the target utterance with the context. Models fine-tuned on BERT and SpanBERT are expected to perform well at deciding contextual incoherence. Identifying negative samples in Fold 1, however, requires more sophisticated and non-trivial approach as the target utterances are, just as the positive examples, contextually coherent with the context. As such, a model that correlates contextual incoherence with negative samples naturally performs poorly on Fold 1. The F 1 N eg scores for Fold 2 − → Fold 1, and Fold 3 − → Fold 1 modes under both "w/o CC", and "w/ CC" settings are adversely affected by the low precision of the models in both the subtasks. In other words, the baseline models in these two modes perform poor in extracting empty spans from the ground truth negative examples in subtask 1 and also classify most of the negative examples as positive in subtask 2.</p><p>On the other hand, we do not observe any significant performance drop for either negative or positive examples when the models trained in Fold 1 are evaluated in Fold 2 and 3. This affirms the superiority of Fold 1 as a training dataset. Besides, note that Fold 1 is a more challenging and practical choice than the rest of the two folds as in real scenarios, we need to identify causes of emotions within a single dialogue by reasoning over the utterances in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Challenges in the Task</head><p>This section identifies several examples that indicate the need for complex reasoning to solve the causal span extraction task. Abilities to accurately reason will help validate if a candidate span is causally linked to the target emotion. We believe these pointers would help further research on this dataset and solving the task in general.</p><p>Amount of Spans One of the primary challenges of this task is determining the set of spans that can sufficiently be treated as the cause for a target emotion. The spans should have coverage to be able to formulate logical reasoning steps (performed implicitly by annotators) that include skills such as  numerical reasoning <ref type="figure" target="#fig_7">(Fig. 4)</ref>, amongst others.</p><p>Emotional Dynamics Understanding emotional dynamics in conversations is closely tied with emotion cause identification. As shown in our previous sections, many causal phrases in the dataset depend on the inter-personal event/concept mentions, emotions, and self-influences (sharing causes). We also observe that emotion causes may be present across multiple turns, thus requiring the ability to model long-term information. Emotions of the contextual utterances help in this modeling. In fact, without the emotional information of the contextual utterances, our annotators found it difficult to annotate emotion causes in the dataset. Understanding cordial greetings, conflicts, agreements, and empathy are some of the many scenarios where contextual emotional dynamics play a significant role.</p><p>Commonsense Knowledge Extracting emotion causes in conversations comprises complex reasoning steps and commonsense knowledge is an integral part of this process. The role of commonsense reasoning in emotion cause recognition is more evident when the underlying emotion the cause is  <ref type="figure" target="#fig_7">Figure 4</ref>: In this example, PB, in utt. 12, is sad because of failing to negotiate the desired amount to sell a TV. While "the price is final" is a valid causal span, one also needs to identify the discussion where PA is ready to pay only $2000, which is significantly lesser than the originally quoted $2500.  <ref type="figure" target="#fig_8">Figure 5</ref>: In this example, the emotion cause for utt. 2 may lie in phrases spoken by (and for) the counterpart (PA) and not the target speaker (PB) i.e., "flashy red lines" in PB's utterance points to the property of the "watch" that PA bought. One needs to infer such co-referential links to extract the correct causal spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>latent. Consider the example below:</head><p>( In this case, P A is happily offering help to P B . The cause of happiness in this example is due to the event "greeting" or intention to offer help. On the other hand, P B is fearful because of his/her broken computer. The causes of elicited emotions by both the speakers can only be inferred using commonsense knowledge.</p><p>Complex Co-reference While in narratives, coreferences are accurately used and often explicit, it is not the case in dialogues (see <ref type="figure" target="#fig_8">Fig. 5</ref>).</p><p>Exact vs. Perceived Cause At times, the complex and informal nature of conversations prohibits the extraction of exact causes. In such cases, our annotators extract the spans that can be perceived as the respective cause. These causal spans can be rephrased to represent the exact cause for the expressed emotion. For example, In the above example, the cause lies in the following sentence-"I just want my flip phone to work", with the exact cause meaning-"My flip r?</p><p>.  <ref type="figure" target="#fig_9">Figure 6</ref>: In this example, the cause for the happy state of PB (utt. 6) is corroborated by three indicated spans. First, pB gets happy over receiving a "birthday present" (utt. 3) which is a "gold watch" (utt.4). Then, the emotion evoked by the 4 th utterance is propagated into PB's next utterance where it is confirmed that PB loves the gift ("I love it!"). Performing temporal reasoning over these three spans helps understand that PB is happy because of liking a present received as a birthday gift.</p><p>phone is not working". Special dialogue-act labels such as goal achieved and goal not-achieved can also be adopted to describe such causes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From Cause Extraction to Causal Reasoning</head><p>Extracting causes of utterances involve reasoning steps. In this work, we do not ask our annotators to explain the reasoning steps pertaining to the extracted causes. However, one can still sort the extracted causes of an utterance according to their temporal order of occurrence in the dialogue. The resulting sequence of causes can be treated as a participating subset of the reasoning process as shown in <ref type="figure" target="#fig_9">Fig. 6</ref>. In the future, this dataset can be extended by including reasoning procedures. However, coming up with an optimal set of instructions for the annotators to code the reasoning steps is one of the major obstacles. <ref type="figure" target="#fig_5">Fig. 7</ref> also demonstrates the process of reasoning where utterance 1 and 2 are the triggers of HAPPY emotion in the utterance 3. However, the reasoning steps that are involved to extract these causes can be defined as: P A is happy because his/her goal to participate in the house open party is achieved after the confirmation of P B who will organize the house open party. This reasoning includes understanding discourse <ref type="bibr" target="#b2">(Chakrabarty et al., 2019)</ref>, logic and leveraging commonsense knowledge.</p><p>More generally, emotion causal reasoning in conversations extends the task of identifying emotion cause to determining the function and explanation of why the stimuli or triggers evoke the emotion in the target utterance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this work, we address the problem of Recognizing Emotion Cause in CONversations and introduce a new dataset-RECCON. It is a dialogue-level dataset containing more than 1, 126 dialogues and 10, 600 utterance causal span pairs. We identify various emotion types and key challenges that make the task of recognizing emotion cause in conversations extremely challenging. Further, we also propose two subtasks and formulate transformer-based strong baselines to address these tasks. Our proposed dataset only incorporates dyadic conversations. Future work will target the analysis of emotion cause in multi-party settings. We also plan to annotate the reasoning steps involved in identifying causal spans of elicited emotions in conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Emotion Causation Variables</head><p>Various factors can control elicited emotions in a conversation. We identify some of these factors (see <ref type="figure">Fig. 8</ref>) as stated below: Topic: Topic is a key element that governs and drives a conversation. Without knowing the topical information, dialogue understanding can be incomplete and vague.</p><p>Goal: The goal of the speakers can directly impact the agency appraisal <ref type="bibr" target="#b11">(Ellsworth and Scherer, 2003)</ref> of emotions, e.g., although it can be quite frustrating at times, a customer care agent generally tends to please the customers and try to be nice to them. Goals can often be very implicit in a conversation, and some conversations may not even have any goal, e.g., social casual talk. In this work, as the interlocutors' goals in a conversation are not available as prior information, we do not count on it. However, in several cases, our annotators could infer the goals from the conversational context and utilize that information to find relevant causal spans in the context.</p><p>Agency (A): Agency controls the basic behavior of a person under varied circumstances. According to the theory of appraisals <ref type="bibr" target="#b11">(Ellsworth and Scherer, 2003)</ref> in affective computing, agency can also signify different dimensions, such as values, needs, personality, intents, and more. In our case, we ignore the role of agency in emotion causal reasoning as this information is not available in the dataset. Moreover, our dataset is already pre-annotated with emotion labels; hence the variable A does not play any role in this work.</p><p>Stimulus: Event, Situation, Experience, Statement, and Opinion (S). This variable is defined as the stimulus or trigger that evokes the emotion. The stimulus could refer to events, situations, opinions, experiences mentioned in the conversational context (H(U t )) (by either of the speakers) or even be based on the counterpart's reaction towards an event cared by the speaker (inter-personal emotional influence).</p><p>Consider the following example where the first utterance by person A (P A ) is the context and the second utterance by person B (P B ) is the target. We are interested in knowing the cause of P B 's emotion <ref type="bibr">(EXCITED and HAPPY)</ref> in this target utterance:</p><p>(3) A (EXCITED and HAPPY): You know I am getting married! B (EXCITED and HAPPY): Wow! that's great news. Who is that lucky person? When is the ceremony?</p><p>In the conversation, P B listens to and positively reacts to the event "P A is getting married". P A also feels happy due to the same event-"getting married". Here, we could infer that P B 's emotion is caused either by the reference of the first utterance to the event of getting married, or by the fact that P A is happy about getting married-both of which can be considered as stimulus for P B 's emotions.</p><p>Another example is given below where the cause of P A 's emotion is the event "football match" and a negative emotion DISGUST indicates P A 's unsatisfied experience of the match. In contrast, P B takes pleasure of the match with HAPPINESS emotion. Interestingly in this example, the same event acts as trigger for both the persons and causes two contrasting emotions in them. The conversations can be dynamic and emotions can be triggered from the situations induced in the conversations. Consider the example below: In this example, P A feels disgusted in utterance 3 because of person B's angry and unexpected response. On another side, one can infer that P B gets angry or annoyed to hear person A saying "You look a bit lost".</p><p>A stimulus can be latent too and may require the ability of commonsense inference to identify. Our annotators were instructed to identify these cases. When identified, our annotators wrote their understanding of the inferred cause in the form of natural language. Consider the example below: In this case, person A is happily offering help to customer B. The cause of happiness in this example is due to the event "greeting" or intention to offer help. On the other hand, person B is fearful because of his/her broken computer. The causes of elicited emotions by both the speakers can only be inferred using commonsense knowledge.</p><p>Awareness and Inclinations (Q): Q represents background knowledge, prior assumptions if any, pre-existing inter-speaker relations, speaker's knowledge and opinion about the topic, and any other background or external information that are not explicitly present in the conversational history. Such knowledge usually evolves depending on how the speaker experiences the environment and interacts with it. In the process of a conversation, certain sensory or other external events can directly initiate cognition and affect. We call these inputs as Q. These inputs can also be non-verbal cues.</p><p>Affective reactions to these sensory inputs can occur with or without any complex cognitive modeling. When the stimulus is sudden and unexpected, the affective reaction can occur before evaluating and appraising the situation through cognitive modeling. This is called Affective Primacy <ref type="bibr" target="#b30">(Zajonc, 1980)</ref>. For example, our immediate reaction when we encounter an unknown creature in the jungle without evaluating whether it is safe or dangerous. In our case, Q is unknown and needs to be guessed from the whole conversation.</p><p>If we refer to example 5, one can speculate that person A's opinion in utterance 1 may not be the sole reason for person B's anger. Person B may also be in a preexisting bad mood due to some prior incidents that are not captured in the course of the conversation.</p><p>Elicited emotion (E): E encodes the emotion of the speaker at time t. As proposed by the psychology theorist Lazarus in his article <ref type="bibr" target="#b19">(Lazarus, 1982)</ref>, the emotional-state can be triggered by cognition and thinking, we think in a conversation, this state can be controlled by Topic, Goal, S, P , and Q.</p><p>In this work, we identify the stimuli S that cause an expressed emotion in a conversation. We assume that these stimuli are either mentioned or can be inferred in the conversational context U .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Connection to Interpretability of the Contextual Models</head><p>One of the advantages of identifying the causes of emotions in conversations is its role in interpreting a model's predictions. We reckon two situations where emotion cause identification can be useful to verify the interpretability of the contextual emotion recognition models that rely on attention mechanisms to count on the context:</p><p>• In conversations, utterances may not contain any explicit emotion bearing words or sound neutral on the surface but still carry emotions that can only be inferred from the context. In these cases, one can probe contextual models by dropping the causal utterances that contribute significantly to evoke emotion in the target utterance. It would be interesting to observe whether the family of deep networks that rely on attention mechanisms for context modeling e.g., transformer assign higher probability scores to causal contextual utterances in order to make correct predictions.</p><p>• As explained in §5, the cause can be present in the target utterance and the model may not need to cater contextual information to predict the emotion. In such cases, it would be worth checking whether attention-based models assign high probability scores to the spans in the target utterance that contribute to the causes of its emotion.</p><p>One should also note that a model does not always need to identify the cause of emotions to make correct predictions. For example, (7) A (HAPPY): Germany won the match! B (HAPPY): That's great! Here, a model can predict the emotion of P B by just leveraging the cues present in the corresponding utterance. However, the utterance by P B is just an expression and the cause of the emotion is an event-"Germany won the match". Nonetheless, identifying the causes of emotions expressed in a conversation makes the model trustworthy, interpretable, and explainable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Emotion causes in conversations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>3b): The cause of the emotion is primarily due to a stable mood of the speaker that was induced in the previous dialogue turns; Hybrid (3c): The hybrid type with both inter-personal emotional influence and self-contagion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fold 1 :</head><label>1</label><figDesc>Consider a dialogue D and a target utterance U t in D. We construct the complete set of negative examples as {</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>F1 P os : This is the F1 score introduced in (Rajpurkar et al., 2016) to evaluate predictions of extractive QA models and calculated over positive examples in the data. F1 N eg : Negative F1 represents the F1 score of detecting negative examples with respect to the gold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( 2 )</head><label>2</label><figDesc>A (neutral): How can I help you Sir?. B (frustrated): I just want my flip phone to work--that's all I need.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>An example of emotional reasoning where the happiness in utt. 3 is caused by the triggers in utt. 1 and 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>person X and Y-are governed by interactions between several variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>( 4 )</head><label>4</label><figDesc>A (DISGUST): Such a disappointing football match! B (HAPPINESS): No! I am enjoying it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( 5 )</head><label>5</label><figDesc>A (NEUTRAL): How are you? You look a bit lost. B (ANGER): Don't bother me. A (DISGUST): Okay, I am going.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>( 6 )</head><label>6</label><figDesc>A (HAPPY): Hello, thanks for calling 123 Tech Help, I'm Todd. How can I help you? B (FEAR): Hello ? Can you help me ? My computer ! Oh man ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Yes. I think so. It's not very expensive. It's in the right area and it has everything that we are looking for. My cousin is driving me up the wall.3, PA Well she's been away for three and a half years in New York and suddenly she just shows up.</figDesc><table><row><cell>(i)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1, (A)</cell><cell>I like this apartment . Do you think we can afford the mortgage ? neutral</cell><cell>1)</cell><cell>PA</cell><cell cols="2">You know I am getting married!</cell><cell>excited</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">PB Wow! That's great news.</cell><cell></cell></row><row><cell>2, (B)</cell><cell></cell><cell></cell><cell></cell><cell>Who is the lucky person?</cell><cell cols="2">happy</cell></row><row><cell></cell><cell>happy</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>PA</cell><cell cols="3">Such a disappointing football match!</cell><cell>disgust</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">PB No! I am enjoying it. happy</cell><cell></cell></row><row><cell>(ii)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1, (A) 2, (B)</cell><cell>Hi Paul. How are you, friend? disgust Not good. neutral</cell><cell></cell><cell>1, PA 2, PB</cell><cell>Why does that bother you? Why did he invite her here?</cell><cell>angry</cell><cell>emotion influence</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>emotion</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>transition</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>frustrated</cell></row><row><cell></cell><cell></cell><cell cols="2">13, PA</cell><cell cols="3">My worst times I think about her, you</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>know sad</cell><cell cols="2">sharing experience</cell></row></table><note>frustrated</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>correct) UCS pairs as positive examples, whereas pairs (U, S) with S / ∈ CS(U ) are negative examples. In §6.1.1 we describe the sampling strategies for negative examples.</figDesc><table><row><cell>4 Building the RECCON dataset</cell></row><row><cell>4.1 Emotional dialogue sources</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="3">: Datasets for Emotion Cause Extraction and related</cell></row><row><cell cols="3">tasks. Datasets in Xia and Ding (2019); Chen et al. (2020) are</cell></row><row><cell>derived from Gui et al. (2016).</cell><cell></cell><cell></cell></row><row><cell>Description</cell><cell cols="2">RECCON-DD RECCON-IE</cell></row><row><cell># Dialogues</cell><cell>1106</cell><cell>16</cell></row><row><cell># Utterances</cell><cell>11104</cell><cell>665</cell></row><row><cell># Utterances annotated with emotion cause</cell><cell>5861</cell><cell>494</cell></row><row><cell># Utterances cater to background cause</cell><cell>395</cell><cell>70</cell></row><row><cell># Utterances where cause solely lies in the</cell><cell>1521</cell><cell>80</cell></row><row><cell>same utterance</cell><cell></cell><cell></cell></row><row><cell># Utterances where cause includes the same</cell><cell>3370</cell><cell>243</cell></row><row><cell>utterance along with contextual utterances</cell><cell></cell><cell></cell></row><row><cell># Utterance with emotion Anger</cell><cell>451</cell><cell>89</cell></row><row><cell># Utterance with emotion Fear</cell><cell>74</cell><cell>-</cell></row><row><cell># Utterance with emotion Disgust</cell><cell>140</cell><cell>-</cell></row><row><cell># Utterance with emotion Frustration</cell><cell>-</cell><cell>109</cell></row><row><cell># Utterance with emotion Happy</cell><cell>4361</cell><cell>58</cell></row><row><cell># Utterance with emotion Sad</cell><cell>351</cell><cell>70</cell></row><row><cell># Utterance with emotion Surprise</cell><cell>484</cell><cell>-</cell></row><row><cell># Utterance with emotion Excited</cell><cell>-</cell><cell>197</cell></row><row><cell># Utterance with emotion Neutral</cell><cell>5243</cell><cell>142</cell></row><row><cell># UCS pairs</cell><cell>9915</cell><cell>1154</cell></row><row><cell># Utterances having single cause</cell><cell>55%</cell><cell>41%</cell></row><row><cell># Utterances having two causes</cell><cell>31%</cell><cell>24%</cell></row><row><cell># Utterances having three causes</cell><cell>9%</cell><cell>17%</cell></row><row><cell># Utterances having more than three causes</cell><cell>5%</cell><cell>18%</cell></row><row><cell># Causes per utterance (Average)</cell><cell>1.69</cell><cell>2.34</cell></row><row><cell># No Context</cell><cell>43%</cell><cell>35%</cell></row><row><cell># Inter-Personal</cell><cell>32%</cell><cell>19%</cell></row><row><cell># Self-Contagion</cell><cell>9%</cell><cell>20%</cell></row><row><cell># Hybrid</cell><cell>11%</cell><cell>17%</cell></row><row><cell># Latent</cell><cell>5%</cell><cell>10%</cell></row><row><cell># Utterances (Ut) having cause at U (t−1)</cell><cell>2851</cell><cell>183</cell></row><row><cell># Utterances (Ut) having cause at U (t−2)</cell><cell>1182</cell><cell>124</cell></row><row><cell># Utterances (Ut) having cause at U (t−3)</cell><cell>578</cell><cell>94</cell></row><row><cell># Utterances (Ut) having cause at &gt; U (t−3)</cell><cell>769</cell><cell>200</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the RECCON annotated dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>I like this apartment . Do you think we can afford the mortgage ?Yes. I think so. It's not very expensive. It's in the right area and it has everything that we are looking for.I like this apartment . Do you think we can afford the mortgage ? Yes. I think so. It's not very expensive. It's in the right area and it has everything that we are looking for. No context: 2a. Unmentioned Latent Cause: 2b. Distinguishing emotion cause from emotional expressions: 2c. I like this apartment . Do you think we can afford the mortgage ? Yes. I think so. It's not very expensive. It's in the right area and it has everything that we are looking for. Doris, I'm glad you're home. I'm terrified. I don't know what to do! fear</figDesc><table><row><cell></cell><cell></cell><cell>2, PB</cell><cell cols="3">Yes. I think so. It's not very expensive. It's in the right area and it has everything that</cell><cell></cell><cell>2, PB</cell><cell>What is it? What happened?</cell><cell>neutral</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">we are looking for. happy</cell><cell></cell><cell></cell><cell>3, PA 1, PA</cell><cell>I think someone is stalking me. I like this apartment . Do you think we fear</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>can afford the mortgage ?</cell><cell>neutral</cell></row><row><cell>1, PA</cell><cell cols="2">I like this apartment . Do you think we can afford the mortgage ? neutral</cell><cell>1, PA</cell><cell cols="3">Doris, I'm glad you're home. I'm terrified. I don't know what to do! fear</cell><cell>2, PB</cell><cell>in the right area and it has everything that Yes. I think so. It's not very expensive. It's</cell><cell>1, PA</cell><cell>I don't Doris,</cell></row><row><cell>2, PB</cell><cell cols="2">neutral neutral Yes. I think so. It's not very expensive. It's 1, PA 1, PA in the right area and it has everything that we are looking for. happy</cell><cell>1, PA 2, PB 3, PA</cell><cell cols="4">Doris, I'm glad you're home. I'm terrified. I don't know what to do! fear Doris, I'm glad you're home. I'm terrified. 1, PA I don't know what to do! fear 1, PA What is it? What happened? neutral I think someone is stalking me. fear 1, PA</cell><cell>I won the prize! excited we are looking for. happy I like winter. happy</cell><cell>inter-speaker cause sharing</cell><cell>2, PB 3, PA</cell><cell>What I think</cell></row><row><cell></cell><cell>2, PB 2, PB</cell><cell></cell><cell>2, PB</cell><cell cols="2">What is it? What happened? What is it? What happened? 2, PB neutral</cell><cell>neutral</cell><cell>2, PB 2, PB</cell><cell>Wow! Incredible! Me too neutral</cell><cell>excited</cell></row><row><cell></cell><cell>1, PA</cell><cell>happy happy</cell><cell>3, PA</cell><cell cols="2">I think someone is stalking me. I think someone is stalking me. 3, PA fear 1, PA</cell><cell cols="2">fear 3, PA</cell><cell>emotional expression It's snowing heavily. What about taking a</cell></row><row><cell>1, PA 2, PB 3, PA 4, PB 5, PA</cell><cell cols="2">(a) Figure 2: neutral happy 2, PB I like winter. happy Me too neutral It's snowing heavily. What about taking a walk? happy That's a good idea. Let's go! happy I like winter. happy 1, PA What a heavy snow! Look! The water is Me too neutral frozen. happy 2, PB It's snowing heavily. What about taking a walk? happy That's a good idea. Let's go! happy 3, PA 4, PB</cell><cell>1, PA 1, PA 2, PB 2, PB 1, PA 2, PB</cell><cell cols="4">Wow! Incredible! I won the prize! excited excited I won the prize! excited 1, PA inter-speaker cause sharing (b) What is it? What happened? I think someone is stalking me. inter-speaker fear neutral 2, PB 3, PA Wow! Incredible! I won the prize! excited excited inter-speaker cause sharing cause sharing 2, PB Wow! Incredible! excited emotional expression emotional expression emotional expression 4, PB 5, PA 1, PA Wow! Incredible! I won the prize! excited excited inter-speaker 1, PA 2, PB cause sharing emotional expression 2, PB You like it? Show me your necklace. neutral neutral 3, PA</cell><cell>(c) That's a good idea. Let's go! walk? happy What a heavy snow! Look! The water is happy happy frozen. Oh! You're engaged! What a beautiful engagement ring! Who to? happy Of course Mike. Who else? We fell in love at first sight. happy to be? happy When's the wedding going</cell><cell>1, PA 2, PB 1, PA 2, PB</cell><cell>I won Wow! Show You l</cell></row><row><cell></cell><cell>5, PA</cell><cell>What a heavy snow! Look! The water is frozen. happy</cell><cell cols="2">3, PA Wow! Yes a lot!</cell><cell>happy</cell><cell></cell><cell>4, PB</cell><cell>are a lot of things to sort out. We haven't decided yet. There</cell><cell>happy</cell><cell>3, PA Wow</cell></row><row><cell></cell><cell></cell><cell>(a) Mood Setting</cell><cell></cell><cell cols="2">(b) Generic Cause</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>The statistics of RECCON comprising both positive (valid) and negative (invalid) UCS pairs. DD − → RECCON-DD; IEMO − → RECCON-IE. Utterances with only latent emotion causes are ignored in our experiments.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Results for Causal Span Extraction task on the test sets of RECCON-DD and RECCON-IE. All scores are in percentage and are reported at best validation F1 scores.</figDesc><table /><note>DD − → RECCON-DD; IEMO − → RECCON-IE; RoBERTa − → RoBERTa Base.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Results for Causal Emotion Entailment task on the test sets of RECCON-DD and RECCON-IE. Class wise F1 score and the overall macro F1 scores are reported. All scores reported at best macro F1 scores. DD − → RECCON- DD; IEMO − → RECCON-IE. All models are RoBERTa-based models.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>84.55 73.82 32.63 58.17 85.85 75.45 SpanBERT 33.26 57.03 80.03 69.78 34.64 60.00 86.02 75.71 IEMO RoBERTa 9.81 18.59 93.45 87.60 10.19 26.88 91.68 84.52 SpanBERT 16.20 30.22 87.15 77.45 22.41 37.80 90.54 82.86 83.52 72.66 32.95 59.02 95.36 87.63 SpanBERT 33.26 57.03 84.02 74.80 32.37 57.04 95.01 87.00</figDesc><table><row><cell></cell><cell></cell><cell>Model</cell><cell>w/o CC</cell><cell></cell><cell cols="2">w/ CC</cell></row><row><cell></cell><cell></cell><cell cols="2">EMP os F1P os F1Neg</cell><cell>F1</cell><cell cols="2">EM F1P os F1Neg</cell><cell>F1</cell></row><row><cell cols="7">Fold 1 − → Fold 1 45.99 Fold 1 − → DD RoBERTa 26.82 Fold 2 DD RoBERTa 26.82 RoBERTa 9.81 18.59 92.18 85.41 10.93 28.26 95.49 90.85 45.99 IEMO SpanBERT 16.20 30.22 88.63 79.80 24.07 40.57 96.28 92.41</cell></row><row><cell>Fold 3</cell><cell>DD</cell><cell>RoBERTa SpanBERT 33.26 26.82</cell><cell cols="4">45.99 81.50 70.26 32.95 59.02 95.37 87.65 57.03 79.65 69.83 32.31 56.99 94.92 86.87</cell></row><row><cell>Fold 1 − →</cell><cell>IEMO</cell><cell>RoBERTa SpanBERT 16.20 9.81</cell><cell cols="4">18.59 91.82 84.83 10.93 28.26 95.47 90.81 30.22 86.95 77.25 24.07 40.57 96.28 92.41</cell></row><row><cell>Fold 2</cell><cell>DD</cell><cell>RoBERTa SpanBERT 32.31 33.26</cell><cell cols="4">58.44 90.14 82.19 41.61 73.57 99.98 92.04 58.61 90.20 82.29 41.97 74.85 99.94 92.43</cell></row><row><cell>Fold 2 − →</cell><cell>IEMO</cell><cell>RoBERTa SpanBERT 22.13 15.93</cell><cell cols="4">31.74 92.93 86.50 30.28 59.14 99.43 94.58 38.84 90.37 82.49 32.50 65.45 98.37 95.50</cell></row><row><cell>Fold 1</cell><cell>DD</cell><cell>RoBERTa SpanBERT 32.31 33.26</cell><cell cols="3">58.44 71.29 60.45 36.06 65.04 58.61 72.52 61.70 31.52 60.81</cell><cell>0.19 17.12 0.67 16.19</cell></row><row><cell>Fold 2 − →</cell><cell>IEMO</cell><cell>RoBERTa SpanBERT 22.13 15.93</cell><cell cols="3">31.74 90.70 82.91 22.96 46.87 38.84 85.03 74.34 21.85 49.18</cell><cell>4.66 6.36</cell><cell>6.35 7.40</cell></row><row><cell>Fold 3</cell><cell>DD</cell><cell>RoBERTa SpanBERT 30.62 28.72</cell><cell cols="4">51.32 90.06 82.11 41.29 74.95 99.94 92.44 54.96 89.41 81.21 42.61 75.36 99.93 92.46</cell></row><row><cell>Fold 3 − →</cell><cell>IEMO</cell><cell>RoBERTa SpanBERT 17.41 14.54</cell><cell cols="4">26.51 93.68 87.79 24.35 53.46 97.84 94.08 31.75 91.85 84.86 32.87 62.70 99.54 95.11</cell></row><row><cell>Fold 1</cell><cell>DD</cell><cell>RoBERTa SpanBERT 30.62 28.72</cell><cell cols="3">51.32 75.55 64.31 37.22 69.64 54.96 75.49 64.46 31.94 60.81</cell><cell>0.90 18.59 0.15 16.00</cell></row><row><cell>Fold 3 − →</cell><cell>IEMO</cell><cell>RoBERTa SpanBERT 17.41 14.54</cell><cell cols="4">26.51 92.33 85.61 21.20 48.34 11.42 9.76 31.75 89.41 80.94 21.48 45.49 4.01 5.84</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>Results for Causal Span Extraction task on the test sets of RECCON-DD and RECCON-IE. All scores are in percentage and are reported at best validation F1 scores.</figDesc><table /><note>RoBERTa − → RoBERTa Base; DD − → RECCON-DD; IEMO − → RECCON-IE. Fold i − → Fold j: Trained on Fold i, Tested on Fold j.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Pos. F1 Neg. F1 macro F1 Pos. F1 Neg. F1 macro F1</figDesc><table><row><cell></cell><cell cols="2">Model</cell><cell></cell><cell>w/o CC</cell><cell></cell><cell></cell><cell>w/ CC</cell><cell></cell></row><row><cell>Fold 1</cell><cell>DD</cell><cell>Base Large</cell><cell>56.64 50.48</cell><cell>85.13 87.35</cell><cell>70.88 68.91</cell><cell>64.28 66.23</cell><cell>88.74 87.89</cell><cell>76.51 77.06</cell></row><row><cell>Fold 1 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>25.98 32.34</cell><cell>90.73 95.61</cell><cell>58.36 63.97</cell><cell>28.02 40.83</cell><cell>95.67 95.68</cell><cell>61.85 68.26</cell></row><row><cell>Fold 2</cell><cell>DD</cell><cell>Base Large</cell><cell>57.50 56.13</cell><cell>82.71 88.33</cell><cell>70.11 72.23</cell><cell>59.06 60.09</cell><cell>86.91 88.00</cell><cell>72.98 74.04</cell></row><row><cell>Fold 1 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>32.60 36.61</cell><cell>89.99 94.60</cell><cell>61.30 65.60</cell><cell>27.14 37.59</cell><cell>94.16 94.63</cell><cell>60.65 66.11</cell></row><row><cell>Fold 3</cell><cell>DD</cell><cell>Base Large</cell><cell>57.52 56.04</cell><cell>82.72 88.28</cell><cell>70.12 72.16</cell><cell>49.30 60.63</cell><cell>79.27 88.30</cell><cell>64.29 74.46</cell></row><row><cell>Fold 1 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>33.24 36.55</cell><cell>90.30 94.59</cell><cell>61.77 65.57</cell><cell>23.83 37.87</cell><cell>92.97 94.69</cell><cell>58.40 66.28</cell></row><row><cell>Fold 2</cell><cell>DD</cell><cell>Base Large</cell><cell>76.21 79.52</cell><cell>91.23 91.27</cell><cell>83.72 85.40</cell><cell>89.37 93.05</cell><cell>95.21 97.22</cell><cell>92.32 95.13</cell></row><row><cell>Fold 2 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>46.12 48.36</cell><cell>93.80 92.06</cell><cell>69.96 70.21</cell><cell>65.09 61.12</cell><cell>95.60 95.59</cell><cell>80.35 78.35</cell></row><row><cell>Fold 1</cell><cell>DD</cell><cell>Base Large</cell><cell>52.52 51.57</cell><cell>75.51 67.58</cell><cell>64.02 59.57</cell><cell>41.86 43.25</cell><cell>3.25 19.95</cell><cell>22.55 31.60</cell></row><row><cell>Fold 2 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>31.51 29.64</cell><cell>92.09 87.68</cell><cell>61.80 58.66</cell><cell>25.22 26.30</cell><cell>74.69 76.44</cell><cell>49.96 51.37</cell></row><row><cell>Fold 3</cell><cell>DD</cell><cell>Base Large</cell><cell>74.73 75.79</cell><cell>90.33 88.43</cell><cell>82.53 82.11</cell><cell>92.64 93.34</cell><cell>96.99 97.23</cell><cell>94.81 95.29</cell></row><row><cell>Fold 3 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>51.23 43.00</cell><cell>93.70 88.47</cell><cell>72.46 65.74</cell><cell>63.91 59.03</cell><cell>94.55 92.21</cell><cell>79.23 75.62</cell></row><row><cell>Fold 1</cell><cell>DD</cell><cell>Base Large</cell><cell>52.02 51.53</cell><cell>74.59 65.76</cell><cell>63.31 58.65</cell><cell>41.64 41.86</cell><cell>2.99 4.89</cell><cell>22.31 23.38</cell></row><row><cell>Fold 3 − →</cell><cell>IEMO</cell><cell>Base Large</cell><cell>34.74 27.58</cell><cell>91.46 84.13</cell><cell>63.10 55.86</cell><cell>19.13 18.33</cell><cell>54.25 48.01</cell><cell>36.69 33.17</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 7 :</head><label>7</label><figDesc>Results for Causal Emotion Entailment task on the test sets of RECCON-DD and RECCON-IE. Class wise F1 scores and the overall macro F1 scores are reported. All scores reported at best macro F1 scores. DD − → RECCON-</figDesc><table /><note>DD; IEMO − → RECCON-IE. All models are RoBERTa-based models. Fold i − → Fold j: Trained on Fold i, Tested on Fold j.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>I'm sorry, but the price is final . sadness</figDesc><table><row><cell>12, PB</cell><cell></cell><cell></cell><cell>1, PA</cell><cell>Many ha</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>darling!</cell></row><row><cell></cell><cell></cell><cell></cell><cell>2, PB</cell><cell>Thank yo</cell></row><row><cell></cell><cell></cell><cell></cell><cell>3, PA</cell><cell>And here</cell></row><row><cell>1, PA</cell><cell cols="2">When do you want to have the house</cell><cell></cell><cell>present</cell></row><row><cell></cell><cell>open party? neutral</cell><cell></cell><cell>4, PB</cell><cell>Gold wa</cell></row><row><cell>2, PB</cell><cell>How about next Friday?</cell><cell>neutral</cell><cell>5, PA</cell><cell>Do you l</cell></row><row><cell>3, PA</cell><cell>Friday sounds good!</cell><cell>happy</cell><cell>6, PB</cell><cell>I love it!</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">pronounced as reckon.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">By "causal span from evidence in the context" we really mean a causal span from the conversation history H(Ut).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Creating a dataset for named entity recognition in the archaeology domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Brandsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milco</forename><surname>Wansleeben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Lambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4573" to="4577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">IEMOCAP: Interactive emotional dyadic motion capture database. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murtaza</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Chun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth S</forename><surname>Narayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">AMPERSAND: Argument mining for PER-SuAsive oNline discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuhin</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hidey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathy</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alyssa</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1291</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2933" to="2943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conditional causal relationships between emotions and causes in texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.252</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3111" to="3121" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint learning for emotion classification and emotion cause detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1066</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10-31" />
			<biblScope unit="page" from="646" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Emotion cause detection with linguistic constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Yat Mei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China. Coling</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="179" to="187" />
		</imprint>
	</monogr>
	<note>Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Identifying sources of opinions with conditional random fields and extraction patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2005-06-08" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
	<note>Proceedings of the Conference</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Emotion recognition on twitter: comparative study and training a unison model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Colneriĉ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janez</forename><surname>Demsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Finding emotion holder from Bengali blog Texts-An unsupervised syntactic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipankar</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 24th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="621" to="628" />
		</imprint>
		<respStmt>
			<orgName>Tohoku University, Sendai, Japan. Institute of Digital Enhancement of Cognitive Processing, Waseda University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA; Long and Short Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-02" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Facial expression and emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American psychologist</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">384</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Appraisal processes in emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Phoebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scherer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="572" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Overview of ntcir-13 eca task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui</forename><surname>Ruifeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NTCIR-13 Conference</title>
		<meeting>the NTCIR-13 Conference</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detecting emotion stimuli in emotion-bearing sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diman</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-18117-2_12</idno>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing -16th International Conference, CICLing</title>
		<meeting><address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-04-14" />
			<biblScope unit="volume">9042</biblScope>
			<biblScope unit="page" from="152" to="165" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Rada Mihalcea, and Soujanya Poria. 2020. Utterance-level dialogue understanding: An empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Event-driven emotion cause extraction with corpus construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1639" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Emotion cause detection with linguistic construction in chinese weibo text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-45924-9_42</idno>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Chinese Computing -Third CCF Conference</title>
		<meeting><address><addrLine>Shenzhen, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09" />
			<biblScope unit="volume">496</biblScope>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<title level="m">Spanbert: Improving pre-training by representing and predicting spans</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decision support with text-based emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Kratzwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzana</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Kraus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.06397</idno>
	</analytic>
	<monogr>
		<title level="m">Deep learning for affective computing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Stefan Feuerriegel, and Helmut Prendinger</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Thoughts on the relations between emotion and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lazarus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1019" to="1024" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A text-driven rule-based system for emotion cause detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Yat Mei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</title>
		<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="53" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dailydialog: A manually labelled multi-turn dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-11-27" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sentiment Analysis and Opinion Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.2200/S00416ED1V01Y201204HLT016</idno>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Extracting causes of emotions from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alena</forename><surname>Neviarouskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Aono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Joint Conference on Natural Language Processing, IJCNLP 2013</title>
		<meeting><address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10-14" />
			<biblScope unit="page" from="932" to="936" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing / ACL</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A psychoevolutionary theory of emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Plutchik</surname></persName>
		</author>
		<idno type="DOI">10.1177/053901882021004003</idno>
	</analytic>
	<monogr>
		<title level="j">Social Science Information</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="529" to="553" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Toward a cognitive semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Talmy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Emotion-cause pair extraction: A new task to emotion analysis in texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixiang</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1096</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1003" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Feeling and thinking: Preferences need no inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Zajonc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
