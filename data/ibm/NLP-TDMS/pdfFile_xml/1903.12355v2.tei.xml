<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Local Aggregation for Unsupervised Learning of Visual Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxu</forename><surname>Zhuang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">Lin</forename><surname>Zhai</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Yamins</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Local Aggregation for Unsupervised Learning of Visual Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised approaches to learning in neural networks are of substantial interest for furthering artificial intelligence, both because they would enable the training of networks without the need for large numbers of expensive annotations, and because they would be better models of the kind of general-purpose learning deployed by humans. However, unsupervised networks have long lagged behind the performance of their supervised counterparts, especially in the domain of large-scale visual recognition. Recent developments in training deep convolutional embeddings to maximize non-parametric instance separation and clustering objectives have shown promise in closing this gap. Here, we describe a method that trains an embedding function to maximize a metric of local aggregation, causing similar data instances to move together in the embedding space, while allowing dissimilar instances to separate. This aggregation metric is dynamic, allowing soft clusters of different scales to emerge. We evaluate our procedure on several large-scale visual recognition datasets, achieving state-of-the-art unsupervised transfer learning performance on object recognition in ImageNet, scene recognition in Places 205, and object detection in PASCAL VOC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep convolutional neural networks (DCNNs) have achieved great success on many tasks across a variety of domains, such as vision <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b60">60,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b6">7]</ref>, audition <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b47">47]</ref>, and natural language processing <ref type="bibr" target="#b68">[68,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b37">38]</ref>. However, most successful DCNNs are trained in a supervised fashion on labelled datasets <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b60">60,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26]</ref>, requiring the costly collection of large numbers of annotations. There is thus substantial interest in finding methods that can train DCNNs solely using unlabeled data, which are often readily available. Over many decades of work, substantial progress has been achieved using a wide variety of unsupervised learning approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b67">67,</ref><ref type="bibr" target="#b71">71,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b70">70,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b63">63,</ref><ref type="bibr" target="#b49">49]</ref>. Nevertheless, unsupervised networks are still typically significantly lower performing than their supervised counterparts, and are rarely used in real-world applications <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>In contrast to the inefficiency of unsupervised learning in artificial neural networks, humans and non-human primates develop powerful and domain-general visual systems with very few labels <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b65">65,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b61">61]</ref>. Although the mechanisms underlying the efficiency of biological learning still remain largely unknown <ref type="bibr" target="#b4">[5]</ref>, researchers reliably report that infants as young as three months can group perceptually similar stimuli <ref type="bibr" target="#b46">[46]</ref>, even for stimulus types that the infants have never seen before. Moreover, this ability arises long before these infants appear to have an explicit concept of object category <ref type="bibr" target="#b46">[46,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b7">8]</ref>. These findings suggest that biological unsupervised learning may take advantage of inherent visual similarity, without requiring sharp boundaries between stimulus categories.</p><p>Inspired by these results, we propose a novel unsupervised learning algorithm through local non-parametric aggregation in a latent feature space. First, we non-linearly embed inputs in a lower-dimensional space via a neural network. We then iteratively identify close neighbors surrounding each example in the embedding space, while optimizing the embedding function to strengthen the degree of local aggregation. Our procedure, which we term Local Aggregation (LA), causes inputs that are naturally dissimilar to each other to move apart in the embedding space, while allowing inputs that share statistical similarities to arrange themselves into emergent clusters. By simultaneously optimizing this soft clustering structure and the non-linear embedding in which it is performed, our procedure exposes subtle statistical regularities in the data. The resulting representation in turn robustly supports downstream tasks.</p><p>Here, we illustrate the LA procedure in the context of large-scale visual learning. Training a standard convolution neural network with LA using images from ImageNet <ref type="bibr" target="#b9">[10]</ref> significantly outperforms current state-of-art unsupervised algorithms on transfer learning to classification tasks on both ImageNet and the Places 205 dataset <ref type="bibr" target="#b72">[72]</ref>. In addition, LA shows consistent improvements as the depth of the embedding function increases, allowing it to achieve 60.2% top-1 accuracy on ImageNet classification. This is, as far as we know, the first time an unsupervised model has surpassed the milestone AlexNet network trained directly on the supervised task. We also show that, through further finetuning, LA trained models obtain state-of-the-art results on the PASCAL object detection task.</p><p>The remainder of this paper is organized as follows: in section 2, we discuss related work; in section 3, we describe the LA method; in section 4, we show experimental results; in section 5, we present analyses illustrating how this algorithm learns and justifying key parameter choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Unsupervised learning methods span a very broad spectrum of approaches going back to the roots of artificial neural networks <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b58">58,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b24">25]</ref>, and are too numerous to fully review here. However, several recent works have achieved exciting progress in unsupervised representation learning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b67">67,</ref><ref type="bibr" target="#b71">71]</ref>. Although the LA method draws inspiration from these works, it differs from them in some important conceptual ways.</p><p>DeepCluster. DeepCluster <ref type="bibr" target="#b5">[6]</ref> (DC) trains a DCNN in a series of iterative rounds. In each round, features from the penultimate layer of the DCNN from the previous round are clustered, and the cluster assignments are used as selfgenerated supervision labels for further training the DCNN using standard error backprogation. Like DC, LA also uses an iterative training procedure, but the specific process within each iteration differs significantly. First, unlike the clustering step of DC where all examples are divided into mutually-exclusive clusters, our method identifies neighbors separately for each example, allowing for more flexible statistical structures than a partition. Indeed, as shown in Section 5.2, the use of individual semantic neighbor identifiers rather than global clustering is important for performance improvement. Secondly, the optimization step of LA differs from that of DC by optimizing a different objective function. Specifically, DC optimizes the cross-entropy loss between predicted and ground truth cluster labels, requiring an additional and computationally expensive linear readout layer. Moreover, due to arbitrary changes in the cluster label indices across iterative rounds, this additional readout layer needs to be frequently recomputed. In contrast, LA employs an objective function that directly optimizes a local soft-clustering metric, requiring no extra readout layer and only a small amount of additional computation on top of the feature representation training itself. These differences lead both to better final performance and substantially improved training efficiency.</p><p>Instance Recognition.</p><p>The Instance Recognition task <ref type="bibr" target="#b67">[67]</ref> (IR) treats each example as its own "category" and optimizes the DCNN representation to output an embedding in which all examples are well-separated from each other. LA uses a similar embedding framework, but achieves significantly better performance by pursuing a distinct optimization goal. Specifically, while IR optimizes for equally separating representations of all examples, LA encourages a balance between separation and clustering on a per-example basis, as measured by the local aggregation criterion. For this reason, the LA approach can be thought of as a principled hybrid between the DC and IR approaches.</p><p>Self-supervised "missing-data" tasks. These tasks build representations by hiding some information about each example input, and then optimizing the network to predict the hidden information from the visible information that remains. Examples include context prediction <ref type="bibr" target="#b12">[13]</ref>, colorization of grayscale images <ref type="bibr" target="#b12">[13]</ref>, inpainting of missing portions of images <ref type="bibr" target="#b52">[52]</ref>, and the Split-Brain method <ref type="bibr" target="#b71">[71]</ref>. However, it is ultimately unclear whether these tasks are perfectly aligned with the needs of robust visual representation. Indeed, it has been found that deeper networks better minimizing the loss functions used in such tasks gain little transfer learning performance on object recognition tasks <ref type="bibr" target="#b13">[14]</ref>. Moreover, most missing-data tasks rely on structures that are specific to visual data, making them potentially less general than the embedding/clustering concepts used in DC, IR or our LA method.</p><p>Generative models. Another broad class of unsupervised learning algorithm, often termed deep generative models, focuses on reconstructing input images from a bottlenecked latent representation. The networks trained by these algorithms use the latent representations for other tasks, including object recognition. These learning methods include classical ones such as Restricted Boltzman Machines <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41]</ref> as well as more recent ones such as Variational Auto-Encoders <ref type="bibr" target="#b34">[35]</ref> and Generative Adversarial Networks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref>. Although the features learned by generative models have been put to a wide variety of exciting uses <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b69">69,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b32">33]</ref>, their power as latent representations for downstream visual tasks such as object recognition has yet to be fully realized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>Our overall objective is to learn an embedding function f θ (realized via a neural network) that maps images</p><formula xml:id="formula_0">I = {x 1 , x 2 , ..., x N } to features V = {v 1 , v 2 , ..., v N } with v i = f θ (x i ) in a compact D-dimension representation space</formula><p>where similar images are clustered while dissimilar images are separated. To achieve this objective, we design an iterative procedure to bootstrap the aggregation power of a deep non-linear embedding function. More specifically, at any given stage during training the embedding function, we dynamically identify two sets of neighbors for an x i and its embedding v i : close neighbors C i and background neighbors B i . Intuitively, close neighbors are those whose embeddings should be made similar to v i , while background neighbors are used to set the distance scale with respect to which the judgement of closeness should be measured. To help better understand these two sets, we provide a schematic illustration in <ref type="figure" target="#fig_7">Fig. 1</ref>, and describe the details of how they are defined mathematically in section 3.1. Using B i and C i , we then define the level of local aggregation L(C i , B i |θ, x i ) near each input x i , which characterizes the relative level of closeness within C i , compared to that in B i . The parameters θ of the neural network realizing the embedding function are then tuned over the course of training to maximize L(C i , B i |θ, x i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Neighbor Identification</head><p>We first describe how the neighbor types B i and C i are defined. Nearest-neighbor based identification for B i : At any given step of optimization, the background neighbors for a given embedded point v i are simply defined as the k closest embedded points N k (v i ) within V, where distance is judged using the cosine distance on the embedding space. The number k of background neighbors to be used is a hyperparameter of the algorithm. Robustified clustering-based identification for C i : To identify close neighbors, we first apply an unsupervised clustering algorithm on all embedded points V to cluster the representations into m groups G = {G 1 , G 2 , ..., G m }. Let g(v i ) denote the cluster label of v i in this clustering result, i.e. i ∈ G g(vi) . In the simplest version of our procedure, we then define C i to be the set G g(vi) . However, because clustering can be a noisy and somewhat arbitrary process, we compute multiple clusterings under slightly different conditions, and then aggregate neighbors across these multiple clusterings to achieve more stable results. Specifically, let {G (j) } be clusters for H distinct clusterings, where G (j) = {G  <ref type="bibr">(vi)</ref> . The number m of clusters and number H of clusterings are hyperparameters of the algorithm. In this work, we use k-means clustering as the standard unsupervised algorithm.</p><formula xml:id="formula_1">C i = H j=1 G (j) g (j)</formula><p>Intuitively, background neighbors are an unbiased sample of nearby points that (dynamically) set the scale at which "close-ness" should be judged; while close neighbors are those that are especially nearby, relative to those in other clusters. The mathematical definitions above represent just one specific way to formalize these ideas, and many alternatives are possible. In Section 5.2, we show that our choices are not arbitrary by exploring the consequences of making alternate decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Local Aggregation Metric</head><p>Given the definition of B i and C i , we describe the formulation of our local aggregation metric, L(C i , B i |θ, x i ). We build our formulation upon a non-parametric softmax operation proposed by Wu et al. in <ref type="bibr" target="#b67">[67]</ref>. In that work, the authors define the probability that an arbitrary feature v is recognized as the i-th image to be:</p><formula xml:id="formula_2">P (i|v) = exp(v T i v/τ ) N j=1 exp(v T j v/τ )<label>(1)</label></formula><p>where τ ∈ [0, 1] is a fixed scale hyperparameter, and where both {v i } and v are projected onto the L2-unit sphere in the D-dimensional embedding space (e.g. normalized such that v 2 = 1). Following equation 1, given an image set A, we then define the probability of feature v being recognized as an image in A as:</p><formula xml:id="formula_3">P (A|v) = i∈A P (i|v)<label>(2)</label></formula><p>Finally, we formulate L(C i , B i |θ, x i ) as the negative log-likelihood of v i being recognized as a close neighbor (e.g. is in C i ), given that v i is recognized as a background neighbor (e.g. is in B i ):</p><formula xml:id="formula_4">L(C i , B i |θ, x i ) = −log P (C i ∩ B i |v i ) P (B i |v i )<label>(3)</label></formula><p>The loss to be minimized is then:</p><formula xml:id="formula_5">L i = L(C i , B i |θ, x i ) + λ θ 2 2 (4)</formula><p>where λ is a regularization hyperparameter. Discussion. Because the definition of L(C i , B i |θ, x i ) is somewhat involved, we describe a simple conceptual analysis that illustrates the intuition for why we chose it as a measure of local aggregation. Letting C c i denote the complement of C i in I, we have P (</p><formula xml:id="formula_6">B i |v i ) = P (C c i ∩ B i |v i ) + P (C i ∩ B i |v i ). Thus, from equation 3, we see that L(C i , B i |θ, x i ) is minimized when P (C i ∩ B i |v i ) is maximized and P (C c i ∩ B i |v i ) is minimized.</formula><p>It is easy to understand the meaning of minimizing P (C c i ∩ B i |v i ): this occurs as the distances between v i and its non-close background neighbors are maximized. The consequences of maximizing P (C i ∩ B i |v i ) are a bit more subtle. As shown empirically in <ref type="bibr" target="#b66">[66]</ref> (albeit in the supervised context), as long as the scaling parameter τ 1, maximizing P (A|v i ) for any set A causes the emergence of natural "sub-categories" in (the embeddings of) A, and encourages v i to move closer to one of these sub-categories rather than their overall average. This empirical result can be intuitively understood by recognizing the fact that exp(v T i v/τ ) increases exponentially when v T i v approaches 1, suggesting that P (A|v i ) will approach 1 when A includes a small cluster of features that are all very close to v. Putting these observations together, the optimized representation space created by minimizing L(C i , B i |θ, x i ) is, intuitively, like that shown in <ref type="figure" target="#fig_7">Fig. 1</ref>: a set of embedded points that have formed into small clusters at a distribution of natural scales. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ConvNet ConvNet ConvNet</head><p>Embedding Space After Optimization ...... ......</p><formula xml:id="formula_7">x 1 x 3 x 2 jetchev2016texture jetchev2016texture x 4 v 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Close Neighbors</head><p>Background Neighbors <ref type="figure" target="#fig_7">Figure 1</ref>. Illustration of the Local Aggregation (LA) method. For each input image, we use a deep neural network to embed it into a lower dimension space ("Embedding Space" panel). We then identify its close neighbors (blue dots) and background neighbors (black dots). The optimization seeks to push the current embedding vector (red dot) closer to its close neighbors and further from its background neighbors. The blue arrow and black arrow are examples of influences from different neighbors on the current embedding during optimization. The "After Optimization" panel illustrates the typical structure of the final embedding after training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Memory Bank</head><p>As defined above, the neighbor identification procedures and the loss function implicitly describe computations involving all the embedded features V, which soon becomes intractable for large datasets. To address this issue, we follow <ref type="bibr" target="#b67">[67,</ref><ref type="bibr" target="#b66">66]</ref> and maintain a running average for V, which is called the memory bank,</p><formula xml:id="formula_8">denotedV = {v 1 ,v 2 , ...,v N }.</formula><p>Similarly to <ref type="bibr" target="#b67">[67,</ref><ref type="bibr" target="#b66">66]</ref>, we initialize the memory bank with random D-dimensional unit vectors and then update its values by mixingv i and v i during training as follows:</p><formula xml:id="formula_9">v i ← (1 − t)v i + tv i<label>(5)</label></formula><p>where t ∈ [0, 1] is a fixed mixing hyperparameter. With the help ofV, we can then rewrite the neighbor identification procedures and equation 1 by replacing the feature sets V withV. In particular for C i , the cluster label function g is applied tov i by index identification, ensuring the chosen cluster includes the index i itself. After this replacement, it is no longer necessary to recompute V before every step to identify (good approximations of) C i and B i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In this section, we describe tests of the LA method on visual representation learning and compare its performance to that of other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment Settings</head><p>We first list key parameters used for network training. Following <ref type="bibr" target="#b67">[67]</ref>, we set parameter τ = 0.07, D = 128, λ = 0.0001, and t = 0.5. For all network structures, we use SGD with momentum of 0.9 and batch size 128. Initial learning rates are set to 0.03, and dropped by a factor of 10 when validation performances saturate, typically leading to training for 200 epochs with two learning rate drops. Most of these parameters are taken from <ref type="bibr" target="#b67">[67]</ref>, as our conceptual framework is similar, but a further hyper-parameter search might lead to better results, given that our optimization goal differs substantially.</p><p>As a warm start for our models, we begin training using the IR loss function for the first 10 epochs, before switching over to using the LA method. Following the methods of <ref type="bibr" target="#b5">[6]</ref>, for AlexNet <ref type="bibr" target="#b36">[37]</ref> and VGG16 <ref type="bibr" target="#b60">[60]</ref> architectures, we add batch normalization (BN) layers <ref type="bibr" target="#b31">[32]</ref> after all convolution and fully-connected layers, before ReLu operations, to allow a higher learning rate and a faster convergence speed. Though adding BN is known to improve convergence speed but not typically to lead to higher final ImageNet performance levels using supervised training regimes, it is unclear whether this remains true when using unsupervised training methods. Importantly, the potentially competitive IR method <ref type="bibr" target="#b67">[67]</ref> did not originally include BN in their AlexNet and VGG16, so to ensure that we have fairly compared that method to LA or DC, we also train AlexNet and VGG16 with BN on the IR task. For all structures, we replace the final category readout layer with a linear layer with D output units, followed by a L2-normalization operation to ensure that the output is a unit vector.</p><p>We set k = 4096 for computing B i using the nearest neighbors procedure. In computing C i , we use kmeans <ref type="bibr" target="#b44">[44]</ref> implemented in Faiss <ref type="bibr" target="#b33">[34]</ref> as the standard unsupervised clustering algorithm, generating multiple clusterings for robustness via different random initializations. Using the notation of Section 3, AlexNet is trained with H = 3, m = 30000, VGG16 is trained with H = 6, m = 10000, all ResNet structures are trained with H = 10, m = 30000. We justify all parameter choices and intuitively explain why they are optimal in Section 5.2. All code for reproducing our training is available at: [WEBSITE WITHHOLD].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Transfer Learning Results</head><p>After fully training networks on ImageNet, we then test the quality of the learned visual representations by evaluating transfer learning to other tasks, including ImageNet classification on held-out validation images, scene classification on Places205 <ref type="bibr" target="#b72">[72]</ref>, and object detection on PAS-CAL VOC 2007 <ref type="bibr" target="#b16">[17]</ref>. For classification tasks, we also report K-nearest neighbor (KNN) classification results using the embedding features, acquired via a method similar to that in <ref type="bibr" target="#b67">[67]</ref>. Specifically, we take top K nearest neighbors N K for the feature v either (for ImageNet) from the saved memory bank or (for Places) from the computed network outputs for center crops of training images. Their labels are then weighted by exp(v T i v/τ ) and combined to get final predictions. We report results for K = 200 as in <ref type="bibr" target="#b67">[67]</ref>.</p><p>Object Recognition. To evaluate transfer learning for the ImageNet classification task, we fix network weights learned during the unsupervised procedure, add a linear readout layer on top of each layer we want to evaluate, and train the readout using cross-entropy loss together with L2 weight decay. We use SGD with momentum of 0.9, batch size 128, and weight decay 0.0001. Learning rate is initialized at 0.01 and dropped by a factor of 10 when performance saturates, typically leading to 90 training epochs with two learning rate drops. We report 10-crop validation performances to ensure comparability with <ref type="bibr" target="#b5">[6]</ref>. Performance results in <ref type="table" target="#tab_7">Table 1</ref> show that LA significantly outperforms other methods with all architectures, especially in deeper architectures. LA-trained AlexNet reaches 42.4%, which is 1.4% higher than previous state-of-theart. Improvements over previous unsupervised state-of-theart are substantially larger for VGG16 (+4.9%), ResNet-18 (+3.7%), and ResNet-50 (+6.2%). In particular, LAtrained ResNet-50 achieves 60.2% top-1 accuracy on Im-ageNet classification, surpassing AlexNet trained directly on the supervised task. Using KNN classifiers, LA outperforms the IR task by a large margin with all architectures. There is a consistent performance increase for the LA method both from overall deeper architectures, and from earlier layers to deeper layers within an architecture. Most alternative training methods (e.g. <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b70">70]</ref>) do not benefit significantly from increasing depth. For example, ResNet-101 trained using Color <ref type="bibr" target="#b70">[70]</ref> can only achieve 39.6% and the best performance using ResNet-101 with unsupervised task is only 48.7% with CPC <ref type="bibr" target="#b50">[50]</ref>.</p><p>Scene Categorization. To test the generalization ability of the learned representations to a data distribution distinct from that used in training, we assessed transfer to the Places <ref type="bibr" target="#b72">[72]</ref> dataset, which includes 2.45M images labelled with 205 scene categories. As in the previous section, we train linear readout layers for the scene categorization task on top of the pretrained ImageNet model, using training procedures and hyper-parameters identical to those used in ImageNet transfer learning. Results shown in <ref type="table">Table 2</ref> illustrate that the LA method surpasses previous methods in transfer learning performance with all architectures, especially with deeper networks. Please refer to the supplementary material for K-nearest neighbor classification performance. These result indicate strong generalization ability of the visual representations learned via the LA method.</p><p>Object Detection. The results presented in <ref type="table" target="#tab_7">Table 1</ref> and 2 illustrate the utility of LA for learning representations for visual categorization tasks. However, visual challenges faced in real life also include other tasks, such as object detection. Therefore, we also evaluate the transfer learning ability of our models to the object detection task in the PASCAL VOC 2007 <ref type="bibr" target="#b16">[17]</ref> dataset. The typical PASCAL detection task evaluation procedure <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b71">71,</ref><ref type="bibr" target="#b67">67,</ref><ref type="bibr" target="#b64">64]</ref> finetunes unsupervised architectures using the Fast RCNN <ref type="bibr" target="#b18">[19]</ref> method. However, Fast RCNN is substantially less computationally efficient than more recently proposed pipelines such as Faster RCNN <ref type="bibr" target="#b55">[55]</ref> or Mask RCNN <ref type="bibr" target="#b22">[23]</ref>, and is less well-supported by validated reference implementations  <ref type="table">Table 3</ref>, illustrating that the LA method achieves state-of-the-art unsupervised transfer learning for the PASCAL detection task. Interestingly, the performance gaps between the best unsupervised methods and the supervised controls are comparatively smaller for the PASCAL task than for the classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Visualizations</head><p>In this subsection, we analyze the embedding space through visualizations.</p><p>Density distribution in the embedding space. The LA optimization objective seeks to minimize the distances be-  <ref type="table">Table 3</ref>. PASCAL VOC 2007 detection mAP. A=AlexNet, V=VGG16, and R=ResNet50. Bold numbers are the best in their columns. Performances with Faster RCNN are produced by us, except that of ResNet50 of IR, which is as reported in <ref type="bibr" target="#b67">[67]</ref>. Most numbers using Fast RCNN are taken from <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b67">67]</ref>. For numbers produced by us, we show the averages of three independent runs. Standard deviations are close to 0.2% in all cases.  tween v i and C i while maximizing those between v i and B i , intuitively leading to an embedding that is locally dense at some positions but generally sparse across the space. Indeed, <ref type="figure" target="#fig_3">Figure 2</ref> shows that the local density of the LA embedding is much higher than that created by the IR method, while the background density is only slightly higher (note differing x-axis scales in the <ref type="figure">figure)</ref>. Moreover, insofar as deeper networks achieve lower minimums of the LA objective, we expect that their embeddings will exhibit higher local density and lower background density as compared to shallower networks. By comparing the density distributions of the ResNet-18 embedding to that of ResNet-50, <ref type="figure" target="#fig_3">Figure 2</ref> shows that this expectation is confirmed. These results help better characterize the LA optimization procedure.</p><formula xml:id="formula_10">Method A Fast A Faster V Fast V Faster R</formula><p>Success   <ref type="figure">Figure 3</ref>. For each of several validation images in the left-most column, nearest neighbors in LA-trained RestNet-50 embedding, with similarity decreasing from left to right. The three top columns are successfully-classified cases, with high KNN-classifier confidence, while the lower three are failure cases, with low KNNclassifier confidence. sified according to the nearest-neighbor classifier. Unsurprisingly, the successful examples show that the LA-trained model robustly groups images belonging to the same category regardless of backgrounds and view points. Interestingly, however, the network shows substantial ability to recognize high-level visual context. This is even more obvious for the failure cases, where it can be seen that the network coherently groups images according to salient characteristics. In fact, most failure cases produced by the LA model appear to be due to the inherently ill-posed nature of the ImageNet category labelling, in which the category label is only one of several potentially valid object types present in the image, and which no unsupervised method could unambiguously resolve. To further illustrate this point, we use the multi-dimensional scaling (MDS) algorithm <ref type="bibr" target="#b2">[3]</ref> to visualize part of the embedding space (see <ref type="figure" target="#fig_5">Fig. 4</ref>). In particular, the LA successfully clusters images with trombones regardless of background, number of trombones, or viewpoint, while it (perhaps inevitably) distinguishes those images from images of humans playing trombones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High Accuracy Classes</head><p>Low Accuracy Classes  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablations</head><p>In this subsection, we empirically justify the design of the LA procedure by ablating or modifying several key features of the procedure. We also provide analyses suggesting intuitive reasons underlying the meaning and influence of parameters on final performance. Please refer to the supplementary material for further analyses.</p><p>Dynamic Locality for Background Neighbors. We chose a nearest-neighbor based procedure for identifying B i to embody the idea of dynamically rescaling the local background against which closeness is judged. We tested two ablations of our procedure that isolate the relevance of this choice, including (i) simply using all inputs for background, or (ii) using a fixed clustering-based identification procedure. (See supplement for details on how these were defined.) Experiments show that the local dynamic nearestneighbor procedure is substantially more performant than either ablation (see <ref type="table" target="#tab_4">Table 4</ref>). The desirability of a local rather than global background measurement is consistent with the observation that the density of features varies widely across the embedding space (see <ref type="figure" target="#fig_3">Figure 2</ref>). That the dynamic nature of the computation of the background is  useful is illustrated by the comparison of results from computing neighbors in an online fashion from v i , relative to the cluster-based procedure depending only onV.</p><formula xml:id="formula_11">C i {i} N k (1,</formula><p>Robust Clustering for Close Neighbors. We also sought to understand the importance of the specific clustering procedure for defining close neighbors C i . One alternative to using cluster-based identification would be to instead identify "especially close" neighbors as those within a neighborhood N k , for some k k. Using this in the definition of C i is equivalent to optimizing the embedding to bring especially close neighbors closer together, while somewhat further away neighbors are moved apart. While this approach would have been a conceptually simpler way to define local aggregation than the cluster-based definition of close neighbors, it turns out to be substantially less effective in producing a useful representation (see <ref type="table" target="#tab_6">Table 5</ref>).</p><p>Given the need for cluster-based identification, a variety of alternative approaches to k-means are theoretically possible, including DBSCAN <ref type="bibr" target="#b15">[16]</ref>, Affinity Propagation <ref type="bibr" target="#b17">[18]</ref>, spectral methods <ref type="bibr" target="#b59">[59,</ref><ref type="bibr" target="#b62">62]</ref>, and gaussian mixtures <ref type="bibr" target="#b56">[56,</ref><ref type="bibr" target="#b57">57]</ref>. However, our present context is strongly constrained by the requirement that the clustering algorithm scale well to large datasets, effectively limiting the options to k-means and DBSCAN. Unfortunately, DBSCAN is known to perform poorly in settings with high ambient dimensions or highly variable density distributions <ref type="bibr" target="#b15">[16]</ref>, both of which are characteristics of the embedding space we work with here (see <ref type="figure" target="#fig_3">Figure 2</ref>). Indeed, we find that replacing k-means with DB-SCAN leads to trivial representations, across a wide variety of parameter settings (see supplement for details).</p><p>The robust clustering procedure described in Section 3.1 has several hyperparameters, including number of clusters m and number of clusterings H. To intuitively understand their effect, we performed a set of network characterization experiments (see supplement for details). These experiments indicated that two basic factors were of importance in creating clusterings that lead to good representations: the skewness of the cluster of close neighbors around its intended target, as measured by the distance from the cluster center to the embedded vector v i , and the size of the cluster, as measured by its cardinality as a set. We found that (i) clusterings of close neighbors with lower skewness were robustly associated with better performance, indicating that skewness should be minimized whenever possible; and (ii) there was an optimal size for the set of close neighbors that scaled with the representation capacity (i.e. depth) of the underlying network. Both of these facts are consistent with a picture in which the ideal embedding is one in which each category is equally likely to occur and in which each example of each category is equally "representative" -e.g. in which clusters of points corresponding to natural categories occupy isotropic spheres of equal size. Networks of smaller capacity that cannot completely achieve the optimal distribution will (poorly) approximate the optimal embedding by fracturing their embeddings of single categories into subsets that maintain isotropy by reducing the relative size of clusters, each containing only part of the true category. These considerations help explain the optimal settings for parameters H and m: higher H (i.e. more clusterings) will tend to produce more isotropic clusters, as outliers due to randomness are averaged out. However, increasing H beyond a point set by the capacity of the network will lead to clusters of too large a size for the network to handle (see supplement <ref type="figure" target="#fig_7">Figure 1</ref>, from A to B, or from B to C). This negative influence can be shown in <ref type="table" target="#tab_6">Table 5</ref> by the slight performance drop from (3, 10k) to <ref type="bibr">(10, 10k)</ref>. Increasing m (e.g. the number of clusters) can then compensate by decreasing the neighborhood size without increasing cluster anisotropy (see supplement <ref type="figure" target="#fig_7">Figure 1</ref>, from C to D). This conpensation can be shown in <ref type="table" target="#tab_6">Table 5</ref> by the performance increase from (10, 10k) to <ref type="bibr">(10, 30k)</ref>. More experiments detailing these conclusions are shown in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>In this work, we have introduced a local aggregation (LA) objective for learning feature embeddings that seeks to discover a balance between bringing similar inputs together and allowing dissimilar inputs to move apart, embodying a principled combination of several key ideas from recent advances in unsupervised learning. We have shown that when applied to DCNNs, the LA objective creates representations that are useful for transfer learning to a variety of challenging visual tasks. We also analyze aspects of our procedure, giving an intuition for how it works.</p><p>In future work we hope to improve the LA objective along a variety of directions, including incorporating nonlocal manifold learning-based priors for detecting similarity, improving identification of dissimilarity via measures of representational change over multiple steps of learning, and extending to the case of non-deterministic embedding functions. We also seek to apply the LA objective beyond the image processing domain, including to video and audio signals. Finally, we hope to compare the LA procedure to biological vision systems, both in terms of the feature representations learned and the dynamics of learning during visual development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Clustering Combination</head><p>In this section we provide an illustration figure for the effects of combining multiple clusterings in <ref type="figure" target="#fig_7">Figure 1</ref>, which is also mentioned in Section 5.2. Additionally, we show the nearest neighbor validation performances in <ref type="table" target="#tab_7">Table 1</ref> to support our hyper-parameter choices for H, m in different architectures.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting</head><p>Network A V R-18 R-50 </p><formula xml:id="formula_12">(1, 1k) - -35.2 - (1,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Transfer Learning Details</head><p>Besides the settings listed in the main paper, there are additional settings for data augmentation during our transfer learning training to ImageNet and Places 205 datasets. In general, we use random crop and random horizontal flip as data augmentation techniques during transfer learning for all architectures on both ImageNet and Places 205 datasets, where the specific random crop implementation varies across networks and datasets. For AlexNet on Im-ageNet and all architectures on Places 205, we use the AlexNet style random crop <ref type="bibr" target="#b25">[26]</ref>, which is first resizing the image so that its smallest side is 256 and then randomly cropping a 224 × 224 patch. For VGG16, ResNet-18, and ResNet-50 on ImageNet, we use the ResNet style random crop <ref type="bibr" target="#b23">[24]</ref>, which is first randomly choosing a patch whose aspect ratio and area suffice two conditions and then resizing that path to 224 × 224. The two sufficed conditions are: its area is at least 20% of the overall area and at most 100% of the overall area; its aspect ratio ranges from 3/4 to 4/3. We use the same data augmentation techniques for the same architecture trained with different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. DeepCluster Results Details</head><p>The DeepCluster <ref type="bibr" target="#b5">[6]</ref> VGG16, ResNet-18, and ResNet-50 results are produced by us, where the DC-VGG16 network is provided by the authors and the DC-ResNet-18 and DC-ResNet-50 networks are trained by us using the provided source codes.</p><p>More specifically, for ResNet-18, two implementations of DC-ResNet-18 network are trained. Both of them modifies the standard ResNet-18 architecture by removing the final pooling and final fully connected layer and then adding additional fully connected layers, where the last layer has 10000 units. One implementation (DC-ResNet-18-A) only has that 10000-unit fully connected layer and the other implementation (DC-ResNet-18-B) has two more 4096-unit fully connected layers before that. We find that DC-ResNet-18-B performs slightly better than DC-ResNet-18-A and thus report the performances of DC-ResNet-18-B in the main paper.</p><p>Similarly for ResNet-50, two implementations (DC-ResNet-50-A and DC-ResNet-50-B) are trained. However, we find it impossible to train DC-ResNet-50-B as the kmeans clustering results always become trivial at the third epoch. So the results reported in the paper are from DC-ResNet-50-A, which should only be slightly worse than DC-ResNet-50-B.</p><p>Other hyper-parameters for network training are mostly the same as used in the provided source codes. Meanwhile, all hyper-parameters for transfer learning to ImageNet and Places 205 are also the same as provided, except the data augmentation techniques which are the same as described in Section B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Places KNN Results</head><p>We run models on center crops of training images in Places 205 <ref type="bibr" target="#b72">[72]</ref> dataset to generate the memory bankV. We then run the KNN validation similarly to the ImageNet <ref type="bibr" target="#b9">[10]</ref> KNN procedure, which is described in the main paper. The results are shown in <ref type="table">Table 2</ref>  <ref type="table">Table 2</ref>. KNN results for Places 205 dataset. "A" means "AlexNet". "V" means VGG16. "R" means "ResNet".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Faster RCNN Details</head><p>Our Faster RCNN <ref type="bibr" target="#b55">[55]</ref> implementations are based on tffaster-rcnn. We use SGD with momentum of 0.9, batch size 256, and weight decay 0.0001. Learning rate is initialized as 0.001 and dropped by a factor of 10 after 50000 steps. We train the models for 70000 steps. In particular, we set the number of total RoIs for training the region classifier to be 128 to reproduce the original Faster RCNN results, as indicated by <ref type="bibr">[?]</ref>. For AlexNet, we fine-tune all layers. For VGG16, we fix "conv1" and "conv2" while fine-tuning others. For ResNet-50, we fix the first convolution layer and the first three blocks while fine-tuning others. Other hyper-parameters are the same as the default settings in tffaster-rcnn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Other Hyperparameters</head><p>There are several other adjustable hyper-parameters in LA training procedure, such as the updating frequency for the clustering results, the parameter k in N k for B i , and whether doing clustering onV or network outputs on center crops of I. In this section, we show results of experiments illustrating the influences of these parameters in <ref type="table">Table 3</ref>  <ref type="table">Table 3</ref>. Nearest neighbor validation performances for ResNet-18 trained with different settings. "Baseline" uses H = 1, m = 10000, and k = 4096. Other settings change one of the hyperparameters while keeping the others the same. "center crop" represents the experiment with clustering result acquired on the center crops rather thanV. "more freq" represents the experiment with clustering result updated every 1000 steps.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>m</head><label></label><figDesc>(j) } with j ∈ {1, 2, ..., H}, and {g (j) } defined accordingly. We then define</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Distributions across all ImageNet training images of local and background densities for feature embeddings. We compare features from ResNet-18 (orange bars) and Resnet-50 (green bars) architectures as trained by the LA method, as well as that of a ResNet-18 architecture trained by the Instance Recognition (IR) method (blue bars). The local and background densities at each embedded vector are estimated by averaging dot products between that vector and, respectively, its top 30 or its 1000th-4096th, nearest neighbors inV. See supplementary material for more detail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>and failure examples. To help qualitatively illustrate the successes and failures of the LA objective, Figure 3 shows nearest neighbors in the training set for several validation images, both correctly and incorrectly clas-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Multi-dimensional scaling (MDS) embedding results for network outputs of classes with high validation accuracy (left panel) and classes with low validation accuracy (right panel). For each class, we randomly choose 100 images of that class from the training set and apply the MDS algorithm to the resulting 600 images. Dots represent individual images in each color-coded category. Gray boxes show examples of images from a single class ("trombone") that have been embedded in two distinct subclusters.Choice of B i {1, 2, ..., N } Cluster-based N 4096</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of the effect of combining across multiple clusterings to achieve robustness. The target embedded vector vi is represented by the red dot, while blue dots represent close neighbors Ci under the specified hyperparameter settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>17.1 16.9 16.3 14.1 3.5 Context [13] 16.2 23.3 30.2 31.7 29.6</figDesc><table><row><cell>Method</cell><cell cols="3">conv1 conv2 conv3 conv4 conv5 KNN</cell></row><row><cell></cell><cell></cell><cell>AlexNet</cell></row><row><cell>Random</cell><cell cols="3">11.6 -</cell></row><row><cell>Color [70]</cell><cell cols="2">13.1 24.8 31.0 32.6 31.8</cell><cell>-</cell></row><row><cell>Jigsaw [48]</cell><cell cols="2">19.2 30.1 34.7 33.9 28.3</cell><cell>-</cell></row><row><cell>Count [49]</cell><cell cols="2">18.0 30.6 34.3 32.5 25.7</cell><cell>-</cell></row><row><cell cols="4">SplitBrain [71] 17.7 29.3 35.4 35.2 32.8 11.8</cell></row><row><cell>IR [67]</cell><cell cols="3">16.8 26.5 31.8 34.1 35.6 31.3</cell></row><row><cell cols="4">IR(with BN)* 18.4 30.1 34.4 39.2 39.9 34.9</cell></row><row><cell>DC [6]</cell><cell cols="2">13.4 32.3 41.0 39.6 38.2</cell><cell>-</cell></row><row><cell>LA (ours)</cell><cell cols="3">18.7 32.7 38.1 42.3 42.4 38.1</cell></row><row><cell></cell><cell></cell><cell>VGG16</cell></row><row><cell>IR</cell><cell cols="3">16.5 21.4 27.6 35.1 39.2 33.9</cell></row><row><cell cols="4">IR(with BN)* 13.2 18.7 27.3 39.8 50.4 42.1</cell></row><row><cell>DC*</cell><cell cols="2">18.2 27.5 41.5 51.3 52.7</cell><cell>-</cell></row><row><cell>LA (ours)</cell><cell cols="3">14.3 23.4 28.3 44.5 57.6 46.6</cell></row><row><cell></cell><cell></cell><cell>ResNet-18</cell></row><row><cell>IR</cell><cell cols="3">16.0 19.9 29.8 39.0 44.5 41.0</cell></row><row><cell>DC*</cell><cell cols="2">16.4 17.2 28.7 44.3 49.1</cell><cell>-</cell></row><row><cell>LA (ours)</cell><cell>9.1</cell><cell cols="2">18.7 34.8 48.4 52.8 45.0</cell></row><row><cell></cell><cell></cell><cell>ResNet-50</cell></row><row><cell>IR</cell><cell cols="3">15.3 18.8 24.9 40.6 54.0 46.5</cell></row><row><cell>DC*</cell><cell cols="2">18.9 27.3 36.7 52.4 44.2</cell><cell>-</cell></row><row><cell>LA (ours)</cell><cell cols="3">10.2 23.3 39.3 49.0 60.2 49.4</cell></row></table><note>Table 1. ImageNet transfer learning and KNN classifier perfor- mance. Numbers within the red box are the best for the given architecture. Performances of most methods using AlexNet are taken from [6, 67].*: performance number produced by us, please refer to the supplementary material for training details.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table Lamp</head><label>Lamp</label><figDesc></figDesc><table><row><cell>Rock_beauty Great grey Saltshaker Zebra owl</cell></row><row><cell>Pred:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table /><note>Nearest neighbor validation performances of ResNet-18 trained with different choices of Bi. We use H = 3 and m = 1000 for cluster-based Bi to make the number of neighbors in Bi comparable to 4096. In all experiments, we use cluster-based Ci with H = 1 and m = 10000.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Nearest neighbor validation performances of ResNet-18 trained with different choices of Ci. All experiments use N4096 as Bi. {i} means Ci only includes vi itself. (1, 10k) means clustering-based Ci with H = 1 and m = 10000. Other pairs have similar meanings. See the supplementary material for details.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 1 .</head><label>1</label><figDesc>Nearest neighbor validation performances of different architectures trained with different choices of Ci. "A" means</figDesc><table><row><cell>10k)</cell><cell cols="2">30.6 38.9 35.7 40.2</cell></row><row><cell>(1, 20k)</cell><cell>-</cell><cell>-35.0 -</cell></row><row><cell>(3, 10k)</cell><cell cols="2">31.1 -36.2 -</cell></row><row><cell>(6, 10k)</cell><cell cols="2">30.4 39.7 37.3 42.4</cell></row><row><cell>(10, 10k)</cell><cell>-</cell><cell>-36.1 42.3</cell></row><row><cell>(10, 30k)</cell><cell>-</cell><cell>-37.9 43.4</cell></row></table><note>"AlexNet". "V" means VGG16. "R" means "ResNet". Similarly to Table 5 in the main text, (1, 10k) means clustering-based Ci with H = 1 and m = 10000.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The developing visual brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Atkinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="311" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modern multidimensional scaling: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Groenen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="280" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hierarchical development of the primate visual cortex, as revealed by neurofilament immunoreactivity: early maturation of the middle temporal area (mt)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bourne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Rosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral cortex</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="414" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Development of human visual function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Braddick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Atkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1588" to="1609" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? a new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6299" to="6308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Concept acquisition in the human infant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Child development</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="419" to="424" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01781</idno>
		<title level="m">Very deep convolutional networks for natural language processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">New types of deep neural network learning for speech recognition and related applications: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8599" to="8603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep generative image models using a laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-task self-supervised visual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2051" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<title level="m">Adversarial feature learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A densitybased algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Kdd</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Clustering by passing messages between data points. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="972" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Deep speech: Scaling up end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.5567</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiple sensitive periods in the development of the primate visual system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Harwerth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Von Noorden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">232</biblScope>
			<biblScope unit="issue">4747</biblScope>
			<biblScope unit="page" from="235" to="238" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The organization of behavior. na</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">O</forename><surname>Hebb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal processing magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reducing the dimensionality of data with neural networks. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Advances in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6245</biblScope>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Infant learning of ill-defined categories. Merrill-Palmer Quarterly of Behavior and Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Husaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="page" from="443" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Texture synthesis with spatial generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jetchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.08207</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<title level="m">Billion-scale similarity search with gpus</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06856</idno>
		<title level="m">Datadependent initializations of convolutional neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Building high-level features using large scale unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1112.6209</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multiple sensitive periods in human visual development: evidence from visually deprived children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental Psychobiology: The Journal of the International Society for Developmental Psychobiology</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="163" to="183" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Precomputed real-time texture synthesis with markovian generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="702" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Least squares quantization in pcm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on information theory</title>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="129" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Ensemble of exemplar-svms for object detection and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Categorization in infancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Quinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="443" to="450" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Audio-visual speech recognition using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Noda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakadai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="722" to="737" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Representation learning by learning to count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning features by watching objects move</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2701" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Early category and concept development: Making sense of the blooming, buzzing confusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Rakison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Oakes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Gaussian mixture models. Encyclopedia of biometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reynolds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="827" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Speaker verification using adapted gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Quatieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital signal processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="19" to="41" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Optimal unsupervised learning in a singlelayer linear feedforward neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Sanger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="459" to="473" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Normalized cuts and image segmentation. Departmental Papers (CIS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page">107</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Organization, development and function of complex brain networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sporns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Chialvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Hilgetag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="418" to="425" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Multiclass spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Y</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>IEEE</publisher>
			<biblScope unit="page">313</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations using videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Transitive invariance for self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Reorganization of global form and motion processing during human visual development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wattam-Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Birtles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nyström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Von Hofsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rosander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Braddick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Improving generalization via scalable neighborhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Recent trends in deep learning based natural language processing. ieee Computational intelligenCe magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="55" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5907" to="5915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Split-brain autoencoders: Unsupervised learning by cross-channel prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1058" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning deep features for scene recognition using places database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
