<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Strong but Simple Baseline with Dual-Granularity Triplet Loss for Visible-Thermal Person Re-Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijun</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxia</forename><surname>Chai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoheng</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xichuan</forename><surname>Zhou</surname></persName>
						</author>
						<title level="a" type="main">Strong but Simple Baseline with Dual-Granularity Triplet Loss for Visible-Thermal Person Re-Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Visible-thermal person re-identification</term>
					<term>dual- granularity triplet loss</term>
					<term>fine to coarse granularity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This letter presents a conceptually simple and effective dual-granularity triplet loss for visible-thermal person re-identification (VT-ReID). Generally, ReID models are always trained with the sample-based triplet loss and identification loss from the fine granularity level. Further, center-based loss could be introduced to encourage the intra-class compactness and inter-class discrimination from the coarse granularity level. Our proposed dual-granularity triplet loss well organizes the sample-based triplet loss and center-based triplet loss in a hierarchical fine to coarse granularity manner, just with some simple configurations of typical operations, such as pooling and batch normalization. Experiments on RegDB and SYSU-MM01 datasets show that with only the global features our dualgranularity triplet loss can improve the VT-ReID performance by a significant margin. It can be a strong VT-ReID baseline to boost future research with high quality.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>V ISIBLE-thermal person re-identification (VT-ReID), aiming to search a person of interest cross-modality and cross-sensor cameras deployed at different locations, is widely encountered in a practical 24-hour intelligent surveillance scenarios, especially during the nighttime <ref type="bibr" target="#b17">[18]</ref>. Compared to traditional visible-visible ReID (VV-ReID), which focuses on retrieving pedestrians only cross RGB cameras <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b19">[20]</ref>, VT-ReID is a more challenge problem, since person images are from different modalities with a huge gap. Apart from the intra-modality (intra-and inter-class) variations as existed in VV-ReID, VT-ReID additionally suffers from the large crossmodality discrepancy.</p><p>Recently, due to the broad application prospects of VT-ReID, an large number of studies with some novel and effective modules or training strategies are presented to address this problem <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b18">[19]</ref>. However, many works ignored the design of baseline model, just evaluating the effectiveness of their ideas with a poor baseline. It has negative effect on the developing of VT-ReID community, since the improvement of baseline model plays an important role. Therefore, the present study focuses on developing a strong and effective VT-ReID baseline with some simple and typical means.</p><p>Generally, to simultaneously address the intra-modality variations and cross-modality discrepancy, different methods H. <ref type="bibr">Liu</ref> have been proposed, mainly focusing on model designing and metric learning. Moreover, in order to obtain great results, researchers in the academia always aggregate several part (local) features <ref type="bibr" target="#b13">[14]</ref> or leverage semantic features from pose estimation <ref type="bibr" target="#b11">[12]</ref>. However, such approaches are not the preferable choice for industry, always bringing additional consumption. In our previous study <ref type="bibr" target="#b7">[8]</ref>, we have explored how to build the two-stream backbone network and proposed the hetero-center based triplet loss under the part person feature learning framework. Therefore, to be different from <ref type="bibr" target="#b7">[8]</ref>, in this letter, we try to adopt some simple and typical means to improve the VT-ReID model with only the global person features extracted by the backbone model.</p><p>This letter mainly focuses on the design of an effective baseline from two aspects. On one hand, some simple and typical means are experimentally explored to obtain the global features, including the pooling and batch normalization operations. On the other hand, the organization manner of sample-based triplet loss and center-based triplet loss are also experimentally explored to guide the network training. To summarize, our dual-granularity triplet loss (DGTL), in a hierarchical fine to coarse granularity manner, could achieve superior performance on RegDB <ref type="bibr" target="#b9">[10]</ref> and SYSU-MM01 <ref type="bibr" target="#b15">[16]</ref> datasets. It can be a new baseline for VT-ReID with only the global features, through a simple but effective strategy. <ref type="figure">Fig. 1</ref> illustrates the framework of our proposed baseline model for VT-ReID, mainly consists of two components: (1) the backbone network, and (2) the dual-granularity triplet loss module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DUAL-GRANULARITY TRIPLET LOSS BASED BASELINE MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Backbone network</head><p>Based on the observation of our previous study <ref type="bibr" target="#b7">[8]</ref>, we empirically set the backbone with a two-stream network to process images from two different modalities, as shown in <ref type="figure">Fig. 1</ref>. Following <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b20">[21]</ref>, the ResNet50 <ref type="bibr" target="#b2">[3]</ref> model is adopted to construct the backbone network. The shallow convolution block (layer0) and the first res-convolution block (layer1) are set as the modality-specific submodule with different parameters to learn the modality-specific low-level 3D information from two heterogeneous modalities. Then the remaining 3 res-convolution blocks (layer2, layer3 and layer4) are set as the modality-shared submodule with shared arXiv:2012.05010v2 [cs.CV] 10 Mar 2021 The proposed dual-granularity triplet loss based feature learning framework for VT-ReID, including two components: backbone network and dualgranularity triplet loss module. The backbone network contains two modality-specific submodules with independent parameters and one modality-shared submodule with shared parameters. The dual-granularity triplet loss module focuses on learning high quality person features with inter-class discrimination and intra-class compactness ability. At the beginning, the 3D feature maps outputted from the backbone are respectively processed by two pooling methods in the fine granularity branch and coarse granularity branch. In fine granularity branch, the pooling features are supervised by the sample-based triplet loss (L f tri ) and identification loss (L id ) with BNNeck <ref type="bibr" target="#b8">[9]</ref> to obtain features f bn , following the black lines (our baseline). Meanwhile, in the coarse granularity branch, the pooling features are firstly fused with f bn . Afterwards, the fused features are supervised by the center-based triplet loss (L c tri ) and identification loss (L id ) from the coarse granularity level to obtain features f bnf , following the additional red lines. During testing, the f bn and f bnf with L2 normalization can be adopted as the person features.</p><p>parameters to learn the multi-modality shared mid-level feature representations in a common 3D feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dual-granularity triplet loss module</head><p>Our proposed dual-granularity triplet loss (DGTL) module focuses on three aspects for setting the new VT-ReID baseline, including 1) the pooling methods, 2) the batch normalization neck and 3) loss function. At each iteration, we adopt the identity-balanced sampling method <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b20">[21]</ref> to construct the mini-batch. For each of P randomly selected person identities, K visible images and K thermal images are randomly sampled, totally including 2 * P K images.</p><p>1) Pooling methods: After obtaining the 3D person feature maps from the backbone network, we should firstly translate them into 1D feature vectors. We experimentally study three kinds of the pooling methods, the global average pooling (Avg), the global max pooling (Max) and the generalizedmean pooling (GeM) <ref type="bibr" target="#b10">[11]</ref>. The results are shown in Tables III and IV. <ref type="bibr" target="#b0">1</ref> 2) Batch normalization neck: The batch normalization neck (BNNeck) <ref type="bibr" target="#b8">[9]</ref> is firstly introduced in VV-ReID to address the inconsistent problem of identification and metric (e.g. triplet) losses in the same embedding space. Namely, the metric loss and identification loss should process different feature vectors, before or after the batch normalization layer. However, in our framework, the BNNeck is only applied in the fine granularity branch, while in the coarse granularity branch the metric and <ref type="bibr" target="#b0">1</ref> When the pooling methods in fine and coarse branches are identical (as experimentally set for RegDB dataset), the two branches degenerate to one with a feature skip connection across the batch normalization layer. identification losses are both applied to the features after the batch normalization layer (f bnf ), as shown in <ref type="figure">Fig. 1</ref>.</p><p>3) Dual-granularity triplet loss: Our previous study <ref type="bibr" target="#b7">[8]</ref> only concentrates on the center-based triplet loss, which is in the coarse granularity level. Here, we simultaneously consider the sample-based triplet loss and center-based triplet loss by constructing two branches, and arrange them in a hierarchical fine to coarse granularity manner, as shown in <ref type="figure">Fig. 1</ref>. One branch focuses on the fine granularity level with sample-based triplet loss (L f tri ) and identification loss (L id ) (our baseline). The other branch processes the fused features, focusing on the coarse granularity level with center-based triplet loss (L c tri ) and identification loss (L id ).</p><p>Fine granularity triplet loss: We equally process person features from the fine granularity level based on each sample whether it is from visible modality or thermal modality. The online hard-mining triplet loss [?] is adopted as our fine granularity triplet loss L f tri . For each feature f a in the minibatch, we can mine the hardest positive f p and hardest negative f n to construct the triplet, to compute the fine granularity triplet loss,</p><formula xml:id="formula_0">L f tri (f ) = P i=1 2K a=1 m + max p=1...2K f i a − f i p 2 (1) − min j=1...P n=1...2K j =i f i a − f j n 2 + ,</formula><p>where m is the margin, f i a denotes the a th image feature of the i th identity in the mini-batch, [·] + = max(·, 0) represents the standard hinge loss, f a −f p 2 denotes the Euclidean distance of two feature vectors f a and f p .</p><p>Coarse granularity triplet loss: We process the visible and thermal person features from the coarse granularity level based on heterogeneous centers of each identity. The hetero-center triplet loss <ref type="bibr" target="#b7">[8]</ref> is adopted as our coarse granularity triplet loss L c tri . For each identity, we can focus on the only one crossmodality positive center pair and the mined hardest (intraand inter-modality) negative center pair, to compute the coarse granularity triplet loss,</p><formula xml:id="formula_1">Lc tri(f ) = P i=1 mc + f c i v − f c i t 2 − min m∈{v,t} j =i f c i v − f c j m 2 +<label>(2)</label></formula><formula xml:id="formula_2">+ P i=1 mc + f c i t − f c i v 2 − min m∈{v,t} j =i f c i t − f c j m 2 + , where mc is the margin, f c i v = 1 K K j=1 f i v,j , f c i t = 1 K K j=1 f i t,j</formula><p>are the visible and thermal centers of i th identity, respectively. f i v,j and f i t,j respectively denote the j th visible and thermal image features of i th identity.</p><p>Dual-granularity triplet loss: Finally, the overall dualgranularity triplet loss (DGTL) is,</p><formula xml:id="formula_3">L all = f ine granularity L f tri (f p ) + L id (f bn ) + coarse granularity L c tri (f bnf ) + L id (f bnf ),</formula><p>(</p><p>where f p , f bn and f bnf are the global person features as shown in <ref type="figure">Fig. 1</ref>. The hierarchical fine to coarse granularity arrangement manner of L f tri and L c tri is also illustrated in <ref type="figure">Fig. 1</ref>. The main contributions of Eq. (3) are 1) the organization of L f tri and L c tri , 2) the processing features for each triplet loss, corresponding to the position of BNNeck.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head><p>We evaluate the effectiveness of our proposed method for VT-ReID on two public datasets, RegDB <ref type="bibr" target="#b9">[10]</ref> and SYSU-MM01 <ref type="bibr" target="#b15">[16]</ref>. The implementation 2 of our method is with the Pytorch framework. The training and testing procedures are following the official settings as done in <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b19">[20]</ref>. For the P K sampling strategy, we set P = 8, K = 4 for the RegDB, and P = 6, K = 8 for the SYSU-MM01. The pooling method is Max in both fine and coarse branches for RegDB, while Avg in fine branch and Max in coarse branch for SYSU-MM01. We set m = 0.3, mc = 0.3 for RegDB, and mc = 0.8 for SYSU-MM01. The fusion method is element-wise sum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Comparison to the state-of-the-art</head><p>In this section, our DGTL with only the global features is compared to some state-of-the-art VT-ReID methods, recently published in 2020. The results on the RegDB and SYSU-MM01 datasets are listed in Tables I and II, respectively. In this subsection, the mean results of 10 trials are reported following the standard dataset settings. They show that our proposed DGTL method can achieve much better performance, especially compared to those methods with only the global features (CMSP <ref type="bibr" target="#b14">[15]</ref>,HAT <ref type="bibr" target="#b20">[21]</ref>,MSR <ref type="bibr" target="#b1">[2]</ref>,MACE <ref type="bibr" target="#b16">[17]</ref>,Hi-CMD <ref type="bibr" target="#b0">[1]</ref>,CML <ref type="bibr" target="#b4">[5]</ref>,JSIA <ref type="bibr" target="#b12">[13]</ref> and XIV <ref type="bibr" target="#b3">[4]</ref>), even outperforming the 2 https://github.com/hijune6/DGTL-for-VT-ReID DDAG <ref type="bibr" target="#b18">[19]</ref> method, which adopts the part-aggregated feature learning to refine the person features. Moreover, the results based on the f bn feature, just the direct output of the ResNet50 model, also can achieve satisfactory performance, even similar to those results based on f bnf feature on RegDB dataset. It demonstrates the effectiveness of our dual-granularity triplet loss module with a simple but effective strategy, which truly can be a strong VT-ReID baseline to boost future research with high quality.</p><p>Our DGTL method performs worse than HcTri <ref type="bibr" target="#b7">[8]</ref>, which is our previous study for part feature learning with much more model parameters and training tricks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Alation experiments</head><p>We evaluate the effectiveness of our proposed DGTL module, including three components, pooling methods, loss functions organization and the BNNeck configuration. To simply show the effectiveness of different components, during the ablation experiments, only one trial experimental results are reported, rather than the mean results of 10 trials.</p><p>Tables III and IV list the results of different pooling method arrangements in fine and coarse granularity branches, respectively. Different pooling methods truly perform differently,    . Therefore, the pooling method is a key factor for constructing the VT-ReID baseline. <ref type="table" target="#tab_5">Table V</ref> lists the results of different triplet loss arrangements in the fine and coarse granularity branches. In our baseline methods (only with the fine granularity branch), the combination of L f tri and L c tri truly can improve the VT-ReID performance. As to the dual-granularity setting, the arrangements of L f tri and L c tri have impact on the performance. In summary, our proposed hierarchical fine to coarse (f2c) granularity manner could obtain the best performance. <ref type="table" target="#tab_1">Table VI</ref> shows that the BNNeck <ref type="bibr" target="#b8">[9]</ref> module only applied in the fine granularity branch is the best setting. Moreover, <ref type="figure" target="#fig_1">Fig. 2</ref> also illustrates the effects of different fusion methods and the margin parameter in L c tri .</p><p>The best performances for two datasets are with different configurations. The reason may lie in the image conditions.  For RegDB, the visible and corresponding thermal images are well aligned. While for SYSU-MM01, the visible and corresponding infrared images are with arbitrary poses and views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSIONS</head><p>In this letter, we propose a strong VT-ReID baseline with a simple but effective strategy. To our best knowledge, it can achieve the best performance with only the global features extracted by the backbone model. Our proposed DGTL method arranges the sample-based triplet loss and center-based triplet loss in a hierarchical fine to coarse granularity manner. Some simple configurations of typical operations, e.g. the pooling methods and batch normalization, are also explored for VT-ReID tasks. We hope that this study can promote the VT-ReID research with high quality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1. The proposed dual-granularity triplet loss based feature learning framework for VT-ReID, including two components: backbone network and dualgranularity triplet loss module. The backbone network contains two modality-specific submodules with independent parameters and one modality-shared submodule with shared parameters. The dual-granularity triplet loss module focuses on learning high quality person features with inter-class discrimination and intra-class compactness ability. At the beginning, the 3D feature maps outputted from the backbone are respectively processed by two pooling methods in the fine granularity branch and coarse granularity branch. In fine granularity branch, the pooling features are supervised by the sample-based triplet loss (L f tri ) and identification loss (L id ) with BNNeck [9] to obtain features f bn , following the black lines (our baseline). Meanwhile, in the coarse granularity branch, the pooling features are firstly fused with f bn . Afterwards, the fused features are supervised by the center-based triplet loss (L c tri ) and identification loss (L id ) from the coarse granularity level to obtain features f bnf , following the additional red lines. During testing, the f bn and f bnf with L2 normalization can be adopted as the person features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>The effects of (a) fusion methods (sum: element-wise sum, cat: concatenation) and (b) margin parameter mc in L c tri on RegDB and SYSU-MM01 datasets. Re-identification rates of rank1 and mAP (%).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, Y. Chai, X. Tan, D. Li and X. Zhou are with the School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, 400044, China.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I COMPARISON</head><label>I</label><figDesc>TO THE STATE-OF-THE-ART METHODS ON THE REGDB DATASETS. RE-IDENTIFICATION RATES AT RANK1 AND MAP (%).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Visible to Thermal</cell><cell cols="2">Thermal to Visible</cell></row><row><cell cols="2">Methods</cell><cell>Venue</cell><cell>rank1</cell><cell>mAP</cell><cell>rank1</cell><cell>mAP</cell></row><row><cell cols="2">CMSP [15]</cell><cell>IJCV20</cell><cell>65.07</cell><cell>64.50</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">HAT [21]</cell><cell>TIFS20</cell><cell>71.83</cell><cell>67.56</cell><cell>70.02</cell><cell>66.30</cell></row><row><cell cols="2">MSR [2]</cell><cell>TIP20</cell><cell>48.43</cell><cell>48.67</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">MACE [17]</cell><cell>TIP20</cell><cell>72.37</cell><cell>69.09</cell><cell>72.12</cell><cell>68.57</cell></row><row><cell cols="2">Hi-CMD [1]</cell><cell>CVPR20</cell><cell>70.93</cell><cell>66.04</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CML [5]</cell><cell>MM20</cell><cell>59.81</cell><cell>60.86</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">JSIA [13]</cell><cell>AAAI20</cell><cell>48.10</cell><cell>48.90</cell><cell>48.50</cell><cell>49.30</cell></row><row><cell cols="2">XIV [4]</cell><cell>AAAI20</cell><cell>62.21</cell><cell>60.18</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">DDAG [19]</cell><cell>ECCV20</cell><cell>69.34</cell><cell>63.46</cell><cell>68.06</cell><cell>61.08</cell></row><row><cell>DGTL</cell><cell>f bn f bnf</cell><cell>ours</cell><cell>83.56 83.92</cell><cell>73.36 73.78</cell><cell>81.27 81.59</cell><cell>71.22 71.65</cell></row><row><cell cols="2">HcTri [8]</cell><cell>TMM20</cell><cell>91.05</cell><cell>83.28</cell><cell>89.30</cell><cell>81.46</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE II</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">COMPARISON TO THE STATE-OF-THE-ART METHODS ON THE</cell></row><row><cell cols="7">SYSU-MM01 DATASETS. RE-IDENTIFICATION RATES AT RANK1 AND</cell></row><row><cell></cell><cell></cell><cell cols="2">MAP (%).</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">All search</cell><cell cols="2">Indoor search</cell></row><row><cell cols="2">Methods</cell><cell>Venue</cell><cell>rank1</cell><cell>mAP</cell><cell>rank1</cell><cell>mAP</cell></row><row><cell cols="2">CMSP [15]</cell><cell>IJCV20</cell><cell>43.56</cell><cell>44.98</cell><cell>48.62</cell><cell>57.50</cell></row><row><cell cols="2">HAT [21]</cell><cell>TIFS20</cell><cell>55.29</cell><cell>53.89</cell><cell>62.10</cell><cell>69.37</cell></row><row><cell cols="2">MSR [2]</cell><cell>TIP20</cell><cell>37.35</cell><cell>38.11</cell><cell>39.64</cell><cell>50.88</cell></row><row><cell cols="2">MACE [17]</cell><cell>TIP20</cell><cell>51.64</cell><cell>50.11</cell><cell>57.35</cell><cell>64.79</cell></row><row><cell cols="2">Hi-CMD [1]</cell><cell>CVPR20</cell><cell>34.94</cell><cell>35.94</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CML [5]</cell><cell>MM20</cell><cell>51.80</cell><cell>51.21</cell><cell>54.98</cell><cell>63.7</cell></row><row><cell cols="2">JSIA [13]</cell><cell>AAAI20</cell><cell>38.10</cell><cell>36.90</cell><cell>43.80</cell><cell>52.90</cell></row><row><cell cols="2">XIV [4]</cell><cell>AAAI20</cell><cell>49.92</cell><cell>50.73</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">DDAG [19]</cell><cell>ECCV20</cell><cell>54.75</cell><cell>53.02</cell><cell>61.02</cell><cell>67.98</cell></row><row><cell>DGTL</cell><cell>f bn f bnf</cell><cell>ours</cell><cell>54.66 57.34</cell><cell>52.72 55.13</cell><cell>59.21 63.11</cell><cell>66.27 69.20</cell></row><row><cell cols="2">HcTri [8]</cell><cell>TMM20</cell><cell>61.68</cell><cell>57.51</cell><cell>63.41</cell><cell>68.17</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III</head><label>III</label><figDesc></figDesc><table><row><cell cols="5">THE EFFECTS OF DIFFERENT POOLING METHODS IN BASELINE NETWORK</cell></row><row><cell cols="5">(THE FINE GRANULARITY BRANCH). RE-IDENTIFICATION RATES OF</cell></row><row><cell></cell><cell cols="3">RANK1 AND MAP (%).</cell><cell></cell></row><row><cell></cell><cell>RegDB</cell><cell></cell><cell cols="2">SYSU-MM01</cell></row><row><cell>Fine</cell><cell>rank1</cell><cell>mAP</cell><cell>rank1</cell><cell>mAP</cell></row><row><cell>Avg</cell><cell>70.63</cell><cell>65.13</cell><cell>58.66</cell><cell>54.57</cell></row><row><cell>Max</cell><cell>80.49</cell><cell>71.23</cell><cell>49.04</cell><cell>47.35</cell></row><row><cell>GeM</cell><cell>75.39</cell><cell>67.72</cell><cell>55.85</cell><cell>53.25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV THE</head><label>IV</label><figDesc>EFFECTS OF DIFFERENT POOLING METHODS IN THE COARSE GRANULARITY BRANCH. THE POOLING METHOD IN FINE GRANULARITY BRANCH IS MAX FOR REGDB DATASET AND AVG FOR SYSU-MM01 DATASET. RE-IDENTIFICATION RATES OF RANK1 AND MAP (%).</figDesc><table><row><cell></cell><cell></cell><cell>RegDB</cell><cell></cell><cell></cell></row><row><cell>Fine</cell><cell>Coarse</cell><cell>features</cell><cell>rank1</cell><cell>mAP</cell></row><row><cell></cell><cell>Avg</cell><cell>f bn f bnf</cell><cell>83.59 83.30</cell><cell>72.08 72.13</cell></row><row><cell>Max</cell><cell>Max</cell><cell>f bn f bnf</cell><cell>83.64 84.27</cell><cell>74.53 75.18</cell></row><row><cell></cell><cell>GeM</cell><cell>f bn f bnf</cell><cell>77.82 77.28</cell><cell>68.59 68.17</cell></row><row><cell></cell><cell></cell><cell>SYSU-MM01</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Avg</cell><cell>f bn f bnf</cell><cell>56.59 56.74</cell><cell>54.02 54.23</cell></row><row><cell>Avg</cell><cell>Max</cell><cell>f bn f bnf</cell><cell>55.35 59.22</cell><cell>52.44 54.93</cell></row><row><cell></cell><cell>GeM</cell><cell>f bn f bnf</cell><cell>56.22 57.67</cell><cell>53.98 55.14</cell></row><row><cell cols="5">always with large gaps (e.g. Avg vs. Max: 70.63 vs. 80.49,</cell></row><row><cell cols="2">rank1 on regdb dataset)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V THE</head><label>V</label><figDesc>ABLATION STUDY OF TRIPLET LOSSES ORGANIZING IN THE FINE AND COARSE GRANULARITY BRANCHES, CENTER-BASED TRIPLET LOSS (L c tri ) AND SAMPLE-BASED TRIPLET LOSS (L f tri ). RE-IDENTIFICATION RATES OF RANK1 AND MAP (%).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">RegDB</cell><cell cols="2">SYSU-MM01</cell></row><row><cell>index</cell><cell>Fine</cell><cell>Coarse</cell><cell>features</cell><cell>rank1</cell><cell>mAP</cell><cell>rank1</cell><cell>mAP</cell></row><row><cell>x</cell><cell>L f tri</cell><cell>×</cell><cell>f bn</cell><cell>80.49</cell><cell>71.23</cell><cell>58.66</cell><cell>54.57</cell></row><row><cell>y z</cell><cell>L c tri L f tri + L c tri</cell><cell>× ×</cell><cell>f bn f bn</cell><cell>80.58 83.74</cell><cell>65.57 74.81</cell><cell>53.22 57.95</cell><cell>50.34 55.48</cell></row><row><cell>f2f</cell><cell>L f tri</cell><cell>L f tri</cell><cell>f bn f bnf</cell><cell>80.78 78.16</cell><cell>72.09 71.36</cell><cell>53.75 57.51</cell><cell>50.45 54.70</cell></row><row><cell>c2c</cell><cell>L c tri</cell><cell>L c tri</cell><cell>f bn f bnf</cell><cell>81.70 82.33</cell><cell>66.65 66.68</cell><cell>54.72 57.45</cell><cell>50.64 53.44</cell></row><row><cell>c2f</cell><cell>L c tri</cell><cell>L f tri</cell><cell>f bn f bnf</cell><cell>80.53 78.74</cell><cell>72.90 72.58</cell><cell>53.88 57.53</cell><cell>51.16 55.82</cell></row><row><cell>f2c</cell><cell>L f tri</cell><cell>L c tri</cell><cell>f bn f bnf</cell><cell>83.64 84.27</cell><cell>74.53 75.18</cell><cell>55.96 59.32</cell><cell>53.85 56.48</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI THE</head><label>VI</label><figDesc>ABLATION STUDY OF BNNECK [9] IN THE FINE AND COARSE GRANULARITY BRANCHES. WHETHER APPLYING THE BNNECK OR NOT, I.E., WHERE THE TRIPLET LOSS SHOULD BE ADOPTED, FOR THE POOL FEATURES (fp,f pf ) OR THE BATCH NORMALIZATION FEATURES (f b n, f bnf )? RE-IDENTIFICATION RATES OF RANK1 AND MAP (%).</figDesc><table><row><cell>Fine</cell><cell>Coarse</cell><cell cols="2">RegDB</cell><cell cols="2">SYSU-MM01</cell></row><row><cell>L f tri</cell><cell>Lc tri</cell><cell>rank1</cell><cell>mAP</cell><cell>rank1</cell><cell>mAP</cell></row><row><cell>fp</cell><cell>×</cell><cell>80.49</cell><cell>71.23</cell><cell>58.66</cell><cell>54.57</cell></row><row><cell>f bn</cell><cell>×</cell><cell>77.43</cell><cell>70.53</cell><cell>49.78</cell><cell>48.99</cell></row><row><cell>fp</cell><cell>f pf</cell><cell>75.97</cell><cell>66.52</cell><cell>58.37</cell><cell>54.49</cell></row><row><cell>f bn</cell><cell>f bnf</cell><cell>81.17</cell><cell>72.57</cell><cell>54.77</cell><cell>52.42</cell></row><row><cell>fp</cell><cell>f bnf</cell><cell>84.27</cell><cell>75.18</cell><cell>59.32</cell><cell>56.48</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hi-cmd: Hierarchical cross-modality disentanglement for visible-infrared person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning modality-specific representations for visible-infrared person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="579" to="590" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Infrared-visible cross-modal person re-identification with an x modality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4610" to="4617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Class-aware modality mix and center-guided metric learning for visible-thermal person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM, 2020</title>
		<imprint>
			<biblScope unit="page" from="889" to="897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gallery based k-reciprocal-like re-ranking for heavy cross-camera discrepancy in person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="page" from="64" to="75" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enhancing the discriminative feature learning for visible-thermal cross-modality person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">398</biblScope>
			<biblScope unit="page" from="11" to="19" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Parameter sharing exploration and heterocenter triplet loss for visible-thermal person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMM</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A strong baseline and batch normalization neck for deep person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMM</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2597" to="2609" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Person recognition system based on a combination of body images from visible light and thermal cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">605</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fine-tuning cnn image retrieval with no human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radenović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1655" to="1668" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Pose-driven deep convolutional model for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3980" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cross-modality paired-images generation for rgb-infrared person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep multi-patch matching network for visible thermal person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMM</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rgb-ir person reidentification by cross-modality similarity preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="1765" to="1785" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Rgb-infrared crossmodality person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5380" to="5389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cross-modality person re-identification via modality-aware collaborative ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Leng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="9387" to="9399" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bi-directional centerconstrained top-ranking for visible thermal person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIFS</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="407" to="419" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic dual-attentive aggregation learning for visible-infrared person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep learning for person re-identification: A survey and outlook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04193</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visible-infrared person re-identification via homogeneous augmented tri-modal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIFS</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="728" to="739" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
