<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-supervised Transfer Learning for Image Rain Removal</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-supervised Transfer Learning for Image Rain Removal</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Single image rain removal is a typical inverse problem in computer vision. The deep learning technique has been verified to be effective for this task and achieved state-of-theart performance. However, previous deep learning methods need to pre-collect a large set of image pairs with/without synthesized rain for training, which tends to make the neural network be biased toward learning the specific patterns of the synthesized rain, while be less able to generalize to real test samples whose rain types differ from those in the training data. To this issue, this paper firstly proposes a semi-supervised learning paradigm toward this task. Different from traditional deep learning methods which only use supervised image pairs with/without synthesized rain, we further put real rainy images, without need of their clean ones, into the network training process. This is realized by elaborately formulating the residual between an input rainy image and its expected network output (clear image without rain) as a specific parametrized rain streaks distribution. The network is therefore trained to adapt real unsupervised diverse rain types through transferring from the supervised synthesized rain, and thus both the short-of-training-sample and bias-to-supervised-sample issues can be evidently alleviated. Experiments on synthetic and real data verify the superiority of our model compared to the state-of-the-arts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Rain streaks and rain drops often occlude or blur the key information of the images captured outdoors. Thus the rain removal task for an image or a video is useful and necessary, which can be served as an important pre-processing step for outdoor visual system. An effective rain removal technique can often help an image/video better deliver more accurate detection or recognition results <ref type="bibr" target="#b16">[17]</ref>.</p><p>Current rain removal tasks can be mainly divided into two categories: video rain removal (VRR) and single image rain removal (SIRR). Compared to VRR, which could * Deyu Meng is the corresponding author. utilize the temporal correlation among consecutive frames, SIRR is generally much more difficult and challenging without the aid of much prior knowledge capable of being extracted from a single image. Since being firstly proposed by Kang et al. <ref type="bibr" target="#b16">[17]</ref>, the SIRR problem has been attracting much attention. Recently, deep learning methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b7">8]</ref> have been empirically substantiated to achieve state-of-the-art performance for SIRR by training an appropriate, carefully designed network to detect and remove the rain streaks simultaneously.</p><p>Albeit achieving good performance on this task, current deep learning approach still exists some limitations on the methodology. First, for training data, since it is hard to obtain clean/rainy image pairs from real rainy scenarios, previous methods use synthesized data as an alternative, and mainly adopt the strategy of adding the "fake" rain streaks synthesized by the Photoshop software 1 on the clean images. Two samples of such synthesized rainy images are shown in <ref type="figure" target="#fig_0">Figure 1.</ref>(b) and (c) (the corresponding clean image is shown in <ref type="figure" target="#fig_0">Figure 1.(a)</ref>). Albeit being varied by the rain streak direction and density, the synthesized rainy images still cannot include sufficiently wider range of rain streak patterns in real rainy images. For instance, in <ref type="figure" target="#fig_0">Figure 1.(d)</ref>, the rain streaks have multiple directions in a single frame influenced by the wind; in <ref type="figure" target="#fig_0">Figure 1</ref>.(e), the rain streaks have multi-layers because of their different distances to the camera; in <ref type="figure" target="#fig_0">Figure 1</ref>.(f), the rain streaks produce the effect of aggregation which is similar to fog or mist. Therefore there exists obvious bias between synthetic training data and real testing data in this task, naturally leading to an issue that the network trained on the synthetic training data possibly not capable of being finely generalized to the real test data.</p><p>Meanwhile, one of the main problems for deep learning methods lies on the preliminary conditions that they generally need sufficiently large number of supervised samples (ideal cases are natural images with/without real rain for our task), which are generally time-consuming and cumbersome to collect, in order to train a derain network. However, one generally can easily attain large amount of practical unsupervised samples, i.e., real rainy images, while without their corresponding clean ones. How to rationally feed these cheap samples into the network training is not only meaningful and necessary for the investigated task, but also possibly inevitable in the next generation of deep learning to fully prompt its capability on unsupervised data for general image restoration tasks.</p><p>Due to the inconsistence in the distribution of training data and test data, this task can be naturally viewed as a typical domain adaption problem. How to transfer from learning the synthesized rain patterns (training, supervised) to learning real rain patterns (testing, unsupervised) is crucial. To alleviate the aforementioned issue of previous supervised deep learning methods for the SIRR task, instead of from the perspective of manually collecting more appropriate supervised dataset (real rainy images and their corresponding clean ones) to better suit this task, we propose a novel semi-supervised method attempting to effectively feed unsupervised real rainy images into the network training as well, ultimately expecting to transfer from synthesized rain domain to real rain domain. Different from previous supervised deep learning methods by only using synthesized image pairs as network inputs, our method is capable of fully utilizing unsupervised practical rainy images during training in a mathematically sound manner. Specifically, our model allows both the supervised synthetic data and unsupervised real data being fed into the network simultaneously, and the network parameters can be optimized by the combination of least square residuals (for supervised samples) of network output images of supervised inputs and their ground truth labels, and negative log-likelihood (NLL) losses of a specific parametrized rain distribution (for unsupervised samples) measured by the difference of network output images of unsupervised inputs and their original rainy ones. In this manner, both supervised synthetic and unsupervised real samples can be rationally employed in our method for network training.</p><p>In summary, the main contributions of the proposed method are:</p><p>• To our knowledge, this is the first work that takes notice of domain adaption issue for SIRR task. We are the first to propose a semi-supervised transfer learning framework for this task. Different from the previous deep learning SIRR methods, our model can fully take use of the unsupervised real rainy images, which can be easily collected in practice, without need of the corresponding clean ones. Such unsupervised samples not only help evidently reduce the time and labor costs of pre-collecting image pairs with/without real rain for network parameters updating, but also alleviate the over-fitting issue of the deep network on limited rain types covered by only supervised training samples through compensating those unsupervised ones containing more general and practical rain characteristics. • We provide a general methodology for simultaneously utilizing supervised and unsupervised knowledge for image restoration tasks. For supervised one, the traditional least square loss between network output images and their clean ones can be directly employed. For the unsupervised one, we can rationally formulate the residual between the expected output clean images and their original noisy ones through a likelihood term imposed on a parameterized distribution designed based on the domain understanding for residuals (e.g., rain in our study). • We design an Expectation Maximization algorithm together with a gradient descent strategy to solve the proposed model. The rain distribution parameters and network parameters can be optimized by sequence in each epoch. Experiments implemented on synthesized rainy images and especially real ones show that our model is capable of transferring from learning synthesized to real rain patterns, thus substantiating the superiority of the proposed method compared to the state-of-the-arts. The rest of this paper is organized as follows. In Section 2 we detailedly review the previous derain methods along a history line. In Section 3 we present our model as well as the optimization algorithms. We show the experimental results in Section 4 and make conclusion in Section 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Single image rain removal methods</head><p>The problem of SIRR was firstly proposed by Kang et al. <ref type="bibr" target="#b16">[17]</ref>. They detected the rain from the high frequency part of an image based on morphological component analysis and dictionary learning. Chen et al.'s <ref type="bibr" target="#b4">[5]</ref> also operated on the high frequency part of the rainy image but they employed a hybrid feature set, including histogram of oriented gradients, depth of field, and Eigen color, in order to distinguish the rain portions from the image and enhance the texture/edge information. After that, Luo et al. <ref type="bibr" target="#b25">[26]</ref> introduced screen blend model and used discriminative sparse coding for rain layer separation, and the model is solved by greedy pursuit algorithm. Li et al.'s <ref type="bibr" target="#b23">[24]</ref> incorporated patch-based Gaussian mixture model to deliver the prior information of image background and rain layer, and trained the model parameters under pre-collected clean and rainy images. Similarly, Zhang et al. <ref type="bibr" target="#b29">[30]</ref> learned a set of generic sparsitybased and low-rank representation-based convolutional filters to represent background and rain streaks, respectively. Gu et al. <ref type="bibr" target="#b13">[14]</ref> combined analysis sparse representation to represent image large-scale structures and synthesis sparse representation to represent image fine-scale textures, including the directional prior and the non-negativeness prior in their JCAS model. More recently, Zhu et al. <ref type="bibr" target="#b32">[33]</ref> proposed a joint optimization process that alternates between removing rain-streak details from background layer and removing non-streak details from rain layer. Their model is aided by the rain priors, which are narrow directions and self-similarity of rain patches, and the background prior, which is centralized sparse representation. Chang et al. <ref type="bibr" target="#b3">[4]</ref> transformed a rainy image into a domain where the line pattern appearance has extremely distinct low-rank structure, and proposed a model with compositional directional total variational and low-rank priors, to deal with the rain streaks as line pattern noise and camera noise at the same time.</p><p>While these model-based methods are mathematically sound, they mostly suffer from slow speed when testing because they need to solve an optimization problem. Deep learning has an advantage on test speed and has been substantiated to be effective in many computer vision tasks <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b14">15]</ref>, so does in SIRR. Fu et al. firstly introduced deep learning technique for this task in <ref type="bibr" target="#b8">[9]</ref>. They trained a convolutional neural network (CNN) with three hidden layers on the high frequency domain of the image. Later, they further ameliorated the CNN by introducing deeper hidden layers, batch normalization and negative residual mapping structure, and achieved better effect <ref type="bibr" target="#b9">[10]</ref>. To better deal with the scenario of heavy rain images (where individual streaks are hardly seen, and thus visually similar to mist or fog). Yang et al. <ref type="bibr" target="#b28">[29]</ref> exploited a contextualized dilated network with a binary map. In their model, a continuous process of rain streak detection, estimation and removal are predicted in a sequential order. Zhang et al. <ref type="bibr" target="#b31">[32]</ref> applied the mechanism of GAN and introduced a perceptual loss function for the consideration of rain removal problem. Afterwards, they developed a density aware multi-stream dense network for joint rain density estimation and de-raining <ref type="bibr" target="#b30">[31]</ref>. In summary, these methods learn from synthesized rain data and test their learned network in real scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Video rain removal methods</head><p>For literature comprehensiveness, we simply list several representative state-of-the-art video rain removal methods.</p><p>Since the extra inter-frame information is extremely helpful, these methods showed relatively better reconstruction effect than SIRR methods. Early video derain methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b17">18]</ref> designed many useful techniques to detect potential rain streaks based on their physical characteristics and removed these detected rain by image restoration algorithms. In recently years, low-rankness <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27]</ref>, total variation <ref type="bibr" target="#b15">[16]</ref>, stochastic distribution priors <ref type="bibr" target="#b27">[28]</ref>, convolutional sparse coding <ref type="bibr" target="#b21">[22]</ref>, neural networks <ref type="bibr" target="#b24">[25]</ref> have been applied to the task and achieved satisfying results.</p><p>Since the SIRR problem is more difficult in real world with less information provided other than a rainy image, to design an effective SIRR regime is also more challenging beyond VRR ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Semi-supervised model for SIRR</head><p>We show the framework of our model which includes the training data (both supervised and unsupervised samples) and the network loss in <ref type="figure">Figure 2</ref>. As introduced aforementioned, our model is capable of feeding not only supervised synthesized rainy images but also unsupervised real rainy images into the network training process, in order to transfer from learning synthesized rain patterns to learning real rain patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model formulation</head><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>.(d,e,f), the real rain usually shows relatively more complex patterns and representations compared to synthesized rain. However, due to the technical defects, these data's "labels" (i.e., the corresponding clean images) are generally unavailable. Although we can hardly exactly extract the rain layer, as well as the clean background, from a real rainy image, we instead can design a parametrized distribution to finely approximate its stochastic configurations. Since the rain generally contains multi-modal structures due to their occurrence on positions with different distances to the cameras, we can finely approximately express the rain as a Gaussian mixture model (GMM). That is,</p><formula xml:id="formula_0">R ∼ K k=1 π k N (R|µ k , Σ k ),<label>(1)</label></formula><p>where π k , µ k , Σ k denote the mixture coefficients, Gaussian distribution means and variances. Mixture models can be universal approximations to any continuous functions if the parameters are learned appropriately, and thus it is suitable to be utilized to describe the rain streaks to-be-extracted from the input rainy image. Thus the negative log likelihood function imposed on these unsupervised samples can be written as: <ref type="figure">Figure 2</ref>: The flow chart of the proposed method. Those surrounded with concrete yellow square frames are the given inputs for network training. The arrows represent the forward process of network training. The upper panel shows the supervised learning term, which is to minimize the difference of network output and the corresponding clean image using a least square loss. The lower panel shows the unsupervised learning term, which is to minimize an MAP model with a GMM likelihood term imposed on rain distribution and a TV regularization term on background. The network structure and parameters are shared in both parts. A K-L regularizer between the distribution of two types of residuals (extracted rain) is further added to control the degree of freedom.</p><formula xml:id="formula_1">L unsupervised (R; Π, Σ) = − N n=1 log K k=1 π k N (Rn|0, Σ k ),<label>(2)</label></formula><p>where Π = π 1 , ...π K , Σ = Σ 1 , ...Σ K , K is the number of mixture components, and N is the number of samples. Note that the means of Gaussian distributions are manually set to be zero, and this doesn't affect the results in our experiments. By utilizing the above encoding manner, we can also construct an objective function for unsupervised rainy images, which can be further used to fine-tune the network parameters through back-propagating its gradients to the network layers.</p><p>Meanwhile, we follow the network structure and negative residual mapping skill of DerainNet <ref type="bibr" target="#b9">[10]</ref> (a deep convolutional neural network) to formulate the loss function on supervised samples. The network which is denoted by f w (·) (here w represents the network parameters) is supposed to remove the rain streaks of input image and output a rain-free one. The classical loss function of CNN is to minimize the least square loss between the expected derain output f w (x i ) and the ground truth label y i , as shown in the upper panel of <ref type="figure">Figure 2</ref>. That is, the loss function imposed on the supervised samples is with the following least square form:</p><formula xml:id="formula_2">L supervised = N i=1 ||f w (x i ) − y i || 2 F ,<label>(3)</label></formula><p>where x i , i = 1, ...N represents the samples of the synthesized rainy image. Moreover, since GMM can be adapted to any continuous distribution, in order to let it better fit the real rain samples, we add a constraint that the discrepancy between synthesized rain data domain and real rain data domain is not too far by minimizing a Kullback−Leibler divergence between a Gaussian G syn learned from the synthesized rain and the aforementioned mixture of Gaussians GM M real learned from the real rain during training, with a small controlling parameter, as shown in the middle-right of <ref type="figure">Figure 2</ref>. This is to indicate that our model is expecting to transfer from synthesized rain to real rain, other than to arbitrary domains. Since this KL divergence is not analytically tractable, we use the minimum of KL divergence between G syn and each component of GM M real as an empirical and simple substitute, to ensure that at least one component of GMM learned from the real samples is similar to rain. That is,</p><formula xml:id="formula_3">DKL(Gsyn||GM M real ) min k DKL(Gsyn||GM M k real ),<label>(4)</label></formula><p>where GM M k real indicates the kth component of GM M real .</p><p>To further remove the potential remained rain streaks in the output image, we add a Total Variation regularizer term to slightly smooth the image. Note that together with the aforementioned likelihood term on rain, a complete MAP model (likelihood + regularizer) is formulated on the to-beestimated network outputs of the unsupervised real rain images. It facilitates a right direction for gradient descent to network training on these unsupervised data even without specific explicit guidance of corresponding clean images.</p><p>By combining Eq.(2), (3), (4) and TV term, the entire objective function to train the network is formulated as:</p><formula xml:id="formula_4">L(w, Π, Σ) = N 1 i=1 ||fw(xi) − yi|| 2 F + α N 2 n=1 ||fw(x)n||T V +βDKL(Gx||GM Mx)−λ N 2 n=1 log K k=1 π k N (xn −fw(x)n|0, Σ k ),<label>(5)</label></formula><p>where x i , y i , i = 1, ...N 1 represent corresponding rainy input and ground truth label sample pairs of the synthesized supervised data, andx n , n = 1, ...N 2 represent the rainy input of the real unsupervised data without ground truth labels. Through the last term of Eq. (5), the unsupervised data can be fed into the same network with which imposed on the supervised data, and the termx n − f w (x) n is the supposed rain extracted from the input rainy image, which is equivalent to R n as defined in Eq. (2). α, β and λ are the trade-off parameters. Note that when α, β and λ equal to 0, our model degenerates to the conventional supervised deep learning model <ref type="bibr" target="#b9">[10]</ref>. By using such objective setting, the network can be trained not only by the well annotated supervised data, but also purely unsupervised inputs by fully encoding the prior information underlying rain streak distributions. As compared with the traditional deep learning techniques implemented on only supervised samples, the better generalization effect of the network is expected due to the fact that it facilitates a rational transferring effect from the supervised samples to unsupervised types of rain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The EM algorithm</head><p>Since the loss function in Eq. (5) is intractable, we use the Expectation Maximization algorithm <ref type="bibr" target="#b6">[7]</ref> to iteratively solve the model. In E step, the posterior distribution which represents the responsibility of certain mixture component is calculated. In M step, the mixture distribution and the convolutional neural network parameters are updated.. </p><formula xml:id="formula_5">γ nk = π k N (x n − f w (x) n |0, Σ k ) k π k N (x n − f w (x) n |0, Σ k ) .<label>(6)</label></formula><p>M step : After the E step, the loss function in Eq. <ref type="formula" target="#formula_4">(5)</ref> is unfolded into a differential one with respect to GMM parameters, shown as:</p><formula xml:id="formula_6">min w,Π,Σ λ N 2 n=1 K k=1 γ nk ( (xn −fw(x)n) 2 2Σ k + 1 2 log |Σ k |−log π k ) + N 1 i=1 ||fw(xi)−yi|| 2 F +α N 2 n=1 ||fw(xn)||T V +βDKL(Gx||GM Mx).<label>(7)</label></formula><p>The closed-form solution of mixture coefficients and Gaussian covariance parameters are <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_7">N k = N n=1 γ nk , π k = N k N ,<label>(8)</label></formula><formula xml:id="formula_8">Σ k = 1 N k N n=1 γ nk (x n − f (x) n ) 2 , k = 1, ...K. (9)</formula><p>Then we can employ the gradient methods to optimize the objective function as defined in Eq. <ref type="bibr" target="#b6">(7)</ref> and the gradient so calculated can thus be easily back propagated to the network to gradually ameliorate its parameters w. We readily utilize Adam <ref type="bibr" target="#b18">[19]</ref>, the off-the-shelf first order gradient optimization algorithm, for network parameter training on the objective function (7) imposed on both synthesized supervised and real unsupervised training samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Discussions on domain transfer learning</head><p>The main difference of the proposed method from the other supervised deep learning SIRR methods is the involvement of the real world rainy images whose ground truth rain-free images or ground-truth rain images) are unavailable during training. One main motivation for this investigation is that the manually synthesized rain shapes usually differ from real ones collected in practice. According to several SIRR methods in the framework of deep learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31]</ref>, clean images are used to synthesize rainy images by Photoshop software. Although each clean image is supposed to synthesize several different type of rainy image, as shown in upper panel of <ref type="figure" target="#fig_0">Figure 1</ref>, the difference of scale, illuminance and distance to the camera of the real rain streaks and usually accompanied fog or mist visual effect are hardly sufficiently considered, thus yielding nonnegligible gap between the synthesized rainy images for training and the real rainy images for testing.</p><p>In our method, the involvement of the unsupervised real rainy data alleviates this problem. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, we use the same synthesized rainy data with <ref type="bibr" target="#b9">[10]</ref> as the supervised training data. To empirically show the domain transfer capability and verify the superiority of our model on this point, we use a different way to synthesize rainy images introduced in <ref type="bibr" target="#b27">[28]</ref>, and separate them as unsupervised input set and validation set. Therefore the supervised training rain and validation rain lie in distinct domains. We found that our model shows better capability to overcome the gap and transfer from the training data domain to validation data domain. Although our semi-supervised model not extremely finely fit the effect of the training data when the unsupervised term in our loss function Eq. (5) plays more important role (as shown in Column 1 of <ref type="figure" target="#fig_2">Figure 3</ref>, green and blue lines are our semi-supervised model, with different unsupervised term parameters), Column 2 of <ref type="figure" target="#fig_2">Figure 3</ref> reflects that our model has better effect on the target domain (solid line represents supervised data domain while dotted line represents target domain). Moreover, with the training dataset booming, the baseline supervised CNN (red line in <ref type="figure" target="#fig_2">Figure 3</ref>) tends more and more to achieve specific patterns of the training data (i.e., the performance of training data improve), thus less being generalized to the validation data (i.e., the performance of testing data does not improve correspondingly, even slightly worsen) if they lie in separate domain, as shown in Column 3 of <ref type="figure" target="#fig_2">Figure 3</ref>. However, the involvement of the unsupervised term in our loss function can effectively alleviate this issues, as shown in Column 4 and 5 of <ref type="figure" target="#fig_2">Figure 3</ref>, which is critical in real rain removal task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this section, we evaluate our methods both on synthesized rainy data and real world rainy data. The compared methods include the discriminative sparse coding based method (DSC) <ref type="bibr" target="#b25">[26]</ref>, layer priors based method (LP) <ref type="bibr" target="#b23">[24]</ref>, CNN method <ref type="bibr" target="#b9">[10]</ref>, joint bi-layer optimization (JBO) <ref type="bibr" target="#b32">[33]</ref>, multi-task deep learning method (JORDER) <ref type="bibr" target="#b28">[29]</ref> and multistream dense net (DID-MDN) <ref type="bibr" target="#b30">[31]</ref>. These methods include conventional unsupervised model-driven methods and more recent supervised data-driven deep learning methods. Our method to some extent can be viewed as an intrinsic combination of both methodologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation details</head><p>For supervised training data, we use one million 64×64 synthesized rainy/clean image patch pairs which are the same with the baseline CNN method <ref type="bibr" target="#b9">[10]</ref>. For unsupervised training data, we collect the real world rainy images from the dataset provided by <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b31">32]</ref> and Google image search. We randomly cropped one million 64×64 image patches from these images to constitute the unsupervised samples. Batch size is 20. The initial learning rate is 10 −3 , decaying by multiplying 0.1 after every 5 epochs. We train 15 epochs in total. The training is implemented using Tensorflow <ref type="bibr" target="#b0">[1]</ref>.</p><p>We design the number of GMM components as 3. For the trade-off parameter λ, we simply set it as 0.5 throughout all our experiments. The parameter α which controls the TV smoothing term is set as a small value 10 −5 . The parameter β which controls the KL divergence term is set to be 10 −9 . The network structures and related parameters are directly inherited from the baseline method <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiments on synthetic images</head><p>In this subsection, we evaluate the rain removal effect of our method with synthetic data by both visual quality and performance metric. We use the skill of <ref type="bibr" target="#b27">[28]</ref> to synthesize the rainy image as test data. Considering the complexity and multiformity of the rain streaks, we compare our methods with others under two different scenarios: sparse rain streaks and dense rain streaks. In each scenario we use ten test images. <ref type="figure" target="#fig_3">Figure 4</ref> shows an example of synthetic data with sparse rain streaks. The added rain streaks are sparse but with multiple lengths and layers, in consideration of the different distance to the camera. As shown in <ref type="figure" target="#fig_3">Figure 4</ref>, the DSC method <ref type="bibr" target="#b25">[26]</ref> and JBO method <ref type="bibr" target="#b32">[33]</ref> fail to remove the main component of the rain streaks. The LP method <ref type="bibr" target="#b23">[24]</ref> tends to blur the visual effect of the image and over-smooth the texture and edge information. The two deep learning methods CNN <ref type="bibr" target="#b9">[10]</ref> and JORDER <ref type="bibr" target="#b28">[29]</ref> have better rain removal effects, but rain streaks sill clearly exist in their results. Comparatively, our method could better remove the sparse rain streaks and keep the background information.</p><p>We also design the experiments with dense rain streaks scenario. In real world, the dense rain streaks have the effect of aggregation, blurring the image similar to fog or mist when the rain is heavy. In <ref type="figure">Figure 5</ref>, the added rain is heavy, with not only the long rain streaks, but also the brought blurring effect damaging the image visual quality. As shown in <ref type="figure">Figure 5</ref>, the results of DSC <ref type="bibr" target="#b25">[26]</ref>, JORDER <ref type="bibr" target="#b28">[29]</ref> and JBO <ref type="bibr" target="#b32">[33]</ref> still have obvious rain streaks, while LP <ref type="bibr" target="#b23">[24]</ref> still oversmoothes the image. Compared with the baseline CNN method <ref type="bibr" target="#b9">[10]</ref>, our method has better restoration results.</p><p>Since the ground truth is known for the synthetic experiments, we use the most extensive performance metric Peak Signal-to-Noise Ratio (PSNR) for a quantitative evaluation. As is evident in <ref type="table" target="#tab_0">Table 1</ref>, our method attains the best PSNR in both two groups of data with different scenarios, in agree- (e) CNN <ref type="bibr" target="#b9">[10]</ref> (f) JORDER <ref type="bibr" target="#b28">[29]</ref> (g) JBO <ref type="bibr" target="#b32">[33]</ref> (h) Ours </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experiments on real images</head><p>The most direct way to evaluate a SIRR method is to see its visual effect of restoration results on the real world rainy images. We use the testing data selected from the Google search. To better represent the diversity of the real rain scenarios, we intentionally select images with different types of rain streaks as shown in <ref type="figure">Figure 6</ref>.</p><p>To confirm the necessity of investigating transfer learning for this task, we list the complete synthesized rain types <ref type="bibr" target="#b8">[9]</ref> in our supervised training data in <ref type="figure">Figure 7</ref>. The bias of rain between <ref type="figure">Figures 6 and 7</ref> is obvious and the transfer ability of our model can thus be substantiated. The visual (a) Input (b) Ground truth (c) DSC <ref type="bibr" target="#b25">[26]</ref> (d) LP <ref type="bibr" target="#b23">[24]</ref> (e) CNN <ref type="bibr" target="#b9">[10]</ref> (f) JORDER <ref type="bibr" target="#b28">[29]</ref> (g) JBO <ref type="bibr" target="#b32">[33]</ref> (h) Ours <ref type="figure">Figure 5</ref>: Synthesized rain removal results under the dense rain streaks scenario.</p><p>effect of derained images verify that our method can remove more rain streaks and better keep the visual quality. Compared to other competing methods, our method can remove more amount of the rain streaks while still better keep the structure of image undamaged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have attempted to solve the SIRR problem in a semi-supervised transfer learning manner. We train a CNN on both synthesized supervised and real unsupervised rainy images. In this manner, our method especially alleviates the hard-to-collect-trainingsample and overfitting-to-training-sample issues existed in conventional deep learning methods designed for this task. ] <ref type="figure">Figure 6</ref>: Real rain streaks removal experiments under different scenarios. From left to right are input image, results of DSC <ref type="bibr" target="#b25">[26]</ref>, LP <ref type="bibr" target="#b23">[24]</ref>, CNN <ref type="bibr" target="#b9">[10]</ref>, DID-MDN <ref type="bibr" target="#b30">[31]</ref> and ours. Demarcated areas in each image are amplified at a 3 time larger scale. <ref type="figure">Figure 7</ref>: List of fourteen synthesized rain data types in our supervised data. The left image is the original one without rain streaks, and the right 14 ones are those superimposed with different rain types. The rain details can be more evidently observed by zooming in the images on a computer screen.</p><p>The experiments implemented on synthesized and real images substantiate the effectiveness of the proposed method.</p><p>We admit that our model is still not almighty for all rainy image which could be extremely complicated to handle. The involvement of more elaborate priors on rain and background layers in training the network could be the future direction to further improve the performance for this task. Also this semi-supervised transfer learning methodology could be considered into other inverse problems as well. We wish to apply the human prior knowledge into the learning process of neural network framework, more sufficiently realizing the combination of data-based and model-based methods. The ultimate goal is to take advantage of both supervised data-based deep learning methods, which could shorten the testing time to fulfill the online requirement, and model-based method, to put the network training into a more explainable direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The comparison of the synthesized rain and real rain. (a) is a clean image; (b), (c) are two synthesized rainy image samples. (d), (e), (f) are real world rainy images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>E step : Introduce a latent variable z nk where z nk ∈ {0, 1} and K k=1 z nk = 1, indicating the assignment of noise term (x n −f w (x) n ) to a certain component of the mixture model. According to the Bayes' theorem, the posterior responsibility of component k for generating the noise is given by:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The PSNR trend graph of supervised training data and validation data during training process. In all subgraphs, the solid line represents trend of supervised training data and the dotted line represents the trend of validation data. Note that they in distinct domain because of the different rain-synthesized way. The red, green, blue lines represent the unsupervised term controlling parameter λ in Eq. (5) equals to 0 (equivalent to supervised learning), 0.2 and 1, respectively. The three rows use five hundred, five thousand and ten thousand image patches as the training data from top to bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Synthesized rain removal results under the sparse rain streaks scenario. ment with the visual effect in Figures 4 and 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Mean PSNR comparison of two groups of data on synthesized rainy images. Dataset Input DSC[26] LP[24] JORDER[29] CNN[10] JBO[33] DID-MDN[31] Ours</figDesc><table><row><cell>Dense 17.95</cell><cell>19.00</cell><cell>19.27</cell><cell>18.75</cell><cell>19.90</cell><cell>18.87</cell><cell>18.60</cell><cell>21.60</cell></row><row><cell>Sparse 24.14</cell><cell>25.05</cell><cell>25.67</cell><cell>24.22</cell><cell>26.88</cell><cell>25.24</cell><cell>25.66</cell><cell>26.98</cell></row><row><cell>(a) Input</cell><cell cols="2">(b) Ground truth</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(c) DSC [26]</cell><cell></cell><cell>(d) LP [24]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.photoshopessentials.com/photo-effects/rain/ arXiv:1807.11078v2 [cs.CV] 12 Apr 2019</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledge</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of rain and snow in frequency space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasa</forename><surname>Barnum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rain or snow detection in image sequences through use of a histogram of orientation of streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérémie</forename><surname>Bossu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Hautière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Tarel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="348" to="367" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transformed lowrank model for line pattern noise removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luxin</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1726" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visual depth guided color image rain streaks removal using sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duan-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Cheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wei</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1430" to="1455" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A generalized lowrank appearance model for spatio-temporally correlated rain streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiou-Ting</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1968" to="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald B</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (methodological)</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Residual-guide network for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huafeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 ACM Multimedia Conference on Multimedia Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1751" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clearing the skies: A deep network architecture for single-image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghao</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2944" to="2956" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Removing rain from single images via a deep detail network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06173</idno>
		<title level="m">Lightweight pyramid networks for image deraining</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A deep tree-structured fusion model for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08632</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection and removal of rain from videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitiz</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 IEEE Computer Society Conference on</title>
		<meeting>the 2004 IEEE Computer Society Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint convolutional analysis and synthesis sparse representation for single image layer separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1717" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel tensor-based video rain streaks removal approach via utilizing discriminatively intrinsic priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai-Xiang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Zhu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi-Le</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Jian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic single-image-based rain streaks removal via image decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wei</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Hsiang</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1742" to="1755" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Video deraining and desnowing using temporal correlation and low-rank matrix completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Hwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae-Young</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Su</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2658" to="2670" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Video rain streak removal by multiscale convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6644" to="6653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recurrent squeeze-and-excitation context aggregation net for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="262" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rain streak removal using layer priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2736" to="2744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">D3r-net: Dynamic routing residue recurrent network for video rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Removing rain from a single image via discriminative sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3397" to="3405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Video desnowing and deraining based on matrix decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4210" to="4219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Should we encode rain streaks in video as deterministic or stochastic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep joint rain detection and removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Convolutional sparse and lowrank coding-based rain streak removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1259" to="1267" />
		</imprint>
	</monogr>
	<note>2017 IEEE Winter Conference on</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Density-aware single image de-raining using a multi-stream dense network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwanath</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05957</idno>
		<title level="m">Image de-raining using a conditional generative adversarial network</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Joint bi-layer optimization for single-image rain streak removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
