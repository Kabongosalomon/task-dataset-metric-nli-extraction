<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting intubation support requirement of patients using Chest X-ray with Deep Representation Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-11-04">November 4, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Aniket</roleName><surname>Maurya</surname></persName>
							<email>theaniketmaurya@gmail.com</email>
						</author>
						<title level="a" type="main">Predicting intubation support requirement of patients using Chest X-ray with Deep Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-04">November 4, 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent developments in medical imaging with Deep Learning presents an evidence of automated diagnosis and prognosis. It can also be a complement to currently available diagnosis methods. Deep Learning can be leveraged for diagnosis, severity prediction, intubation support prediction and many similar tasks. We present prediction of intubation support requirement for patients from the Chest X-ray using Deep representation learning. We release our source code publicly on https://github.com/aniketmaurya/covid-research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>According to <ref type="bibr">[who, 2014]</ref> the world is to see a short of 12.9 million health-care workers by 2035. This problem of shortage of medical experts and medical equipment is more visible in this COVID-19 pandemic <ref type="bibr">[Byatnal, 2020]</ref>  <ref type="bibr" target="#b7">[Ranney et al., 2020]</ref>. COVID-19 test result time has not improved much to help slow the spread of the virus <ref type="bibr" target="#b9">[Stein, 2020]</ref>. There is an urgent need to upgrade the current healthcare system with recent technology advancements <ref type="bibr">[who, 2020]</ref>.</p><p>Approximately 3.2% of COVID-19 patients required intubation and invasive ventilation support in some point of their illness <ref type="bibr" target="#b4">[Meng et al., 2020]</ref>. Sometimes COVID-19 patients crash suddenly and require immediate care for intubation and ventilation <ref type="bibr" target="#b10">[Strickland, 2020]</ref>. Providing intubation can put infection risk to the provider and every person in the room. Some delay may occur during intubation process due to heightened anxiety and rush, this can increase the infection risk.</p><p>In this work, we present prediction of intubation support requirement to patients using Deep Representation Learning. We show that how we can leverage deep learning for taking proactive measures like arranging beds, ventilators, oxygen cylinders. It can give enough time to healthcare provider to be prepared with personal protective equipment properly. We produce Chest X-ray representation of patients and train our learning algorithm to classify whether the person will need intubation support during the duration of his illness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work and Background</head><p>Recently a lot of work has been started in automating the disease prognosis and diagnosis task with Deep Learning. It is mainly due to recent advancements in Deep learning. Convolutional Neural Networks <ref type="bibr" target="#b2">[Lecun et al., 1998</ref>] are now able to reach human level performance in classification and detection tasks <ref type="bibr">[Geirhos et al., 2018]</ref>. <ref type="bibr" target="#b6">[Rajpurkar et al., 2017]</ref>  <ref type="bibr" target="#b1">[Irvin et al., 2019]</ref>  <ref type="bibr" target="#b3">[Lu et al., 2020]</ref> detects chest pneumonia with radiologist level accuracy. Image recognition with deep learning is being used for detecting different type of diseases like diabetic retinopathy and skin cancer <ref type="bibr" target="#b11">[Tymchenko et al., 2020</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Radiologist level Pneumonia Detection using Chest X-ray images</head><p>ChexNet <ref type="bibr" target="#b6">[Rajpurkar et al., 2017]</ref> can predict Pneumonia from CXRs with better F1 score than a group of experienced radiologists. It is a 121-layered deep convolutional neural network trained on ChestX-ray14 dataset <ref type="bibr" target="#b12">[Wang et al., 2017]</ref> for classifying Chest X-ray image as Pneumatic. The dataset is comprised of 112,120 frontal-view Chest X-ray images of 30,805 unique patients. To train this network, images are first resized to 224x224 dimension and normalized by the ImageNet <ref type="bibr" target="#b8">[Russakovsky et al., 2015]</ref> mean and standard deviation. This sets a benchmark for other similar lungs disease diagnosis task. The network is able to achieve state of the art score on total 14 different lungs disease diagnosis task. It achieves F1 score of 0.435 which is higher than achieved by a group of radiologists that is 0.385. <ref type="bibr">[Cohen et al., 2020a]</ref> predicts severity of COVID-19 from the chest x-ray of patients. To train this network, a representation of 1024 dimensional vector is produced from non-covid CXR pre-trained network, 18 outputs (from classification layer), 4 outputs as subset of 18 outputs (lung opacity, pneumonia, infiltration, and consolidation) and Lung opacity output is used for creating final data representation. It further evaluates the input data features for overfitting &amp; bias and analyses the model with Saliency map. Knowing severity can help COVID-19 patients and hospitals so that they can arrange themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">COVID-19 Severity prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>We use covid-chestxray-dataset <ref type="bibr">[Cohen et al., 2020b]</ref>  <ref type="figure" target="#fig_0">(Figure 1)</ref>, an open dataset collected from public and indirect collection from hospitals and physicians. The dataset is available on GitHub. It has a total of 535 AP and PA view of X-ray images in PNG format, which is a lossless image format. The ratio of COVID-19 positive and negative is 63.9% and 36%, where total positive labels are 342 and non-positives are 193. The metadata of this dataset contains labels of 25 lungs disease, shown in <ref type="table" target="#tab_0">Table 1</ref>. To avoid issues with float round off the image pixels are normalized to be in range of <ref type="bibr">[-1024,1024]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Diagnosing COVID-19 using Deep Representation Learning of CXRs</head><p>Convolutional Neural Networks once trained on a huge dataset are frequently used for training on new task using transfer-learning <ref type="bibr" target="#b10">[Tan et al., 2018]</ref>, a method where weights of neural networks are initialised from the weights of pre-trained network. Deep Neural Networks learn the representation of the dataset and the data representation can be used for other tasks as well <ref type="bibr">[Huang et al., 2016]</ref>. TorchXRayVision <ref type="bibr">[Cohen et al., 2020c]</ref>, an open-source library for Chest X-ray datasets and models is used for ease of experiment. We use the <ref type="bibr">DenseNet-121 [Huang et al., 2018]</ref> from TorchXRayVision library which is pre-trained on non-covid to produce 1024 dimensional vector representation of CXRs. The pre-trained DenseNet-121 model has been trained on large amount of chest x-ray dataset for different chest abnormality classification. We use this model for creating representation of COVID-19 CXR image data. We remove the last layer of the network, i.e. the classification layer, and extract the embedding from the last convolution layer. The obtained features are of dimension 7x7x1024, we applied 2D average pooling to convert it into 1x1x1024 dimension. We use this embedding to train k-nearest neighbors classification algorithm (KNN) with scikit-learn Python library <ref type="bibr" target="#b5">[Pedregosa et al., 2011]</ref>, where k is the number of neighbors. We split the dataset into train and test using random sampling. Our train data consisted of 428 images and test data consisted of 107 images.</p><p>We train the KNN model with K=8 and took euclidean distance as distance metric d = (X 1 âˆ’ X 2 ) 2 . We get 73% precision and 83% recall. We plot confusion matrix of our classification outputs in <ref type="figure" target="#fig_1">Figure 2</ref>. <ref type="bibr">[Cohen et al., 2020b]</ref> intubated attribute represents whether the patient was intubated at any point during his illness. Given a CXR, we predict whether the patient will need intubation, <ref type="figure" target="#fig_2">Figure  3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Predicting intubation requirement of patients</head><p>For this task we used AP and PA view of Chest X-ray of COVID and other Chest diseases, total of 25 different pathology, <ref type="table" target="#tab_0">Table 1</ref>. We produce our feature representation similar to section 4.1 and labels are 1 and 0 where 1 is intubation was required for the patient and 0 means intubation was not required.</p><p>We randomly split dataset into train and test set. Our training set comprised of 75% of the total data. Train dataset length is 119 and test dataset length is 40. We experiment with number of neighbors (k) from 2 to 14 inclusively. We find that k=5 gives the best precision and recall. After training, we plot the confusion matrix of the test result as in <ref type="figure" target="#fig_2">Figure 3</ref> 20 intubated and 10 non-intubated patients are classified correctly as intubated and non-intubated respectively while 6 intubated and 4 non-intubated patients are classified incorrectly. We calculate 0.84 (95% CI 0.62, 0.86) AUC on the test set, <ref type="figure" target="#fig_3">Figure 4</ref>. We use bootstrap method to create 95% CI with 10,000  bootstrap samples with replacement from the test dataset. We observe 0.84 (95% CI 0.615, 0.863) ROC-AUC for our KNN classifier. This shows how we can use representations when dataset is limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We need to leverage Deep learning methods to automate our healthcare system wherever possible. Deep learning methods can assist in better resource management. X-rays are economical to CT scan and is available most of the places. It can be used to get an instant prognosis which can help in deciding quarantine and triaging. Severity prediction can be used to check if the current resources can support the patient status. Intubation support prediction can help hospital in managing the bed, ventilator and oxygen cylinders in advance.</p><p>However, due to COVID-19 there has been a lot of research that has come up with different solution and suggestion for disease diagnosis. But before deploying any machine automated solution we must need to test it thoroughly for any kind of bias. [Huang et al., 2018] Huang, G., Liu, Z., van der Maaten, L., and Weinberger, K. Q. (2018). Densely connected convolutional networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>1 means COVID-19 +Ve and 0 means -Ve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Confusion matrix of COVID-19 classification from CXR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Confusion Matrix of patient intubation classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Intubation classification ROC curve. 95% Confidence interval for score 0.615, 0.863 [Byatnal, 2020] Byatnal, A. (2020). Shortage of health care workers plagues india's fight against covid-19. [Cohen et al., 2020a] Cohen, J. P., Dao, L., Morrison, P., Roth, K., Bengio, Y., Shen, B., Abbasi, A., Hoshmand-Kochi, M., Ghassemi, M., Li, H., and Duong, T. Q. (2020a). Predicting covid-19 pneumonia severity on chest x-ray with deep learning. [Cohen et al., 2020b] Cohen, J. P., Morrison, P., and Dao, L. (2020b). Covid-19 image data collection. arXiv 2003.11597. [Cohen et al., 2020c] Cohen, J. P., Viviano, J., Hashir, M., and Bertrand, H. (2020c). TorchXRayVision: A library of chest X-ray datasets and models. https://github.com/mlmed/torchxrayvision. [Geirhos et al., 2018] Geirhos, R., Janssen, D. H. J., SchÃ¼tt, H. H., Rauber, J., Bethge, M., and Wichmann, F. A. (2018). Comparing deep neural networks against humans: object recognition when the signal gets weaker. [Huang et al., 2016] Huang, C., Li, Y., Loy, C. C., and Tang, X. (2016). Learning deep representation for imbalanced classification. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5375-5384.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Pathalogy</cell><cell cols="2">Negative Positive</cell></row><row><cell>Aspergillosis</cell><cell>534</cell><cell>1</cell></row><row><cell>Aspiration</cell><cell>534</cell><cell>1</cell></row><row><cell>Bacterial</cell><cell>487</cell><cell>48</cell></row><row><cell>COVID-19</cell><cell>193</cell><cell>342</cell></row><row><cell>Chlamydophila</cell><cell>534</cell><cell>1</cell></row><row><cell>Fungal</cell><cell>512</cell><cell>23</cell></row><row><cell>H1N1</cell><cell>534</cell><cell>1</cell></row><row><cell>Herpes</cell><cell>532</cell><cell>3</cell></row><row><cell>Influenza</cell><cell>531</cell><cell>4</cell></row><row><cell>Klebsiella</cell><cell>526</cell><cell>9</cell></row><row><cell>Legionella</cell><cell>526</cell><cell>9</cell></row><row><cell>Lipoid</cell><cell>527</cell><cell>8</cell></row><row><cell>MERS-CoV</cell><cell>527</cell><cell>8</cell></row><row><cell>MRSA</cell><cell>534</cell><cell>1</cell></row><row><cell>Mycoplasma</cell><cell>530</cell><cell>5</cell></row><row><cell>No Finding</cell><cell>520</cell><cell>15</cell></row><row><cell>Nocardia</cell><cell>531</cell><cell>4</cell></row><row><cell>Pneumocystis</cell><cell>513</cell><cell>22</cell></row><row><cell>Pneumonia</cell><cell>26</cell><cell>509</cell></row><row><cell>SARS</cell><cell>519</cell><cell>16</cell></row><row><cell>Staphylococcus</cell><cell>534</cell><cell>1</cell></row><row><cell>Streptococcus</cell><cell>518</cell><cell>17</cell></row><row><cell>Tuberculosis</cell><cell>524</cell><cell>11</cell></row><row><cell>Varicella</cell><cell>530</cell><cell>5</cell></row><row><cell>Viral</cell><cell>157</cell><cell>378</cell></row></table><note>: covid-chestxray-datset pathology negative and positive frequency</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Global health workforce shortage to reach 12.9 million in coming decades</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
	<note>Push for stronger health systems as africa battles</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Irvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multi-objective evolutionary design of deep convolutional neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intubation and Ventilation amid the COVID-19 Outbreak: Wuhan&apos;s Experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anesthesiology</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1317" to="1332" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Rajpurkar</surname></persName>
		</author>
		<title level="m">Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Critical supply shortages -the need for ventilators and personal protective equipment during the covid-19 pandemic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ranney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Nejm</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Russakovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Coronavirus test results get faster, but still too slow to help slow disease spread</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stein ; Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ai can help hospitals triage covid-19 patients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Strickland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Strickland, 2020. A survey on deep transfer learning</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep learning approach to diabetic retinopathy detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tymchenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
