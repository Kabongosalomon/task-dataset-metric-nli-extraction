<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-07-15">15 Jul 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park, New York</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyra</forename><surname>Yee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park, New York</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park, New York</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park, New York</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park, New York</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park, New York</settlement>
									<region>CA, NY</region>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-07-15">15 Jul 2019</date>
						</imprint>
					</monogr>
					<note>Facebook FAIR&apos;s WMT19 News Translation Task Submission</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes Facebook FAIR's submission to the WMT19 shared news translation task. We participate in two language pairs and four language directions, English ↔ German and English ↔ Russian. Following our submission from last year, our baseline systems are large BPE-based transformer models trained with the FAIRSEQ sequence modeling toolkit which rely on sampled backtranslations. This year we experiment with different bitext data filtering schemes, as well as with adding filtered back-translated data. We also ensemble and fine-tune our models on domain-specific data, then decode using noisy channel model reranking. Our submissions are ranked first in all four directions of the human evaluation campaign. On En→De, our system significantly outperforms other systems as well as human translations. This system improves upon our WMT'18 submission by 4.5 BLEU points.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We participate in the WMT19 shared news translation task in two language pairs and four language directions, English→German (En→De), German→English (De→En), English→Russian (En→Ru), and Russian→English (Ru→En). Our methods are based on techniques and approaches used in our submission from last year , including the use of subword models, <ref type="bibr" target="#b12">(Sennrich et al., 2016)</ref>, large-scale back-translation, and model ensembling. We train all models using the FAIRSEQ sequence modeling toolkit <ref type="bibr" target="#b9">(Ott et al., 2019)</ref>. Although document level context for En→De is now available, all our systems are pure sentence level systems. In the future, we expect better results from leveraging this additional context information.</p><p>Compared to our WMT18 submission, we also decide to compete in the En↔Ru and De→En translation directions. Although all four directions are considered high resource settings where large amounts of bitext data is available, we demonstrate that leveraging high quality monolingual data through back-translation is still very important. For all language directions, we back-translate the Newscrawl dataset using a reverse direction bitext system. In addition to back-translating the relatively clean Newscrawl dataset, we also experiment with back-translating portions of the much larger and noisier Commoncrawl dataset. For our final models, we apply a domain-specific finetuning process and decode using noisy channel model reranking <ref type="bibr">(Anonymous, 2019)</ref>.</p><p>Compared to our WMT18 submission in the En→De direction, we observe substantial improvements of 4.5 BLEU. Some of these gains can be attributed to differences in dataset quality, but we believe most of the improvement comes from larger models, larger scale back-translation, and noisy channel model reranking with strong channel and language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>For the En↔De language pair we use all available bitext data including the bicleaner version of Paracrawl. For our monolingual data we use English and German Newscrawl. Although our language models were trained on document level data, we did not use document level boundaries in our final decoding step, so all our systems are purely sentence level systems.</p><p>For the En↔Ru language pair we also use all available bitext data. For our monolingual data we use English and Russian Newscrawl as well as a filtered portion of Russian Commoncrawl. We choose to use Russian Commoncrawl to augment our monolingual data due to the relatively small size of Russian Newscrawl compared to English and German.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Preprocessing</head><p>Similar to last year's submission for En→De, we normalize punctuation and tokenize all data with the Moses tokenizer <ref type="bibr" target="#b6">(Koehn et al., 2007)</ref>. For En↔De we use joint byte pair encodings (BPE) with 32K split operations for subword segmentation <ref type="bibr" target="#b12">(Sennrich et al., 2016)</ref>. For En↔Ru, we learn separate BPE encodings with 24K split operations for each language. Systems trained with this separate BPE encoding performed significantly better than those trained with joint BPE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Bitext</head><p>Large datasets crawled from the internet are naturally very noisy and can potentially decrease the performance of a system if they are used in their raw form. Cleaning these datasets is an important step to achieving good performance on any downstream tasks.</p><p>We apply language identification filtering (langid; <ref type="bibr">Lui et al., 2012)</ref>, keeping only sentence pairs with correct languages on both sides. Although not the most accurate method of language identification <ref type="bibr" target="#b5">(Joulin et al., 2016)</ref>, one side effect of using langid is the removal of very noisy sentences consisting of mostly garbage tokens, which are classified incorrectly and filtered out.</p><p>We also remove sentences longer than 250 tokens as well as sentence pairs with a source/target length ratio exceeding 1.5. In total, we filter out about 30% of the original bitext data. See <ref type="table">Table 1</ref> for details on the bitext dataset sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Monolingual</head><p>For monolingual Newscrawl data we also apply langid filtering. Since the monolingual Newscrawl corpus for Russian is significantly smaller than that of German or English, we augment our monolingual Russian data with data from the commoncrawl corpus. Commoncrawl is the largest monolingual corpus available for training but is also very noisy. In order to select a limited amount of high quality, in-domain sentences from the larger corpus, we adopt the method of <ref type="bibr" target="#b8">Moore and Lewis (2010)</ref> for selecting indomain data ( §3.2.1). Our base system is based on the big Transformer architecture <ref type="bibr" target="#b13">(Vaswani et al., 2017)</ref> as implemented in FAIRSEQ. We experiment with increasing network capacity by increasing embed dimension, FFN size, number of heads, and number of layers. We find that using a larger FFN size <ref type="formula" target="#formula_1">(8192)</ref> gives a reasonable improvement in performance while maintaining a manageable network size. All subsequent models, including ensembles, use this larger FFN Transformer architecture.</p><p>We trained all our models using FAIR-SEQ <ref type="bibr" target="#b9">(Ott et al., 2019)</ref> on 128 Volta GPUs, following the setup described in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Large-scale Back-translation</head><p>Back-translation is an effective and commonly used data augmentation technique to incorporate monolingual data into a translation system. Backtranslation first trains an intermediate target-tosource system that is used to translate monolingual target data into additional synthetic parallel data. This data is used in conjunction with human translated bitext data to train the desired sourceto-target system.</p><p>In this work we used back-translations obtained by sampling  from an ensemble of three target-to-source models. We found that models trained on data back-translated using an ensemble instead of a single model performed better <ref type="table" target="#tab_2">(Table 2)</ref>. Previous work also found that upsampling the bitext data can improve backtranslation . We adopt this method to tune the amount of bitext and synthetic data the model is trained on. We find a ratio of 1:1 synthetic to bitext data to perform the best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Back-translating Commoncrawl</head><p>The amount of monolingual Russian data available in the Newscrawl dataset is significantly smaller than that of English and German (   order to increase the amount of monolingual Russian data for back-translation, we experiment with incorporating Commoncrawl data. Commoncrawl is a much larger and noisier dataset compared to Newscrawl, and is also non-domain specific. We experiment with methods to identify a subset of Commoncrawl that is most similar to Newscrawl. Specifically, we use the in-domain filtering method described in <ref type="bibr" target="#b8">Moore and Lewis (2010)</ref>. Given an in domain corpus I, in this case Newscrawl, and a non-domain specific corpus N , in this case Commoncrawl, we would like the find the subcorpus N I that is drawn from the same distribution as I. For any given sentence s, we can calculate, using Bayes' rule, the probability a sentence s in N is drawn from N I</p><formula xml:id="formula_0">Newscrawl 434M 559M 80M + langid filter 424M 521M 76M Commoncrawl - - 1.2B + KenLM filter - - 60M Total 424M 521M 136M</formula><formula xml:id="formula_1">P (N I |s, N ) = P (s|N I )P (N I |N ) P (s|N )<label>(1)</label></formula><p>We ignore the P (N I |N ) term, since it will be constant for any given I and N , and use P (s|I) instead of P (s|N I ), since I and N I are drawn from the same distribution. Moving into the log domain, we can calculate the probability score for a sentence s by log P (N I |s, N ) = log P (s|I) − log P  L N trained on I and N respectively. Our corpora are very large and we therefore use an n-gram model <ref type="bibr" target="#b4">(Heafield, 2011)</ref> rather than a neural language model which would be much slower to train and evaluate. We train two language models L I and L N on Newscrawl and Commoncrawl respectively, then score every sentence s in Commoncrawl by H I (s)−H N (s). We select a cutoff of 0.01, and use all sentences that score higher than this value for back-translation, or about 5% of the entire dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fine-tuning</head><p>Fine-tuning with domain-specific data is a common and effective method to improve translation quality for a downstream task. After completing training on the bitext and back-translated data, we train for an additional epoch on a smaller in-domain corpus. For De→En, we fine-tune on test sets from previous years, including new-stest2012, newstest2013, newstest2015, and new-stest2017. For En→De, we fine-tune on previous test sets as well as the News-Commentary dataset. For En↔Ru we fine-tune on a combination of News-Commentary, newstest2013, newstest2015, and newstest2017. The other test sets are held out for other tuning procedures and evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Noisy Channel Model Reranking</head><p>N -best reranking is a method of improving translation quality by scoring and selecting a candidate hypothesis from a list of n-best hypotheses generated by a source-to-target, or forward model. For our submissions, we rerank using a noisy channel model approach.</p><p>Given a target sequence y and a source sequence x, the noisy channel approach applies Bayes' rule to model</p><formula xml:id="formula_3">P (y|x) = P (x|y)P (y) P (x)<label>(2)</label></formula><p>Since P (x) is constant for a given source sequence x, we can ignore it. We refer to the remaining terms P (y|x), P (x|y), and P (y), as the forward model, channel model, and language model respectively. In order to combine these scores for reranking, we calculate for every one of our n-best hypotheses:</p><p>log P (y|x) + λ 1 log P (x|y) + λ 2 log P (y) (3)</p><p>The weights λ 1 and λ 2 are determined by tuning them with a random search on a validation set and selecting the weights that give the best performance. In addition, we also tune a length penalty.</p><p>For all translation directions, our forward models are ensembles of fine-tuned and backtranslated models. Since we compete in both directions for both language pairs, for any given translation direction we can use the forward model for the reverse direction as the channel model. Our language models for each of the target languages English, German, and Russian, are big Transformer decoder models with FFN 8192. We train the language models on the monolingual Newscrawl dataset, and use document level context for the English and German models. Perplexity scores for the language models on the bolded target language of each translation direction are shown in table 4. With a smaller amount of monolingual Russian data available, we observe that our Russian language model performs worse than the German and English language models.</p><p>To select the length penalty and weights, λ 1 and λ 2 , for decoding, we use random search, choosing values in the range [0, 2) for the weights and values in the range [0, 1) for the length penalty. For all language directions, we choose the weights that give the highest BLEU score on a combined dataset of newstest2014 and newstest2016.</p><p>To run our final decoding step, we first use the forward model with beam size 50 to generate an n-best list. We then use the channel and language models to score each of these hypotheses, using the weights and length penalty tuned previously. Finally, we select the hypothesis with the highest score as our output.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Postprocessing</head><p>For En→De and En→Ru, we also change the standard English quotation marks (" ... ") to Germanstyle quotation marks ( " ... ").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Results and ablations for En→De are shown in Table 5, De→En in <ref type="table" target="#tab_9">Table 6</ref>, En→Ru in <ref type="table" target="#tab_11">Table 7</ref> and Ru→En in <ref type="table" target="#tab_12">Table 8</ref>. We report case-sensitive Sa-creBLEU scores using SacreBLEU (Post, 2018) 1 , using international tokenization for En→Ru. In the final row of each table we also report the case-sensitive BLEU score of our submitted system on this year's test set. All single models and individual models within ensembles are averages of the last 10 checkpoints of training. Our baseline systems are big Transformers as described in <ref type="bibr" target="#b13">(Vaswani et al., 2017)</ref>. The baselines were trained with minimally filtered data, removing only those sentences longer than 250 words and exceeding a source/target length ratio of 1.5 This setup gave us a reasonable baseline to evaluate data filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">English→German</head><p>For En→De, langid filtering, larger FFN, and ensembling improve our baseline performance on news2018 by about 1.5 BLEU. Note that our best  bitext only systems already outperforms our system from last year by 1 BLEU point. This is perhaps due to the addition of higher quality bitext data and improved data filtering techniques. The addition of back-translated (BT) data improves single model performance by only 0.3 BLEU, but combining this with fine-tuning and ensembling gives us a total of 3 BLEU. Finally, applying reranking on top of these strong ensembled systems gives another 1.4 BLEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">German→English</head><p>For De→En, as with En→De, we see similar improvements with langid filtering, larger FFN, and ensembling on the order of 1.4 BLEU. Compared to En→De however, we also observe that the addition of back-translated data is much more significant, improving single model performance by over 2.5 BLEU. Fine-tuning, ensembling, and reranking add an additional 2.4 BLEU, with reranking contributing 1.5 BLEU, a majority of the improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">English→Russian</head><p>For En→Ru, we observe large improvements of 2.4 BLEU over a bitext-only model after applying langid filtering, larger FFN, and ensembling.</p><p>Since we start with a lower quality initial En↔Ru bitext dataset, we observe a large improvement of 3.5 BLEU by adding back-translated data. Augmenting this back-translated data with Commoncrawl adds an additional 0.2 BLEU. Finally, applying fine-tuning, ensembling, and reranking adds 2.2 BLEU, with reranking contributing 1 BLEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Russian→English</head><p>For Ru→En, we observe similar trends to En↔De, with langid filtering, larger FFN, and    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Human Evaluations</head><p>All our systems participated in the human evaluation campaign of WMT'19. For different systems, different styles of evaluations were used. All our systems except Ru→En were evaluated with document level context and had a document level rating collected. Source based direct assessment was used for systems translating from English, and target based direct assessment was used for systems translating to English. See <ref type="table" target="#tab_13">Table 9</ref> for more details. Facebook-FAIR was ranked first in all four language directions we compete in. <ref type="table" target="#tab_15">Table 10</ref> shows that our En→De submission significantly outperforms other systems as well as human translations. Our submissions for De→En, En→Ru and Ru→En also achieve the highest score.</p><p>Although our systems are pure sentence-level models, they performed well irrespective of whether the evaluation method used document context or not. For document level rankings, our En→De system also ranked first and significantly outperformed human translations. Our En→Ru submission achieved the highest score among all submissions and is tied for the first place with human translations. The De→En system achieved the second highest score among constrained systems. See <ref type="bibr">(Bojar et al., 2019)</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper describes Facebook FAIR's submission to the WMT19 news translation task. For all four translation directions, En↔De and En↔Ru, we use the same strategy of filtering bitext data, performing sampling-based back-translation on monolingual data, then training strong individual mo-  dels on a combination of this data. Each of these models is fine-tuned and ensembled into a final system that is used for decoding with noisy channel model reranking. We demonstrate the effectiveness of our noisy channel-based reranking approach even when applied on top of very strong systems, and rank first in all four directions of the human evaluation campaign.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>). In</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>SacreBLEU for English-Russian models trained with data back-translated using a single model vs. an ensemble of two models</figDesc><table><row><cell>En</cell><cell>De</cell><cell>Ru</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Number of sentences in monolingual datasets available for back-translation</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Perplexity scores for language models on bolded target languages in all translation directions</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>SacreBLEU scores on English→German.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>SacreBLEU scores on German→English.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>SacreBLEU scores on English→Russian</figDesc><table><row><cell>Ru→En</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>: SacreBLEU scores on Russian→English</cell></row><row><cell>ensembling improving performance of a bitext-</cell></row><row><cell>only system by 1.6 BLEU. Backtranslation adds</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell>: Human evaluation configurations; M denotes</cell></row><row><cell>monolingual human evaluation, or target-based direct</cell></row><row><cell>assessment, where translations are compared to human</cell></row><row><cell>references; B denotes bilingual/source based evaluation</cell></row><row><cell>where the human annotators evaluate MT output based</cell></row><row><cell>only on the source sentence (and no reference translati-</cell></row><row><cell>on is present); +DC denotes systems evaluated with do-</cell></row><row><cell>cument level context, -DC without document context.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 10 :</head><label>10</label><figDesc>Official results of the WMT'19 En→De News Translation Task. Systems are ordered by DA z-score; systems within a cluster are considered tied; grayed entries indicate systems using resources beyond the provided data.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">SacreBLEU signatures: BLEU+case.mixed+lang.en-de+numrefs.1+smooth.exp+</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">BLEU, again most likely due to the lower quality bitext data available. Fine-tuning, ensembling, and reranking add almost 4 BLEU, with reranking contributing 1.2 BLEU.4.5 RerankingFor every language direction, reranking gives a significant improvement, even when applied on top of an ensemble of very strong back-translated models. We also observe that the biggest improvement of 1.5 BLEU comes in the De→En language direction, and the smallest improvement of 1 BLEU in the En→Ru direction. This is perhaps due to the relatively weak Russian language model, which is trained on significantly less data compared to English and German. Improving our language models may lead to even greater improvements with reranking.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">BLEU+case.mixed+lang.de-en+numrefs.1+smooth.exp+ test.wmt{17/18}+tok.13a+version.1.2.11, BLEU+case.mixed+lang.ru-en+numrefs.1+smooth.exp+ test.wmt{17/18}+tok.13a+version.1.2.11, BLEU+case.mixed+lang.en-ru+numrefs</title>
		<idno>test.wmt{17/18}+tok.13a+version.1.2.11</idno>
		<imprint/>
	</monogr>
	<note>1+smooth.exp+ test.wmt{17/18}+tok.intl+version.1.2.11</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>References Ondřej</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haddow</surname></persName>
		</author>
		<imprint>
			<pubPlace>Matthias Huck, Philipp Koehn</pubPlace>
		</imprint>
	</monogr>
	<note>and Christof Monz. 2019. Findings of the 2019 conference on machine translation (wmt19)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Shared Task Papers, Florence, Italy. Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of the Fourth Conference on Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding back-translation at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Kenlm: faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Demo Session</title>
		<meeting><address><addrLine>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">2012. langid. py: An off-the-shelf language identification tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 system demonstrations</title>
		<meeting>the ACL 2012 system demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Intelligent selection of language model training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="220" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2019: Demonstrations</title>
		<meeting>NAACL-HLT 2019: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scaling neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WMT</title>
		<meeting>of WMT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A call for clarity in reporting BLEU scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiser</forename><surname>Ukasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Conference on Neural Information Processing Systems</title>
		<meeting>the 31st Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
