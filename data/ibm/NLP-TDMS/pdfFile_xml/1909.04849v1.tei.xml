<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Discrete Hard EM Approach for Weakly Supervised Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
							<email>danqic@cs.princeton.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<email>hannaneh@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Allen Institute for Artificial Intelligence</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Discrete Hard EM Approach for Weakly Supervised Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many question answering (QA) tasks only provide weak supervision for how the answer should be computed. For example, TRIVIAQA answers are entities that can be mentioned multiple times in supporting documents, while DROP answers can be computed by deriving many different equations from numbers in the reference text. In this paper, we show it is possible to convert such tasks into discrete latent variable learning problems with a precomputed, task-specific set of possible solutions (e.g. different mentions or equations) that contains one correct option. We then develop a hard EM learning scheme that computes gradients relative to the most likely solution at each update. Despite its simplicity, we show that this approach significantly outperforms previous methods on six QA tasks, including absolute gains of 2-10%, and achieves the stateof-the-art on five of them. Using hard updates instead of maximizing marginal likelihood is key to these results as it encourages the model to find the one correct answer, which we show through detailed qualitative analysis. 1</p><p>is used to compute the objective as follows:</p><p>However, there are two major problems in the MML objective in our settings. First, MML can be</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A natural setting in many question answering (QA) tasks is to provide weak supervision to determine how the question should be answered given the evidence text. For example, as seen in <ref type="figure">Figure</ref> 1, TRIVIAQA answers are entities that can be mentioned multiple times in supporting documents, while DROP answers can be computed by deriving many different equations from numbers in the reference text. Such weak supervision is attractive because it is relatively easy to gather, allowing for large datasets, but complicates learning because there are many different spurious ways to derive the correct answer. It is natural to The answer text is mentioned five times in the given document, however, only the fourth span actually answers the question. (Bottom) Reading comprehension with discrete reasoning. There are many potential equations which execute the answer ('4'), but only one of them is the correct equation <ref type="bibr">('40-36')</ref> and the others are false positives. model such ambiguities with a latent variable during learning, but most prior work on reading comprehension has rather focused on the model architecture and used heuristics to map the weak signal to full supervision (e.g. by selecting the first answer span in TRIVIAQA <ref type="bibr" target="#b15">(Joshi et al., 2017;</ref><ref type="bibr" target="#b33">Tay et al., 2018;</ref><ref type="bibr" target="#b32">Talmor and Berant, 2019)</ref>). Some models are trained with maximum marginal likelihood (MML) <ref type="bibr" target="#b16">(Kadlec et al., 2016;</ref><ref type="bibr" target="#b31">Swayamdipta et al., 2018;</ref><ref type="bibr" target="#b6">Clark and Gardner, 2018;</ref>, but it is unclear if it gives a meaningful improvement over the heuristics.</p><p>In this paper, we show it is possible to formulate a wide range of weakly supervised QA tasks as discrete latent-variable learning problems. First, we define a solution to be a particular derivation of a model to predict the answer (e.g. a span in  <ref type="bibr" target="#b15">(Joshi et al., 2017)</ref> 61,888 7,993 7,701 2.7 2 NARRATIVEQA <ref type="bibr" target="#b17">(Kočiskỳ et al., 2018)</ref> 32,747 3,461 10,557 4.3 5 TRIVIAQA-OPEN <ref type="bibr" target="#b15">(Joshi et al., 2017)</ref> 78,785 8,837 11,313 6.7 4 NATURALQUESTIONS-OPEN <ref type="bibr">(Kwiatkowski et al., 2019) 79,168 8,757</ref> 3,610 1.8 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Reading comprehension with discrete reasoning</head><p>DROPnum <ref type="bibr" target="#b10">(Dua et al., 2019)</ref> 46,973 5,850 -8.2 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Semantic Parsing</head><p>WIKISQL <ref type="bibr" target="#b42">(Zhong et al., 2017)</ref> 56,355 8,421 15,878 346.1 5 <ref type="table">Table 1</ref>: Six QA datasets in three different categories used in this paper (detailed in Section 5) along with the size of each dataset. An average and median of the size of precomputed solution sets (denoted by Z) are also reported. Details on how to obtain Z are given in Section 4.</p><p>the document or an equation to compute the answer). We demonstrate that for many recently introduced tasks, which we group into three categories as given in <ref type="table">Table 1</ref>, it is relatively easy to precompute a discrete, task-specific set of possible solutions that contains the correct solution along with a modest number of spurious options. The learning challenge is then to determine which solution in the set is the correct one, while estimating a complete QA model.</p><p>We model the set of possible solutions as a discrete latent variable, and develop a learning strategy that uses hard-EM-style parameter updates. This algorithm repeatedly (i) predicts the most likely solution according to the current model from the precomputed set, and (ii) updates the model parameters to further encourage its own prediction. Intuitively, these hard updates more strongly enforce our prior beliefs that there is a single correct solution. This method can be applied to any problem that fits our weak supervision assumptions and can be used with any model architecture.</p><p>We experiment on six different datasets (Table 1) using strong task-specific model architectures <ref type="bibr" target="#b8">(Devlin et al., 2019;</ref><ref type="bibr" target="#b10">Dua et al., 2019;</ref><ref type="bibr" target="#b13">Hwang et al., 2019)</ref>. Our learning approach significantly outperforms previous methods which use heuristic supervision and MML updates, including absolute gains of 2-10%, and achives the state-of-the-art on five datasets. It outperforms recent state-of-the-art reward-based semantic parsing algorithms <ref type="bibr" target="#b22">(Liang et al., 2018;</ref><ref type="bibr" target="#b1">Agarwal et al., 2019)</ref> by 13% absolute percentage on WIKISQL, strongly suggesting that having a small precomputed set of possible solutions is a key ingredient. Finally, we present a detailed analysis showing that, in practice, the introduction of hard updates encourages models to assign much higher probability to the correct solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Reading Comprehension. Large-scale reading comprehension (RC) tasks that provide full supervision for answer spans <ref type="bibr" target="#b28">(Rajpurkar et al., 2016)</ref> have seen significant progress recently <ref type="bibr" target="#b30">(Seo et al., 2017;</ref><ref type="bibr" target="#b36">Xiong et al., 2018;</ref><ref type="bibr" target="#b39">Yu et al., 2018a;</ref><ref type="bibr" target="#b8">Devlin et al., 2019)</ref>. More recently, the community has moved towards more challenging tasks such as distantly supervised RC <ref type="bibr" target="#b15">(Joshi et al., 2017)</ref>, RC with free-form human generated answers <ref type="bibr" target="#b17">(Kočiskỳ et al., 2018)</ref> and RC requiring discrete or multi-hop reasoning <ref type="bibr" target="#b10">(Dua et al., 2019;</ref><ref type="bibr" target="#b38">Yang et al., 2018)</ref>. These tasks introduce new learning challenges since the gold solution that is required to answer the question (e.g. a span or an equation) is not given.</p><p>Nevertheless, not much work has been done for this particular learning challenge. Most work on RC focuses on the model architecture and simply chooses the first span or a random span from the document <ref type="bibr" target="#b15">(Joshi et al., 2017;</ref><ref type="bibr" target="#b33">Tay et al., 2018;</ref><ref type="bibr" target="#b32">Talmor and Berant, 2019)</ref>, rather than modeling this uncertainty as a latent choice. Others maximize the sum of the likelihood of multiple spans <ref type="bibr" target="#b16">(Kadlec et al., 2016;</ref><ref type="bibr" target="#b31">Swayamdipta et al., 2018;</ref><ref type="bibr" target="#b6">Clark and Gardner, 2018;</ref>, but it is unclear if it gives a meaningful improvement. In this paper, we highlight the learning challenge and show that our learning method, independent of the model architecture, can give a significant gain. Specifically, we assume that one of mentions are related to the question and others are false positives because (i) this happens for most cases, as the first example in <ref type="table">Table 2</ref>, and (ii) even in the case where multiple mentions contribute to the answer, there is often a single span which fits the question the best.</p><p>Semantic Parsing. Latent-variable learning has been extensively studied in the literature of semantic parsing <ref type="bibr" target="#b41">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b7">Clarke et al., 2010;</ref><ref type="bibr" target="#b4">Berant et al., 2013;</ref><ref type="bibr" target="#b3">Artzi and Zettlemoyer, 2013)</ref>. For example, a question and an answer pair (x, y) is given but the logical form that is used to compute the answer is not. Two common learning paradigms are maximum marginal likelihood (MML) and rewardbased methods. In MML, the objective maximizes z∈Ẑ P(z|x), whereẐ is an approximation of a set of logical forms executing y <ref type="bibr" target="#b4">Berant et al., 2013;</ref><ref type="bibr" target="#b18">Krishnamurthy et al., 2017)</ref>. In reward-based methods, a reward function is defined as a prior, and the model parameters are updated with respect to it <ref type="bibr" target="#b14">(Iyyer et al., 2017;</ref><ref type="bibr" target="#b21">Liang et al., 2017</ref><ref type="bibr" target="#b22">Liang et al., , 2018</ref>. Since it is computationally expensive to obtain a precomputed set in semantic parsing, these methods typically recompute the set of logical forms with respect to the beam at every parameter update. In contrast, our learning method targets tasks that a set of solutions can be precomputed, which include many recent QA tasks such as reading comprehension, open-domain QA and a recent SQL-based semantic parsing task <ref type="bibr" target="#b42">(Zhong et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section, we first formally define our general setup, which we will instantiate for specific tasks in Section 4 and then we describe our learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setup</head><p>Let x be the input of a QA system (e.g. a question and a document) and y be the answer text (e.g. <ref type="bibr">'Robert Schumann' or '4')</ref>. We define a solution as a particular derivation that a model is supposed to produce for the answer prediction (e.g. a span in the document or an equation to compute the answer, see <ref type="table">Table 2</ref>). Let f denote a task-specific, deterministic function which maps a solution to the textual form of the answer (e.g. by simply returning the string associated with a particular selected mention or solving an equation to get the final number, see <ref type="table">Table 2</ref>). Our goal is to learn a model (with parameters θ) which takes an input x and outputs a solution z such that f (z) = y.</p><p>In a fully supervised scenario, a true solution z is given, and θ is estimated based on a collection of (x,z) pairs. In this work, we focus on a weakly supervised setting in whichz is not given and we define Z tot as a finite set of all the possible solutions. In the case that the search space is very large or infinite, we usually can approximate Z tot with a high coverage in practice. Then, we obtain Z = {z ∈ Z tot : f (z) = y} by enumerating all z ∈ Z tot . This results a set of all the possible solutions that lead to the correct answer. We assume it contains one solution that we want to learn to produce, and potentially many other spurious ones. In practice, Z is defined in a task-specific manner, as we will see in Section 4.</p><p>At inference time, the model produces a solutionz ∈ Z tot from an input x with respect to θ and predicts the final answer as f (z). Note that we cannot compute Z at inference time because the groundtruth y is not given. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Method</head><p>In a fully-supervised setting wherez is given, we can learn θ by optimizing the negative log likelihood ofz given the input x with respect to θ. J Sup (θ|x,z) = −log P(z|x; θ)</p><p>In our weak supervision scenario, the model has access to x and Z = {z 1 , z 2 , . . . , z n }, and the selection of the best solution in Z can be modeled as a latent variable. We can compute the maximum marginal likelihood (MML) estimate, which marginalizes the likelihood of each z i ∈ Z given the input x with respect to θ. Formally, maximized by assigning high probabilities to any subset of z i ∈ Z; whereas in our problems, instances in Z other than one correct z are spurious solutions which the model should ideally assign very low probability. Second, in MML we optimize the sum over probabilities of Z during training but typically predict the maximum probability solution during inference, creating a discrepancy between training and testing.</p><p>We introduce a learning strategy with a hard-EM approach. First, the model computes the likelihood of each z i given the input x with respect to θ, P(z i |x; θ), and picks one of Z with the largest likelihood:z</p><formula xml:id="formula_0">= argmax z i ∈Z P(z i |x; θ)</formula><p>Then, the model optimizes on a standard negative log likelihood objective, assumingz is a true solution. The objective can be re-written as follows:</p><formula xml:id="formula_1">J Hard (θ|x, Z) = −log P(z|x; θ) = −log max z i ∈Z P(z i |x; θ) = −max z i ∈Z log P(z i |x; θ) = min z i ∈Z J Sup (θ|x, z i )</formula><p>This objective can be seen as a variant of MML, where the sum is replaced with a max.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task Setup</head><p>We apply our approach to three different types of QA tasks: multi-mention reading comprehension, RC with discrete reasoning and a semantic parsing task. In this section, we describe each task in detail: how we define a solution z and pre-compute a set Z based on input x and answer y. The statistics of |Z| and examples on each task are shown in <ref type="table">Table 1</ref> and <ref type="table">Table 2</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multi-Mention Reading Comprehension</head><p>Multi-mention reading comprehension naturally occurs in several QA tasks such as (i) distantlysupervised reading comprehension where a question and answer are collected first before the evidence document is gathered (e.g. TRIVIAQA), (ii) abstractive reading comprehension which requires a free-form text to answer the question (e.g. NARRATIVEQA), and (iii) open-domain QA where only question-answer pairs are provided.</p><p>Given a question Q = [q 1 , . . . , q l ] and a document D = [d 1 , . . . , d L ], where q i and d j denote the tokens in the question and document, the output y is an answer text, which is usually mentioned multiple times in the document.</p><p>Previous work has dealt with this setting by detecting spans in the document through text matching <ref type="bibr" target="#b15">(Joshi et al., 2017;</ref><ref type="bibr" target="#b6">Clark and Gardner, 2018)</ref>. Following previous approaches, we define a solution z as a span in the document. We obtain a set of possible solutions Z = {z 1 , . . . , z n } by finding exact match or similar mentions of y, where z i = (s i , e i ) is a span of text with start and end token indices s i and e i . Specifically,</p><formula xml:id="formula_2">g max = max 1≤s i ≤e i ≤L g([d s i , . . . , d e i ], y) Z = {z i = (s i , e i ) s.t. g(s i , e i ) = g max },</formula><p>where g is a string matching function. If the answer is guaranteed to be a span in the document D, g is a binary function which returns 1 if two strings are the same, and 0 otherwise. If the answer is free-form text, we choose g as the ROUGE-L metric <ref type="bibr" target="#b24">(Lin, 2004)</ref>. This complicates the learning because the given document contains many spans matching to the text, while most of them are not related to answering the question. As an example shown in <ref type="table">Table 2</ref>, only the fourth span out of six is relevant to the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reading Comprehension with Discrete Reasoning</head><p>Some reading comprehension tasks require reasoning in several discrete steps by finding clues from the document and aggregating them. One such example is mathematical reasoning, where the model must pick numbers from a document and compute an answer through arithmetic operations <ref type="bibr" target="#b10">(Dua et al., 2019)</ref>. In this task, the input is also a question Q and a document D, and the output y is given as a numeric value. We define a solution z to be an executable arithmetic equation. Since there is an infinite set of potential equations, we approximate Z tot as a finite set of arithmetic equations with two numeric values and one operation, following <ref type="bibr" target="#b10">Dua et al. (2019)</ref>. 3 Specifically,</p><formula xml:id="formula_3">Z tot = z i = (o 1 , n 1 , o 2 , n 2 ) s.t. o 1 , o 2 ∈ {+, −, %}, n 1 , n 2 ∈ N D ∪ N Q ∪ S , 1. Multi-Mention Reading Comprehension (TRIVIAQA, NARRATIVEQA, TRIVIAQA-OPEN &amp; NATURALQUESTIONS-OPEN)</formula><p>Question: Which composer did pianist Clara Wieck marry in 1840? Document: Robert Schumann was a German composer and influential music critic. He is widely regarded as one of the greatest composers of the Romantic era. (...) Robert Schumann himself refers to it as "an affliction of the whole hand". (...) Robert Schumann is mentioned in a 1991 episode of Seinfeld "The Jacket". (...) Clara Schumann was a German musician and composer, considered one of the most distinguished pianists of the Romantic era. Her husband was the composer Robert Schumann . &lt;Childhood&gt; (...) At the age of eight, the young Clara Wieck performed at the Leipzig home of Dr. Ernst Carus. There she met another gifted young pianist who had been invited to the musical evening, named Robert Schumann , who was nine years older. Schumann admired Clara' s playing so much that he asked permission from his mother to discontinue his law studies. (...) In the spring of 1853, the then unknown 20-year-old Brahms met Joachim in Hanover, made a very favorable impression on him, and got from him a letter of introduction to Robert Schumann . Answer (y): Robert Schumann f : Text match Ztot: All spans in the document Z: Spans which match 'Robert schumann' (red text)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Reading Comprehension with Discrete Reasoning (DROPnum)</head><p>Question: How many yards longer was Rob Bironas' longest field goal compared to John Carney's only field goal? Document: (...) The Chiefs tied the game with QB Brodie Croyle completing a 10 yard td pass to WR Samie Parker. Afterwards the Titans responded with Kicker Rob Bironas managing to get a 37 yard field goal. Kansas city would take the lead prior to halftime with croyle completing a 9 yard td pass to FB Kris Wilson. In the third quarter Tennessee would draw close as Bironas kicked a 37 yard field goal. The Chiefs answered with kicker John Carney getting a 36 yard field goal. Afterwards the Titans would retake the lead with Young and Williams hooking up with each other again on a 41 yard td pass. (...) Tennessee clinched the victory with Bironas nailing a 40 yard and a 25 yard field goal. With the win the Titans kept their playoff hopes alive at 8 6 . Answer (y): 4 f : Equation executor Ztot: Equations with two numeric values and one arithmetic operation Z: { 41-37, 40-36, 10-6, ... }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SQL Query Generation (WIKISQL)</head><p>Question: What player played guard for Toronto in 1996-1997?  <ref type="table">Table 2</ref>: Examples of the input, answer text (y), f , Z tot and Z. First, in multi-mention reading comprehension, the answer text 'Robert Schumann' is mentioned six times but only the fourth span is related to the question. Second, in reading comprehension with discrete reasoning, many equations yield to the answer 4, but only '40-37' answers the question. Lastly, in SQL query generation, five SQL queries lead to the answer but only the first one is the correct query. See Section 4 for more details.</p><p>where N D and N Q are all numeric values appearing in D and Q, respectively, and S are a set of predefined special numbers. Then</p><formula xml:id="formula_4">Z = {z i ∈ Z tot s.t. f (z i ) = y}</formula><p>where f is an execution function of equations. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example Z given a question and a document. We can see that one equation is correct, while the others are false positives which coincidentally lead to the correct answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">SQL Query Generation</head><p>To evaluate if our training strategy generalizes to other weak supervision problems, we also study a semantic parsing task where a question and an answer are given but the logical form to execute the answer is not. In particular, we consider a task of answering questions about a given table by generating SQL queries.</p><p>The input is a question Q = [q 1 , . . . , q l ] and a table header H = [h 1 , . . . , h n L ], where q i is a token, h i is a multi-token title of each column, and n L is the number of headers. The supervision is given as the SQL query result y, which is always a text string.</p><p>We define a solution to be an SQL query. Since the set of potential queries is infinite, we approximate Z tot as a set of non-nested SQL queries with at most three conditions. 4 Specifically, given A as a set of aggregating operators {sum, mean, max, min, count} and C as a set of</p><formula xml:id="formula_5">possible conditions {(h, o, t) s.t. h ∈ [1, n L ], o ∈ {=, &lt;, &gt;}, t ∈ spans in Q}, we define Z tot : Z tot = {z i = (z sel i , z agg i , {z cond i,j } 3 j=1 } s.t. z sel i ∈ [1, n L ] z agg i ∈ {none} ∪ A z cond i,j ∈ {none} ∪ C for j ∈ [1, 3]}, then, Z = {z i ∈ Z tot s.t. f (z i ) = y},</formula><p>where f is an SQL executor. The third example in <ref type="table">Table 2</ref> shows Z may contain many spurious SQL querie, e.g. the third query in Z coincidentally executes the answer because 'John Long' is ranked first among all the guards in alphabetical order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We experiment on a range of question answering tasks with varied model architectures to demonstrate the effectiveness of our approach.</p><p>Built on top of strong base models, our learning method is able to achieve state-of-the-art on NARRATIVEQA, TRIVIAQA-OPEN, NATURALQUESTIONS-OPEN, DROP num and WIKISQL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Multi-mention Reading Comprehension</head><p>We experiment on two reading comprehension datasets and two open-domain QA datasets. For reading comprehension, we evaluate on TRIVI-AQA (Wikipedia) <ref type="bibr" target="#b15">(Joshi et al., 2017)</ref> and NAR-RATIVEQA (summary) <ref type="bibr" target="#b17">(Kočiskỳ et al., 2018)</ref>.</p><p>For open-domain QA, we follow the settings in  and use the QA pairs from TRIV-IAQA-unfiltered <ref type="bibr" target="#b15">(Joshi et al., 2017)</ref> and NAT-URAL QUESTIONS (Kwiatkowski et al., 2019) with short answers and discard the given evidence documents. We refer to these two datasets as TRIVIAQA-OPEN and NATURALQUESTIONS- <ref type="bibr">OPEN. 5</ref> We experiment with three learning methods as follows.</p><p>• First Only: J(θ) = −logP(z 1 |x; θ), where z 1 appears first in the given document among all z i ∈ Z.</p><p>• MML: J(θ) = −logΣ n i=1 P(z i |x; θ). • Ours: J(θ) = −logmax 1≤i≤n P(z i |x; θ). P(z i |Q, D) can be obtained by any model which outputs the start and end positions of the input document. In this work, we use a modified version of BERT <ref type="bibr" target="#b8">(Devlin et al., 2019)</ref> for multiparagraph reading comprehension <ref type="bibr" target="#b25">(Min et al., 2019)</ref>.</p><p>Training details. We use uncased version of BERT base . For all datasets, we split documents into a set of segments up to 300 tokens because BERT limits the size of the input. We use batch size of 20 for two reading comprehension tasks and 192 for two open-domain QA tasks. Following <ref type="bibr" target="#b6">Clark and Gardner (2018)</ref>, we filter a subset of segments in TRIVIAQA through TF-IDF similarity between a segment and a question to maintain a reasonable length. For opendomain QA tasks, we retrieve 50 Wikipedia articles through TF-IDF  and further run BM25 <ref type="bibr" target="#b29">(Robertson et al., 2009)</ref> to retrieve 20 (for train) or 80 (for development and test) paragraphs. We try 10, 20, 40 and 80 paragraphs on the development set to choose the number of paragraphs to use on the test set.</p><p>To avoid local optima, we perform annealing: at training step t, the model optimizes on MML objective with a probability of min(t/τ , 1) and otherwise use our objective, where τ is a hyperparameter. We observe that the performance is improved by annealing while not being overly sensitive to the hyperparameter τ . We include full hyperparameters and detailed ablations in Appendix B.</p><p>Results. <ref type="table" target="#tab_3">Table 3</ref> compares the results of baselines, our method and the state-of-the-art on four datasets. 6 First of all, we observe that First-Only is a strong baseline across all the datasets. We hypothesize that this is due to the bias in the dataset that answers are likely to appear earlier in the paragraph. Second, while MML achieves comparable result to the First-Only baseline, our learning method outperforms others by 2+ F1/ROUGE-L/EM consistently on all datasets. Lastly, our method achieves the new state-ofthe-art on NARRATIVEQA, TRIVIAQA-OPEN and NATURALQUESTIONS-OPEN, and is comparable to the state-of-the-art on TRIVIAQA, despite our aggressive truncation of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reading Comprehension with Discrete Reasoning</head><p>We experiment on a subset of DROP <ref type="bibr" target="#b10">(Dua et al., 2019)</ref> with numeric answers (67% of the entire dataset) focusing on mathematical reasoning. We refer to this subset as DROP num . The current state-of-the-art model is an augmented version of QANET <ref type="bibr" target="#b39">(Yu et al., 2018a)</ref> which selects two numeric values from the document or the question and performs addition or subtraction to get the an-   <ref type="bibr" target="#b40">(Yu et al., 2018b)</ref> 74.5 73.5 Coarse2Fine <ref type="bibr" target="#b9">(Dong and Lapata, 2018)</ref> 79.0 78.5 SQLova <ref type="bibr" target="#b13">(Hwang et al., 2019)</ref> 87.2 86.2 X-SQL <ref type="bibr" target="#b11">(He et al., 2019)</ref> 89.5 88.7 <ref type="table">Table 4</ref>: Results on WIKISQL. We compare accuracy with weakly-supervised or fully-supervised settings. Our method outperforms previous weakly-supervised methods and most of published fully-supervised methods.</p><p>swer. The equation to derive the answer is not given, and <ref type="bibr" target="#b10">Dua et al. (2019)</ref> adopted the MML objective. P(z i |Q, D) can take as any model which generates equations based on the question and document. Inspired by <ref type="bibr" target="#b10">Dua et al. (2019)</ref>, we take a sequence tagging approach on top of two competitive models: (i) augmented QANET, the same model as <ref type="bibr" target="#b10">Dua et al. (2019)</ref> but only supporting addition, subtraction and counting, and (ii) augmented BERT, which supports addition, subtraction and percentiles. 7</p><p>Training details. We truncate the document to be up to 400 words. We use the batch size of 14 7 As we use a different set of operations for the two models, they are not directly comparable. Details of the model architecture are shown in Appendix A. and 10 for QANET and BERT, respectively.</p><p>Results. <ref type="table" target="#tab_3">Table 3</ref> shows the results on DROP num . Our training strategy outperforms the First-Only baseline and MML by a large margin, consistently across two base models. In particular, with BERT, we achieve an absolute gain of 10%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">SQL Query Generation</head><p>Finally, we experiment on the weakly-supervised setting of WIKISQL <ref type="bibr" target="#b42">(Zhong et al., 2017)</ref>, in which only the question &amp; answer pair is used and the SQL query (z) is treated as a latent variable. P(z i |Q, H) can be computed by any query generation or semantic parsing models. We choose SQLova <ref type="bibr" target="#b13">(Hwang et al., 2019</ref>), a competitive model on WIKISQL (designed for fully supervised setting), as our base model. We modify the model to incorporate either the MML objective or our hard-EM learning approach for the weakly-supervised setting.</p><p>We compare with both traditional and recentlydeveloped reward-based algorithms for weak supervision, including beam-based MML (MML which keeps a beam during training), conventional hard EM 8 , REINFORCE (Williams, 1992), iterative ML <ref type="bibr" target="#b21">(Liang et al., 2017;</ref><ref type="bibr" target="#b0">Abolafia et al., 2018)</ref> and a family of MAPO (Memory-augmented policy optimization) <ref type="bibr" target="#b22">(Liang et al., 2018;</ref><ref type="bibr" target="#b1">Agarwal et al., 2019)</ref>. For a fair comparison, we only consider single models without execution-guided decoding.</p><p>Training details. We adopt the same set of hyperparameters as in <ref type="bibr" target="#b13">Hwang et al. (2019)</ref>, except that we change the batch size to 10 and truncate the input to be up to 180 words. Results. <ref type="table">Table 4</ref> shows that our training method significantly outperforms all the weaklysupervised learning algorithms, including 10% gain over the previous state of the art. These results indicate that precomputing a solution set and training a model through hard updates play a significant role to the performance. Given that our method does not require SQL executions at training time (unlike MAPO), it provides a simpler, more effective and time-efficient strategy.</p><p>Comparing to previous models with full supervision, our results are still on par and outperform most of the published results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis</head><p>In this section, we will conduct thorough analyses and ablation studies, to better understand how our model learns to find a solution from a precomputed set of possible solutions. We also provide more examples and analyses in Appendix C.</p><p>Varying the size of solution set at inference time. <ref type="figure">Figure 2</ref> shows a breakdown of the model accuracy with respect to the size of a solution set (|Z|) at test time. We observe that the model with our training method outperforms the model with MML objective consistently across different values of |Z|. The gap between MML and our method is marginal when |Z| = 0 or 1, and gradually increases as |Z| grows.</p><p>Varying the size of solution set at training. To see how our learning method works with respect to the size of a solution set (|Z|) of the training data, particularly with large |Z|, we take 5 subsets of the training set on WIKISQL with |Z| = 3, 10, 30, 100, 300. We train a model with those subsets and evaluate it on the original development set, both with our training method and MML objective. <ref type="figure">Figure 3</ref> shows statistics of each subset and results. We observe that (i) our learning method outperforms MML consistently over different values of |Z|, and (ii) the gain is particularly large when |Z| &gt; 3.</p><p>Model predictions over training. We analyze the top 1 prediction and the likelihood of z ∈ Z assigned by the model on DROP num with different number of training iterations (steps from 1k to 32k). <ref type="table">Table 5</ref> shows one example on DROP num with the answer text '4', along with the model's top 1 prediction and a subset of Z. We observe that Q: How many yards longer was Rob Bironas' longest field goal compared to John Carney's only field goal? (Answer: 4) P: ... The Titans responded with Kicker Rob Bironas managing to get a 37 yard field goal. ...Tennessee would draw close as Bironas kicked a 37 yard field goal. The Chiefs answered with kicker John Carney getting a 36 yard field goal. The Titans would retake the lead with Young and Williams hooking up with each other again on a 41 yard td pass. ...Tennessee clinched the victory with Bironas nailing a 40 yard and a 25 yard field goal.</p><p>t Pred Z (ordered by P(z|x; θt)) 1k 10-9 10-6 41-37 40-36 41-37 ‡ 2k 37-36 40-36 41-37 41-37 ‡ 10-6 4k 40-36 40-36 41-37 ‡ 41-37 10-6 8k 40-36 40-36 41-37 ‡ 41-37 10-6 16k 37-36 40-36 41-37 41-37 ‡ 10-6 32k 40-36 40-36 41-37 41-37 ‡ 10-6 <ref type="table">Table 5</ref>: An example from DROP num (same as <ref type="figure" target="#fig_0">Figure 1</ref> and <ref type="table">Table 2)</ref>, with its answer text '4' and a subset of the solution set (Z), containing two of '41-38' (which '41' come from different mentions; one denoted by ‡ for distinction), '40-36' and '10-4'. For each training step t, the top 1 prediction and Z ordered by P (z|x; θ t ), a probability of z ∈ Z with respect to the model at t through training procedure are shown. Note that at inference time Z is not given, so top 1 prediction is not necessarily an element of Z. the model first begins by assigning a small, uniform probability distribution to Z, but gradually learns to favor the true solution. The model sometimes gives the wrong prediction-for example, at t = 16k, and changes its prediction from the true solution to the wrong solution, '37-36'-but again changes its prediction to be a true solution afterward. In addition, its intermediate wrong solution, '37-36' indicates the model was confused with distinguishing the longest field goal of Rob Bironas (40 vs. 37), which is an understandable mistake.</p><p>We also compare the predictions from the model with our method to those from the model with MML, which is shown in Appendix C.</p><p>Quality of the predicted solution. We analyze if the model outputs the correct solution, since the solution executing the correct answer could be spurious. First, on NARRATIVEQA and DROP num , we manually analyze 50 samples from the development set and find that 98% and 92% of correct cases produce the correct solution respectively. Next, on WIKISQL, we compare the predictions from the model to the annotated SQL queries on the development set. This is possible because gold SQL queries are available in the dataset for the full supervision. Out of 8,421 examples, 7,110 predictions execute the correct answers. Among those, 88.5% of the predictions are exactly same as the annotated queries. Others are the cases where (i) both queries are correct, (ii) the model prediction is correct but the annotated query is incorrect, and (iii) the annotated query is correct and the model prediction is spurious. We show a full analysis in Appendix C.</p><p>Robustness to the noise in |Z|. Sometimes noise arises during the construction of |Z|, such as |Z| constructed based on ROUGE-L for NARRA-TIVEQA. To explore the effect of noise in Z, we experiment with more noisy solution set by picking all the spans with scores that is equal to or larger than the 5th highest. The new construction method increases |Z| from 4.3 to 7.1 on NARRA-TIVEQA. The result by MML objective drops significantly (56.07→ 51.14) while the result by ours drops marginally (58.77→ 57.97), suggesting that MML suffers more with a noisier Z while ours is more robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we demonstrated that, for many QA tasks which only provide the answer text as supervision, it is possible to precompute a discrete set of possible solutions that contains one correct option. Then, we introduced a discrete latent variable learning algorithm which iterates a procedure of predicting the most likely solution in the precomputed set and further increasing the likelihood of that solution. We showed that this approach significantly outperforms previous approaches on six QA tasks including reading comprehension, opendomain QA, discrete reasoning task and semantic parsing, achieving absolute gains of 2-10% and setting the new state-of-the-art on five wellstudied datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Model details</head><p>We describe the detailed model architecture used as a base model. In other words, we describe how we obtain P(z|x; θ).</p><p>The following paragraphs describe (i) BERT extractive model used for multi-mention RC (Section 5.1) and (ii) BERT sequence tagging model for discrete reasoning task (Section 5.2), respectively. For QANET for discrete reasoning and the model for SQL generation (Section 5.3), we use the open-sourced code of the original implementation 9 of <ref type="bibr" target="#b10">Dua et al. (2019)</ref> and <ref type="bibr" target="#b13">Hwang et al. (2019)</ref> and do not make any modification except the objective function, so we refer to original papers.</p><p>All implementations are done in Pytorch <ref type="bibr" target="#b27">(Paszke et al., 2017)</ref>. For BERT, we modify the open-sourced implementation in PyTorch 10 and use the uncased version of BERT base .</p><p>Extractive QA model for multi-mention RC The model architecture is closed to that of <ref type="bibr" target="#b25">Min et al. (2019)</ref> and <ref type="bibr" target="#b2">Alberti et al. (2019)</ref>, where the model operates independently on each paragraph, and selects the best matching paragraph and its associated answer span.</p><p>The input is a question Q and a set of paragraphs {P 1 , . . . , P N }, and the desired output is a span from one of paragraphs. Since our goal is to compute a probability of a specific span, z, let's say z is s-th through e-th word in k-th paragraph.</p><p>The model receives a question Q and a single paragraph P i in parallel. Then, S i = Q : [SEP] : P , a list of m + n i + 1 words, where : indicates a concatenation, [SEP] is a special token, m is the length of Q, and n i is the length of P i . This S i is fed into BERT:</p><formula xml:id="formula_6">S i = BERT(S) ∈ R h×(m+n i +1)</formula><p>where h is the hidden dimension of BERT. Then,</p><formula xml:id="formula_7">p i,start = Softmax S T i W 1 ∈ R m+n i +1 p i,end = Softmax S T i W 2 ∈ R m+n i +1</formula><p>where W 1 , W 2 ∈ R h are learnable vectors. 9 https://github.com/allenai/allennlp/ blob/master/allennlp/models/reading_ comprehension/naqanet.py and https: //github.com/naver/sqlova 10 https://github.com/huggingface/ pytorch-pretrained-BERT Finally, the probability of z, s-th through e-th word in i-th paragraph, is obtained by:</p><formula xml:id="formula_8">P(z|Q, P i ) = p s i,start × p e i,end</formula><p>where p d denotes d-th element of the vector p. Separately, a paragraph selector is trained through</p><formula xml:id="formula_9">p i,exit = Softmax W 3 maxpool(S i ) ∈ R 2 where W 3 ∈ R h×2 is learnable vector. At in- ference time, k = argmax i p 1</formula><p>i,exit is computed and P(z|Q, P k ) is only considered to output a span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequence Tagging model for discrete reasoning</head><p>The basic idea of the model is closed to that of <ref type="bibr" target="#b10">Dua et al. (2019)</ref>. The input is a question Q and a paragraph P . Our goal is to compute a probability of an equation, z = (o 1 , n 1 , o 2 , n 2 ), where o 1 , o 2 ∈ {+, −, * 0.01} and n 1 , n 2 ∈ N P ∪N Q ∪S, N P and N Q are all numeric values appearing in P and Q, and S are a set of predefined special numbers. 11 .</p><p>First, BERT encodings of the question and the paragraph is obtained viā</p><formula xml:id="formula_10">S = BERT(Q : [SEP] : P ) ∈ R h×(m+n+1)</formula><p>where : indicates a concatenation, [SEP] is a special token, m is the length of Q, n is the length of P , and h is the hidden dimension of BERT. Then,</p><formula xml:id="formula_11">p input = Softmax S T W 1 ∈ R (m+n+1)×4 p special = Softmax maxpool(S)W 2 ∈ R |S|×4</formula><p>where W 1 ∈ R h×4 and W 2 ∈ R h×|S|×4 are learnable matrices. Then,</p><formula xml:id="formula_12">P(z|x) = Π m+n+1 i=1 p g(i) input Π |S| j=1 p h(j) special where g(i) =      α(o 1 ) if [Q : [SEP] : P ] i = n 1 α(o 2 ) if [Q : [SEP] : P ] i = n 2 0 o.w. h(j) =      α(o 1 ) if S j = n 1 α(o 2 ) if S j = n 2 0 o.w. α(o) =      1 if o = '+' 2 if o = '-' 3 if o = '*0.01'</formula><p>Here, subscript i of the vector or the sequence indicate i-th dimension of the vector or i-th element of the sequence, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Annealing</head><p>To prevent the model to be optimized on early decision of the model, we perform annealing: at training step t, the model optimizes on MML objective with a probability of min(t/τ , 1) and otherwise use our objective, where τ is a hyperparameter. We observe that the performance is improved by annealing while not being sensitive to the hyperparameter τ . Ablations and chosen τ for each dataset are shown in <ref type="table" target="#tab_5">Table 6</ref>. Note that for DROP num with QANET and WIKISQL, we do not ablate with varying τ and just report the number without annealing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Examples</head><p>To see if the prediction from the model is the correct solution to derive the answer, we analyze outputs from the model.</p><p>TRIVIAQA. <ref type="table" target="#tab_7">Table 7</ref> shows one example from TRIVIAQA where the answer text (Montgomery) is mentioned in the paragraph multiple times. Predictions from the model with our training method and that with MML objective are shown in the red text and the blue text, respectively. The span predicted by the model with our method actually answers to the question, while other spans with the answer text is not related to the question.</p><p>DROP num .  Question &amp; Passage Q: How many sports are not olympic sports but are featured in the asian games ? (A: 10) P: The first 30 sports were announced by the singapore national olympic council on 10 december 2013 on the sidelines of the 27th sea games in myanmar. It announced then that there was room for as many as eight more sports. On 29 april 2014 the final six sports namely boxing equestrian floorball petanque rowing and volleyball were added to the programme. Floorball will feature in the event for the first time after being a demonstration sport in the 2013 edition. In its selection of events the organising committee indicated their desire to set a model for subsequent games in trimming the number of 'traditional' sports to refocus on the seag' s initial intent to increase the level of sporting excellence in key sports. Hence despite room for up to eight traditional sports only two floorball and netball were included in the programme. Amongst the other 34 sports 24 are olympic sports and all remaining sports are featured in the asian games.  <ref type="table" target="#tab_6">Table 8</ref>: An example from DROP num , with its answer text '10' and a subset of Z, containing '10', two of 'eight+two' (which 'eight' come from different mentions; one denoted by ' ‡' for distinction) and '34-24'. The below tables are predictions from the model with our training strategy (left) and MML (right). For each training step t, the top 1 prediction and Z ordered by P (z|x; θ t ), a probability of z ∈ Z with respect to the model at t are shown. Note that at inference time Z cannot be obtained, so top 1 prediction is not necessarily in Z.  <ref type="table">Table 9</ref>: Four examples from WIKISQL where the prediction from the model is different from annotated SQL query, although the executed answers are the same. Q, H, A and P indicate the given question, the given table header, annotated SQL query and predicted SQL query. First two example shows the case where both queries are correct. Next example shows the case that the model prediction makes more sense than the annotated query. The last example shows the cases that the annotated query makes more sense than the model prediction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Examples from two different question answering tasks. (Top) Multi-mention reading comprehension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Varying the size of solution set (|Z|) at test time. We compare the model trained on MML objective (blue) and our training strategy (orange). Our approach consistently outperforms MML on DROP num and WIKISQL, especially when |Z| is large.Group Avg |Z| Median |Z| # Varying the size of solution set (|Z|) at training. (Left) Subsets of the train set on WIKISQL varying in the size of solution set (|Z|). All subsets contain 10k training examples (total in the original train set is 55k). All subsets are evaluated on the same, original development set for a fair comparison. (Right) Performance across subsets of the training set with varying |Z|. Our method achieves substantial gains over MML.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>arXiv:1909.04849v1 [cs.CL] 11 Sep 2019</figDesc><table><row><cell>Task &amp; Dataset</cell><cell>Train</cell><cell># Examples Dev</cell><cell>Test</cell><cell>Avg</cell><cell>|Z| Median</cell></row><row><cell>1. Multi-mention reading comprehension</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TRIVIAQA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table Header :</head><label>Header</label><figDesc>player, year, position, ...</figDesc><table><row><cell>Answer (y): John Long</cell></row><row><cell>f : SQL executor</cell></row><row><cell>Ztot: Non-nested SQL queries with up to 3 conditions</cell></row><row><cell>Z: Select player where position=guard and year in toronto=1996-97</cell></row><row><cell>Select max(player) where position=guard and year in toronto=1996-97</cell></row><row><cell>Select min(player) where position=guard</cell></row><row><cell>Select min(player) where year in toronto=1996-97</cell></row><row><cell>Select min(player) where position=guard and year in toronto=1996-97</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results on multi-mention reading comprehension &amp; discrete reasoning tasks. We report performance on five datasets with different base models. Note that we are not able to obtain the test result on the subset DROP num . Previous state-of-the-art are from<ref type="bibr" target="#b34">Wang et al. (2018)</ref>,<ref type="bibr" target="#b26">Nishida et al. (2019)</ref>,, and<ref type="bibr" target="#b10">Dua et al. (2019)</ref>, respectively. Our training method consistently outperforms the First-Only and MML by a large margin in all the scenarios.</figDesc><table><row><cell>Model</cell><cell cols="2">Accuracy</cell></row><row><cell></cell><cell>Dev</cell><cell>Test</cell></row><row><cell>Weakly-supervised setting</cell><cell></cell><cell></cell></row><row><cell>REINFORCE (Williams, 1992)</cell><cell>&lt; 10</cell><cell></cell></row><row><cell>Iterative ML (Liang et al., 2017)</cell><cell>70.1</cell><cell></cell></row><row><cell>Hard EM (Liang et al., 2018)</cell><cell>70.2</cell><cell></cell></row><row><cell>Beam-based MML (Liang et al., 2018)</cell><cell>70.7</cell><cell></cell></row><row><cell>MAPO (Liang et al., 2018)</cell><cell>71.8</cell><cell>72.4</cell></row><row><cell>MAPOX (Agarwal et al., 2019)</cell><cell>74.5</cell><cell>74.2</cell></row><row><cell>MAPOX+MeRL (Agarwal et al., 2019)</cell><cell>74.9</cell><cell>74.8</cell></row><row><cell>MML</cell><cell>70.6</cell><cell>70.5</cell></row><row><cell>Ours</cell><cell>84.4</cell><cell>83.9</cell></row><row><cell>Fully-supervised setting</cell><cell></cell><cell></cell></row><row><cell>SQLNet (Xu et al., 2018)</cell><cell>69.8</cell><cell>68.0</cell></row><row><cell>TypeSQL</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>(Left) Ablations with varying values of τ on TRIVIAQA. (Middle) Ablations with varying values of τ on DROP num with BERT. (Right) Final τ chosen for the main results on each dataset. Note that for DROP num with QANET and WIKISQL, we just report the number without annealing.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>WIKISQL. WIKISQL provides the annotated SQL queries, makes it easy to compare the predictions from the model to the annotated queries. Out of 8421 examples from the development set, 7110 predictions execute the correct answers. Among those, 6296 predictions are exactly same as the annotated queries. For cases where the predictions execute the correct answers but are not exactly same as the groundtruth queries, we show four examples inTable 9. In the first example, both the annotated query and the prediction are correct, because the selected column does not matter for counting. Similarly in the second example, both queries are correct because Capital (exonym) and Capital (endonym) both indicate the capital city. In the third example, the prediction makes more sense than the annotated query because the question does not imply anything about min. In the last example, the annotated query makes more sense than the prediction because the prediction misses Ship Type = battleship. We conjecture that the model might learn to ignore some information in the question if the table header implies the table is specific about that information, hence does not need to condition on that information. What is the state capital of Alabama? (Groundtruth: Montgomery) D: Alabama is nicknamed the Yellowhammer State, after the state bird. Alabama is also known as the "Heart of Dixie" and the "Cotton State". The state tree is the longleaf pine, and the state flower is the camellia. Alabama's capital is Montgomery. (...) From 1826 to 1846, Tuscaloosa served as Alabama's capital. On January 30, 1846, the Alabama legislature announced it had voted to move the capital city from Tuscaloosa to Montgomery. The first legislative session in the new capital met in December 1847. A new capitol building was erected under the direction of Stephen Decatur Button of Philadelphia. The first structure burned down in 1849, but was rebuilt on the same site in 1851. This second capitol building in Montgomery remains to the present day.</figDesc><table><row><cell>shows predictions from the</cell></row><row><cell>model with our method and that with MML ob-</cell></row><row><cell>jective over training procedure. We observe that</cell></row><row><cell>the model with our method learns to assign a high</cell></row><row><cell>probability to the best solution ('34-24'), while the</cell></row><row><cell>model with MML objective fails to do so. An-</cell></row><row><cell>other notable observation is that the model with</cell></row><row><cell>our method assign sparse distribution of likelihood</cell></row><row><cell>over Z, compared to the model with MML objec-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>An example from TRIVIAQA with multiple spans of the answer text (underlined). The model trained with self-training technique outputs the correct answer (red) and the model trained on MML objective does not (blue).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Q</head><label></label><figDesc>How many times was the # of total votes 2582322? H Election, # of candidates nominated, # of seats won, # of total votes, % of popular vote A Select count(# of seats won) where # of total votes = 2582322 P Select count(Election) where # of total votes = 2582322 Q What official or native languages are spoken in the country whose capital city is Canberra? H Country (exonym), Capital (exonym), Country (endonym) Capital (endonym), Official or native language A Select Official or native languages where Capital (exonym) = Canberra P Select Official or native languages where Capital (endonym) = Canberra Q What is the episode number that has production code 8abx15? H No. in set, No. in series, Title, Directed by, Written by, Original air date, Production code A Select min(No.in series) where Production code = 8ABX15 P Select No.in series where Production code = 8abx15 Q what is the name of the battleship with the battle listed on May 13, 1915? H Estimate, Name, Nat., Ship Type, Principal victims, Date A Select Name where Ship Type = battleship and Date = may 13, 1915 P Select Name where Date = may 13, 1915</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code is publicly available at https://github. com/shmsw25/qa-hard-em.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This is a main difference from multi-instance learning (MIL)<ref type="bibr" target="#b43">(Zhou et al., 2009)</ref>, since a bag of input instances is given at inference time in MIL.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This approximation covers 93% of the examples in the development set.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This approximation covers 99% of the examples in the development set.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Following, we treat the dev set as the test set and split the train set into 90/10 for training and development. Datasets and their split can be downloaded from https://bit.ly/2HK1Fqn.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">For NARRATIVEQA, we compare with models trained on NARRATIVEQA only. For open-domain QA, we only compare with models using pipeline approach.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">This method differs from ours in that it does not have a precomputed set, and uses a beam of candidate predictions to execute for each update.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">S = {1,2, 3, 4, 5, 7, 10, 12, 100, 1000}   </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported by ONR (N00014-18-1-2826, N00014-17-S-B001), DARPA N66001-19-2-403, NSF (IIS-1616112, IIS-1252835, IIS-1562364), ARO (W911NF-16-1-0121), an Allen Distinguished Investigator Award, Samsung GRO and gifts from Allen Institute for AI, Google and Amazon.</p><p>The authors would like to thank the anonymous reviewers, Eunsol Choi, Christopher Clark, Victor Zhong and UW NLP members for their valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Daniel A Abolafia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03526</idno>
		<title level="m">Neural program synthesis with priority queue training</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to generalize from sparse and underspecified rewards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A BERT baseline for the Natural Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08634</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08113</idno>
		<title level="m">SQL: reinforce schema representation with context</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Comparing measures of sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niall</forename><surname>Hurley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Rickard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Information Theory</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonseok</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyeung</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01069</idno>
		<title level="m">A comprehensive exploration on WikiSQL with table-aware word contextualization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Search-based neural structured learning for sequential question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Text understanding with the attention sum reader network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bajgar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The NarrativeQA reading comprehension challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočiskỳ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural semantic parsing with type constraints for semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Petrov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural symbolic machines: Learning semantic parsers on Freebase with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Memory augmented policy optimization for program synthesis and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="389" to="446" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">ROUGE: A package for automatic evaluation of summaries. Text Summarization Branches Out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Compositional questions do not necessitate multi-hop reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-style generative reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itsumi</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazutoshi</forename><surname>Shinoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisako</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junji</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The probabilistic relevance framework: BM25 and beyond. Foundations and Trends R in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Multi-mention learning for reading comprehension with neural cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MultiQA: An empirical investigation of generalization and transfer in reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Densely connected attention propagation for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><forename type="middle">Tuan</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siu</forename><forename type="middle">Cheung</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multigranularity hierarchical attention fusion networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DCN+: Mixed objective and deep residual coattention for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SQL-Net: Generating structured queries from natural language without reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fast and accurate reading comprehension by combining self-attention and convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">TypeSQL: Knowledgebased type-aware neural text-to-sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2SQL: Generating structured queries from natural language using reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multi-instance learning by treating instances as noni.i.d. samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Yin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Feng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
