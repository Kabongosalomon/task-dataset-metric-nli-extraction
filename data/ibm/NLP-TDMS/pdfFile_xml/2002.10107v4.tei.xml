<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Subjective Features of Questions of QA Websites using BERT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issa</forename><surname>Annamoradnejad</surname></persName>
							<email>moradnejad@ce.sharif.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Sharif University of Technology Tehran</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadamin</forename><surname>Fazli</surname></persName>
							<email>fazli@sharif.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Sharif University of Technology Tehran</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jafar</forename><surname>Habibi</surname></persName>
							<email>jhabibi@sharif.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Sharif University of Technology Tehran</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Subjective Features of Questions of QA Websites using BERT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Q&amp;A websites</term>
					<term>Subjective features</term>
					<term>Quality prediction</term>
					<term>Transfer learning</term>
					<term>BERT</term>
					<term>NLP</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Community Question-Answering websites, such as StackOverflow and Quora, expect users to follow specific guidelines in order to maintain content quality. These systems mainly rely on community reports for assessing contents, which has serious problems such as the slow handling of violations, the loss of normal and experienced users' time, the low quality of some reports, and discouraging feedback to new users. Therefore, with the overall goal of providing solutions for automating moderation actions in Q&amp;A websites, we aim to provide a model to predict 20 quality or subjective aspects of questions in QA websites. To this end, we used data gathered by the CrowdSource team at Google Research in 2019 and a fine-tuned pre-trained BERT model on our problem. Based on the evaluation by Mean-Squared-Error (MSE), the model achieved a value of 0.046 after 2 epochs of training, which did not improve substantially in the next ones. Results confirm that by simple fine-tuning, we can achieve accurate models in little time and on less amount of data. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In recent years, online Q&amp;A websites have attracted many users and are considered as reliable sources by experts from various fields. These websites provide an interface for users to exchange and share knowledge. The user asking a question lacks knowledge of a specific topic and experts on the same topic provide the desired knowledge. In this way, questions and answers are the source of information, replacing other sources like documents or databases <ref type="bibr" target="#b0">[1]</ref>.</p><p>These systems, in addition to general user rules, have specific rules to maintain their content quality. Question quality is essential both for the personal use of users and for the question and answering platforms as a whole, because high-quality question-answer pairs attract more users and improve platform traffic <ref type="bibr" target="#b1">[2]</ref>. Therefore, detecting, removing or editing low-quality questions is a necessary step for the success of websites.</p><p>Due to the vast expanse of some of these systems in terms of the number of users, manual check and verification of new content by the administrators and official moderators are not feasible, and these systems require scalable solutions. In major Q&amp;A networks, such as Stack Exchange websites 2 , the current strategy is to use crowdsourcing and reliance on user reports. This strategy has serious problems, including the slow handling of violations, the loss of normal and experienced users' time, the low quality of user reports, and discouraging feedback to new users.</p><p>With the overall goal of providing solutions for automating moderation actions in Q&amp;A websites, in this research, we plan to provide a model that could predict 20 quality or subjective aspects of questions. Since these aspects include questions about opinions, recommendations, or personal experiences, they are harder to answer by computer than questions with single, verifiable answers <ref type="bibr" target="#b2">[3]</ref>.</p><p>Given the need to maintain quality standards for the contents of online Q&amp;A communities and the significant problems of crowdsourcing, providing solutions and models for automatically detecting user violations can bring upon faster detection of user violations (such as detection of spam, advertisement, grammar faults, etc) and therefore, saving users time and improve the quality of the contents.</p><p>Unfortunately, it is hard to build subjective questionanswering algorithms, because of a lack of data and predictive models. In this article, we use data gathered by the CrowdSource team at Google Research, a group dedicated to advancing NLP and other types of ML science via crowdsourcing <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. We used this new data set to build predictive algorithms for different subjective aspects of question quality.</p><p>Transfer Learning allowed researchers to smash multiple benchmarks with minimal task-specific fine-tuning and provided the rest of the NLP community with pre-trained models that could easily with less data and less compute time be finetuned to produce state of the art results <ref type="bibr" target="#b5">[6]</ref>. Google's BERT is one of these models that theoretically allows us to smash multiple benchmarks with minimal task-specific fine-tuning <ref type="bibr" target="#b6">[7]</ref>. Therefore, this paper aims at predicting different subjective aspects of questions in question-answering websites using BERT. Since the task is to predict values of 20 target qualities of questions, which they are all related to the question title and body, therefore, those that relate to the answer feature are excluded from this research.</p><p>The structure of this article is as follows: Section 2 reviews past works on quality prediction of questions in QA websites and latest NLP models. Section 3 explains the data and section 4 elaborates on the methodology. In Section 5, evaluation of the experiment is presented, and Section 6 is the concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LITERATURE REVIEW</head><p>A few works focused on quantifying the quality of a question by analyzing their features. Research has shown that too short questions have a low probability of obtaining an answer <ref type="bibr" target="#b7">[8]</ref>.</p><p>Another study analyzed unanswered questions in Stackoverflow and found that answered questions have higher scores compared to unanswered questions <ref type="bibr" target="#b8">[9]</ref>.</p><p>In <ref type="bibr" target="#b9">[10]</ref> authors find that the number of answers is the most significant feature to predict the long-term value of a question together with its answers set and it is direct feedback on the usefulness/quality of the question. However, this proposed feature cannot be used on new questions since they are yet to be answered.</p><p>Transfer learning, particularly models like ULMFiT, Allen AI's ELMO, and Google's BERT, focuses on storing knowledge gained from training on one problem and applying it to a different but related problem (usually after simple fine-tuning on small amount of data).</p><p>The first transfer learning method in Natural Language Processing (NLP) was Universal Language Model Fine-tuning for Text Classification (ULMFiT) method <ref type="bibr" target="#b10">[11]</ref> that fine tunes the language model on a new data set after training a language model on a preliminary data set, such as Wikitext. Finally, the resulting fine-tuned language model can be used in a prediction task for a new data set. The model, besides significantly outperforming many state-of-the-art tasks, was done by training on only 100 labeled examples, that matched performances equivalent to old models trained on 100× more data.</p><p>ELMo is another related study that includes task-specific architectures and uses the pre-trained representations as additional features <ref type="bibr" target="#b11">[12]</ref>. It is a deep contextualized word representation that represented complex characteristics of word use (e.g., syntax and semantics). The BERT language model consists of several transformer encoders stacked together and is designed from unlabeled text to pretrain deep bidirectional representations by jointly conditioning on left and right context in all layers <ref type="bibr" target="#b6">[7]</ref>. They presented two general types, named the BERT-base and the BERT-large, which used the BooksCorpus with 800M words <ref type="bibr" target="#b12">[13]</ref> and English Wikipedia with 2,500M words <ref type="bibr" target="#b13">[14]</ref>, respectively. The characteristics of these models are presented below (L is the number of stacked encoders, H the hidden layer size, and A the number of self-attention heads): In this section, we will briefly explain our used data set, alongside some general statistics on the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data</head><p>The CrowdSource team at Google Research, a group dedicated to advancing NLP and other types of ML science via crowdsourcing, has collected data on a number of quality scoring aspects of questions and answers from QA websites in 2019. The questions consists of 5 categories: "Technology", "Stackoverflow", "Culture", "Science", "Life arts" and was collected from nearly 70 different stack exchange websites. Reportedly, raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common sense to complete the task <ref type="bibr" target="#b2">[3]</ref>.</p><p>Data is relatively small, only made of 6079 rows. It originally contains 40 columns, of which 10 are given as basic features (question title, body, answer …) and the rest are target quality labels. Of the 10 feature columns, we only used 'question_title' and 'question_body' for the purposes of this study and the rest is excluded. From the 30 target columns, 21 are related to the question and the remaining 9 columns are related to answer quality. Thus, we excluded columns related to answer from the data set. Finally, we removed 'question_body_critical' column, as its intent and meaning was not clear to us and no definition was given. <ref type="table" target="#tab_0">Table 1</ref> gives the name and description of the selected target columns that we focus in this research. As we said earlier, target labels are aggregated from multiple raters and have continuous values in the range [0,1]. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2 Correlation heat-map for the target columns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. General Statistics and EDA</head><p>In this section, we introduce a few general statistics on the data set. <ref type="figure" target="#fig_0">Figure 1</ref> depicts distribution of the selected target values.</p><p>Since the values are real values, we used 'numpy.linspace' to create 10 sub-ranges (0.1 each) for the purposes of this depiction. We can see that most of the columns, such as 'question_asker_intent_understanding' and 'question_conversational', are unevenly distributed and aggregated in one side value (0 or 1). <ref type="figure">Figure 2</ref> depicts correlation heat-map for the values of the target columns. We can barely view any strong correlation (lighter color) between the values of these columns. However, we can see a few anti-correlations (dark colors), such as conversation vs. fact, conversational vs. has commonly accepted answer, and fact-seeking vs. opinion-seeking.</p><p>Even though, because of our pre-trained model we do not require to perform feature extraction/engineering, we extracted a few simple features and depicted their correlation with target values. This was done to better understand the underlying latent relationships in data. To this end, we extracted character count and word count on question title and body, punctuations count in question body, and number of duplicate words, duplication rate, and number of sentences in question body. Correlation of these extracted features with target columns are depicted in <ref type="figure" target="#fig_2">Figure 3</ref>. We can see that the extracted features do not have string correlations with the target values (coefficient between -0.17 to +0.25).</p><p>Finally, we performed sentiment analysis on the question body to extract polarity and subjectivity of texts. The mean for polarity is positive, while the questions are prone to be objective. Scatter plot for this analysis is depicted in <ref type="figure" target="#fig_3">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPOSED METHOD</head><p>We used transfer learning from pre-trained transformers. Ref <ref type="bibr" target="#b6">[7]</ref> introduced a new language representation model called BERT, which was described partially in Section II. BERT stands for Bidirectional Encoder Representations from Transformers and is a multi-layer bidirectional Transformer encoder. The architecture is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.</p><p>In using pre-trained BERT model, the steps are: (1) plug in the task specific inputs and outputs into BERT and (2) fine-tune all the parameters end-to-end. Therefore, by fine-tuning pretrained BERT model we can get away with traditional training. Our instance loops over the folds in GroupKFold and trains each fold for 5 epochs with a batch_size of 6. A binary crossentropy is used as the objective loss function. We did not alter any of the BERT default parameters; however, we did perform the finetuning on our data for learning rate values between 1e-5 to 9e-5.</p><p>We used 'tensorflow' and 'huggingface transformers' libraries in python for our base model, and sklearn, pandas, numpy, matplotlib and math libraries for data loading, additional preprocessing, and evaluation metrics.</p><p>HuggingFace created the well-known transformers library, formerly known as 'pytorch-transformers' or 'pytorchpretrained-BERT', it brings together over 40 state-of-the-art pretrained NLP models (BERT, GPT-2, RoBERTa, CTRL…) <ref type="bibr" target="#b14">[15]</ref>. The implementation gives interesting additional utilities like tokenizer, optimizer or scheduler that we utilized in the implementation of this paper. While the transformers library can be self-sufficient, but incorporating it within the 'fastai' library provides simpler implementation compatible with powerful fastai tools like Discriminate Learning Rate, Gradual Unfreezing or Slanted Triangular Learning Rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preprocessing</head><p>We performed the default model specific tokenizers provided by 'huggingface'. For target variables, first we applied rank transform method (values are replaced with their corresponding ranks) and then, we continued with min-max scaling. This made the target values evenly distributed between 0 and 1.</p><p>We defined the maximum sequence length that will be used for the input to BERT (maximum is usually 512 tokens). Due to the 2 x 512 input, it will require significantly more memory when fine-tuning BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EVALUATION</head><p>We used 80% of data for training and 20% (1216 rows) for validation. Mean squared error was utilized on the validation set   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this study, we experiment the BERT model to solve a part of the problem of moderation actions in QA websites. To be specific, we used BERT to predict 20 quality or subjective aspects of questions in QA websites. Predicting subjective aspects is a hard problem with computers and we showed that it could benefit from transfer learning from pre-trained transformers.</p><p>Our model achieved MSE with a value of 0.046 in predicting target values. Results confirm that by simple fine-tuning pretrained BERT model, we can achieve high accuracy, in little time, and on less amount of data.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Distribution of 21 target values. Values between 0 and 1; total sample size=6079.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>BERT-base: L:12, H: 768, A:12, Parameters: 110M 2. BERT-large: L:24, H:1024, A:16, Parameters: 340M III. DATA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3</head><label>3</label><figDesc>Correlation heat-map between extracted sample features and target values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4</head><label>4</label><figDesc>Results of sentiment analysis on question bodyto gain the accuracy of the model. Based on our results (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Name and description of target columns</figDesc><table><row><cell>Target Column</cell><cell>Column description</cell></row><row><cell>1 asker intent</cell><cell>Is the question's intent understood</cell></row><row><cell>understanding</cell><cell>well?</cell></row><row><cell>2 conversational</cell><cell>Is the question conversational?</cell></row><row><cell>3 expect short</cell><cell>Does the question expect short</cell></row><row><cell>answer</cell><cell>answer?</cell></row><row><cell>4 fact seeking</cell><cell>Is the question looking for factual</cell></row><row><cell></cell><cell>information?</cell></row><row><cell>5 has commonly</cell><cell>Does the question has commonly</cell></row><row><cell>accepted answer</cell><cell>accepted answer?</cell></row><row><cell>6 interestingness</cell><cell>Does the question look interesting to</cell></row><row><cell>others</cell><cell>others?</cell></row><row><cell>7 interestingness</cell><cell>Does the question look interesting to</cell></row><row><cell>self</cell><cell>the asker?</cell></row><row><cell>8 multi intent</cell><cell>Does the question has multiple</cell></row><row><cell></cell><cell>intents (multiple questions inside</cell></row><row><cell></cell><cell>one)?</cell></row><row><cell>9 not really a</cell><cell>Should the question be reported as</cell></row><row><cell>question</cell><cell>not a question?</cell></row><row><cell>10 opinion seeking</cell><cell>Does the question asks for opinion-</cell></row><row><cell></cell><cell>based answers?</cell></row><row><cell>11 type choice</cell><cell>Is the question a multi-choice</cell></row><row><cell></cell><cell>question?</cell></row><row><cell>12 type compare</cell><cell>Is the question looking for</cell></row><row><cell></cell><cell>comparison between alternatives?</cell></row><row><cell>13 type</cell><cell>Is the question looking for</cell></row><row><cell>consequence</cell><cell>consequence of a possible action?</cell></row><row><cell>14 type definition</cell><cell>Is the question looking to define</cell></row><row><cell></cell><cell>something?</cell></row><row><cell>15 type entity</cell><cell>Is the question related to an entity?</cell></row><row><cell cols="2">16 type instructions Is the question looking for</cell></row><row><cell></cell><cell>instructions?</cell></row><row><cell>17 type procedure</cell><cell>Is the question about a</cell></row><row><cell></cell><cell>procedure/looking for procedure?</cell></row><row><cell>18 type reason</cell><cell>Is the question looking expects</cell></row><row><cell>explanation</cell><cell>explanation of reason?</cell></row><row><cell>19 type spelling</cell><cell>Is the question about spelling?</cell></row><row><cell>20 well written</cell><cell>Is the question well-written?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 )</head><label>2</label><figDesc>on 4864 rows, we achieved value of 0.05 for MSE in all of learning rate values after one epoch of training. After three epochs, model achieved values between 0.046 and 0.048, which did not improve in the next epochs. Our best results came from the second iteration with LR=3e-5 and LR=5e-5, where the model achieved MSE with a value of 0.046. In conclusion, we can say that epochs of training did not substantially improve model's accuracy and one epoch of training is enough to achieve an accurate model.In case of timing and performance, it took 8.76 minutes in average for each epoch on a computer with 16GB RAM and Intel(R) Xeon(R) CPU 2.00GHz.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Accuracy of our model with different LRs in 5 epochs</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code is available at: https://github.com/Moradnejad/Predicting-Subjective-Features-on-QA-Websites</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A group of 170+ QA websites in diverse fields covering specific topics, such as Stackoverflow.com, Askubuntu.com and Superuser.com.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Question quality in community question answering forums: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baltadzhieva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chrupała</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Sigkdd Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Design lessons from the fastest Q&amp;A site in the west</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mamykina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Manoim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hripcsak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hartmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2857" to="2866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Google Question Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="Available:kaggle.com/c/google-quest-challenge" />
	</analytic>
	<monogr>
		<title level="j">Kaggle</title>
		<imprint>
			<date type="published" when="2019-02-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Crowdsource -Apps on Google Play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="Available:play.google.com" />
	</analytic>
	<monogr>
		<title level="m">Google Play, 2020</title>
		<imprint>
			<date type="published" when="2020-02-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Google Crowdsource: what you need to know</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gordon</surname></persName>
		</author>
		<ptr target="Available:androidpit.com/google-crowdsource-what-you-need-to-know" />
	</analytic>
	<monogr>
		<title level="j">AndroidPIT</title>
		<imprint>
			<date type="published" when="2016-02-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">BERT Fine-Tuning Tutorial with PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryan</surname></persName>
		</author>
		<ptr target="Available:mccormickml.com/2019/07/22/BERT-fine-tuning/" />
		<imprint>
			<date type="published" when="2020-02-20" />
			<pubPlace>McCormick ML, 2019, Accessed on</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analyzing and predicting not-answered questions in community-based question answering services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Toward understanding the causes of unanswered questions in software information sites: a case study of Stack Overflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Perry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2013 9th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="663" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discovering value from community activity on focused question answering sites: a case study of Stack overflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="850" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06146</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Me</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Transfer Learning from Transformers to Fake News Challenge Stance Detection (FNC-1) Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Slovikovskaya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14353</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
		<idno>abs/1506.06724</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">towards data science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Bert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberta</forename><surname>Xlnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xlm</forename><surname>Distilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename></persName>
		</author>
		<ptr target="Available:towardsdatascience.com/fastai-with-transformers-BERT-roBERTa-xlnet-xlm-distilBERT-4f41ee18ecb2" />
	</analytic>
	<monogr>
		<title level="m">Fastai with Transformers</title>
		<imprint>
			<date type="published" when="2019-02-20" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
