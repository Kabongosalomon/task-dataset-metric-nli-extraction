<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AdaCos: Adaptively Scaling Cosine Logits for Effectively Learning Deep Face Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-05-07">7 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CUHK-SenseTime Joint Laboratory</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">SIAT-SenseTime Joint Lab</orgName>
								<orgName type="department" key="dep2">Shenzhen Institutes of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
							<email>xgwang@ee.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CUHK-SenseTime Joint Laboratory</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
							<email>hsli@ee.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CUHK-SenseTime Joint Laboratory</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">AdaCos: Adaptively Scaling Cosine Logits for Effectively Learning Deep Face Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-07">7 May 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The cosine-based softmax losses <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b7">8]</ref> and their variants <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b6">7]</ref> achieve great success in deep learning based face recognition. However, hyperparameter settings in these losses have significant influences on the optimization path as well as the final recognition performance. Manually tuning those hyperparameters heavily relies on user experience and requires many training tricks.</p><p>In this paper, we investigate in depth the effects of two important hyperparameters of cosine-based softmax losses, the scale parameter and angular margin parameter, by analyzing how they modulate the predicted classification probability. Based on these analysis, we propose a novel cosinebased softmax loss, AdaCos, which is hyperparameter-free and leverages an adaptive scale parameter to automatically strengthen the training supervisions during the training process. We apply the proposed AdaCos loss to largescale face verification and identification datasets, including LFW [13], MegaFace [16], and IJB-C [23] 1:1 Verification. Our results show that training deep neural networks with the AdaCos loss is stable and able to achieve high face recognition accuracy. Our method outperforms state-of-the-art softmax losses <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b6">7]</ref> on all the three datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent years witnessed the breakthrough of deep Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35]</ref> on significantly improving the performance of one-to-one (1 : 1) face verification and one-to-many (1 : N ) face identification tasks. The successes of deep face CNNs can be mainly credited to three factors: enormous training data <ref type="bibr" target="#b8">[9]</ref>, deep neural network architectures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref> and effective loss functions <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b6">7]</ref>. Modern face datasets, such as LFW <ref type="bibr" target="#b12">[13]</ref>, CASIA-WebFace <ref type="bibr" target="#b42">[43]</ref>, MS1M <ref type="bibr" target="#b8">[9]</ref> and MegaFace <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b15">16]</ref>, contain huge number of identities which enable the training of deep networks. A number of recent studies, such as DeepFace <ref type="bibr" target="#b35">[36]</ref>, DeepID2 <ref type="bibr" target="#b30">[31]</ref>, DeepID3 <ref type="bibr" target="#b31">[32]</ref>, VGGFace <ref type="bibr" target="#b24">[25]</ref> and FaceNet <ref type="bibr" target="#b28">[29]</ref>, demonstrated that properly designed network architectures also lead to improved performance.</p><p>Apart from the large-scale training data and deep structures, training losses also play key roles in learning accurate face recognition models <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b10">11]</ref>. Unlike image classification tasks, face recognition is essentially an open set recognition problem, where the testing categories (identities) are generally different from those used in training. To handle this challenge, most deep learning based face recognition approaches <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36]</ref> utilize CNNs to extract feature representations from facial images, and adopt a metric (usually the cosine distance) to estimate the similarities between pairs of faces during inference.</p><p>However, such inference evaluation metric is not well considered in the methods with softmax cross-entropy loss function 1 , which train the networks with the softmax loss but perform inference using cosine-similarities. To mitigate the gap between training and testing, recent works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b7">8]</ref> directly optimized cosine-based softmax losses. Moreover, angular margin-based terms <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b6">7]</ref> are usually integrated into cosine-based losses to maximize the angular margins between different identities. These methods improve the face recognition performance in the open-set setup. In spite of their successes, the training processes of cosine-based losses (and their variants introducing margins) are usually tricky and unstable. The convergence and performance highly depend on the hyperparameter settings of loss, which are determined empirically through large amount of trials. In addition, subtle changes of these hyperparameters may fail the entire training process.</p><p>In this paper, we investigate state-of-the-art cosine-based softmax losses <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b6">7]</ref>, especially those aiming at maximizing angular margins, to understand how they provide supervisions for training deep neural networks. Each of the functions generally includes several hyperprameters, which have substantial impact on the final performance and are usually difficult to tune. One has to repeat training with different settings for multiple times to achieve optimal performance. Our analysis shows that different hyperparameters in those cosine-based losses actually have similar effects on controlling the samples' predicted class probabilities. Improper hyperparameter settings cause the loss functions to provide insufficient supervisions for optimizing networks.</p><p>Based on the above observation, we propose an adaptive cosine-based loss function, AdaCos, which automatically tunes hyperparameters and generates more effective supervisions during training. The proposed AdaCos dynamically scales the cosine similarities between training samples and corresponding class center vectors (the fullyconnection vector before softmax), making their predicted class probability meets the semantic meaning of these cosine similarities. Furthermore, AdaCos can be easily implemented using built-in functions from prevailing deep learning libraries <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15]</ref>. The proposed AdaCos loss leads to faster and more stable convergence for training without introducing additional computational overhead.</p><p>To demonstrate the effectiveness of the proposed Ada-Cos loss function, we evaluated it on several face benchmarks, including LFW face verification <ref type="bibr" target="#b12">[13]</ref>, MegaFace one-million identification <ref type="bibr" target="#b23">[24]</ref> and IJB-C <ref type="bibr" target="#b22">[23]</ref>. Our method outperforms state-of-the-art cosine-based losses on all these benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Cosine similarities for inference. For learning deep face representations, feature-normalized losses are commonly adopted to enhance the recognition accuracy. Coco loss <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> and NormFace <ref type="bibr" target="#b38">[39]</ref> studied the effect of normalization and proposed two strategies by reformulating softmax loss and metric learning. Similarly, Ranjan et al. in <ref type="bibr" target="#b27">[28]</ref> also discussed this problem and applied normalization on learned feature vectors to restrict them lying on a hypersphere. Movrever, compared with these hard normalization, ring loss <ref type="bibr" target="#b44">[45]</ref> came up with a soft feature normalization approach with convex formulations.</p><p>Margin-based softmax loss. Earlier, most face recognition approaches utilized metric-targeted loss functions, such as triplet <ref type="bibr" target="#b40">[41]</ref> and contrastive loss <ref type="bibr" target="#b5">[6]</ref>, which utilize Euclidean distances to measure similarities between features. Taking advantages of these works, center loss <ref type="bibr" target="#b41">[42]</ref> and range loss <ref type="bibr" target="#b43">[44]</ref> were proposed to reduce intra-class variations via minimizing distances within each class <ref type="bibr" target="#b1">[2]</ref>. Following this, researchers found that constraining margin in Euclidean space is insufficient to achieve optimal generalization. Then angular-margin based loss functions were proposed to tackle the problem. Angular constraints were integrated into the softmax loss function to improve the learned face representation by L-softmax <ref type="bibr" target="#b18">[19]</ref> and Asoftmax <ref type="bibr" target="#b17">[18]</ref>. CosFace <ref type="bibr" target="#b39">[40]</ref>, AM-softmax <ref type="bibr" target="#b37">[38]</ref> and ArcFace <ref type="bibr" target="#b6">[7]</ref> directly maximized angular margins and employed simpler and more intuitive loss functions compared with aforementioned methods.</p><p>Automatic hyperparameter tuning. The performance of an algorithm highly depends on hyperparameter settings. Grid and random search <ref type="bibr" target="#b2">[3]</ref> are the most widely used strategies. For more automatic tuning, sequential model-based global optimization <ref type="bibr" target="#b13">[14]</ref> is the mainstream choice. Typically, it performs inference with several hyperparameters settings, and chooses setting for the next round of testing based on the inference results. Bayesian optimization <ref type="bibr" target="#b29">[30]</ref> and tree-structured parzen estimator approach <ref type="bibr" target="#b3">[4]</ref> are two famous sequential model-based methods. However, these algorithms essentially run multiple trials to predict the optimized hyperparameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Investigation of hyperparameters in cosinebased softmax losses</head><p>In recent years, state-of-the-art cosine-based softmax losses, including L2-softmax <ref type="bibr" target="#b27">[28]</ref>, CosFace <ref type="bibr" target="#b39">[40]</ref>, Arc-Face <ref type="bibr" target="#b6">[7]</ref>, significantly improve the performance of deep face recognition. However, the final performances of those losses are substantially affected by their hyperparameters settings, which are generally difficult to tune and require multiple trials in practice. We analyze two most important hyperparameters, the scaling parameter s and the margin parameter m, in cosine-based losses. Specially, we deeply study their effects on the prediction probabilities after softmax, which serves as supervision signals for updating entire neural network. Let x i denote the deep representation (feature) of the ith face image of the current mini-batch with size N , and y i be the corresponding label. The predicted classification probability P i,j of all N samples in the mini-batch can be estimated by the softmax function as</p><formula xml:id="formula_0">P i,j = e fi,j C k=1 e f i,k ,<label>(1)</label></formula><p>where f i,j is logit used as the input of softmax, P i,j represents its softmax-normalized probability of assigning x i to class j, and C is the number of classes. The cross-entropy loss associated with current mini-batch is</p><formula xml:id="formula_1">L CE = − 1 N N i=1 log P i,yi = − 1 N N i=1 log e fi,y i C k=1 e f i,k .</formula><p>(2) Conventional softmax loss and state-of-the-art cosinebased softmax losses <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b6">7]</ref> calculate the logits f i,j in different ways. In conventional softmax loss, logits f i,j are obtained as the inner product between feature x i and the jth class weights W j as f i,j = W T j x i . In the cosine-based softmax losses <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b6">7]</ref>, cosine similarity is calculated by cos θ i,j = x i , W j / x i W j . The logits f i,j are calculated as f i,j = s·cos θ i,j , where s is a scale hyperparameter. To enforce angular margin on the representations, ArcFace <ref type="bibr" target="#b6">[7]</ref> modified the loss to the form</p><formula xml:id="formula_2">f i,j = s · cos (θ i,j + ½{j = y i } · m),<label>(3)</label></formula><p>while CosFace <ref type="bibr" target="#b39">[40]</ref> uses</p><formula xml:id="formula_3">f i,j = s · (cos θ i,j − ½{j = y i } · m),<label>(4)</label></formula><p>where m is the margin. The indicator function ½{j = y i } returns 1 when j = y i and 0 otherwise. All margin-based variants decrease f i,yi associate with the correct class by subtracting margin m. Compared with the losses without margin, margin-based variants require f i,yi to be greater than other f i,j for j = y i , by a specified m.</p><p>Intuitively, on one hand, the parameter s scales up the narrow range of cosine distances, making the logits more discriminative. On the other hand, the parameter m enlarges the margin between different classes to enhance classification ability. These hyperparameters eventually affect P i,yi . Empirically, an ideal hyperparameter setting should help P i,j to satisfy the following two properties: (1) Predicted probabilities P i,yi of each class (identity) should span to the range [0, 1]: the lower boundary of P i,yi should be near 0 while the upper boundary near 1; (2) Changing curve of P i,yi should have large absolute gradients around θ i,yi to make training effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Effects of the scale parameter s</head><p>The scale parameter s can significantly affect P i,yi . Intuitively, P i,yi should gradually increase from 0 to 1 as the angle θ i,yi decreases from π 2 to 0 2 , i.e., the smaller the angle between x i and its corresponding class weight W yi is, the larger the probability should be. Both improper probability range and probability curves w.r.t. θ i,yi would negatively affect the training process and thus the recognition performance.</p><p>We first study the range of classification probability P i,j . Given scale parameter s, the range of probabilities in all cosine-based softmax losses is</p><formula xml:id="formula_4">1 1 + (C − 1) · e s ≤ P i,j ≤ e s e s + (C − 1) ,<label>(5)</label></formula><p>where the lower boundary is achieved when f i,j = s · 0 = 0 and f i,k = s · 1 = s for all k = j in Eq. (1). Similarly, the <ref type="bibr" target="#b1">2</ref> Mathematically, θ can be any value in [0, π]. We empirically found, however, the maximum θ is always around π 2 . See the red curve in <ref type="figure">Fig</ref>  upper bound is achieved when f i,j = s and f i,k = 0 for all k = j. The range of P i,j approaches 1 when s → ∞, i.e.,</p><formula xml:id="formula_5">lim s→+∞ e s e s + (C − 1) − 1 1 + (C − 1) · e s = 1, (6)</formula><p>which means that the requirement of the range spanning [0, 1] could be satisfied with a large s. However it does not mean that the larger the scale parameter, the better the selection is. In fact the probability range can easily approach a high value, such as 0.94 when class number C = 10 and scale parameter s = 5.0. But an oversized scale would lead to poor probability distribution, as will be discussed in the following paragraphs.</p><p>We investigate the influences of parameter s by taking P i,yi as a function of s and angle θ i,yi where y i denotes the label of x i . Formally, we have</p><formula xml:id="formula_6">P i,yi = e fi,y i e fi,y i + B i = e s·cos θi,y i e s·cos θi,y i + B i ,<label>(7)</label></formula><p>where B i = k =yi e f i,k = k =yi e s·cos θ i,k are the logits summation of all non-corresponding classes for feature x i . We observe that the values of B i are almost unchanged during the training process. This is because the angles θ i,k for non-corresponding classes k = y i always stay around π 2 during training (see red curve in <ref type="figure" target="#fig_1">Fig. 1</ref>). Therefore, we can assume B i is constant, i.e., B i ≈ k =yi e s·cos(π/2) = C − 1. We then plot curves of probabilities P i,yi w.r.t. θ i,yi under different setting of parameter s in <ref type="figure" target="#fig_3">Fig. 2(a)</ref>. It is obvious that when s is too small (e.g., s = 10 for class/identity number C = 2, 000 and C = 20, 000), the maximal value of P i,yi could not reach 1. This is undesirable because even when the network is very confident on a sample x i 's corresponding class label  y i , e.g. θ i,yi = 0, the loss function would still penalize the classification results and update the network. On the other hand, when s is too large (e.g., s = 64), the probability curve P i,yi w.r.t. θ i,yi is also problematic. It would output a very high probability even when θ i,yi is close to π/2, which means that the loss function with large s may fail to penalize mis-classified samples and cannot effectively update the networks to correct mistakes.</p><formula xml:id="formula_7">m = 0.2 m = 0.4 m = 0.6 m = 0.8 m = 1.0 Fixed AdaCos (b) P i,y i w.r.t. θ i,y i .</formula><p>In summary, the scaling parameter s has substantial influences to the range as well as the curves of the probabilities P i,yi , which are crucial for effectively training the deep network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Effects of the margin parameter m</head><p>In this section, we investigate the effect of margin parameters m in cosine-based softmax losses (Eqs. (3) &amp; (4)), and their effects on feature x i 's predicted class probability P i,yi . For simplicity, we here study the margin parameter m for ArcFace (Eq. 3); while the similar conclusions also apply to the parameter m in CosFace (Eq. <ref type="formula" target="#formula_3">(4)</ref>).</p><p>We first re-write classification probability P i,yi following Eq. <ref type="formula" target="#formula_6">(7)</ref> as</p><formula xml:id="formula_8">P i,yi = e fi,y i e fi,y i + B i = e s·cos (θi,y i +m) e s·cos (θi,y i +m) + B i .<label>(8)</label></formula><p>To study the influence of parameter m on the probability P i,yi , we assume both s and B i are fixed. Following the discussion in Section 3.1, we set B i ≈ C − 1, and fix s = 30. The probability curves P i,yi w.r.t. θ i,yi under different m are shown in <ref type="figure" target="#fig_3">Fig. 2(b)</ref>. According to <ref type="figure" target="#fig_3">Fig. 2(b)</ref>, increasing the margin parameter shifts probability P i,yi curves to the left. Thus, with the same θ i,yi , larger margin parameters lead to lower probabilities P i,yi and thus larger loss even with small angles θ i,yi . In other words, the angles θ i,yi between the feature x i and its corresponding class's weights W yi have to be very small for sample i being correctly classified. This is the reason why margin-based losses provide stronger supervisions for the same θ i,yi than conventional cosine-based losses. Proper margin settings have shown to boost the final recognition performance in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Although larger margin m provides stronger supervisions, it should not be too large either. When m is oversized (e.g., m = 1.0), the probabilities P i,yi becomes unreliable. It would output probabilities around 0 even θ i,yi is very small. This lead to large loss for almost all samples even with very small sample-to-class angles, which makes the training difficult to converge. In previous methods, the margin parameter selection is an ad-hoc procedure and has no theoretical guidance for most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Summary of the hyparameter study</head><p>According to our analysis, we can draw the following conclusions:</p><p>(1) Hyperparameters scale s and margin m can substantially influence the prediction probability P i,yi of feature x i with ground-truth identity/category y i . For the scale parameter s, too small s would limit the maximal value of P i,yi . On the other hand, too large s would make most predicted probabilities P i,yi to be 1, which makes the training loss insensitive to the correctness of θ i,yi . For the margin parameter m, a too small margin is not strong enough to regularize the final angular margin, while an oversized margin makes the training difficult to converge.</p><p>(2) The effect of scale s and margin m can be unified to modulate the mapping from cosine distances cos θ i,yi to the prediction probability P i,yi . As shown in <ref type="figure" target="#fig_3">Fig. 2(a)</ref> and <ref type="figure" target="#fig_3">Fig. 2(b)</ref>, both small scales and large margins have similar effect on θ i,yi for strengthening the supervisions, while both large scales and small margins weaken the supervisions. Therefore it is feasible and promising to control the probability P i,yi using one single hyperparameter, either s or m. Considering the fact that s is more related to the range of P i,yi that required to span [0, 1], we will focus on automatically tuning the scale parameter s in the reminder of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The cosine-based softmax loss with adaptive scaling</head><p>Based on our previous studies on the hyperparameters of the cosine-based softmax loss functions, in this section, we propose a novel loss with a self-adaptive scaling scheme, namely AdaCos, which does not require the ad-hoc and time-consuming manual parameter tuning. Training with the proposed loss does not only facilitate convergence but also results in higher recognition accuracy.</p><p>Our previous studies on <ref type="figure" target="#fig_1">Fig. 1</ref> show that during the training process, the angles θ i,k for k = y i between the feature x i and its non-corresponding weights W k =yi are almost always close to π 2 , In other words, we could safely assume that B i ≈ k =yi e s·cos(π/2) = C −1 in Eq. <ref type="bibr" target="#b6">(7)</ref>. Obviously, it is the probability P i,yi of feature x i belonging to its corresponding class y i that has the most influence on supervision for network training. Therefore, we focus on designing an adaptive scale parameter for controling the probabilities P i,yi .</p><p>From the curves of P i,yi w.r.t. θ i,yi <ref type="figure" target="#fig_3">(Fig. 2(a)</ref>), we observe that the scale parameter s does not only simply affect P i,yi 's boundary of of determining correct/incorrect but also squeezes/stretches the P i,yi curvature; In contrast to scale s, margin parameter m only shifts the curve in phase. We therefore propose to automatically tune the scale parameter s and eliminate the margin parameter m from our loss function, which makes our proposed AdaCos loss different from state-of-the-art softmax loss variants with angular margin. With softmax function, the predicted probability can be defined by</p><formula xml:id="formula_9">P i,j = es ·cos θi,j C k=1 es ·cos θ i,k ,<label>(9)</label></formula><p>wheres is the automatically tuned scale parameter to be discussed below. Let us first re-consider the P i,yi (Eq. <ref type="formula" target="#formula_6">(7)</ref>) as a function of θ i,yi . Note that θ i,yi represents the angle between sample x i and the weight vector of its ground truth category y i . For network training, we hope to minimize θ i,yi with the supervision from the loss function L CE . Our objective is choose a suitable scales which makes predicted probability P i,yi change significantly with respect to θ i,yi . Mathematically, we find the point where the absolute gradient value ∂Pi,y i (θ) ∂θ reaches its maximum, when the second-order derivative of P i,yi at θ 0 equals 0, i.e.,</p><formula xml:id="formula_10">∂ 2 P i,yi (θ 0 ) ∂θ 0 2 = 0,<label>(10)</label></formula><p>where θ 0 ∈ [0, π 2 ]. Combining Eqs. <ref type="formula" target="#formula_6">(7)</ref> and <ref type="formula" target="#formula_0">(10)</ref>, we obtain an transcendental equation. Considering that P (θ 0 ) is close to <ref type="bibr">1 2</ref> , the relation between the scale parameter s and the point (θ 0 , P (θ 0 )) can be approximated as</p><formula xml:id="formula_11">s 0 = log B i cos θ 0 ,<label>(11)</label></formula><p>where B i can be well approximated as B i = k =yi e s·cos θ i,k ≈ C − 1 since the angles θ i,k distribute around π/2 during training (see Eq. (7) and <ref type="figure" target="#fig_1">Fig. 1)</ref>. Then the task of automatically determinings would reduce to select an reasonable central angleθ in [0, π/2].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Automatically choosing a fixed scale parameter</head><p>Since π 4 is in the center of [0, π 2 ], it is natural to regard π/4 as the point, i.e. setting θ 0 = π/4 for figuring out an effective mapping from angle θ i,yi to the probability P i,yi . Then the supervisions determined by P i,yi would be backpropagated to update θ i,yi and further to update network parameters. According to Eq. (11), we can estimate the corresponding scale parameter s f as</p><formula xml:id="formula_12">s f = log B i cos π 4 = log k =yi e s·cos θ i,k cos π 4 (12) ≈ √ 2 · log (C − 1)</formula><p>where B i is approximated by C − 1.</p><p>For such an automatically-chosen fixed scale parameter s f (see Figs. 2(a) and 2(b)), it depends on the number of classes C in the training set and also provides a good guideline for existing cosine distance based softmax losses to choose their scale parameters. In contrast, the scaling parameters in existing methods was manually set according to human experience. It acts as a good baseline method for our dynamically tuned scale parameters d in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Dynamically adaptive scale parameter</head><p>As <ref type="figure" target="#fig_1">Fig. 1</ref> shows, the angles θ i,yi between features x i and their ground-truth class weights W yi gradually decrease as the training iterations increase; while the angles between features x i and non-corresponding classes W j =yi become stabilize around π 2 , as shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. Although our previously fixed scale parameters f behaves properly as θ i,yi changes over [0, π 2 ], it does not take into account the fact that θ i,yi gradually decrease during training. Since smaller θ i,yi gains higher probability P i,yi and thus gradually receives weaker supervisions as the training proceeds, we therefore propose a dynamically adaptive scale parameters d to gradually apply stricter requirement on the position of θ 0 which can progressively enhance the supervisions throughout the training process.</p><p>Formally we introduce a modulating indicator variable θ (t) med , which is the median of all corresponding classes' angles, θ (t) i,yi , from the mini-batch of size N at the t-th iteration. θ (t) med roughly represents the current network's degree of optimization on the mini-batch. When the median angle is large, it denotes that the network parameters are far from optimum and less strict supervisions should be applied to make the training converge more stably; when the median angle θ (t) med is small, it denotes that the network is close to optimum and stricter supervisions should be applied to make the intra-class angles θ i,yi become even smaller. Based on this observation, we set the central angleθ  </p><formula xml:id="formula_13">B (t) avg = 1 N i∈N (t) B (t) i = 1 N i∈N (t) k =yi es (t−1) d ·cos θ i,k ,<label>(13)</label></formula><p>where N (t) denotes the face identity indices in the minibatch at the t-th iteration. Unlike approximating B i ≈ C−1 for the fixed adaptive scale parameters f , here we estimate B (t) i using the scale parameters (t−1) d of previous iteration, which provides us a more accurate approximation. Be reminded that B (t) i also includes dynamic scales (t) d . We can obtain it by solving the nonlinear function given by the above equation. In practice, we notice thats (t) d changes very little following iterations. So, we just uses</p><formula xml:id="formula_14">(t−1) d to calculate B (t) i</formula><p>with Eq. <ref type="bibr" target="#b6">(7)</ref>. Then we can obtain dynamic scales</p><formula xml:id="formula_15">(t) d</formula><p>directly with Eq. (11). So we have:</p><formula xml:id="formula_16">s (t) d = log B (t) avg cos θ (t) med ,<label>(14)</label></formula><p>where B</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(t)</head><p>avg is related to the dynamic scale parameter. We estimate it using the scale parameters</p><formula xml:id="formula_17">(t−1) d of the previous iteration.</formula><p>At the begin of the training process, the median angle θ (t) med of each mini-batch might be too large to impose enough supervisions for training. We therefore force the central angle θ (t) med to be less than π 4 . Our dynamic scale parameter for the t-th iteration could then be formulated as</p><formula xml:id="formula_18">s (t) d =        √ 2 · log (C − 1) t = 0, log B (t) avg cos min( π 4 , θ (t) med ) t ≥ 1,<label>(15)</label></formula><formula xml:id="formula_19">wheres (0) d</formula><p>is initialized as our fixed scale parameters f when t = 0. Substitutings</p><formula xml:id="formula_20">(t) d into f i,j =s (t)</formula><p>d ·cos θ i,j , the corresponding gradients can be calculated as follows</p><formula xml:id="formula_21">∂L( x i ) ∂ x i = C j=1 (P (t) i,j − ½(y i = j)) ·s (t) d ∂ cos θ i,j ∂ x i , ∂L( W j ) ∂ W j = (P (t) i,j − ½(y i = j)) ·s (t) d ∂ cos θ i,j ∂ W j ,<label>(16)</label></formula><p>where ½ is the indicator function and</p><formula xml:id="formula_22">P (t) i,j = es (t) d ·cos θi,j C k=1 es (t) d ·cos θ i,k .<label>(17)</label></formula><p>Eq. <ref type="bibr" target="#b16">(17)</ref> shows that the dynamically adaptive scale parameters (t) d influences classification probabilities differently at each iteration and also effectively affects the gradients (Eq. (16)) for updating network parameters. The benefit of dynamic AdaCos is that it can produce reasonable scale parameter by sensing the training convergence of the model in the current iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We examine the proposed AdaCos loss function on several public face recognition benchmarks and compare it with state-of-the-art cosine-based softmax losses. The compared losses include l2-softmax <ref type="bibr" target="#b27">[28]</ref>, CosFace <ref type="bibr" target="#b39">[40]</ref>, and ArcFace <ref type="bibr" target="#b6">[7]</ref>. We present evaluation results on LFW <ref type="bibr" target="#b12">[13]</ref>, MegaFace 1-million Challenge <ref type="bibr" target="#b23">[24]</ref>, and IJB-C <ref type="bibr" target="#b22">[23]</ref> data. We also present results on some exploratory experiments to show the convergence speed and robustness against lowresolution images.</p><p>Preprocessing. We use two public training datasets, CASIA-WebFace <ref type="bibr" target="#b42">[43]</ref> and MS1M <ref type="bibr" target="#b8">[9]</ref>, to train CNN models with our proposed loss functions. We carefully clean the noisy and low-quality images from the datasets. The cleaned WebFace <ref type="bibr" target="#b42">[43]</ref> and MS1M <ref type="bibr" target="#b8">[9]</ref> contain about 0.45M and 2.35M facial images, respectively. All models are trained based on these training data and directly tested on the test splits of the three datasets. RSA <ref type="bibr" target="#b21">[22]</ref> is applied to the images to extract facial areas. Then, according to detected facial landmarks, the faces are aligned through similarity transformation and resized to the size 144 × 144. All image pixel values are subtracted with the mean 127.5 and dividing by 128.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results on LFW</head><p>The LFW <ref type="bibr" target="#b12">[13]</ref> dataset collected thousands of identities from the inertnet. Its testing protocol contains about 13, 000 images for about 1, 680 identities with a total of 6, 000 ground-truth matches. Half of the matches are positive while the other half are negative ones. LFW's primary difficulties lie in face pose variations, color jittering, illumination variations and aging of persons. Note portion of the pose variations can be eliminated by the RSA <ref type="bibr" target="#b21">[22]</ref> facial landmark detection and alignment algorithm, but there still exist some non-frontal facial images which can not be aligned by RSA <ref type="bibr" target="#b21">[22]</ref> and then aligned manually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Comparison on LFW</head><p>For all experiments on LFW <ref type="bibr" target="#b12">[13]</ref>, we train ResNet-50 models <ref type="bibr" target="#b9">[10]</ref> with batch size of 512 on the cleaned WebFace <ref type="bibr" target="#b42">[43]</ref> dataset. The input size of facial image is 144 × 144 and the feature dimension input into the loss function is 512. Different loss functions are compared with our proposed AdaCos losses.</p><p>Results in <ref type="table">Table 1</ref> show the recognition accuracies of models trained with different softmax loss functions. Our proposed AdaCos losses with fixed and dynamic scale parameters (denoted as Fixed AdaCos and Dyna. AdaCos) surpass the state-of-the-art cosine-based softmax losses under the same training configuration. For the hyperparameter settings of the compared losses, the scaling parameter is set as 30 for l2-softmax <ref type="bibr" target="#b27">[28]</ref>, CosFace <ref type="bibr" target="#b39">[40]</ref> and Arc-  Face <ref type="bibr" target="#b6">[7]</ref>; the margin parameters are set as 0.25 and 0.5 for CosFace <ref type="bibr" target="#b39">[40]</ref>, and ArcFace <ref type="bibr" target="#b6">[7]</ref>, respectively. Since LFW is a relatively easy evaluation set, we train and test all losses for three times. The average accuracy of our proposed dynamic AdaCos is 0.26% higher than state-of-the-art Arc-Face <ref type="bibr" target="#b6">[7]</ref> and 1.52% than l2-softmax <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Exploratory Experiments</head><p>The change of scale parameters and feature angles during training. In this part, we will show the change of scale parameters changes along with the current recognition performance of the model, which continuously strengthens the supervisions by gradually reducing θ i,yi and thus shrinkings  <ref type="figure">Figure 4</ref>: The change of θ i,yi when training on the cleaned WebFace dataset. θ i,yi represents the angle between the feature vector of i-th sample and the weight vector of its ground truth category y i . Curves calculated by proposed dynamic AdaCos loss, l2-softmax loss <ref type="bibr" target="#b27">[28]</ref>, CosFace <ref type="bibr" target="#b39">[40]</ref> and ArcFace <ref type="bibr" target="#b6">[7]</ref> are shown. Best viewed in color.</p><p>dynamic AdaCos loss, the scale parameters (t) d adaptively decreases as the training iterations increase, which indicates that the loss function provides stricter supervisions to update network parameters. <ref type="figure">Fig. 4</ref> illustrates the change of θ i,j by our proposed dynamic AdaCos and l2-softmax. The average (orange curve) and median (green curve) of θ i,yi , which indicating the angle between a sample and its groundtruth category, gradually reduce while the average (maroon curve) of θ i,j where j = y i remains nearly π 2 . Compared with l2-softmax loss, our proposed loss could achieve much smaller sample feature to category angles on the groundtruth classes and leads to higher recognition accuracies.</p><p>Convergence rates. Convergence rate is an important indicator of efficiency of loss functions. We examine the convergence rates of several cosine-based losses at different training iterations. The training configurations are same as <ref type="table">Table 1</ref>. Results in <ref type="table" target="#tab_2">Table 2</ref> reveal that the convergence rates when training with the AdaCos losses are much higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results on MegaFace</head><p>We then evaluate the performance of proposed AdaCos on the MegaFace Challenge <ref type="bibr" target="#b15">[16]</ref>, which is a publicly available identification benchmark, widely used to test the performance of facial recognition algorithms. The gallery set of MegaFace incorporates over 1 million images from 690K identities collected from Flickr photos <ref type="bibr" target="#b36">[37]</ref>. We follow Ar-cFace <ref type="bibr" target="#b6">[7]</ref>'s testing protocol, which cleaned the dataset to make the results more reliable. We train the same Inception-   ResNet <ref type="bibr" target="#b32">[33]</ref> models with CASIA-WebFace <ref type="bibr" target="#b42">[43]</ref> and MS1M <ref type="bibr" target="#b8">[9]</ref> training data, where overlapped subjects are removed. <ref type="table" target="#tab_4">Table 3</ref> and <ref type="figure" target="#fig_9">Fig. 5</ref> summarize the results of models trained on both WebFace and MS1M datasets and tested on the cleaned MegaFace dataset. The proposed AdaCos and state-of-the-art softmax losses are compared, where the dynamic AdaCos loss outperforms all compared losses on the MegaFace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results on IJB-C 1:1 verification protocol</head><p>The IJB-C dataset <ref type="bibr" target="#b22">[23]</ref>    <ref type="table">Table 4</ref>: True accept rates by different compared softmax losses on the IJB-C 1:1 verification task. The same training data (WebFace <ref type="bibr" target="#b42">[43]</ref> and MS1M <ref type="bibr" target="#b8">[9]</ref>) and Inception-ResNet <ref type="bibr" target="#b32">[33]</ref> networks are used. The results of FaceNet <ref type="bibr" target="#b28">[29]</ref>, VGGFace <ref type="bibr" target="#b24">[25]</ref>, and Crystal Loss <ref type="bibr" target="#b26">[27]</ref> are from <ref type="bibr" target="#b26">[27]</ref>.  : TARs by different compared softmax losses on the IJB-C 1:1 verification task. The same training data (Web-Face <ref type="bibr" target="#b42">[43]</ref> and MS1M <ref type="bibr" target="#b8">[9]</ref>) and Inception-ResNet <ref type="bibr" target="#b32">[33]</ref> are used. The results of FaceNet <ref type="bibr" target="#b28">[29]</ref>, VGGFace <ref type="bibr" target="#b24">[25]</ref> are reported in Crystal Loss <ref type="bibr" target="#b26">[27]</ref>.</p><p>We compare the softmax loss functoins, including the proposed AdaCos, l2-softmax <ref type="bibr" target="#b27">[28]</ref>, CosFace <ref type="bibr" target="#b39">[40]</ref>, and Ar-cFace <ref type="bibr" target="#b6">[7]</ref> with the same training data (WebFace <ref type="bibr" target="#b42">[43]</ref> and MS1M <ref type="bibr" target="#b8">[9]</ref>) and network architecture (Inception-ResNet <ref type="bibr" target="#b32">[33]</ref>). We also report the results of FaceNet <ref type="bibr" target="#b28">[29]</ref>, VGGFace <ref type="bibr" target="#b35">[36]</ref> listed in Crystal loss <ref type="bibr" target="#b26">[27]</ref>. <ref type="table">Table 4</ref> and <ref type="figure" target="#fig_11">Fig. 6</ref> exhibit their performances on the IJB-C 1:1 verification. Our proposed dynamic AdaCos achieves the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this work, we argue that the bottleneck of existing cosine-based softmax losses may primarily comes from the mis-match between cosine distance cos θ i,yi and the classification probability P i,yi , which limits the final recognition performance. To address this issue, we first deeply analyze the effects of hyperparameters in cosine-based softmax losses from the perspective of probability. Based on these analysis, we propose the AdaCos which automatically adjusts an adaptive parameters (t) d in order to reformulate the mapping between cosine distance and classification probability. Our proposed AdaCos loss is simple yet effective. We demonstrate its effectiveness and efficiency by exploratory experiments and report its state-of-the-art performances on several public benchmarks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Average θi,y iMedian θi,y i Average θi,j, j = yi</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Changing process of angles in each mini-batch when training on WebFace. (Red) average angles in each mini-batch for non-corresponding classes, θ i,j for j = y i . (Blue) median angles in each mini-batch for corresponding classes, θ i,yi . (Brown) average angles in each mini-batch for corresponding classes, θ i,yi .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>P i,y i w.r.t. θ i,y i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Curves of P i,yi w.r.t. θ i,yi by choosing different sclae and margin parameters. (Left) C = 2000. (Right) C = 20000.Fig. 2(a)is for choosing different scale parameters andFig. 2(b)is for fixing s = 30 and choosing different margin parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>The change of the fixed adaptive scale parameters f and dynamic adaptive scale parameters (t) d when training on the cleaned WebFace dataset. The dynamic scale parameters (t) d gradually and automatically decreases to strengthen training supervisions for feature angles θ i,yi , which validates our assumption on the adaptive scale parameter in our proposed AdaCos loss. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>d</head><label></label><figDesc>and feature angles θ i,j during training with our proposed AdaCos loss. The scale parameters (t) d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 Average</head><label>2</label><figDesc>(t) d . Fig. 3 shows the change of the scale parameter s with our proposed fixed AdaCos and dynamic AdaCos losses. For the Degree of θi,j θi,y i of l2-softmax θi,y i of CosFace θi,y i of ArcFace θi,y i of Dynamic AdaCos θi,j, j = yi of Dynamic AdaCos</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>s = 45 CosFace s = 45, m = 0.15 ArcFace s = 45, m = 0.3 Fixed AdaCos Dynamic AdaCos Recognition accuracy curves on MegaFace dataset by Inception-ResNet [34] models trained with different softmax losses and on the same cleaned Web-Face [43] and MS1M [9] training data. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>s = 45 CosFace s = 45, m = 0.15 ArcFace s = 45, m = 0.3 Fixed AdaCos Dynamic AdaCos</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6</head><label>6</label><figDesc>Figure 6: TARs by different compared softmax losses on the IJB-C 1:1 verification task. The same training data (Web-Face [43] and MS1M [9]) and Inception-ResNet [33] are used. The results of FaceNet [29], VGGFace [25] are reported in Crystal Loss [27].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Softmax 70.15 85.33 89.50 93.05 l2-softmax [28] 79.08 88.52 93.38 98.22 CosFace [40] 78.17 90.87 98.52 99.37 ArcFace [7] 82.43 92.37 98.78 99.55 Fixed AdaCos 85.10 94.38 99.05 99.63 Dyna. AdaCos 88.52 95.78 99.30 99.73</figDesc><table><row><cell>Method</cell><cell>25k</cell><cell>Num. of Iteration 50k 75k</cell><cell>100k</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Convergence rates of different softmax losses. At the same iterations, training with our proposed dynamic AdaCos loss leads to the best recognition accuracy.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>contains about 3, 500 identities with a total of 31, 334 still facial images and 117, 542 unconstrained video frames. In the 1:1 verification, there are 19, 557 positive matches and 15, 638, 932 negative matches, which allow us to evaluate TARs at various FARs (e.g., 10 −7 ). 73% 99.49% 99.03% 97.85% 95.56% 92.05% CosFace 99.82% 99.68% 99.46% 98.57% 97.58% 95.50% ArcFace 99.78% 99.65% 99.48% 98.87% 98.03% 96.88% Fixed AdaCos 99.85% 99.70% 99.47% 98.80% 97.92% 96.85% Dynamic AdaCos 99.88% 99.72% 99.51% 99.02% 98.54% 97.41%</figDesc><table><row><cell>Method</cell><cell>10 1</cell><cell>10 2</cell><cell>Size of MegaFace Distractor 10 3 10 4</cell><cell>10 5</cell><cell>10 6</cell></row><row><cell>l2-softmax</cell><cell>99.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Recognition accuracy on MegaFace by Inception-ResNet<ref type="bibr" target="#b33">[34]</ref> models trained with different compared softmax loss and the same cleaned WebFace<ref type="bibr" target="#b42">[43]</ref> and MS1M<ref type="bibr" target="#b8">[9]</ref> training data.FaceNet<ref type="bibr" target="#b28">[29]</ref> 92.45% 81.71% 66.45% 48.69% 33.30% 20.95% -VGGFace<ref type="bibr" target="#b24">[25]</ref> 95.64% 87.13% 74.79% 59.75% 43.69% 32.20% -Crystal Loss [27] 99.06% 97.66% 95.63% 92.29% 87.35% 81.15% 71.37% l2-softmax 98.40% 96.45% 92.78% 86.33% 77.25% 62.61% 26.67% CosFace [40] 99.01% 97.55% 95.37% 91.82% 86.94% 76.25% 61.72% ArcFace [7] 99.07% 97.75% 95.55% 92.13% 87.28% 82.15% 72.28% Fixed AdaCos 99.05% 97.70% 95.48% 92.35% 87.87% 82.38% 72.66% Dynamic AdaCos 99.06% 97.72% 95.65% 92.40% 88.03% 83.28% 74.07%</figDesc><table><row><cell>Method</cell><cell>10 −1</cell><cell>10 −2</cell><cell>True Accept Rate @ False Accept Rate 10 −3 10 −4 10 −5</cell><cell>10 −6</cell><cell>10 −7</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We denote it as "softmax loss" for short in the remaining sections.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work is supported in part by SenseTime Group Limited, in part by the General Research Fund through the Research Grants Council of Hong Kong under Grants CUHK14202217, CUHK14203118, CUHK14205615, CUHK14207814, CUHK14213616, CUHK14208417, CUHK14239816, in part by CUHK Direct Grant, and in part by National Natural Science Foundation of China (61472410) and the Joint Lab of CAS-HK.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Kriegman. Eigenfaces vs. fisherfaces: Recognition using class specific linear projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Hespanha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="711" to="720" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Algorithms for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balázs</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kégl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2546" to="2554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07698</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Von mises-fisher clustering models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="154" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ms-celeb-1m: A dataset and benchmark for large-scale face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep metric learning using triplet network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Similarity-Based Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01507</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Labeled faces in the wild: A database for studying face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Learned-Miller</surname></persName>
		</author>
		<idno>07-49</idno>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sequential model-based optimization for general algorithm configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Holger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning and Intelligent Optimization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="507" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The megaface benchmark: 1 million faces for recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4873" to="4882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhiksha</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large-margin softmax loss for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="507" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning deep features via congenerous cosine loss for person recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.06890</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Rethinking feature discrimination and polymerization for large-scale recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.00870</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recurrent scale approximation for object detection in cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Iarpa janus benchmark-c: Face dataset and protocol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brianna</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><surname>Niggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th IAPR International Conference on Biometrics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Level playing field for million scale face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Nech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3406" to="3415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankan</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Cheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.01159</idno>
		<title level="m">Crystal loss and quality pooling for unconstrained face verification and recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">L2-constrained softmax loss for discriminative face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09507</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2951" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep learning face representation by joint identificationverification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1988" to="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deepid3: Face recognition with very deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.00873</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Friedland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Elizalde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damian</forename><surname>Poland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Borth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.01817</idno>
		<title level="m">The new data in multimedia research</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">100</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Additive margin softmax for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.05599</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Normface: l 2 hypersphere embedding for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06369</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingchao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.09414</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengcai</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7923</idno>
		<title level="m">Learning face representation from scratch</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Range loss for deep face recognition with longtailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Ring loss: Convex feature normalization for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dipan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5089" to="5097" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
