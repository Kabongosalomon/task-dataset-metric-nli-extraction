<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Transferring and Regularizing Prediction for Semantic Segmentation *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
							<email>yihengzhang.chn@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
							<email>zhaofanqiu@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">AI Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>JD</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
							<email>dongeliu@ustc.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
							<email>tmei@jd.com</email>
							<affiliation key="aff1">
								<orgName type="institution">AI Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>JD</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Transferring and Regularizing Prediction for Semantic Segmentation *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semantic segmentation often requires a large set of images with pixel-level annotations. In the view of extremely expensive expert labeling, recent research has shown that the models trained on photo-realistic synthetic data (e.g., computer games) with computer-generated annotations can be adapted to real images. Despite this progress, without constraining the prediction on real images, the models will easily overfit on synthetic data due to severe domain mismatch. In this paper, we novelly exploit the intrinsic properties of semantic segmentation to alleviate such problem for model transfer. Specifically, we present a Regularizer of Prediction Transfer (RPT) that imposes the intrinsic properties as constraints to regularize model transfer in an unsupervised fashion. These constraints include patch-level, cluster-level and context-level semantic prediction consistencies at different levels of image formation. As the transfer is label-free and data-driven, the robustness of prediction is addressed by selectively involving a subset of image regions for model regularization. Extensive experiments are conducted to verify the proposal of RPT on the transfer of models trained on GTA5 and SYN-THIA (synthetic data) to Cityscapes dataset (urban street scenes). RPT shows consistent improvements when injecting the constraints on several neural networks for semantic segmentation. More remarkably, when integrating RPT into the adversarial-based segmentation framework, we report to-date the best results: mIoU of 53.2%/51.7% when transferring from GTA5/SYNTHIA to Cityscapes, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation aims at assigning semantic labels to every pixel of an image. Leveraging on CNNs <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref>, significant progress has been reported for this fundamental task <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36]</ref>. One drawback of the existing approaches, nevertheless, is the requirement of large quantities of pixel-level annotations, such as in VOC <ref type="bibr" target="#b14">[15]</ref>, * This work was performed at JD AI Research. COCO <ref type="bibr" target="#b27">[28]</ref> and Cityscapes <ref type="bibr" target="#b10">[11]</ref> datasets, for model training. Labeling of semantics at pixel-level is cost expensive and time consuming. For example, the Cityscapes dataset is composed of 5,000 high-quality pixel-wise annotated images, and the annotation on a single image is reported to take more than 1.5 hours.</p><p>An alternative is by utilizing synthetic data, which is largely available in 3D engines (e.g., SYNTHIA <ref type="bibr" target="#b40">[41]</ref>) and 3D computer games (e.g., GTA5 <ref type="bibr" target="#b39">[40]</ref>). The ground-truth semantics of these data can be automatically generated without manual labeling. Nevertheless, in the case where the synthetic data is different from the real images, the domain gap might be difficult to bridge. Unsupervised domain adaptation is generally regarded as an appealing way to address the problem of domain gap. The existing approaches include narrowing the gap by transferring images across domains <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b49">50]</ref> and learning domain-invariant representation via adversarial mechanism <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>In this paper, we consider model overfitting in source domain as the major cause of domain mismatch. As shown in <ref type="figure">Figure 1</ref>(a), although Fully Convolutional Networks (FCN) perfectly segment the synthetic image by correct labeling of pixels, directly deploying this model for real image yields poor results. Instead of leveraging training samples in the target domain for model fine-tuning, this paper explores label-free constraints to alleviate the problem of model overfitting. These constraints are intrinsic and generic in the context of semantic segmentation. <ref type="figure">Figure 1</ref>(b)∼(d) illustrate three label-free constraints being investigated. The first two constraints, namely patch-based and cluster-based consistencies guide the segmentation based on the prediction consistency among the pixels in an image patch and among the clusters of patches sharing similar visual properties, respectively. The last criterion, namely spatial logic, contextualizes the prediction of labels based on spatial relation between image patches. Based on these criteria, we propose a novel Regularizer of Prediction Transfer (RPT) for transferring the model trained on synthetic data for semantic segmentation of real images.  <ref type="figure">Figure 1</ref>. The examples of (a) predictions on two domains by fully convolutional networks trained on synthetic data; (b)∼(d) the three evaluation criteria we studied, i.e., patch-based consistency, cluster-based consistency and spatial logic.</p><p>The main contribution of this paper is on the exploration of label-free data-driven constraints for transferring of model to bridge domain gap. These constraints are imposed as regularizers during training to transfer an overfitted source model for proper labeling of pixels in the target domain. Specifically, at the lowest level of regularization, majority voting is performed to derive a dominative category for each image patch. The dominative category serves as a local cue for pixels with low prediction confidence to adjust their label prediction during training. The patch-level regularization is then extended to a higher level of regularization to explore cluster-level and context-level prediction consistency. Despite its simplicity, the three regularizers, when jointed optimized in a fully convolutional network with adversarial learning, show impressive performances by outperforming several state-of-the-art methods, when transferring the models trained on GTA5 and SYN-THIA for semantic segmentation on the Cityscapes dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>CNN Based Semantic Segmentation. As one of the most challenging computer vision task, semantic segmentation has received intensive research attention. With the surge of deep learning and convolutional neural networks (CNNs), Fully Convolutional Network (FCN) <ref type="bibr" target="#b29">[30]</ref> successfully serves as an effective approach that employs CNNs to perform dense semantic prediction. Following FCN, various schemes, ranging from multi-path feature aggregation and refinement <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">58]</ref> to multi-scale context extraction and integration <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59]</ref>, have been developed and achieved great success in leveraging contextual information for semantic segmentation. Postprocessing techniques, such as CRF <ref type="bibr" target="#b5">[6]</ref> and MRF <ref type="bibr" target="#b28">[29]</ref>, could further be applied to take the spatial consistency of labels into account and improve the predictions from FCNs. Considering that such methods typically rely on the datasets with pixel-level annotations which are extremely expensive and laborious to collect, researchers have also strived to utilize a weaker form of annotation, such as image-level tags <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37]</ref>, bounding boxes <ref type="bibr" target="#b11">[12]</ref>, scribbles <ref type="bibr" target="#b1">[2]</ref> and statistics <ref type="bibr" target="#b34">[35]</ref>, for semantic segmentation. The development of computer graphics techniques provides an alternative approach that exploits synthetic data with free annotations. This work aims to study the methods of applying the semantic segmentation model learnt on the computer-generated syn-thetic data to unlabeled real data.</p><p>Domain Adaptation of Semantic Segmentation. To alleviate the issues of expensive labeling efforts in collecting pixel-level annotations, domain adaptation is studied for semantic segmentation. FCNWild <ref type="bibr" target="#b19">[20]</ref>, which is one of the early works, attempts to align the features in different domains from both global and local aspects by adversarial training. Curriculum <ref type="bibr" target="#b54">[55]</ref> proposes a curriculum-style learning approach to bridge the domain gap between synthetic and real data. Later on, similar to domain adaptation in image recognition and object detection <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b51">52]</ref>, visual appearance-level and/or representation-level adaptation are exploited in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b56">57]</ref> for this task. <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref> perform an image-to-image translation that transfers the synthetic images to the real domain in the appearance-level. From the perspective of the representation-level adaptation, AdaSegNet <ref type="bibr" target="#b46">[47]</ref> proposes to apply adversarial learning on segmentation maps for adapting structured output space. FCAN <ref type="bibr" target="#b56">[57]</ref> employs the two levels of adaptation simultaneously, in which the appearance gap between synthetic and real images is minimized and the network is encouraged to learn domain-invariant representations. There have been several other strategies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b60">61]</ref>, being performed for cross-domain semantic segmentation. For example, ROAD <ref type="bibr" target="#b9">[10]</ref> devises a target guided distillation module and a spatial-aware adaptation module for real style and distribution orientation. Labels from the source domain are transferred to the target domain as the additional supervision in CyCADA <ref type="bibr" target="#b18">[19]</ref>. Depth maps which are available in virtual 3D environments are utilized as geometric information to reduce domain shift in <ref type="bibr" target="#b8">[9]</ref>. <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b60">61]</ref> treat target predictions as the guide for learning a model applicable to the images in target domain by self-supervised learning. <ref type="bibr" target="#b3">[4]</ref> proposes a domain invariant structure extraction framework that decouples the structure and texture representations of images and improves the performance of segmentation.</p><p>Summary. Most of the aforementioned approaches mainly investigate the problem of domain adaptation for semantic segmentation through bridging the domain gap during training. Our work is different in the way that we seek the additional regularization for the prediction in target domain based on the intrinsic and generic properties of semantic segmentation task. Such solution formulates an innovative and promising research direction for this task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Regularizer of Prediction Transfer</head><p>We start by introducing the Regularizer of Prediction Transfer (RPT) for semantic segmentation. Three criteria are defined to assess the quality of segmentation. The result of assessment is leveraged to guide the transfer of a learnt model in the source domain for semantic segmentation in the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Patch-based Consistency</head><p>The idea is to enforce all pixels in a patch to be consistent in the prediction of semantic labels. Here, a patch is defined as a superpixel that groups neighboring pixels with similar visual appearance. We employ Simple Linear Iterative Clustering (SLIC) <ref type="bibr" target="#b0">[1]</ref>, which is both speed and memory efficient in the generation of superpixels by adopting k-means algorithm. Given one image from target domain x t , SLIC splits the image into N superpixels {S i |i = 1, ..., N }. Each superpixel S i = {p j i |j = 1, ..., M i } is composed of M i adjacent pixels with similar appearance. We assume that all or the majority of pixels will be annotated with the same semantic labels. Here, the dominative categoryŷ i of a superpixel is defined as the most number of predicted labels among all the pixels in this superpixel.</p><p>As SLIC considers only visual cue, a superpixel usually contains multiple regions of different semantic labels. Simply involving all pixels in network optimization can run into the risk of skew optimization. To address this problem, a subset of pixels is masked out from patch-based regularization. Specifically, in superpixel S i , pixels p j i ∈ S i are clustered into two groups depending on the predicted probability of the dominative categoryŷ i : (a) P seg (ŷ i |p j i ) &lt;= λ pc means that the probability is less than or equal to a pre- defined threshold λ pc . In other words, the pixel p j i is predicted with labels different from the dominative category with relatively high probability. This group of pixels should be exempted from regularization. (b) P seg (ŷ i |p j i ) &gt; λ pc represents that p j i has relatively higher confidence to be predicted as the dominative category. In this case, the dominativeŷ i is leveraged as a cue to guide the prediction of these pixels. To the end, the loss item for patch-based consistency regularization of a target image x t is formulated as:</p><formula xml:id="formula_0">L pc (x t ) = − i,j I (Pseg(ŷi|p j i )&gt;λpc) logP seg (ŷ i |p j i ) ,<label>(1)</label></formula><p>where I (·) is an indicator function to selectively mask out pixels from optimization by thresholding. <ref type="figure" target="#fig_1">Figure 2</ref> shows examples of superpixels that are masked out (i.e., unpunished) and involved (i.e., punished) for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Cluster-based Consistency</head><p>In addition to patch, we also enforce the consistency of label prediction among the clusters of patches that are visually similar. Specifically, cluster-level regularization imposes a constraint that the superpixels with similar visual properties should predict the cluster dominative category as their label. To this end, superpixels are further grouped into clusters. The feature representation of a superpixel is extracted through ResNet-101 <ref type="bibr" target="#b17">[18]</ref>, which is pre-trained on ImageNet dataset <ref type="bibr" target="#b41">[42]</ref>. The feature vector utilized for clustering is generated by averagely pooling the feature maps of the superpixel region from res5c layer. All the superpixels from target domain images are grouped into K = 2048 clusters by k-means algorithm. The cluster-level dominative categoryỹ k is determined by majority voting among the superpixels within a cluster. <ref type="figure" target="#fig_2">Figure 3</ref> visualizes seven examples of clusters and the corresponding dominative categories by t-SNE <ref type="bibr" target="#b47">[48]</ref>. As clustering is imperfect, it is ex-pected that some superpixels will be incorrectly grouped. Denote P seg (ỹ k |p j i ), where p j i ∈ S i ∈ C k , as the probability of predicting cluster-level dominative category as label for pixel p j i . Similar to patch-based consistency regularization, pixels with low confidence on the cluster-level category will not be punished during network optimization. Thus, the loss item of cluster-based consistency regularization for a target image x t is defined as:</p><formula xml:id="formula_1">L cc (x t ) = − i,j,Si∈C k I (Pseg(ỹ k |p j i )&gt;λcc) logP seg (ỹ k |p j i ) ,<label>(2)</label></formula><p>where λ cc is a pre-defined threshold to gate whether a pixel should be masked out from regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Spatial Logic</head><p>A useful cue to leverage for target-domain segmentation is the spatial relation between semantic labels. For instance, a superpixel of category sky is likely on the top of another superpixel labeled with building or road, and not vice versa. These relations are expected to be invariant across the source and target domains. The supportive hypothesis behind is introduced in [4] that the high-level structure information of an image is informative for semantic segmentation and can be readily shared across domains. As such, the motivation of spatial logic is to preserve the spatial relations learnt in source domain to target domain.</p><p>Formally, we exploit the LSTM encoder-decoder architecture to learn the vertical relation between superpixels, as shown in <ref type="figure" target="#fig_4">Figure 4</ref>. The main goal of this architecture is to speculate the category of the masked segment in the sequence according to context information. Then, the produced probability can be used to evaluate the logical validity of the predicted category in the masked segment. Suppose we have a prediction sequence Y, where Y = {y 1 , y 2 , ..., y T −1 , y T } including T superpixel predictions sliced from one column of prediction map. Let y t ∈ R C+1 denote the one-hot vector of the t-th prediction in the sequence, and the dimension of y t , i.e., C + 1, is the number of semantic categories plus one symbol as an identification of masked prediction. The masked prediction se-quenceŶ, which is fed into the LSTM encoder, is generated by masking a segment of consecutive predictions with the identical semantic category in the original sequence Y. The LSTM encoder embeds the masked prediction sequenceŶ into a sequence representation. The LSTM decoder, which is attached on the top of the encoder, then speculates the categories of the masked segment and reconstructs the original sequence Y. To learn the aforementioned spatial logic, the encoder-decoder architecture is optimized with the crossentropy loss supervised by the label from source domain.</p><p>Next, the optimized model can be utilized to estimate the validity of each prediction from the view of spatial logic. For the target image x t , we first slice the prediction map  to several columns consisting of vertically neighbored superpixels. The patch-level dominative categories of the superpixels in the column are organized into a prediction sequence. For the superpixel S i in the column, the spatial logical probability P logic (ŷ i |S i ) is measured by the LSTM encoder-decoder only when the prediction of this superpixel is masked in the input sequence. Once this probability is lower than the threshold λ sl , we consider this prediction to be illogical and punish the prediction ofŷ i by the segmentation network. The loss of spatial logic regularization is computed as:</p><formula xml:id="formula_2">L sl (x t ) = i,j I (P logic (ŷi|Si)&lt;λ sl ) logP seg (ŷ i |p j i ) ,<label>(3)</label></formula><p>where P logic (·) denotes the prediction from LSTM encoderdecoder architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Semantic Segmentation with RPT</head><p>The proposed Regularizer of Prediction Transfer (RPT) can be easily integrated into most of the existing frameworks for domain adaptation of semantic segmentation. Here, we choose the widely adopted framework based on adversarial learning as shown in <ref type="figure" target="#fig_5">Figure 5</ref>. The principle in this framework is equivalent to guiding the semantic segmentation in both domains by fooling a domain discriminator D with the learnt source and target representations. Formally, given the training set X s = {x i s |i = 1, . . . , N s } in source domain and X t = {x i t |i = 1, . . . , N t } in target domain, the adversarial loss L adv is the average classification loss, which is formulated as: where E denotes the expectation over the image set. The discriminator D will attempt to minimize this loss by differentiating between source and target representations, and the shared Fully Convolutional Network (FCN) is learnt to fool the domain discriminator. Considering that the image region corresponding to the receptive field of each spatial unit in the final feature map is treated as an individual instance during semantic segmentation, the representations of such instances are expected to be invariant across domains. Thus we employ a fully convolutional domain discriminator whose outputs are the domain prediction of each image region corresponding to the spatial unit in the feature map.</p><formula xml:id="formula_3">L adv (X s , X t ) = −E xt∼Xt [log(D(x t ))] −E xs∼Xs [log(1 − D(x s )] .<label>(4)</label></formula><p>Since training labels are available in the source domain, the loss function is based on the pixel-level classification loss L seg . In contrast, due to the absence of training labels, the loss function in the target domain is defined based upon the following three regularizers:</p><formula xml:id="formula_4">Lrpt(Xt) = E x t ∼X t [Lcc(xt) + Lpc(xt) + L sl (xt)] . (5)</formula><p>Here, we empirically treat each loss in RPT equally. Thus, the overall objective of the segmentation framework integrates L adv , L seg and L rpt as:</p><formula xml:id="formula_5">min F CN {−ε min D L adv (Xs, Xt) + Lseg(Xs) + Lrpt(Xt)} ,<label>(6)</label></formula><p>where ε = 0.1 is the trade-off parameter to align the scale of different losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation</head><p>Training strategy. Our proposed network is implemented in Caffe <ref type="bibr" target="#b23">[24]</ref> framework and the weights are trained by SGD optimizer. We employ dilated FCN <ref type="bibr" target="#b5">[6]</ref> originated from the ImageNet pre-trained ResNet-101 as our backbone followed by a PSP module <ref type="bibr" target="#b58">[59]</ref>, unless otherwise stated. The domain discriminator for adversarial learning is borrowed from FCAN <ref type="bibr" target="#b56">[57]</ref>. During the training stage, images are randomly cropped to 713 × 713 due to the limitation of GPU memory. Both random horizontal flipping and image resizing are utilized for data augmentation. To make the training process stable, we pre-train the FCN on data from the source domain with annotations. At the stage of pre-training, the "poly" policy whose power is fixed to 0.9 is adopted with the initial learning rate 0.001. Momentum and weight decay are 0.9 and 0.0005 respectively. Each mini-batch has 8 samples and maximum training iterations is set as 30K. With the source domain pre-trained weights, we perform the domain adaptation by finetuning the whole adaptation framework which is equipped with our proposed RPT. The initial learning rate is 0.0001 and the total training iteration is 10K. Other training hyper-parameters remain unchanged. Following <ref type="bibr" target="#b25">[26]</ref>, we randomly selected 500 images from the official training set of Cityscapes as a general validation set. The hyper-parameters (λ pc = λ cc = λ sl = 0.25, ε = 0.1) are all determined on this set.</p><p>Complexity of superpixel. RPT highly relies on the quality of superpixel extraction. For robustness, superpixels with complex content ideally should be excluded from model training. The term "complex" refers to the distribution of semantic labels in a superpixel. In our case, we measure complexity based on the proportion of pixels being predicted with the dominative category over the number of pixels in a superpixel. A larger value implies consistency in prediction and hence safer to involve the corresponding superpixel in regularizations. Empirically, RPT only regularizes the top-50% of superpixels. The empirical choice will be further validated in the next section.</p><p>State update of RPT. During network optimization, the segmentation prediction P seg , superpixel dominative categoryŷ i and cluster dominative categoryỹ k change gradually. Iteratively updating these "states" is computationally expensive because reassigning the categories to superpixel and cluster (e.g.,ŷ i andỹ k ) requires the semantic predictions collected from the whole training set of the target domain. Considering these predictions only change slightly during training, we first calculate these states before the optimization (without regularization) and fix these states at the beginning of iterations. Then, we will update the predictions or states for N su times evenly during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Datasets</head><p>The experiments are conducted on GTA5 <ref type="bibr" target="#b39">[40]</ref>, SYN-THIA <ref type="bibr" target="#b40">[41]</ref> and Cityscapes <ref type="bibr" target="#b10">[11]</ref> datasets. The proposed RPT is trained on GTA5 and SYNTHIA (source domain) and Cityscapes (target domain). GTA5 is composed of 24,966 synthetic images of size 1914×1052. These images are generated by Grand Theft Auto V (GTA5), a modern computer game, to render city scenes. The pixels of these images are annotated with 19 classes that are compatible with the labels in Cityscapes. Similarly, SYNTHIA consists of synthetic images of urban scenes with resolutions of 1280 × 760. Following <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47]</ref>, we use the subset, SYNTHIA-  RAND-CITYSCAPES, which has 9,400 images being annotated with labels consistent with Cityscapes for experiments. Cityscapes is composed of 5,000 images of resolution 2048 × 1024. These images are split into three subsets of sizes 2,975, 500 and 1,525 for training, validation and testing, respectively. The pixels of these images are annotated with 19 classes. In the experiments, the training subset is treated as the target-domain training data, where the pixel-level annotation is assumed unknown to RPT. On the other hand, the target-domain testing data is from validation subset. The same setting is also exploited in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47]</ref>. To this end, the performance of RPT is assessed by treating GTA5 as source domain and Cityscapes as target domain (i.e., GTA5 → Cityscapes), and similarly, SYN-THIA → Cityscapes. The metrics are per class Intersection over Union (IoU) and mean IoU over all the classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Evaluation of RPT</head><p>RPT is experimented on top of six different network architectures derived from FCN which leverages on either ResNet-50 or ResNet-101 as the backbone network. Specially, we adopt Adaptive Batch Normalization (ABN) to replace the mean and variance of BN in the original version of FCN, resulting in a variant of network named FCN+ABN. Note that the BN layer is first learnt in source domain and then replaced by ABN when being applied to the target domain. In addition, leveraging on the adversarial training (ADV), another variant, FCN+ABN+ADV, is trained to learn domain-invariant representations.</p><p>We first verify the impact of N su , the number of state updating, in RPT. <ref type="table" target="#tab_0">Table 1</ref> summarizes the impact on six variants of network for domain adaptation on GTA5 → Cityscapes. All the networks are pre-trained on ImageNet dataset and then injected with RPT. The super- script, RPT n , refers to the number of times for state updating (see <ref type="table" target="#tab_0">Table 1</ref> for exact number). The baselines are obtained by performing domain adaptation of semantic segmentation on the use of the corresponding network architectures, but without RPT. Overall, RPT improves the baseline without regularization. The improvement is consistently observed across the variants of networks, and proportional to the number of state updating at the expense of computation cost. RPT 3 achieves the best performance (mIoU = 52.6%) and with 5.4% improvement over the baseline of the same network (FCN+ABN+ADV). <ref type="figure" target="#fig_6">Figure 6</ref>(a) shows the performance changes in terms of mIoU during training over different times of state updating. The training starts with model learning in source domain. State updating, such as the assignment of dominative categories at superpixel and cluster levels, is then performed three times evenly during the training process in the target domain. Despite dropping in performance at the start of training after each state updating, mIoU gradually improves and eventually converges to a higher value than the previous round. <ref type="figure" target="#fig_6">Figure 6(b)</ref> shows the performance trend when the percentage of complex superpixels being excluded from learning gradually increases. As shown, the value mIoU constantly increases till reaching the level when 50% of superpixels are filtered. In the remaining experiments, we fix the setting of RPT to involve 50% of superpixels in regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">An Ablation Study</head><p>Next, we conduct an ablation study to assess the performance impacts of different design components. We separately assess the three regularizations in RPT: patchbased consistency regularization (PCR), cluster-based consistency regularization (CCR) and spatial logic regularization (SLR). <ref type="table" target="#tab_1">Table 2</ref> details the contribution of each component towards the overall performance. FCN adv , by considering adaptive batch normalization and adversarial learning (ABN+ADV), successfully boosts mIoU from 32.3% to 47.2%. The result indicates the importance of narrowing the domain gap between synthetic data and real images. The three regularizations in target domain introduce 1.8%, 0.6% and 0.8% of improvement, respectively. Furthermore, by increasing the number of state updating during network optimization, additional 2.2% of improvement is observed <ref type="table">Table 3</ref>. Comparisons with the state-of-the-art unsupervised domain adaptation methods on GTA5 → Cityscapes adaptation. Please note that the baseline methods are divided into five groups: (1) representation-level domain adaptation by adversarial learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref>; (2) appearance-level domain adaptation by image translation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref>; (3) appearance-level + representation-level adaptation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b56">57]</ref>; (4) self-learning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b60">61]</ref>; <ref type="bibr" target="#b4">(5)</ref> others <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b59">60]</ref>. <ref type="bibr">Method</ref> road sdwlk bldng wall fence pole light sign vgttn trrn sky person rider car truck bus train mcycl bcycl mIoU FCNWild <ref type="bibr" target="#b19">[20]</ref> 70. <ref type="bibr" target="#b3">4</ref>  -  from RPT 1 to RPT 3 . <ref type="figure" target="#fig_7">Figure 7</ref> shows the gradual improvement on semantic segmentation of five images, when different design components are incrementally integrated.</p><formula xml:id="formula_6">- - - - - - - - - - - - - - - - - -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Comparisons with State-of-the-Art</head><p>We compare with several state-of-the-art techniques for unsupervised domain adaptation on GTA5 → Cityscapes. Broadly, we can categorize the baseline methods into five categories: (1) representation-level domain adaptation by adversarial learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref>;</p><p>(2) appearance-level domain adaptation by image translation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref>; (3) appearance-level + representation-level adaptation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b56">57]</ref>; (4) self-learning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b60">61]</ref>; <ref type="bibr" target="#b4">(5)</ref> others <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b59">60]</ref>. The performance comparisons on GTA5 → Cityscapes adaptation are summarized in <ref type="table">Table 3</ref>. FCN adv +RPT 3 achieves new state-of-the-art performance with mIoU of 52.6%. Benefiting from the proposed regularizations, FCN adv +RPT 3 outperforms SSF-DAN <ref type="bibr" target="#b12">[13]</ref> and ADVENT <ref type="bibr" target="#b48">[49]</ref>, which also adopt a similar adversarial mechanism, by additional improvement of 7.2% and 7.1%, respectively. The performance is also better than the most recently proposed FCAN <ref type="bibr" target="#b56">[57]</ref> and Stylization <ref type="bibr" target="#b13">[14]</ref>, which exploit a novel appearance transferring module that is not considered in RPT. Comparing to the best reported result to-date by MLSL <ref type="bibr" target="#b22">[23]</ref>, our proposed model still leads the performance by 3.6%. By further integrating with the multi-scale (MS) scheme, i.e, FCN adv +RPT 3 +MS, the mIoU boosts to 53.2% with 9 out of the 19 categories reach to-date the best reported performances.</p><p>To verify the generalization of RPT, we also test the performance on SYNTHIA → Cityscapes using the same settings. Following previous works <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b60">61]</ref>, the performances are reported in terms of mIoU@16 and mIoU@13 by not considering the different number of categories. The performance comparisons are summarized in <ref type="table" target="#tab_4">Table 4</ref>. Similarly, FCN adv +RPT 3 +MS achieves the best performance with mIoU@16 = 51.7% and mIoU@13 = 59.5%. The performances are better than PyCDA, which reports the best known results, by 5% and 6.2% respectively.   <ref type="figure" target="#fig_8">Figure 8</ref> shows examples to demonstrate the effectiveness of patch-based and cluster-based consistency regularizations. Here, we crop some highlighted regions of input image, ground truth, prediction by FCN adv and prediction by FCN adv +RPT 3 , respectively. On one hand, as shown in <ref type="figure" target="#fig_8">Figure 8</ref>(a), patch-based consistency encourages the pixels to be predicted as the dominative category of the superpixel. On the other hand, cluster-based consistency is able to correct the predictions with the cue of visual similarity across superpixels as illustrated in <ref type="figure" target="#fig_8">Figure 8(b)</ref>. These examples validate our motivation of enforcing label consistency within superpixel and cluster, where most semantic labels are correctly predicted in the target domain. <ref type="figure">Figure 9</ref> further visualizes the merit of modeling spatial context by spatial logic regularization. Given the segmentation results from FCN adv , our proposed LSTM encoder-decoder outputs the logical probability of assigning current semantic labels to each region. The darkness indicates that the region is predicted with low logical probability. Better results are achieved by penalizing the illogical predictions, such as road on the top of vegetation (1st row) or car (2nd row), sky below building (3rd row), fence above building (4th row).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Examples of Regularization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head><p>FCNadv Logical Probability FCNadv+RPT 3 <ref type="figure">Figure 9</ref>. The examples of punished patches by spatial logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have presented Regularizer of Prediction Transfer (RPT) for unsupervised domain adaptation of semantic segmentation. RPT gives light to a novel research direction, by directly exploring the three intrinsic criteria of semantic segmentation to restrict the label prediction on the target domain. These criteria, when imposed as regularizers during training, are found to be effective in alleviating the problem of model overfitting. The patch-based consistency attempts to unify the prediction inside each region by introducing its dominative category to the unconfident pixels. The clusterbased consistency further amends the prediction according to other visually similar regions which belong to the same cluster. In pursuit of suppressing illogical predictions, spatial logic is involved to regularize the spatial relation which is shared across domains. Experiments conducted on the transfer from GTA5 to Cityscapes show that the injection of RPT can consistently improve the domain adaptation across different network architectures. More remarkably, the setting of FCN adv +RPT 3 achieves new state-of-the-art performance. A similar conclusion is also drawn from the adaptation from SYNTHIA to Cityscapes, which demonstrates the generalization ability of RPT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2006.06570v1 [cs.CV] 11 Jun 2020</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Example of pixels to be unpunished (a) or punished (b) in optimization. (a) For the unpunished cases, some pixels are very confident in the class differed from the dominative category. (b) For the punished cases, most pixels inside the region predict relatively high probabilities for the dominative category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Feature space visualization of seven superpixel clusters using t-SNE. The dominative category is given for each cluster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>The LSTM encoder-decoder architecture to learn the spatial logic in the prediction map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>The adversarial-based semantic segmentation adaptation framework with RPT. The shared FCN is learnt with adversarial loss for domain-invariant representations across two domains. The predictions on source domain are optimized by supervised label, while the target domain predictions are regularized by RPT loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Two analysis experiments of (a) the effectiveness of state updating during training of RPT 3 ; (b) the percentage of filtered complex superpixels of RPT 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Examples of semantic segmentation results on GTA5-Cityscapes adaptation. The original images, their ground truth and comparative results at different stages of FCN adv +RPT 3 are given.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Examples showing the effectiveness of patch-based consistency and cluster-based consistency in RPT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>RPT performances in terms of mean IoU for domain adaptation of semantic segmentation on GTA5 → Cityscapes.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Method</cell><cell cols="4">ResNet-50 FCN +ABN +ADV FCN +ABN +ADV ResNet-101</cell></row><row><cell></cell><cell></cell><cell cols="6">baseline 30.1 35.7 45.7</cell><cell>32.3 39.1 47.2</cell></row><row><cell></cell><cell></cell><cell cols="2">RPT 1</cell><cell cols="4">33.0 39.3 48.7</cell><cell>36.1 42.9 50.4</cell></row><row><cell></cell><cell></cell><cell cols="2">RPT 2</cell><cell cols="4">33.4 39.9 50.0</cell><cell>37.9 44.2 51.7</cell></row><row><cell></cell><cell></cell><cell cols="2">RPT 3</cell><cell cols="4">33.5 40.0 50.0</cell><cell>39.1 44.6 52.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50 .4</cell></row><row><cell></cell><cell>54</cell><cell></cell><cell cols="2">State Update</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50 .3</cell></row><row><cell></cell><cell>52</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50 .2</cell></row><row><cell>mIoU (%)</cell><cell>46 48 50</cell><cell></cell><cell>RPT 1</cell><cell>RPT 2</cell><cell cols="2">RPT 3</cell><cell>mIoU (%)</cell><cell>50 50 .1</cell></row><row><cell></cell><cell>44</cell><cell cols="2">w\o</cell><cell></cell><cell></cell><cell></cell><cell>49 .9</cell></row><row><cell></cell><cell>42</cell><cell>5 RPT</cell><cell cols="3">10 Number of training iterations (k) 15 20 25 30</cell><cell>35</cell><cell>40</cell><cell>Percentage of filtered complex superpixels (%) 0 5 10 15 20 25 30 35 40 45 49 .8</cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(a) State updating</cell><cell></cell><cell></cell><cell>(b) Filtering complex superpixels</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Contribution of each design in RPT for domain adaptation of semantic segmentation on GTA5 → Cityscapes.</figDesc><table><row><cell>Method</cell><cell cols="4">ABN ADV PCR CCR SLR SU mIoU</cell></row><row><cell>FCN +ABN FCN adv (+ADV) +PCR +CCR RPT 1 (+SLR) RPT 3</cell><cell>√ √ √ √ √ √</cell><cell>√ √ √ √ √ √ √ √ √</cell><cell>√ √ √ √ √ √</cell><cell>32.3 39.1 47.2 49.0 49.6 50.4 52.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>32.4 62.1 14.9 5.4 10.9 14.2 2.7 79.2 21.3 64.6 44.1 4.2 70.4 8.0 7.</figDesc><table><row><cell></cell><cell cols="3">3 0.0 3.5</cell><cell>0.0 27.1</cell></row><row><cell>Learning [44]</cell><cell cols="4">88.0 30.5 78.6 25.2 23.5 16.7 23.5 11.6 78.7 27.2 71.9 51.3 19.5 80.4 19.8 18.3 0.9 20.8 18.4 37.1</cell></row><row><cell>ROAD [10]</cell><cell cols="4">76.3 36.1 69.6 28.6 22.4 28.6 29.3 14.8 82.3 35.3 72.9 54.4 17.8 78.9 27.7 30.3 4.0 24.9 12.6 39.4</cell></row><row><cell>CyCADA [19]</cell><cell cols="4">79.1 33.1 77.9 23.4 17.3 32.1 33.3 31.8 81.5 26.7 69.0 62.8 14.7 74.5 20.9 25.6 6.9 18.8 20.4 39.5</cell></row><row><cell>AdaptSegNet [47]</cell><cell cols="4">86.5 36.0 79.9 23.4 23.3 23.9 35.2 14.8 83.4 33.3 75.6 58.5 27.6 73.7 32.5 35.4 3.9 30.1 28.1 42.4</cell></row><row><cell>CLAN [31]</cell><cell cols="4">87.0 27.1 79.6 27.3 23.3 28.3 35.5 24.2 83.6 27.4 74.2 58.6 28.0 76.2 33.1 36.7 6.7 31.9 31.4 43.2</cell></row><row><cell>Conditional [21]</cell><cell cols="4">89.2 49.0 70.7 13.5 10.9 38.5 29.4 33.7 77.9 37.6 65.8 75.1 32.4 77.8 39.2 45.2 0.0 25.5 35.4 44.5</cell></row><row><cell>SSF-DAN [13]</cell><cell cols="4">90.3 38.9 81.7 24.8 22.9 30.5 37.0 21.2 84.8 38.8 76.9 58.8 30.7 85.7 30.6 38.1 5.9 28.3 36.9 45.4</cell></row><row><cell>ADVENT [49]</cell><cell cols="4">89.4 33.1 81.0 26.6 26.8 27.2 33.5 24.7 83.9 36.7 78.8 58.7 30.5 84.8 38.5 44.5 1.7 31.6 32.4 45.5</cell></row><row><cell>I2I Adapt [32]</cell><cell cols="4">85.8 37.5 80.2 23.3 16.1 23.0 14.5 9.8 79.2 36.5 76.4 53.4 7.4 82.8 19.1 15.7 2.8 13.4 1.7 35.7</cell></row><row><cell>Stylization [14]</cell><cell cols="4">86.9 44.5 84.7 38.8 26.6 32.1 42.3 22.5 84.7 30.9 85.9 67.0 28.1 85.7 38.3 31.8 21.5 31.3 24.6 47.8</cell></row><row><cell>DCAN [50]</cell><cell cols="4">85.0 30.8 81.3 25.8 21.2 22.2 25.4 26.6 83.4 36.7 76.2 58.9 24.9 80.7 29.5 42.9 2.5 26.9 11.6 41.7</cell></row><row><cell>DISE [4]</cell><cell cols="4">91.5 47.5 82.5 31.3 25.6 33.0 33.7 25.8 82.7 28.8 82.7 62.4 30.8 85.2 27.7 34.5 6.4 25.2 24.4 45.4</cell></row><row><cell>FCAN [57]</cell><cell cols="4">88.9 37.9 82.9 33.2 26.1 42.8 43.2 28.4 86.5 35.2 78.0 65.9 22.8 86.7 23.7 34.9 2.7 24.0 41.9 46.6</cell></row><row><cell>FCTN [54]</cell><cell cols="3">72.2 28.4 74.9 18.3 10.8 24.0 25.3 17.9 80.1 36.7 61.1 44.7 0.0 74.5 8.9 1.5 0.0 0.0</cell><cell>0.0 30.5</cell></row><row><cell>CBST [61]</cell><cell cols="4">89.6 58.9 78.5 33.0 22.3 41.4 48.2 39.2 83.6 24.3 65.4 49.3 20.2 83.3 39.0 48.6 12.5 20.3 35.3 47.0</cell></row><row><cell>PyCDA [26]</cell><cell cols="4">92.3 49.2 84.4 33.4 30.2 33.3 37.1 35.2 86.5 36.9 77.3 63.3 30.5 86.6 34.5 40.7 7.9 17.6 35.5 48.0</cell></row><row><cell>MLSL [23]</cell><cell cols="4">89.0 45.2 78.2 22.9 27.3 37.4 46.1 43.8 82.9 18.6 61.2 60.4 26.7 85.4 35.9 44.9 36.4 37.2 49.3 49.0</cell></row><row><cell>Curriculum [55]</cell><cell>72.9 30 74.9 12.1 13.2 15.3 16.8 14.1 79.3 14.5 75.5 35.7 10 62.1 20.6 19</cell><cell>0</cell><cell cols="2">19.3 12 31.4</cell></row><row><cell>Penalizing [60]</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>44.7 84.2 34.6 27.6 30.2 36.0 36.0 85.0 43.6 83.0 58.6 31.6 83.3 35.3 49.7 3.3 28.8 35.6 48.5 FCN adv +RPT 1 88.7 37.0 85.2 36.6 27.7 42.6 49.1 30.0 86.9 37.6 80.7 66.8 27.5 88.1 30.3 39.5 22.5 28.0 53.0 50.4 FCN adv +RPT 3 89.2 43.3 86.1 39.5 29.9 40.2 49.6 33.1 87.4 38.5 86.0 64.4 25.1 88.5 36.6 45.8 23.9 36.5 56.8 52.6 FCN adv +RPT 3 +MS 89.7 44.8 86.4 44.2 30.6 41.4 51.7 33.0 87.8 39.4 86.3 65.6 24.5 89.0 36.2 46.8 17.6 39.1 58.3 53.2</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>38.1</cell></row><row><cell>Effective [43]</cell><cell cols="4">79.8 29.3 77.8 24.2 21.6 6.9 23.5 44.2 80.5 38.0 76.2 52.7 22.2 83.0 32.3 41.3 27.0 19.3 27.7 42.5</cell></row><row><cell>MaxSquare [8]</cell><cell cols="4">89.3 40.5 81.2 29.0 20.4 25.6 34.4 19.0 83.6 34.4 76.5 59.2 27.4 83.8 38.4 43.6 7.1 32.2 32.5 45.2</cell></row><row><cell cols="2">Bidirectional [25] 91.0 Image Ground Truth</cell><cell>FCN</cell><cell>FCNadv</cell><cell>FCNadv+RPT 3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Comparisons with the state-of-the-art unsupervised domain adaptation methods on SYNTHIA → Cityscapes transfer. road sdwlk bldng wall fence pole light sign vgttn sky person rider car bus mcycl bcycl mIoU@16 mIoU@13 Learning [44] 80.1 29.1 77.5 2.8 0.4 26.8 11.1 18.0 78.1 76.7 48.2 15.2 70.5 17.4 8.7 16.7 36.1 -ROAD [10] 77.7 30.0 77.5 9.6 0.3 25.8 10.3 15.6 77.6 79.8 44.5 16.6 67.8 14.5 7.0 23.8 13.7 78.2 81.5 53.4 21.2 73.0 32.9 22.6 30.7 -47.8 Conditional [21] 85.0 25.8 73.5 3.4 3.0 31.5 19.5 21.3 67.4 69.4 68.5 25.0 76.5 41.6 17.9 29.5 FCN adv +RPT 3 88.9 46.5 84.5 15.1 0.5 38.5 39.5 30.1 85.9 85.8 59.8 26.1 88.1 46.8 27.7 56.1 51.2 58.9 FCN adv +RPT 3 +MS 89.1 47.3 84.6 14.5 0.4 39.4 39.9 30.3 86.1 86.3 60.8 25.7 88.7 49.0 28.4 57.5 51.7 59.5</figDesc><table><row><cell>36.2</cell><cell>-</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radhakrishna</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Appu</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Whats the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploring object relation in mean teacher for cross-domain detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyu</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">All about structure: Adapting structural information across domains for boosting semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui-Po</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsiao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chen</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Searching for efficient multi-scale architectures for dense image prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain adaptation for semantic segmentation with maximum squares loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Road: Reality oriented adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ssf-dan: Separated semantic feature based domain adaptation network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongye</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Domain stylization: A strong, simple baseline for synthetic to real image domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aysegul</forename><surname>Dundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Zedlewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.09384</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Laplacian pyramid reconstruction and refinement for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic multiscale filters for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongying</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CyCADA: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02649</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conditional generative adversarial network for structured domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixiang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Mlsl: Multi-level selfsupervised learning for domain adaptation with spatially independent and semantically consistent labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javed</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Ali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13776</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Constructing self-motivated pyramid curriculums for crossdomain semantic segmentation: A non-adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Lixin Duan, and Boqing Gong</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning markov random field for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1814" to="1828" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image to image translation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zak</forename><surname>Murez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soheil</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyungnam</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Transferrable prototypical networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Constrained convolutional neural networks for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krhenbhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large kernel matters -improve semantic segmentation by global convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">From image-level to pixel-level labeling with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Full-resolution residual networks for semantic segmentation in street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning deep spatio-temporal dependence for semantic video segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Multimedia</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Effective use of synthetic data for urban scene semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fatemeh Sadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Sadegh Aliakbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose M</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning from synthetic data: Addressing domain shift for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">Gokhan</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Denseaspp for semantic segmentation in street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Semi-supervised domain adaptation with subspace learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ambrish Tyagi, and Amit Agrawal. Context encoding for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A fully convolutional tri-branch network (fctn) for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C-C Jay</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICASSP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A curriculum domain adaptation approach to the semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Foroosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Customizable architecture search for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fully convolutional adaptation networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Icnet for real-time semantic segmentation on high-resolution images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Penalizing top performers: Conservative loss for semantic segmentation adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ceyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Bvk Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
