<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Scale Progressive Fusion Network for Single Image Deraining</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of North Carolina at Charlotte 3 King&apos;s College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baojin</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjun</forename><surname>Jiang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Scale Progressive Fusion Network for Single Image Deraining</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rain streaks in the air appear in various blurring degrees and resolutions due to different distances from their positions to the camera. Similar rain patterns are visible in a rain image as well as its multi-scale (or multiresolution) versions, which makes it possible to exploit such complementary information for rain streak representation. In this work, we explore the multi-scale collaborative representation for rain streaks from the perspective of input image scales and hierarchical deep features in a unified framework, termed multi-scale progressive fusion network (MSPFN) for single image rain streak removal. For similar rain streaks at different positions, we employ recurrent calculation to capture the global texture, thus allowing to explore the complementary and redundant information at the spatial dimension to characterize target rain streaks. Besides, we construct multi-scale pyramid structure, and further introduce the attention mechanism to guide the fine fusion of this correlated information from different scales. This multi-scale progressive fusion strategy not only promotes the cooperative representation, but also boosts the end-to-end training. Our proposed method is extensively evaluated on several benchmark datasets and achieves state-of-the-art results. Moreover, we conduct experiments on joint deraining, detection, and segmentation tasks, and inspire a new research direction of vision taskdriven image deraining. The source code is available at https://github.com/kuihua/MSPFN .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Due to substantial degradation of the image content in rain images and videos, traditional image enhancement algorithms <ref type="bibr" target="#b26">[27]</ref> struggle to make desirable improvements on image quality. Therefore, developing specialized solutions for image deraining is imperative to a wide range of tasks <ref type="bibr" target="#b11">[12]</ref>, e.g. object detection and semantic segmentation. * Corresponding author  <ref type="figure">Figure 1</ref>. Demonstration of the collaborative representation of rain streaks. Specifically, similar rain patterns among rain streaks, both within the same scale (highlighted in cyan, pink and dark blue boxes) or cross different scales (highlighted in red, yellow, orange and green boxes), can help reconstruct the target rain streak (white box in the original rain image) with the complementary information (e.g. similar appearance, formation, etc.).</p><p>Traditional deraining methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b31">32]</ref> use simple linear-mapping transformations and are not robust to variations of the input <ref type="bibr" target="#b10">[11]</ref>, e.g., rain streaks with various directions, densities and sizes. Recently, deep-learning based methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b15">16]</ref> which operate with convolutional and non-linear layers have witnessed remarkable advantages over traditional methods. Despite obvious improvements on feature representation brought by those methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16]</ref>, their single-scale frameworks can hardly capture the inherent correlations of rain streaks across scales.</p><p>The repetitive samples of rain streaks in a rain image as well as its multi-scale versions (multi-scale pyramid images) may carry complementary information (e.g. similar appearance) to characterize target rain streaks. As illustrated in <ref type="figure">Fig. 1</ref>, the rain streaks (highlighted in the white box) in the original rain image share the similar rain patterns with the rain streaks (highlighted in the cyan, pink and dark blue boxes) at different positions as well as those (highlighted in the red, yellow, orange and green boxes) in the 1/2 scale rain image. Therefore, rain streaks both from the same scale (solid arrows) and across different scales (dashed arrows) encode complementary or redundant information for feature representation, which would help deraining in the original image. This correlation of image contents across scales has been successfully applied to other computer vision tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref>. Recently, authors in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref> construct pyramid frameworks to exploit the multi-scale knowledge for deraining. Unfortunately, those exploitations fail to make full use of the correlations of multi-scale rain streaks (although restricted to a fixed scale-factor of 2 <ref type="bibr" target="#b9">[10]</ref>). For example, Fu et al. <ref type="bibr" target="#b7">[8]</ref> decompose the rain image into different pyramid levels based on its resolution, and then individually solve the restoration sub-problems at the specific scale space through several parallel sub-networks. Such decomposition strategy is the basic idea of many recurrent deraining frameworks <ref type="bibr" target="#b18">[19]</ref>. Unlike <ref type="bibr" target="#b7">[8]</ref> completing the deraining task from each individual resolution level, Zheng et al. <ref type="bibr" target="#b43">[44]</ref> present a density-specific optimization for rain streak removal in a coarse-to-fine fashion, and gradually produce the rain-free image stage-by-stage <ref type="bibr" target="#b14">[15]</ref>. However, there are no direct communications of the inter-level features across cascaded pyramid layers except for the final outputs, thus failing to take all-rounded advantages of the correlated information of rain streaks across different scales. Consequently, these methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref> are still far from producing the desirable deraining results with the limited exploitation and utilization of multi-scale rain information.</p><p>To address these limitations of the prior works, we explore the multi-scale representation from input image scales and deep neural network representations in a unified framework, and propose a multi-scale progressive fusion network (MSPFN) to exploit the correlated information of rain streaks across scales for single image deraining. Specifically, we first generate the Gaussian pyramid rain images using Gaussian kernels to down-sample the original rain image in sequence. A coarse-fusion module (CFM) ( §3.1) is designed to capture the global texture information from these multi-scale rain images through recurrent calculation (Conv-LSTM), thus enabling the network to cooperatively represent the target rain streak using similar counterparts from global feature space. Meanwhile, the representation of the high-resolution pyramid layer is guided by previous outputs as well as all low-resolution pyramid layers. A finefusion module (FFM) ( §3.2) is followed to further integrate these correlated information from different scales. By using the channel attention mechanism, the network not only discriminatively learns the scale-specific knowledge from all preceding pyramid layers, but also reduces the feature redundancy effectively. Moreover, multiple FFMs can be cascaded to form a progressive multi-scale fusion. Finally, a reconstruction module (RM) is appended to aggregate the coarse and fine rain information extracted respectively from CFM and FFM for learning the residual rain image, which is the approximation of real rain streak distribution. The over-all framework is outlined in <ref type="figure" target="#fig_2">Fig. 2</ref>. The main contributions of this paper are as follows:</p><p>• We uncover the correlations of rain streaks in an image and propose a novel multi-scale progressive fusion network (MSPFN) which collaboratively represents rain streaks from multiple scales via the pyramid representation. • To better characterize rain streaks of different scales, we devise three basic modules, coarse-fusion module (CFM), fine-fusion module (FFM) and reconstruction module (RM), to effectively extract and integrate the multi-scale information. In these modules, the complementary information of similar patterns with rain streaks, both within the same scale or across different scales (pyramid layers), is progressively fused to characterize the rain streaks distribution in a collaborative/cooperative manner. • Apart from achieving the state-of-the-art deraining performance in terms of the conventional quantitative measurements (e.g. PSNR and SSIM), we build several synthetic rain datasets based on COCO <ref type="bibr" target="#b2">[3]</ref> and BDD <ref type="bibr" target="#b37">[38]</ref> datasets for joint image deraining, detection and segmentation tasks. To the best of our knowledge, we are the first to apply mainstream visionoriented tasks (detection and segmentation) for comprehensively evaluating the deraining performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In the last few years, substantial improvements <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17]</ref> have been observed on rain image restoration. In this work, we mainly focus on single image deraining because it is more challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Single Image Deraining</head><p>Previous traditional methods for single image deraining <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14]</ref> fail under the complex rain conditions and produce degraded image contents due to the limited linearmapping transformation. Very recently, deep-learning based approaches <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b38">39]</ref> have emerged for rain streak removal and demonstrated impressive restoration performance. For example, Fu et al. <ref type="bibr" target="#b5">[6]</ref> introduce a three-layer convolutional neural network (CNN) to estimate and remove rain streaks from its rain-contaminated counterpart. To better represent rain streaks, Zhang et al. <ref type="bibr" target="#b39">[40]</ref> take the rain density into account and present a multi-task CNN for joint rain density estimation and deraining. Later, Zhang et al. <ref type="bibr" target="#b40">[41]</ref> further incorporate quantitative, visual and discriminative performance into the objective function, and propose a conditional generative adversarial network for rain streak removal. In order to alleviate the learning difficulty, recurrent frameworks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b25">26]</ref> are designed to remove rain streaks in a stage-wise manner.  <ref type="figure" target="#fig_2">Figure 2</ref>. Outline of the proposed multi-scale progressive fusion network (MSPFN). We set the pyramid level to 3 as an example. MSPFN consists of four parts: initial feature extraction, coarse fusion, fine fusion, and rain streak reconstruction, which are combined to regress the residual rain image I * R . We produce the rain-free image IDerain by subtracting I * R from the original rain image IRain. The goal is to make IDerain as close as possible to the rain free image I Clean .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Multi-scale Learning</head><p>Rain streaks in the air show the apparent self-similarity, both within the same scale or across different scales, which makes it possible to exploit the correlated information across scales for rain streak representation. However, most existing deraining methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b39">40]</ref> ignore the underlying correlations of rain streaks across different scales. Only a few attempts <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref> have been made to exploit the multiscale knowledge. Fu et al. <ref type="bibr" target="#b7">[8]</ref> decompose the restoration task into multiple subproblems and employ a set of parallel subnetworks to individually estimate the rain information in a specific pyramid scale space. However, it does not exploit and utilize the correlated information among these pyramid layers. Different from the parallel pyramid framework in <ref type="bibr" target="#b7">[8]</ref>, Zheng et al. <ref type="bibr" target="#b43">[44]</ref> propose the cascaded pyramid network, which is similar to LapSRN <ref type="bibr" target="#b14">[15]</ref>, to iteratively remove rain streaks. However, only the high-level features are used to help the adjacent pyramid representation, which results in losing some useful hierarchical and scale features in a deep cascaded network. The significance of these features produced at different stages has been verified on image reconstruction tasks <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>Different from these methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref>, in this work we introduce a novel framework MSPFN to achieve the collaborative representation of rain streaks across different scales, where the rich multi-scale rain information extracted from the Gaussian pyramid images is progressively aggregated along the pyramid layers and stages of the network. As a result, our predicted rain streak distribution is more accurate via the multi-scale collaborative representation.  tions of rain streaks across different scales. We present the details of each building block and the loss function in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multi-scale Coarse Fusion</head><p>For a given rain image, our method first generates the Gaussian pyramid rain images using Gaussian kernels to down-sample the original rain image into different scales, e.g. 1/2 and 1/4. The network takes as input the pyramid rain images and extracts the shallow features through multiple parallel initial convolution layers (see the first block of "initial layer" in <ref type="figure" target="#fig_2">Fig. 2</ref>). Based on the initial features from each scale, the coarse-fusion module (CFM) then performs the deep extraction and fusion of multi-scale rain information through several parallel residual recurrent units (RRU), as shown in <ref type="figure" target="#fig_3">Fig. 3</ref>. The reasons for designing CFM are three folds: (a) To exploit the repetition of rain streaks under the same scale, we apply the recurrent calculation and residual learning to capture the global texture information, making it possible to cooperatively represent target rain streaks. More accurately, we introduce Conv-LSTM to model the information flow of context textures at spatial dimension with the recursive memory, where the contextual texture correlations are transformed into structured cyclic dependencies to capture the complementary or redundant rain information (e.g. the solid arrows in <ref type="figure">Fig. 1</ref>). (b) The multi-scale structure provides an alternative solution to greatly increase the receptive filed to cover more contents while maintaining a  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-scale Fine Fusion</head><p>The outputs of CFM go through the fine-fusion module (FFM) to refine the correlated information from different scales. As shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, FFM enjoys the similar multiscale structure with CFM for convenience. Unlike CFM, we introduce the channel attention unit (CAU) to enhance the discriminative learning ability of the network through focusing on the most informative scale-specific knowledge, making the cooperative representation more efficient. To alleviate the computation burden, we apply the strided convolution to reduce the spatial dimension of features, and finally utilize the deconvolution layer to increase the resolution to avoid losing resolution information, resulting in the U-shaped residual attention block (URAB). As depicted in <ref type="figure" target="#fig_5">Fig. 4</ref>, URAB is composed of several CAUs, along with the short skip connections to help the fine representation of multi-scale rain information. Moreover, long skip connections are used between cascaded FFMs to achieve progressive fusion of multi-scale rain information as well as to facilitate the effective backward propagation of the gradient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Rain Streak Reconstruction</head><p>To learn the final residual rain image, we further integrate both low-and high-level multi-scale features respectively from CFM and FFM via a reconstruction module (RM), schematically depicted in <ref type="figure" target="#fig_2">Fig. 2</ref>. Specifically, the outputs from CFM are concatenated with the outputs from the last FFM, and then a convolution layer is used to learn the channel interdependence and rescale the feature values from the two modules. Similarly, the iterative sampling and fusion of rain information across different pyramid layers are implemented to estimate the residual rain image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Loss Function</head><p>Mean squared error (MSE) is the commonly used loss to train the network <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b33">34]</ref>. However, it usually produces blurry and over-smoothed visual effect with the loss of highfrequency textures due to the squared penalty. In this work, we perform the successive approximation to the real rain streak distribution I R with the guidance of the Charbonnier penalty function <ref type="bibr" target="#b14">[15]</ref>, which is more tolerant of small errors and holds better convergence during training. The function is expressed as</p><formula xml:id="formula_0">L con = (I * R − I R ) 2 + ε 2 .<label>(1)</label></formula><p>In Equation <ref type="formula" target="#formula_0">(1)</ref>, I * R denotes the predicted residual rain image. The predicted rain-free image I Derain is generated by subtracting I * R from its rain-contaminated counterpart I Rain . The penalty coefficient ε is empirically set to 10 −3 .</p><p>In order to further improve the fidelity and authenticity of high-frequency details while removing rain streaks, we propose the additional edge loss to constrain the highfrequency components between the ground truth I Clean and the predicted rain-free image I Derain . The edge loss is defined as</p><formula xml:id="formula_1">L edge = (Lap(I Clean ) − Lap(I Derain )) 2 + ε 2 . (2)</formula><p>In Equation <ref type="formula">(2)</ref>, Lap(I Clean ) and Lap(I Derain ) denote the edge maps respectively extracted from I Clean and I Derain via the Laplacian operator <ref type="bibr" target="#b12">[13]</ref>. Then, the total loss function is given by</p><formula xml:id="formula_2">L = L con + λ × L edge ,<label>(3)</label></formula><p>where the weight parameter λ is empirically set to 0.05 to balance the loss terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Discussions</head><p>We conduct extensive experiments on several synthetic and real-world rain image datasets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b28">29]</ref> to evaluate the restoration performance of our proposed MSPFN as well as six state-of-the-art deraining methods. These representative methods include DerainNet <ref type="bibr" target="#b5">[6]</ref>, RESCAN <ref type="bibr" target="#b18">[19]</ref>, DIDMDN <ref type="bibr" target="#b39">[40]</ref>, UMRL <ref type="bibr" target="#b36">[37]</ref>, SEMI <ref type="bibr" target="#b30">[31]</ref> and PreNet <ref type="bibr" target="#b25">[26]</ref>. There is no unified training datasets for all competing methods in this paper, e.g. PreNet refers to JORDER <ref type="bibr" target="#b34">[35]</ref> and uses 1254 pairs for training. UMRL refers to <ref type="bibr" target="#b39">[40]</ref> and uses 12700 images for training. Therefore, directly taking the results from their papers is unfair and meaningless. To this end, we collect about 13700 clean/rain image pairs from <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b6">7]</ref> for training our network as well as other competing methods for a fair comparison. In particular, these competing methods are retrained in the experiments with their publicly released codes and follow their original settings under the unified training dataset. Separately, the detailed descriptions of the used datasets are tabulated in Table 1. In order to quantitatively evaluate the restoration quality, we adopt the commonly used evaluation metrics, such as Peak Signal to Noise Ratio (PSNR), Feature Similarity (FSIM) <ref type="bibr" target="#b41">[42]</ref>, and Structural Similarity (SSIM) <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>In our baseline, the pyramid levels are set to 3, i.e. the original scale, 1/2 scale and 1/4 scale. In CFM, the filter numbers of each recurrent Conv-LSTM are respectively set to 32, 64, and 128, corresponding to the gradually increasing resolution. The depths/numbers of FFM (M) and CAU (N) are set to 10 and 3, respectively. We use Adam optimizer with batch size of 8 for training on one NVIDIA Titan Xp GPU. The learning rate is initialized to 2 × 10 −4 and reduced by half at every 20000 steps till 1 × 10 −6 . We train the network for 30 epochs with the above settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Studies</head><p>Validation on Basic Components. Using our baseline model (M = 10, N = 3), we design six comparison models to analyze the effects of the proposed basic modules (CFM and FFM), multi-scale pyramid framework, and multi-scale progressive fusion scheme on deraining performance. Quantitative results on Test100 dataset are listed in <ref type="table">Table 2</ref>. From the results, our baseline MSPFN exhibits great superiority over its incomplete versions, including Model1 (single-scale framework with only the original input), Model2 (removing CFM from MSPFN), and Model3 (removing all FFMs from MSPFN), surpassing them by 0.73dB, 0.28dB, and 3.60dB (PSNR), respectively. Moreover, we construct Model4 by applying the fusion strategy in <ref type="bibr" target="#b7">[8]</ref> to verify the effectiveness of the proposed multi-scale progressive fusion scheme. It is evident that MSPFN gains a significant improvement over Model4 by 0.54dB with an acceptable complexity increase. Model5 (M = 5, N = 1) and Model6 (M = 6, N = 3) are the simplified variants of MSPFN with smaller depths. When compared with the single-scale framework (Model1), Model5 has the approximately equal amount of parameters but achieves faster inference speed with the multi-scale pyramid framework. Model6 has the similar computation complexity but more parameters as compared with Model1. The results show that Model5 achieves the comparable performance while it's a quarter more efficient. Model6 gains the better scores over Model1 by 0.32dB while keeping the similar computation complexity. We attribute these advantages to the effective cooperative representation of rain streaks among different pyramid layers and stages of the network.</p><p>Parameter Analysis on M and N . We assess the influence of the depth of FFM (M) and the number of CAU (N) on deraining performance. Based on our baseline (M = 10, N = 3), we construct three comparison models, i.e. MSPFN M 17N 1 , MSPFN M 13N 2 and MSPFN M 8N 5 , while keeping approximately the same number of parameters. As shown in <ref type="table" target="#tab_1">Table 3</ref>, the performance declines with the reduction of M. This indicates the important role of FFM for exploiting the multi-scale rain information in a progressive fashion. When increasing the number of CAU (MSPFN M 17N 2 ), it yields a slight improvement (0.13dB), but with additional 30% of the parameters. We also add two models MSPFN M 30N 1 and MSPFN M 5N 1 for comparison. The former is designed to pursue a better deraining performance with more FFMs to enhance multi-scale fusion, while the latter is a lightweight model with smaller depth (M = 5, N = 1) and width (all filter channels = 32). Meanwhile, the strided convolution and deconvolution are employed twice in our proposed U-shaped residual attention block (URAB) of MSPFN M 5N 1 to further alleviate the computation burden. As we expected, MSPFN M 30N 1 achieves the best scores for all the metrics. MSPFN M 5N 1 still obtains the acceptable performance, although being a much lighter network. Considering the tradeoff between efficiency and deraining performance, we set M and N to 17 and 1 respectively in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparisons with State-of-the-arts 4.3.1 Synthesized Data</head><p>We compare our MSPFN (M = 17, N = 1) with other six top-performing deraining methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b25">26]</ref> on five synthetic datasets. Quantitative results are shown in <ref type="table" target="#tab_2">Table 4</ref>. One can see that MSPFN achieves remarkable improvements over these state-of-the-art methods. For example, MSPFN surpasses DerainNet <ref type="bibr" target="#b5">[6]</ref> and DIDMDN <ref type="bibr" target="#b39">[40]</ref> by 9.01dB and 2.74dB, respectively, in terms of PSNR on Test1200 dataset. Visual results on different rain condi-  tions (diverse rain streak orientations and magnitudes) are presented in <ref type="figure" target="#fig_6">Fig. 5</ref>. MSPFN exhibits impressive restoration performance on all scenarios, generating results with rich and credible image textures while removing main rain streaks. For other comparison methods, they tend to blur the image contents, or still leave some visible rain streaks. For example, only our MSPFN restores the clear and credible image details in the "Giraffe" image, while the competing methods fail to remove rain streaks and their results have obvious color distortion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Real-world Data</head><p>We conduct additional comparisons on three real-world datasets, including Real200 <ref type="bibr" target="#b39">[40]</ref>, Rain in Driving (RID) and Rain in Surveillance (RIS) datasets <ref type="bibr" target="#b17">[18]</ref>, to further verify the generalization capability of MSPFN. RID and RIS cover 2495 and 2348 samples, collected from car-mounted cameras and networked traffic surveillance cameras in rainy days respectively. Moreover, we use another two quantitative indicators, Naturalness Image Quality Evaluator (NIQE) <ref type="bibr" target="#b22">[23]</ref> and Spatial-Spectral Entropy-based Quality (SSEQ) <ref type="bibr" target="#b21">[22]</ref>, to quantitatively evaluate the reference-free restoration performance. The smaller scores of SSEQ and NIQE indicate better perceptual quality and clearer contents. The results are listed in <ref type="table" target="#tab_3">Table 5</ref>. As expected, our proposed MSPFN has the best average scores on 200 realworld samples, outperforming the state-of-the-art deraining methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b25">26]</ref> by a large margin. Moreover, we show four representative deraining examples in <ref type="figure">Fig. 6</ref> for visual comparison. In the last image, obvious rain streaks are observed in the results of other deraining methods, but our MSPFN can well preserve more realistic and credible image details while effectively removing main rain streaks.  <ref type="figure">Figure 6</ref>. Comparison results on four real-world scenarios with RESCAN <ref type="bibr" target="#b18">[19]</ref>, UMRL <ref type="bibr" target="#b36">[37]</ref> and PreNet <ref type="bibr" target="#b25">[26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Other Applications</head><p>Image deraining under complex weather conditions can be considered as an effective enhancement of image content. It can potentially be incorporated into other high-level vision systems for applications such as object detection and segmentation. This motivates us to investigate the effect of restoration performance on the accuracy of object detection and segmentation based on some popular algorithms, e.g. YOLOv3 <ref type="bibr" target="#b24">[25]</ref>, Mask R-CNN <ref type="bibr" target="#b11">[12]</ref>, and RefineNet <ref type="bibr" target="#b20">[21]</ref>. To this end, we randomly select a total of 850 samples from COCO <ref type="bibr" target="#b2">[3]</ref> and BDD <ref type="bibr" target="#b37">[38]</ref> datasets to create three new synthetic rain datasets COCO350 (for detection), BDD350 (for performing deraining methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b25">26]</ref>, the restoration procedures are directly implemented on these three datasets to produce the rain-free images. And then we apply the public available pre-trained models of YOLOv3 (for detection), Mask R-CNN (for instance segmentation), and RefineNet (for semantic segmentation) to perform the the downstream tasks. Qualitative results, including the deraining performance as well as the precision of the subsequent detection and segmentation tasks, are tabulated in <ref type="table" target="#tab_4">Table 6</ref>. In addition, visual comparisons are shown in <ref type="figure">Fig. 7</ref>. It is obvious that rain streaks can greatly degrade the detection accuracy and segmentation precision, night scenarios in particular, i.e. by missing targets and producing low detection or segmentation confidence (mean pixel accuracy (mPA) and mean Intersection of Union (mIoU)). In addition, the detection precision of the produced rain-free images by MSPFN shows a notable improvement over that of original rain inputs by nearly 10%, and MSPFN achieves the best results of 52.96% mPA as well as 35.90% mIoU for semantic segmentation task on BDD150. When compared with other top-performing deraining models, the rain-free images generated by MSPFN show more credible contents with more details, which effectively promote the detection and segmentation performance. Moreover, we also evaluate our lightweight deraining model MSPFN * with lighter depth (M = 5, N = 1) and width (with all filter channels of 32) since computation efficiency is crucial for mobile devices and applications require real-time throughput such as autonomous driving. MSPFN * still achieves competitive performance compared with other models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b25">26]</ref> while it's a half more efficient in terms of inference time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose a novel multi-scale progressive fusion network (MSPFN) to exploit the multi-scale rain information to cooperatively represent rain streaks based on the pyramid framework. To achieve this goal, we design several basic modules (CFM, FFM and RM) along with our proposed multi-scale progressive fusion mechanism to explore the inherent correlations of the similar rain patterns among multi-scale rain streaks. Consequently, our predicted rain streak distribution is potentially more correct due to the collaborative representation of rain streaks across different scales. Experimental results on several synthetic deraining datasets and real-world scenarios, as well as several downstream vision tasks (i.e. object detection and segmentation) have shown great superiority of our proposed MSPFN algorithm over other top-performing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>shows the overall pipeline of our proposed multiscale progressive fusion network (MSPFN) for image deraining by excavating and exploiting the inherent correla-Pixel-wise Summation Skip Connection Convolution Conv-LSTM Initial Features : Input Gate : Hidden State in t : Output Gate : Hidden State in t+1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Pipeline of the proposed residual recurrent units (RRU).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Pipeline of our proposed U-shaped residual attention block (URAB). URAB is composed of several cascaded channel attention units (CAUs) to promote the fusion of the multi-scale rain information and reduce the feature redundancy by focusing on the most useful channels. shallow depth. (c) The high-resolution representations benefit from the outputs of previous stages as well as all lowresolution pyramid layers via iterative sampling and fusion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Restoration results on synthetic datasets, including Rain100H, Rain100L, Test100, and Test1200.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Dataset description. A total of 13712 clean/rain image pairs are used for training. There are additional 4300 labeled reference samples as well as 200 real-world scenarios for testing. Evaluation of the basic components in our baseline MSPFN on Test100 dataset. We obtain the average inference time of deraining on images with size of 512× 384.</figDesc><table><row><cell>Datasets</cell><cell></cell><cell cols="2">Training Samples</cell><cell cols="2">Testing Samples</cell><cell>Name</cell><cell></cell></row><row><cell cols="2">Rain14000 [7]</cell><cell>11200</cell><cell></cell><cell cols="2">2800</cell><cell cols="2">Test2800</cell></row><row><cell cols="2">Rain1800 [35]</cell><cell>1800</cell><cell></cell><cell>0</cell><cell></cell><cell cols="2">Rain1800</cell></row><row><cell>Rain800 [41]</cell><cell></cell><cell>700</cell><cell></cell><cell cols="2">100</cell><cell cols="2">Test100</cell></row><row><cell cols="2">Rain100H [35]</cell><cell>0</cell><cell></cell><cell cols="2">100</cell><cell cols="2">Rain100H</cell></row><row><cell cols="2">Rain100L [35]</cell><cell>0</cell><cell></cell><cell cols="2">100</cell><cell cols="2">Rain100L</cell></row><row><cell cols="2">Rain1200 [40]</cell><cell>0</cell><cell></cell><cell cols="2">1200</cell><cell cols="2">Test1200</cell></row><row><cell>Rain12 [20]</cell><cell></cell><cell>12</cell><cell></cell><cell>0</cell><cell></cell><cell cols="2">Rain12</cell></row><row><cell cols="2">Real200 [29, 31]</cell><cell>0</cell><cell></cell><cell cols="2">200</cell><cell cols="2">Real200</cell></row><row><cell>RID/RIS [18]</cell><cell></cell><cell>0</cell><cell></cell><cell cols="2">2495/2348</cell><cell cols="2">RID/RIS</cell></row><row><cell>Total Count</cell><cell></cell><cell>13712</cell><cell></cell><cell cols="2">9343</cell><cell>-</cell><cell></cell></row><row><cell>Models</cell><cell>Model1</cell><cell>Model2</cell><cell>Model3</cell><cell>Model4</cell><cell>Model5</cell><cell>Model6</cell><cell>MSPFN</cell></row><row><cell>PSNR</cell><cell>26.56</cell><cell>27.01</cell><cell>23.69</cell><cell>26.75</cell><cell>26.48</cell><cell>26.88</cell><cell>27.29</cell></row><row><cell>SSIM</cell><cell>0.861</cell><cell>0.864</cell><cell>0.831</cell><cell>0.863</cell><cell>0.862</cell><cell>0.865</cell><cell>0.869</cell></row><row><cell>FSIM</cell><cell>0.921</cell><cell>0.923</cell><cell>0.905</cell><cell>0.923</cell><cell>0.921</cell><cell>0.923</cell><cell>0.925</cell></row><row><cell>Ave. inf. time (s)</cell><cell>0.192</cell><cell>0.224</cell><cell>0.113</cell><cell>0.238</cell><cell>0.141</cell><cell>0.180</cell><cell>0.308</cell></row><row><cell>Par. (Millions)</cell><cell>5.53</cell><cell>11.30</cell><cell>2.29</cell><cell>11.75</cell><cell>5.60</cell><cell>8.45</cell><cell>13.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of the depth of FFM (M), the number of CAU (N), as well as the model parameters on Test100 dataset. MSPFN M aN b denotes the model with M = a and N = b.</figDesc><table><row><cell>Models</cell><cell>MSPFN M 30N 1</cell><cell>MSPFN M 17N 1</cell><cell>MSPFN M 17N 2</cell><cell>MSPFN M 13N 2</cell><cell>MSPFN M 10N 3</cell><cell>MSPFN M 8N 5</cell><cell>MSPFN M 5N 1</cell></row><row><cell>PSNR</cell><cell>27.91</cell><cell>27.50</cell><cell>27.63</cell><cell>27.42</cell><cell>27.29</cell><cell>27.13</cell><cell>24.99</cell></row><row><cell>SSIM</cell><cell>0.879</cell><cell>0.876</cell><cell>0.877</cell><cell>0.874</cell><cell>0.869</cell><cell>0.867</cell><cell>0.850</cell></row><row><cell>SSIM</cell><cell>0.929</cell><cell>0.928</cell><cell>0.928</cell><cell>0.927</cell><cell>0.925</cell><cell>0.924</cell><cell>0.916</cell></row><row><cell>Par. (Millions)</cell><cell>21.81</cell><cell>13.35</cell><cell>17.20</cell><cell>13.63</cell><cell>13.22</cell><cell>14.56</cell><cell>1.65</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Comparison results of average PSNR, SSIM and FSIM on several widely used rain datasets, including Rain100H, Rain100L, Test100, Test2800, and Test1200. MSPFN w/o Eloss denotes our model without the edge constraint in the loss function.</figDesc><table><row><cell>Methods</cell><cell>Test100 PSNR/SSIM/FSIM</cell><cell>Rain100H PSNR/SSIM/FSIM</cell><cell>Rain100L PSNR/SSIM/FSIM</cell><cell>Test2800 PSNR/SSIM/FSIM</cell><cell>Test1200 PSNR/SSIM/FSIM</cell><cell>Average PSNR/SSIM/FSIM</cell></row><row><cell>DerainNet [6]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Comparison results of average NIQE/SSEQ on real-world datasets (Real200, RID, and RIS). The smaller scores indicate better perceptual quality.</figDesc><table><row><cell>Methods</cell><cell>RESCAN [19]</cell><cell>UMRL [37]</cell><cell>PreNet [26]</cell><cell>MSPFN (Ours)</cell></row><row><cell>Real200</cell><cell>4.724/30.47</cell><cell>4.675/29.38</cell><cell>4.620/29.51</cell><cell>4.459/29.26</cell></row><row><cell>RID</cell><cell>6.641/40.62</cell><cell>6.757/41.04</cell><cell>7.007/43.04</cell><cell>6.518/40.47</cell></row><row><cell>RIS</cell><cell>6.485/50.89</cell><cell>5.615/43.45</cell><cell>6.722/48.22</cell><cell>6.135/43.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .</head><label>6</label><figDesc>Comparison results of joint image deraining, object detection, and semantic segmentation on COCO350, BDD350, and BDD150 datasets. MSPFN * denotes the lightweight model with lighter depth and width comparing to MSPFN. These rain images are of diverse streak orientations and magnitudes, and at the same time have complex imaging conditions such as night scenes. By using our proposed deraining algorithm MSPFN as well as other top-Examples of joint deraining, object detection and segmentation. The first row denotes the instance segmentation results of Mask R-CNN<ref type="bibr" target="#b11">[12]</ref> on BDD150 dataset. The second and third rows are the comparison results of semantic segmentation by RefineNet<ref type="bibr" target="#b20">[21]</ref> on BDD150 dataset. We use YOLOv3<ref type="bibr" target="#b24">[25]</ref> for object detection on COCO350 dataset and the results are shown in the last two rows. MSPFN</figDesc><table><row><cell>Methods</cell><cell>Rain input</cell><cell>RESCAN [19]</cell><cell>PreNet [26]</cell><cell>MSPFN  *  (Ours)</cell><cell>MSPFN (Ours)</cell></row><row><cell></cell><cell cols="4">Deraining; Dataset: COCO350/BDD350; Image Size: 640× 480/1280× 720</cell><cell></cell></row><row><cell>PSNR</cell><cell>14.79/14.13</cell><cell>17.04/16.71</cell><cell>17.53/16.90</cell><cell>17.74/17.38</cell><cell>18.23/17.85</cell></row><row><cell>SSIM</cell><cell>0.648/0.470</cell><cell>0.745/0.646</cell><cell>0.765/0.652</cell><cell>0.773/0.678</cell><cell>0.782/0.761</cell></row><row><cell>Ave.inf.time (s)</cell><cell>-/-</cell><cell>0.55/1.53</cell><cell>0.22/0.76</cell><cell>0.08/0.23</cell><cell>0.58/1.24</cell></row><row><cell cols="6">Object Detection; Algorithm: YOLOv3 [25]; Dataset: COCO350/BDD350; Threshold: 0.6</cell></row><row><cell>Precision (%)</cell><cell>23.03/36.86</cell><cell>28.74/40.33</cell><cell>31.31/38.66</cell><cell>30.99/39.91</cell><cell>32.56/41.04</cell></row><row><cell>Recall (%)</cell><cell>29.60/42.80</cell><cell>35.61/47.79</cell><cell>37.92/48.59</cell><cell>37.99/49.74</cell><cell>39.31/50.40</cell></row><row><cell>IoU (%)</cell><cell>55.50/59.85</cell><cell>59.81/61.98</cell><cell>60.75/61.08</cell><cell>61.06/61.90</cell><cell>61.69/62.42</cell></row><row><cell></cell><cell cols="4">Deraining; Dataset: BDD150; Image Size: 1280× 720</cell><cell></cell></row><row><cell>PSNR</cell><cell>18.00</cell><cell>20.96</cell><cell>21.52</cell><cell>21.73</cell><cell>22.48</cell></row><row><cell>SSIM</cell><cell>0.722</cell><cell>0.859</cell><cell>0.886</cell><cell>0.887</cell><cell>0.904</cell></row><row><cell>Ave.inf.time (s)</cell><cell>-</cell><cell>1.53</cell><cell>0.76</cell><cell>0.23</cell><cell>1.24</cell></row><row><cell></cell><cell cols="4">Semantic Segmentation; Algorithm: RefineNet [21]; Dataset: BDD150</cell><cell></cell></row><row><cell>mPA (%)</cell><cell>33.29</cell><cell>45.34</cell><cell>50.28</cell><cell>50.25</cell><cell>52.96</cell></row><row><cell>mIoU (%)</cell><cell>20.49</cell><cell>31.52</cell><cell>33.42</cell><cell>33.74</cell><cell>35.90</cell></row><row><cell cols="6">detection), and BDD150 (for segmentation) through Pho-</cell></row><row><cell>toshop.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* denotes the lightweight model with lighter depth and width comparing to MSPFN.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported by National Key R&amp;D Project (2016YFE0202300) and National Natural Science Foundation of China (U1903214, 61671332, U1736206, 41771452, 41771454, 61971165), and Hubei Province Technological Innovation Major Project (2019AAA049, 2018CFA024).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analysis of rain and snow in frequency space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasa</forename><surname>Barnum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page">256</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rain or snow detection in image sequences through use of a histogram of orientation of streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérémie</forename><surname>Bossu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Hautière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Tarel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="348" to="367" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cocostuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1209" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust video content alignment and compensation for rain removal in a cnn framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheen-Hau</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lap-Pui</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6286" to="6295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A generalized lowrank appearance model for spatio-temporally correlated rain streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiou-Ting</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1968" to="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Clearing the skies: A deep network architecture for single-image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghao</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2944" to="2956" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Removing rain from single images via a deep detail network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3855" to="3863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Lightweight pyramid networks for image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">When does a camera see rain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitiz</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1067" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Superresolution from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Glasner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Bagon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="349" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rana</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noa</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">90</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Piotr Dollar, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on ICCV</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimally isotropic laplacian operator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behzad</forename><surname>Kamgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Parsi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azriel</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1467" to="1472" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatic single-image-based rain streaks removal via image decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wei</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Hsiang</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1742" to="1755" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep laplacian pyramid networks for fast and accurate super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Sheng</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="624" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoteng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loong-Fah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Cheong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.06830</idno>
		<title level="m">Single image deraining using scale-aware multi-stage recurrent network</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Heavy rain image restoration: Integrating physics model and conditional adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoteng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loong-Fah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Cheong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1633" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Single image deraining: A comprehensive benchmark analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iago</forename><forename type="middle">Breno</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">K</forename><surname>Tokuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><forename type="middle">Hirata</forename><surname>Junior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cesar-Junior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochun</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3838" to="3847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Recurrent squeeze-and-excitation context aggregation net for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="254" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rain streak removal using layer priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2736" to="2744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1925" to="1934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">No-reference image quality assessment based on spatial and spectral entropies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixiong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">Conrad</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing: Image Communication</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="856" to="863" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Making a &quot;completely blind &quot; image quality analyzer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="212" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attentive generative adversarial network for raindrop removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2482" to="2491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Progressive image deraining networks: a better and simpler baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Dongwei Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3937" to="3946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multinet: Realtime joint semantic reasoning for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Teichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Zoellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1013" to="1020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image super-resolution using dense skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiejie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinquan</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4799" to="4807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spatial attentive single-image deraining with a high quality real rain dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rynson Wh</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12270" to="12279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semi-supervised transfer learning for image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3877" to="3886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An improved guidance image based method to remove rain and snow in a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianglong</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer and Information Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploiting self-similarities for single frame super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian conference on ACCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="497" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Scale-free single image deraining via visibility-enhanced recurrent wavelet learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2948" to="2961" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep joint rain detection and removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1357" to="1366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Single image deraining using a recurrent multi-scale aggregation and enhancement network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youzhao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on ICME</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1378" to="1383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Uncertainty guided multi-scale residual learning-using a cycle spinning cnn for single image de-raining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Yasarla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8405" to="8414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Bdd100k: A diverse driving video database with scalable annotation tooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vashisht</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04687</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Convolutional sparse and lowrank coding-based rain streak removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on WACV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1259" to="1267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Density-aware single image de-raining using a multi-stream dense network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="695" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image de-raining using a conditional generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwanath</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fsim: A feature similarity index for image quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanqin</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2378" to="2386" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Residual dense network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yapeng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2472" to="2481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Residual multiscale based single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yupei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miaomiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunli</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
