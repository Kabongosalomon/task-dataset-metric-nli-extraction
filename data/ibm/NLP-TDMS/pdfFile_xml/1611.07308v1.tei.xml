<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Variational Graph Auto-Encoders 1 A latent variable model for graph-structured data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-11-21">21 Nov 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
							<email>t.n.kipf@uva.nl</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling@uva</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nl</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Canadian Institute for Advanced Research (CIFAR)</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Variational Graph Auto-Encoders 1 A latent variable model for graph-structured data</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-11-21">21 Nov 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: Latent space of unsupervised VGAE model trained on Cora citation network dataset <ref type="bibr" target="#b0">[1]</ref>. Grey lines denote citation links. Colors denote document class (not provided during training). Best viewed on screen.</p><p>We introduce the variational graph autoencoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs (see <ref type="figure">Figure 1</ref>). We demonstrate this model using a graph convolutional network (GCN) [4] encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.</p><p>Definitions We are given an undirected, unweighted graph G = (V, E) with N = |V| nodes. We introduce an adjacency matrix A of G (we assume diagonal elements set to 1, i.e. every node is connected to itself) and its degree matrix D. We further introduce stochastic latent variables z i , summarized in an N × F matrix Z. Node features are summarized in an N × D matrix X.</p><p>Inference model We take a simple inference model parameterized by a two-layer GCN:</p><p>Here, µ = GCN µ (X, A) is the matrix of mean vectors µ i ; similarly log σ = GCN σ <ref type="figure">(X, A)</ref>.</p><p>The two-layer GCN is defined as GCN(X, A) =Ã ReLU Ã XW 0 W 1 , with weight matrices W i . GCN µ (X, A) and GCN σ (X, A) share first-layer parameters W 0 . ReLU(·) = max(0, ·) and A = D − 1 2 AD − 1 2 is the symmetrically normalized adjacency matrix.</p><p>Generative model Our generative model is given by an inner product between latent variables:</p><p>where A ij are the elements of A and σ(·) is the logistic sigmoid function.</p><p>Learning We optimize the variational lower bound L w.r.t. the variational parameters W i :</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 A latent variable model for graph-structured data  <ref type="bibr" target="#b0">[1]</ref>. Grey lines denote citation links. Colors denote document class (not provided during training). Best viewed on screen.</p><p>We introduce the variational graph autoencoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs (see <ref type="figure" target="#fig_0">Figure 1</ref>). We demonstrate this model using a graph convolutional network (GCN) <ref type="bibr" target="#b3">[4]</ref> encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.</p><p>Definitions We are given an undirected, unweighted graph G = (V, E) with N = |V| nodes. We introduce an adjacency matrix A of G (we assume diagonal elements set to 1, i.e. every node is connected to itself) and its degree matrix D. We further introduce stochastic latent variables z i , summarized in an N × F matrix Z. Node features are summarized in an N × D matrix X.</p><p>Inference model We take a simple inference model parameterized by a two-layer GCN:</p><formula xml:id="formula_0">q(Z | X, A) = N i=1 q(z i | X, A) , with q(z i | X, A) = N (z i | µ i , diag(σ 2 i )) .<label>(1)</label></formula><formula xml:id="formula_1">Here, µ = GCN µ (X, A) is the matrix of mean vectors µ i ; similarly log σ = GCN σ (X, A). The two-layer GCN is defined as GCN(X, A) =Ã ReLU Ã XW 0 W 1 , with weight matrices W i . GCN µ (X, A) and GCN σ (X, A) share first-layer parameters W 0 . ReLU(·) = max(0, ·) and A = D − 1 2 AD − 1 2</formula><p>is the symmetrically normalized adjacency matrix.</p><p>Generative model Our generative model is given by an inner product between latent variables:</p><formula xml:id="formula_2">p (A | Z) = N i=1 N j=1 p (A ij | z i , z j ) , with p (A ij = 1 | z i , z j ) = σ(z i z j ) ,<label>(2)</label></formula><p>where A ij are the elements of A and σ(·) is the logistic sigmoid function.</p><p>Learning We optimize the variational lower bound L w.r.t. the variational parameters W i :</p><formula xml:id="formula_3">L = E q(Z|X,A) log p (A | Z) − KL q(Z | X, A) || p(Z) ,<label>(3)</label></formula><p>where KL[q(·)||p(·)] is the Kullback-Leibler divergence between q(·) and p(·). We further take a Gaussian prior p(Z) = i p(z i ) = i N (z i | 0, I). For very sparse A, it can be beneficial to re-weight terms with A ij = 1 in L or alternatively sub-sample terms with A ij = 0. We choose the former for the following experiments. We perform full-batch gradient descent and make use of the reparameterization trick <ref type="bibr" target="#b1">[2]</ref> for training. For a featureless approach, we simply drop the dependence on X and replace X with the identity matrix in the GCN.</p><p>Non-probabilistic graph auto-encoder (GAE) model For a non-probabilistic variant of the VGAE model, we calculate embeddings Z and the reconstructed adjacency matrixÂ as follows:</p><formula xml:id="formula_4">A = σ ZZ , with Z = GCN(X, A) .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experiments on link prediction</head><p>We demonstrate the ability of the VGAE and GAE models to learn meaningful latent embeddings on a link prediction task on several popular citation network datastets <ref type="bibr" target="#b0">[1]</ref>. The models are trained on an incomplete version of these datasets where parts of the citation links (edges) have been removed, while all node features are kept. We form validation and test sets from previously removed edges and the same number of randomly sampled pairs of unconnected nodes (non-edges).</p><p>We compare models based on their ability to correctly classify edges and non-edges. The validation and test sets contain 5% and 10% of citation links, respectively. The validation set is used for optimization of hyperparameters. We compare against two popular baselines: spectral clustering (SC) <ref type="bibr" target="#b4">[5]</ref> and DeepWalk (DW) <ref type="bibr" target="#b5">[6]</ref>. Both SC and DW provide node embeddings Z. We use Eq. 4 (left side) to calculate scores for elements of the reconstructed adjacency matrix. We omit recent variants of DW <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> due to comparable performance. Both SC and DW do not support input features.</p><p>For VGAE and GAE, we initialize weights as described in <ref type="bibr" target="#b8">[9]</ref>. We train for 200 iterations using Adam <ref type="bibr" target="#b9">[10]</ref> with a learning rate of 0.01. We use a 32-dim hidden layer and 16-dim latent variables in all experiments. For SC, we use the implementation from <ref type="bibr" target="#b10">[11]</ref> with an embedding dimension of 128. For DW, we use the implementation provided by the authors of <ref type="bibr" target="#b7">[8]</ref> with standard settings used in their paper, i.e. embedding dimension of 128, 10 random walks of length 80 per node and a context size of 10, trained for a single epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Results for the link prediction task in citation networks are summarized in <ref type="table" target="#tab_0">Table 1</ref>. GAE* and VGAE* denote experiments without using input features, GAE and VGAE use input features. We report area under the ROC curve (AUC) and average precision (AP) scores for each model on the test set. Numbers show mean results and standard error for 10 runs with random initializations on fixed dataset splits. Both VGAE and GAE achieve competitive results on the featureless task. Adding input features significantly improves predictive performance across datasets. A Gaussian prior is potentially a poor choice in combination with an inner product decoder, as the latter tries to push embeddings away from the zero-center (see <ref type="figure" target="#fig_0">Figure 1</ref>). Nevertheless, the VGAE model achieves higher predictive performance on both the Cora and the Citeseer dataset.</p><p>Future work will investigate better-suited prior distributions, more flexible generative models and the application of a stochastic gradient descent algorithm for improved scalability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Latent space of unsupervised VGAE model trained on Cora citation network dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Link prediction task in citation networks. See<ref type="bibr" target="#b0">[1]</ref> for dataset details. ± 0.01 88.5 ± 0.00 80.5 ± 0.01 85.0 ± 0.01 84.2 ± 0.02 87.8 ± 0.01 DW<ref type="bibr" target="#b5">[6]</ref> 83.1 ± 0.01 85.0 ± 0.00 80.5 ± 0.02 83.6 ± 0.01 84.4 ± 0.00 84.1 ± 0.00 GAE* 84.3 ± 0.02 88.1 ± 0.01 78.7 ± 0.02 84.1 ± 0.02 82.2 ± 0.01 87.4 ± 0.00 VGAE* 84.0 ± 0.02 87.7 ± 0.01 78.9 ± 0.03 84.1 ± 0.02 82.7 ± 0.01 87.5 ± 0.01 GAE 91.0 ± 0.02 92.0 ± 0.03 89.5 ± 0.04 89.9 ± 0.05 96.4 ± 0.00 96.5 ± 0.00 VGAE 91.4 ± 0.01 92.6 ± 0.01 90.8 ± 0.02 92.0 ± 0.02 94.4 ± 0.02 94.7 ± 0.02</figDesc><table><row><cell>Method</cell><cell>AUC</cell><cell>Cora</cell><cell>AP</cell><cell>AUC</cell><cell>Citeseer</cell><cell>AP</cell><cell>AUC</cell><cell>Pubmed</cell><cell>AP</cell></row><row><cell>SC [5]</cell><cell>84.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Christos Louizos, Mart van Baalen, Taco Cohen, Dave Herman, Pramod Sinha and Abdul-Saboor Sheikh for insightful discussions. This project was funded by SAP Innovation Center Network.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning (ICML)</title>
		<meeting>The 31st International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Leveraging social media networks for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="478" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Aistats</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
