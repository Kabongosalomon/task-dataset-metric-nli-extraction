<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SAD: Saliency-based Defenses Against Adversarial Examples</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Vision &amp; Artificial Intelligence Lab</orgName>
								<orgName type="institution">University of Texas at San Antonio</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Patrick</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Vision &amp; Artificial Intelligence Lab</orgName>
								<orgName type="institution">University of Texas at San Antonio</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Geyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Vision &amp; Artificial Intelligence Lab</orgName>
								<orgName type="institution">University of Texas at San Antonio</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><forename type="middle">S</forename><surname>Fernandez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Vision &amp; Artificial Intelligence Lab</orgName>
								<orgName type="institution">University of Texas at San Antonio</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SAD: Saliency-based Defenses Against Adversarial Examples</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the rise in popularity of machine and deep learning models, there is an increased focus on their vulnerability to malicious inputs. These adversarial examples drift model predictions away from the original intent of the network and are a growing concern in practical security. In order to combat these attacks, neural networks can leverage traditional image processing approaches or state-of-the-art defensive models to reduce perturbations in the data. Defensive approaches that take a global approach to noise reduction are effective against adversarial attacks, however their lossy approach often distorts important data within the image. In this work, we propose a visual saliency based approach to cleaning data affected by an adversarial attack. Our model leverages the salient regions of an adversarial image in order to provide a targeted countermeasure while comparatively reducing loss within the cleaned images. We measure the accuracy of our model by evaluating the effectiveness of state-of-the-art saliency methods prior to attack, under attack, and after application of cleaning methods. We demonstrate the effectiveness of our proposed approach in comparison with related defenses and against established adversarial attack methods, across two saliency datasets. Our targeted approach shows significant improvements in a range of standard statistical and distance saliency metrics, in comparison with both traditional and state-of-the-art approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With increased adoption of machine and deep learning models into critical systems, adversarial attacks against these models have proportionally become a growing concern. Adversarial examples have been demonstrated in a growing range of applications, not only in classification tasks, but also in malware detection <ref type="bibr" target="#b8">[9]</ref> and recognition of speech and audio <ref type="bibr" target="#b18">[19]</ref>. In the physical world, models used in facial recognition systems <ref type="bibr" target="#b19">[20]</ref> and autonomous vehicle interpretations of traffic signs, road pat-terns, and pedestrians <ref type="bibr" target="#b11">[12]</ref> are also susceptible to these distorted inputs. Adversarial attacks, such as fast gradient sign method (FGSM) <ref type="bibr" target="#b7">[8]</ref>, iterative FGSM (I-FGSM) <ref type="bibr" target="#b10">[11]</ref>, Carlini-Wagner's L2 (CWL2) <ref type="bibr" target="#b2">[3]</ref> and DeepFool <ref type="bibr" target="#b14">[15]</ref>, take a broad range of approaches toward a similar goal: drifting a targeted model away its original intent through a series of malicious inputs <ref type="bibr" target="#b0">[1]</ref>. Attacks can be categorized as targeted or non-targeted, describing their intention of misleading a model toward a specific desired outcome or generally causing it to incorrectly interpret the input. Additionally, attacks may be white-or black-box, if the adversary has prior knowledge of the underlying model, training information, or system. In this work, we focus on black-box non- <ref type="figure">Figure 1</ref>. Comparison of CPD <ref type="bibr" target="#b23">[24]</ref> on cleaning measures of ECSSD <ref type="bibr" target="#b20">[21]</ref> data attacked with FGSM <ref type="bibr" target="#b7">[8]</ref>. Top row: Original image, ground truth saliency map; Bottom row from left (defenses): bit-depth reduction, JPEG compression, SHIELD <ref type="bibr" target="#b3">[4]</ref>, SAD. targeted attacks to images, in an attempt to provide defense for general machine learning models against a range of attacks. We leverage prevalent defense measures, identifying approaches that take a global approach to removing distortions as well as recent localized approaches. Ultimately, we propose a new defense strategy, SAD, which uses regions of interest to strategically reduce adversarial distortions. <ref type="figure">Figure 1</ref> motivates the effectiveness of our proposed approach, comparing the saliency maps of an adversarial example image after application of bit-depth reduction, JPEG compression, SHIELD <ref type="bibr" target="#b3">[4]</ref>, and our proposed SAD model. Some defense techniques, including bit-depth reduction and JPEG compression, use a globalized approach to clean the inputs, while other techniques, such as SHIELD <ref type="bibr" target="#b3">[4]</ref>, use a more localized approach in reducing distortions. Both types of approach have demonstrated performance against adversarial attacks of image classification models, however it is difficult to ensure preservation of the data integrity.</p><p>While ROI region selection can be prohibitive on a perturbed image, some visual saliency models have been proven effective despite adversarial attack. <ref type="bibr" target="#b6">[7]</ref>. In <ref type="figure" target="#fig_1">Figure  2</ref>, an image from ECSSD <ref type="bibr" target="#b20">[21]</ref> dataset is shown with a generated saliency map, prior to and after a FGSM <ref type="bibr" target="#b7">[8]</ref> attack. Note the reduction in salient region identification in the upper leaves of the image, however the overall content remains correctly identified.</p><p>In this work, we propose a novel defense technique based on visual saliency. The proposed approach identifies a region of interest (ROI) and leverages a saliency map to apply targeted cleaning techniques. In demonstration of our proposed method, we evaluate the performance of state-of-theart saliency models on established saliency data under the following conditions: original data, attacked by FGSM and DeepFool, and finally cleaned by four methods. We discuss the impact of the choice of saliency estimation approaches in the effectiveness of our defense solution, and recommend augmentations for future improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Among all the different cleaning techniques, we divide them into two major categories: globalized techniques and localized techniques. Globalized techniques, including methods such as bit-depth reduction and JPEG compression, have proven to be successful in reducing the effectiveness of adversarial attacks through the use of relatively simplistic approaches. Bit-depth reduction limits the color in an image, which reduces distortions and therefore the effectiveness of the adversarial attacks. However, while bit-depth reduction impacts general perturbations, it can also damage core features used to identify salient information. JPEG Compression can also be used to reduce the effectiveness of malicious input by compressing the image. This causes malicious inputs to get smoothed out, but at the same time introduces unwanted artifacts. These unwanted artifacts can have unexpected consequences in saliency generation. While each technique has a unique way of approaching the problem, they all reduce overall number of features within the data. However, these globalized techniques are predictable and thus can be easily circumvented. Related to globalized approaches, distillation has also been demonstrated by Papernot et al as a viable means of defending against adversarial examples in deep neural networks <ref type="bibr" target="#b16">[17]</ref>. Magnet <ref type="bibr" target="#b13">[14]</ref> takes a cryptography-based approach to defending against adversarial examples. Built for gray-box attacks, this defense is randomly selected from a set of precomputed methods at runtime. Beyond globalized approaches, there are more localized approaches, such as image quilting <ref type="bibr" target="#b5">[6]</ref>, watermarking and SHIELD <ref type="bibr" target="#b3">[4]</ref>. Inherent randomness in these techniques makes them difficult for the adversarial attacks to circumvent.</p><p>We present a unique method that reduces the effectiveness of adversarial attacks while preserving original content, and demonstrate its viability by examining the saliency of the images prior to attacks, under attacks, and after defenses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Saliency-based Adversarial Defense (SAD)</head><p>In response to the need for a targeted defense measure against diverse adversarial inputs, we propose a Saliencybased Adversarial Defense (SAD) approach outlined in <ref type="figure">Fig</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model Description</head><p>In order to select the most relevant ROI, our proposed model leverages a model for visual saliency estimation. First, a saliency map is generated for the input image. Our implementation uses PiCANet <ref type="bibr" target="#b12">[13]</ref> trained on the DUTS-TR dataset <ref type="bibr" target="#b22">[23]</ref>. Once a map is generated, JPEG compression is applied at differing qualities based on the saliency predictions. In addition to the images to be processed, a list of compression level must be passed as a parameter to our model. This list will be denoted as Q, where Q(i) denotes the ith compression level. Much like SHIELD <ref type="bibr" target="#b3">[4]</ref>, each image processed is segmented into 8×8 windows. W ij is used to denote the window at the ith row and jth column of the image. The saliency map, taken as a grey-scale image, is identically segmented into 8×8 windows. Each window in the saliency map is assigned a scalar value, from 0 to 255, based on the average saliency prediction of all pixels within the window. These scalar values, denoted as Sal ij , are then divided by a threshold and used as an index into Q. The compression level C for W ij can be expressed as the following equation.</p><formula xml:id="formula_0">C(W ij ) = Q( Sal ij · |Q| 255 )<label>(1)</label></formula><p>The goal of this approach is to reduce the effectiveness of an adversarial attack while minimizing damage done to the ROI.</p><p>This technique is similar in nature to SHIELD <ref type="bibr" target="#b3">[4]</ref>, with the primary difference being the replacement of a randomized compression algorithm with a saliency based compression algorithm. <ref type="figure" target="#fig_3">Figure 4</ref> provides an example input, saliency prediction and output that demonstrates compressing the background significantly more than the salient parts of the image. In this example, the output has salient regions compressed at 90% while non-salient regions are compressed at 20%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments &amp; Results</head><p>In this section, we first review the extensive setup of datasets, adversarial image generations, adversarial defenses, and evaluation metrics used in this work. We then specify the series of experiments performed, and demonstrate the performance of our proposed approach in the final section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Two popular saliency datasets, ECSSD <ref type="bibr" target="#b20">[21]</ref> and SALI-CON <ref type="bibr" target="#b9">[10]</ref>, were chosen for experimental setup, due to their prominence recent saliency research and their degree of difficulty. The Extended Complex Scene Saliency Dataset (ECSSD) <ref type="bibr" target="#b20">[21]</ref> is comprised of complex scenes, presenting textures and structures common to real-world images. ECSSD <ref type="bibr" target="#b20">[21]</ref> contains 1,000 intricate images and respective ground-truth saliency maps, created as an average of the labeling of five human participants. The Salicency in Context (SALICON) <ref type="bibr" target="#b9">[10]</ref> is a similarly complex dataset, chosen in this work to provide a broader range of scenes and a larger number of samples. SALICON <ref type="bibr" target="#b9">[10]</ref> contains a training set of 10,000 images and their respective ground-truth saliency maps as well as a validation set of 5,000 images with their corresponding ground-truths and was designed to purpose of evaluating current saliency models with natural scene images. In addition to ground truth saliency maps, this dataset provides fixation maps for analysis. For our experiments, we selected only the training set of SALICON <ref type="bibr" target="#b9">[10]</ref> to evaluate the saliency models, for a total of 10,000 images on this dataset.</p><p>Two adversarial attacks were chosen in this work, for their prominence as well as diversity in approach. We leveraged FGSM <ref type="bibr" target="#b7">[8]</ref> and DeepFool <ref type="bibr" target="#b14">[15]</ref> attacks to evaluate the efficacy of our proposed countermeasure. The Fast Gradient Sign Method (FGSM) <ref type="bibr" target="#b7">[8]</ref> was chosen as it is a more traditional attack which has proven to be effective in creating input images which are significantly misleading to popular convolutional frameworks. The inclusion of FGSM <ref type="bibr" target="#b7">[8]</ref> allows us to test the effectiveness of saliency models and cleaning algorithms against a well-known and common adversarial attack. DeepFool <ref type="bibr" target="#b14">[15]</ref> was chosen as it is considered a state-of-the-art attack against image-based classification models, with a more robust attack surface. As each of these approaches requires an objective function to consider in their attack, we chose a common VGG16 <ref type="bibr" target="#b21">[22]</ref> backbone and pretrained this model using the ImageNet <ref type="bibr" target="#b4">[5]</ref> dataset.</p><p>In defense against the adversarial examples, we selected three countermeasures in comparison with our proposed SAD approach: bit-depth Reduction, JPEG-compression, and SHIELD. <ref type="bibr" target="#b3">[4]</ref>. We chose these as a balance of global and localized defense techniques, for a robust comparison with our proposed approach. Both bit-depth reduction and JPEG-compression are established countermeasures to defend against adversarial attacks, effective in reducing the number of perturbations present within the images. For the purposes of our experiments, we used a 3-bit depth reduction and a compression level of 80 for JPEGcompression. The recent Secure Heterogeneous Image Ensemble with Localized Denoising (SHIELD) <ref type="bibr" target="#b3">[4]</ref> uses a randomized compression levels to reduce the number of perturbations present within the images.</p><p>In order to evaluate the effectiveness of our defense, we put all images -original, adversarial, and "cleaned"through state-of-the-art saliency models, and evaluate the performance of each model. As these models have demonstrated top performance on these popular saliency datasets, we can establish how they are affected by the adversarial inputs. In this work, we selected three diverse models to generate saliency maps for the images: BASNet <ref type="bibr" target="#b17">[18]</ref>, CPD <ref type="bibr" target="#b23">[24]</ref>, and SalGAN <ref type="bibr" target="#b15">[16]</ref>. The Boundary-Aware Salient Object Detection model (BASNet) <ref type="bibr" target="#b17">[18]</ref> uniquely leverages edges and bounding boxes to help establish a saliency map for an image. The Cascaded Partial Decoder (CPD) <ref type="bibr" target="#b23">[24]</ref> model incorporates a holistic attention mechanism into the traditional encoder-decoder framework. The Saliency GAN (SalGAN) <ref type="bibr" target="#b15">[16]</ref> model is a generative adversarial network approach, providing discriminator and generator models in adversarial training. It is important to note that SalGAN <ref type="bibr" target="#b15">[16]</ref> was mainly designed with to generate saliency maps based on eye-fixations rather than a basic saliency map.</p><p>Finally, we leverage saliency metrics in this work as an evaluation of the effectiveness of our proposed defense. The MIT Saliency Benchmark <ref type="bibr" target="#b1">[2]</ref> provides established metrics for saliency estimation models, on both binary saliency maps and fixation maps. For the purposes of this work, in application to only ground truth maps, we selected Earth Mover's Distance (EMD), Pearson's Correlation Coefficient (CC), Normalized Scanpath Saliency (NSS), KL-Divergence (KLD) and similarity score (SIM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiments</head><p>To establish a baseline, we generated the saliency maps for the ECSSD and SALICON datasets using the BASNet <ref type="bibr" target="#b17">[18]</ref>, CPD <ref type="bibr" target="#b23">[24]</ref>, and SalGAN <ref type="bibr" target="#b15">[16]</ref> saliency models.</p><p>After establishing a baseline, we then took each dataset and performed separate FGSM and DeepFool attacks on the images. In uniform comparison, all attacks leveraged a VGG-16 common backbone. The same saliency models were used to generate saliency maps of each set of these attacked images.</p><p>Finally, all attacked images were cleaned using a series of adversarial attack defenses. We started by performing a bit-depth reduction on the attacked images, reducing the images to a 3-bit color representation. Next, we performed a JPEG compression on the attacked images, compressing the image quality by 80 percent. Once we finished the JPEG compression, we performed the state-ofthe-art defense SHIELD on the attacked images. SHIELD functions takes JPEG compression but instead applying a uniform image compression level, the compression is applied in patches, randomly determining the quality reduction of the image. We took the new images from all the current cleaning techniques and then fed them into all of the saliency models to get their respective saliency maps to use for the metrics. Once we had all of the saliency maps, we then ran all of our metrics on the cleaned images to show how the cleaning techniques affected the saliency maps.</p><p>Finally, using the same experimental guidelines, we performed SAD on the attacked datasets. Testing was performed with 2 lists of compression qualities <ref type="bibr" target="#b19">(20,</ref><ref type="bibr">50,</ref><ref type="bibr">70,</ref><ref type="bibr">70,</ref><ref type="bibr">80,</ref><ref type="bibr">90)</ref> and (50, 70, 90). The cleaned SAD images were then run through the same metrics in order to make a direct comparison of our technique and other modern cleaning techniques. <ref type="figure">Figure 5</ref> provides a collection of images picked from ECSSD <ref type="bibr" target="#b20">[21]</ref>. The first two rows of the figure contain the original image and its respective ground truth. The third row contains the saliency map generated by BASNet <ref type="bibr" target="#b17">[18]</ref> from an FGSM <ref type="bibr" target="#b7">[8]</ref> adversarial example. In this figure, FGSM <ref type="bibr" target="#b7">[8]</ref> is shown to cause minor distortions to the saliency maps that were generated by BASNET <ref type="bibr" target="#b17">[18]</ref>. The following rows contain the resulting saliency map from the bit-depth reduction, JPEG-Compression, SHIELD <ref type="bibr" target="#b3">[4]</ref> and SAD respectively. These rows demonstrate the highlight the effects that each cleaning technique has on the saliency map generation. <ref type="table">Table 1</ref> shows the results of running the BASNet <ref type="bibr" target="#b17">[18]</ref> visual saliency model <ref type="bibr" target="#b17">[18]</ref> against the SALICON <ref type="bibr" target="#b9">[10]</ref> dataset. <ref type="table">Tables 2 and 3</ref> show metric results of running BASNet <ref type="bibr" target="#b17">[18]</ref> and CPD <ref type="bibr" target="#b23">[24]</ref> respectively on the entire ECSSD <ref type="bibr" target="#b20">[21]</ref> dataset. In each of these cases we conclude that SAD performs significantly better on global attacks, such as FGSM <ref type="bibr" target="#b7">[8]</ref>, than localised attacks, such as DeepFool <ref type="bibr" target="#b14">[15]</ref>. This is because more distortions are present in the nonsalient regions of global attacks, thus more distortions are removed overall. We posit that for localised attacks on ECSSD <ref type="bibr" target="#b20">[21]</ref>, while SAD performed worse than standard JPEG compression, the difference in performance is comparatively small. <ref type="figure">Figures 6 and 7</ref> are min-max normalised graphs presented to visualise these results. <ref type="table">Table 4</ref> shows metric results of running CPD <ref type="bibr" target="#b23">[24]</ref> on the SALICON <ref type="bibr" target="#b9">[10]</ref> dataset. In this case, because CPD <ref type="bibr" target="#b23">[24]</ref> does not perform well on this fixation based dataset, the overall results do not vary much between the original, attacked, and cleaned examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>In general, DeepFool <ref type="bibr" target="#b14">[15]</ref> has little to no effect on saliency prediction as is illustrated by <ref type="figure">Figure 8</ref>. In this figure we see only slight difference between the original, attacked and cleaned saliency predictions. This result is further backed up by the metrics of DeepFool <ref type="bibr" target="#b14">[15]</ref> across all tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>With adversarial attacks increasing in popularity and constantly evolving, new defenses are continuously being counteracted by new methods of attack. In this work, we presented a new method for defense against adversarial images which is based upon visual saliency estimation. In comparison with existing localized and global approaches, our method is a strategically applied defense. Our targeted approach demonstrates better reduction of adversarial distortions while preserving salient content of the original data. Our proposed SAD model outperforms existing countermeasures in a range of standard saliency metrics.</p><p>While SAD has been proven effective, there are still <ref type="figure">Figure 5</ref>. Comparison of BASNet <ref type="bibr" target="#b17">[18]</ref> on cleaning measures of ECSSD <ref type="bibr" target="#b20">[21]</ref> data attacked with FGSM. From top: Original image, ground truth, Attacked, BitDepth, JPEG, SHIELD <ref type="bibr" target="#b3">[4]</ref>, SAD many different areas to explore. In future work, we will look to optimize saliency thresholds as well as the backend saliency model, to further improve the results of SAD. Further analysis of the effectiveness of our model will be explored in comparison with a growing number of state-ofthe-art defenses on additional saliency datasets, and can be analyzed in terms of the classification of images across similar phases -before attack, during attack, and after cleaned. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>- ure 3 .</head><label>3</label><figDesc>Our model estimates relevant regions of interest (ROI) in an input and strategically applies countermeasures against adversarial perturbations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Consequences of adversarial attack on ECSSD data<ref type="bibr" target="#b20">[21]</ref> predicted using PiCANet<ref type="bibr" target="#b12">[13]</ref>. Top row: original image, Bottom row: FGSM attack<ref type="bibr" target="#b7">[8]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Overview of SAD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Example input and output of SAD. Top down: Original image, Saliency prediction, Output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .Table 3 .Table 4 .</head><label>234</label><figDesc>Evaluation of the BASNet[18] visual saliency model[18] on the ECSSD[21] dataset. Evaluation of the CPD[24] saliency visual saliency model[24] on the ECSSD[21] dataset. Evaluation of the CPD [24] visual saliency model[24] on the SALICON[10] dataset.Figure 8. Comparison of SalGAN[16] on cleaning measures of SALICON[10] data attacked with DeepFool[15]. From top: Original image, ground truth, Attacked, BitDepth. JPEG, SHIELD[4], SAD</figDesc><table><row><cell>Data: SALICON, Model: BASNet</cell><cell>EMD ↓</cell><cell>CC ↑</cell><cell>NSS ↑</cell><cell>KLD ↓</cell><cell>SIM ↑</cell></row><row><cell>Original</cell><cell cols="5">83.60872647 0.4218207896 0.3761202097 10.67353916 0.4060104787</cell></row><row><cell>FGSM</cell><cell cols="5">79.91393103 0.4087593555 0.3648214042 11.35947323 0.3891682327</cell></row><row><cell>DeepFool</cell><cell cols="5">83.60636636 0.4222988188 0.3763460219 10.67110252 0.40616256</cell></row><row><cell>FGSM + Bit-depth Reduction</cell><cell cols="5">75.04985629 0.3049599528 0.2969438136 13.31941891 0.3179412484</cell></row><row><cell>FGSM + JPEG80 Compression</cell><cell cols="5">79.73553778 0.4079829454 0.3639315665 11.40826893 0.3880238533</cell></row><row><cell>FGSM + SHIELD</cell><cell cols="5">79.44973525 0.4092005491 0.3637762368 11.43848801 0.3876400888</cell></row><row><cell>FGSM + SAD (20 50 70 70 80 90)</cell><cell cols="5">79.25510666 0.4074067175 0.3620625138 11.51703453 0.3857473135</cell></row><row><cell>FGSM + SAD (50 70 90)</cell><cell cols="5">79.89621414 0.4122531116 0.3667055368 11.30664825 0.3907471597</cell></row><row><cell>DeepFool + Bit-depth Reduction</cell><cell cols="5">78.72886619 0.3303083181 0.3210006058 12.43772602 0.3442973197</cell></row><row><cell>DeepFool + JPEG80 Compression</cell><cell cols="2">83.44919726 0.421741128</cell><cell cols="3">0.3755041957 10.72119999 0.4052546024</cell></row><row><cell>DeepFool + SHIELD</cell><cell cols="5">83.24127967 0.4230029285 0.3759891391 10.71790504 0.4055115879</cell></row><row><cell cols="6">DeepFool + SAD (20 50 70 70 80 90) 83.10682231 0.4206542075 0.3742873669 10.78884315 0.403165251</cell></row><row><cell>DeepFool + SAD (50 70 90)</cell><cell cols="5">83.54616027 0.4241522551 0.3771335781 10.64822292 0.4069490135</cell></row><row><cell cols="5">Table 1. Evaluation of the BASNet[18] visual saliency model[18] on the SALICON[10] dataset.</cell><cell></cell></row><row><cell>Data: ECSSD, Model: BASNet</cell><cell>EMD ↓</cell><cell>CC ↑</cell><cell>NSS ↑</cell><cell>KLD ↓</cell><cell>SIM ↑</cell></row><row><cell>Original</cell><cell cols="5">48.07041578 0.9120191336 1.979211807 1.506018996 0.8843896985</cell></row><row><cell>FGSM</cell><cell cols="5">45.51845167 0.8434635997 1.829114914 3.207652092 0.8040903211</cell></row><row><cell>DeepFool</cell><cell>47.9678527</cell><cell>0.908826232</cell><cell cols="2">1.972466826 1.60269177</cell><cell>0.8807195425</cell></row><row><cell>FGSM + Bit-depth Reduction</cell><cell cols="5">41.21447617 0.5987574458 1.297375202 8.744916916 0.5463407636</cell></row><row><cell>FGSM + JPEG80 Compression</cell><cell cols="5">45.44040079 0.8403670192 1.823511362 3.267945766 0.8005516529</cell></row><row><cell>FGSM + SHIELD</cell><cell cols="5">45.26718383 0.8304385543 1.805399299 3.560398102 0.7886587977</cell></row><row><cell>FGSM + SAD (20 50 70 70 80 90)</cell><cell cols="3">45.35846763 0.8506878614 1.85140121</cell><cell cols="2">3.170518398 0.8131732941</cell></row><row><cell>FGSM + SAD (50 70 90)</cell><cell cols="3">45.93143812 0.8615031838 1.87408042</cell><cell cols="2">2.825253487 0.8248550296</cell></row><row><cell>DeepFool + Bit-depth Reduction</cell><cell cols="4">43.46246487 0.6593744755 1.430215001 7.15671587</cell><cell>0.6113178134</cell></row><row><cell>DeepFool + JPEG80 Compression</cell><cell>47.933426</cell><cell cols="2">0.9080747962 1.97224772</cell><cell>1.61575985</cell><cell>0.8803170323</cell></row><row><cell>DeepFool + SHIELD</cell><cell cols="5">47.71402123 0.8999755979 1.953188896 1.781389356 0.870287478</cell></row><row><cell cols="6">DeepFool + SAD (20 50 70 70 80 90) 47.33478719 0.9016960859 1.960625887 1.858531952 0.8717075586</cell></row><row><cell>DeepFool + SAD (50 70 90)</cell><cell cols="5">47.77355919 0.9041004777 1.961497784 1.685516238 0.8761977553</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Synthesizing robust adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="284" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Judd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<ptr target="http://saliency.mit.edu/" />
		<title level="m">Mit saliency benchmark</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2017-05" />
			<biblScope unit="page" from="39" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shield: Fast, practical defense and vaccination for deep learning using jpeg compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanbhogue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Kounavis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="196" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">09</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image quilting for texture synthesis and transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 28th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="341" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the salience of adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fernandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Symposium on Visual Computing (ISVC)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adversarial examples for malware detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Manoharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Symposium on Research in Computer Security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="62" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Salicon: Saliency in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.02533</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01236</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Picanet: Learning pixelwise contextual attention for saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3089" to="3098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Magnet: a two-pronged defense against adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2017 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="135" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepfool: a simple and accurate method to fool deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2574" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Salgan: Visual saliency prediction with adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sayrol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">G</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Oconnor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Scene Understanding Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distillation as a defense to adversarial perturbations against deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="582" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Basnet: Boundary-aware salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imperceptible, robust, and targeted adversarial examples for automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cottrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5231" to="5240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accessorize to a crime: Real and stealthy attacks on state-ofthe-art face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1528" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical image saliency detection on extended cssd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="717" to="729" />
			<date type="published" when="2016-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to detect salient objects with image-level supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cascaded partial decoder for fast and accurate salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3907" to="3916" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
