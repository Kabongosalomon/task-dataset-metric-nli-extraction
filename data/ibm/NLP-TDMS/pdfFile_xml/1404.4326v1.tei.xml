<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Open Question Answering with Weakly Supervised Embedding Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 7253</orgName>
								<orgName type="institution">Université de Technologie de Compiègne -CNRS</orgName>
								<address>
									<settlement>Heudiasyc, Compiègne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
							<email>jaseweston@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Google</orgName>
								<address>
									<addrLine>111 8th avenue</addrLine>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
							<email>nusunier@utc.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 7253</orgName>
								<orgName type="institution">Université de Technologie de Compiègne -CNRS</orgName>
								<address>
									<settlement>Heudiasyc, Compiègne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Open Question Answering with Weakly Supervised Embedding Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>natural language processing</term>
					<term>question answering</term>
					<term>weak su- pervision</term>
					<term>embedding models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper addresses the challenging problem of open-domain question answering, which consists of building systems able to answer questions from any domain. Any advance on this difficult topic would bring a huge leap forward in building new ways of accessing knowledge. An important development in this area has been the creation of large-scale Knowledge Bases (KBs), such as Freebase <ref type="bibr" target="#b3">[4]</ref> and DBpedia <ref type="bibr" target="#b14">[15]</ref> which store huge amounts of general-purpose information. They are organized as databases of triples connecting pairs of entities by various relationships and of the form (left entity, relationship, right entity). Question answering is then defined as the task of retrieving the correct entity or set of entities from a KB given a query expressed as a question in natural language.</p><p>The use of KBs simplifies the problem by separating the issue of collecting and organizing information (i.e. information extraction) from the one of searching through it (i.e. question answering or natural language interfacing). However, open question answering remains challenging because of the scale of these KBs (billions of triples, millions of entities and relationships) and of the difficulty for machines to interpret natural language. Recent progress <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b9">10]</ref> has been made by tackling this problem with semantic parsers. These methods convert questions into logical forms or database queries (e.g. in SPARQL) which are then subsequently used to query KBs for answers. Even if such systems have shown the ability to handle large-scale KBs, they require practitioners to hand-craft lexicons, grammars, and KB schema for the parsing to be effective. This nonnegligible human intervention might not be generic enough to conveniently scale up to new databases with other schema, broader vocabularies or other languages than English.</p><p>In this paper, we instead take the approach of converting questions to (uninterpretable) vectorial representations which require no pre-defined grammars or lexicons and can query any KB independent of its schema. Following <ref type="bibr" target="#b9">[10]</ref>, we focus on answering simple factual questions on a broad range of topics, more specifically, those for which single KB triples stand for both the question and an answer (of which there may be many). For example, (parrotfish.e, live-in.r, southern-water.e) stands for What is parrotfish's habitat? and southern-water.e and (cantonese.e, be-major-language-in.r, hong-kong.e) for What is the main language of Hong-Kong? and cantonese.e. In this task, the main difficulties come from lexical variability rather than from complex syntax, having multiple answers per question, and the absence of a supervised training signal.</p><p>Our approach is based on learning low-dimensional vector embeddings of words and of KB triples so that representations of questions and corresponding answers end up being similar in the embedding space. Unfortunately, we do not have access to any human labeled (query, answer) supervision for this task. In order to avoid transferring the cost of manual intervention to the one of labeling large amounts of data, we make use of weak supervision. We show empirically that our model is able to take advantage of noisy and indirect supervision by (i) automatically generating questions from KB triples and treating this as training data; and (ii) supplementing this with a data set of questions collaboratively marked as paraphrases but with no associated answers. We end up learning meaningful vectorial representations for questions involving up to 800k words and for triples of an mostly automatically created KB with 2.4M entities and 600k relationships. Our method strongly outperforms previous results on the WikiAnswers+ReVerb evaluation data set introduced by <ref type="bibr" target="#b9">[10]</ref>. Even if the embeddings obtained after training are of good quality, the scale of the optimization problem makes it hard to control and to lead to convergence. Thus, we propose a method to fine-tune embedding-based models by carefully optimizing a matrix parameterizing the similarity used in the embedding space, leading to a consistent improvement in performance.</p><p>The rest of the paper is organized as follows. Section 2 discusses some previous work and Section 3 introduces the problem of open question answering. Then, Section 4 presents our model and Section 5 our experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Large-scale question answering has a long history, mostly initiated via the TREC tracks <ref type="bibr" target="#b21">[22]</ref>. The first successful systems transformed the questions into queries which were fed to web search engines, the answer being subsequently extracted from top returned pages or snippets <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b0">1]</ref>. Such approaches require significant engineering to hand-craft queries and then parse and search over results.</p><p>The emergence of large-scale KBs, such as Freebase <ref type="bibr" target="#b3">[4]</ref> or DBpedia <ref type="bibr" target="#b14">[15]</ref>, changed the setting by transforming open question answering into a problem of querying a KB using natural language. This is a challenging problem, which would require huge amount of labeled data to be tackled properly by purely supervised machine learning methods because of the great variability of language and of the large scale of KBs. The earliest methods for open question-answering with KBs, based on hand-written templates <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b20">21]</ref>, were not robust enough to such variability over possibly evolving KBs (addition/deletion of triples and entities). The solution to gain more expressiveness via machine learning comes from distant or indirect supervision to circumvent the issue of labeled data. Initial works attempting to learn to connect KBs and natural language with less supervision have actually been tackling the information extraction problem <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>Recently, new systems for learning question answering systems with few labeled data have been introduced based on semantic parsers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b11">12]</ref>. Such works tend to require realistic amounts of manual intervention via labeled examples, but still need vast efforts to carefully design lexicons, grammars and the KB. In contrast, <ref type="bibr" target="#b9">[10]</ref> proposed a framework for open question answering requiring little human annotation. Their system, Paralex, answers questions with more limited semantics than those introduced in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12]</ref>, but does so at a very large scale in an open-domain manner. It is trained using automatically and collaboratively generated data and using the KB ReVerb <ref type="bibr" target="#b8">[9]</ref>. In this work, we follow this trend by proposing an embedding-based model for question answering that is also trained under weak and cheap supervision.</p><p>Embedding-based models are getting more and more popular in natural language processing. Starting from the neural network language model of <ref type="bibr" target="#b1">[2]</ref>, these methods have now reached near state-of-the-art performance on many standard tasks while usually requiring less hand-crafted features <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20]</ref>. Recently, some embedding models have been proposed to perform a connection between natural language and KBs for word-sense disambiguation <ref type="bibr" target="#b4">[5]</ref> and for information extraction <ref type="bibr" target="#b23">[24]</ref>. Our work builds on these approaches to instead learn to perform open question answering under weak supervision, which to our knowledge has not been attempted before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Open-domain Question Answering</head><p>In this paper, we follow the question answering framework of <ref type="bibr" target="#b9">[10]</ref> and use the same data. Hence, relatively little labeling or feature engineering has been used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>Our work considers the task of question answering as in <ref type="bibr" target="#b9">[10]</ref>: given a question q, the corresponding answer is given by a triple t from a KB. This means that we consider questions for which a set of triples t provide an interpretation of the question and its answer, such as: Here, we only give a single t per question, but many can exist. In the remainder, the KB is denoted K and its set of entities and relationships is E. The word vocabulary for questions is termed V. n v and n e are the sizes of V and E respectively.</p><p>Our model consists in learning a function S(·), which can score questionanswer triple pairs (q, t). Hence, finding the top-ranked answert(q) to a question q is directly carried out by:t</p><formula xml:id="formula_0">(q) = arg max t ∈K S(q, t ) .</formula><p>To handle multiple answer, we instead present the results as a ranked list, rather than taking the top prediction, and evaluate that instead.</p><p>Using the scoring function S(·) allows to directly query the KB without needing to define an intermediate structured logical representation for questions as in semantic parsing systems. We aim at learning S(·), with no human-labeled supervised data in the form (question, answer) pairs, but only by indirect supervision, generated either automatically or collaboratively. We detail in the rest of this section our process for creating training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Data</head><p>Our training data consists of two sources: an automatically created KB, Re-Verb, from which we generate questions and a set of pairs of questions collaboratively labeled as paraphrases from the website WikiAnswers.</p><p>Knowledge Base The set of potential answers K is given by the KB ReVerb <ref type="bibr" target="#b8">[9]</ref>.</p><p>ReVerb is an open-source database composed of more than 14M triples, made of more than 2M entities and 600k relationships, which have been automatically extracted from the ClueWeb09 corpus <ref type="bibr" target="#b16">[17]</ref>. In the following, entities are denoted with a .e suffix and relationships with a .r suffix. ReVerb contains broad and general knowledge harvested with very little human intervention, which suits the realistically supervised setting. But, as a result, ReVerb is ambiguous and noisy with many useless triples and entities as well as numerous duplicates. For instance, winston-churchill.e, churchill.e and even roosevelt-and-churchill.e are all distinct entities. <ref type="table" target="#tab_3">Table 3</ref>.2 presents some examples of triples: some make sense, some others are completely unclear or useless.</p><p>In contrast to highly curated databases such Freebase, ReVerb has more noise but also many more relation types (Freebase has around 20k). So for some types of triple it has much better coverage, despite the larger size of Freebase; for example Freebase does not cover verbs like afraid-of or suffer-from.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questions Generation</head><p>We have no available data of questions q labeled with their answers, i.e. with the corresponding triples t ∈ K. Following <ref type="bibr" target="#b9">[10]</ref>, we hence decided to create such question-triple pairs automatically. These pairs are generated using the 16 seed questions displayed in <ref type="table" target="#tab_2">Table 2</ref>. At each round, we pick a triple at random and then generate randomly one of the seed questions. Note only triples with a *-in.r relation (denoted r-in in <ref type="table" target="#tab_2">Table 2</ref>) can generate from the pattern where did e r ?, for example, and similar for other constraints. Otherwise, the pattern is chosen randomly. Except for these exceptions, we used all 16 seed questions for all triples hence generating approximately 16 × 14M questions stored in a training set we denote D.</p><p>The generated questions are imperfect and noisy and create a weak training signal. Firstly, their syntactic structure is rather simplistic, and real questions as posed by humans (such as in our actual test) can look quite different to them. Secondly, many generated questions do not correspond to semantically valid English sentences. For instance, since the type of entities in ReVerb is unknown, a pattern like who does e r ? can be chosen for a triple where the type of ? in (?, r, e) is not a person, and similar for other types (e.g. when). Besides, for the strings representing entities and relationships in the questions, we simply used their names in ReVerb, replacingby spaces and stripping off what is e's r ? (e, r, ?) who is r by e ? (e, r-in, ?) when did e r ? (e, r-on, ?) when did e r ? (e, r-in, ?) when was e r ? (e, r-on, ?) when was e r ? (e, r-in, ?) where was e r ? (e, r-in, ?) where did e r ? their suffixes, i.e. the string representing winston-churchill.e is simply winston churchill. While this is often fine, this is also very limited and caused many incoherences in the data. Generating questions with a richer KB than ReVerb, such as Freebase or DBpedia, would lead to better quality because typing and better lexicons could be used. However, this would contradict one of our motivations which is to train a system with as little human intervention as possible (and hence choosing ReVerb over hand-curated KBs).</p><p>Paraphrases The automatically generated examples are useful to connect KB triples and natural language. However, they do not allow for a satisfactory modeling of English language because of their poor wording. To overcome this issue, we again follow <ref type="bibr" target="#b9">[10]</ref> and supplement our training data with an indirect supervision signal made of pairs of question paraphrases collected from the WikiAnswers website.</p><p>On WikiAnswers, users can tag pairs of questions as rephrasing of each other. <ref type="bibr" target="#b9">[10]</ref> harvested a set of 18M of these question-paraphrase pairs, with 2.4M distinct questions in the corpus. These pairs have been labeled collaboratively. This is cheap but also causes the data to be noisy. Hence, <ref type="bibr" target="#b9">[10]</ref> estimated that only 55% of the pairs were actual paraphrases. The set of paraphrases is denoted P in the following. By considering all words and tokens appearing in P and D, we end up with a size for the vocabulary V of more than 800k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Embedding-based Model</head><p>Our model ends up learning vector embeddings of symbols, either for entities or relationships from ReVerb, or for each word of the vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Question-KB Triple Scoring</head><p>Architecture Our framework concerns the learning of a function S(q, t), based on embeddings, that is designed to score the similarity of a question q and a triple t from K.</p><p>Our scoring approach is inspired by previous work for labeling images with words <ref type="bibr" target="#b22">[23]</ref>, which we adapted, replacing images and labels by questions and triples. Intuitively, it consists of projecting questions, treated as a bag of words (and possibly n-grams as well), on the one hand, and triples on the other hand, into a shared embedding space and then computing a similarity measure (the dot product in this paper) between both projections. The scoring function is then:</p><formula xml:id="formula_1">S(q, t) = f (q) g(t)</formula><p>with f (·) a function mapping words from questions into Contrary to previous work modeling KBs with embeddings (e.g. <ref type="bibr" target="#b23">[24]</ref>), in our model, an entity does not have the same embedding when appearing in the lefthand or in the right-hand side of a triple. Since, g(·) sums embeddings of all constituents of a triple, we need to use 2 embeddings per entity to encode for the fact that relationships in the KB are not symmetric and so that appearing as a left-hand or right-hand entity is different.</p><formula xml:id="formula_2">R k , f (q) = V Φ(q). V is the matrix of R nv×k containing all word embeddings v, Φ(q) is the (sparse) binary representation of q (∈ {0,<label>1}</label></formula><p>This approach can be easily applied at test time to score any (question, triple) pairs. Given a question q, one can predict the corresponding answer (a triple) t(q) with:t (q) = arg max</p><formula xml:id="formula_3">t ∈K S(q, t ) = arg max t ∈K f (q) g(t ) .</formula><p>Training by Ranking Previous work <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> has shown that this kind of model can be conveniently trained using a ranking loss. Hence, given our data set D = {(q i , t i ), i = 1, . . . , |D|} consisting of (question, answer triple) training pairs, one could learn the embeddings using constraints of the form:</p><formula xml:id="formula_4">∀i, ∀t = t i , f (q i ) g(t i ) &gt; 0.1 + f (q i ) g(t ) ,</formula><p>where 0.1 is the margin. That is, we want the triple that labels a given question to be scored higher than other triples in K by a margin of 0.1. We also enforce a constraint on the norms of the columns of V and W , i.e. ∀ i , ||v i || 2 ≤ 1 and ∀ j , ||w j || 2 ≤ 1.</p><p>To train our model, we need positive and negative examples of (q, t) pairs. However, D only contains positive samples, for which the triple actually corresponds to the question. Hence, during training, we use a procedure to corrupt triples. Given (q, t) ∈ D, we create a corrupted triple t with the following method: pick another random triple t tmp from K, and then, replace with 66% chance each member of t (left entity, relationship and right entity) by the corresponding element in t tmp . This heuristic creates negative triples t somewhat similar to their positive counterpart t, and is similar to schemes of previous work (e.g. in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5]</ref>).</p><p>Training the embedding model is carried out by stochastic gradient descent (SGD), updating W and V at each step. At the start of training the parameters of f (·) and g(·) (the n v × k word embeddings in V and the n e × k entities and rel. embeddings in W ) are initialized to random weights (mean 0, standard deviation 1 k ). Then, we iterate the following steps to train them: 1. Sample a positive training pair (q i , t i ) from D. 2. Create a corrupted triple t i ensuring that t i = t i . 3. Make a stochastic gradient step to minimize 0.1−f (q i ) g(t i )+f (q i ) g(t i ) + . 4. Enforce the constraint that each embedding vector is normalized.</p><p>The learning rate of SGD is updated during the course of learning using adagrad <ref type="bibr" target="#b7">[8]</ref>. x + is the positive part of x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multitask Training with Paraphrases Pairs</head><p>We multitask the training of our model by training on pairs of paraphrases of questions (q 1 , q 2 ) from P as well as training on the pseudolabeled data constructed in D. We use the same architecture simply replacing g(·) by a copy of f (·). This leads to the following function that scores the similarity between two questions:</p><formula xml:id="formula_5">S prp (q 1 , q 2 ) = f (q 1 ) f (q 2 ) .</formula><p>The matrix W containing embeddings of words is shared between S and S prp , allowing it to encode information from examples from both D and P. Training of S prp is also conducted with SGD (and adagrad) as for S, but, in this case, negative examples are created by replacing one of the questions from the pair by another question chosen at random in P.</p><p>During our experiments, W and V were learned by alternating training steps using S and S prp , switching from one to another at each step. The initial learning rate was set to 0.1 and the dimension k of the embedding space to 64. Training ran for 1 day on a 16 core machine using hogwild <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fine-tuning the Similarity between Embeddings</head><p>The scale of the problem forced us to keep our architecture simple: with n e ≈ 3.5M (with 2 embeddings for each entity) and n v ≈ 800k, we have to learn around 4.3M embeddings. With an embedding space of dimension k = 64, this leads to around 275M parameters to learn. The training algorithm must also stay simple to scale on a training set of around 250M of examples (D and P combined); SGD appears as the only viable option.</p><p>SGD, combined with adagrad for adapting the learning rate on the course of training, is a powerful algorithm. However, the scale of the optimization problem makes it very hard to control and conduct properly until convergence. When SGD stops after a pre-defined number of epochs, we are almost certain that the problem is not fully solved and that some room for improvement remains: we observed that embeddings were able to often rank correct answers near the top of the candidates list, but not always in the first place.</p><p>In this paper, we introduce a way to fine-tune our embedding-based model so that correct answers might end up more often at the top of the list. Updating the embeddings involves working on too many parameters, but ultimately, these embeddings are meant to be used in a dot-product that computes the similarity between q and t. We propose to learn a matrix M ∈ R k×k parameterizing the similarity between words and triples embeddings. The scoring function becomes:</p><formula xml:id="formula_6">S ft (q, t) = f (q) M g(t) .</formula><p>M has only k 2 parameters and can be efficiently determined by solving the following convex problem (fixing the embedding matrices W and V ):</p><formula xml:id="formula_7">min M λ 2 M 2 F + 1 m m i=1 1 − S ft (q i , t i ) + S ft (q i , t i ) 2 + ,</formula><p>where X F is the Frobenius norm of X. We solve this problem in a few minutes using L-BFGS on a subset of m = 10M examples from D. We first use 4M examples to train and 6M as validation set to determine the value of the regularization parameter λ. We then retrain the model on the whole 10M examples using the selected value, which happened to be λ = 1.7 × 10 −5 . This fine-tuning is related to learning a new metric in the embedding space, but since the resulting M is not symmetric, it does not define a dot-product. Still, M is close to a constant factor times identity (as in the original score S(·)). The fine-tuning does not deeply alter the ranking, but, as expected, allows for a slight change in the triples ranking, which ends in consistent improvement in performance, as we show in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Protocols</head><p>We first detail the data and metrics which were chosen to assess the quality of our embedding model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test Set</head><p>The data set WikiAnswers+ReVerb contains no labeled examples but some are needed for evaluating models. We used the test set which has been created by <ref type="bibr" target="#b9">[10]</ref> in the following way: (1) they identified 37 questions from a heldout portion of WikiAnswers which were likely to have at least one answer in ReVerb, (2) they added all valid paraphrases of these questions to obtain a set of 691 questions, (3) they ran various versions of their paralex system on them to gather candidate triples (for a total of 48k), which they finally hand-labeled.</p><p>Reranking We first evaluated different versions of our model against the paralex system in a reranking setting. For each question q from the WikiAn-swers+ReVerb test set, we take the provided candidate triples t and rerank them by sorting by the score S(q, t) or S ft (q, t) of our model, depending whether we use fine-tuning or not. As in <ref type="bibr" target="#b9">[10]</ref>, we then compute the precision, recall and F1-score of the highest ranked answer as well as the mean average precision (MAP) of the whole output, which measures the average precision over all levels of recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full Ranking</head><p>The reranking setting might be detrimental for paralex because our system simply never has to perform a full search for the good answer among the whole ReVerb KB. Hence, we also conducted an experiment where, for each of the 691 questions of the WikiAnswers+ReVerb test set, we ranked all 14M triples from ReVerb. We labeled the top-ranked answers ourselves and computed precision, recall and F1-score. 1  <ref type="figure">Fig. 1</ref>. Precision-recall curves of our embedding model and Paralex <ref type="bibr" target="#b9">[10]</ref> for reranking question-answer pairs from the WikiAnswers+ReVerb test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>This section now discusses our empirical performance.</p><p>Reranking <ref type="table" target="#tab_3">Table 3</ref> and <ref type="figure">Figure 1</ref> present the results of the reranking experiments. We compare various versions of our model against two versions of paralex, whose results were given in <ref type="bibr" target="#b9">[10]</ref>.</p><p>First, we can see that multitasking with paraphrase data is essential since it improves F1 from 0.60 to 0.68. Paraphrases allow for the embeddings to encode a richer connection between KB constituents and words, as well as between words themselves. Note that the WikiAnswers data provides word alignment between paraphrases, which we did not use, unlike paralex. We also tried to use n-grams (2.5M most frequent) as well as the words to represent the question, but this did not bring any improvement, which might at first seem counter-intuitive. We believe this is due to two factors: <ref type="bibr" target="#b0">(1)</ref> it is hard to learn good embeddings for n-grams since their frequency is usually very low and (2) our automatically generated questions have a poor syntax and hence, many n-grams in this data set do not make sense. We actually conducted experiments with several variants of our model, which tried to take the word ordering into account (e.g. with convolutions), and they all failed to outperform our best performance without word order, once again perhaps because the supervision is not clean enough to allow for such elaborated language modeling. Fine-tuning the embedding model is very beneficial to optimize the top of the list and grants a bump of 5 points of F1: carefully tuning the similarity makes a clear difference. All versions of our system greatly outperform paralex: the fine-tuned model improves the F1-score by almost 20 points and, according to <ref type="figure">Figure 1</ref>, is better in precision for all levels of recall. paralex works by starting with an initial lexicon mapping from the KB to language and then gradually increasing its coverage by iterating on the WikiAnswers+ReVerb data. Most of its predictions come from automatically acquired templates and rules: this allows for a good precision but it is not flexible enough across language variations to grant a satisfying recall. Most of our improvement comes from a much better recall.</p><p>However, as we said earlier, this reranking setting is detrimental for paralex because paralex was evaluated on the task of reranking some of its own predictions. The results provided for paralex, while not corresponding to those of a full ranking among all triples from ReVerb (it is still reranking among a subset of candidates), concerns an evaluation setting more complicated than for our model. Hence, we also display the results of a full ranking by our system in the following. <ref type="table" target="#tab_4">Table 4</ref> and <ref type="figure" target="#fig_1">Figure 2</ref> display the results of our model to rank all 14M triples from ReVerb. The performance of the plain models is not good (F1 = 0.22 only for S ft ) because the ranking is degraded by too many candidates. But most of these can be discarded beforehand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full Ranking</head><p>We hence decided to filter out some candidates before ranking by using a simple string matching strategy: after pos-tagging the question, we construct a set of candidate strings containing (i) all noun phrases that appear less than 1,000 <ref type="table">Table 5</ref>. Examples of nearest neighboring entities and relationships from REVERB for some words from our vocabulary. The prefix L:, resp. R:, indicates the embedding of an entity when appearing in left-hand side, resp. right-hand side, of triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word</head><p>Closest entities or relationships from ReVerb in the embedding space get rid of get-rid-of.r be-get-rid-of.r rid-of.r can-get-rid-of.r will-get-rid-of.r should-get-rid-of.r have-to-get-rid-of.r want-to-get-rid-of.r will-not-get-rid-of.r help-get-rid-of.r useful be-useful-for.r be-useful-in.r R:wide-range-of-application.e can-be-useful-for.r be-use-extensively-for.r be-not-very-useful-for.r R:plex-or-technical-algorithm. As expected, string matching greatly improves results, both in precision and recall, and also significantly reduces evaluation time.</p><p>The final F1 obtained by our fine-tuned model is even better then the result of paralex in reranking, which is pretty remarkable, because this time, this setting advantages it quite a lot.</p><p>Embeddings <ref type="table">Table 5</ref> displays some examples of nearest neighboring entities from ReVerb for some words from our vocabulary. As expected, we can see that verbs or adverbs tend to correspond to relationships while nouns refer to entities. Interestingly, the model learns some synonymy and hyper/hyponymy. For instance, radiation is close to x-ray.e and iphone to smartphone.e. This happens thanks to the multitasking with paraphrase data, since in our automatically generated (q, t) pairs, the words radiation and iphone are only used for entities with the strings radiation and iphone respectively in their names. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation on WebQuestions</head><p>Our initial objective was to be able to perform open-domain question answering. In this last experimental section, we tend to evaluate how generic our learned system is. To this end, we propose to ask our model to answer questions coming from another dataset from the literature, but without retraining it with labeled data, just by directly using the parameters learned on WikiAnswers+ReVerb.</p><p>We chose the data set WebQuestions <ref type="bibr" target="#b2">[3]</ref>, which consists of natural language questions matched with answers corresponding to entities of Freebase: in this case, no triple has to be returned, only a single entity. We used exact string matching to find the ReVerb entities corresponding to the Freebase answers from the test set of WebQuestions and obtained 1,538 questions labeled with ReVerb out of the original 2,034.</p><p>Results of different versions of our model are displayed in <ref type="table" target="#tab_5">Table 6</ref>. For each test question, we record the rank of the first ReVerb triple containing the answer entity. Top-1 and Top-10 are computed on questions for which the system returned at least one answer (around 1,000 questions using string matching), while F1 is computed for all questions. Of course, performance is not great and can not be directly compared with that of the best system reported in <ref type="bibr" target="#b2">[3]</ref> (more than 0.30 of F1). One of the main reasons is that most questions of WebQuestions, such as Who was vice-president after Kennedy died?, should be represented by multiple triples, a setting for which our system has not been designed. Still, for a system trained with almost no manual annotation nor prior information on another dataset, with an other -very noisy-KB, the results can be seen as particularly promising. Besides, evaluation is broad since, in ReVerb, most entities actually appear many times under different names as explained in Section 3. Hence, there might be higher ranked answers but they are missed by our evaluation script.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper introduces a new framework for learning to perform open question answering with very little supervision. Using embeddings as its core, our approach can be successfully trained on imperfect labeled data and indirect supervision and significantly outperforms previous work for answering simple factual questions. Besides, we introduce a new way to fine-tune embedding models for cases where their optimization problem can not be completely solved.</p><p>In spite of these promising results, some exciting challenges remain, especially in order to scale up this model to questions with more complex semantics. Due to the very low supervision signal, our work can only answer satisfactorily simple factual questions, and does not even take into account the word ordering when modeling them. Further, much more work has to be carried out to encode the semantics of more complex questions into the embedding space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>nv ) indicating absence or presence of words. Similarly, g(·) is a function mapping entities and relationships from KB triples into R k , g(t) = W Ψ (t), W the matrix of R ne×k containing all entities and relationships embeddings w, and Ψ (q) the (sparse) binary representation of t (∈ {0, 1} ne ) indicating absence or presence of entities and relationships.Representing questions as a bag of words might seem too limited, however, in our particular setup, syntax is generally simple, and hence quite uninformative. A question is typically formed by an interrogative pronoun, a reference to a relationship and another one to an entity. Besides, since lexicons of relationships and entities are rather disjoint, even a bag of words representation should lead to decent performance, up to lexical variability. There are counter-examples such as What are cats afraid of ? vs. What are afraid of cats ? which require different answers, but such cases are rather rare. Future work could consider adding parse tree features or semantic role labels as input to the embedding model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Precision-recall curves for retrieving answers for questions from the WikiAn-swers+ReVerb test set, among the whole ReVerb KB (14M candidates).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>e R:internal-and-external-use.e R:authoring.e R:good-or-bad-purpose.e radiation R:radiation.e L:radiation.e R:gamma-radiation.e L:gamma-radiation.e L:x-ray.e L:gamma-ray.e L:cesium-137.e R:electromagnetic-radiation.e L:external-beam-radiation.e L:visible-light.e barack-obama L:president-elect-barack-obama.e L:barack-obama.e R:barack-obama.e L:president-barack-obama.e L:obama-family.e L:sen.-barack-obama.eL:president-elect-obama.e R:president-barack-obama.e L:democratic-presidential-candidate-barack-obama.e L:today-barack-obama.e iphone R:iphone.e L:iphone.e R:t-mobile.e R:apple-iphone.e L:lot-of-software.e L:hotmail.e R:windows-mobile-phone.e L:skype.e R:smartphone.e R:hd-dvd-player.e times in ReVerb, (ii) all proper nouns if any, otherwise the least frequent noun phrase in ReVerb. This set of strings is then augmented with the singular form of plural nouns, removing the final "s", if any. Then, only the triples containing at least one of the candidate strings are scored by the model. On average, about 10k triples (instead of 14M) are finally ranked for each question, making our approach much more tractable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Examples of triples from the KB ReVerb. left entity, relationship, right entity churchill.e, be-man-of.r, great-accomplishment.e churchill-and-roosevelt.e, meet-in.r, cairo.e churchill.e, reply-on.r, may-19.e crick.e, protest-to.r, churchill.e churchill.e, leave-room-for.r, moment.e winston-churchill.e, suffer-from.r, depression.e churchill.e, be-prime-minister-of.r, great-britain.e churchill.e, die-in.r, winter-park.e winston-churchill.e, quote-on.r, mug.e churchill.e, have-only.r, compliment.e</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Patterns for generating questions from ReVerb triples following<ref type="bibr" target="#b9">[10]</ref>.</figDesc><table><row><cell>KB Triple Question Pattern</cell><cell>KB Triple Question Pattern</cell></row><row><cell>(?, r, e) who r e ?</cell><cell>(?, r, e)</cell></row><row><cell>(?, r, e) what r e ?</cell><cell></cell></row><row><cell>(e, r, ?) who does e r ?</cell><cell></cell></row><row><cell>(e, r, ?) what does e r ?</cell><cell></cell></row><row><cell>(?, r, e) what is the r of e ?</cell><cell></cell></row><row><cell>(?, r, e) who is the r of e ?</cell><cell></cell></row><row><cell>(e, r, ?) what is r by e ?</cell><cell></cell></row><row><cell>(?, r, e) who is e's r ?</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Performance of variants of our embedding models and Paralex<ref type="bibr" target="#b9">[10]</ref> for reranking question-answer pairs from the WikiAnswers+ReVerb test set.</figDesc><table><row><cell>Method</cell><cell cols="2">F1 Prec Recall MAP</cell></row><row><cell>Paralex (No. 2-arg)</cell><cell>0.40 0.86 0.26</cell><cell>0.12</cell></row><row><cell>Paralex</cell><cell>0.54 0. 77 0.42</cell><cell>0.22</cell></row><row><cell>Embeddings</cell><cell>0.68 0.68 0.68</cell><cell>0.37</cell></row><row><cell cols="2">Embeddings (no paraphrase) 0.60 0.60 0.60</cell><cell>0.34</cell></row><row><cell cols="2">Embeddings (incl. n-grams) 0.68 0.68 0.68</cell><cell>0.39</cell></row><row><cell>Embeddings+fine-tuning</cell><cell cols="2">0.73 0.73 0.73 0.42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Performance of our embedding model for retrieving answers for questions from the WikiAnswers+ReVerb test set, among the whole ReVerb KB (14M candidates).</figDesc><table><row><cell>Method</cell><cell></cell><cell>F1</cell></row><row><cell>Embeddings</cell><cell></cell><cell>0.16</cell></row><row><cell cols="2">Embeddings+fine-tuning</cell><cell>0.22</cell></row><row><cell>Embeddings</cell><cell cols="2">+string-matching 0.48</cell></row><row><cell cols="3">Embeddings+fine-tuning+string-matching 0.57</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Performance of our embedding model for retrieving answers for questions from the WebQuestions test set, among the whole ReVerb KB (14M candidates).</figDesc><table><row><cell>Method</cell><cell></cell><cell>Top-1 Top-10 F1</cell></row><row><cell>Emb.</cell><cell></cell><cell>0.025 0.094 0.025</cell></row><row><cell cols="2">Emb.+fine-tuning</cell><cell>0.032 0.106 0.032</cell></row><row><cell>Emb.</cell><cell cols="2">+string-match. 0.085 0.246 0.068</cell></row><row><cell cols="3">Emb.+fine-tuning+string-match. 0.094 0.270 0.076</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We provide the top-ranked answers and our labels as supplementary material.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Askmsr: Question answering using the worldwide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2002 AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases</title>
		<meeting>2002 AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint learning of words and meaning representations for open-text semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 15th Intern. Conf. on Artif. Intel. and Stat</title>
		<meeting>of the 15th Intern. Conf. on Artif. Intel. and Stat</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of Empirical Methods in Natural Language Processing (EMNLP &apos;11)</title>
		<meeting>the Conference of Empirical Methods in Natural Language Processing (EMNLP &apos;11)<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1608" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scaling question answering to the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reading the web with learned syntactic-semantic inference rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DBpedia -a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web Journal</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference of the 47th Annual Meeting of ACL</title>
		<meeting>of the Conference of the 47th Annual Meeting of ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Building a 70 billion word corpus of english from clueweb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pomikálek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakubícek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rychlỳ</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="502" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hogwild!: A lock-free approach to parallelizing stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS 24)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Template-based question answering over rdf data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C. Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st international conference on World Wide Web</title>
		<meeting>the 21st international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Large scale image annotation: learning to rank with joint word-image embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Connecting language and knowledge bases with embedding models for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1366" to="1371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Natural language questions for the web of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
