<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An AMR Aligner Tuned by Transition-based Parser</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
							<email>yjliu@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zheng</surname></persName>
							<email>bzheng@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
							<email>qinb@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
							<email>tliu@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An AMR Aligner Tuned by Transition-based Parser</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a new rich resource enhanced AMR aligner which produces multiple alignments and a new transition system for AMR parsing along with its oracle parser. Our aligner is further tuned by our oracle parser via picking the alignment that leads to the highestscored achievable AMR graph. Experimental results show that our aligner outperforms the rule-based aligner in previous work by achieving higher alignment F1 score and consistently improving two open-sourced AMR parsers. Based on our aligner and transition system, we develop a transition-based AMR parser that parses a sentence into its AMR graph directly. An ensemble of our parsers with only words and POS tags as input leads to 68.4 Smatch F1 score, which outperforms the parser of Wang and Xue (2017).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abstract Meaning Representation (AMR) <ref type="bibr" target="#b3">(Banarescu et al., 2013)</ref> is a semantic representation which encodes the meaning of a sentence in a rooted and directed graph, whose nodes are abstract semantic concepts and edges are semantic relations between concepts (see <ref type="figure" target="#fig_0">Figure 1</ref> for an example). Parsing a sentence into its AMR graph has drawn a lot of research attention in recent years with a number of parsers being developed <ref type="bibr" target="#b10">(Flanigan et al., 2014;</ref><ref type="bibr" target="#b29">Wang et al., 2015b;</ref><ref type="bibr" target="#b24">Pust et al., 2015;</ref><ref type="bibr" target="#b1">Artzi et al., 2015;</ref><ref type="bibr" target="#b19">Peng et al., 2015;</ref><ref type="bibr" target="#b30">Zhou et al., 2016;</ref><ref type="bibr" target="#b12">Goodman et al., 2016;</ref><ref type="bibr" target="#b6">Damonte et al., 2017;</ref><ref type="bibr" target="#b2">Ballesteros and Al-Onaizan, 2017;</ref><ref type="bibr" target="#b11">Foland and Martin, 2017;</ref><ref type="bibr" target="#b14">Konstas et al., 2017)</ref>.</p><p>The nature of abstracting away the association between a concept and a span of words complicates the training of the AMR parser. A wordconcept aligner is required to derive such association from the sentence-AMR-graph pair and the * * Email corresponding. alignment output is then used as reference to train the AMR parser. In previous works, such alignment is extracted by either greedily applying a set of heuristic rules <ref type="bibr" target="#b10">(Flanigan et al., 2014)</ref> or adopting the unsupervised word alignment technique from machine translation <ref type="bibr" target="#b23">(Pourdamghani et al., 2014;</ref>. The rule-based aligner -JAMR aligner proposed by <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> is widely used in previous works thanks to its flexibility of incorporating additional linguistic resources like Word-Net. However, achieving good alignments with the JAMR aligner still faces some difficult challenges. The first challenge is deriving an optimal alignment in ambiguous situations. Taking the sentence-AMR-graph pair in <ref type="figure" target="#fig_0">Figure 1</ref> for example, the JAMR aligner doesn't distinguish between the two "nuclear"s in the sentence and can yield sub-optimal alignment in which the first "nuclear" is aligned to the nucleus˜2 concept. <ref type="bibr">1</ref> The second challenge is recalling more semantically matched word-concept pair without harming the alignment precision. The JAMR aligner adopts a rule that aligns the word-concept pair which at least have a common longest prefix of 4 characters, but omitting the shorter cases like aligning the word "actions" to the concept act-01 and the semantically matched cases like aligning the word "example" to the concept exemplify-01. The final challenge which is faced by both the rule-based and unsupervised aligners is tuning the alignment with downstream parser learning. Previous works treated the alignment as a fixed input. Its quality is never evaluated and its alternatives are never explored. All these challenges make the JAMR aligner achieve only an alignment F1 score of about 90% and influence the performance of the trained AMR parsers.</p><p>In this paper, we propose a novel method to solve these challenges and improve the word-toconcept alignment, which further improves the AMR parsing performance. A rule-based aligner and a transition-based oracle AMR parser lie in the core of our method. For the aligner part, we incorporate rich semantic resources into the JAMR aligner to recall more word-concept pairs and cancel its greedily aligning process. This leads to multiple alignment outputs with higher recall but lower precision. For the parser part, we propose a new transition system that can parse the raw sentence into AMR graph directly. Meanwhile, a new oracle algorithm is proposed which produces the best achievable AMR graph from an alignment. Our aligner is tuned by our oracle parser by feeding the alignments to the oracle parser and picking the one which leads to the highest Smatch F1 score . The chosen alignment is used in downstream training of the AMR parser. Based on the newly proposed aligner and transition system, we develop a transition-based parser that directly parses a sentence into its AMR graph and it can be easily improved through ensemble thanks to its simplicity.</p><p>We conduct experiments on LDC2014T12 dataset. 2 Both intrinsic and extrinsic evaluations are performed on our aligner. In the intrinsic evaluation, our aligner achieves an alignment F1 score of 95.2%. In the extrinsic evaluation, we replace the JAMR aligner with ours in two openthat there is no nucleus˜2 in the AMR corpus. 2 catalog.ldc.upenn.edu/ldc2014t12 sourced AMR parsers, which leads to consistent improvements on both parsers. We also evaluate our transition-based parser on the same dataset. Using both our aligner and ensemble, a score of 68.1 Smatch F1 is achieved without any additional resources, which is comparable to the parser of . With additional part-ofspeech (POS) tags, our ensemble parser achieves 68.4 Smatch F1 score and outperforms that of . The contributions of this paper come in two folds:</p><p>• We propose a new AMR aligner ( §3) which recalls more semantically matched pairs and produces multiple alignments. We also propose a new transition system for AMR parsing ( §4.1) and use its oracle ( §4.2) to pick the alignment that leads to the highest-scored achievable AMR graph ( §4.3). Both intrinsic and extrinsic evaluations ( §5) show the effectiveness of our aligner by achieving higher F1 score and consistently improving two opensourced AMR parsers.</p><p>• We build a new transition-based parser ( §4.4) upon our aligner and transition system which directly parses a raw sentence into its AMR graph. Through simple ensemble, our parser achieves 68.4 Smatch F1 score with only words and POS tags as input ( §6) and outperforms the parser of .</p><p>Our code and the alignments for LDC2014T12 dataset are publicly available at https:// github.com/Oneplus/tamr 2 Related Work AMR Parsers. AMR parsing maps a natural language sentence into its AMR graph. Most current parsers construct the AMR graph in a two-staged manner which first identifies concepts (nodes in the graph) from the input sentence, then identifies relations (edges in the graph) between the identified concepts. <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> and their follow-up works <ref type="bibr" target="#b9">(Flanigan et al., 2016;</ref><ref type="bibr" target="#b30">Zhou et al., 2016)</ref> model the parsing problem as finding the maximum spanning connected graph. <ref type="bibr" target="#b29">Wang et al. (2015b)</ref> proposes to greedily transduce the dependency tree into AMR graph and a bunch of works <ref type="bibr" target="#b28">(Wang et al., 2015a;</ref><ref type="bibr" target="#b12">Goodman et al., 2016;</ref> further improve the transducer's performance with rich features and imitation learning. 3 Transition-based methods that directly parse an input sentence into its AMR graph have also been studied <ref type="bibr" target="#b2">(Ballesteros and Al-Onaizan, 2017;</ref><ref type="bibr" target="#b6">Damonte et al., 2017)</ref>. In these works, the concept identification and relation identification are performed jointly.</p><p>An aligner which maps a span of words into its concept serves to the generation of training data for the concept identifier, thus is important to the parser training. Missing or incorrect alignments lead to poor concept identification, which then hurt the overall AMR parsing performance. Besides the typical two-staged methods, the aligner also works in some other AMR parsing algorithms like that using syntax-based machine translation <ref type="bibr" target="#b24">(Pust et al., 2015)</ref>, sequence-to-sequence <ref type="bibr" target="#b21">(Peng et al., 2017;</ref><ref type="bibr" target="#b14">Konstas et al., 2017)</ref>, Hyperedge Replacement Grammar <ref type="bibr" target="#b19">(Peng et al., 2015)</ref> and Combinatory Category Grammar <ref type="bibr" target="#b1">(Artzi et al., 2015)</ref>. <ref type="bibr" target="#b20">Peng et al. (2018)</ref> proposed a transition-based parser that parses AMR graph from the identified concepts, which is close to the transition-based method in terms of . However, their work relies on the identified concepts and can be treated as a two-staged method.</p><p>Previous aligner works solve the alignment problem in two different ways. The rule-based aligner <ref type="bibr" target="#b10">(Flanigan et al., 2014)</ref> defines a set of heuristic rules which align a span of words to the graph fragment and greedily applies these rules. The unsupervised aligner <ref type="bibr" target="#b23">(Pourdamghani et al., 2014;</ref> uncovers the word-toconcept alignment from the linearized AMR graph through EM. All these approaches yield a single alignment for one sentence and its effect on the downstream parsing is not considered. <ref type="bibr" target="#b16">Lyu and Titov (2018)</ref> proposed to model alignment as a latent variable. Improved performance was achieved which indicates the usefulness of improving alignment. In addition to the work on AMR-to-string alignment, there are also works trying to uncover the alignment between AMR and dependency syntax <ref type="bibr" target="#b26">(Szubert et al., 2018)</ref>.</p><p>JAMR Aligner <ref type="bibr" target="#b10">(Flanigan et al., 2014)</ref>. Two components exist in the JAMR aligner: 1) a set of heuristic rules and 2) a greedy search process.</p><p>The heuristic rules in the JAMR aligner are a set of indicator functions ρ(c, w s,e ) which take a concept c and a span of words w s,e starting from s and ending with e as input and return whether they should be aligned. These rules can be categorized into matching rules and updating rules. The matching rules directly compare c with w s,e and determine if they should be aligned. The updating rules first retrieve the concept c that w s,e aligns, then determine if c and w s,e should be aligned by checking whether c and c meet some conditions. Here, we illustrate how update rules work by applying a rule named Entity Type on the AMR graph in <ref type="figure" target="#fig_0">Figure 1</ref> as an example. When determining if the entity type concept country should be aligned to "North Korea", the Entity Type rule first retrieve that this span is aligned to the fragment (name :op1 "North" :op2 "Korea"), then determine if they are aligned by checking if name is the tail concept of country.</p><p>The greedy search process applies rules in a manually defined order. The results are mutually exclusive which means once a graph fragment is aligned by one rule, it cannot be realigned. By doing so, conflicts between the alignments produced by different rules are resolved. <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> didn't talk about the principle of orders but it generally follows the principle that 1) the matching rules have higher priorities than the updating rules, and 2) exact matching rules have higher priorities than the fuzzy matching rules.</p><p>3 Enhanced Rule-based Aligner</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Enhancing Aligner with Rich Semantic Resources</head><p>Error propagates in the greedy search process. An alignment error can lead to future errors because of the dependencies and mutual exclusions between rules. In the JAMR aligner, rules that recall more alignments but introduce errors are carefully opted out and it influences the aligner's performance. Our motivation is to use rich semantic resources to recall more alignments. Instead of resolving the resulted conflicts and errors by greedy search, we keep the multiple alignments produced by the aligner and let a parser decide the best alignment.</p><p>In this paper, we use two kinds of semantic resources to recall more alignments, which include the similarity drawn from Glove embedding (Pen-(Semantic Named Entity) Applies to name concepts and their opn children. Matches a span that matches the semantic match of each child in numerical order. (Morphological Named Entity) Applies to name concepts and their opn children. Matches a span that matches the morphological match of each child in numerical order. (Semantic Concept) Applies to any concept. Strips off trailing '-[0-9]+' from the concept, and matches any semantic matching word. (Morphological Concept) Applies to any concept. Strips off trailing '-[0-9]+' from the concept, and matches any morphological matching word or WordNet lemma.  <ref type="bibr" target="#b8">(Fellbaum et al., 2009</ref>) in the WordNet project 5 . Two additional matching schemes semantic match and morphological match are proposed as:</p><p>Semantic Match. Glove embedding encodes a word into its vector representation. We define semantic match of a concept as a word in the sentence that has a cosine similarity greater than 0.7 in the embedding space with the concept striping off trailing number (e.g. run-01 → run).</p><p>Morphological Match. Morphosemantic is a database that contains links among derivational links connecting noun and verb senses (e.g., "example" and exemplify). We define morphological match of a concept as a word in the sentence having the (word, concept) link in the database.</p><p>By defining the semantic match and morphological match, we extend the rules in <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> with four additional matching rules as shown in <ref type="table" target="#tab_0">Table 1</ref>. These rules are intended to recall the concepts or entities which either semantically resemble a span of words but differ in the surface form, or match a span of words in their morphological derivation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Producing Multiple Alignments</head><p>Using the rules in the JAMR aligner along with our four extended matching rules, we propose an algorithm to draw multiple alignments from a pair of sentence and AMR graph and it is shown in Algorithm 1. In this algorithm, A c denotes the set of candidate alignments for a graph fragment c, in which each alignment is represented as a tuple (s, e, c ) where s denotes the starting position, Algorithm 1: Our alignment algorithm.</p><p>Input: An AMR graph with a set of graph fragments C; a sentence W ; a set of matching rules PM ; and a set of updating rules PU . Output: a set of alignments A. e denotes the ending position, and c denotes the concept that lead to this alignment. At the beginning, A c is initialized as an empty set (line 1 to 2). Then all the matching rules are tried to align a span of words to that fragment (line 3 to 7). After applying all the matching rules, all the updating rules are repeatedly applied until no new alignment is generated in one iteration (line 8 to 16). During applying the updating rules, we keep track of the dependencies between fragments. Finally, all the possible combination of the alignments are enumerated without considering the one that violates the fragment dependencies (line 17 to 26). situation but is required to consider the association between concepts and spans. This stops the deterministic parsers which build AMR graph only from the derived concepts 6 from being used because they do not distinguish alignments that yields to the same set of concepts. <ref type="bibr">7</ref> This discussion shows that to evaluate the quality of an alignment, we need a deterministic (oracle) parser which builds the AMR graph from the raw sentence. Ballesteros and Al-Onaizan (2017) presented a transition-based parser that directly parses a sentence into its AMR graph. A transition system which extends the swap-based dependency parsing system to handle AMR non-projectivities <ref type="bibr" target="#b6">(Damonte et al., 2017)</ref> was proposed in their work. Their work presented the possibility for the oracle parser, but their oracle parser was not touched explicitly. What's more, in the non-projective dependency parsing, Choi and McCallum (2013)'s extension to the list-based system <ref type="bibr" target="#b18">(Nivre, 2008)</ref> with caching mechanism achieves expected linear time complexity and requires fewer actions to parse a non-projective tree than the swap-based system. Their extension to transition-based AMR parsing is worth studying.</p><p>In this paper, we propose to extend Choi and McCallum (2013)'s transition system to AMR parsing and present the corresponding oracle parser. The oracle parser is used for tuning our aligner and training our parser. We also present a comprehensive comparison of our system with that of <ref type="bibr" target="#b2">Ballesteros and Al-Onaizan (2017)</ref> in Section 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">List-based Extension for AMR Parsing</head><p>We follow Choi and McCallum (2013) and define a state in our transition system as a quadruple s = (σ, δ, β, A), where σ is a stack holding processed words, δ is a deque holding words popped out of σ that will be pushed back in the future, and β is a buffer holding unprocessed words. A is a set of labeled relations. A set of actions is defined to parse sentence into AMR graph. <ref type="table" target="#tab_2">Table 2</ref> gives a formal illustration of these actions and how they work. The first five actions in <ref type="table" target="#tab_2">Table 2</ref> are our extended actions, and they are used to deriving concepts from the input sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Oracle Parser</head><p>Given an alignment and the gold standard AMR graph, we can build the best AMR graph by repeatedly applying one of these actions and this is what we called oracle parser. Before running the oracle parser, we first remove the concepts which aren't aligned with any span of words from the AMR graph. During running the oracle parser, for a state s = (σ|s 0 , δ, b 0 |b 1 |β, A), our oracle parser decides which action to apply by checking the following conditions one by one.</p><p>1. If b 0 is a word and it doesn't align to any concept, perform DROP.</p><p>2. If b 1 is within a span in the alignment, perform MERGE.</p><p>3. If b 0 is a word or span and it only aligns to one entity concept c, perform ENTITY(c).</p><p>4. If b 0 is a word or span and it aligns to one or more concepts, perform CONFIRM(c) where c is the concept b 0 aligns and has the longest graph distance to the root.</p><p>5. If b 0 is a concept and its head concept c has the same alignment as b 0 , perform NEW(c).</p><p>6. If b 0 is a concept and there is an unprocessed edge r between s 0 and t 0 , perform LEFT(r) or RIGHT(r) according to r's direction.</p><p>7. If s 0 has unprocessed edge, perform CACHE.</p><p>8. If s 0 doesn't have unprocessed edge, perform REDUCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">perform SHIFT.</head><p>We test our oracle parser on the hand-align data created by <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> and it achieves 97.4 Smatch F1 score. 8 Besides the errors resulted from incorrect manual alignments, entity errors made by the limitation of our ENTITY(c) action count a lot. Since our ENTITY action directly converts the surface form of a word span into an entity. It cannot correctly generate entity names when they require derivation, 9 or where tokenization errors exist. 10   <ref type="figure">Figure 2</ref>: The workflow of tuning the aligner with the oracle parser. a i denotes the i-th alignment, g i denotes the i-th AMR graph, and s i denotes the score of the i-th AMR graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Tune the Aligner with Oracle Parser</head><p>Using our oracle parser, we tune the aligner by picking the alignment which leads to the highestscored AMR graph from the set of candidates (see <ref type="figure">Figure 2</ref> for the workflow). When more than one alignment achieve the highest score, we choose the one with the smallest number of actions. Intuitively, choosing the one with the smallest number of actions will encourage structurally coherent 8 Since some alignments in hand-align were created on incorrect AMR annotations, we filter out them and only use the correct subset which has 136 pairs of alignment and AMR graph. This data is also used in our intrinsic evaluation. 9 e.g., "North Koreans" cannot be parsed into (name :op1 "North" :op2 "Korea") 10 e.g., "Wi Sung -lac" cannot be parsed into (name :op1 "Wi" :op2 "Sung-lac") alignment 11 because coherent alignment requires fewer CACHE actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parsing Model</head><p>Based on our aligner and transition system, we propose a transition-based parser which parse the raw sentence directly into its AMR graph. In this paper, we follow Ballesteros and Al-Onaizan (2017) and use StackLSTM  to model the states. The score of a transition action a on state s is calculated as</p><formula xml:id="formula_0">p(a|s) = exp{g a · STACKLSTM(s) + b a } a exp{g a · STACKLSTM(s) + b a } ,</formula><p>where STACKLSTM(s) encodes the state s into a vector and g a is the embedding vector of action a. We encourage the reader to refer Ballesteros and Al-Onaizan (2017) for more details.</p><p>Ensemble. Ensemble has been shown as an effective way of improving the neural model's performance <ref type="bibr" target="#b13">(He et al., 2017)</ref>. Since the transitionbased parser directly parse a sentence into its AMR graph, ensemble of several parsers is easier compared to the two-staged AMR parsers. In this paper, we ensemble the parsers trained with different initialization by averaging their probability distribution over the actions.   5 Alignment Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Settings</head><p>We evaluate our aligner on the LDC2014T12 dataset. Two kinds of evaluations are carried out including the intrinsic and extrinsic evaluations. For the intrinsic evaluation, we follow <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> and evaluate the F1 score of the alignments produced by our aligner against the manually aligned data created in their work (handalign). We also use our oracle parser's performance as an intrinsic evaluation assuming that better alignment leads to higher scored oracle parser.</p><p>For the extrinsic evaluation, we plug our alignment into two open-sourced AMR parsers: 1) JAMR <ref type="bibr" target="#b10">(Flanigan et al., 2014</ref><ref type="bibr" target="#b9">(Flanigan et al., , 2016</ref> and 2) CAMR <ref type="bibr">(Wang et al., 2015b,a)</ref> and evaluate the final performances of the AMR parsers on both the newswire proportion and the entire dataset of LDC2014T12. We use the configuration in <ref type="bibr" target="#b9">Flanigan et al. (2016)</ref> for JAMR and the configuration in <ref type="bibr" target="#b28">Wang et al. (2015a)</ref> without semantic role labeling (SRL) features for CAMR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Intrinsic Evaluation. <ref type="table" target="#tab_4">Table 3</ref> shows the intrinsic evaluation results, in which our alignment intrinsically outperforms JAMR aligner by achieving better alignment F1 score and leading to a higher scored oracle parser.</p><p>Extrinsic Evaluation. <ref type="table" target="#tab_5">Table 4</ref> shows the results. From this table, we can see that our alignment consistently improves all the parsers by a margin ranging from 0.5 to 1.7. Both the intrinsic and the  extrinsic evaluations show the effectiveness our aligner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation</head><p>To have a better understanding of our aligner, we conduct ablation test by removing the semantic matching and oracle parser tuning respectively and retrain the JAMR parser on the newswire proportion. The results are shown in <ref type="table" target="#tab_7">Table 5</ref>. From this table, we can see that removing either of these components harms the performance. Removing oracle parser tuning leads to severe performance drop and the score is even lower than that with JAMR aligner. We address this observation to that alignment noise is introduced by the semantic matching especially by the word embedding similarity component. Without filtering the noise by our oracle parser, just introducing more matching rules will harm the performance.</p><p>6 Parsing Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Settings</head><p>We use the same settings in our aligner extrinsic evaluation for the experiments on our transitionbased parser. For the input to the parser, we tried two settings: 1) using only words as input, and 2) using words and POS tags as input. Automatic POS tags are assigned with Stanford POS tagger . Word embedding from  is used in the same way with Ballesteros and Al-Onaizan (2017). To opt out the effect of different initialization in training the neural network, we run 10 differently seeded runs and report their average performance following <ref type="bibr" target="#b25">Reimers and Gurevych (2017)</ref>.  trend is witnessed using words and POS tags as input. When replacing the JAMR alignments with ours, the parsing performances are improved in the same way as in <ref type="table" target="#tab_5">Table 4</ref>, which further confirms the effectiveness of our aligner. The second block in <ref type="table" target="#tab_8">Table 6</ref> shows the results of our ensemble parser, in which ensemble significantly improves the performance and more parsers ensembled, more improvements are achieved. An ensemble of 10 parsers with only words as input achieves 68.1 Smatch F1 score which is comparable to the AMR parser of . Using the minimal amount of additional syntactic information -POS tags, the performance of the ensemble of 10 parsers is further pushed to 68.4, which surpasses that of  which relied on named entity recognition (NER) and dependency parsing (DEP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>A further study on the speed shows that our 10 parser ensemble can parse 43 tokens per second which is faster than JAMR (7 tokens/sec.) and CAMR (24 tokens/sec.) thanks to the simplicity of our model and independence of preprocessing, like NER and DEP. 12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparison to Ballesteros and</head><p>Al-Onaizan <ref type="formula">(2017)</ref> To explain the improved performance against <ref type="bibr" target="#b2">Ballesteros and Al-Onaizan (2017)</ref> in <ref type="table" target="#tab_8">Table 6</ref>, we give a comprehensive comparison between our transition system and that of <ref type="bibr" target="#b2">Ballesteros and Al-Onaizan (2017)</ref>.</p><p>Capability. In both these two systems, a span of words can only be derived into concept for one time. "Patch" actions are required to generate new concepts from the one that is aligned to the same span. <ref type="bibr">13</ref> Ballesteros and Al-Onaizan (2017) uses a DEPENDENT action to generate one tail concept for one hop and cannot deal with the cases which have a chain of more than two concepts aligned to the same span. Our list-based system differs theirs by using a NEW action to deal these cases. Since the new concept is pushed onto the buffer, NEW action can be repeatedly applied and used to generate arbitrary concepts that aligned to the same span. On the development set of LDC2014T12, our oracle achieves 91.7 Smatch F1 score over the JAMR alignment, which outperforms Ballesteros and Al-Onaizan (2017)'s oracle (89.5 in their paper) on the same alignment. This result confirms that our list-based system is more powerful.</p><p>Number of Actions. Our list-based system also differs theirs in the number of oracle actions required to parse the same AMR graphs. We use the oracles from two systems to parse the development set of LDC2014T12 on the same JAMR alignments. <ref type="figure" target="#fig_2">Figure 3</ref> shows the comparison in which our system clearly uses fewer actions (the average number of our system is 63.7 and that of Ballesteros and Al-Onaizan (2017) is 86.4). Using fewer actions makes the parser learned from the oracle less prone to error propagation. We attribute the improved performance in <ref type="table" target="#tab_8">Table 6</ref> to this advantage of transition system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we propose a new AMR aligner which is tuned by a novel transition-based AMR oracle parser. Our aligner is also enhanced by rich semantic resource and recalls more alignments. Both the intrinsic and extrinsic evaluations show the effectiveness of our aligner by achieving higher alignment F1 score and consistently improving two open-sourced AMR parsers. We also develop transition-based AMR parser based on our aligner and transition system and it achieves a performance of 68.4 Smatch F1 score via ensemble with only words and POS tags as input.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>AMR graph for the sentence "North Korea froze its nuclear actions in exchange for two nuclear reactors."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(c, ws,e) then 7 Ac ← Ac ∪ (s, e, nil); 8 updated ← true ; 9 while updated is true do 10 updated ← false; 11 for ρU ∈ PU do 12 for c, c ∈ C × C do 13 for (s, e, d) ∈ A c do 14 if ρU (c, ws,e) ∧ (s, e, c ) / ∈ Ac then 15 Ac ← Ac ∪ (s, e, c ); 16 updated ← true; 17 A ← ∅ ; 18 for (a1, ..., ac) ∈ CartesianProduct(A1, ..., A |C| ) do 19 legal ← true; 20 for a ∈ (a1, ..., ac) do 21 (s, e, c ) ← a; 22 (s , e , d) ← a c ; 23 if s = s ∧ e = e then 24 legal ← false ; 25 if legal then 26 A ← A ∪ (a1, ..., ac);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Number of actions required to parse the development set by two systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The extended rules. nington et al., 2014) 4 and the morphosemantic database</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>pops out the word that doesn't convey any semantics (e.g., function words and punctuations).MERGE [σ|s0, δ, b0|b1|β, A] [σ|s0, δ, b0 b1|β, A]concatenates a sequence of words into a span, which can be derived as a named entity (name) or date-entity. CONFIRM(c)[σ|s0, δ, b0|β, A]   [σ|s0, δ, c|β, A] derives the first element of the buffer (a word or span) into a concept c.</figDesc><table><row><cell>Transition Current State</cell><cell>Resulting State</cell><cell></cell><cell>Description</cell></row><row><cell>DROP [σ|s0, δ, b0|β, A]</cell><cell>[σ|s0, δ, β, A]</cell><cell></cell><cell></cell></row><row><cell>ENTITY(c) [σ|s0, δ, b0|β, A]</cell><cell cols="2">[σ|s0, δ, c|β, A ∪ relations(c)]</cell><cell>a special form of CONFIRM that derives</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the first element into an entity and builds</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the internal entity AMR fragment.</cell></row><row><cell>NEW(c) [σ|s0, δ, b0|β, A]</cell><cell>[σ|s0, δ, c|b0|β, A]</cell><cell></cell><cell>generates a new concept c and pushes it</cell></row><row><cell></cell><cell></cell><cell></cell><cell>to the front of the buffer.</cell></row><row><cell>LEFT(r) [σ|s0, δ, b0|β, A]</cell><cell>[σ|s0, δ, b0|β, A ∪ {s0</cell><cell cols="2">r ← − b0}] links a relation r between the top</cell></row><row><cell>RIGHT(r) [σ|s0, δ, b0|β, A]</cell><cell>[σ|s0, δ, b0|β, A ∪ {s0</cell><cell>r − → b0}]</cell><cell>concepts on the stack and the buffer.</cell></row><row><cell>CACHE [σ|s0, δ, b0|β, A]</cell><cell>[σ, s0|δ, b0|β, A]</cell><cell></cell><cell>passes the top concept of the stack onto</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the deque.</cell></row><row><cell>SHIFT [σ|s0, δ, b0|β, A]</cell><cell>[σ|s0|δ|b0, [ ], β, A]</cell><cell></cell><cell>shifts the first concept of the buffer onto</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the stack along with those on the deque.</cell></row><row><cell>REDUCE [σ|s0, δ, b0|β, A]</cell><cell>[σ, δ, b0|β, A]</cell><cell></cell><cell>pops the top concept of the stack.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The transition system. The letters in monospace font represent the concepts, the italic letters represent the word, and the letters in normal font are either concepts or words.</figDesc><table><row><cell></cell><cell></cell><cell>a1</cell><cell></cell><cell>g1</cell><cell></cell><cell>s1</cell></row><row><cell>Training Data</cell><cell>Aligner</cell><cell>. . .</cell><cell>Oracle</cell><cell>. . .</cell><cell>Eval.</cell><cell>. . .</cell></row><row><cell></cell><cell></cell><cell>an</cell><cell></cell><cell>gn</cell><cell></cell><cell>sn</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">highest-scored, pick</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The intrinsic evaluation results.</figDesc><table><row><cell>model</cell><cell>newswire</cell><cell>all</cell></row><row><cell cols="2">JAMR parser: Word, POS, NER, DEP</cell><cell></cell></row><row><cell>+ JAMR aligner</cell><cell>71.3</cell><cell>65.9</cell></row><row><cell>+ Our aligner</cell><cell>73.1</cell><cell>67.6</cell></row><row><cell cols="2">CAMR parser: Word, POS, NER, DEP</cell><cell></cell></row><row><cell>+ JAMR aligner</cell><cell>68.4</cell><cell>64.6</cell></row><row><cell>+ Our aligner</cell><cell>68.8</cell><cell>65.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>The parsing results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>The ablation test results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>shows the performance of our transition-</cell></row><row><cell>based parser along with comparison to the parsers</cell></row><row><cell>in the previous works. When compared with our</cell></row><row><cell>transition-based counterpart (Ballesteros and Al-</cell></row><row><cell>Onaizan, 2017), our word-only model outperforms</cell></row><row><cell>theirs using the same JAMR alignment. The same</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>The parsing results. xn denotes the ensemble of n differently initialized parsers. The difference in rounding is due to previous works report differently rounded results. † BA17 represents the result of Ballesteros and Al-Onaizan (2017), ‡ Damonte et al. (2017)'s result is drawn from Ballesteros and Al-Onaizan (2017).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use the tail number in nucleus˜X to distinguish two different concepts in the AMR graph. We need to note</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3"><ref type="bibr" target="#b29">Wang et al. (2015b)</ref> and the follow-up works refer their transducing process as "transition-based". However, to distinguish their work with that of<ref type="bibr" target="#b6">Damonte et al. (2017)</ref> and<ref type="bibr" target="#b2">Ballesteros and Al-Onaizan (2017)</ref>, we use the term "transduce" instead.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">nlp.stanford.edu/projects/glove/ 5 wordnet.princeton.edu/wordnet/ download/standoff/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Transition-based AMR ParserOur enhanced rule-based aligner produces multiple alignments, and we would like to use our parser to evaluate their qualities. A parameterized parser does not accomplish such goal because training its parameters depends on the aligner's outputs. A deterministic parser works in this</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">e.g. the reference relation identifier in<ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> and the oracle transducer in<ref type="bibr" target="#b29">Wang et al. (2015b)</ref>. 7 recall the "nuclear" example in Section 1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">e.g. the first "nuclear" aligned to nucleus˜1 inFig. 1</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their helpful comments and suggestions. This work was supported by the National Key Basic Research Program of China via grant 2014CB340503 and the National Natural Science Foundation of China (NSFC) via grant 61632011 and 61772153.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">In our speed comparison, we also count the time of preprocessing for JAMR and CAMR. All the comparison is performed in the same single-threaded settings</title>
		<imprint/>
	</monogr>
	<note>13 e.g., three concepts in the fragment (person :source (country :name (name :op1 &quot;North&quot; :op2 &quot;Korea&quot;))) are aligned to &quot;North Koreans</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Broad-coverage ccg semantic parsing with amr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Amr parsing using stack-lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 7th Linguistic Annotation Workshop and Interoperability</title>
		<meeting>of the 7th Linguistic Annotation Workshop and Interoperability</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>with Discourse</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Transition-based dependency parsing with selectional branching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An incremental parser for abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Putting semantics into wordnet&apos;s &quot;morphosemantic&quot; links</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Osherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology. Challenges of the Information Society</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cmu at semeval-2016 task 8: Graph-based amr parsing with infinite ramp loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 10th International Workshop on Semantic Evaluation</title>
		<meeting>of the 10th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>SemEval-2016</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Abstract meaning representation parsing using lstm recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Foland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Noise reduction and targeted exploration in imitation learning for abstract meaning representation parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep semantic role labeling: What works and whats next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural amr: Sequence-to-sequence models for parsing and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Two/too simple adaptations of word2vec for syntax problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Amr parsing as graph prediction with latent alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunchuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mc-Closky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Algorithms for deterministic incremental dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A synchronous hyperedge replacement grammar based approach for amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sequence-to-sequence models for cache transition systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Addressing the data sparsity issue in neural amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Aligning english strings with abstract meaning representation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parsing english into abstract meaning representation using syntaxbased machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Pust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A structured syntax-semantics interface for englishamr alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ida</forename><surname>Szubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Getting the most out of amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Boosting transition-based amr parsing with refined actions and auxiliary analyzers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A transition-based algorithm for amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Amr parsing with an incremental joint model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">U</forename><surname>Weiguang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhui</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
