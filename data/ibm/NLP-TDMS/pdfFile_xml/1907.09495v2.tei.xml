<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ISONN: ISOMORPHIC NEURAL NETWORK FOR GRAPH REPRESENTATION LEARNING AND CLASSIFICATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IFM Lab Florida State University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
							<email>jiawei@ifmlab.org</email>
							<affiliation key="aff0">
								<orgName type="institution">IFM Lab Florida State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ISONN: ISOMORPHIC NEURAL NETWORK FOR GRAPH REPRESENTATION LEARNING AND CLASSIFICATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Under review as a conference paper at ICLR 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning models have achieved huge success in numerous fields, such as computer vision and natural language processing. However, unlike such fields, it is hard to apply traditional deep learning models on the graph data due to the 'node-orderless' property. Normally, adjacency matrices will cast an artificial and random node-order on the graphs, which renders the performance of deep models on graph classification tasks extremely erratic, and the representations learned by such models lack clear interpretability. To eliminate the unnecessary nodeorder constraint, we propose a novel model named Isomorphic Neural Network (ISONN), which learns the graph representation by extracting its isomorphic features via the graph matching between input graph and templates. ISONN has two main components: graph isomorphic feature extraction component and classification component. The graph isomorphic feature extraction component utilizes a set of subgraph templates as the kernel variables to learn the possible subgraph patterns existing in the input graph and then computes the isomorphic features. A set of permutation matrices is used in the component to break the node-order brought by the matrix representation. Three fully-connected layers are used as the classification component in ISONN. Extensive experiments are conducted on benchmark datasets, the experimental results can demonstrate the effectiveness of ISONN, especially compared with both classic and state-of-the-art graph classification methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work relates to subgraph mining, graph neural networks, network embedding as well as graph classification. We will discuss them briefly in the followings.</p><p>Subgraph Mining: Mining subgraph features from graph data has been studied for many years. The aim is to extract useful subgraph features from a set of graphs by adopting some specific criteria. One classic unsupervised method (i.e., without label information) is gSpan <ref type="bibr" target="#b39">(Yan &amp; Han, 2002)</ref>, which builds a lexicographic order among graphs and map each graph to a unique minimum DFS code as its canonical label. GRAMI (Elseidy et al., 2014)  only stores templates of frequent subgraphs and treat the frequency evaluation as a constraint satisfaction problem to find the minimal set. For the supervised model (i.e., with label information), CORK utilizes labels to guide the feature selection, where the features are generated by gSpan <ref type="bibr" target="#b32">(Thoma et al., 2009</ref>). Due to the mature development of the sub-graph mining field, subgraph mining methods have also been adopted in life sciences (Mrzic</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The graph structure is attracting increasing interests because of its great representation power on various types of data. Researchers have done many analyses based on different types of graphs, such as social networks, brain networks and biological networks. In this paper, we will focus on the binary graph classification problem, which has extensive applications in the real world. For example, one may wish to identify the social community categories according to the users' social interactions , distinguish the brain states of patients via their brain networks <ref type="bibr" target="#b36">Wang et al. (2017)</ref>, and classify the functions of proteins in a biological interaction network <ref type="bibr" target="#b14">Hamilton et al. (2017)</ref>.</p><p>To address the graph classification task, many approaches have been proposed. One way to estimate the usefulness of subgraph features is feature evaluation criteria based on both labeled and unlabeled graphs <ref type="bibr" target="#b18">Kong &amp; Yu (2010)</ref>. Some other works also proposed to design a pattern exploration approach based on pattern co-occurrence and build the classification model <ref type="bibr" target="#b16">Jin et al. (2009)</ref> or develop a boosting algorithm <ref type="bibr" target="#b37">Wu et al. (2014)</ref>. However, such works based on BFS or DFS cannot avoid computing a large quantity of possible subgraphs, which causes high computational complexity though the explicit subgraphs are maintained. Recently, deep learning models are also widely used to solve the graph-oriented problems. Although some deep models like <ref type="bibr">MPNN Gilmer et al. (2017)</ref> and <ref type="bibr">GCN Kipf &amp; Welling (2016)</ref> learn implicit structural features, the explict structural information cannot be maintained for further research. Besides, most existing works on graph classification use the aggregation of the node features in graphs as the graph representation <ref type="bibr" target="#b38">Xu et al. (2018)</ref>; <ref type="bibr" target="#b14">Hamilton et al. (2017)</ref>, but simply doing aggregation on the whole graph cannot capture the substructure precisely. While there are other models can capture the subgraphs, they often needs more complex computation and mechanism <ref type="bibr" target="#b36">Wang et al. (2017)</ref>; <ref type="bibr" target="#b28">Narayanan et al. (2017</ref> Under review as a conference paper at ICLR 2020 However, we should notice that when we deal with the graph-structured data, different node-orders will result in very different adjacency matrix representations for most existing deep models which take the adjacency matrices as input if there is no other information on graph. Therefore, compared with the original graph, matrix naturally poses a redundant constraint on the graph node-order. Such a node-order is usually unnecessary and manually defined. The different graph matrix representations brought by the node-order differences may render the learning performance of the existing models to be extremely erratic and not robust. Formally, we summarize the encountered challenges in the graph classification problem as follows:</p><p>• Explicit useful subgraph extraction. The existing works have proposed many discriminative models to discover useful subgraphs for graph classification, and most of them require manual efforts. Nevertheless, how to select the contributing subgraphs automatically without any additional manual involvement is a challenging problem.</p><p>• Graph representation learning. Representing graphs in the vector space is an important task since it facilitates the storage, parallelism and the usage of machine learning models for the graph data. Extensive works have been done on node representations <ref type="bibr" target="#b13">Grover &amp; Leskovec (2016)</ref>; <ref type="bibr" target="#b24">Lin et al. (2015)</ref>; <ref type="bibr" target="#b21">Lai et al. (2017)</ref>; <ref type="bibr" target="#b14">Hamilton et al. (2017)</ref>, whereas learning the representation of the whole graph with clear interpretability is still an open problem requiring more explorations.</p><p>• Node-order elimination. Nodes in graphs are orderless, whereas the matrix representations of graphs cast an unnecessary order on the nodes, which also renders the features extracted with the existing learning models, e.g., CNN, to be useless for the graphs. Thus, how to break such a node-order constraint is challenging.</p><p>• Efficient matching for large subgraphs. To break the node-order, we will try all possible node permutations to find the best permutation for a subgraph. Clearly, trying all possible permutaions is a combinatorial explosion problem, which is extremly time-comsuming for finding large subgraph templates. The problem shows that how to accelerate the proposed model for large subgraphs also needs to be solved.</p><p>In this paper, we propose a novel model, namely Isomorphic Neural Network (ISONN) and its variants, to address the aforementioned challenges in the graph representation learning and classification problem. ISONN is composed of two components: the graph isomorphic feature extraction component and the classification component, aiming at learning isomorphic features and classifying graph instances, respectively. In the graph isomorphic feature extraction component, ISONN automatically learns a group of subgraph templates of useful patterns from the input graph. ISONN makes use of a set of permutation matrices, which act as the node isomorphism mappings between the templates and the input graph. With the potential isomorphic features learned by all the permutation matrices and the templates, ISONN adopts one min-pooling layer to find the best node permutation for each template and one softmax layer to normalize and fuse all subgraph features learned by different kernels, respectively. Such features learned by different kernels will be fused together and fed as the input for the classification component. ISONN further adopts three fully-connected layers as the classification component to project the graph instances to their labels. Moreover, to accelerate the proposed model when dealing with large subgraphs, we also propose two variants of ISONN to gurantee the efficiency. <ref type="bibr">et al., 2018)</ref>. Moreover, several parallel computing based methods <ref type="bibr" target="#b29">(Qiao et al., 2018;</ref><ref type="bibr" target="#b15">Hill et al., 2012;</ref><ref type="bibr" target="#b23">Lin et al., 2014)</ref> have proposed to reduce the time cost.</p><p>Graph Neural Network and Network Embedding: Graph Neural Networks <ref type="bibr" target="#b26">(Monti et al., 2017;</ref><ref type="bibr" target="#b4">Atwood &amp; Towsley, 2016;</ref><ref type="bibr" target="#b25">Masci et al., 2015;</ref><ref type="bibr" target="#b17">Kipf &amp; Welling, 2016;</ref><ref type="bibr" target="#b6">Battaglia et al., 2018)</ref> have been studied in recent years because of the prosperity of deep learning. Traditional deep models cannot be directly applied to graphs due to the special data structure. The general graph neural model MoNet <ref type="bibr" target="#b26">(Monti et al., 2017)</ref> employs CNN architectures on non-Euclidean domains such as graphs and manifold. The GCN proposed in <ref type="bibr" target="#b17">(Kipf &amp; Welling, 2016)</ref> utilizes the normalized adjacency matrix to learn the node features for node classification; <ref type="bibr" target="#b5">(Bai et al., 2018)</ref> proposes the multiscale convolutional model for pairwise graph similarity with a set matching based graph similarity computation. However, these existing works based on graph neural networks all fail to investigate the node-orderless property of the graph data and to maintain the explicit structural information.</p><p>Another important topic related to this paper is network embedding <ref type="bibr" target="#b7">(Bordes et al., 2013;</ref><ref type="bibr" target="#b24">Lin et al., 2015;</ref><ref type="bibr" target="#b21">Lai et al., 2017;</ref><ref type="bibr">Abu-El-Haija et al., 2018;</ref><ref type="bibr" target="#b14">Hamilton et al., 2017)</ref>, which aims at learning the feature representation of each individual node in a network based on either the network structure or attribute information. Distinct from these network embedding works, the graph representation learning problem studied in this paper treats each graph as an individual instance and focuses on learning the representation of the whole graph instead.</p><p>Graph Classification: Graph classification is an important problem with many practical applications. Data like social networks, chemical compounds, brain networks can be represented as graphs naturally and they can have applications such as community detection , anti-cancer activity identification <ref type="bibr" target="#b19">(Kong et al., 2013;</ref><ref type="bibr" target="#b18">Kong &amp; Yu, 2010)</ref> and Alzheimer's patients diagnosis <ref type="bibr" target="#b34">(Tong et al., 2017;</ref> respectively. Traditionally, researchers mine the subgraphs by DFS or BFS <ref type="bibr" target="#b30">(Saigo et al., 2009;</ref><ref type="bibr" target="#b19">Kong et al., 2013)</ref>, and use them as the features. With the rapid development of deep learning (DL), many works are done based on DL methods. GAM builds the model by RNN with self-attention mechanism <ref type="bibr" target="#b22">(Lee et al., 2018)</ref>. DCNN extend CNN to general graph-structured data by introducing a diffusion-convolution operation <ref type="bibr" target="#b4">(Atwood &amp; Towsley, 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TERMINOLOGY AND PROBLEM DEFINITION</head><p>In this section, we will define the notations and the terminologies used in this paper and give the formulation for the graph classification problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NOTATIONS</head><p>In the following sections, we will use lower case letters like x to denote scalars, lower case bold letters (e.g. x) to represent vectors, bold-face capital letters (e.g. X) to show the matrices. For tensors or sets, capital calligraphic letters are used to denote them. We use x i to represent the i-th element in x. Given a matrix X, we use X(i, j) to express the element in i-th row and j-th column. For i-th row vector and j-th column vector, we use X(i, :) and X(:, j) to denote respectively. Moreover, notations x and X denote the transpose of vector x and matrix X respectively. Besides, the F -norm of matrix X can be represented as</p><formula xml:id="formula_0">X F = ( i,j |X i,j | 2 ) 1 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PROBLEM FORMULATION</head><p>Many real-world inter-connected data can be formally represented as the graph-structured data.</p><p>DEFINITION 1 (Graph): Formally, a graph can be represented as G = (V, E), where the sets V and E denote the nodes and links involved in the graph, respectively.</p><p>Some representative examples include the human brain graphs (where the nodes denote brain regions and links represent the correlations among these regions), biological molecule graphs (with the nodes represent the atoms and links denote the atomic bonds), as well as the geographical graphs in the offline world (where the nodes denote the communities and the links represent the commute routes among communities). Meanwhile, many concrete real-world application problems, e.g., brain graph based patient disease diagnosis, molecule function classification and community vibrancy prediction can also be formulated as the graph classification problems.</p><p>Problem Definition: Formally, given a graph set G = {G 1 , G 2 , · · · , G n } with a small number of labeled graph instances, the graph classification problem aims at learning a mapping, i.e., f : G → Y, to project each graph instance into a pre-defined label space Y = {+1, −1}.              In this paper, we will take the graph binary classification as an example to illustrate the problem setting for ISONN. A simple extension of the model can be applied to handle more complicated learning scenarios with multi-class or multi-label as well.</p><formula xml:id="formula_1">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_2">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_3">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_4">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_5">+ t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O</formula><formula xml:id="formula_6">+ t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O</formula><formula xml:id="formula_7">+ t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O</formula><formula xml:id="formula_8">+ t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O</formula><formula xml:id="formula_9">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_10">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_11">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_12">i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V</formula><formula xml:id="formula_13">= " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B l v B V U m 6 0 W X V j c s K 9 g F N K J P p p B 0 6 m Y R 5 C C X 0 N 9 y 4 U M S t P + P O v 3 H S Z q G t B w Y O 5 9 z L P X P C l D O l X f f b K W 1 s b m 3 v l H c r e / s H h 0 f V 4 5 O u S o w k t E M S n s h + i B X l T N C O Z p r T f i o p j k N O e + H 0 L v d 7 T 1 Q q l o h H P U t p E O O x Y B E j W F v J r / s x 1 p M w y m 7 m 9 W G 1 5 j b c B d A 6 8 Q p S g w L t Y f X L H y X E x F R o w r F S A 8 9 N d Z B h q R n h d F 7 x j a I p J l M 8 p g N L B Y 6 p C r J F 5 j m 6 s M o I R Y m 0 T 2 i 0 U H 9 v Z D h W a h a H d j K P q F a 9 X P z P G x g d X Q c Z E 6 n R V J D l o c h w p B O U F 4 B G T F K i + c w S T C S z W R G Z Y I m J t j V V b A n e 6 p f X S b f Z 8 N y G 9 9 C s t W 6 L O s p w B u d w C R 5 c Q Q v u o Q 0 d I J D C M 7 z C m 2 O c F + f d + V i O l p x i 5 x T + w P n 8 A W W 2 k T 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 p S b 5 D J D 4 r 0 l A D i g P K U O b e U R r 0 4 = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B l v B V U m 6 0 W X V j c s K 9 g F N K J P p p B 0 6 m Y R 5 C C X 0 N 9 y 4 U M S t P + P O v 3 H S Z q G t B w Y O 5 9 z L P X P C l D O l X f f b K W 1 s b m 3 v l H c r e / s H h 0 f V 4 5 O u S o w k t E M S n s h + i B X l T N C O Z p r T f i o p j k N O e + H 0 L v d 7 T 1 Q q l o h H P U t p E O O x Y B E j W F v J r / s x 1 p M w y m 7 m 9 W G 1 5 j b c B d A 6 8 Q p S g w L t Y f X L H y X E x F R o w r F S A 8 9 N d Z B h q R n h d F 7 x j a I p J l M 8 p g N L B Y 6 p C r J F 5 j m 6 s M o I R Y m 0 T 2 i 0 U H 9 v Z D h W a h a H d j K P q F a 9 X P z P G x g d X Q c Z E 6 n R V J D l o c h w p B O U F 4 B G T F K i + c w S T C S z W R G Z Y I m J t j V V b A n e 6 p f X S b f Z 8 N y G 9 9 C s t W 6 L O s p w B u d w C R 5 c Q Q v u o Q 0 d I J D C M 7 z C m 2 O c F + f d + V i O l p x i 5 x T + w P n 8 A W W 2 k T 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 p S b 5 D J D 4 r 0 l A D i g P K U O b e U R r 0 4 = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B l v B V U m 6 0 W X V j c s K 9 g F N K J P p p B 0 6 m Y R 5 C C X 0 N 9 y 4 U M S t P + P O v 3 H S Z q G t B w Y O 5 9 z L P X P C l D O l X f f b K W 1 s b m 3 v l H c r e / s H h 0 f V 4 5 O u S o w k t E M S n s h + i B X l T N C O Z p r T f i o p j k N O e + H 0 L v d 7 T 1 Q q l o h H P U t p E O O x Y B E j W F v J r / s x 1 p M w y m 7 m 9 W G 1 5 j b c B d A 6 8 Q p S g w L t Y f X L H y X E x F R o w r F S A 8 9 N d Z B h q R n h d F 7 x j a I p J l M 8 p g N L B Y 6 p C r J F 5 j m 6 s M o I R Y m 0 T 2 i 0 U H 9 v Z D h W a h a H d j K P q F a 9 X P z P G x g d X Q c Z E 6 n R V J D l o c h w p B O U F 4 B G T F K i + c w S T C S z W R G Z Y I m J t j V V b A n e 6 p f X S b f Z 8 N y G 9 9 C s t W 6 L O s p w B u d w C R 5 c Q Q v u o Q 0 d I J D C M 7 z C m 2 O c F + f d + V i O l p x i 5 x T + w P n 8 A W W 2 k T 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 p S b 5 D J D 4 r 0 l A D i g P K U O b e U R r 0 4 = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B l v B V U m 6 0 W X V j c s K 9 g F N K J P p p B 0 6 m Y R 5 C C X 0 N 9 y 4 U M S t P + P O v 3 H S Z q G t B w Y O 5 9 z L P X P C l D O l X f f b K W 1 s b m 3 v l H c r e / s H h 0 f V 4 5 O u S o w k t E M S n s h + i B X l T N C O Z p r T f i o p j k N O e + H 0 L v d 7 T 1 Q q l o h H P U t p E O O x Y B E j W F v J r / s x 1 p M w y m 7 m 9 W G 1 5 j b c B d A 6 8 Q p S g w L t Y f X L H y X E x F R o w r F S A 8 9 N d Z B h q R n h d F 7 x j a I p J l M 8 p g N L B Y 6 p C r J F 5 j m 6 s M o I R Y m 0 T 2 i 0 U H 9 v Z D h W a h a H d j K P q F a 9 X P z P G x g d X Q c Z E 6 n R V J D l o c h w p B O U F 4 B G T F K i + c w S T C S z W R G Z Y I m J t j V V b A n e 6 p f X S b f Z 8 N y G 9 9 C s t W 6 L O s p w B u d w C R 5 c Q Q v u o Q 0 d I J D C M 7 z C m 2 O c F + f d + V i O l p x i 5 x T + w P n 8 A W W 2 k T 8 = &lt; / l a t e x i t &gt;ŷ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 3 z H k 9 E z c T N q 3 p P P D L H B 2 g 1 d O J g = " &gt; A A A B + 3 i c b V A 9 T 8 M w F H w p X 6 V 8 h T K y W L R I T F X S B c Y K F s Y i 0 R a p i S r H d V q r j h P Z D q K K 8 l d Y G E C I l T / C x r / B a T N A y 0 m W T n f v 6 Z 0 v S D h T 2 n G + r c r G 5 t b 2 T n W 3 t r d / c H h k H 9 f 7 K k 4 l o T 0 S 8 1 g + B F h R z g T t a a Y 5 f U g k x V H A 6 S C Y 3 R T + 4 J F K x W J x r + c J 9 S M 8 E S x k B G s j j e x 6 0 5 t i n X k R 1 t M g z O Z 5 3 h z Z D a f l L I D W i V u S B p T o j u w v b x y T N K J C E 4 6 V G r p O o v 0 M S 8 0 I p 3 n N S x V N M J n h C R 0 a K n B E l Z 8 t s u f o 3 C h j F M b S P K H R Q v 2 9 k e F I q X k U m M k i o 1 r 1 C v E / b 5 j q 8 M r P m E h S T Q V Z H g p T j n S M i i L Q m E l K N J 8 b g o l k J i s i U y w x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED METHOD</head><p>The overall architecture of ISONN is shown in <ref type="figure" target="#fig_13">Figure 1</ref>. The ISONN framework includes two main components: graph isomorphic feature extraction component and classification component. The graph isomorphic feature extraction component includes a graph isomorphic layer, a minpooling layer as well as a softmax layer and the classification component is composed by three fully-connected layers. They will be discussed in detail in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">GRAPH ISOMORPHIC FEATURE EXTRACTION COMPONENT</head><p>Graph isomorphic feature extraction component targets at learning the graph features. To achieve that objective, ISONN adopts an automatic feature extraction strategy for graph representation learning. In ISONN, one graph isomorphic feature extraction component involves three layers: the graph isomorphic layer, the min-pooling layer and the softmax layer. In addition, we can further construct a deep graph isomorphic neural network by stacking multiple isomorphic feature extraction components on top of each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">GRAPH ISOMORPHIC LAYER</head><p>Graph isomorphic layer is the first effective layer in deep learning that handles the node-order restriction in graph representations. Assume we have a graph G = {V, E}, and its adjacency matrix to be A ∈ R |V|×|V| . In order to find the existence of specific subgraph patterns in the input graph, ISONN matches the input graph with a set of subgraph templates. Each template is denoted as a kernel variable K i ∈ R k×k , ∀i ∈ {1, 2, · · · , c}. Here, k denotes the node number in subgraphs and c is the channel number (i.e., total template count). Meanwhile, to match one template with regions in the input graph (i.e., sub-matrices in A), we use a set of permutation matrices, which map both rows and columns of the kernel matrix to the subgraphs effectively. The permutation matrix can be represented as P ∈ {0, 1} k×k that shares the same dimension with the kernel matrix. Therefore, given a kernel matrix K i and a sub-matrix M (s,t) ∈ R k×k in A (i.e., a region in the input graph G and s, t ∈ {1, 2, · · · , (|V| − k + 1)} denotes a starting index pair in A), there may exist k! different such permutation matrices. The optimal should be the matrix P * that minimizes the following term.</p><formula xml:id="formula_14">P * = arg min P∈P PK i P − M (s,t) 2 F ,<label>(1)</label></formula><p>where P = {P 1 , P 2 , · · · , P k! } covers all the potential permutation matrices. Formally, the isomorphic feature extracted based on the kernel K i for the regional sub-matrix M <ref type="bibr">(s,t)</ref> in A can be represented as</p><formula xml:id="formula_15">z i,(s,t) = P * K i (P * ) − M (s,t) 2 F = min{ PK i P − M (s,t) 2 F } P∈P = min(z i,(s,t) (1 : k!)),<label>(2)</label></formula><p>where vectorz i,(s,t) ∈ R k! contains entryz i,(s,t) (j) = P j K i P j − M (s,t) 2 F , ∀j ∈ {1, 2, · · · , k!} denoting the isomorphic features computed by the j-th permutation matrix P j ∈ P.</p><p>As indicated by the <ref type="figure" target="#fig_13">Figure 1</ref>, ISONN computes the final isomorphic features for the kernel K i via two steps: (1) computing all the potential isomorphic features via different permutation matrices with the graph isomorphic layer, and (2) identifying and fusing the optimal features with the minpooling layer and softmax layer to be introduced as follows. By shifting one kernel matrix K i on regional sub-matrices, ISONN extracts the isomorphic features on the matrix A, which can be denoted as a 3-way tensorZ i ∈ R k!×(|V|−k+1)×(|V|−k+1) , whereZ i (1 : k!, s, t) =z i,(s,t) (1 : k!). In a similar way, we can also compute the isomorphic feature tensors based on the other kernels, which can be denoted asZ 1 ,Z 2 , · · · ,Z c respectively. 4.1.2 MIN-POOLING LAYER Given the tensorZ i computed by K i in the graph isomorphic layer, ISONN will identify the optimal permutation matrices via the min-pooling layer. Formally, we can represent results of the optimal permutation selection withZ i as matrix Z i :</p><formula xml:id="formula_16">Z i (s, t) = min{Z i (1 : k!, s, t)}.</formula><p>( <ref type="formula">3)</ref> The min-pooling layer learns the optimal matrix Z i for kernel K i along the first dimension (i.e., the dimension indexed by different permutation matrices), which can effectively identify the isomorphic features created by the optimal permutation matrices. For the remaining kernel matrices, we can also achieve their corresponding graph isomorphic feature matrices as Z 1 , Z 2 , · · · , Z c respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">SOFTMAX LAYER</head><p>Based on the above descriptions, a perfect matching between the subgraph templates with the input graph will lead to a very small isomorphic feature, e.g., a value approaching to 0. If we feed the small features into the classification component, the useful information will vanish and the relative useless information (i.e., features learned by the subgraphs dismatch the kernels) dominates the learning feature vector in the end. Meanwhile, the feature values computed in Equation <ref type="formula" target="#formula_23">(3)</ref> can also be in different scales for different kernels. To effectively normalize these features, we propose to apply the softmax function to matrices Z 1 , Z 2 , · · · , Z c across all c kernels. Compared with the raw features, e.g., Z i , softmax as a non-linear mapping can also effectively highlight the useful features in Z i by rescaling them to relatively larger values especially compared with the useless ones. Formally, we can represent the fused graph isomorphic features after rescaling by all the kernels as a 3-way tensor Q, where slices along first dimension can be denoted as:</p><formula xml:id="formula_17">Q(i, :, :) =Ẑ i , whereẐ i = sof tmax(−Z i ), ∀i ∈ {1, . . . , c}.<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CLASSIFICATION COMPONENT</head><p>After the isomorphic feature tensor Q is obtained, we feed it into a classification component. Let q denote the flattened vector representation of feature tensor Q, and we pass it to three fully-connected layers to get the predicted label vectorŷ. For the graph binary classification, suppose we have the ground truth y = (y g 1 , y g 2 ) and the predicted label vectorŷ g = (ŷ g 1 ,ŷ g 2 ) for the sample g from the training batch set B. We use cross-entropy as the loss function in ISONN. Formally, the fullyconnected (FC) layers and the objective function can be represented as follows respectively: FC Layers:</p><formula xml:id="formula_18">d 1 = σ(W 1 q + b 1 ), d 2 = σ(W 2 d 1 + b 2 ), y = σ(W 3 d 2 + b 3 ), Objective Function: L = − g∈B 2 j=1 y g j logŷ g j ,<label>(5)</label></formula><p>where W i and b i represent the weights and biases in i-th layer respectively for i ∈ {1, 2, 3}. The σ denotes the adopted the relu activation function. To train the proposed model, we adopt the back propagation algorithm to learn both the subgraph templates and the other involved variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MORE DISCUSSIONS ON GRAPH ISOMORPHIC FEATURE EXTRACTION IN ISONN</head><p>Before introducing the empirical experiments to test the effectiveness of ISONN, we would like to provide more discussions about the computation time complexity of the graph isomorphic feature extraction component involved in ISONN. Formally, given the input graph G with n = |V| nodes, by shifting the kernel variables (of size k × k) among the dimensions of the corresponding graph adjacency matrix, we will be able to obtain (n−k+1) 2 regional sub-matrices (or O(n 2 ) regional submatrices for notation simplicity). Here, we assume ISONN has only one isomorphic layer involving c different kernels. In the forward propagation, the introduced time cost in computing the graph  isomorphic features can be denoted as O(ck!k 3 n 2 ), where term k! is introduced in enumerating all the potential permutation matrices and k 3 corresponds to the matrix multiplication time cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. S</head><p>According to the notation, we observe that n is fixed for the input graph. Once the kernel channel number c is decided, the time cost notation will be mainly dominated by k. To lower down the above time complexity notation, in this part, we propose to further improve ISONN from two perspectives: (1) compute the optimal permutation matrix in a faster manner, and (2) use deeper model architectures with small-sized kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">FAST PERMUTATION MATRIX COMPUTATION</head><p>Instead of enumerating all the permutation matrices in the graph isomorphic feature extraction as indicated by Equations 2-3, here we introduce a fast way to compute the optimal permutation matrix for the provided kernel variable matrix, e.g., K i , and input regional sub-matrix, M (s,t) , directly according to the following theorem.</p><p>THEOREM 1 Formally, let the kernel variable K i and the input regional sub-matrix M (s,t) be k×k real symmetric matrices with k distinct eigenvalues α 1 &gt; α 2 &gt; · · · &gt; α k and β 1 &gt; β 2 &gt; · · · &gt; β k , respectively, and their eigendecomposition be represented by</p><formula xml:id="formula_19">K i = U Ki Λ Ki U Ki , and M (s,t) = U M (s,t) Λ M (s,t) U M (s,t)<label>(6)</label></formula><p>where U Ki and U M (s,t) are orthogonal matrices of eigenvectors and Λ Ki = diag(α j ), Λ M (s,t) = diag(β j ). The minimum of ||PK i P − M (s,t) || 2 is attained for the following P's:</p><formula xml:id="formula_20">P * = U M (s,t) SU Ki<label>(7)</label></formula><p>where S ∈ S = {diag(s 1 , s 2 , · · · , s k )|s i = 1 or − 1}.</p><p>The proof of the theorem will be provided in appendix. In computing the optimal permutation matrix P * , trials of different S will be needed. Meanwhile, to avoid such time costs, we introduce to take the upper bound value of U M (s,t) SU Ki as the approximated optimal permutation matrix instead, which together with the corresponding optimal feature z i,(s,t) can be denoted as follows:</p><formula xml:id="formula_21">P * = |U M (s,t) ||U Ki | and z i,(s,t) = ||P * K(P * ) − M (s,t) || 2 ,<label>(8)</label></formula><p>where |·| denotes the absolute value operator and |U M (s,t) ||U Ki | ≥ U M (s,t) SU Ki hold for ∀S ∈ S.</p><p>By replacing Equations 2-3 with Equation 7, we can compute the optimal graph isomorphic feature for the kernel K i and input regional sub-matrix M (s,t) with a much lower time cost. Furthermore, since the eigendecomposition time complexity of a k × k matrix is O(k 3 ), based on the above theorem, we will be able to lower down the total time cost in graph isomorphic feature extraction to O(ck 3 n 2 ), which can be further optimized with the method introduced in the following subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">DEEP GRAPH ISOMORPHIC FEATURE EXTRACTION</head><p>Here, we will illustrate the advantages of deep ISONN model with small-sized kernels compared against shallow ISONN model with large kernels. In <ref type="figure" target="#fig_14">Figure 2</ref>, we provide an example two ISONN models with different model architectures • the left model has one single layer and 6 kernels, where the kernel size k = 12;</p><p>• the right model has two layers: layer 1 involves 2 kernels of size 3, and layer 2 involves 3 kernels of size 4.</p><p>By comparing these two different models, we observe that they have identical representation learning capacity. However, the time cost in feature extraction introduced by the left model is much higher than that introduced by the right model, which can be denoted as O(6(12 3 )n 2 ) and O(2(3 3 )n 2 + 3(4 3 )n 2 ), respectively.</p><p>Therefore, for the ISONN model, we tend to use small-sized kernels. Formally, according to the fast method provided in the previous part, given a 1-layer ISONN model with c large kernels of size k, its graph isomorphic feature extraction time complexity can be denoted as O(ck 3 n 2 ). Inspired by <ref type="figure" target="#fig_14">Figure 2</ref>, without affecting the representation capacity, such a model can be replaced by a max{ log c 2 , log k 3 }-layers deep ISONN model instead, where each layer involves 2 kernels of size 3. The graph isomorphic feature extraction time complexity of the deep model will be O (max{ log c 2 , log k 3 }) · 2 · 3 3 n 2 (or O (max{ log c , log k }) · n 2 for simplicity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>To evaluate the performance of ISONN, in this section, we will talk about the experimental settings as well as five benchmark datasets. Finally, we will discuss the experimental results with parameter analyses on kernel size , channel number and time complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">EXPERIMENTAL SETTINGS</head><p>In this subsection, we will use five real-world benchmark datasets:  . MUTAG has 125 positive and 63 negative graph instances with graph size 28 × 28. PTC is a relative large dataset, which has 152 positive and 192 negative graph instances with graph size 109 × 109. With these datasets, we first introduce the comparison methods used in this paper and then talk about the experimental setups and the adopted evaluation metrics in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">COMPARISON METHODS</head><p>• ISONN &amp; ISONN-fast : The proposed method ISONN uses a set of template variables as well as the permutation matrices to extract the isomorphic features and feed these features to the classification component. The variant model named ISONN-fast uses the Equation <ref type="formula" target="#formula_21">8</ref> to compute the optimal permutation matrices and other settings remain unchanged. • Freq: The method uses the top-k frequent subgraphs as its features. This is also an unsupervised feature selection method based on frequency. • AE: We use the autoencoder model (AE) <ref type="bibr" target="#b35">Vincent et al. (2010)</ref> to get the features of graphs without label information. It is an unsupervised learning method, which learns the latent representations of connections in the graphs without considering the structural information. • CNN: It is the convolutional model <ref type="bibr" target="#b20">Krizhevsky et al. (2012)</ref> learns the structural information within small regions of the whole graph. We adopt one convolution layer and three fully-connected layer to be the classification module. • SDBN: A model proposed in <ref type="bibr" target="#b36">Wang et al. (2017)</ref>, which reorders the nodes in the graph first and then feeds the reordered graph into an augmented CNN. In this way, it not only learns the structural information but also tries to minimize the effect of the order constraint. • WL: WL Shervashidze &amp; Borgwardt (2009) is a classic algorithm to do the graph isomorphism test. For the graph classification, we computes the similarity scores for test graphs and train graph. The mean of all similarity scores between each test graph and train graphs will be used to do the classification. • GCN: GCN is proposed in <ref type="bibr" target="#b17">Kipf &amp; Welling (2016)</ref> use the adjacent matrix to learn the implicit structure information in graphs. Here, we use two graph convolutional layers to  (e) PTC <ref type="figure">Figure 3</ref>: Effectiveness of Different k performs better than GIN but worse than ISONN, showing that GCN can learn some sturctual information without node labels, but GIN cannot work with the adjacency matrix as input. ISONN-fast achieves the best scores on MUTAG and second-best on HIV-fMRI, yet worse than several other methods on other datasets. This can be the approximation on P may impair the performance. Comparing ISONN with AE, ISONN achieves better results. This means the structural information is more important than only connectivity information for the classification problem. If compared with CNN, the results also show the contribution of breaking the node-order in learning the subgraph templates. Similar to SDBN, ISONN also finds the features from subgraphs, but ISONN gets better performance with more concise architecture. Contrasting with GCN and GIN, ISONN can maintain the explict subgraph structures in graph representations, while the GCN and GIN simply use the aggragation of the neighboring node features, losing the graph-level substructure infomation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">PARAMETER ANALYSIS</head><p>To further study the proposed method, we will discuss the effects of different kernel size and channel number in ISONN. The model convergence analysis will be provided in appendix.</p><p>• Kernel Size: We show the effectiveness of different k in <ref type="figure">Figure 3</ref>. Based on the previous statement, parameter k can affect the final results since it controls the size of learned subgraph templates. To investigate the best kernel size for each dataset, we fix the channel number c = 1. As <ref type="figure">Figure 3</ref> shows, different datasets have different appropriate kernel sizes. The best kernel sizes are 2, 4, 3, 4, 4 for the three datasets respectively. • Channel Number: We also study the effectiveness of multiple channels (i.e., multiple templates in one layer). To discuss how the channel number influences the results, we choose the best kernel size for each dataset (i.e., 2, 4, 3, 4, 4 respectively). From all subfigures in <ref type="figure">Figure 4</ref>, we can see that the differences among the different channel numbers by using only one isomorphic layer. As shown in <ref type="figure">Figure 4</ref>, ISONN achieves the best results by c = 3, 2, 1, 1, 2, respectively, which means the increase of the channel number can improve the performance, but more channels do not necessarily lead to better results. The reason could be the more templates we use, the more complex our model would be. With such a complex model, it is easy to learn an overfitting model on train data, especially when the dataset is quite small. Thus, increasing the channel number can improve the performance but the effectiveness will still depend on the quality and the quantity of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">TIME COMPLEXITY STUDY</head><p>To study the efficiency of ISONN and ISONN-fast, we collect the actual running time on training model, which is shown in <ref type="figure" target="#fig_17">Figure 5</ref>. In both Figures 5(a) and 5(b) 2 , the x-axis denotes its value for k or c and the y-axis denotes the time cost with different parameters. From <ref type="figure" target="#fig_17">Figure 5</ref> show the same pattern. When the k increases, the time cost grows exponentially. This pattern can be directly explained by the size of the permutation matrix set. When we increase the kernel size by one, the number of corresponding permutation matrices grows exponentially. While changing c, shown in <ref type="figure" target="#fig_17">Figure 5</ref>(b), it is easy to observe that those curves are basically linear with different slopes. This is also natural since whenever we add one channel, we only need to add a constant number of the permutation matrices. To study the efficiency of ISONN-fast, <ref type="figure" target="#fig_17">Figure 5</ref>(c) shows the running times of ISONN and ISONN-fast on MUTAG. As it shows, ISONN-fast use less time when the kernel size greater than 4, otherwise ISONN and ISONN will have little difference since the eigen decomposition has nearly the same time complexity as calculating all possible node permutaions. The results also verify the theoretical time complexity analysis in 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we proposed a novel graph neural network named ISONN to solve the graph classification problem. ISONN consists of two components: (1) isomorphic component, where a set of permutation matrices is used to break the randomness order posed by matrix representation for a bunch of templates and one min-pooling layer and one softmax layer are used to get the best isomorphic features, and (2) classification component, which contains three fully-connected layers. We further discuss the two efficient variants of ISONN to accelerate the model. Next, we perform the experiments on five real-world datasets. The experimental results show the proposed method outperforms all comparison methods, which demonstrates the superiority of our proposed method. The experimental analysis on time complexity illustrates the efficiency of the ISONN-fast. Before giving the proof of Theorem 1, we need to introduce Lemma 1 first.</p><p>LEMMA 1 If A and B are Hermitian matrices with eigenvalues α 1 ≥ α 2 ≥ · · · ≥ α k and β 1 ≥ β 2 ≥ · · · ≥ β k respectively, then ||A − B|| ≥ n i=1 (α i − β i ) 2 .</p><p>Based on Lemma 1, we can derive the proof of Theorem 1 as follows.</p><p>PROOF 1 From Lemma 1, Equation 9 holds for any orthogonal matrix R since the eigenvalues of RK i R are the same as those of K i .</p><formula xml:id="formula_22">||RK i R − M (s,t) || 2 ≥ n j=1 (α j − β j ) 2<label>(9)</label></formula><p>On the other hand, if we use P in 7, we have</p><formula xml:id="formula_23">||PK i P − M (s,t) || 2 = ||U M (s,t) SU Ki U Ki Λ Ki U Ki U Ki SU M (s,t) − U M (s,t) Λ M (s,t) U M (s,t) || 2 = ||U M (s,t) (SΛ Ki S − Λ M (s,t) )U M (s,t) || 2 = ||SΛ Ki S − Λ M (s,t) || 2 = ||Λ Ki − Λ M (s,t) || 2 = n j=1 (α j − β j ) 2<label>(</label></formula><p>10) where we use the equations that ||UX|| = ||UX || = ||X|| for any orthogonal matrix U and SΛ Ki S = S 2 Λ Ki = Λ Ki since S and Λ Ki are both orthogonal matrices and S 2 = I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">CONVERGENCE ANALYSIS</head><p>The <ref type="figure">Figure 6</ref> shows the convergence trend of ISONN on five datasets, where the x-axis denotes the epoch number and the y-axis is the training loss, respectively. From these sub-figures, we can know that the proposed method can achieve a stable optimal solution within 50 iterations except for MUTAG (it needs almost 130 epochs to converge), which also illustrates our method would converge relatively fast.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>P1&lt;</head><label></label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; P2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1 i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1 i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w Vt 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1 + t u X V 3 D r J K v I L U o I D f r 3 7 1 B g n L Y p S G C a p 1 1 3 N T E + R U G c 4 E T i u 9 T G N K 2 Z g O s W u p p D H q I J / f O y V n V h m Q K F G 2 p C F z 9 f d E T m O t J 3 F o O 2 N q R n r Z m 4 n / e d 3 M R N d B z m W a G Z R s s S j K B D E J m T 1 P B l w h M 2 J i C W W K 2 1 s J G 1 F F m b E R V W w I 3 v L L q 6 R 1 U f f c u n d / W W v c F H G U 4 Q R O 4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; P2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1 i N O E + x E d K h E K R t F K n V 4 Q Z o 1 Z v 9 Y v V 9 y q u w B Z J 1 5 O K p C j 0 S 9 / 9 Q Y x S y O u k E l q T N d z E / Q z q l E w y W e l X m p 4 Q t m Y D n n X U k U j b v x s c e + M X F h l Q M J Y 2 1 J I F u r v i Y x G x k y j w H Z G F E d m 1 Z u L / 3 n d F M M b P x M q S Z E r t l w U p p J g T O b P k 4 H Q n K G c W k K Z F v Z W w k Z U U 4 Y 2 o p I N w V t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; P1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O J U O 7 d k 7 A B Z e Q r r K 9 f r F y f F m 7 m M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c I 9 g P a U D b b S b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 S R T D J s s E Y n q h F S j 4 B K b h h u B n V Q h j U O B 7 X B 8 O / P b T 6 g 0 T + S D m a Q Y x H Q o e c Q Z N V b q 9 M I o 9 6 d 9 r 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>4 R w 8 u I I G 3 I E P T W A g 4 B l e 4 c 1 5 d F 6 c d + d j 0 V p y i p l j + A P n 8 w f D / Y / G &lt; / l a t e x i t &gt; P2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 P G m 3 j Q + Z w a M w L G w v H x J a e p E Q T M = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p Z p P u T o Q S + i e 8 e F D E q 3 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W N z a 3 t n e J u a W / / 4 P C o f H z S M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M 7 + Z + + 4 l r I 2 L 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>t 9 e Z 2 0 a l X P r X o P V 5 X 6 b R 5 H E c 7 g H C 7 B g 2 u o w z 0 0 o A k M J D z D K 7 w 5 E + f F e X c + l q 0 F J 5 8 5 h T 9 w P n 8 A x Y G P x w = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " 7 p S b 5 D J D 4 r 0 l A D i g P K U O b e U R r 0 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 1 :</head><label>1</label><figDesc>0 a a u m i n B X f 3 y O u m 3 W 6 7 T c u / a j c 5 1 W U c V T u E M L s C F S + j A L X S h B w S e 4 B l e 4 c 3 K r R f r 3 f p Y j l a s c u c E / s D 6 / A E X k p R 1 &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 3 z H k 9 E z c T N q 3 p P P D L H B 2 g 1 d O J g = " &gt; A A A B + 3 i c b V A 9 T 8 M w F H w p X 6 V 8 h T K y W L R I T F X S B c Y K F s Y i 0 R a p i S r H d V q r j h P Z D q K K 8 l d Y G E C I l T / C x r / B a T N A y 0 m W T n f v 6 Z 0 v S D h T 2 n G + r c r G 5 t b 2 T n W 3 t r d / c H h k H 9 f 7 K k 4 l o T 0 S 8 1 g + B F h R z g T t a a Y 5 f U g k x V H A 6 S C Y 3 R T + 4 J F K x W J x r + c J 9 S M 8 E S x k B G s j j e x 6 0 5 t i n X k R 1 t M g z O Z 5 3 h z Z D a f l L I D W i V u S B p T o j u w v b x y T N K J C E 4 6 V G r p O o v 0 M S 8 0 I p 3 n N S x V N M J n h C R 0 a K n B E l Z 8 t s u f o 3 C h j F M b S P K H R Q v 2 9 k e F I q X k U m M k i o 1 r 1 C v E / b 5 j q 8 M r P m E h S T Q V Z H g p T j n S M i i L Q m E l K N J 8 b g o l k J i s i U y w x 0 a a u m i n B X f 3 y O u m 3 W 6 7 T c u / a j c 5 1 W U c V T u E M L s C F S + j A L X S h B w S e 4 B l e 4 c 3 K r R f r 3 f p Y j l a s c u c E / s D 6 / A E X k p R 1 &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 3 z H k 9 E z c T N q 3 p P P D L H B 2 g 1 d O J g = " &gt; A A A B + 3 i c b V A 9 T 8 M w F H w p X 6 V 8 h T K y W L R I T F X S B c Y K F s Y i 0 R a p i S r H d V q r j h P Z D q K K 8 l d Y G E C I l T / C x r / B a T N A y 0 m W T n f v 6 Z 0 v S D h T 2 n G + r c r G 5 t b 2 T n W 3 t r d / c H h k H 9 f 7 K k 4 l o T 0 S 8 1 g + B F h R z g T t a a Y 5 f U g k x V H A 6 S C Y 3 R T + 4 J F K x W J x r + c J 9 S M 8 E S x k B G s j j e x 6 0 5 t i n X k R 1 t M g z O Z 5 3 h z Z D a f l L I D W i V u S B p T o j u w v b x y T N K J C E 4 6 V G r p O o v 0 M S 8 0 I p 3 n N S x V N M J n h C R 0 a K n B E l Z 8 t s u f o 3 C h j F M b S P K H R Q v 2 9 k e F I q X k U m M k i o 1 r 1 C v E / b 5 j q 8 M r P m E h S T Q V Z H g p T j n S M i i L Q m E l K N J 8 b g o l k J i s i U y w x 0 a a u m i n B X f 3 y O u m 3 W 6 7 T c u / a j c 5 1 W U c V T u E M L s C F S + j A L X S h B w S e 4 B l e 4 c 3 K r R f r 3 f p Y j l a s c u c E / s D 6 / A E X k p R 1 &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S 3 z H k 9 E z c T N q 3 p P P D L H B 2 g 1 d O J g = " &gt; A A A B + 3 i c b V A 9 T 8 M w F H w p X 6 V 8 h T K y W L R I T F X S B c Y K F s Y i 0 R a p i S r H d V q r j h P Z D q K K 8 l d Y G E C I l T / C x r / B a T N A y 0 m W T n f v 6 Z 0 v S D h T 2 n G + r c r G 5 t b 2 T n W 3 t r d / c H h k H 9 f 7 K k 4 l o T 0 S 8 1 g + B F h R z g T t a a Y 5 f U g k x V H A 6 S C Y 3 R T + 4 J F K x W J x r + c J 9 S M 8 E S x k B G s j j e x 6 0 5 t i n X k R 1 t M g z O Z 5 3 h z Z D a f l L I D W i V u S B p T o j u w v b x y T N K J C E 4 6 V G r p O o v 0 M S 8 0 I p 3 n N S x V N M J n h C R 0 a K n B E l Z 8 t s u f o 3 C h j F M b S P K H R Q v 2 9 k e F I q X k U m M k i o 1 r 1 C v E / b 5 j q 8 M r P m E h S T Q V Z H g p T j n S M i i L Q m E l K N J 8 b g o l k J i s i U y w x 0 a a u m i n B X f 3 y O u m 3 W 6 7 T c u / a j c 5 1 W U c V T u E M L s C F S + j A L X S h B w S e 4 B l e 4 c 3 K r R f r 3 f p Y j l a s c u c E / s D 6 / A E X k p R 1 &lt; / l a t e x i t &gt;K1&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q W n 0 y h z f 6 4 A F W S / H + Y Y y h i e 4 + V Y = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 2 8 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 Y k E V Q a w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s l V h Q 7 a f z 1 D N 0 Z p U h C i N l n z R o r v 7 e S L H Q e i o C O 5 m F 1 M t e J v 7 n 9 R I T X v o p k 3 F i q C S L Q 2 H C k Y l Q V g E a M k W J 4 V N L M F H M Z k V k j B U m x h Z V s i V 4 y 1 9 e J e 1 6 z X N r 3 l 2 9 0 r j K 6 y j C C Z z C O X h w A Q 2 4 g S a 0 g I C C Z 3 i F N + f J e X H e n Y / F a M H J d 4 7 h D 5 z P H 6 K Q k e 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q W n 0 y h z f 6 4 A F W S / H + Y Y y h i e 4 + V Y = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 2 8 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 Y k E V Q a w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s l V h Q 7 a f z 1 D N 0 Z p U h C i N l n z R o r v 7 e S L H Q e i o C O 5 m F 1 M t e J v 7 n 9 R I T X v o p k 3 F i q C S L Q 2 H C k Y l Q V g E a M k W J 4 V N L M F H M Z k V k j B U m x h Z V s i V 4 y 1 9 e J e 1 6 z X N r 3 l 2 9 0 r j K 6 y j C C Z z C O X h w A Q 2 4 g S a 0 g I C C Z 3 i F N + f J e X H e n Y / F a M H J d 4 7 h D 5 z P H 6 K Q k e 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q W n 0 y h z f 6 4 A FW S / H + Y Y y h i e 4 + V Y = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g ya a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 2 8 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 Y k E V Q a w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s l V h Q 7 a f z 1 D N 0 Z p U h C i N l n z R o r v 7 e S L H Q e i o C O 5 m F 1 M t e J v 7 n 9 R I T X v o p k 3 F i q C S L Q 2 H C k Y l Q V g E a M k W J 4 V N L M F H M Z k V k j B U m x h Z V s i V 4 y 1 9 e J e 1 6 z X N r 3 l 2 9 0 r j K 6 y j C C Z z C O X h w A Q 2 4 g S a 0 g I C C Z 3 i F N + f J e X H e n Y / F a M H J d 4 7 h D 5 z P H 6 K Q k e 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q W n 0 y h z f 6 4 A F W S / H + Y Y y h i e 4 + V Y = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 2 8 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 Y k E V Q a w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s l V h Q 7 a f z 1 D N 0 Z p U h C i N l n z R o r v 7 e S L H Q e i o C O 5 m F 1 M t e J v 7 n 9 R I T X v o p k 3 F i q C S L Q 2 H C k Y l Q V g E a M k W J 4 V N L M F H M Z k V k j B U m x h Z V s i V 4 y 1 9 e J e 1 6 z X N r 3 l 2 9 0 r j K 6 y j C C Z z C O X h w A Q 2 4 g S a 0 g I C C Z 3 i F N + f J e X H e n Y / F a M H J d 4 7 h D 5 z P H 6 K Q k e 0 = &lt; / l a t e x i t &gt; K2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P c Y M y N B Z r m P W Y e 8 y v o K + 9 z p N z 5 U = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N z S R D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b S 0 T R W i L S C 5 V N 8 C a c i Z o y z D D a T d W F E c B p 5 1 g c p 3 5 n U e q N J P i 3 k x j 6 k d 4 J F j I C D Z W e q j 2 I 2 z G Q Z j e z g b 1 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 q S R F Q Y w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s F T i i 2 k / n q W f o z C p D F E p l n z B o r v 7 e S H G k 9 T Q K 7 G Q W U i 9 7 m f i f 1 0 t M e O m n T M S J o Y I s D o U J R 0 a i r A I 0Z I o S w 6 e W Y K K Y z Y r I G C t M j C 2 q Z E v w l r + 8 S t r 1 m u f W v L t 6 p X G V 1 1 G E E z i F c / D g A h p w A 0 1 o A Q E F z / A K b 8 6 T 8 + K 8 O x + L 0 Y K T 7 x z D H z i f P 6 Q V k e 4 = &lt;/ l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P c Y M y N B Z r m P W Y e 8 y v o K + 9 z p N z 5U = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N z S R D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b S 0 T R W i L S C 5 V N 8 C a c i Z o y z D D a T d W F E c B p 5 1 g c p 3 5 n U e q N J P i 3 k x j 6 k d 4 J F j I C D Z W e q j 2 I 2 z G Q Z j e z g b 1 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 q S R F Q Y w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s F T i i 2 k / n q W f o z C p D F E p l n z B o r v 7 e S H G k 9 T Q K 7 G Q W U i 9 7 m f i f 1 0 t M e O m n T M S J o Y I s D o U J R 0 a i r A I 0 Z I o S w 6 e W Y K K Y z Y r I G C t M j C 2 q Z E v w l r + 8 S t r 1 m u f W v L t 6 p X G V 1 1 G E E z i F c / D g A h p w A 0 1 o A Q E F z / A K b 8 6 T 8 + K 8 O x + L 0 Y K T 7 x z D H z i f P 6 Q V k e 4 = &lt;/ l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P c Y M y N B Z r m P W Y e 8 y v o K + 9 z p N z 5U = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N z S R D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b S 0 T R W i L S C 5 V N 8 C a c i Z o y z D D a T d W F E c B p 5 1 g c p 3 5 n U e q N J P i 3 k x j 6 k d 4 J F j I C D Z W e q j 2 I 2 z G Q Z j e z g b 1 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 q S R F Q Y w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s F T i i 2 k / n q W f o z C p D F E p l n z B o r v 7 e S H G k 9 T Q K 7 G Q W U i 9 7 m f i f 1 0 t M e O m n T M S J o Y I s D o U J R 0 a i r A I 0 Z I o S w 6 e W Y K K Y z Y r I G C t M j C 2 q Z E v w l r + 8 S t r 1 m u f W v L t 6 p X G V 1 1 G E E z i F c / D g A h p w A 0 1 o A Q E F z / A K b 8 6 T 8 + K 8 O x + L 0 Y K T 7 x z D H z i f P 6 Q V k e 4 = &lt;/ l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P c Y M y N B Z r m P W Y e 8 y v o K + 9 z p N z 5U = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N z S R D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b S 0 T R W i L S C 5 V N 8 C a c i Z o y z D D a T d W F E c B p 5 1 g c p 3 5 n U e q N J P i 3 k x j 6 k d 4 J F j I C D Z W e q j 2 I 2 z G Q Z j e z g b 1 6 q B c c W v u H G i V e D m p Q I 7 m o P z V H 0 q S R F Q Y w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s F T i i 2 k / n q W f o z C p D F E p l n z B o r v 7 e S H G k 9 T Q K 7 G Q W U i 9 7 m f i f 1 0 t M e O m n T M S J o Y I s D o U J R 0 a i r A I 0 Z I o S w 6 e W Y K K Y z Y r I G C t M j C 2 q Z E v w l r + 8 S t r 1 m u f W v L t 6 p X G V 1 1 G E E z i F c / D g A h p w A 0 1 o A Q E F z / A K b 8 6 T 8 + K 8 O x + L 0 Y K T 7 x z D H z i f P 6 Q V k e 4 = &lt; / l a t e x i t &gt;Kc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L m 9 5 Z 0 c n a n f qS z L b H 3 H h h l Y o / x M = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 1 I d V C u u D V 3 D r R K v J x U I E d z U P 7 q D y O S C C o N 4 V j r n u f G x k + x M o x w O i v 1 E 0 1 j T C Z 4 R H u W S i y o 9 t N 5 6 h k 6 s 8 o Q h Z G y T x o 0 V 3 9 v p F h o P R W B n c x C 6 m U v E / / z e o k J L / 2 U y T g x V J L F o T D h y E Q o q w A Nm a L E 8 K k l m C h m s y I y x g o T Y 4 s q 2 R K 8 5 S + v k n a 9 5 r k 1 7 6 5 e a V z l d R T h B E 7 h H D y 4 g A b c Q B N a Q E D B M 7 z C m / P k v D j v z s d i t O D k O 8 f w B 8 7 n D + 6 K k h 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L m 9 5 Z 0 c n a n f qS z L b H 3 H h h l Y o / x M = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 1 I d V C u u D V 3 D r R K v J x U I E d z U P 7 q D y O S C C o N 4 V j r n u f G x k + x M o x w O i v 1 E 0 1 j T C Z 4 R H u W S i y o 9 t N 5 6 h k 6 s 8 o Q h Z G y T x o 0 V 3 9 v p F h o P R W B n c x C 6 m U v E / / z e o k J L / 2 U y T g x V J L F o T D h y E Q o q w A Nm a L E 8 K k l m C h m s y I y x g o T Y 4 s q 2 R K 8 5 S + v k n a 9 5 r k 1 7 6 5 e a V z l d R T h B E 7 h H D y 4 g A b c Q B N a Q E D B M 7 z C m / P k v D j v z s d i t O D k O 8 f w B 8 7 n D + 6 K k h 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L m 9 5 Z 0 c n a n f q S z L b H 3 H h h l Y o / x M = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 1 I d V C u u D V 3 D r R K v J x U I E d z U P 7 q D y O S C C o N 4 V j r n u f G x k + x M o x w O i v 1 E 0 1 j T C Z 4 R H u W S i y o 9 t N 5 6 h k 6 s 8 o Q h Z G y T x o 0 V 3 9 v p F h o P R W B n c x C 6 m U v E / / z e o k J L / 2 U y T g x V J L F o T D h y E Q o q w A N m a L E 8 K k l m C h m s y I y x g o T Y 4 s q 2 R K 8 5 S + v k n a 9 5 r k 1 7 6 5 e a V z l d R T h B E 7 h H D y 4 g A b c Q B N a Q E D B M 7 z C m / P k v D j v z s d i t O D k O 8 f w B 8 7 n D + 6 K k h 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L m 9 5 Z 0 c n a n f q S z L b H 3 H h h l Y o / x M = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B F v B V Z n p R p d F N 4 K b C v Y B 7 V g y a a Y N T T J D k l H K 0 P 9 w 4 0 I R t / 6 L O / / G T D s L b T 0 Q O J x z L / f k B D F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d x 6 p 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a H a F 9 i M g z C 9 n Q 1 I d V C u u D V 3 D r R K v J x U I E d z U P 7 q D y O S C C o N 4 V j r n u f G x k + x M o x w O i v 1 E 0 1 j T C Z 4 R H u W S i y o 9 t N 5 6 h k 6 s 8 o Q h Z G y T x o 0 V 3 9 v p F h o P R W B n c x C 6 m U v E / / z e o k J L / 2 U y T g x V J L F o T D h y E Q o q w A N m a L E 8 K k l m C h m s y I y x g o T Y 4 s q 2 R K 8 5 S + v k n a 9 5 r k 1 7 6 5 e a V z l d R T h B E 7 h H D y 4 g A b c Q B N a Q E D B M 7 z C m / P k v D j v z s d i t O D k O 8 f w B 8 7 n D + 6 K k h 8 = &lt; / l a t e x i t &gt; Pk! &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; Pk! &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; Pk! &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 9 G 3 N C B 7 y p I r T U b g V b o X 9 z Y / I b I = " &gt; A A A B + n i c b V C 7 T s M w F L 3 h W c o r h Z H F 0 C I x V U k X G C t Y G I t E H 1 I b R Y 7 r t F Y d J 7 I d U B X 6 K S w M I M T K l 7 D x N z h t B m g 5 k q W j c + 7 V P T 5 B w p n S j v N t r a 1 v b G 5 t l 3 b K u 3 v 7 B 4 d 2 5 a i j 4 l Q S 2 i Y x j 2 U v w I p y J m h b M 8 1 p L 5 E U R w G n 3 W B y k / v d B y o V i 8 W 9 n i b U i / B I s J A R r I 3 k 2 5 X a I M J 6 H I R Z a + Z n k 9 N Z z b e r T t 2 Z A 6 0 S t y B V K N D y 7 a / B M C Z p R I U m H C v V d 5 1 E e x m W m h F O Z + V B q m i C y Q S P a N 9 Q g S O q v G w e f Y b O j T J E Y S z N E x r N 1 d 8 b G Y 6 U m k a B m c x z q m U v F / / z + q k O r 7 y M i S T V V J D F o T D l S M c o 7 w E N m a R E 8 6 k h m E h m s i I y x h I T b d o q m x L c 5 S + v k k 6 j 7 j p 1 9 6 5 R b V 4 X d Z T g B M 7 g A l y 4 h C b c Q g v a Q O A R n u E V 3 q w n 6 8 V 6 t z 4 W o 2 t W s X M M f 2 B 9 / g C k q p O U &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " / V t + 0 R d S S 5 A / s b V i R u a b h 3 H o i B U = " &gt; A A A B 6 n i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s a L Y k W W m I U J I E L 2 V v m Y M P e 3 m V 3 z 4 R c + A k 2 F h p j 6 y + y 8 9 + 4 w B U K v m S S l / d m M j M v S A T X x n W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q 6 z h V D F s s F r H q B F S j 4 B J b h h u B n U Q h j Q K B j 8 H 4 e u Y / P q H S P J Y P Z p K g H 9 G h 5 C F n 1 F j p v n p T 7 Z c r b s 2 d g 6 w S L y c V y N H s l 7 9 6 g 5 i l E U r D B N W 6 6 7 m J 8 T O q D G c C p 6 V e q j G h b E y H 2 L V U 0 g i 1 n 8 1 P n Z I z q w x I G C t b 0 p C 5 + n s i o 5 H W k y i w n R E 1 I 7 3 s z c T / v G 5 q w k s / 4 z J J D U q 2 W B S m g p i Y z P 4 m A 6 6 Q G T G x h D L F 7 a 2 E j a i i z N h 0 S j Y E b / n l V d K u 1 z y 3 5 t 3 V K 4 2 r P I 4 i n M A p n I M H F 9 C A W 2 h C C x g M 4 R l e 4 c 0 R z o v z 7 n w s W g t O P n M M f + B 8 / g B S 3 Y 0 l &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / V t + 0 R d S S 5 A / s b V i R u a b h 3 H o i B U = " &gt; A A A B 6 n i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s a L Y k W W m I U J I E L 2 V v m Y M P e 3 m V 3 z 4 R c + A k 2 F h p j 6 y + y 8 9 + 4 w B U K v m S S l / d m M j M v S A T X x n W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q 6 z h V D F s s F r H q B F S j 4 B J b h h u B n U Q h j Q K B j 8 H 4 e u Y / P q H S P J Y P Z p K g H 9 G h 5 C F n 1 F j p v n p T 7 Z c r b s 2 d g 6 w S L y c V y N H s l 7 9 6 g 5 i l E U r D B N W 6 6 7 m J 8 T O q D G c C p 6 V e q j G h b E y H 2 L V U 0 g i 1 n 8 1 P n Z I z q w x I G C t b 0 p C 5 + n s i o 5 H W k y i w n R E 1 I 7 3 s z c T / v G 5 q w k s / 4 z J J D U q 2 W B S m g p i Y z P 4 m A 6 6 Q G T G x h D L F 7 a 2 E j a i i z N h 0 S j Y E b / n l V d K u 1 z y 3 5 t 3 V K 4 2 r P I 4 i n M A p n I M H F 9 C A W 2 h C C x g M 4 R l e 4 c 0 R z o v z 7 n w s W g t O P n M M f + B 8 / g B S 3 Y 0 l &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / V t + 0 R d S S 5 A / s b V i R u a b h 3 H o i B U = " &gt; A A A B 6 n i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s a L Y k W W m I U J I E L 2 V v m Y M P e 3 m V 3 z 4 R c + A k 2 F h p j 6 y + y 8 9 + 4 w B U K v m S S l / d m M j M v S A T X x n W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q 6 z h V D F s s F r H q B F S j 4 B J b h h u B n U Q h j Q K B j 8 H 4 e u Y / P q H S P J Y P Z p K g H 9 G h 5 C F n 1 F j p v n p T 7 Z c r b s 2 d g 6 w S L y c V y N H s l 7 9 6 g 5 i l E U r D B N W 6 6 7 m J 8 T O q D G c C p 6 V e q j G h b E y H 2 L V U 0 g i 1 n 8 1 P n Z I z q w x I G C t b 0 p C 5 + n s i o 5 H W k y i w n R E 1 I 7 3 s z c T / v G 5 q w k s / 4 z J J D U q 2 W B S m g p i Y z P 4 m A 6 6 Q G T G x h D L F 7 a 2 E j a i i z N h 0 S j Y E b / n l V d K u 1 z y 3 5 t 3 V K 4 2 r P I 4 i n M A p n I M H F 9 C A W 2 h C C x g M 4 R l e 4 c 0 R z o v z 7 n w s W g t O P n M M f + B 8 / g B S 3 Y 0 l &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / V t + 0 R d S S 5 A / s b V i R u a b h 3 H o i B U = " &gt; A A A B 6 n i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s a L Y k W W m I U J I E L 2 V v m Y M P e 3 m V 3 z 4 R c + A k 2 F h p j 6 y + y 8 9 + 4 w B U K v m S S l / d m M j M v S A T X x n W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q 6 z h V D F s s F r H q B F S j 4 B J b h h u B n U Q h j Q K B j 8 H 4 e u Y / P q H S P J Y P Z p K g H 9 G h 5 C F n 1 F j p v n p T 7 Z c r b s 2 d g 6 w S L y c V y N H s l 7 9 6 g 5 i l E U r D B N W 6 6 7 m J 8 T O q D G c C p 6 V e q j G h b E y H 2 L V U 0 g i 1 n 8 1 P n Z I z q w x I G C t b 0 p C 5 + n s i o 5 H W k y i w n R E 1 I 7 3 s z c T / v G 5 q w k s / 4 z J J D U q 2 W B S m g p i Y z P 4 m A 6 6 Q G T G x h D L F 7 a 2 E j a i i z N h 0 S j Y E b / n l V d K u 1 z y 3 5 t 3 V K 4 2 r P I 4 i n M A p n I M H F 9 C A W 2 h C C x g M 4 R l e 4 c 0 R z o v z 7 n w s W g t O P n M M f + B 8 / g B S 3 Y 0 l &lt; / l a t e x i t &gt; IsoNN Framework Architecture. (The left subplot provides the outline of the proposed framework, including the graph isomorphic feature extraction component and the classification component respectively. Meanwhile, the right subplot illustrates the detailed architecture of the proposed framework, where the graph isomorphic features are extracted with the graph isomorphic layer, min-pooling layer and softmax layer, and the graphs are further classified with three fullyconnected layers.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 2 :</head><label>2</label><figDesc>An Illustration of Deep Architecture of ISONN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>HIV-fMRI Cao et al. (2015a), HIV-DTI Cao et al. (2015a), BP-fMRI Cao et al. (2015b), MUTAG 1 and PTC 1 . Both HIV-fMRI and HIV-DTI have 56 positive instances and 21 negative instances. Also, graph instances in both of them are represented as 90 × 90 matrices Cao et al. (2015a). BP-fMRI has 52 positive and 45 negative instances and each instance is presented by an 82 × 82 matrix Cao et al. (2015b). MUTAG and PTC are two datasets which have been widely used in academia Xu et al. (2018); Shervashidze</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 5 :</head><label>5</label><figDesc>Time Complexity Study</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Figure 6: Convergence Analysis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). 1 arXiv:1907.09495v2 [cs.LG] 28 Sep 2019</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Classification Results of the Comparison Methods. Methods Dataset Metric Freq AE CNN SDBN WL GCN GIN ISONN-fast ISONN</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Since the PTC is a relative large dataset compared with the others, its running time is in different scale compared with the other datasets, which makes the time growth curve of other datasets not obvious. Thus, we don't show the results on PTC.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">can be used to do graph classification with node features. We adopt the same experimental setting as GIN-0</title>
	</analytic>
	<monogr>
		<title level="m">GIN is proposed in Xu et</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>stated in Xu et al.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">We select top-100 features for Freq as stated in Wang et al. (2017) with a three layer MLP classifier, where the neuron numbers are 1024, 128, 2. For Autoencoder, we apply the two-layer encoder and two-layer decoder. For the CNN, we apply the one convolutional layer with the size 5 × 5 × 50, a max-pooling layer with kernel size 2 × 2, one gating relu layer as activation layer and we set parameters in the classification module the same as Freq classifier. For the SDBN, we set the architecture as follows: we use two layers of &quot;convolution layer + max pooling layer + activation layer &quot; and concatenate a fully connected layer with 100 neurons as well as an activation layer, where the parameters are the same as those in CNN. We also set the dropout rate in SDBN being 0.5 to avoid overfitting. For WL kernel, if the average similarity score for one test</title>
	</analytic>
	<monogr>
		<title level="m">EXPERIMENTAL SETUP AND EVALUATION METRICS In our experiments, to make the results more reliable, we partition the datasets into 3 folds and then set the ratio of train/test according to 2 : 1, where two folds are treated as the training data and the remaining one is the testing data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>graph greater than 0.5, we assign the test graph positive label, otherwise, assign negative label. We follow the setting in Kipf &amp; Welling (2016) and Xu et al.. to do GCN and GIN-0</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">no node label information) for GCN and GIN. In the experiments, we set the kernel size k in the isomorphic layer for three datasets as 2, 4, 3, 4, 4 respectively, and then set the parameters in classification component the same as those in Freq classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Here</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">we will use the adjacency matrices as features (i.e</title>
		<imprint/>
	</monogr>
	<note>In this experiment, we adopt Adam optimizer and the set the learning rate η = 0.001, and then we report the average results on balanced datasets</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">(k = 3, c = 1), (k = 4, c = 1) and (k = 4, c = 2) for the HIV-DTI, BP-fMRI, MUTAG and PTC, respectively. The results are shown in Table 1. From that table, we can observe that ISONN outperforms all other baseline methods on these all datasets. We need to remark that ISONN and ISONN-fast are very close on MUTAG, and ISONN has the best performance in total on PTC. Compared with Freq, the proposed method achieves a better performance without searching for all possible subgraphs manually. AE has almost the worst performance among all comparison methods. This is because the features learned from AE do not contain any structural information. For HIV-DTI, AE gets 0 in F1. This is because the dataset contains too many zeros, which makes the AE learns trivial features. Also, for PTC, its F1 is higher than other models, but the accuracy only get 50.0, which indicates AE actually have a bad performance since it cannot discriminate the classes of the instances (i.e., predicting all positive classes). CNN performs better than AE but still worse than ISONN. The reason can be that it learns some structural information but fails to learn representative structural patterns. SDBN is designed for brain images, so it may not work for MUTAG and PTC. One possible reason for WL got bad results is the isomorphism test is done on the whole graph, which may lead to erratic results</title>
	</analytic>
	<monogr>
		<title level="m">2 EXPERIMENTAL RESULTS In this section, we investigate the effectiveness of the learned subgraph-based graph feature representations for graphs. We adopt one isomorphic layer where the kernel size k = 2 and channel number c = 3 for HIV-fMRI, one isomorphic layer with (k = 4, c = 2)</title>
		<editor>GCN REFERENCES Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, and Alexander A Alemi</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9180" to="9190" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Diffusion-convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Towsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Convolutional set matching for graph similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.10866</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational inductive biases, deep learning, and graph networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying hiv-induced subgraph patterns in brain networks with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bokai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><forename type="middle">B</forename><surname>Ragin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="223" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identification of discriminative subgraph patterns in fmri brain networks in bipolar affective disorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bokai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Liang Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><forename type="middle">L</forename><surname>Vizueta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">D</forename><surname>Altshuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Brain Informatics and Health</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Grami: Frequent subgraph and pattern mining in a single large graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Elseidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehab</forename><surname>Abdelhamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spiros</forename><surname>Skiadopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panos</forename><surname>Kalnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="517" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Identifying human mobility via trajectory embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goce</forename><surname>Trajcevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xucheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengli</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conferences on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1689" to="1695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An iterative mapreduce approach to frequent subgraph mining in biological datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bismita</forename><surname>Srichandan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajshekhar</forename><surname>Sunderraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Bioinformatics</title>
		<meeting>the ACM Conference on Bioinformatics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="661" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph classification based on pattern co-occurrence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Calvin</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semi-supervised feature selection for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="793" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative feature selection for uncertain graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><forename type="middle">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ragin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 SIAM International Conference on Data Mining</title>
		<meeting>the 2013 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="82" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Prune: Preserving proximity and global ranking for network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-An</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Chi</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Hao Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi-Yen</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shou-De</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5257" to="5266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graph classification using structural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John Boaz</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1666" to="1674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-scale frequent subgraph mining in mapreduce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqing</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ghinita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 30th International Conference on Data Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="844" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-ninth AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Geodesic convolutional neural networks on riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision workshops</title>
		<meeting>the IEEE international conference on computer vision workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5115" to="5124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Grasping frequent subgraph mining for bioinformatics applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Mrzic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Meysman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wout</forename><surname>Bittremieux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Moris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Cule</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Goethals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Laukens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioData mining</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annamalai</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahinthan</forename><surname>Chandramohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajasekar</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shantanu</forename><surname>Jaiswal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05005</idno>
		<title level="m">Learning distributed representations of graphs</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A parallel approach for frequent subgraph mining in a single large graph using spark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengcai</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyun</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">230</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">gboost: a mathematical programming approach to graph classification and regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroto</forename><surname>Saigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadashi</forename><surname>Kadowaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koji</forename><surname>Tsuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="69" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast subtree kernels on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1660" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Near-optimal supervised feature selection among frequent subgraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marisa</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 SIAM International Conference on Data Mining</title>
		<meeting>the 2009 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1076" to="1087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonlinear graph fusion for multi-modal classification of alzheimers disease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinquan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Machine Learning in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Alzheimer&apos;s Disease Neuroimaging Initiative, et al. Multi-modal classification of alzheimer&apos;s disease using nonlinear graph fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinquan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="171" to="181" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Structural deep brain network mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bokai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Ta</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><forename type="middle">B</forename><surname>Ragin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="475" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Boosting for multi-graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingquan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="416" to="429" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
		<title level="m">How powerful are graph neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">gspan: Graph-based substructure pattern mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="721" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An end-to-end deep learning architecture for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
