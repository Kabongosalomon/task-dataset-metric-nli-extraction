<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2020 RACT: TOWARDS AMORTIZED RANKING-CRITICAL TRAINING FOR COLLABORATIVE FILTERING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Lobel</surname></persName>
							<email>samuel_lobel@brown.educhunyl@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Duke University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2020 RACT: TOWARDS AMORTIZED RANKING-CRITICAL TRAINING FOR COLLABORATIVE FILTERING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We investigate new methods for training collaborative filtering models based on actor-critic reinforcement learning, to more directly maximize ranking-based objective functions. Specifically, we train a critic network to approximate ranking-based metrics, and then update the actor network to directly optimize against the learned metrics. In contrast to traditional learning-to-rank methods that require re-running the optimization procedure for new lists, our critic-based method amortizes the scoring process with a neural network, and can directly provide the (approximate) ranking scores for new lists. We demonstrate the actor-critic's ability to significantly improve the performance of a variety of prediction models, and achieve better or comparable performance to a variety of strong baselines on three large-scale datasets.</p><p>Published as a conference paper at ICLR 2020 engineering sufficient statistics for efficient critic learning. Experimental results on three large-scale datasets demonstrate the actor-critic's ability to significantly improve the performance of a variety of latent-variable models, and achieve better or comparable performance to strong baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND: VAES FOR COLLABORATIVE FILTERING</head><p>Vectors are denoted as bold lower-case letters x, matrices as bold uppercase letters X, and scalars as lower-case non-bold letters x. We use • for function composition, for the element-wise multiplication, and | · | for cardinality of a set. δ(·) is the indicator function.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommender systems are an important means of improving a user's web experience. Collaborative filtering is a widely-applied technique in recommender systems <ref type="bibr" target="#b48">(Ricci et al., 2015)</ref>, in which patterns across similar users and items are leveraged to predict user preferences <ref type="bibr" target="#b54">(Su &amp; Khoshgoftaar, 2009</ref>). This naturally fits within the learning paradigm of latent variable models (LVMs) <ref type="bibr" target="#b2">(Bishop, 2006)</ref>, where latent representations capture the shared patterns. Due to their simplicity and effectiveness, LVMs are still a dominant approach. Traditional LVMs employ linear mappings of limited modeling capacity <ref type="bibr" target="#b40">(Paterek, 2007;</ref><ref type="bibr" target="#b35">Mnih &amp; Salakhutdinov, 2008)</ref>, and a growing body of literature involves applying deep neural networks (DNNs) to collaborative filtering to create more expressive models <ref type="bibr" target="#b60">Wu et al., 2016;</ref><ref type="bibr" target="#b30">Liang et al., 2018)</ref>. Among them, variational autoencoders (VAEs) <ref type="bibr" target="#b23">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b47">Rezende et al., 2014)</ref> have been proposed as non-linear extensions of LVMs <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>. Empirically, VAEs significantly outperform many competing LVMbased methods. One essential contribution to the improved performance is the use of the multinomial likelihood, which is argued by <ref type="bibr" target="#b30">Liang et al. (2018)</ref> to be a close proxy to ranking loss. This property is desirable, because in recommender systems we generally care more about the ranking of predictions than an individual item's score. Hence, prediction results are often evaluated using top-N ranking-based metrics, such as Normalized Discounted Cumulative Gain (NDCG) <ref type="bibr" target="#b20">(Järvelin &amp; Kekäläinen, 2002)</ref>. The VAE is trained to maximize the likelihood of observations; as shown below, this does not necessarily result in higher ranking-based scores. A natural question concerns whether one may directly optimize against ranking-based metrics, which are by nature non-differentiable and piecewise-constant. Previous work on learning-to-rank has been explored this question in the information-retrieval community, where relaxations/approximations of ranking loss are considered <ref type="bibr" target="#b56">(Weimer et al., 2008;</ref><ref type="bibr" target="#b32">Liu et al., 2009;</ref><ref type="bibr" target="#b27">Li, 2014;</ref><ref type="bibr" target="#b58">Weston et al., 2013)</ref>.</p><p>In this paper, we borrow the actor-critic idea from reinforcement learning (RL) <ref type="bibr" target="#b55">(Sutton et al., 1998)</ref> to propose an efficient and scalable learning-to-rank algorithm. The critic is trained to approximate the ranking metric, while the actor is trained to optimize against this learned metric. Specifically, with the goal of making the actor-critic approach practical for recommender systems, we introduce a novel feature-based critic architecture. Instead of treating raw predictions as the critic input, and hoping the neural network will discover the metric's structure from massive data, we consider We use n ∈ {1, . . . , N } to index users, and m ∈ {1, . . . , M } to index items. The user-item interaction matrix X ∈ {0, 1} N ×M collected from the users' implicit feedback is defined as:</p><p>x nm 1, if interaction of user n with item m is observed; 0, otherwise.</p><p>(1)</p><p>Note that x nm = 0 does not necessarily mean user n dislikes item m; they may simply be unaware of the item. Further, x nm = 1 is not equivalent to saying user n likes item m, but that there is at least interest.</p><p>VAE model VAEs have been investigated for collaborative filtering <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>, where this principled Bayesian approach is shown to achieve strong performance on large-scale datasets. Given the user's interaction history x = [x 1 , ..., x M ] ∈ {0, 1} M , our goal is to predict the full interaction behavior with all remaining items. To simulate this process during training, a random binary mask b ∈ {0, 1} M is introduced, with the entry 1 as un-masked, and 0 as masked. Thus, x h = x b is the user's partial interaction history. The goal becomes recovering the masked interactions: x p = x (1 − x h ), which is equivalent to recovering the full x as x h is known.</p><p>In LVMs, each user's binary interaction behavior is assumed to be controlled by a k-dimensional user-dependent latent representation z ∈ R K . When applying VAEs to collaborative filtering <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>, the user's latent feature z is represented as a distribution q(z|x), obtained from some partial history x h of x. With the assumption that q(z|x) follows a Gaussian form, the inference of z for the corresponding x is performed as:</p><formula xml:id="formula_0">q φ (z|x) = N (µ, diag(σ 2 )), with µ, σ 2 = f φ (x h ), x h = x b, b ∼ Ber(α),<label>(2)</label></formula><p>where α is the hyper-parameter of a Bernoulli distribution, f φ is a φ-parameterized neural network, which outputs the mean µ and variance σ 2 of the Gaussian distribution.</p><p>After obtaining a user's latent representation z, we use the generative process to make predictions. In <ref type="bibr" target="#b30">Liang et al. (2018)</ref> a multinomial distribution is used to model the likelihood of items. Specifically, to construct p θ (x|z), z is transformed to produce a probability distribution π over M items, from which the interaction vector x is assumed to have been drawn:</p><formula xml:id="formula_1">x ∼ Mult(π), with π = Softmax(g θ (z))<label>(3)</label></formula><p>where g θ is a θ-parameterized neural network. The output π is normalized via a softmax function to produce a probability vector π ∈ ∆ M −1 (an (M − 1)-simplex) over the entire item set.</p><p>Training Objective Learning VAE parameters {φ, θ} yields the following generalized objective:</p><formula xml:id="formula_2">L β (x; θ, φ) = L E +βL R , with L E = −E q φ (z|x) log p θ (x|z) and L R = KL(q φ (z|x)||p(z)) (4)</formula><p>where L E is the negative log likelihood (NLL) term, L R is the KL regularization term with standard normal prior p(z), and β is a weighting hyper-parameter. When β = 1, we can lower-bound the log marginal likelihood of the data using equation 4 as −L β=1 (x; θ, φ) ≤ log p(x). This is commonly known as the evidence lower bound (ELBO) in variational inference <ref type="bibr" target="#b3">(Blei et al., 2017)</ref>. Thus equation 4 is the negative β-regularized ELBO. To improve the optimization efficiency, the reparametrization trick <ref type="bibr" target="#b23">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b47">Rezende et al., 2014)</ref> is used to draw samples z ∼ q φ (z|x) to obtain an unbiased estimate of the ELBO, which is further optimized via stochastic optimization. We call this procedure maximum likelihood estimate (MLE)-based training, as it effectively maximizes the (regularized) ELBO. The testing stage of VAEs for collaborative filtering is detailed in Section A of the Supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Advantages of VAEs</head><p>The VAE framework successfully scales to relatively large datasets by making use of amortized inference <ref type="bibr" target="#b12">(Gershman &amp; Goodman, 2014)</ref>: the prediction for all users share the same procedure, which effectively requires evaluating two functions -the encoder f φ (·) and the decoder g θ (·). Crucially, as all users share the same encoder/decoder, the number of parameters required for an autoencoder is independent of the number of users. This is in contrast to some traditional latent factor collaborative filtering models <ref type="bibr" target="#b40">(Paterek, 2007;</ref><ref type="bibr" target="#b18">Hu et al., 2008;</ref><ref type="bibr" target="#b35">Mnih &amp; Salakhutdinov, 2008)</ref>, where a unique latent vector is learned for each user. The reuse of encoder/decoder for all users is well-aligned with collaborative filtering, where user preferences are analyzed by exploiting the similar patterns inferred from past experiences <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>. VAEs has the two advantages simultaneously: expressive representation power as a non-linear model, and the number of parameters being independent of the number of users. Pitfalls of VAEs Among various likelihood forms, it was argued in <ref type="bibr" target="#b30">Liang et al. (2018)</ref> that multinomial likelihoods are a closer proxy to the ranking loss than the traditional Gaussian or logistic likelihoods. Though simple and effective, the MLE procedure may still diverge with the ultimate goal in recommendation of correctly suggesting the top-ranked items. To illustrate the divergence between MLE-based training and ranking-based evaluation, consider the example in <ref type="figure">Figure 1</ref>. For the target x = {1, 1, 0, 0}, two different predictions A and B are provided. In MLE, the training loss is the multinomial NLL: −x log π, where π is the predicted probability. From the NLL point of view, B is a better prediction than A, because B shows a lower loss than A. However, B ranks an incorrect item highest, and therefore would return a worse recommendation than A. Fortunately, NDCG is calculated directly from the ranking, and so captures this dependence. This inspired us to directly use ranking-based evaluation metrics to guide training. For details on calculating NDCG, refer to Section E.2 of the Supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RANKING-CRITICAL TRAINING</head><p>We introduce a novel algorithm for recommender system training, which we call Ranking-Critical Training (RaCT). RaCT learns a differentiable approximation to the ranking metric, which the prediction network then leverages as a target for optimization through gradient ascent. This is in contrast to existing methods in collaborative filtering, which define an objective relaxation ahead of time. This methodology of learning approximations to functions which cannot be optimized directly stems from the actor-critic paradigm of RL, which we adapt for collaborative filtering.</p><p>Any ranking-based evaluation metric can be considered as a "black box" function ω : {π; x, b} → y ∈ [0, 1], which takes in the prediction π to compare with the ground-truth x (conditioned on the mask b), and outputs a scalar y to rate the prediction quality. As in equation 2, b partitions a user's interactions into those that are "observed" and "unobserved" during inference. As we are only interested in recovering the unobserved items in recommendation, we compute the ranking score of predicted items π p = π (1 − x h ) based on the ground-truth items x p .</p><p>One salient component of a ranking-based Oracle metric ω * is to sort π p . The sorting operation is nondifferentiable, rendering it impossible to directly use ω * as the critic. While REINFORCE (Williams, 1992) may appear to be suited to tackle the non-differentiable problem, it suffers from large estimate variance <ref type="bibr" target="#b52">(Silver et al., 2014)</ref>, especially in the collaborative filtering problem, which has a very large prediction space. This motivates consideration of a differentiable neural network to approximate the mapping executed by the Oracle. In the actor-critic framework, the prediction network is called the actor, and the network which approximates the oracle is called the critic. The actor begins by making a prediction (action) given the user's interaction history as the state. The critic learns to estimate the value of each action, which we define as the task-specific reward, i.e., the Oracle's output. The value predicted by the critic is then used to train the actor. Under the assumption that the critic produces the exact values, the actor is trained based on an unbiased estimate of the gradient of the prediction value in terms of relevant ranking quality metrics. In <ref type="figure" target="#fig_0">Figure 2</ref>, we illustrate the actor-critic paradigm in (b), and the traditional auto-encoder shown in (a) can be used as the actor in our paradigm. The actor can be viewed as the function composition of encoder f φ (·) and g θ (·) in VAEs. The critic mimics the ranking-based evaluation scores, so that it can provide ranking-sensitive feedback in the actor learning.</p><p>Naive critic Conventionally one may concatenate vectors [π p , x p ] as input to a neural network, and train a network to output the measured ranking scores y. However, this naive critic is impractical, and failed in our experiments. Our hypothesis is that since this network architecture has a huge number of parameters to train (as the input data layer is of length 2M , where M &gt; 10k), it would require rich data for training. Unfortunately, this is impractical: {π, x} ∈ R M are very high-dimensional, and the implicit feedback used in collaborative filtering is naturally sparse.</p><p>Feature-based critic The naive critic hopes a deep network can discover structure from massive data by itself, leaving much valuable domain knowledge unused. We propose a more efficient critic, that takes into account the structure underlined by the assumed likelihood in MLE <ref type="bibr" target="#b34">(Miyato &amp; Koyama, 2018)</ref>. We describe our intuition and method below, and provide the justification from the perspective of adversarial learning in Section D of the Supplement.</p><p>Consider the computation procedure of the evaluation metric as a function decomposition ω = ω 0 •ω ψ , including two steps:</p><p>• ω 0 : π → h, feature engineering of prediction π into the sufficient statistics h ;</p><p>• ω ψ : h →ŷ, neural approximation of the mapping from the statistics h to the estimated ranking scoreŷ, using a ψ-parameterized neural network.</p><p>The success of this two-step critic largely depends on the effectiveness of the feature h. We hope feature h is (i) compact so that fewer parameters in the critic ω ψ can simplify training; (ii) easy-tocompute so that training and testing is efficient; and (iii) informative so that the necessary information is preserved. We suggest to use a 3-dimensional vector as the feature, and leave more complicated feature engineering as future work. In summary, our feature is</p><formula xml:id="formula_3">h = [L E , |H 0 |, |H 1 |],<label>(5)</label></formula><p>where (i) L E is the negative log-likelihood in equation 4, defined in the MLE training loss. (ii) |H 0 | is the number of unobserved items that a user will interact, with H 0 = {m|x m = 1 and b m = 0}. (iii) |H 1 | is the number of observed items that a user has interacted, with H 1 = {m|x m = 1 and b m = 1}.</p><p>The NLL characterizes the prediction quality of the actor's output π against the ground-truth x in an item-to-item comparison manner, e.g., the inner product between two vectors −x log π as in the multinomial NLL <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>. Ranking is made easier when there are many acceptable items to rank highly (e.g. when |H 0 | is large), and made difficult when predicting from very few interactions (e.g. when |H 1 | is small), motivating these two features. Including these three features allows the critic to guide training by weighting the NLL's relation to ranking given this context about the user. Interestingly, this idea to consider the importance of user behavior statistics coincides with the scaling trick in SVD <ref type="bibr" target="#b38">(Nikolakopoulos et al., 2019b)</ref>.</p><p>Note that |H 0 | and |H 1 | are user-specific, indicating the user's frequency to interact with the system, which can be viewed as side-information about the user. They are only used as features in training the critic to better approximate the ranking scores, and not in training the actor. Hence, we do not use additional information in the testing stage.</p><p>Actor Pre-training In order to be a helpful feature for the critic, the NLL must hold some relationship to the ranking-based objective function. But for the high-dimensional datasets common to collaborative filtering, the ranking score is near-uniformly zero for a randomly-initialized actor. In this situation, a trained critic will not propagate derivatives to the actor, and therefore the actor will not improve. We mitigate this problem by using a pre-trained actor, such as VAEs that have been trained via MLE.</p><p>Critic Pre-training Training a generic critic to approximate the ranking scores for all possible predictions is difficult and cumbersome. Furthermore, it is unnecessary. In practice, a critic only needs to estimate the ranking scores on the restricted domain of the current actor's outputs. Therefore, we train the critic offline on top of the pre-trained MLE-based actor. To train the critic, we minimize the Mean Square Error (MSE) between the critic output and true ranking score y from the Oracle:</p><formula xml:id="formula_4">L C (h, y; ψ) = ω ψ (h) − y 2 ,<label>(6)</label></formula><p>where the target y is generated using its non-differential definition, which plays the role of ground truth simulator in training.</p><p>Actor-critic Training Once the critic is well trained, we fix its parameters ψ and update the actor parameters {φ, θ} to maximize the estimated ranking score</p><formula xml:id="formula_5">L A (h; φ, θ) = ω ψ (h),<label>(7)</label></formula><p>where h is defined in equation 5, including NLL feature extracted from the prediction made in equation 4, together with count features. During back-propagation, the gradient of L A wrt the prediction π is ∂L A ∂π = ∂L A ∂h ∂h ∂π . It further updates the actor parameters, with the encoder gradient ∂L A ∂φ = ∂L A ∂π ∂π ∂φ and the decoder gradient ∂L A ∂θ = ∂L A ∂π ∂π ∂θ . Updating the actor changes its predictions, so we must update the critic to produce the correct ranking scores for its new input domain.</p><p>The full RaCT training procedure is summarized in Algorithm 1 in the Supplement. Stochastic optimization is used, where a batch of users U = {x i |i ∈ B} is drawn at each iteration, with B as a random subset of user index in {1, · · · , N }. The pre-training of the actor in Stage 1 and the critic in Stage 2 are important; they provide good initialization to the actor-critic training in Stage 3 for fast convergence. Further, we provide an alternative interpretation to view our actor-critic approach in equation 6 and equation 7 from the perspective of adversarial learning <ref type="bibr" target="#b13">(Goodfellow et al., 2014)</ref> in the Supplement. This can partially justify our choice of feature engineering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Deep Learning for Collaborative Filtering There are many recent efforts focused on developing deep learning models for collaborative filtering <ref type="bibr" target="#b50">(Sedhain et al., 2015;</ref><ref type="bibr" target="#b62">Xue et al., 2017;</ref><ref type="bibr" target="#b16">He et al., 2018a;</ref><ref type="bibr" target="#b37">b;</ref>. Early work on DNNs focused on explicit feedback settings <ref type="bibr" target="#b11">(Georgiev &amp; Nakov, 2013;</ref><ref type="bibr" target="#b49">Salakhutdinov et al., 2007;</ref>, such as rating predictions. Recent research gradually recognized the importance of implicit feedback <ref type="bibr" target="#b60">(Wu et al., 2016;</ref><ref type="bibr" target="#b30">Liang et al., 2018)</ref>, where the user's preference is not explicitly presented <ref type="bibr" target="#b18">(Hu et al., 2008)</ref>. This setting is more practical but challenging, and is the focus of our work. The proposed actor-critic method belongs to the general two-level architectures for recommendation systems, where a coarse to fine prediction procedure is used. For a systematic method comparison for top-N recommendation tasks, we suggest referring to <ref type="bibr" target="#b9">Dacrema et al. (2019)</ref>. Our method is closely related to three papers, on VAEs <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>, collaborative denoising autoencoder (CDAE) <ref type="bibr" target="#b60">(Wu et al., 2016)</ref> and neural collaborative filtering (NCF) . CDAE and NCF may suffer from scalability issues: the model size grows linearly with both the number of users as well as items. The VAE <ref type="bibr" target="#b30">(Liang et al., 2018)</ref> alleviates this problem via amortized inference. Our work builds on top of the VAE, and improves it by optimizing to the ranking-based metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learned Metrics in Vision &amp; Languages</head><p>Recent research in computer vision and natural language processing has generated excellent results, using learned instead of hand-crafted metrics. Among the rich literature of generating realistic images via generative adversarial networks (GANs) <ref type="bibr" target="#b13">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b42">Radford et al., 2015;</ref><ref type="bibr" target="#b21">Karras et al., 2018)</ref>, our work is most similar to Larsen et al. <ref type="formula" target="#formula_0">(2016)</ref>, where the VAE objective <ref type="bibr" target="#b23">(Kingma &amp; Welling, 2013)</ref> is augmented with the learned representations in the GAN discriminator <ref type="bibr" target="#b13">(Goodfellow et al., 2014)</ref> to better measure image similarities. For language generation, the discrepancy between word-level MLE training and sequence-level semantic evaluation has been alleviated with GANs or RL techniques <ref type="bibr" target="#b0">(Bahdanau et al., 2016;</ref><ref type="bibr" target="#b44">Ren et al., 2017;</ref><ref type="bibr" target="#b31">Lin et al.,</ref>  Learning to Rank (L2R) The idea of L2R has existed for two decades in the information-retrieval community. The goal is to maximize a given ranking-based evaluation metric <ref type="bibr" target="#b32">(Liu et al., 2009;</ref><ref type="bibr" target="#b27">Li, 2014)</ref>, generally through optimizing objective relaxations <ref type="bibr" target="#b56">(Weimer et al., 2008)</ref>. Many L2R methods used in recommendation, such as the popular pairwise L2R methods BPR <ref type="bibr" target="#b45">(Rendle et al., 2009)</ref> and WARP <ref type="bibr" target="#b57">(Weston et al., 2011)</ref>, are trained by optimizing a pairwise classification function that penalizes mis-ranked pairs of items. Through negative sampling <ref type="bibr" target="#b18">(Hu et al., 2008)</ref>, these methods can scale to extremely high-dimensional output spaces. However, it is computationally expensive to compute low-variance updates to a model when the number of items is large.</p><p>An alternative to the pairwise approach is listwise loss functions, which minimize a loss calculated from a user's entire interaction history. By considering the entire interaction history these methods can more closely model ranking, and generally perform better than their pairwise counterparts <ref type="bibr" target="#b61">(Xia et al., 2008)</ref>. Furthermore, compared to methods which calculate relative ranking for each pair <ref type="bibr" target="#b57">(Weston et al., 2011)</ref>, the per-user amortization of rank-calculation can be computed more efficiently. NLL is an example of a listwise loss function, as it is calculated over a user's entire interaction history. Interestingly, NLL is also used as the loss function for ListNet <ref type="bibr" target="#b6">(Cao et al., 2007)</ref>, a classic listwise L2R method designed to probabilistically maximize Top-1 Recall. The VAE framework under NLL can be seen as a principled extension of this method to Top-N collaborative filtering. Our ranking-critical training further extends this methodology by explicitly calculating the relationship between a differentiable listwise loss function and the desired ranking-based evaluation function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>Experimental Settings We implemented our algorithm in TensorFlow. The source code to reproduce the experimental results and plots is included as Supplementary Material. We conduct experiments on three publicly available large-scale datasets, which represent different item recommendation scenarios, including user-movie ratings and user-song play counts. This is the same set of user-item consumption datasets used in <ref type="bibr" target="#b30">Liang et al. (2018)</ref>, and we keep the same pre-processing steps for fair comparison. The statistics of the datasets, evaluation protocols and hyper-parameters are summarized in the Supplement. VAE <ref type="bibr" target="#b30">(Liang et al., 2018)</ref> is used as the baseline, which plays the role of our actor pre-training. The NCDG@100 ranking metric is used as the critic's target in training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Methods</head><p>We use ranking-critical training to improve the three MLE-based methods described in Section 2.1: VAE, DAE, and MF. We also adapt traditional L2R methods as the actors in our framework, where the L2R loss is used to replace L E in equation 5 to construct the feature. We consider WARP and LambdaRank, two pairwise loss functions designed for optimizing NDCG, for these experiments. We also compare our approaches with four representative baseline methods in collaborative filtering. CDAE <ref type="bibr" target="#b60">(Wu et al., 2016</ref>) is a strongly-performing neural-network based method, weighted MF <ref type="bibr" target="#b18">(Hu et al., 2008</ref>) is a linear latent-factor model, and SLIM <ref type="bibr" target="#b39">(Ning &amp; Karypis, 2011)</ref> and EASE <ref type="bibr" target="#b53">(Steck, 2019)</ref> are item-to-item similarity models. We additionally compare with Bayesian Pairwise Ranking <ref type="bibr" target="#b45">(Rendle et al., 2009</ref>), but as this method did not yield competitive performance on these datasets, we omit the results.  Training/Evaluation Correlation We visualize scatter plots between learning objectives and evaluation metric for all users on ML-20M dataset in <ref type="figure" target="#fig_1">Figure 4</ref>. More details and an enlarged visualization is shown in <ref type="figure" target="#fig_3">Figure 6</ref> of the Supplement. The Pearson's correlation r is computed. NLL exhibits low correlation with the target NDCG (r is close to zero), while the learned metric in RaCT shows much higher positive correlation. It strongly indicates RaCT optimizes a more direct objective than an MLE approach. Further, NLL should in theory have a negative correlation with the target NDCG, as we wish that minimizing NLL can maximize NDCG. However, in practice it yields positive correlation. We hypothesize that this is because the number of interactions for each user may dominate the NLL values. That partially motivates us to consider the number of user interactions as features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with traditional L2R methods</head><p>As examples of traditional L2R methods, we compare to our method using WARP <ref type="bibr" target="#b57">(Weston et al., 2011) and</ref><ref type="bibr">LambdaRank (Burges et al., 2007)</ref> as the rankingcritical objectives. We use implementations of both methods designed specifically to maximize NDCG. We observe that WARP and LambdaRank are roughly 2 and 10 times more computationally expensive than RaCT per epoch, respectively. <ref type="table" target="#tab_2">Table 1</ref> shows the results of RaCT, WARP and LambdaRank, using the same amount of wall-clock training time. We observe the trends that WARP degrades performance, and LambdaRank provides performance roughly equal to VAE. WARP's poor performance is perhaps due to poor approximation of the ranking when the number of items is large.</p><p>Comparison with existing methods In <ref type="table" target="#tab_2">Table 1</ref>, we report our RaCT performance, and compare with competing methods in terms of three evaluation metrics: NDCG@100, Recall@20, and Recall@50. We use the published code 1 of <ref type="bibr" target="#b30">Liang et al. (2018)</ref>, and reproduce the VAE as our actor pre-training. We further use their reported values for the classic collaborative filtering methods CDAE, WMF, and SLIM. Our reproduced VAE results are very close to <ref type="bibr" target="#b30">Liang et al. (2018)</ref>   <ref type="bibr" target="#b30">(Liang et al., 2018)</ref> 0.4159 0.4172 1.37 WARP 0.3123 0.3439 31.63  Netflix datasets, but slightly lower on the MSD dataset. The RaCT is built on top of our VAE runs, and consistently improves its baseline actor for all the evaluation metrics and datasets, as seen by comparing the rows RaCT and VAE ‡ . The proposed RaCT also significantly outperforms competing LVMs, including VAE, CDAE, and WMF.</p><p>When comparing to EASE <ref type="bibr" target="#b53">(Steck, 2019)</ref>, our method performs substantially better for ML-20M, comparably for Netflix, and is substantially outperformed for MSD. We observe a similar trend when comparing SLIM (an item-to-item similarity method) and CDAE (a latent variable method). As SLIM and EASE rely on recreating the Gram-matrix G = X T X, their performance should improve with the the number of users <ref type="bibr" target="#b53">(Steck, 2019)</ref>. However this performance may come at a computational cost, as inference requires multiplication with an unfactored M × M matrix. EASE requires computing a dense item-to-item similarity matrix, making its inference on MSD roughly 30 times more expensive than for VAE or RaCT. A practitioner's choice between these two methods should be informed by the specifics of the dataset as well as demands of the system.</p><p>In the Supplement, we study the generalization of RaCT trained with different ranking-metrics in Section F.1, and break down the performance improvement with different cut-off values of NDCG in Section F.3, and with different number of interactions of X in Section F.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">WHAT ACTOR CAN BE IMPROVED BY RACT?</head><p>In RL, the choice of policy plays a crucial role in the agent's performance. Similarly, we would like to study how different actor designs impact RaCT performance. <ref type="table" target="#tab_4">Table 2</ref> shows the performance of various policies before and after applying RaCT. The results on NDCG@100 are reported. The VAE, DAE and MF models follow the setup in <ref type="bibr" target="#b30">Liang et al. (2018)</ref>.</p><p>We modify one component of the VAE at a time, and check the change of performance improvement that RaCT can provide. (1) VAE (Gaussian): we change likelihood form from multinomial to Gaussian, and observe a smaller performance improvement. This shows the importance of having a closer proxy of ranking-based loss.</p><p>(2) VAE (β = 0): we remove the KL regularization by setting β = 0, and replace the posterior sampling with a delta distribution. We see a marginally smaller performance improvement. This compares a stochastic and deterministic policy. The stochastic policy (i.e., posterior sampling) provides higher exploration ability for the actor, allowing more diverse samples generated for the critic's training. This is essential for better critic learning.</p><p>(3) VAE (Linear): we limit the expressive ability of the actor by using a linear encoder and decoder. This significantly degrades performance, and the RaCT cannot help much in this case. RaCT shows improvements for all MLE-based methods, including DAE and MF from <ref type="bibr" target="#b30">Liang et al. (2018)</ref>. It also shows significant improvement over WARP. Please see detailed discussion in Section F.5 of the Supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ABLATION STUDY ON FEATURE-BASED CRITIC</head><p>In <ref type="figure" target="#fig_2">Figure 5</ref>, we investigate the importance of the features we designed in equation 5, using results from the ML-20M dataset. The full feature vector consists of three elements: h = [L E , |H 0 |, |H 1 |]. L E is mandatory, because it links the actor to the critic; removing it would break the back-propagation to train the actor. We carefully remove |H 0 | or |H 1 | from h at each time, and observe that it leads to performance degradation. In particular, removing |H 0 | results in a severe over-fitting issue. When both counts are removed, we observe an immediate performance drop, as depicted by the orange curve. Overall, the results indicate that all three features are necessary to our performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION &amp; DISCUSSION</head><p>We have proposed an actor-critic framework for collaborative filtering on implicit data. The critic learns to approximate the ranking scores, which in turn improves the traditional MLE-based nonlinear LVMs with the learned ranking-critical objectives. To make it practical and efficient, we introduce a few techniques: a feature-based critic to reduce the number of learnable parameters, posterior sampling as exploration for better critic estimates, and pre-training of actor and critic for fast convergence. The experimental results on three large-scale datasets demonstrate the actor-critic's ability to significantly improve the results of a variety of latent-variable models, and achieve better or comparable performance to strong baseline methods.</p><p>Though RaCT improves VAEs, it does not start from the best performing actor model. The very recent work by <ref type="bibr" target="#b9">Dacrema et al. (2019)</ref> conducts a systematic analysis of algorithmic proposals for top-N recommendation tasks. There are other simple and efficient methods that perform better than VAEs, such as pure SVD-based models <ref type="bibr" target="#b8">(Cremonesi et al., 2010;</ref><ref type="bibr" target="#b38">Nikolakopoulos et al., 2019b)</ref>, <ref type="bibr">RecWalk (Nikolakopoulos &amp; Karypis, 2019)</ref> and Personalized Diffusions <ref type="bibr" target="#b37">(Nikolakopoulos et al., 2019a)</ref>. One interesting future research direction is to explore learning-to-rank techniques for them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of contributions:</head><p>Sam and Chunyuan conceptualized learning-to-rank for VAEs. Sam created and implemented the current algorithm, made the model work, and ran all experiments. Chunyuan set up the experiments, led and completed the manuscript writing. Lawrence edited every version of the manuscript. Jianfeng proofread an early version of the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A TESTING STAGE OF VAES FOR COLLABORATIVE FILTERING</head><p>We focus on studying the performance of various models under strong generalization <ref type="bibr" target="#b29">(Liang et al., 2015)</ref> as in <ref type="bibr" target="#b30">(Liang et al., 2018)</ref>. All users are split into training/validation/test sets. The models are learned using the entire interaction history of the users in the training set. To evaluate, we use a part of the interaction history from held-out (validation and test) users to infer the user-level representations from the model, and compute quality metrics by quantifying how well the model ranks the rest of the unseen interaction history from the held-out users. Specifically, for a held-out user with the full history x, we take x h = x b offline using the randomly generated mask b. x h is then frozen as the testing input, and is fed into various trained models during the evaluation stage to get the predictionπ. The recovered interactionx =π (1 − x h ) for the masked seen part is then evaluated by ranking-based metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B BACKGROUND ON TRADITIONAL LEARNING-TO-RANK METHODS</head><p>Formally, the Bayesian Personalized Ranking (BPR) <ref type="bibr" target="#b45">(Rendle et al., 2009</ref>) loss for the n-th user is</p><formula xml:id="formula_6">L BPR = i∈K+ j∈K− σ(π nj − π ni ),<label>(8)</label></formula><p>where σ(·) is the sigmoid function, K + denotes the set of items that the user has interacted with before, and K − denotes the complement item set.</p><p>The Weighted Approximate-Rank Pairwise (WARP) model <ref type="bibr" target="#b57">(Weston et al., 2011)</ref> has been shown to perform better than BPR for implicit feedback <ref type="bibr" target="#b24">(Kula, 2015)</ref>:</p><formula xml:id="formula_7">L WARP = ni∈K+ j∈K− w(r i )max(0, 1 + π nj − π ni )),<label>(9)</label></formula><p>where w(·) is a weighting function for different ranks, and r i is the rank for the i-th item for n-th user. A common choice of weighting function w(·) for optimizing NDCG is w(r) = r i=1 α i , with α i = 1/i. WARP improves BPR by the weights w(·) and the margin between positive and negative items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C PSEUDO-CODE FOR RACT</head><p>We summarize the full training procedure of RaCT in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D INTERPRETATION WITH GANS</head><p>We can view our actor-critic approach in equation 6 and equation 7 from the perspective of Generative Adversarial Networks (GANs). GANs constitute a framework to construct a generator G that can mimic a target distribution, and have achieved significant success in generating realistic images <ref type="bibr" target="#b13">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b42">Radford et al., 2015;</ref><ref type="bibr" target="#b21">Karras et al., 2018;</ref><ref type="bibr" target="#b4">Brock et al., 2018)</ref>. The most distinctive feature of GANs is the discriminator D that evaluates the divergence between the current generator distribution and the target distribution <ref type="bibr" target="#b13">(Goodfellow et al., 2014;</ref>. The GAN learning procedure performs iterative training between the discriminator and generator, with the discriminator acting as an increasingly meticulous critic to refine the generator. In our work, the actor can be interpreted as the generator, while the critic can be viewed as the discriminator.</p><p>Note that GANs and actor-critic models learn the metric functions <ref type="bibr" target="#b10">(Finn et al., 2016)</ref>, and it has been shown in <ref type="bibr" target="#b41">Pfau &amp; Vinyals (2016)</ref> that GANs can be viewed as actor-critic in an environment where the actor cannot affect the reward. This is exactly our setup. One key difference is that we know the Oracle metric, and the critic is trained to mimic the Oracle's behaviour.</p><p>Algorithm 1: Our full ranking-critical training with stochastic optimization. Input : Interaction matrix X; Actor parameters (encoder φ and decoder θ), Critic parameters ψ. Conditioned on interaction history x h corrupted from x, the actor predicts the distribution parameter π over items, which further constructs the likelihood p(x|π). We use q to designate the data empirical distribution, the target conditional is q(x|π). It can be formulated as the standard adversarial loss for the conditional GAN <ref type="bibr" target="#b33">(Mirza &amp; Osindero, 2014)</ref>. It has been shown that the optimal critic <ref type="bibr" target="#b13">(Goodfellow et al., 2014;</ref> for a conditional GAN can be represented as the log likelihood ratio</p><formula xml:id="formula_8">R * (π, x) = log q(x|π) p(x|π)<label>(10)</label></formula><p>In the collaborative filtering setup, we often make the assumptions that p(x|π) are simple distributions, such as multinomial in VAEs <ref type="bibr" target="#b30">(Liang et al., 2018)</ref> and Gaussian in MF. This simplification allows the parameterization of critic following the following form <ref type="bibr" target="#b34">(Miyato &amp; Koyama, 2018)</ref>:</p><formula xml:id="formula_9">R * (π, x) = x Vν(π) + C<label>(11)</label></formula><p>where x is the target, ν(π) is a layer of the critic with input π, and V and C are the parameters to learn. Most notably, this formulation introduces the prediction information via an inner product, as opposed to concatenation. The form equation 11 is indeed the form we proposed for NLL feature x log π, with V = I and ν(·) = log(·). C includes the normalizer for the prediction probability <ref type="bibr" target="#b34">(Miyato &amp; Koyama, 2018)</ref>, which is related to the count features in equation 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 DATASETS</head><p>We conduct experiments on three publicly available datasets. <ref type="table" target="#tab_6">Table 3</ref> summarizes the statistics of the data. These three ten-million-size datasets represent different item recommendation scenarios, including user-movie ratings and user-song play counts. This is the same set of medium-to large-scale user-item consumption datasets used in <ref type="bibr" target="#b30">Liang et al. (2018)</ref>, and we keep the same pre-processing steps for fair comparison.  <ref type="bibr" target="#b1">-Mahieux et al., 2011)</ref>. We binarize play counts, and keep users who have listened to at least 20 songs as well as songs that are listened to by at least 200 users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 EVALUATION PROTOCOL</head><p>In the testing stage, we get the predicted ranking by sorting the multinomial probability π p . For each user, we compare the predicted ranking of the held-out items with their true ranking. Two ranking-based metrics are considered, Recall@R and the truncated NDCG (NDCG@R), where R is the cut-off hyper-parameter. While Recall@R considers all items ranked within the first R to be equally important, NDCG@R uses a monotonically increasing discount to emphasize the importance of higher ranks versus lower ones.</p><p>Formally, we define m(r) as the item at rank r, and H 0 as the held-out unobserved items that a user will interact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DCG@R =</head><p>R r=1 2 δ[m(r)∈H0] − 1 log(r + 1) .</p><p>By dividing DCG@R by its best possible value, we obtain NDCG@R in [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall@R =</head><formula xml:id="formula_11">R r=1 δ[m(r) ∈ H 0 ] min(R, |H 0 |) .<label>(13)</label></formula><p>The denominator normalizes Recall@R in [0, 1], with maximum value 1 corresponding to the case that all relevant items are ranked in the top R positions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 EXPERIMENT HYPER-PARAMETERS</head><p>We set hyper-parameters by following <ref type="bibr" target="#b30">Liang et al. (2018)</ref>      <ref type="table" target="#tab_8">Table 4</ref>. Please refer to <ref type="bibr" target="#b14">Goodfellow et al. (2016)</ref> for the activation functions. Batch Normalization <ref type="bibr" target="#b19">(Ioffe &amp; Szegedy, 2015)</ref> is used to normalize the input features, because the magnitude of the inputs (NLL) change as training progresses. The encoder outputs the mean and variance of the varational distribution; the variance is implemented via an exponential function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F ADDITIONAL EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 GENERALIZATION ACROSS RANKING METRICS</head><p>To study the generalization ability of RaCT, we consider training the critic against Recall@100, in addition to NDCG@100. The only difference is that Recall treats each item as equally important, while NDCG treats the higher ranking items as more important. The results are shown in <ref type="table" target="#tab_10">Table 6</ref>. Indeed, the RaCT gets slightly better testing Recall values when trained against the Recall metric, and the reverse holds for NDCG. More importantly, RaCT allows generalization across different ranking metrics: all testing metric values are significantly improved when trained against either Recall or NDCG.</p><p>Following <ref type="bibr" target="#b30">Liang et al. (2018)</ref>, we compare with NCF on two small datasets, ML-1M (6,040 users, 3,704 items) and Pinterest <ref type="bibr">(55,187 users, 9,916 items)</ref>. This is because the prediction stage of NCF is slow, due to a lack of amortized inference as in VAE. We use their publicly available datasets and metrics for fair comparison. The results are evaluated with a small cut-off value R, to only study the highly ranked items: NDCG@10 and Recall@10. The performance are compared in <ref type="table" target="#tab_11">Table 7</ref>. Our observation that DAE performs better than VAE on these two datasets is consistent with Liang   <ref type="figure" target="#fig_3">Figure 6</ref> explores the relationship between NLL, the learned RaCT metric, and NDCG. We ensure that the best model for each method is used: the model after actor pre-training (Stage 1) is used for NLL plots, and the model after the actor-critic alternative training (Stage 3) is used for RaCT plots. The bottom row of plots displays the output of these models on the testing data. This demonstrates that RaCT's connection to the ranking metric generalizes to unseen data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 BREAKDOWN ANALYSIS FOR DIFFERENT CUT-OFF VALUES</head><p>NDCG@100 only reflects the ranking quality at the cut-off value R = 100. i.e., the top-100 ranking items. To study the ranking quality at different range of the predicted list, we consider a large range of R, and report the corresponding NDCG values. We consider R = 5, 20, 50, 100, 200, and report the results in <ref type="figure" target="#fig_4">Figure 7</ref>. The NDCG@R values are improved for various R, though the critic is trained against NDCG@100. This is because the NDCG metrics of different R are highly correlated, the RaCT can generalize across them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.4 BREAKDOWN ANALYSIS FOR DIFFERENT NUMBER OF INTERACTIONS</head><p>In <ref type="figure">Figure 8</ref>, we show performance improvement across increasing user interactions. We use ML-20M dataset for this case study. The # interactions is the number of items each user interacts with (groundtruth), indicating the user's activity level. <ref type="figure">Figure 8(a)</ref> shows the scatter plots between NDCG@100 values and various number of interactions on the testing dataset, for both VAE and our RaCT methods. RaCT generally improves VAE for a large range of user interactions. We further categorize the users in four groups according to their number of interactions: &lt;250, 250−500, 501−750, &gt;750, and plot the mean of NDCG@100 values for two methods in <ref type="figure">Figure 8(b)</ref>. RaCT improves VAE except for users with high activity level (&gt;750). This is probably because the number of the most active users is small, as observed in <ref type="figure">Figure 8(a)</ref>. It yields a lack of training data for critic learning, which potentially hurts the performance. F.5 ON THE PERFORMANCE IMPROVEMENT OF ACTORS VIA RACT.</p><p>We also consider the two other auto-encoder variants used in <ref type="bibr" target="#b30">Liang et al. (2018)</ref> as the actor. (1) The DAE in <ref type="bibr" target="#b30">Liang et al. (2018)</ref> chooses a smaller architecture M → 600 → M , which achieves better performance than the larger architecture as in our VAE (β = 0) by prevent over-fitting. While we observe the same result, it is interesting to note that the VAE (β = 0) shows a much larger improvement gain than DAE <ref type="bibr" target="#b30">(Liang et al., 2018)</ref> when trained with our RaCT technique, and eventually significantly outperforms the latter. This shows that the additional modeling capacity is necessary to capture the more complex relationship in prediction, when the goal is ranking rather than MLE. (2) The MF in <ref type="bibr" target="#b30">Liang et al. (2018)</ref> employs a Gaussian likelihood, which also gets slight improvement with the RaCT. Overall, we can conclude that the RaCT method improves all the MLE-based variants.</p><p>We also use ranking-loss-based WARP as the actor. For the large datasets considered in this paper, calculating the full WARP-loss for each user is impractically slow. We derive a simple approximation to WARP which runs in quasilinear time to the number of items. Even so, it takes around 30 minutes per epoch on ML-20M dataset, roughly 30 times slower than the VAE. WARP yields the score 0.312, which is lower than other baseline methods. This is consistent with the studies in <ref type="bibr" target="#b30">Liang et al. (2018)</ref>; <ref type="bibr" target="#b51">Sedhain et al. (2016)</ref>. However, when RaCT is applied, WARP gets a significant improvement; in fact, the largest improvement gain of all the actors. This indicates the RaCT is a more direct and effective approach for learning to rank on large datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of learning parameters {φ, θ} in the two different paradigms. (a) Learning with MLE, as in VAEs; (b) Learning with a learned ranking-critic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Correlation between the learning objectives (MLE or RaCT) and evaluation metrics on training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Ablation study on features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Correlation between the learning objectives (NLL or RaCT) and evaluation metrics NDCG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>The improvement at various cut-off value R in evaluation. Given a specific R, the dashed line shows the VAE, and square dot shows the RaCT. Improvement breakdown over different user interactions. (a) Scatter plot between NDCG@100 and activity levels. Note only # interactions ≤ 1000 is visualized, there is a long tail (&gt;1000) in the distribution. (b) Comparison of the mean NDCG@100 values for four user groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Performance improvement (NDCG@100) with RaCT over the VAE baseline. 2017). The RL approach directly optimizes the metric used at test time, and has shown improvement on various applications, including dialogue<ref type="bibr" target="#b28">(Li et al., 2016)</ref>, image captioning<ref type="bibr" target="#b46">(Rennie et al., 2017)</ref> and translations<ref type="bibr" target="#b43">(Ranzato et al., 2015)</ref>. Despite the significant successes in other domains, there has been little if any research reported for directly learning the metrics with deep neural networks for collaborative filtering. Our work fills the gap, and we hope it inspires more research in this direction.</figDesc><table><row><cell>Validation NDCG@100</cell><cell>0.424 0.428 0.432 0.436 0.440</cell><cell>50</cell><cell>75 RaCT 100 125 150 175 200 # Epoch of actor ML-20M VAE</cell><cell>Validation NDCG@100</cell><cell>0.392 0.38 0.383 0.386 0.389</cell><cell>20</cell><cell>Netflix 60 # Epoch of actor 40 RaCT VAE</cell><cell>80</cell><cell>100</cell><cell>Validation NDCG@100</cell><cell>0.320 0.300 0.305 0.310 0.315</cell><cell>20</cell><cell>MSD 60 # Epoch of actor 40 RaCT VAE</cell><cell>80</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell cols="2">(a) ML-20M dataset</cell><cell></cell><cell></cell><cell cols="3">(b) Netflix dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(c) MSD dataset</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Figure 3:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Comparison on three large datasets. The best testing set performance is reported. The results below the line are from<ref type="bibr" target="#b30">Liang et al. (2018)</ref>, and VAE ‡ shows the VAE results based on our runs. Blue indicates improvement over the VAE baseline, and bold indicates overall best.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>ML-20M</cell><cell></cell><cell></cell><cell>Netflix</cell><cell></cell><cell></cell><cell>MSD</cell><cell></cell></row><row><cell>Metric</cell><cell cols="9">R@20 R@50 NDCG@100 R@20 R@50 NDCG@100 R@20 R@50 NDCG@100</cell></row><row><cell>RaCT</cell><cell>0.403</cell><cell>0.543</cell><cell>0.434</cell><cell>0.357</cell><cell>0.450</cell><cell>0.392</cell><cell>0.268</cell><cell>0.364</cell><cell>0.319</cell></row><row><cell>VAE  ‡</cell><cell>0.396</cell><cell>0.536</cell><cell>0.426</cell><cell>0.350</cell><cell>0.443</cell><cell>0.385</cell><cell>0.260</cell><cell>0.356</cell><cell>0.310</cell></row><row><cell>WARP</cell><cell>0.310</cell><cell>0.448</cell><cell>0.348</cell><cell>0.273</cell><cell>0.360</cell><cell>0.312</cell><cell>0.162</cell><cell>0.253</cell><cell>0.210</cell></row><row><cell cols="2">LambdaRank 0.395</cell><cell>0.534</cell><cell>0.427</cell><cell>0.352</cell><cell>0.441</cell><cell>0.386</cell><cell>0.259</cell><cell>0.355</cell><cell>0.308</cell></row><row><cell>EASE</cell><cell>0.391</cell><cell>0.521</cell><cell>0.420</cell><cell>0.362</cell><cell>0.445</cell><cell>0.393</cell><cell>0.333</cell><cell>0.428</cell><cell>0.389</cell></row><row><cell>VAE</cell><cell>0.395</cell><cell>0.537</cell><cell>0.426</cell><cell>0.351</cell><cell>0.444</cell><cell>0.386</cell><cell>0.266</cell><cell>0.364</cell><cell>0.316</cell></row><row><cell>CDAE</cell><cell>0.391</cell><cell>0.523</cell><cell>0.418</cell><cell>0.343</cell><cell>0.428</cell><cell>0.376</cell><cell>0.188</cell><cell>0.283</cell><cell>0.237</cell></row><row><cell>WMF</cell><cell>0.360</cell><cell>0.498</cell><cell>0.386</cell><cell>0.316</cell><cell>0.404</cell><cell>0.351</cell><cell>0.211</cell><cell>0.312</cell><cell>0.257</cell></row><row><cell>SLIM</cell><cell>0.370</cell><cell>0.495</cell><cell>0.401</cell><cell>0.347</cell><cell>0.428</cell><cell>0.379</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">5.1 OVERALL PERFORMANCE OF RACT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Improvement over VAE In Figure 3, we show the learning curves of RaCT and VAE on the validation set. The VAE converges to a plateau by the time that the RaCT finishes its actor pre- training stage, e.g., 150 epochs on ML-20 dataset, after which the VAE's performance is not improving. By contrast, when the RaCT is plugged in, the performance shows a significant immediate boost. For the amount of improvement gain, RaCT takes only half the number of epochs that VAE takes in the end of actor pre-training. For example, RaCT takes 50 epochs (from 150 to 200) to achieve an improvement of 0.44-0.43 = 0.01, while VAE takes 100 epochs (from 50 to 150) to achieve an improvement of 0.43-0.424 = 0.006.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Performance gain (×10 −3 ) for various actors.</figDesc><table><row><cell>Validation NDCG@100</cell><cell>0.430 0.432 0.434 0.436 0.438 0.440</cell><cell cols="2">VAE [ E, | 0|, | 1|] [ E, | 0|] [ E, | 1|] [ E]</cell><cell></cell></row><row><cell></cell><cell>100 0.428</cell><cell>120</cell><cell>140 # Epoch of actor 160</cell><cell>180</cell><cell>200</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>:</head><label></label><figDesc>Randomly initialize weights φ, θ and ψ</figDesc><table><row><cell cols="4">2 / * Stage 1: Pretrain the actor via MLE</cell><cell>* /</cell></row><row><cell cols="2">3 while not converged do do</cell><cell></cell><cell></cell></row><row><cell>4</cell><cell>Sample a batch of users U;</cell><cell></cell><cell></cell></row><row><cell>5</cell><cell>Update {θ, φ} with gradient</cell><cell>∂L β ∂θ and</cell><cell>∂L β ∂φ in equation 4;</cell></row><row><cell cols="2">6 end</cell><cell></cell><cell></cell></row><row><cell cols="4">7 / * Stage 2: Pretrain the critic via MSE</cell><cell>* /</cell></row><row><cell cols="2">8 while not converged do do</cell><cell></cell><cell></cell></row><row><cell>9</cell><cell>Sample a batch of users U;</cell><cell></cell><cell></cell></row><row><cell>10</cell><cell cols="3">Construct features h in equation 5 and target y from the Oracle;</cell></row><row><cell>11</cell><cell cols="3">Update ψ with gradient ∂L C ∂ψ in equation 6;</cell></row><row><cell cols="2">12 end</cell><cell></cell><cell></cell></row><row><cell cols="4">13 / * Stage 3: Alternative training of actor and critic</cell><cell>* /</cell></row><row><cell cols="2">14 for t = 1, 2, . . . , T do</cell><cell></cell><cell></cell></row><row><cell>15</cell><cell>Sample a batch of users U;</cell><cell></cell><cell></cell></row><row><cell>16</cell><cell>/ * Actor step</cell><cell></cell><cell></cell><cell>* /</cell></row><row><cell>17</cell><cell cols="3">Update {θ, φ} with gradient ∂L A ∂θ and ∂L A ∂φ in equation 7;</cell></row><row><cell>18</cell><cell>/ * Critic step</cell><cell></cell><cell></cell><cell>* /</cell></row></table><note>1 Initialize19 Construct features h in equation 5 and target y from the Oracle;20 Update ψ with gradient ∂L C ∂ψ in equation 6; 21 end</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Summary Statistics of datasets after all pre-processing steps. Interactions# is the number of non-zero entries. Sparsity% refers to the percentage of zero entries in the user-item interaction matrix X. Items# is the number of total items. HO# is the number of validation/test users held out of the total number of users in the 5th column Users#.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Interaction# Sparsity% Item#</cell><cell>User#</cell><cell>HO#</cell></row><row><cell>ML-20M</cell><cell>10.0M</cell><cell>99.64%</cell><cell cols="2">20,108 136,677 10K</cell></row><row><cell>Netflix</cell><cell>56.9M</cell><cell>99.31%</cell><cell cols="2">17,769 463,435 40K</cell></row><row><cell>MSD</cell><cell>33.6M</cell><cell>99.86%</cell><cell cols="2">41,140 571,355 50K</cell></row><row><cell cols="5">1. MovieLens-20M (ML-20M): This is the user-movie rating data collected from a movie</cell></row><row><cell cols="5">recommendation service 2 . The data is binarized by keeping ratings of four or higher and</cell></row><row><cell cols="5">setting other entries as unobserved. Only users who have watched at least five movies are</cell></row><row><cell>considered.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">2. Netflix Prize (Netflix): This is the user-movie rating data from the Netflix Prize 3 . Similarly</cell></row><row><cell cols="5">to ML-20M, the data is binarized by keeping ratings of four or higher, and only users who</cell></row><row><cell cols="3">have watched at least five movies are kept.</cell><cell></cell></row><row><cell cols="5">3. Million Song Dataset (MSD): This is the user-song play count data from the Million Song</cell></row><row><cell>Dataset (Bertin</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>for comparisons. For VAE, the dimension of the latent representation is 200. When KL regularization is removed (β = 0), i.e., for DAE and MF, we instead apply 2 regularization (0.01) on weights to prevent overfitting. Adam optimizer (Kingma &amp; Ba, 2014) is used, with batch size of |B| = 500 users. For ML-20M, the actor is pre-trained for 150 epochs, and alternative training for 50 epochs. On the other two datasets, the actor is pre-trained for 75 epochs, and alternative training for 25 epochs. The critic is pre-trained for 50 epochs for all three datasets. The alternative training has equal update frequency for actor and critic. This schedule ensures that we the have the same total number of actor training epochs as<ref type="bibr" target="#b30">Liang et al. (2018)</ref>: 200 epochs for ML-20M, 100 epochs for the other two datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Network architectures. The arrow indicates the flow between two layers. For each layer, we show the number of units on top of its following activation function. BN indicates Batch Normalization.</figDesc><table><row><cell cols="2">Networks</cell><cell></cell><cell></cell><cell></cell><cell cols="6">Architectures</cell></row><row><cell>Actor</cell><cell>Encoder</cell><cell></cell><cell cols="2">M Linear</cell><cell>→</cell><cell cols="2">600 Tanh</cell><cell>→</cell><cell cols="2">200 Linear&amp; Exp</cell></row><row><cell></cell><cell>Decoder</cell><cell></cell><cell></cell><cell cols="2">200 Linear</cell><cell>→</cell><cell cols="2">600 Tanh</cell><cell>→</cell><cell>M Softmax</cell></row><row><cell></cell><cell>Critic</cell><cell>3 BN</cell><cell>→</cell><cell>100 ReLU</cell><cell>→</cell><cell cols="2">100 ReLU</cell><cell>→</cell><cell cols="2">10 ReLU</cell><cell>→</cell><cell>1 Sigmoid</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Summary of training schedule hyper-parameters. β max indicates the maximum value of β.In the actor pre-training stage, the number of epochs used for increasing and fixing β are shown in row 3 and 4, respectively.</figDesc><table><row><cell>Dataset</cell><cell cols="3">ML-20M Netflix MSD</cell></row><row><cell>β max</cell><cell>0.2</cell><cell>0.2</cell><cell>0.1</cell></row><row><cell># epochs for annealing</cell><cell>100</cell><cell>75</cell><cell>75</cell></row><row><cell># epochs for fixing</cell><cell>50</cell><cell>0</cell><cell>0</cell></row><row><cell># epochs for actor pre-training</cell><cell>150</cell><cell>75</cell><cell>75</cell></row><row><cell># epochs for critic pre-training</cell><cell>50</cell><cell>50</cell><cell>50</cell></row><row><cell># epochs for alternative training</cell><cell>50</cell><cell>25</cell><cell>25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Performance trained with different metrics. (ML-20M)</figDesc><table><row><cell>Training</cell><cell></cell><cell>Testing</cell><cell></cell></row><row><cell></cell><cell cols="3">Recall@20 Recall@50 NDCG@100</cell></row><row><cell>RaCT (Recall@100)</cell><cell>0.40316</cell><cell>0.54317</cell><cell>0.43392</cell></row><row><cell>RaCT (NDCG@100)</cell><cell>0.40269</cell><cell>0.54304</cell><cell>0.43395</cell></row><row><cell>VAE</cell><cell>0.39623</cell><cell>0.53632</cell><cell>0.42586</cell></row><row><cell cols="4">A fully-connected (FC) architecture is used for all networks, as detailed in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Comparison between our RaCT with NCF on two small datasets. NCF results are from<ref type="bibr" target="#b30">Liang et al. (2018)</ref>. VAE) is considered. This is because the sizes of the two datasets are relatively small, the critic can be better trained when more samples are observed. On the larger Pinterest dataset, the auto-encoder variants perform better than NCF by a big margin, and our RaCT further boosts the performance.</figDesc><table><row><cell>Dataset</cell><cell>Metric</cell><cell>NCF DAE RaCT VAE RaCT</cell></row><row><cell>ML-1M</cell><cell cols="2">Recall@10 0.705 0.722 0.722 0.704 0.706 NDCG@10 0.426 0.446 0.446 0.433 0.434</cell></row><row><cell>Pinterest</cell><cell cols="2">Recall@10 0.872 0.886 0.887 0.873 0.878 NDCG@10 0.551 0.580 0.581 0.564 0.568</cell></row><row><cell cols="3">et al. (2018). In general, RaCT shows higher improvement when a larger dataset (Pinterest), or a</cell></row><row><cell>stochastic actor (</cell><cell></cell><cell></cell></row></table><note>F.2 CORRELATION BETWEEN TRAINING METRICS</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/dawenl/vae_cf</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://grouplens.org/datasets/movielens/20m/ 3 https://www.netflixprize.com/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">An actor-critic algorithm for sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philemon</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.07086</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The million song dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thierry Bertin-Mahieux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Whitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lamere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMIR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Variational inference: A review for statisticians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcauliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to rank with nonsmooth cost functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Ragno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to rank: From pairwise approach to listwise approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Performance of recommender algorithms on top-N recommendation tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Turrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender systems</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Are we really making much progress? a worrying analysis of recent neural recommendation approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Maurizio Ferrari Dacrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03852</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A non-iid framework for collaborative filtering with restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1148" to="1156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Amortized inference in probabilistic reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press Cambridge</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<title level="m">Outer product-based neural collaborative filtering. IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adversarial personalized ranking for recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhankui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Collaborative filtering for implicit feedback datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining, 2008. ICDM&apos;08. Eighth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of ir techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaana</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<publisher>TOIS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Kula</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.08439</idno>
		<title level="m">Metadata embeddings for user and item cold-start recommendations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Boesen Lindbo Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1558" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Alice: Towards understanding adversarial learning for joint distribution matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5495" to="5503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to rank for information retrieval and natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="121" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01541</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Content-aware collaborative music recommendation using pre-trained neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minshu</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel Pw</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ISMIR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Variational autoencoders for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jebara</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adversarial ranking for language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ting</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3155" to="3165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to rank for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">cgans with projection discriminator. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">RecWalk: Nearly uncoupled random walks for top-N recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Athanasios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Nikolakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Search and Data Mining</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Personalized diffusions for top-N recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Athanasios N Nikolakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Berberidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios B</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">EigenRec: generalizing pureSVD for effective and efficient top-N recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassilis</forename><surname>Athanasios N Nikolakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstratios</forename><surname>Kalantzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Gallopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garofalakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Slim: Sparse linear methods for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="497" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improving regularized singular value decomposition for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkadiusz</forename><surname>Paterek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD cup and workshop</title>
		<meeting>KDD cup and workshop</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="5" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01945</idno>
		<title level="m">Connecting generative adversarial networks and actor-critic methods</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Sequence level training with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelio</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning-based image captioning with embedding reward</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Zhou Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xutao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bpr: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence</title>
		<meeting>the twenty-fifth conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Self-critical sequence training for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Marcheret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarret</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhava</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">ICML</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Recommender systems: introduction and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bracha</forename><surname>Shapira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Restricted boltzmann machines for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Autorec: Autoencoders meet collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvash</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lexing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="111" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On the effectiveness of linear models for one-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvash</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darius</forename><surname>Braziunas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Deterministic policy gradient algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Lever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Degris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Embarrassingly shallow autoencoders for sparse data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A survey of collaborative filtering techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyuan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in artificial intelligence</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Cofi rank-maximum margin matrix factorization for collaborative ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1593" to="1600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2764" to="2770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning to rank recommendations with the k-order statistic loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM conference on Recommender systems</title>
		<meeting>the 7th ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="245" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Ninth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Listwise approach to learning to rank -theory and algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fen</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep matrix factorization models for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Hong-Jian Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3203" to="3209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07435</idno>
		<title level="m">Deep learning based recommender system: A survey and new perspectives</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangsheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenkui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09477</idno>
		<title level="m">A neural autoregressive approach to collaborative filtering</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
