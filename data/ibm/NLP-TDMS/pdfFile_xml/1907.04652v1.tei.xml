<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Representation Learning via Hard and Channel-Wise Attention Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 4-8, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Gao</surname></persName>
							<email>hongyang.gao@tamu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University College Station</orgName>
								<address>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Texas A&amp;M University College Station</orgName>
								<address>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Representation Learning via Hard and Channel-Wise Attention Networks</title>
					</analytic>
					<monogr>
						<title level="m">KDD &apos;19</title>
						<meeting> <address><addrLine>Anchorage, AK, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">August 4-8, 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3292500.3330897</idno>
					<note>ACM Reference Format: Hongyang Gao and Shuiwang Ji. 2019. Graph Representation Learning via Hard and Channel-Wise Attention Networks. In The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD &apos;19), August 4-8, 2019, Anchorage, AK, USA. ACM, New York, NY, USA, 9 pages. https: // ACM ISBN 978-1-4503-6201-6/19/08. . . $15.00</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS • Computing methodologies → Neural networks</term>
					<term>Structured outputs</term>
					<term>Artificial intelligence KEYWORDS Graph neural networks, hard attention, channel-wise attention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Attention operators have been widely applied in various fields, including computer vision, natural language processing, and network embedding learning. Attention operators on graph data enables learnable weights when aggregating information from neighboring nodes. However, graph attention operators (GAOs) consume excessive computational resources, preventing their applications on large graphs. In addition, GAOs belong to the family of soft attention, instead of hard attention, which has been shown to yield better performance. In this work, we propose novel hard graph attention operator (hGAO) and channel-wise graph attention operator (cGAO). hGAO uses the hard attention mechanism by attending to only important nodes. Compared to GAO, hGAO improves performance and saves computational cost by only attending to important nodes. To further reduce the requirements on computational resources, we propose the cGAO that performs attention operations along channels. cGAO avoids the dependency on the adjacency matrix, leading to dramatic reductions in computational resource requirements. Experimental results demonstrate that our proposed deep models with the new operators achieve consistently better performance. Comparison results also indicates that hGAO achieves significantly better performance than GAO on both node and graph embedding tasks. Efficiency comparison shows that our cGAO leads to dramatic savings in computational resources, making them applicable to large graphs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep attention networks are becoming increasingly powerful in solving challenging tasks in various fields, including natural language processing <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>, and computer vision <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37]</ref>. Compared to convolution layers and recurrent neural layers like LSTM <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>, attention operators are able to capture long-range dependencies and relationships among input elements, thereby boosting performance <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref>. In addition to images and texts, attention operators are also applied on graphs <ref type="bibr" target="#b27">[28]</ref>. In graph attention operators (GAOs), each node in a graph attend to all neighboring nodes, including itself. By employing attention mechanism, GAOs enable learnable weights for neighboring feature vectors when aggregating information from neighbors. However, a practical challenge of using GAOs on graph data is that they consume excessive computational resources, including computational cost and memory usage. The time and space complexities of GAOs are both quadratic to the number of nodes in graphs. At the same time, GAOs belong to the family of soft attention <ref type="bibr" target="#b11">[12]</ref>, instead of hard attention <ref type="bibr" target="#b30">[31]</ref>. It has been shown that hard attention usually achieves better performance than soft attention, since hard attention only attends to important features <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>In this work, we propose novel hard graph attention operator (hGAO). hGAO performs attention operation by requiring each query node to only attend to part of neighboring nodes in graphs. By employing a trainable project vector p, we compute a scalar projection value of each node in graph on p. Based on these projection values, hGAO selects several important neighboring nodes to which the query node attends. By attending to the most important nodes, the responses of the query node are more accurate, thereby leading to better performance than methods based on soft attention. Compared to GAO, hGAO also saves computational cost by reducing the number of nodes to attend.</p><p>GAO also suffers from the limitations of excessive requirements on computational resources, including computational cost and memory usage. hGAO improves the performance of attention operator by using hard attention mechanism. It still consumes large amount of memory, which is critical when learning from large graphs. To overcome this limitation, we propose a novel channel-wise graph attention operator (cGAO). cGAO performs attention operation from the perspective of channels. The response of each channel is computed by attending to all channels. Given that the number of channels is far smaller than the number of nodes, cGAO can significantly save computational resources. Another advantage of cGAO over GAO and hGAO is that it does not rely on the adjacency matrix. In both GAO and hGAO, the adjacency matrix is used to identify neighboring nodes for attention operators. In cGAO, features within the same node communicate with each other, but features in different nodes do not. cHAO does not need the adjacency matrix to identify nodes connectivity. By avoiding dependency on the adjacency matrix, cGAO achieves better computational efficiency than GAO and hGAO.</p><p>Based on our proposed hGAO and cGAO, we develop deep attention networks for graph embedding learning. Experimental results on graph classification and node classification tasks demonstrate that our proposed deep models with the new operators achieve consistently better performance. Comparison results also indicates that hGAO achieves significantly better performance than GAOs on both node and graph embedding tasks. Efficiency comparison shows that our cGAO leads to dramatic savings in computational resources, making them applicable to large graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>In this section, we describe the attention operator and related hard attention and graph attention operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Attention Operator</head><p>An attention operator takes three matrices as input; those are a query matrix</p><formula xml:id="formula_0">Q = [q 1 , q 2 , · · · , q m ] ∈ R d ×m with each q i ∈ R d , a key matrix K = [k 1 , k 2 , · · · , k n ] ∈ R d ×n with each k i ∈ R d , and a value matrix V = [v 1 , v 2 , · · · , v n ] ∈ R p×n with each v i ∈ R p .</formula><p>For each query vector q i , the attention operator produces its response by attending it to every key vector in K. The results are used to compute a weighted sum of all value vectors in V , leading to the output of the attention operator. The layer-wise forwardpropagation operation of attn(Q, K, V ) is defined as</p><formula xml:id="formula_1">E = K T Q ∈R n×m , O = V softmax(E) ∈R p×m ,<label>(1)</label></formula><p>where softmax(·) is a column-wise softmax operator. The coefficient matrix E is calculated by the matrix multiplication between K T and Q. Each element e i j in E represents the inner product result between the key vector k T i and the query vector q j . The matrix multiplication K T Q computes all similarity scores between all query vectors and all key vectors. The column-wise softmax operator is used to normalize the coefficient matrix and make the sum of each column to 1. The matrix multiplication between V and softmax(E) produces the output O. Self-attention <ref type="bibr" target="#b26">[27]</ref> is a special attention operator with Q = K = V .</p><p>In Eq. 1, we employ dot product to calculate responses between query vectors in Q and key vectors in K. There are several other ways to perform this computation, such as Gaussian function and concatenation. Dot product is shown to be the simplest but most effective one <ref type="bibr" target="#b29">[30]</ref>. In this work, we use dot product as the similarity function. In general, we can apply linear transformations on input matrices, leading to following attention operator:</p><formula xml:id="formula_2">E = (W K K) T W Q Q ∈R n×m , O = W V V softmax(E) ∈R p ′ ×m ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">W V ∈ R p ′ ×p W K ∈ R d ′ ×d and W Q ∈ R d ′ ×d .</formula><p>In the following discussions, we will skip linear transformations for the sake of notational simplicity.</p><p>The computational cost of the attention operator as described </p><formula xml:id="formula_4">in Eq. 1 is O(n × d × m) + O(p × n × m) = O(n × m × (d + p)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hard Attention Operator</head><p>The attention operator described above uses soft attention, since responses to each query vector q i are calculated by taking weighted sum over all value vectors. In contrast, hard attention operator <ref type="bibr" target="#b30">[31]</ref> only selects a subset of key and value vectors for computation. Suppose k key vectors (k &lt; n) are selected from the input matrix K and the indices are i 1 , i 2 , · · · , i k with i m &lt; i n and 1 ≤ m &lt; n ≤ k. With selected indices, new key and value matrices are constructed</p><formula xml:id="formula_5">asK = [k i 1 , k i 2 , . . . , k i k ] ∈ R d ×k andṼ = [v i 1 , v i 2 , . . . , v i k ] ∈ R p×k .</formula><p>The output of the hard attention operator is obtained by O = attn(Q,K,Ṽ ). The hard attention operator is converted into a stochastic process in <ref type="bibr" target="#b30">[31]</ref> by setting k to 1 and use probabilistic sampling. For each query vector, it only selects one value vector by probabilistic sampling based on normalized similarity scores given by softmax(Kq i ). The hard attention operators using probabilistic sampling are not differentiable, and requires reinforcement learning techniques for training. This makes soft attention more popular for easier back-propagation training <ref type="bibr" target="#b17">[18]</ref>.</p><p>By attending to less key vectors, the hard attention operator is computationally more efficient than the soft attention operator. The time and space complexities of the hard attention operator are O(m × k × d) and O(m × k), respectively. When k ≪ m, the hard attention operator reduces time and space complexities by a factor of m compared to the soft attention operator. Besides computational efficiency, the hard attention operator is shown to have better performance than the soft attention operator <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref>, because it only selects important feature vectors to attend <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Attention Operator</head><p>The graph attention operator (GAO) was proposed in <ref type="bibr" target="#b27">[28]</ref>, and it applies the soft attention operator on graph data. For each node in a graph, it attends to its neighboring nodes. Given a graph with N nodes, each with d features, the layer-wise forward propagation operation of GAO in <ref type="bibr" target="#b27">[28]</ref> is defined as</p><formula xml:id="formula_6">E = (X T X ) • A, O = X softmax(Ẽ),<label>(3)</label></formula><p>where • denotes element-wise matrix multiplication, A ∈ {0, 1} N ×N and X = [x 1 , x 2 , . . . , x N ] ∈ R d ×N are the adjacency and feature matrices of a graph. Each x i ∈ R d is node i's feature vector. In some situations, A can be normalized as needed <ref type="bibr" target="#b14">[15]</ref>. Note that the softmax function only applies to nonzero elements ofẼ. The time complexity of GAO is O(Cd), where C is the number of edges. On a dense graph with C ≈ N 2 , this reduces to O(N 2 d). On a sparse graph, sparse matrix operations are required to compute GAO with this efficiency. However, current tensor manipulation frameworks such as TensorFlow do not support efficient batch training with sparse matrix operations <ref type="bibr" target="#b27">[28]</ref>, making it hard to achieve this efficiency. In general, GAO consumes excessive computational resources, preventing its applications on large graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HARD AND CHANNEL-WISE ATTENTION OPERATORS AND NETWORKS</head><p>In this section, we describe our proposed hard graph attention operator (hGAO) and channel-wise graph attention operator (cGAO). hGAO applies the hard attention operation on graph data, thereby saving computational cost and improving performance. cGAO performs attention operation on channels, which avoids the dependency on the adjacency matrix and significantly improves efficiency in terms of computational resources. Based on these operators, we propose the deep graph attention networks for network embedding learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hard Graph Attention Operator</head><p>Graph attention operator (GAO) consumes excessive computation resources, including computational cost and memory usage, when graphs have a large number of nodes, which is very common in real-world applications. Given a graph with N nodes, each with d features, GAO requires O(N 2 d) and O(N 2 ) time and space complexities to compute its outputs. This means the computation cost and memory required grow quadratically in terms of graph size. This prohibits the application of GAO on graphs with a large number of nodes. In addition, GAO uses the soft attention mechanism, which computes responses of each node from all neighboring nodes in the graph. Using hard attention operator to replace the soft attention operator can reduce computational cost and improve learning performance. However, there is still no hard attention operator on graph data to the best of our knowledge. Direct use of the hard attention operator as in <ref type="bibr" target="#b30">[31]</ref> on graph data still incurs excessive computational resources. It requires the computation of the normalized similarity scores for probabilistic sampling, which is the key factor of high requirements on computational resources. To address the above limitations of GAO, we propose the hard graph attention operator (hGAO) that applies hard attention on graph data to save computational resources. For all nodes in a graph, we use a projection vector p ∈ R d to select the k-most important nodes to attend. Following the notations defined in Section 2, the layer-wise forward propagation function of hGAO is defined as</p><formula xml:id="formula_7">y = |X T p| ∥p∥ ∈R N (4) for i = 1, 2, · · · , N do idx i = Ranking k (A :i • y) ∈R k<label>(5)</label></formula><formula xml:id="formula_8">X i = X (:, idx i ) ∈R d ×k<label>(6)</label></formula><formula xml:id="formula_9">y i = sigmoid(y(idx i )) ∈R k (7) X i =X i diag(ỹ i ) ∈R d ×k (8) z i = attn(x i ,X i ,X i ) ∈R d (9) Z = [z 1 , z 2 , . . . , z N ] ∈R d ×N<label>(10)</label></formula><p>where A :i denotes the ith column of matrix A, X (:, idx i ) contains a subset of columns of X indexed by idx i , | · | computes element-wise absolute values, • denotes element-wise matrix/vector multiplication, diag(·) constructs a diagonal matrix with the input vector as diagonal elements, Ranking k (·) is an operator that performs the k-most important nodes selection for the query node i to attend and is described in detail below. We propose a novel node selection method in hard attention. For each node in the graph, we adaptively select the k most important adjacent nodes. By using a trainable projection vector p, we compute the absolute scalar projection of X on p in Eq. (4), resulting in y = [y 1 , y 2 , · · · , y N ] T . Here, each y i measures the importance of node i. For each node i, the Ranking k (·) operation in Eq. (5) ranks node i's adjacent nodes by their projection values in y, and selects nodes with the k largest projection values. Suppose the indices of selected nodes for node i are idx i = [i 1 , i 2 , · · · , i k ], node i attends to these k nodes, instead of all adjacent nodes. In Eq. (6), we extract</p><formula xml:id="formula_10">new feature vectorsX i = [x i 1 , x i 2 , . . . , x i k ] ∈ R d ×k using the se- lected indices idx i .</formula><p>Here, we propose to use a gate operation to control information flow. In Eq. <ref type="formula">(7)</ref>, we obtain the gate vectorỹ by applying the sigmoid function to the selected scalar projection values y(idx i ). By matrix multiplicationX i diag(ỹ i ) in Eq. <ref type="formula">(8)</ref>, we control the information of selected nodes and make the projection vector p trainable with gradient back-propagation. We use attention operator to compute the response of node i in Eq. <ref type="bibr" target="#b8">(9)</ref>. Finally, we construct the output feature matrix Z in Eq. <ref type="bibr" target="#b9">(10)</ref>. Note that the projection vector p is shared across all nodes in the graph. This means hGAO only involves d additional parameters, which may not increase the risk of over-fitting.</p><p>By attending to less nodes in graphs, hGAO is computationally more efficient than GAO. The time complexity of hGAO is</p><formula xml:id="formula_11">O(N × log N × k + N × k × d 2 ) if using max heap for k-largest selection.</formula><p>When k ≪ N and d ≪ N , hGAO consumes less time compared to the GAO. The space complexity of hGAO is O(N 2 ) since we need to store the intermediate score matrix during k-most important nodes selection. Besides computational efficiency, hGAO is expected to have better performance than GAO, because it selects important neighboring nodes to attend <ref type="bibr" target="#b19">[20]</ref>. We show in our experiments that hGAO outperforms GAO, which is consistent with the performance of hard attention operators in NLP and computation vision fields <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>This method can be considered as a trade-off between soft attention and the hard attention in <ref type="bibr" target="#b30">[31]</ref>. The query node attends all neighboring nodes in soft attention operators. In the hard attention operator in <ref type="bibr" target="#b30">[31]</ref>, the query node attends to only one node that is probabilistically sampled from neighboring nodes based on the coefficient scores. In our hGAO, we employ an efficient ranking method to select k-most important neighboring nodes for the query node to attend. This avoids computing the coefficient matrix and reduces computational cost. The proposed gate operation enables training of the projection vector p using back-propagation <ref type="bibr" target="#b15">[16]</ref>, thereby avoiding the need of using reinforcement learning methods <ref type="bibr" target="#b22">[23]</ref> for training as in <ref type="bibr" target="#b30">[31]</ref>. <ref type="figure">Figure 1</ref> provides illustrations and comparisons among soft attention operator, hard attention in <ref type="bibr" target="#b30">[31]</ref>, and our proposed hGAO.</p><p>Another possible way to compute the hard attention operator as hGAO is to implement the k-most important node selection based on the coefficient matrix. For each query node, we can select k neighboring nodes with k-largest similarity scores. The responses of the query node is calculated by attending to these k nodes. This method is different from our hGAO in that it needs to compute</p><formula xml:id="formula_12"> (a) (b) (c) Softmax + k 1 k 2 k 3 k 4 v 4 v 3 v 2 v 1 s 1 s 2 s 3 s 4 e1 e2 e3 e4 t q f f f f    Softmax + k 1 k 2 k 3 k 4 v 4 v 3 v 2 v 1 s 1 s 2 s 4 s 3 e1</formula><p>e2 e3 e4</p><formula xml:id="formula_13">f f t q f f Softmax + Ranking k 1 k 1 k 2 k 2 k 3 k 4 v 4 v 3 v 2 v 2 v 1 s 1 s 2 q e1 e2 y4 y3 y2 g g g g t p f f v 1 y1    Figure 1: Illustration of GAO (a)</formula><p>, hard attention operator in <ref type="bibr" target="#b30">[31]</ref> (b), and our proposed hGAO (c). q is the feature vector of a node with four neighboring nodes in a graph. k i and v i are key and value vectors of the neighboring node i. In GAO (a), similarity scores are computed between query vector and key vectors, leading to scalar values s i . The softmax normalizes these values and converts them into weights. The output is computed by taking a weighted sum of value vectors. In hard attention operator (b), the output is generated by probabilistic sampling, which samples a vector from value vectors using computed weights e i . In hGAO (c), a projection vector p is used to compute the importance scores y i . Based on these importance scores, two out of four nodes are selected by ranking. The output is computed by applying soft attention on selected nodes. the coefficient matrix, which takes O(N 2 × d) time complexity. The hard attention operator using this implementation consumes much more computational resources than hGAO. In addition, the selection process in hGAO employs a trainable projection vector p to achieve important node selection. Making the projection vector p trainable allows for the learning of importance scores from data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Channel-Wise Graph Attention Operator</head><p>The proposed hGAO computes the hard attention operator on graphs with reduced time complexity, but it still incurs the same space complexity as GAO. At the same time, both GAO and hGAO need to use the adjacency matrix to identify the neighboring nodes for the query node in the graph. Unlike grid like data such as images and texts, the number and ordering of neighboring nodes in a graph are not fixed. When performing attention operations on graphs, we need to rely on the adjacency matrix, which causes additional usage of computational resources. To further reduce the computational resources required by attention operators on graphs, we propose the channel-wise graph attention operator, which gains significant advantages over GAO and hGAO in terms of computational resource requirements.</p><p>Both GAO and our hGAO use the node-wise attention mechanism in which the output feature vector of node i is obtained by attending the input feature vector to all or selected neighboring nodes. Here, we propose to perform attention operation from the perspective of channels, resulting in our channel-wise graph attention operator (cGAO). For each channel X i: , we compute its responses by attending it to all channels. The layer-wise forward propagation function of cGAO can be expressed as</p><formula xml:id="formula_14">E = XX T ∈R d ×d , O = softmax(E)X ∈R d ×N .<label>(11)</label></formula><p>Note that we avoid the use of adjacency matrix A, which is different from GAO and hGAO. When computing the coefficient matrix E, the similarity score between two feature maps X i: and X j: are calculated by e i j = N k =1 X ik × X jk . It can be seen that features within the same node communicate with each other, and there is no communication among features located in different nodes. This means we do not need the connectivity information provided by adjacency matrix A, thereby avoiding the dependency on the adjacency matrix used in node-wise attention operators. This saves computational resources related to operations with the adjacency matrix.</p><p>The computational cost of cGAO is O(Nd 2 ), which is lower than that of GAO if d &lt; N . When applying attention operators on graph data, we can control the number of feature maps d, but it is hard to reduce the number of nodes in graphs. On large graphs with d ≪ N , cGAO has computational advantages over GAO and hGAO, since its time complexity is only linear to the size of graphs. The  <ref type="figure">Figure 2</ref>: An illustration of our proposed GANet described in Section 3.3. In this example, the input graph contains 6 nodes, each of which has two features. A GCN layer is used to transform input feature vectors into low-dimensional representations.</p><p>After that, we stack two GAMs for feature extraction. To facilitate feature reuse and gradients back-propagation, we add skip concatenation connections for GAMs. Finally, a GCN layer is used to output designated number of feature maps, which can be directly used for node classification predictions or used as inputs of following operations. </p><formula xml:id="formula_15">GAO O(N 2 × d) O(N 2 ) hGAO O(N ×log N ×k +N ×k ×d 2 ) O(N 2 ) cGAO O(N × d 2 ) O(d 2 ) space complexity of cGAO is O(d 2 )</formula><p>, which is independent of graph size. This means the application of cGAO on large graphs does not suffer from memory issues, which is especially useful on memory limited devices such as GPUs and mobile devices. <ref type="table" target="#tab_1">Table 1</ref> provides theoretical comparisons among GAO, hGAO and cGAO in terms of the time and space complexities. Therefore, cGAO enables efficient parallel training by removing the dependency on the adjacency matrix in graphs and significantly reduces the usage of computational resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Proposed Graph Attention Networks</head><p>To use our hGAO and cGAO, we design a basic module known as the graph attention module (GAM). The GAM consists of two operators; those are, a graph attention operator and a graph convolutional network (GCN) layer <ref type="bibr" target="#b14">[15]</ref>. We combine these two operators to enable efficient information propagation within graphs. For GAO and hGAO, they aggregate information from neighboring nodes by taking weighted sum of feature vectors from adjacent nodes. But there exists a situation that weights of some neighboring nodes are close to zero, preventing the information propagation of these nodes. In cGAO, the attention operator is applied among channels and does not involve information propagation among nodes. To overcome this limitation, we use a GCN layer, which applies the same weights to neighboring nodes and aggregate information from all adjacent nodes. Note that we can use any graph attention operator such as GAO, hGAO and cGAO. To facilitate feature reuse and gradients back-propagation, we add a skip connection by concatenating inputs and outputs of the GCN layer.</p><p>Based on GAM, we design graph attention networks, denoted as GANet, for network embedding learning. In GANet, we first apply a GCN layer, which acts as a graph embedding layer to produce lowdimensional representations for nodes. In some data like citation networks dataset <ref type="bibr" target="#b14">[15]</ref>, nodes usually have very high-dimensional feature vectors. After the GCN layer, we stack multiple GAMs depending on the complexity of the graph data. As each GAM only aggregates information from neighboring nodes, stacking more GAMs can collect information from a larger parts of the graph. Finally, a GCN layer is used to produce designated number of output feature maps. The outputs can be directly used as predictions of node classification tasks. We can also add more operations to produce predictions for graph classification tasks. <ref type="figure">Figure 2</ref> provides an example of our GANet. Based on this network architecture, we denote the networks using GAO, hGAO and cGAO as GANet, hGANet and cGANet, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL STUDIES</head><p>In this section, we evaluate our proposed graph attention networks on node classification and graph classification tasks. We first compare our hGAO and cGAO with GAO in terms of computation resources such as computational cost and memory usage. Next, we compare our hGANet and cGANet with prior state-of-the-art models under inductive and transductive learning settings. Performance studies among GAO, hGAO, and cGAO are conducted to show that our hGAO and cGAO achieve better performance than GAO. We also conduct some performance studies to investigate the selection of some hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We conduct experiments on graph classification tasks under inductive learning settings and node classification tasks under transductive learning settings. Under inductive learning settings, training and testing data are separate. The test data are not accessible during training time. The training process will not learn about graph structures of the test data. For graph classification tasks under inductive learning settings, we use the MUTAG <ref type="bibr" target="#b20">[21]</ref>, PTC <ref type="bibr" target="#b20">[21]</ref>, PROTEINS <ref type="bibr" target="#b1">[2]</ref>, D&amp;D <ref type="bibr" target="#b5">[6]</ref>, IMDB-M <ref type="bibr" target="#b31">[32]</ref>, and COLLAB <ref type="bibr" target="#b31">[32]</ref> datasets to fully evaluate our proposed methods. MUTAG, PTC, PROTEINS and D&amp;D are four benchmarking bioinformatics datasets. MUTAG and PTC are much smaller than PROTEINS and D&amp;D in terms of number of graphs and average nodes in graphs. Compared to large datasets, evaluations on small datasets can help investigate the risk of over-fitting, especially for deep learning based methods. COLLAB, IMDB-M are two social network datasets. For these datasets, we follow the same  settings as in <ref type="bibr" target="#b35">[36]</ref>, which employs 10-fold cross validation <ref type="bibr" target="#b2">[3]</ref> with 9 folds for training and 1 fold for testing. The statistics of these datasets are summarized in <ref type="table" target="#tab_2">Table 2</ref>. Unlike inductive learning settings, the unlabeled data and graph structure are accessible during the training process under transductive learning settings. To be specific, only a small part of nodes in the graph are labeled while the others are not. For node classification tasks under transductive learning settings, we use three benchmarking datasets; those are Cora <ref type="bibr" target="#b23">[24]</ref>, Citeseer, and Pubmed <ref type="bibr" target="#b14">[15]</ref>. These datasets are citation networks. Each node in the graph represents a document while an edge indicates a citation relationship. The graphs in these datasets are attributed and the feature vector of each node is generated by bag-of-word representations. The dimensions of feature vectors of three datasets are different depending on the sizes of dictionaries. Following the same experimental settings in <ref type="bibr" target="#b14">[15]</ref>, we use 20 nodes, 500 nodes, and 500 nodes for training, validation, and testing, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>In this section, we describe the experimental setup for inductive learning and transductive learning tasks. For inductive learning tasks, we adopt the model architecture of DGCNN <ref type="bibr" target="#b35">[36]</ref>. DGCNN consists of four parts; those are graph convolution layers, soft pooling, 1-D convolution layers and dense layers. We replace graph convolution layers with our hGANet described in Section 3.3 and the other parts remain the same. The hGANet contains a starting GCN layer, four GAMs and an ending GCN layer. Each GAM is composed of a hGAO, and a GCN layer. The starting GCN layer outputs 48 feature maps. Each hGAO and GCN layer within GAMs outputs 12 feature maps. The final GCN layer produces 97 feature maps as the original graph convolution layers in DGCNN. The skip connections using concatenation is employed between the input and output feature maps of each GAM. The hyper-parameter k is set to 8 in each hGAO, which means each node in a graph selects 8 most important neighboring nodes to compute the response. We apply dropout <ref type="bibr" target="#b25">[26]</ref> with the keep rate of 0.5 to the feature matrix in every GCN layer. For experiments on cGANet, we use the same settings.</p><p>For transductive learning tasks, we use our hGANet to perform node classification predictions. Since the feature vectors for nodes are generated using the bag-of-words method, they are highdimensional sparse features. The first GCN layer acts like an embedding layer to reduce them into low-dimensional features. To be specific, the first GCN layer outputs 48 feature maps to produce 48 embedding features for each node. For different datasets, we stack different number of GAMs. Specifically, we use 4, 2, and 3 GAMs for Cora, Citeseer, and Pubmed, respectively. Each hGAO and GCN layer in GAMs outputs 16 feature maps. The last GCN layer produces the prediction on each node in the graph. We apply dropout with the keep rate of 0.12 on feature matrices in each layer. We also set k to 8 in all hGAOs. We employ identity activation function as <ref type="bibr" target="#b6">[7]</ref> for all layers in the model. To avoid over-fitting, we apply L 2 regularization with λ = 0.0001. All trainable weights are initialized with Glorot initialization <ref type="bibr" target="#b7">[8]</ref>. We use Adam optimizer <ref type="bibr" target="#b13">[14]</ref> for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison of Computational Efficiency</head><p>According to the theoretical analysis in Section 3, our proposed hGAO and cGAO have efficiency advantages over GAO in terms of the computational cost and memory usage. The advantages are expected to be more obvious as the increase of the number of nodes in a graph. In this section, we conduct simulated experiments to evaluate these theoretical analysis results. To reduce the influence of external factors, we use the network with a single graph attention operator and apply TensorFlow profile tool <ref type="bibr" target="#b0">[1]</ref> to report the number of multiply-adds (MAdd), memory usage, and CPU inference time on simulated graph data.</p><p>The simulated data are create with the shape of "number of nodes × number of feature maps". For all simulated experiments, each node on the input graph has 48 features. We test three graph sizes;  those are 1000, 1,0000, and 20,000, respectively. All tested graph operators output 48 feature maps including GAO, hGAO, and cGAO. For hGAOs, we set k = 8 in all experiments, which is the value of hyper-parameter k tuned on graph classification tasks. We report the number of MAdd, memory usage, and CPU inference time.</p><p>The comparison results are summarized in <ref type="table" target="#tab_4">Table 4</ref>. On the graph with 20,000 nodes, our cGAO and hGAO provide 430.31 and 2.81 times speedup compared to GAO. In terms of the memory usage, cGAO can save 98.81% compared to GAO and hGAO. When comparing across different graph sizes, the effects of speedup and memory saving are more apparent as the graph size increases. This is consistent with our theoretical analysis on hGAO and cGAO. Our hGAO can save computational cost compared to GAO. cGAO achieves great computational resources reduction, which makes it applicable on large graphs. Note that the speed up of hGAO over GAO is not as apparent as the computational cost saving due to the practical implementation limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results on Inductive Learning Tasks</head><p>We evaluate our methods on graph classification tasks under inductive learning settings. To compare our proposed cGAOs with hGAO and GAO, we replace hGAOs with cGAOs in hGANet, denoted as cGANet. We compare our models with prior sate-of-the-art models on D&amp;D, PROTEINS, COLLAB, MUTAG, PTC, and IMDB-M datasets, which serve as the benchmarking datasets for graph classification tasks. The results are summarized in <ref type="table" target="#tab_5">Table 5</ref>. <ref type="table">Table 6</ref>: Comparison of results of node classification experiments with prior state-of-the-art models on the Cora, Citeseer, and Pubmed datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Cora Citeseer Pubmed</p><p>DeepWalk <ref type="bibr" target="#b21">[22]</ref> 67.2% 43.2% 65.3% Planetoid <ref type="bibr" target="#b32">[33]</ref> 75.7% 64.7% 77.2% Chebyshev <ref type="bibr" target="#b3">[4]</ref> 81.2% 69.8% 74.4% GCN <ref type="bibr" target="#b14">[15]</ref> 81.5% 70.3% 79.0% GAT <ref type="bibr" target="#b27">[28]</ref> 83.0 ± 0.7% 72.5 ± 0.7% 79.0 ± 0.3% hGANet 83.5 ± 0.7% 72.7 ± 0.6% 79.2 ± 0.4%</p><p>From the results, we can observe that the our hGANet consistently outperforms DiffPool <ref type="bibr" target="#b33">[34]</ref> by margins of 0.90%, 1.40%, and 2.00% on D&amp;D, PROTEINS, and COLLAB datasets, which contain relatively big graphs in terms of the average number of nodes in graphs. Compared to DGCNN, the performance advantages of our hGANet are even larger. The superior performances on large benchmarking datasets demonstrate that our proposed hGANet is promising since we only replace graph convolution layers in DGCNN. The performance boosts over the DGCNN are consistently and significant, which indicates the great capability on feature extraction of hGAO compared to GCN layers.</p><p>On datasets with smaller graphs, our GANets outperform prior state-of-the-art models by margins of 1.05%, 2.71%, and 1.23% on MUTAG, PTC, and IMDB-M datasets. The promising performances on small datasets prove that our methods improve the ability of high-level feature extraction without incurring the problem of overfitting. cGANet outperforms prior state-of-the-art models but has lower performances than hGANet. This indicates that cGAO is also effective on feature extraction but not as powerful as hGAO.</p><p>The attention on only important adjacent nodes incurred by using hGAOs helps to improve the performance on graph classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results on Transductive Learning Tasks</head><p>Under transductive learning settings, we evaluate our methods on node classification tasks. We compare our hGANet with prior state-of-the-art models on Cora, Citeseer, and Pubmed datasets in terms of the node classification accuracy. The results are summarized in <ref type="table">Table 6</ref>. From the results, we can observe that our hGANet achieves consistently better performances than GAT, which is the prior state-of-the-art model using graph attention operator. Our hGANet outperforms GAT <ref type="bibr" target="#b27">[28]</ref> on three datasets by margins of 0.5%, 0.2%, and 0.2%, respectively. This demonstrates that our hGAO has performance advantage over GAO by attending less but most important adjacent nodes, leading to better generalization and performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Comparison of cGAO and hGAO with GAO</head><p>Besides comparisons with prior state-of-the-art models, we conduct experiments under inductive learning settings to compare our hGAO and cGAO with GAO. To be fair, we replace all hGAOs with GAOs in hGANet employed on graph classification tasks, which results in GANet. GAOs output the same number of feature maps as the corresponding hGAOs. Like hGAOs, we apply linear transformations on key and value matrices. This means GANets have nearly the same number of parameters with hGANets, which additionally contain limited number of projection vectors in hGAOs. We adopt the same experimental setups as hGANet. We compare our hGANet and cGANet with GANet on all six datasets for graph classification tasks described in Section 4.1. The comparison results are summarized in <ref type="table" target="#tab_6">Table 7</ref>.</p><p>The results show that our cGAO and hGAO have significantly better performances than GAO. Notably, GANet runs out of memory when training on D&amp;D dataset with the same experimental setup as hGANet. This demonstrates that hGAO has memory advantage over GAO in practice although they share the same space complexity. cGAO outperforms GAO on all six datasets but has slightly lower performances than hGAO. Considering cGAO dramatically saves computational resources, cGAO is a good choice when facing large graphs. Since there is no work that realizes the hard attention  <ref type="figure">Figure 3</ref>: Results of employing different k values in hGAOs using hGANet on PROTEINS, COLLAB, and MUTAG datasets under inductive learning settings. We use the same experimental setups described in Section 4.2. We report the graph classification accuracies in this figure. We can see that the best performances is achieved when k = 8.</p><p>operator in <ref type="bibr" target="#b30">[31]</ref> on graph data, we do not provide comparisons with it in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Performance Study of k in hGAO</head><p>Since k is an important hyper-parameter in hGAO, we conduct experiments to investigate the impact of different k values on hGANet. Based on hGANet, we vary the values of k in hGAOs with choices of 4, 8, 16, 32, and 64, which are reasonable selections for k. We report performances of hGANets with different k values on graph classification tasks on PROTEINS, COLLAB, and MUTAG datasets, which cover both large and small datasets. The performance changes of hGANets with different k values are plotted in <ref type="figure">Figure 3</ref>. From the figure, we can see that hGANets achieve the best performances on all three datasets when k = 8. The performances start to decrease as the increase of k values. On PROTEINS and COLLAB datasets, the performances of hGANets with k = 64 are significantly lower than those with k = 8. This indicates that larger k values make the query node to attend more adjacent nodes in hGAO, which leads to worse generalization and performance.</p><p>In this work, we propose novel hGAO and cGAO which are attention operators on graph data. hGAO achieves the hard attention operation by selecting important nodes for the query node to attend. By employing a trainable projection vector, hGAO selects k-most important nodes for each query node based on their projection scores. Compared to GAO, hGAO saves computational resources and attends important adjacent nodes, leading to better generalization and performance. Furthermore, we propose the cGAO, which performs attention operators from the perspective of channels. cGAO removes the dependency on the adjacency matrix and dramatically saves computational resources compared to GAO and hGAO. Based on our proposed attention operators, we propose a new architecture that employs a densely connected design pattern to promote feature reuse. We evaluate our methods under both transductive and inductive learning settings. Experimental results demonstrate that our hGANets achieve improved performance compared to prior state-of-the-art networks. The comparison between our methods and GAO indicates that our hGAO achieves significant better performance than GAO. Our cGAO greatly saves computational resources and makes attention operators applicable on large graphs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The space complexity for storing intermediate coefficient matrix E is O(n × m). If d = p and m = n, the time and space complexities are O(m 2 × d) and O(m 2 ), respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of time and space complexities among GAO, hGAO, and cGAO.</figDesc><table><row><cell>Operator</cell><cell>Time Complexity</cell><cell>Space Complexity</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of datasets used in graph classification tasks under inductive learning settings. We use the D&amp;D, PROTEINS, COLLAB, MUTAG, PTC, and IMDB-M datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Total Graphs Train Graphs Test Graphs</cell><cell>Nodes (max)</cell><cell>Nodes (avg)</cell><cell>Degree</cell><cell>Classes</cell></row><row><cell>MUTAG</cell><cell>188</cell><cell>170</cell><cell>18</cell><cell>28</cell><cell>17.93</cell><cell>2.19</cell><cell>2</cell></row><row><cell>PTC</cell><cell>344</cell><cell>310</cell><cell>34</cell><cell>109</cell><cell>25.56</cell><cell>1.99</cell><cell>2</cell></row><row><cell>PROTEINS</cell><cell>1113</cell><cell>1002</cell><cell>111</cell><cell>620</cell><cell>39.06</cell><cell>3.73</cell><cell>2</cell></row><row><cell>D&amp;D</cell><cell>1178</cell><cell>1061</cell><cell>117</cell><cell>5748</cell><cell>284.32</cell><cell>4.98</cell><cell>2</cell></row><row><cell>IMDB-M</cell><cell>1500</cell><cell>1350</cell><cell>150</cell><cell>89</cell><cell>13.00</cell><cell>10.14</cell><cell>3</cell></row><row><cell>COLLAB</cell><cell>5000</cell><cell>4500</cell><cell>500</cell><cell>492</cell><cell>74.49</cell><cell>65.98</cell><cell>3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Statistics of datasets used in node classification tasks under transductive learning settings. We use the Cora, Citeseer, and Pubmed datasets.</figDesc><table><row><cell>Dataset</cell><cell>Nodes</cell><cell>Features</cell><cell>Training</cell><cell>Validation</cell><cell>Testing</cell><cell>Degree</cell><cell>Classes</cell></row><row><cell>Cora</cell><cell>2708</cell><cell>1433</cell><cell>140</cell><cell>500</cell><cell>1000</cell><cell>4</cell><cell>7</cell></row><row><cell>Citeseer</cell><cell>3327</cell><cell>3703</cell><cell>120</cell><cell>500</cell><cell>1000</cell><cell>5</cell><cell>6</cell></row><row><cell>Pubmed</cell><cell>19717</cell><cell>500</cell><cell>60</cell><cell>500</cell><cell>1000</cell><cell>6</cell><cell>3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of results among GAO, hGAO, and cGAO on different graph sizes in terms of the number of MAdd, memory usage, and CPU prediction time. The input sizes are describe by "number of nodes × number of features". The prediction time is the total execution time on CPU.</figDesc><table><row><cell>Input</cell><cell>Layer</cell><cell>MAdd</cell><cell>Cost Saving</cell><cell>Memory</cell><cell>Memory Saving</cell><cell>Time</cell><cell>Speedup</cell></row><row><cell></cell><cell>GAO</cell><cell>100.61m</cell><cell>0.00%</cell><cell>4.98MB</cell><cell>0.00%</cell><cell>8.19ms</cell><cell>1.0×</cell></row><row><cell>1000 × 48</cell><cell>hGAO</cell><cell>37.89m</cell><cell>62.34%</cell><cell>4.98MB</cell><cell>0.00%</cell><cell>5.61ms</cell><cell>1.46×</cell></row><row><cell></cell><cell>cGAO</cell><cell>9.21m</cell><cell>90.84%</cell><cell>0.99MB</cell><cell>80.12%</cell><cell>0.82ms</cell><cell>9.99×</cell></row><row><cell></cell><cell>GAO</cell><cell>9,646.08m</cell><cell>0.00%</cell><cell>409.6MB</cell><cell>0.00%</cell><cell>947.24ms</cell><cell>1.0×</cell></row><row><cell>10000 × 48</cell><cell>hGAO</cell><cell>468.96m</cell><cell>95.14%</cell><cell>409.6MB</cell><cell>0.00%</cell><cell>371.12ms</cell><cell>2.55×</cell></row><row><cell></cell><cell>cGAO</cell><cell>92.16m</cell><cell>99.04%</cell><cell>9.61MB</cell><cell>97.65%</cell><cell>17.96ms</cell><cell>52.74×</cell></row><row><cell></cell><cell>GAO</cell><cell>38,492.16m</cell><cell>0.00%</cell><cell>1,619.2MB</cell><cell>0.00%</cell><cell>12,784.45ms</cell><cell>1.0×</cell></row><row><cell>20000 × 48</cell><cell>hGAO</cell><cell>1,137.97m</cell><cell>97.04%</cell><cell>1,619.2MB</cell><cell>0.00%</cell><cell>4,548.62ms</cell><cell>2.81×</cell></row><row><cell></cell><cell>cGAO</cell><cell>184.32m</cell><cell>99.52%</cell><cell>19.2MB</cell><cell>98.81%</cell><cell>29.71ms</cell><cell>430.31×</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of results of graph classification experiments with prior state-of-the-art models in terms of accuracies on the D&amp;D, PROTEINS, COLLAB, MUTAG, PTC, and IMDB-M datasets. "-" denotes the result not available.</figDesc><table><row><cell>Models</cell><cell>D&amp;D</cell><cell>PROTEINS</cell><cell>COLLAB</cell><cell>MUTAG</cell><cell>PTC</cell><cell>IMDB-M</cell></row><row><cell>GRAPHSAGE [10]</cell><cell>75.42%</cell><cell>70.48%</cell><cell>68.25%</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PSCN [21]</cell><cell>76.27%</cell><cell>75.00%</cell><cell>72.60%</cell><cell>88.95%</cell><cell>62.29%</cell><cell>45.23%</cell></row><row><cell>SET2SET [29]</cell><cell>78.12%</cell><cell>74.29%</cell><cell>71.75%</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DGCNN [36]</cell><cell>79.37%</cell><cell>76.26%</cell><cell>73.76%</cell><cell>85.83%</cell><cell>58.59%</cell><cell>47.83%</cell></row><row><cell>DiffPool [34]</cell><cell>80.64%</cell><cell>76.25%</cell><cell>75.48%</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>cGANet</cell><cell>80.86%</cell><cell>78.23%</cell><cell>76.96%</cell><cell>89.00%</cell><cell>63.53%</cell><cell>48.93%</cell></row><row><cell>hGANet</cell><cell>81.71%</cell><cell>78.65%</cell><cell>77.48%</cell><cell>90.00%</cell><cell>65.02%</cell><cell>49.06%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Comparison of results of graph classification experiments among GAO, hGAO, and cGAO in terms of accuracies on the D&amp;D, PROTEINS, COLLAB, MUTAG, PTC, and IMDB-M datasets. "OOM" denotes out of memory.</figDesc><table><row><cell>Models</cell><cell>D&amp;D</cell><cell>PROTEINS</cell><cell>COLLAB</cell><cell>MUTAG</cell><cell>PTC</cell><cell>IMDB-M</cell></row><row><cell>GANet</cell><cell>OOM</cell><cell>77.92%</cell><cell>76.06%</cell><cell>87.22%</cell><cell>62.94%</cell><cell>48.89%</cell></row><row><cell>cGANet</cell><cell>80.86%</cell><cell>78.23%</cell><cell>76.96%</cell><cell>89.00%</cell><cell>63.53%</cell><cell>48.93%</cell></row><row><cell>hGANet</cell><cell>81.71%</cell><cell>78.65%</cell><cell>77.48%</cell><cell>90.00%</cell><cell>65.02%</cell><cell>49.06%</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by National Science Foundation grants IIS-1908166 and IIS-1908198.   </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In OSDI</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soon</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schönauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Svn Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distinguishing enzyme structures from non-enzymes without alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew J</forename><surname>Dobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="771" to="783" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large-scale learnable graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1416" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DRAW: A recurrent neural network for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1462" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deepgender: Occlusion and low resolution robust facial gender classification via progressively trained convolutional neural networks with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Juefei-Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eshan</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parag</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="68" to="77" />
		</imprint>
	</monogr>
	<note>Anisha Cherodian, and Marios Savvides</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient backprop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genevieve</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: Tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="9" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Non-locally enhanced encoder-decoder network for single image de-raining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyou</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 ACM Multimedia Conference on Multimedia Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1056" to="1064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coarse-to-fine attention models for document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on New Frontiers in Summarization</title>
		<meeting>the Workshop on New Frontiers in Summarization</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning visual question answering by bootstrapping hard attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Attention-aware deep reinforcement learning for video face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3931" to="3940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prithviraj</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Galligher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Surprisingly easy hardattention for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhant</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="640" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Order matters: Sequence to sequence for sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Abhinav Gupta, and Kaiming He</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Nonlocal neural networks</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A structural smoothing framework for robust graph comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinar</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2134" to="2142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Revisiting semisupervised learning with graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4800" to="4810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">ST-UNet: A spatiotemporal U-network for graph-structured time series modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05631</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An endto-end deep learning architecture for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI Conference on Artificial Inteligence</title>
		<meeting>AAAI Conference on Artificial Inteligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Psanet: Point-wise spatial attention network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="267" to="283" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
