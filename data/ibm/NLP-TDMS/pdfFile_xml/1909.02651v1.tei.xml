<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Correlation Promoted Shape-Variant Context for Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Shuai</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Qun</forename><surname>Liu</surname></persName>
							<email>eaqliu@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
							<email>gangwang6@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Correlation Promoted Shape-Variant Context for Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Context is essential for semantic segmentation. Due to the diverse shapes of objects and their complex layout in various scene images, the spatial scales and shapes of contexts for different objects have very large variation. It is thus ineffective or inefficient to aggregate various context information from a predefined fixed region. In this work, we propose to generate a scale-and shape-variant semantic mask for each pixel to confine its contextual region. To this end, we first propose a novel paired convolution to infer the semantic correlation of the pair and based on that to generate a shape mask. Using the inferred spatial scope of the contextual region, we propose a shape-variant convolution, of which the receptive field is controlled by the shape mask that varies with the appearance of input. In this way, the proposed network aggregates the context information of a pixel from its semantic-correlated region instead of a predefined fixed region. Furthermore, this work also proposes a labeling denoising model to reduce wrong predictions caused by the noisy low-level features. Without bells and whistles, the proposed segmentation network achieves new state-of-the-arts consistently on the six public segmentation datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation or scene parsing is aimed at classifying every pixel in scene images to one of the predefined categories (e.g., person, car, etc.). It has been a critical element in artificial intelligence and can be applied in many practice applications, such as automatic parking system. The recent success of Deep Neural Networks has greatly improved the performance of semantic segmentation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b10">11]</ref>. Most of state-of-the-arts segmentation networks are based on Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28]</ref> pre-trained on ImageNet <ref type="bibr" target="#b57">[58]</ref>, in which CNNs are employed as the local feature extractor. To achieve robust semantic segmentation, informative high-  <ref type="figure">Figure 1</ref>. Most existing methods model spatial-dependent context with predefined window (e.g., the red rectangle region for pixel A in the second image), which may not provide the specific context information and thus weaken the semantic shape layout. In this work, we propose to aggregate the context information from the semantic-dependent region instead of the spatial-dependent one. level context is necessary. Context provides surrounding information of the object, which helps a better discrimination of the object.</p><p>However, due to the diverse shapes (including contours, scales, etc) and the complex layout of objects in scene images, the common context aggregated within a predefined fixed region weakens the semantic shape layout and might bring unnecessary irrelevant information. For example in <ref type="figure">Figure 1</ref>, contexts of pixel A (lake) and pixel B (train) should be different but the predefined receptive fields to collect their contexts largely overlap, which decrease their discriminative power. Meanwhile, not all information in a predefined surrounding region (rectangle region in the second image) is beneficial for their final parsing. Information collected in the semantic correlated region is more helpful to identify the object while that in an irrelevant region, though spatially close, may result in parsing error and hence should be suppressed or even disregarded. For pixel A in <ref type="figure">Figure 1</ref>, information of pixels belonging to the lake and its shore, which are semantic correlated, might be more beneficial than information of other pixels in the predefined fixed window. And for pixel B, the desirable shape of context would align with the train and railroad track. Besides, uniformly integrating smooth global information would degrade the location identity and the local discriminative features <ref type="bibr" target="#b68">[69]</ref>. Therefore, for better scene parsing, diverse shapes of semantic consistent context should be customized. Most existing methods tend to model statistical average representation among a fixed rectangle region <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b70">71]</ref> or the global region <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b29">30]</ref>. In this work, by taking into account the semantic correlation and the shape layout of objects, we propose a shape-variant context model to aggregate the surrounding information of each pixel from their semantic-correlated region inferred according to the appearance of input image.</p><p>To this end, we propose first to learn the relation between a target pixel and others by a novel paired convolution followed by a Gaussian mapping function. The learnt network produces higher value for two pixels with stronger semantic correlation and lower value for weaker correlation. Thus, the proposed network will generate a shape mask indicating a semantic correlated region for each pixel. With the shape mask specifying the size and shape of desirable receptive field, we further propose a shape-variant convolution to aggregate context from semantic-dependent region. The shape-variant convolution is specified by a set of learnable location-invariant convolution parameters and the location-variant shape masks. Thus, the parameters are dependent variables of the semantic correlated region of input image, which change with varying shapes and scales of objects. Furthermore, since the shape-variant context is implicitly scale-variant, we can model not only multi-shape but also multi-scale information in a single layer instead of paralleled <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b70">71]</ref> or stacked <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b17">18]</ref> multi-layers. From a macro perspective, the proposed approach helps control the information flow within network through learning the semantic and spatial relationship of features and determine the information passing or suppression.</p><p>The proposed scale-and shape-variant context model enhances the discriminative power of the high level features. Higher level features are more robust to noise than lower level features at a price of lower spatial position sensitivity. Thus, many segmentation networks also aggregate lowlevel features to improve the position accuracy of the segmentation <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref>. However, aggregating lowlevel features, though helps to recover spatial information, may bring some debatable noise sensitive information that leads to a wrong classification of some pixels. Thus, we propose a model that utilizes the higher level features to attenuate the noisy information of the low-level features before aggregating them, i.e. signals denoising. In such a way, the network could better exploit the advantages of low-level features by alleviating their problems.</p><p>In summary, this paper makes the following contributions: 1) we propose a novel paired convolution to infer the semantic correlation of two pixels and based on that to generate a semantic-correlated region for each pixel; 2) we propose a shape-variant context aggregated within the semantic-correlated region to model the diverse shapes and scales of contexts, which greatly enhances the modeling ability of network; 3) we propose a labeling denoising model to reduce the labeling errors caused by the noisy low-level features; 4) we achieve new state-ofthe-art performance consistently on six public semantic segmentation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Recently, Deep Neural Networks has achieved great success on computer vision <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b64">65]</ref>. Based on the Fully Convolutional Network (FCN) <ref type="bibr" target="#b50">[51]</ref>, in which the fully connected layers in original CNNs are converted to convolutional layers, a lot of approaches, e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b60">61]</ref>, are proposed to improve the performance of semantic segmentation.</p><p>Contextual features modeling plays an important role in scene parsing. <ref type="bibr" target="#b51">[52]</ref> shows that global spatial information helps enforce the features consistency. DeepLab <ref type="bibr" target="#b8">[9]</ref> proposes atrous spatial pyramid pooling (ASPP) to aggregate multi-scale image representations from parallel branches with different dilated rate. DilatedNet <ref type="bibr" target="#b72">[73]</ref> appends several dilated convolution layers after the score maps to perform multi-scale context aggregation. DAG-RNN <ref type="bibr" target="#b61">[62]</ref> and Byeon <ref type="bibr" target="#b5">[6]</ref> propose to model long-range context through recurrent neural networks. Zoom-out <ref type="bibr" target="#b52">[53]</ref> proposes a feed-forward architecture to extract hierarchical zoom-out features. CRF-RNN <ref type="bibr" target="#b76">[77]</ref> uses recurrent layers for jointly end-to-end training the dense CRFs <ref type="bibr" target="#b35">[36]</ref> with their segmentation networks. Piecewise <ref type="bibr" target="#b43">[44]</ref> formulates CNN-based pairwise potential functions to capture patch-patch context and designs image pyramid input for patch-background context. PSPNet <ref type="bibr" target="#b74">[75]</ref> introduces pyramid spatial pooling (PSP) to perform different-region-based global information aggregation. Recently, CCL <ref type="bibr" target="#b17">[18]</ref> proposes a context contrasted local model to parallelly collect local and its surrounding information. EncNet <ref type="bibr" target="#b73">[74]</ref> encodes semantic context to network and stress class-dependent feature maps.</p><p>Different from previous methods, in this work, we try to aggregate context information from semantic-closer region but suppress irrelevant information even in the spatialcloser region. We propose a shape-adaptive convolutional layer to learn diverse shaped contexts whose shapes are determined by the object shape, scale and its surrounding support of the input image. The proposed approach is aimed at not only retaining the location identity and layout infor- mation but also building the effective semantic correlation shown in the training images.</p><p>Label variety is another challenging problem in semantic segmentation. PSPNet <ref type="bibr" target="#b74">[75]</ref> observes the confusion categories and demonstrates that the PSPNet can better address the confusion labels than FCN <ref type="bibr" target="#b50">[51]</ref>. Geng et al. <ref type="bibr" target="#b19">[20]</ref> propose to infer the discriminative confusing groups from a prior confusion matrix. DFN <ref type="bibr" target="#b71">[72]</ref> introduces a smooth and border network to tackle confusing classes. Davis et al. <ref type="bibr" target="#b16">[17]</ref> propose to refine the parsing results using Bayesian strategy with confusion probabilities and label priors. Huang et al. <ref type="bibr" target="#b28">[29]</ref> propose a LabelReplacement network to correct the error predictions. Different from these methods, we propose a learnable Labeling Denoising (LD) model to solve the problems of confusion labels by utilizing the robust higher level features to attenuate the noise in lower level features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Proposed Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Semantic Correlation Dependent Context</head><p>Semantic Segmentation needs to simultaneously deal with object recognition and localization, and hence should build the dense feature connections among large region as well as retain the location identity. Meanwhile, due to the diverse shapes and complicated layout of objects in scene images, the scales and shapes of contexts for different objects are supposed to have very large variation.</p><p>Many existing context modeling methods tend to aggregate surrounding information with a fixed size of rectangle window across all locations, which weaken the location identity and might not be able to effectively represent the diverse shapes and scales of objects in scene images. Different from previous works, we put forward that the more desirable context region should be shape-variant according to the shape of the object and its background that support the object. For example, for pixels belong to the train in <ref type="figure" target="#fig_1">Figure 2</ref>, the more beneficial context should be the surrounding information along the railroad track (magenta color), which are closer in semantics than in space. In a word, for different pixel positions, surrounding information should be collected from semantic correlated region that supports the existence of the correct class of this pixel.  Therefore, in this work, we propose a semantic correlation dependent shape-variant context (SVC) to model diverse shape/scale contexts with location identity. In the SVC, context aggregation is controlled by a semantic correlation mask, specifying where the information should be collected with what extent. With the semantic mask, features in semantic correlated regions are boosted and other irrelevant ones are suppressed. Thus, better context information for parsing of each pixel is aggregated within the specific shape region that supports the existence of the correct class of the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learn the Semantic Correlation</head><p>The shape masks that represent semantic correlation trim the context shapes and decide where the information should be collected with what extent. Next we discuss how to learn the semantic correlation, i.e. how to generate the semantic shape masks. Each value in a shape mask represents the correlation of the corresponding pixel to the target pixel (the center pixel of the mask). Thus, the semantic relationship of each pixel with the target pixel need be learned and injected to the corresponding position in the shape mask. To this end, we introduce a paired convolution, as shown in <ref type="figure" target="#fig_3">Figure 3</ref>, in which a pair of 3×3 local convolution with specific relative position are employed to learn the semantic and spatial correlation of the corresponding pixel with the target pixel (the central dark pixel in <ref type="figure" target="#fig_3">Figure 3</ref>). In each filter of the paired convolution, there are a central convolution for the target pixel and another convolution whose position corresponds to the position in shape mask for the corresponding pixel. We have observed and hence assumed that the feature appearances of pixels belonging to the same object and its context will show strong correlation because they frequently coexist in the training images. Therefore, the difference of the two convolution outputs D i,j m,n can be minimized for two pixels belonging to the same object and its context by learning the convolution parameters from the training images.</p><formula xml:id="formula_0">D i,j m,n = F i,j * Θ m,n 0,0 − F i−m,j−n * Θ m,n m,n<label>(1)</label></formula><p>where * donates the local convolution operator, D i,j m,n represents the convolution output discrepancy of (i−m, j − n) to target position (i, j), F i,j and F i−m,j−n are local features at position (i, j) and (i − m, j − m), Θ m,n 0,0 and Θ m,n m,n are corresponding parameters of two local kernels in the paired convolution. As there might be negative or positive difference, we map it to the value of our context shape mask by a Gaussian function:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shape-Variant Context</head><formula xml:id="formula_1">H W S SV Conv P ix e l A K K Paired Conv H W D P ix e l A H W F H x W . . . M a s k A M a s k A Reshape S = K x K . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S h a p e M a s k s</head><formula xml:id="formula_2">M i,j m,n = ϕ(D i,j m,n )<label>(2)</label></formula><p>where ϕ(a)=exp(− a 2 σ 2 ), which maps the convolution output discrepancy to a semantic correlation value. A smaller discrepancy generates a higher semantic correlation value. M i,j m,n is the mask value at position (m, n) in the semantic shape mask of pixel (i, j). Note that the result is not sensitive to σ as the parameters of the two convolutions are learnt. We use σ = 3 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shape-Variant Context</head><p>The goal of shape-variant context is to customize a desirable shape/scale of context for each pixel instead of a simple smooth context information. To achieve this, we further propose a shape-variant convolution (SV Conv) to adaptively collect the surrounding information. The parameters of shape-variant convolution consists of locationinvariant learnable convolution parameters and semantic shape mask inferred by the proposed paired convolution. The shape mask is used to control the receptive field of the convolution process for each position according to the semantic correlation. Such shape mask crops the convolution kernels into different shapes/scales and leads to a shape-variant convolution operation. In such a way, the proposed method greatly enhances the network modeling ability of diverse shape context.</p><p>The proposed shape-variant context is shown in <ref type="figure" target="#fig_4">Figure  4</ref>. There are two branches, the bypass is designed to learn the semantic correlation, whose outputs are then input to the shape-variant convolution (SV Conv) to provide the semantic shape mask. In detail, the side branch employs paired convolution to learn from the local feature F from a pre-trained CNN the correlations of each pixel with each of all other pixels within the kernel of size K×K centered at this pixel, as described in Eq. (1) and Eq. (2). The number of the output channels is S=K×K where K×K is the kernel size of the proposed shape-variant convolution. The semantic shape masks inferred form input features are employed to weight the normal learnable convolutions (F filters) parameterized by θ d,f m,n of the main branch by:</p><formula xml:id="formula_3">θ i,j,d,f m,n = M i,j m,n θ d,f m,n<label>(3)</label></formula><p>where θ d,f m,n ∈Θ is the convolution parameter for d th input channel at position (m, n) of the f th normal locationinvariant learnable filter, d∈(1, 2..., D) and f ∈(1, 2..., F ). The filter kernel size is K×K and (i, j) is the index of feature map position across all the H×W positions. By Eq. <ref type="formula" target="#formula_3">(3)</ref>, the receptive field of the F normal learnable convolutions parameterized by θ d,f m,n is transformed from a fixed size of K×K to effectively different sizes and shapes for different pixels (i, j) determined by the proposed semantic shape masks M i,j m,n . The resulting F shapevariant filters are employed to generate variegated shape context for each spatial position (i, j):</p><formula xml:id="formula_4">F i,j,f = D d=1 K1 m=−K1 K1 n=−K1θ i,j,d,f m,n F i−m,j−n,d<label>(4)</label></formula><p>where K 1 =(K − 1)/2 and F i−m,j−n,d ∈ F. F i,j,f ∈ F is one target contextual feature map. In such a way, M i,j m,n instructs how to collect F i−m,j−n for F i,j during convolution. All of these functions are differentiable and its back-propagation is easy to derive.</p><p>The standard convolutional operation is location invariant and do not vary with testing images after training. Thus, it could not customize different shapes/scales of context information for different objects of input images. The proposed SV Conv consists of a learnable location-invariant convolution and a location-variant semantic shape mask inferred from the input image. The former is to model the statistical average of the spatial-channel distribution and the latter is to determine the size and shape of the convolution receptive field. They together function as a shape-variant operator to better model the shaped context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling Diverse Shapes in a Single Layer</head><p>Due to the diverse shapes/scales of contextual regions and the shape constraint of convolutional kernels, it is difficult to use a single normal convolutional layer to effectively model shape-variant context because the scope of the context, including its scale and contour, dramatically changes for different objects of input images. With the proposed shape-variant semantic correlation masks, convolution regions with diverse shapes and scales are specified and thus we could model multi-shape and multiscale information in a single layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with State-of-the-art Context Models</head><p>Different from the previous context methods that tend to model statistical average representation within a predefined rectangle region, e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b55">56]</ref>, the proposed approach utilizes the semantic correlation and intentionally picks up the relevant information according to the semantic shape mask inferred by the feature appearance of testing image. Thus, it could not only retain the shape and location identity but also effectively build the beneficial connection among correlated features for classification. Comparing with the deformable convolution <ref type="bibr" target="#b15">[16]</ref>, the objective of the proposed approach is similar to it in terms of collecting the relevant information in the convolution. However, different from <ref type="bibr" target="#b15">[16]</ref> that tries to achieve this via deforming the sampling locations, the proposed SVC finds out the semantic correlation to enhance or attenuate the corresponding information, explicitly leading to the shape-and scale-variant modeling. The criteria or the methods to find the relevant information in the two approaches are also different. Furthermore, our method models diverse shapes of semantic-dependent context in a single layer without stacking layers in <ref type="bibr" target="#b15">[16]</ref>, and avoids the "atrous" in deformable convolution that may lose some detailed information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Labeling Denoising</head><p>Due to the label variety and the complicated correlation among labels in segmentation datasets, regular errors can be found in the results of most state-of-the-arts segmentation networks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b42">43]</ref>. These regular errors could be categorized into "in-context" error and "out-context" error, as show in <ref type="figure">Figure 5</ref>. The "in-context" error is mainly caused by inaccurate positioning and inter-context influence while the "out-context" error is mainly caused by inaccurate classification. The proposed shape-variant context aggregates information from specific semantic correlated region, which helps mitigate the in-context and out-context labeling errors. To get elaborate spatial information, lowerlevel features from middle layers of CNNs are important in the encoder-decoder architecture <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref> as they contain more information about where these objects are <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b50">51]</ref>. But these low-level features also bring debatable noisy information that results in out-context errors. In contrast, the high-level features, e.g., the shape-variant context in this work, though less sensitive to the spatial location, are more robust to noise and more aware of what categories existing in a scene image. To better combine "what" and "where", we propose a labeling denoising (LD) model in this work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head><p>Labeling Errors Ground Truth <ref type="figure">Figure 5</ref>. In-context error, e.g., the first row, refers to incorrect labeling within the label set of the image. Out-context error, e.g., the second row, refers to incorrect labeling outside the label set of the image. that attenuates the noise information when extracting lowlevel spatial information from middle layers. The labeling denoising model first infers the existence potential of each category from a higher-level block and learns penalty scores from the existence potentials. Then, the score maps generated from a lower-level block are charged by the penalty scores. Using the penalty scores learnt from the higher-level block, the scores of nonexistent categories of an input image generated by the lower-level block are greatly suppressed. First, the existence potential is inferred by the score maps from a higher-level block by:</p><formula xml:id="formula_5">E k = F g (F sf (S k ))<label>(5)</label></formula><p>where S k is the score maps from a higher-level (level k) block, F sf is softmax and F g is global max pooling. E k = (e 1 k , ..., e c k , ..., e C k ) and e c k is the existent potential for class c inferred by level k. Then, the penalty P c is learnt by:</p><formula xml:id="formula_6">P c k = ReLU(T − e c k )∆ c k (6)</formula><p>where T is a penalty threshold and ∆ c k is a learnable penalty parameter. The penalty threshold and function ReLU are used to keep the score distribution of existent classes unchanged. The penalty P c k is used to modify the score map of its next lower-level block before aggregating it into the upsampled score map of its next higher-level block as:</p><formula xml:id="formula_7">S c k−1 = ReLU(Ŝ c k−1 − P c k ) + S c k<label>(7)</label></formula><p>whereŜ c k−1 is the score map of class c directly from the lower-level block. S c k−1 is the denoised and aggregated score map from the highest level to the level k − 1, which is further used to modify and be aggregated to the score maps of the lower-level blocks as Eqs (5), <ref type="bibr" target="#b5">(6)</ref>, and <ref type="bibr" target="#b6">(7)</ref>. The proposed labeling denoising (LD) model is shown in <ref type="figure">Figure 6</ref>. In such a way the network could take advantage of both high-level features and low-level features, i.e. better combine "what" and "where". For the skip layers from  <ref type="figure">Figure 6</ref>. Network Architecture. We use ResNet-101 as our base model for fine-tuning and FCN-4s as the backbone segmentation framework. LD is used in decode process for denoising.</p><p>low-level features, the scores of nonexistent categories in an input image are attenuated and those of the existent categories are retained and supplemented to score maps for positioning enhancement. As this mechanism is included in the end-to-end training process, less noisy scores are taken into account during training, and gradients for training such noisy information could be saved for other things such as positioning. The proposed approach could also be viewed as some kind of dropout, which applies dropout to connections that reach some conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate the proposed approach on six public benchmark, COCO-Stuff, SIFT-Flow, CamVid, PASCAL-Person-Part, PASCAL-Context, and Cityscapes. We use ResNet-101 <ref type="bibr" target="#b25">[26]</ref> pre-trained on ImageNet <ref type="bibr" target="#b57">[58]</ref> as our base model for fine-tuning and FCN-4s as the backbone framework. During training, the proposed Network is trained end-toend using standard SGD with batch size 8, fixed momentum 0.9 and weight decay 0.0005. Data augmentations like random flipping, random resize between 0.8 and 1.2 and mean subtraction are used in training. Inspired by <ref type="bibr" target="#b8">[9]</ref>, we use the "poly" learning rate and set the initial learning rate to 5 × 10 −3 for newly initialized parameters and 10 −4 for parameters of pretrained layers, the power is set to 0.9. Batch Normalization <ref type="bibr" target="#b30">[31]</ref> is used in new added layers to accelerate training process. The performance is evaluated by standard pixel accuracy (pixel acc.), mean class accuracy (mean acc.) and mean Intersection-over-Union (mean IoU). Please refer to <ref type="bibr" target="#b50">[51]</ref> for mathematical definitions.</p><p>To model diverse semantic shapes in a single layer, larger kernel is required due to the dramatic changed shapes/scales of objects. But very large kernel is resource-intensive and difficult to converge. To address this issue, we modify Eq. (4) of the proposed SVC similar to the depthwise separable convolution <ref type="bibr" target="#b12">[13]</ref>. The simplified computation of Eq. (4) allows us using large kernel size to model the diverse shapes in spatial space followed by a pointwise convolution to learn the cross-channel correlation. And in labeling denoising model, we use ascending penalty thresholds T = t, 2t, 4t, from the highest to the lowest blocks, where t = 1 C and C is the number of classes.  <ref type="table">Table 2</ref>. Ablation study of the proposed shape-variant context (SVC) approach by comparing it with the shape-fixed context (SFC) on different kernel size. It also shows that the performance gain is not simply brought by the increased number of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ablation Study</head><p>In this section we do ablation studies of the proposed shape-variant context (SVC) and labeling denoising (LD). As shown in <ref type="table" target="#tab_0">Table 1</ref>, comparing the performance gain brought by the proposed LD on PASCAL-Conext (59 classes) and COCO-Stuff (171 classes), we can conclude that the LD could mitigate noisy prediction and it works better on datasets with more semantic categories. This is not a surprise because more categories cause heavier prediction noise and hence the LD works more effectively. <ref type="table" target="#tab_0">Table 1</ref> shows the significant performance gain (7 percent on COCO-Stuff and almost 10 percent on PASCAL-Context) from the baseline by applying the proposed SVC.</p><p>To further study where the performance gain of the proposed SVC comes from, we compare it with the shape-fixed context (SFC) that is implemented by setting a constant shape mask, i.e., M i,j m,n =1 in Eq. (3). We compare them on PASCAL-Context with different kernel sizes shown in <ref type="table">Table 2</ref>, where the 0×0 means the baseline without the context layer. As we employ just a single layer to capture the context information, all kernels used in <ref type="table">Table 2</ref> are larger than convolutional kernels of most other work so that diverse shapes and scales of contextual information could be modelled in a single layer. <ref type="table">Table 2</ref> shows that with the increase of kernel size, the segmentation performance improves up to a certain level then slightly drops with further increase of the kernel size. This is because the network lose too much locality information in overlarge kernel situation. It also shows that a simple increase of the network parameters may not always improve the performance. <ref type="table">Table 2</ref> shows that the proposed SVC significantly outperforms the SFC at all different kernel sizes. It is also not a surprise that the best performance of the SVC is achieved at the kernel size (23×23), much larger than that of the SFC (15×15) because the proposed SVC provides diverse shape context, which is implicitly multiscale with better location identity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Visualization of the semantic shape mask</head><p>As <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table">Table 2</ref> show the significant performance gains brought by the proposed shape-variant context (SVC) that is determined by the proposed shape mask M i,j m,n , it is worthwhile to further study how the mask captures the shape of the context by visualizing it. Four examples of the shape mask M i,j m,n generated at four different locations of two testing images by the learned network are shown in <ref type="figure" target="#fig_6">Figure 7</ref>. The first is the mask of the center of a car. It has higher values at pixels of cars and road as they contains the context information of the center of the car. The second is the mask of some pixel of the cow in the middle of a road. It has higher values at pixels of cows and grass, though they are far away from the target cow and separated by the road. Values of the second mask are low in the area of road as it does not show correlation with the cow in the training database. Consistently, the semantic correlation of the context is also shown by the third and fourth masks respectively for a train and a railway in the second testing image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with the State-of-the-Arts</head><p>The proposed semantic segmentation network is named as SVCNet and we compare it with the state-of-the-arts on six public benchmark, COCO-Stuff, SIFT-Flow, CamVid, PASCAL-Person-Part, PASCAL-Context, and Cityscapes. Before the quantitative comparison, some qualitative results of the proposed SVCNet are shown in <ref type="figure" target="#fig_7">Figure 8</ref>. COCO-Stuff <ref type="bibr" target="#b6">[7]</ref> provides dense pixel-wise annotations for 171 semantic categories. There are 9000 images used for training and 1000 images used for testing. Quantitative results of COCO-Stuff are shown in      <ref type="table">Table 7</ref>. PASCAL-Context testing accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods mean IoU</head><p>Deeplab-v2 <ref type="bibr" target="#b8">[9]</ref> 70.4 RefineNet-Res101 <ref type="bibr" target="#b42">[43]</ref> 73.6 DSSPN-Universal <ref type="bibr" target="#b40">[41]</ref> 76.6 GCN <ref type="bibr" target="#b55">[56]</ref> 76.9 DepthSet <ref type="bibr" target="#b34">[35]</ref> 78.2 PSPNet <ref type="bibr" target="#b74">[75]</ref> 78.4 AAF <ref type="bibr" target="#b33">[34]</ref> 79.1 DFN <ref type="bibr" target="#b71">[72]</ref> 79.3 PSANet <ref type="bibr" target="#b75">[76]</ref> 80.1 DenseASPP-DenseNet161 <ref type="bibr" target="#b70">[71]</ref> 80.6</p><p>SVCNet (ours) 81.0 arts by a large margin on this small dataset, which indicates that the the proposed approach could be trained very well even on small dataset. PASCAL-Context <ref type="bibr" target="#b53">[54]</ref> provides pixel-wise segmentation annotation for 59 classes. There are 4998 training images and 5105 testing images. Quantitative results of Pascal Context are shown in <ref type="table">Table 7</ref>. It shows that the proposed SVCNet outperforms the state-of-the-arts by a large margin.</p><p>Cityscapes <ref type="bibr" target="#b13">[14]</ref> contains 5000 street scene images with pixel-level fine annotations and 19 classes are considered for evaluation. There are 2975 training images, 500 validation images and 1525 testing images. The test results are shown in <ref type="table" target="#tab_6">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we propose to aggregate the context information based on the semantic correlation rather than the predefined spatial-dependent window to collect more effective and discriminative surrounding information for semantic segmentation. The semantic-correlated information even at a far away spatial location will be enhanced and the semantic-uncorrelated information even at a close spatial location will be suppressed in collecting the context information. To this end, we first propose a novel paired convolution to learn the feature semantic-correlation from the training images and to infer it of the query image. This generates a semantic shape mask at each position of the image. Based on it, we propose a shape-variant convolution, in which the receptive field of the convolution is specified by different semantic shape masks at different positions of different query images. The semantic shape masks form diverse scales and shapes of the convolution receptive field to aggregate discriminative context information effectively. Furthermore, to ease the labeling errors, we propose a labeling denoising model, which utilizes more robust higher-level features to attenuate the prediction errors caused by noisier lower-level features. Without bells and whistles, the proposed segmentation network achieves new state-of-the-arts consistently on the six public semantic segmentation datasets, COCO-Stuff, SIFT-Flow, CamVid, PASCAL-Person-Part, PASCAL-Context, and Cityscapes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(Best viewed in color) We propose a novel semantic correlation dependent shape-variant context, which boosts the semantic-correlated features (magenta color) while suppresses the others (white color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>(Best viewed in color) A shape mask is inferred by the Paired Convolution and Gaussian mapping function ϕ, which are designed to learn the semantic correlation between the target pixel and other pixels within the shape mask. Here we show an example of 4 values in a 11×11 mask of the target pixel (dark), in which 4 mask values are generated by the 4 filters of the same color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Semantic correlation-dependent shape-variant context aggregates surrounding information according to the semantic correlation and hence customizes an effective contextual region. It helps control the information flow within network via deciding what information to be passed or suppressed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Four visual examples of the shape-variant masks M i,j m,n generated at four different locations of two testing images by the learned network. The mask center (i, j) is indicated by the small square and its value at (m, n) within the image is shown by the gray level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Qualitative segmentation examples on COCO-Stuff (1st-4th rows) and PASCAL-Context (5th-7th rows).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Ablation study of the proposed approach in terms of IoU.</figDesc><table><row><cell>Methods</cell><cell cols="2">PASCAL-Context COCO-Stuff</cell></row><row><cell>Baseline</cell><cell>42.7</cell><cell>31.5</cell></row><row><cell>Baseline+SVC</cell><cell>52.4</cell><cell>38.5</cell></row><row><cell>Baseline+SVC+LD</cell><cell>53.2</cell><cell>39.6</cell></row><row><cell>Kernel Size</cell><cell>SFC</cell><cell>SVC</cell></row><row><cell>0 × 0</cell><cell>42.7</cell><cell>42.7</cell></row><row><cell>7 × 7</cell><cell>45.6</cell><cell>48.5</cell></row><row><cell>11 × 11</cell><cell>46.6</cell><cell>49.4</cell></row><row><cell>15 × 15</cell><cell>47.1</cell><cell>51.2</cell></row><row><cell>19 × 19</cell><cell>47.0</cell><cell>52.1</cell></row><row><cell>23 × 23</cell><cell>46.7</cell><cell>52.4</cell></row><row><cell>27 × 27</cell><cell>46.5</cell><cell>52.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>The proposed</figDesc><table><row><cell>Methods</cell><cell cols="3">pixel acc. mean acc. mean IoU</cell></row><row><cell>FCN [7]</cell><cell>52.0</cell><cell>34.0</cell><cell>22.7</cell></row><row><cell>DeepLab [8]</cell><cell>57.8</cell><cell>38.1</cell><cell>26.9</cell></row><row><cell>FCN-8s [51]</cell><cell>60.4</cell><cell>38.5</cell><cell>27.2</cell></row><row><cell>DAG-RNN+CRF [62]</cell><cell>63.0</cell><cell>42.8</cell><cell>31.2</cell></row><row><cell>DC+FCN+ [27]</cell><cell>65.5</cell><cell>44.6</cell><cell>33.6</cell></row><row><cell>Deeplab-V2 [9]</cell><cell>65.1</cell><cell>45.5</cell><cell>34.4</cell></row><row><cell>CCL-ResNet101 [18]</cell><cell>66.3</cell><cell>48.8</cell><cell>35.7</cell></row><row><cell>DSSPN [41]</cell><cell>68.5</cell><cell>48.1</cell><cell>36.2</cell></row><row><cell>SVCNet (ours)</cell><cell>69.2</cell><cell>51.5</cell><cell>39.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>COCO-Stuff testing accuracies.</figDesc><table><row><cell>Methods</cell><cell cols="3">pixel acc. mean acc. mean IoU</cell></row><row><cell>Liu et al. [46]</cell><cell>76.7</cell><cell>-</cell><cell>-</cell></row><row><cell>Tighe et al. [66]</cell><cell>75.6</cell><cell>41.1</cell><cell>-</cell></row><row><cell>Farabet et al. [19]</cell><cell>78.5</cell><cell>29.6</cell><cell>-</cell></row><row><cell>Pinheiro et al. [57]</cell><cell>77.7</cell><cell>29.8</cell><cell>-</cell></row><row><cell>Sharma et al. [59]</cell><cell>79.6</cell><cell>33.6</cell><cell>-</cell></row><row><cell>Yang et al. [70]</cell><cell>79.8</cell><cell>48.7</cell><cell>-</cell></row><row><cell>FCN-8s [60]</cell><cell>85.9</cell><cell>53.9</cell><cell>41.2</cell></row><row><cell>DAG-RNN+CRF [62]</cell><cell>87.8</cell><cell>57.8</cell><cell>44.8</cell></row><row><cell>Piecewise [44]</cell><cell>88.1</cell><cell>53.4</cell><cell>44.9</cell></row><row><cell>SVCNet (ours)</cell><cell>89.1</cell><cell>58.2</cell><cell>46.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>SIFT-Flow testing accuracies.</figDesc><table><row><cell>Methods</cell><cell>mean IoU</cell></row><row><cell>DeconvNet [55]</cell><cell>48.9</cell></row><row><cell>SegNet [2]</cell><cell>50.2</cell></row><row><cell>DeepLab [8]</cell><cell>54.7</cell></row><row><cell>DilatedNet [73]</cell><cell>65.3</cell></row><row><cell>Dilation+FSO [38]</cell><cell>66.1</cell></row><row><cell>FC-DenseNet [33]</cell><cell>66.9</cell></row><row><cell>G-FRNet [32]</cell><cell>68.0</cell></row><row><cell>DenseDecoder [3]</cell><cell>70.9</cell></row><row><cell>SVCNet (ours)</cell><cell>75.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>CamVid.</figDesc><table><row><cell>Methods</cell><cell>mean IoU</cell></row><row><cell>Attention [10]</cell><cell>56.4</cell></row><row><cell>HAZN [68]</cell><cell>57.5</cell></row><row><cell>LG-LSTM [40]</cell><cell>58.0</cell></row><row><cell>Graph LSTM [39]</cell><cell>60.2</cell></row><row><cell>DeepLab [8]</cell><cell>62.8</cell></row><row><cell>DeepLab-V2 [9]</cell><cell>64.9</cell></row><row><cell>RefineNet [43]</cell><cell>68.6</cell></row><row><cell>DenseDecoder [3]</cell><cell>68.6</cell></row><row><cell>SVCNet (ours)</cell><cell>73.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>PASCAL-Person-Part.</figDesc><table><row><cell>SVCNet outperforms the previous state-of-the-arts across</cell></row><row><cell>all evaluation metrics.</cell></row><row><cell>SIFT-Flow [45] contains 2688 images annotated with 33</cell></row><row><cell>semantic classes. There are 2488 training images and 200</cell></row><row><cell>testing images. Quantitative results are shown in Table 4.</cell></row><row><cell>The proposed SVCNet outperforms previous state-of-the-</cell></row><row><cell>arts across all evaluation metrics.</cell></row><row><cell>CamVid [4] is a road scene image segmentation dataset</cell></row><row><cell>which provides dense pixel-wise annotations for 11 seman-</cell></row><row><cell>tic categories. There are 367 training images, 101 validation</cell></row><row><cell>images and 233 testing images. The testing results are</cell></row><row><cell>shown in Table 5. It shows that the proposed SVCNet</cell></row><row><cell>outperforms previous state-of-the-arts by a large margin.</cell></row><row><cell>PASCAL-Person-Part [12] provides pixel-level labels for</cell></row><row><cell>six person parts. There are 1717 training/validation images</cell></row><row><cell>and 1818 testing images. Quantitative results of PASCAL-</cell></row><row><cell>Person-Part are reported in Table 6. It shows that the</cell></row><row><cell>proposed SVCNet outperforms the previous state-of-the-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 .</head><label>8</label><figDesc>Cityscapes testing accuracies.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research is supported by Singapore Ministry of Education Academic Research Fund Grant no: 2015-T1-002-140, MOE Tier 1 RG 123/15. It is also supported by the BeingTogether Centre, a collaboration between Nanyang Technological University (NTU) Singapore and University of North Carolina (UNC) at Chapel Hill. The BeingTogether Centre is supported by the National Research Foundation, Prime Ministers Office, Singapore under its International Research Centres in Singapore Funding Initiative. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
		<title level="m">Higher order conditional random fields in deep neural networks. In ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dense decoder shortcut connections for single-pass semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bilinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Prisacariu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Segmentation and recognition using structure from motion point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Brostow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Fauqueur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Loss max-pooling for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S Rota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Neuhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scene labeling with lstm recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonmin</forename><surname>Byeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Raue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cocostuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attention to scale: Scale-aware semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02611</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detect what you can: Detecting and representing objects using holistic models and body parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A classification refinement strategy for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Menart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Akbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07674</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Context contrasted feature and gated multiscale aggregation for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camille</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A network structure to explicitly reduce confusion errors in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qichuan</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.00313</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Laplacian pyramid reconstruction and refinement for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unpaired image captioning by language pivoting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiuxiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recent advances in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiuxiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Kuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scene graph generation with external knowledge and image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiuxiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Handong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyang</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hypercolumns for object segmentation and fine-grained localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Labelbank: Revisiting global perspectives for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang-Tong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09891</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Error correction for dense semantic image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Hui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.03812</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scene parsing with global context embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gated feedback refinement network for dense image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrigank</forename><surname>Md Amirul Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rochan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Drozdzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPRW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adaptive affinity fields for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyh-Jing</forename><surname>Tsung-Wei Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recurrent scene parsing with perspective understanding in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected crfs with gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Feature space optimization for semantic video segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semantic object parsing with graph lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Semantic object parsing with local-global long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglai</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dynamicstructured semantic propagation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multi-scale context intertwining for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient piecewise training of deep structured models for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dan Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Nonparametric scene parsing: Label transfer via dense scene alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Sift flow: Dense correspondence across scenes and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Feature boosting network for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling-Yu</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">Kot</forename><surname>Chichung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Semantic image segmentation via deep parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning markov clustering networks for scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weisi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><forename type="middle">Ling</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Towards robust curve text detection with conditional spatial expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weisi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><forename type="middle">Ling</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Are spatial and global constraints really necessary for segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Boix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Feedforward semantic segmentation with zoom-out features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Mostajabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Payman</forename><surname>Yadollahpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The role of context for object detection and semantic segmentation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam-Gyu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong-Whan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Large kernel matters -improve semantic segmentation by global convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Recursive context propagation network for semantic scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Toward achieving robust low-level and highlevel scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Scene segmentation with dag-recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Aanet: Attribute attention network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiat-Pin</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharmili</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim-Hui</forename><surname>Yap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Finding things: Image parsing with regions and per-exemplar detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Tighe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Bridging category-level and instance-level semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06885</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Zoom better to see clearer: Human and object parsing with hierarchical auto-zoom net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangting</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Combining the best of convolutional layers and recurrent layers: A hybrid network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04871</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Context driven scene parsing with attention to rare classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Denseaspp for semantic segmentation in street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Learning a discriminative feature network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Ambrish Tyagi, and Amit Agrawal. Context encoding for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Psanet: Point-wise spatial attention network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
		<title level="m">Conditional random fields as recurrent neural networks. In ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
