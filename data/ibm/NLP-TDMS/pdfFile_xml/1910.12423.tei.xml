<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ACE: Adaptive Confusion Energy for Natural World Data Distribution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chi</forename><surname>Hsu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yao</forename><surname>Hong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Cyuan</forename><surname>Fan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Sui</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davi</forename><surname>Geiger</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyng-Luh</forename><surname>Liu</surname></persName>
						</author>
						<title level="a" type="main">ACE: Adaptive Confusion Energy for Natural World Data Distribution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the development of deep learning, standard classification problems have achieved good results. However, conventional classification problems are often too idealistic. Most data in the natural world usually have imbalanced distribution and fine-grained characteristics. Recently, many state-of-the-art approaches tend to focus on one or another separately, but rarely on both. In this paper, we introduce a novel and adaptive batch-wise regularization based on the proposed Adaptive Confusion Energy (ACE) to flexibly address the nature world distribution, which usually involves fine-grained and long-tailed properties at the same time. ACE increases the difficulty of the training process and further alleviates the overfitting problem. Through the datasets with the technical issue in fine-grained (CUB, CAR, AIR) and long-tailed (ImageNet-LT), or comprehensive issues (CUB-LT, iNaturalist), the result shows that the ACE is not only competitive to some state-ofthe-art on performance but also demonstrates the effectiveness of training.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the development of deep learning, the fundamental classification problem has been solved. Subsequent classification studies focus on two more challenging issues, finegrained characteristics, and imbalanced data distribution. Fine-grained visual classification (FGVC) is an active and challenging problem in computer vision. Such a recognition task differs from the classical problem of large-scale visual classification (LSVC) by focusing on differentiating similar sub-categories of the same meta-category. In FGVC, the inter-class similarity among the object categories is often pervasive. The intra-class variations further impose ambiguities in learning a unified and discriminative representation for each category. Long-tailed distribution brings another aspect of the challenge that the head categories tend to dominate the training procedure. Thus, the learned classification model performs better on these categories while yielding significantly poor performance for the tail categories. The performance distribution somewhat resembles the data dis- Intertwined of inter-class similarity and intra-class variation <ref type="figure">Figure 1</ref>. Data distribution is not ideal in the real world and is usually accompanied by more than one complicated issue to be solved. For example, iNaturalist 2018 <ref type="bibr" target="#b37">(Van Horn et al., 2018)</ref> hard to learn the tailed classes due to an extreme imbalanced ratio in the long-tailed distribution. Meanwhile, it is hard to disentangle the inter-class similarity and intra-class variation that results from fine-grained characteristics. Eventually, this leads to overfitting.</p><p>tribution. As the natural world distribution often assumes both fine-grained and long-tailed properties, how to satisfactorily address the recognition problem under such a general setting raises a practical and challenging issue.</p><p>Most of the current visual classification tasks usually only have the challenge in one aspect, such as FGVC or longtailed issues, as mentioned above. However, the data distribution is not always idealistic in the natural world. Comprehensive issues usually accompany it. For instance, <ref type="figure">Figure 1</ref> illustrates two concurrent challenges in the iNaturalist 2018 <ref type="bibr" target="#b37">(Van Horn et al., 2018)</ref>. First, the task is a long-tailed distribution with an extremely imbalanced ratio. Since there is a thousand-fold difference in the number of categories, it is hard to learn the tail classes' representation. Meanwhile, it is also an FGVC task where the inter-class similarity and the intra-class variations are subtly intertwined, yielding a daunting classification task, no matter what orders of magnitude of categories (frequent, common, and rare). That makes the model easy to overfit <ref type="bibr" target="#b8">(Dubey et al., 2018)</ref>. From the existing literature, there are only a few attempts to solve these two problems simultaneously. Relevant efforts mostly focus on tackling either task. In FGVC, most of the recent research efforts have converged to learn pivotal local/part details relevant to distinguishing fine-grained categories e.g., <ref type="bibr" target="#b9">(Fu et al., 2017;</ref><ref type="bibr" target="#b43">Yang et al., 2018;</ref><ref type="bibr" target="#b44">Zheng et al., 2019)</ref>, and typically require the fusion of several sophisticated computer vision techniques to accomplish the task such as in <ref type="bibr" target="#b10">(Ge et al., 2019)</ref>. In resolving the long-tailed issue, previous approaches have looked into data balanced sampling <ref type="bibr" target="#b15">(Huang et al., 2016a;</ref><ref type="bibr" target="#b41">Wang et al., 2017)</ref> and the recent development such as <ref type="bibr" target="#b19">Kang et al. (2020)</ref> learns the representation at the first stage and refines the classifier by balanced data sampling. Different existing tasks have varying degrees of fine-grained and long-tail factor. As shown in <ref type="figure" target="#fig_1">Figure 2</ref> (left), we leverage the maximum imbalanced ratio and the normalized feature cosine similarity between each category as the fine-grained and long-tailed factor to evaluate the characteristic of each task.</p><p>Motivated by these developments, we propose a flexible and effective regularization design that aims at guiding the resulting DNN learning to improve model efficiency on tackling the FGVC and long-tailed issues at the same time. Our method is relevant to the pairwise confusion (PC) <ref type="bibr" target="#b8">(Dubey et al., 2018)</ref>. PC only makes an image confuse with another image, but it does not use the rest sufficiently. Furthermore, while PC encounters imbalanced problems, it offers few improvements. The <ref type="figure" target="#fig_1">Figure 2</ref> (right) shows that those approaches can alleviate the overfitting issue in FGVC fail in overcoming the imbalanced issue and vice versa. In this paper, the proposed formulation goes beyond the restriction of working on pairs of data and develops a batch normbased framework with sufficient model capacity to deal with FGVC and long-tailed issues simultaneously. We first assume all samples/images within a batch are of different classes. A batch-wise matrix norm then models the targeted confusion energy, termed Adaptive Confusion Energy (ACE). The matrix is constructed by including prediction results from all images within a batch and an adaptive matrix to adjust class-specific weights. The former is used to handle the FGVC task or overfitting issue, and the latter is for resolving the long-tailed distribution. To achieve efficient DNN learning, we provide an approximation scheme to ACE so that gradient backpropagation can be readily carried out. The promising experimental results support that ACE has good potential to function as a generic regularizer for solving a wide range of classification tasks, no matter the fine-grained property or imbalanced distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Researches in fine-grained and long-tailed visual classification are going on in two different branches. Most articles focus on just one of these issues. We will introduce recent studies on both sides and then briefly explain our approach.</p><p>FGVC. In the early works, the training data are annotated with additional information such as part labels. Along this line, <ref type="bibr" target="#b0">(Berg et al., 2014)</ref> explore the labeled part locations to eliminate highly similar object categories for improving the learned classifiers. The approach in <ref type="bibr" target="#b17">(Huang et al., 2016b)</ref> is established based on a two-stream classification network to capture both object-level and part-level information explicitly. However, due to the rapid research advances in visual classification, the most recent FGVC approaches are designed to complete the model learning solely based on category labels' information. <ref type="bibr" target="#b34">(Sun et al., 2019;</ref><ref type="bibr" target="#b8">Dubey et al., 2018;</ref><ref type="bibr" target="#b40">Wang et al., 2018;</ref><ref type="bibr" target="#b21">Li et al., 2018;</ref><ref type="bibr" target="#b43">Yang et al., 2018;</ref><ref type="bibr" target="#b44">Zheng et al., 2019;</ref><ref type="bibr" target="#b3">Chen et al., 2019;</ref><ref type="bibr" target="#b7">Du et al., 2020b)</ref>.</p><p>Long-tailed visual recognition To alleviate the impact of the imbalanced data, the two common basic methods are re-sampling and re-weighting. Re-sampling in the early studies includes under-sampling <ref type="bibr" target="#b5">(Drummond et al., 2003)</ref> for head categories and over-sampling <ref type="bibr" target="#b2">(Chawla et al., 2002;</ref><ref type="bibr" target="#b12">Han et al., 2005;</ref><ref type="bibr" target="#b27">Mahajan et al., 2018)</ref> for tail categories. In recently, the most common strategy is called class-balanced sampling <ref type="bibr" target="#b32">(Shen et al., 2016)</ref>. Unlike instance-balanced sampling, every image has the same probability of being selected; class-balanced is to weight the sampling frequency of each image according to the number of samples of different categories. Furthermore, <ref type="bibr" target="#b11">(Gupta et al., 2019)</ref> proposed repeat factor sampling (RFS), a dynamic-sampling mechanism, to balance the instances. Unlike sampling, because of the flexibility and convenience of loss calculation, many more complex tasks, such as object detection and instance segmentation, are more likely to leverage the re-weighted loss to solve the problem of long-tail distribution. From the reverse weighting based on category distribution to the Hard Example Mining <ref type="bibr" target="#b33">(Shrivastava et al., 2016)</ref> which is carried out directly according to the credibility of classification without knowing the category, such as Focal loss  and LDAM <ref type="bibr" target="#b1">(Cao et al., 2019)</ref>. Also, due to implementation is easy, some works <ref type="bibr" target="#b4">(Cui et al., 2019;</ref><ref type="bibr" target="#b18">Jamal et al., 2020;</ref><ref type="bibr" target="#b35">Tan et al., 2020)</ref> show competitive results in complex tasks. On the other way, the two-stage training strategies that learn the classifier with re-balancing data and to learn representation with original data is regarded as an effective solution to the constant tail distribution. <ref type="bibr" target="#b45">Zhou et al., 2020;</ref><ref type="bibr" target="#b14">Hu et al., 2020;</ref><ref type="bibr" target="#b39">Wang et al., 2020;</ref><ref type="bibr" target="#b36">Tang et al., 2020;</ref><ref type="bibr" target="#b42">Yang &amp; Xu, 2020)</ref>.</p><p>Confusion energy. In FGVC, the confusion-related formulation for dealing with intra-class variations and interclass similarity has two main implications. First, it can be applied to alleviate the overfitting problem in training an FGVC model. <ref type="bibr" target="#b8">(Dubey et al., 2018</ref>) construct a Siamese neural network, trained with a loss function including pairwise confusion (PC). The design reasons that bringing the class probability distributions closer to each other could prevent the learned FGVC model from overfitting samplespecific artifacts. Second, the confusion tactic can be used to boost the FGVC performance by focusing on local evidence. <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> partition each training image into several local regions and then shuffle them by a region confusion mechanism (RCM). It implicitly excludes the global object structure information and forces the model to predict the category label based on local information. In other words, the ability to identify the object category from local details is expected to be enhanced through shape confusion.</p><p>Our approach to FGVC and long-tail is most relevant to the above confusion-based approaches. We retain the advan-tages of confusion energy and exploit the potential in the long-tailed distribution. And then propose a novel confusion energy term called Adaptive Confusion Energy (ACE), which can flexibly adjust the confusion strength corresponding to the data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>We propose the adaptive confusion energy (ACE) to address the image classification on data with natural world distribution. Our ACE module combines two novel components: 1) Batch confusion norm (BCN) and 2) adaptive matrix A. We elaborate our method as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overfitting Elimination by Batch Confusion Norm</head><p>Given a training set D over total C fine-grained categories, an arbitrary sample x from D is denoted as (I, y) where I represents an image and y ∈ {1, . . . , C} denotes the corresponding class label. We define a batch B = {x 1 , x 2 , . . . , x M } as a set of sample x i randomly sampled from D. Note that M is the batch size. For each training sample x i in a batch B, we forward propagate it through a classification model Φ and then obtain the predicted probability (i.e., softmax) p i . After that we define batch-wise class prediction matrix P by</p><formula xml:id="formula_0">P = [p 1 p 2 . . . p M ] ∈ R C×M ,<label>(1)</label></formula><p>where p i ∈ R C is the predicted probability over the C fine-grained categories. Notice that, in our BCN module, we assume that M ≤ C and all images within a batch B are randomly sampled from the D. On the contrary, the confusion regularization of PC <ref type="bibr" target="#b8">(Dubey et al., 2018)</ref> only affects the paired images with distinct labels. In a nutshell, BCN considers global optimization in substitution a pair.</p><p>The explicit purpose of BCN is to increase the difficulty for a model to learn classification problems by infusing slight classification confusions into the training procedure. To this end, it is reasonable to minimize the rank of the batchwise class prediction matrix P so that the predictions for all samples in a batch are similar:</p><formula xml:id="formula_1">arg min Φ rank(P ) .<label>(2)</label></formula><p>However, the rank-related minimization problems are often NP-hard. To address this problem, in this paper, we utilize convex relaxation methods to approximate the solutions.</p><p>With the help of convex relaxation methods, minimizing the rank of P can be reduced as the minimization of its nuclear norm. That is the batch confusion norm of P can be formulated as</p><formula xml:id="formula_2">P BCN = P *<label>(3)</label></formula><p>where · * is the nuclear norm which computes the sum of the singular values of the underlying tensor/matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stability.</head><p>In order to make the matrix decomposition of P stable and prevent the negative singular values from heavily affecting the training loss, we replace the right-hand side of (3) with P T P * since it is known that rank(P ) = rank(P T P ).</p><p>Finally, by combining all the technique above, our batch confusion norm can be formulated as</p><formula xml:id="formula_4">P BCN = P T P * .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data imbalance control via adaptive matrix A</head><p>In this subsection, we introduce the adaptive matrix A, which equips the BCN in Sec. 3.1 with the ability to handle imbalanced data and finally evolve into our Adaptive Confusion Energy (ACE).</p><p>Empirically, the classification accuracy of different categories (with various data distribution) depends on different levels of confusion energy. Take the tailed classes with few samples; for example, applying high confusion energy on tailed classes may damage the classification performance.</p><p>To fix this issue, we adopt an adaptive matrix A ∈ R C×C to generalize the BCN. The adaptive matrix A enables the BCN to adjust the strength of confusion energy for each category. Here are a couple of criteria for initializing a proper A:</p><p>• When it comes to a dataset with long-tailed distribution, A should alleviate the confusion energy on the tailed categories to prevent the model from getting excessive confusion over these classes.</p><p>• When the data distribution is balanced, A should be approximately the same as an identity matrix.</p><p>Following these guidelines, we design the adaptive matrix A as</p><formula xml:id="formula_5">A ij = ( Ni µ ) σ τ , i = j 0, i = j ,<label>(6)</label></formula><p>where N i , i ∈ {1, 2, ..., C} represents the number of data for each category. Also, µ = 1</p><formula xml:id="formula_6">C C i=1 N i and σ = 1 C C i=1</formula><p>(N i − µ) 2 denote the mean and standard deviation of N i , respectively. Finally, τ stands for a tunable hyperparameter. Note that when N i −→ µ, we have A ii −→ 1. Also, if σ −→ 0 then A ii −→ 1. This means that A will downgrade to the identity matrix when the data distribution is balanced.</p><p>Finally, by incorporating the batch confusion norm with the adaptive matrix A, we can now formulate our novel adaptive confusion energy (ACE) as follows.</p><formula xml:id="formula_7">L ACE = P T A T AP * ,<label>(7)</label></formula><p>where the adaptive confusion energy loss L ACE is computed based on the eigenvalues of P T A T AP . It is worth noting that our ACE has sufficient capability to handle data with natural world distribution by alleviating the overfitting problem in a fine-grained model and considering the imbalance problem in the long-tailed data distribution.</p><p>Learnability. In practice, there is no feasible way to ensure that the parameters of A given in <ref type="formula" target="#formula_7">(7)</ref> is optimal by pre-defined parameters. Therefore, We alternately use it as a good initialization and set A as a learnable model, denoted asÂ. Consequently, we revise the L ACE intô</p><formula xml:id="formula_8">L ACE = P TÂTÂ P * + η Â − A 2 ,<label>(8)</label></formula><p>where η is a tunable weight for the regularization term which regulates the learnable adaptive matrixÂ should not be too far away from A. In practice, we initializeÂ with A and set η = 1 to simply improve the original adaptive matrix using the hand-crafted A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Loss function</head><p>Combine our ACE in Eq. <ref type="formula" target="#formula_8">(8)</ref> with the original classification loss, the overall objective function can now be easily expressed by</p><formula xml:id="formula_9">L = L CE + λL ACE<label>(9)</label></formula><p>where L CE is the cross-entropy loss which is usually applied in classification task and λ is a hyper-parameter to adjust the influence of the ACE loss to learning the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>We conduct extensive experiments to evaluate our approach on three balanced benchmark FGVC datasets, imbalanced datasets, and the natural world distribution dataset. We then describe comparisons to prior work as well as the implementation details. We also provide an insightful ablation study for assessing the performance gains of using adaptive confusion energy (ACE). Finally, several visualization examples are demonstrated for further discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We first evaluate the effectiveness of the proposed approach on three standard fine-grained visual classification datasets, namely, CUB-200-2011 <ref type="bibr" target="#b38">(Wah et al., 2011)</ref>, Stanford Cars <ref type="bibr" target="#b20">(Krause et al., 2013)</ref>, and FGVC-Aircraft <ref type="bibr" target="#b28">(Maji et al., 2013)</ref>. The data ratio between training and testing sets is about 1 : 1 for CUB-200-2011, and Stanford Cars is about 2 : 1 in FGVC-Aircraft. The class distribution of the three datasets is nearly balanced, which can be used to measure the proposed method's performance only in the fine-grained scenario with the adaptive matrixÂ approximating identity matrix. Compared with other datasets for the large-scale visual classification task, these three FGVC datasets have fewer training data for each category.</p><p>Next, we go through the experiments on the imbalanced datasets, ImageNet-LT <ref type="bibr" target="#b25">(Liu et al., 2019)</ref>. The former is a long-tailed distribution with a low fine-grained factor, confirming whether the proposed approach will adjust on the purely imbalanced dataset. The latter is a fine-grained dataset that also has a long-tailed property. It can more clearly measure the impact of different approaches, e.g., <ref type="bibr" target="#b8">Dubey et al., 2018;</ref><ref type="bibr" target="#b7">Du et al., 2020b)</ref>.</p><p>Finally, we then focus on the natural world distribution datasets and CUB-LT <ref type="bibr" target="#b30">(Samuel et al., 2021)</ref> and iNatural-ist2018 <ref type="bibr" target="#b37">(Van Horn et al., 2018)</ref> which has the properties of both fine-grained and long-tailed distribution. Besides, it is also a large-scale dataset. Judging from the recent literature <ref type="bibr" target="#b1">(Cao et al., 2019;</ref><ref type="bibr" target="#b19">Kang et al., 2020)</ref>, this is a reasonably challenging dataset that the performance can serve as an objective measure about our method's usefulness. Finally, we remark that the proposed model does not require any additional annotations in the training process but merely the image-level class annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation details</head><p>We describe the implementation details with FGVC, longtailed, and the comprehensive task. All our inference results are obtained from end-to-end training except the results on ImageNet-LT. The experimental results are the mean of three run. We implement our method using the Pytorch framework <ref type="bibr" target="#b29">(Paszke et al., 2017)</ref>, and the platform with eight Nvidia V100. The source code will be made available.</p><p>FGVC. Following relevant work <ref type="bibr" target="#b43">(Yang et al., 2018;</ref><ref type="bibr" target="#b3">Chen et al., 2019;</ref><ref type="bibr" target="#b44">Zheng et al., 2019)</ref>, we evaluate our method on the widely-used classification backbone ResNet series <ref type="bibr" target="#b13">(He et al., 2016)</ref> and DenseNet-161 <ref type="bibr" target="#b16">(Huang et al., 2017)</ref> which is pre-trained on the ImageNet dataset. For the sake of fair comparison in FGVC training, we use the data augmentation setting as in <ref type="bibr" target="#b3">Chen et al. (2019)</ref> that the input size is set as 448 × 448, and horizontal flipping is randomly performed. The initial learning rate, the hyper-parameter λ, and τ are 0.008, 10, and 0, respectively. The training batch size usually is 16 if the GPU memory is enough and the training optimizer is Momentum SGD, which accompanies with cosine annealing <ref type="bibr" target="#b26">(Loshchilov &amp; Hutter, 2017)</ref> as the learning rate decay.</p><p>Long-tailed visual recognition. We further evaluate the proposed ACE on the imbalanced datasets, ImageNet-LT. For the sake of fair comparison, we follow the implementation details as in  on ImageNet-LT. We present the ResNeXt-50 performance in the following section and the ResNet-10 and ResNeXt-152 at the supplementary. The phenomena between shallow and deep models are almost consistent. Since the ImageNet-LT has a low finegrained factor but a substantial imbalanced issue, we set the hyper-parameter λ and τ as 0.25 and 0.1, respectively.</p><p>Comprehensive tasks. Finally, we have experimental results on the CUB-LT and iNaturalist2018. In addition to using similar augmentation schemes, the setting is following <ref type="bibr" target="#b1">Cao et al., 2019)</ref>. The backbones are ResNet-50 with 224 × 224 input size by 90 training epochs in SGD optimization. The batch size is 16, and the initial learning rate is 0.025 with a cosine annealing decreasing schedule. The confusion weight λ is 2.0 and class-wise confusion weight τ is 0.0. Moreover, the experiment about CUB-LT is the same as the previous FGVC setting.</p><p>Evaluation. After training on the FGVC, imbalanced, and natural world datasets, we evaluate the models on the corresponding balanced test/validation datasets and report the top-1 accuracy, which is used commonly. The value of accuracy is reported in the format of percentage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Fine-grained</head><p>To investigate the performance of different confusion energies between the different backbones, we conduct an ablation study from shallow to deep on the ResNet-50, ResNeXt-50, ResNeXt101, and DenseNet-161. <ref type="table" target="#tab_0">Table 1</ref> shows the head-to-head comparison between PC and ACE. We reimplement the PC at the same training condition, and the experimental results show that ACE has comprehensively improved against PC. <ref type="table">Table 2</ref> shows the comparison to the other state-of-the-art approaches with ResNet-50 backbone. Baseline combines with our approach provides a competitive performance. Note that the state-of-the-art PMG <ref type="bibr" target="#b7">(Du et al., 2020b)</ref> contains four classifiers with ResNet-50 backbone, which leads the size of the parameters becomes 45 million floating points. The size of PMG is larger than the DenseNet-161 backbone, about 29 million. The Table 1 presents the competitiveness of our approach on the DenseNet-161 against PMG. Moreover, while the recent state-of-the-art PMG meets our ACE, it also improves. However, while the datasets are not large-scale, although ACE gains additional improvement, the confusion energies only provide little help. Hence, look at the FGVC research recently; it seems to have reached the limitation so far. Hence, it is reasonable to go through the more challenging tasks, which are large-scale, fine-grained, and long-tailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Long-tailed</head><p>ImageNet-LT has a low fine-grained factor but contains a strong imbalance issue. It is a reasonable dataset to measure the performance of ACE on the purely long-tailed distribution. <ref type="table" target="#tab_1">Table 3</ref> shows the experimental results with the strategy same as . At stage 1 with endto-end training, while the baseline trained with ACE gains a significant improvement, but drop the performance if it is trained with PC. The reason is that PC does not consider the number of each category on the training set, which will destroy the representation learning. ACE has handled the weight of confusion strength to each category, which will carefully alleviate the overfitting issue. Furthermore, through stage 2, no matter cRT or LWS, ACE also gains an additional improvement against baseline or PC. Hence, tackling the imbalanced data distribution with ACE can learn a better representation. Before we look at the nature world dataset, let us quickly look at a small-scale one, CUB-LT, which contains both <ref type="table">Table 4</ref>. The comparison with some recent stat-of-the-art works <ref type="bibr" target="#b42">Yang &amp; Xu, 2020)</ref>  high fine-grained factors and imbalance issues. It is an ideal dataset for investigating the effect the approaches whether fine-grained <ref type="bibr" target="#b8">(Dubey et al., 2018;</ref><ref type="bibr" target="#b6">Du et al., 2020a)</ref> or longtailed <ref type="bibr" target="#b30">Samuel et al., 2021)</ref>. <ref type="figure" target="#fig_2">Figure 3</ref> shows that PC really can tackle the fine-grained property, but the performance drops when it faces the long-tailed issue. <ref type="figure" target="#fig_3">Figure 4</ref> presents that the long-tailed approaches only focus on the imbalanced issue but lack the fine-grained property. Similarly, the fine-grained approaches tackle the finegrained property but not enough to address the imbalanced problem. Hence, the proposed ACE is a comprehensive approach that can easily and efficiently solve fine-grained and imbalanced problems simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Natural World</head><p>The proposed ACE preserves the benefits of confusion energy in the FGVC task and addresses the downside of the confusion energy in the long-tailed challenge. <ref type="table">Table 4</ref> shows the results on the natural world distribution dataset.Â enables the BCN to focus on the head categories but alleviate the confusion energy effect on the tailed categories. Note that our models are trained not only with the most common way of data sampling instance-balanced sampling but also end-to-end. In contrast, LWS  trains the model in two stages and requires the use of class-balanced sampling. Besides, SSP <ref type="bibr" target="#b42">(Yang &amp; Xu, 2020)</ref> starts with the self-supervised learning step and then follows the work of , which contains three stages. <ref type="bibr" target="#b8">Dubey et al. (2018)</ref> has shown that confusion energy alle- viates the overfitting problem and improves the FGVC performance. However, we observe that if the baseline model is coupled with the confusion energy directly, the overall performance only improves slightly on the natural world dataset. It suggests that the long-tailed issue needs further investigations beyond the model of confusion energy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Analysis</head><p>In this section, we give some analysis about the influence of ACE. Classification frameworks usually use the crossentropy loss as the objective function. The training loss always converges to a shallow level, regardless of the characteristics of the dataset. However, this is entirely unreasonable, and to some extent, the model overfits the training data. Hence, we show the performance during training on <ref type="figure">Figure 5</ref> to present that ACE can prevent the model from overfitting the training data.</p><p>Next, consider each category's magnitude corresponding to the classifier weight w i in <ref type="figure">Figure 6</ref>. The scale of w i distribution on the baseline method is very similar to the data distribution. Although PC has alleviated the scale of the head categories, the distribution does not change significantly. Nevertheless, the adaptive confusion energy ACE makes the scale of the head to become smoother. This means that the weights of head categories will not dominate the prediction of the classification.</p><p>In summary, ACE provides several benefits. First, it alleviates the overfitting problem of the cross-entropy loss.</p><p>While training with the cross-entropy loss concerning the ground truth label in the manner of the one-hot vector, the inter-class similarity information is usually significantly suppressed. Consequently, it cannot capture the fine-grained essence by one single cross-entropy loss while handling the overfitting issue. The proposed ACE successfully alleviates this issue. Second, ACE forces the model to learn the interclass similarity so that the classifier is more focused on the discriminative parts. This phenomenon can be found by using the class activation mapping (Grad-CAM) <ref type="bibr" target="#b31">(Selvaraju et al., 2017)</ref> presented in <ref type="figure" target="#fig_5">Figure 7</ref>. Third, ACE does not require additional processing of inputs and outputs during training. There is no extra cost at inference time, which makes it flexible and applicable to real applications. Finally, ACE solves the confusion energy problem while meets the long-tailed distribution. ACE coupled with the adaptive matrixÂ preserves the benefits of confusion energy in the FGVC task and addresses its downside in the long-tailed scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We have developed a general regularization technique specifically designed for addressing the fine-grained visual classification and the long-tailed data distribution problems simultaneously. The proposed adaptive confusion energy (ACE), together with the standard cross-entropy loss, can be used to account for the inherent classification difficulties due to inter-class similarity and intra-class variations. Moreover, it can also solve the long-tailed problem by an adaptive matrix term. The proposed ACE considers the confusion regularization within each training batch and thus is more general than the suitable formulation of pairwise confusion energy. The resulting model can learn discriminative features within regions of interest and alleviate the overfitting problem in training. The provided experimental results nearly achieve state-of-the-art over the three mainstream FGVC datasets and are competitive to leading long-tailed approaches on the imbalanced or natural world distribution datasets. Our future work will focus on generalizing the ACE concept to tensors and extending its applications to other challenging computer vision problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Left: Different datasets have varying degrees of long-tail and fine-grained characteristics. Right: The existing approaches can only solve one aspect of the problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The accuracy with different confusion weight λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>The accuracy of fine-grained and long-tailed approaches in CUB-LT. The proposed work alleviates the concurrent issues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Observation of the overfitting issue. (a) and (b) shows that there is a large gap between training accuracy and validation performance. (c) presents ACE alleviates the overfitting issue and improves the validation performance. The l2-norm of each category corresponds to the weight wi in the classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Heatmap-visualization of testing images by Grad-CAM. We show each model's corresponding heatmap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Head-to-head comparisons of the confusion energy scenarios on the standard FGVC datasets CUB-200-2011 (CUB), Stanford Cars (Cars), and FGVC-Aircraft (Aircraft).</figDesc><table><row><cell>Model</cell><cell cols="2">ResNet-50</cell><cell></cell><cell cols="2">ResNeXt-50</cell><cell>ResNeXt-101</cell><cell>DenseNet-161</cell></row><row><cell></cell><cell cols="6">CUB CAR AIR CUB CAR AIR CUB CAR AIR CUB CAR AIR</cell></row><row><cell cols="2">Baseline 85.5</cell><cell cols="3">92.7 90.3 86.3</cell><cell cols="2">93.1 90.9 87.3</cell><cell>93.5 91.6 87.5</cell><cell>93.4 92.7</cell></row><row><cell>PC</cell><cell>87.0</cell><cell cols="3">92.4 90.1 87.5</cell><cell cols="2">93.2 91.2 88.2</cell><cell>93.7 92.4 88.2</cell><cell>93.6 92.9</cell></row><row><cell>Ours</cell><cell>87.8</cell><cell cols="3">94.3 93.2 88.1</cell><cell cols="2">94.4 93.3 88.6</cell><cell>94.5 93.5 89.2</cell><cell>94.8 93.5</cell></row><row><cell cols="6">Table 2. Compare the results with the typical state-of-the-art. The</cell></row><row><cell cols="2">CNN backbone is ResNet-50.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="5">Param. (M) CUB CAR AIR</cell></row><row><cell>Baseline</cell><cell></cell><cell>24</cell><cell>85.5</cell><cell cols="2">92.7 90.3</cell></row><row><cell>PC  †</cell><cell></cell><cell>24</cell><cell>87.0</cell><cell cols="2">92.4 90.1</cell></row><row><cell>DB</cell><cell></cell><cell>∼24</cell><cell>87.7</cell><cell cols="2">94.3 92.1</cell></row><row><cell>DFL-CNN</cell><cell></cell><cell>∼24</cell><cell>87.4</cell><cell cols="2">93.1 91.7</cell></row><row><cell>NTS-Net</cell><cell></cell><cell>∼24</cell><cell>87.5</cell><cell cols="2">93.9 91.4</cell></row><row><cell>DCL</cell><cell></cell><cell>∼24</cell><cell>87.8</cell><cell cols="2">94.5 93.0</cell></row><row><cell>iSQRT-COV</cell><cell></cell><cell>∼24</cell><cell>88.1</cell><cell cols="2">92.8 90.0</cell></row><row><cell>Ours</cell><cell></cell><cell>24</cell><cell>87.8</cell><cell cols="2">94.3 93.2</cell></row><row><cell cols="2">PC  † (DenseNet-161)</cell><cell>28</cell><cell>88.2</cell><cell cols="2">93.6 92.9</cell></row><row><cell>S3N  ‡</cell><cell></cell><cell>101</cell><cell>88.5</cell><cell cols="2">94.7 92.8</cell></row><row><cell>PMG  ‡</cell><cell></cell><cell>45</cell><cell>88.9</cell><cell cols="2">95.0 92.8</cell></row><row><cell cols="2">Ours (DenseNet-161)</cell><cell>28</cell><cell>89.2</cell><cell cols="2">94.8 93.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>† Re-implemented by the same training setting as ours.‡ Modified ResNet-50 with additional modules.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Following the approach on ImageNet-LT, the proposed ACE gains a significant improvement.</figDesc><table><row><cell>Method</cell><cell cols="4">Many Median Few Total</cell></row><row><cell>ResNeXt-50</cell><cell>65.9</cell><cell>37.5</cell><cell>7.7</cell><cell>44.4</cell></row><row><cell>NCM</cell><cell>56.6</cell><cell>45.3</cell><cell cols="2">28.1 47.3</cell></row><row><cell>cRT</cell><cell>61.8</cell><cell>46.2</cell><cell cols="2">27.4 49.6</cell></row><row><cell>τ -norm</cell><cell>59.1</cell><cell>46.9</cell><cell cols="2">30.7 49.4</cell></row><row><cell>LWS</cell><cell>60.2</cell><cell>47.2</cell><cell cols="2">30.3 49.9</cell></row><row><cell>ResNeXt-50 +PC</cell><cell>63.9</cell><cell>35.5</cell><cell>8.8</cell><cell>42.8</cell></row><row><cell>NCM</cell><cell>52.3</cell><cell>42.9</cell><cell cols="2">28.7 44.6</cell></row><row><cell>cRT</cell><cell>59.3</cell><cell>46.1</cell><cell cols="2">29.5 48.9</cell></row><row><cell>LWS</cell><cell>57.3</cell><cell>46.4</cell><cell cols="2">29.8 48.4</cell></row><row><cell cols="2">ResNeXt-50 + ACE 67.5</cell><cell>42.1</cell><cell cols="2">10.2 47.5</cell></row><row><cell>NCM</cell><cell>57.9</cell><cell>46.7</cell><cell cols="2">31.0 48.9</cell></row><row><cell>cRT</cell><cell>63.2</cell><cell>48.1</cell><cell cols="2">29.7 51.4</cell></row><row><cell>LWS</cell><cell>60.7</cell><cell>49.7</cell><cell cols="2">33.1 51.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>on the iNaturalist 2018. Re-implemented by the same training setting as ours.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell cols="4">Many Median Few Total</cell></row><row><cell>Baseline</cell><cell>ResNet-50</cell><cell>72.2</cell><cell>63.0</cell><cell cols="2">57.2 61.7</cell></row><row><cell>PC  †</cell><cell>ResNet-50</cell><cell>70.9</cell><cell>64.6</cell><cell cols="2">59.6 62.1</cell></row><row><cell cols="2">LDAM-DRW  *  ResNet-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>64.6</cell></row><row><cell>NCM</cell><cell>ResNet-50</cell><cell>55.5</cell><cell>57.9</cell><cell cols="2">59.3 58.2</cell></row><row><cell>cRT</cell><cell>ResNet-50</cell><cell>69.0</cell><cell>66.0</cell><cell cols="2">63.2 65.2</cell></row><row><cell>LWS</cell><cell>ResNet-50</cell><cell>65.0</cell><cell>66.3</cell><cell cols="2">65.5 65.9</cell></row><row><cell>BBN</cell><cell>ResNet-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>66.3</cell></row><row><cell>SSP</cell><cell>ResNet-50</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>68.1</cell></row><row><cell>Ours</cell><cell>ResNet-50</cell><cell>66.6</cell><cell>68.0</cell><cell cols="2">68.2 68.3</cell></row><row><cell>Baseline</cell><cell cols="2">ResNet-152 75.2</cell><cell>66.3</cell><cell cols="2">60.7 65.0</cell></row><row><cell>PC  †</cell><cell cols="2">ResNet-152 72.1</cell><cell>67.2</cell><cell cols="2">61.3 65.9</cell></row><row><cell>NCM</cell><cell cols="2">ResNet-152 59.3</cell><cell>61.9</cell><cell cols="2">62.6 61.9</cell></row><row><cell>cRT</cell><cell cols="2">ResNet-152 73.6</cell><cell>69.3</cell><cell cols="2">66.3 68.5</cell></row><row><cell>LWS</cell><cell cols="2">ResNet-152 69.4</cell><cell>69.5</cell><cell cols="2">68.6 69.1</cell></row><row><cell>Ours</cell><cell cols="2">ResNet-152 69.2</cell><cell>70.8</cell><cell cols="2">72.7 71.7</cell></row><row><cell>†</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* The results reproduced with author's code.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large-scale finegrained visual categorization of birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Birdsnap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2011" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with label-distributionaware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1567" to="1578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SMOTE: synthetic minority over-sampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.953</idno>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Destruction and construction learning for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5157" to="5166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2019.00949</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9268" to="9277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">C4. 5, class imbalance, and cost sensitivity: why under-sampling beats over-sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Holte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on learning from imbalanced datasets II</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fine-grained visual classification via progressive multi-granularity training of jigsaw patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Bhunia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58565-5\10</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<editor>Vedaldi, A., Bischof, H., Brox, T., and Frahm, J.</editor>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12365</biblScope>
			<biblScope unit="page" from="153" to="168" />
		</imprint>
	</monogr>
	<note type="report_type">Proceedings</note>
	<note>Part XX</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fine-grained visual classification via progressive multi-granularity training of jigsaw patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Bhunia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="153" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pairwise confusion for fine-grained visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="70" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Look closer to see better: Recurrent attention convolutional neural network for finegrained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4438" to="4446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weakly supervised complementary parts models for fine-grained image classification from the bottom up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3034" to="3043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">LVIS: A dataset for large vocabulary instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Borderline-smote: A new over-sampling method in imbalanced data sets learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mao</surname></persName>
		</author>
		<idno type="DOI">10.1007/11538059\91</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Intelligent Computing, International Conference on Intelligent Computing, ICIC 2005</title>
		<meeting><address><addrLine>Hefei, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="878" to="887" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to segment the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.01406</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="14042" to="14051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5375" to="5384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Part-stacked cnn for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1173" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00763</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="7607" to="7616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International IEEE Workshop on 3D Representation and Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards faster training of global covariance pooling networks by iterative matrix square root normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="947" to="955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Overcoming classifier imbalance for long-tail object detection with balanced group softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<idno type="DOI">10.1109/CVPR42600.2020.01100</idno>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="10988" to="10997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.324</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10-22" />
			<biblScope unit="page" from="2999" to="3007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename></persName>
		</author>
		<idno>abs/1904.05160</idno>
		<ptr target="http://arxiv.org/abs/1904.05160" />
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="181" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno>abs/1306.5151</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">From generalized zero-shot learning to long-tail with class descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="286" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Relay backpropagation for effective learning of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46478-7\29</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016 -14th European Conference</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="467" to="482" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VII</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<idno>doi: 10. 1109/CVPR.2016.89</idno>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Fine-grained recognition: Accounting for subtle differences between similar classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cholakkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06842</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.01168</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="11659" to="11668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Long-tailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8769" to="8778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The devil is in classification: A simple framework for long-tail instance segmentation. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning a discriminative filter bank within a cnn for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4148" to="4157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7029" to="7039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rethinking the value of labels for improving class-imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>Lin, H.</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to navigate for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="420" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Looking for the devil in the details: Learning trilinear attention sampling network for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5012" to="5021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bbn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9719" to="9728" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
