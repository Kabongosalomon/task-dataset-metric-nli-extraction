<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DEEP CLUSTERING WITH A DYNAMIC AUTOENCODER: FROM RECONSTRUCTION TOWARDS CENTROIDS CONSTRUCTION A PREPRINT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-01-06">January 6, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nairouz</forename><surname>Mrabah</surname></persName>
							<email>nairouz.mrabah@ensi-uma.tn</email>
							<affiliation key="aff0">
								<orgName type="institution">National Engineering School of Tunis University of Tunis El Manar Tunis</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naimul</forename><forename type="middle">Mefraz</forename><surname>Khan</surname></persName>
							<email>n77khan@ee.ryerson.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Ryerson University Toronto</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riadh</forename><surname>Ksantini</surname></persName>
							<email>riadh.ksantini@supcom.tn</email>
							<affiliation key="aff2">
								<orgName type="department">Higher School of Communication of Tunis</orgName>
								<orgName type="institution">University of Carthage Tunis</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zied</forename><surname>Lachiri</surname></persName>
							<email>zied.lachiri@enit.rnu.tn</email>
							<affiliation key="aff3">
								<orgName type="department">National Engineering School of Tunis</orgName>
								<orgName type="institution">University of Tunis El Manar Tunis</orgName>
								<address>
									<country key="TN">Tunisia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DEEP CLUSTERING WITH A DYNAMIC AUTOENCODER: FROM RECONSTRUCTION TOWARDS CENTROIDS CONSTRUCTION A PREPRINT</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-01-06">January 6, 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Unsupervised Learning · Deep Learning · Clustering · Autoencoders</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In unsupervised learning, there is no apparent straightforward cost function that can capture the significant factors of variations and similarities. Since natural systems have smooth dynamics, an opportunity is lost if an unsupervised objective function remains static during the training process. The absence of concrete supervision suggests that smooth dynamics should be integrated. Compared to classical static cost functions, dynamic objective functions allow to better make use of the gradual and uncertain knowledge acquired through pseudo-supervision. In this paper, we propose Dynamic Autoencoder (DynAE), a novel model for deep clustering that overcomes a clusteringreconstruction trade-off, by gradually and smoothly eliminating the reconstruction objective function in favor of a construction one. Experimental evaluations on benchmark datasets show that our approach achieves state-of-the-art results compared to the most relevant deep clustering methods. github.com/nairouz/DynAE</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the interest of evading the curse of dimensionality, a bunch of dimensionality reduction techniques have been proposed. Linear transformations like Principal Component Analysis (PCA) <ref type="bibr" target="#b7">[8]</ref> and Factor Analysis <ref type="bibr" target="#b8">[9]</ref> are broadly adopted for a multitude of applications. Existing non-linear techniques rely on the manifold assumption <ref type="bibr" target="#b9">[10]</ref>, which postulates the existence of low-dimensional manifolds, where the embedded information is concentrated. Multi-dimensional scaling (MDS) <ref type="bibr" target="#b10">[11]</ref> and Isometric Feature Mapping (Isomap) <ref type="bibr" target="#b9">[10]</ref> are among the most commonly used non-linear dimensionality reduction approaches. While these methods target capturing the most relevant information, they are subject to discriminative information loss, which deteriorates the clustering performance.</p><p>To tackle the curse of dimensionality while prioritizing categorical separability, subspace clustering <ref type="bibr" target="#b11">[12]</ref> enables to find relevant dimensions spanning a subspace for each cluster. Contrary to typical dimensionality reduction techniques, subspace clustering does not overlook the discriminative information available in data. However, they are computationally costly. Besides, the existence of clusters within linear subspaces does not conform to the complexity of natural datasets.</p><p>Other than subspace clustering, manifold clustering <ref type="bibr" target="#b12">[13]</ref> also combines discriminative dimensionality reduction with clustering. However, instead of confining the data to low dimensional subspaces, manifold clustering maps the samples to non-linear manifolds by computing a similarity matrix. Spectral K-Means and spectral clustering are popular manifold clustering approaches. Under mild conditions, spectral clustering can be seen as a kernel K-Means problem <ref type="bibr" target="#b13">[14]</ref>. The computational time of this family grows considerably for large-scale datasets. Moreover, the representation power of such methods is limited. The discriminative ability of the similarity matrix usually underfits the natural data semanticity.</p><p>Recently, deep learning has shown great promise in solving pattern recognition problems <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. It allows to learn space transformations and gradually extract higher semantic representations from one layer to another. The immense success of deep learning is mostly imputed to the convenience of using multi-layers architectures in solving data-oriented problems. In practice, three principal reasons can mostly explain the suitability of these models. First, mini-batch Stochastic Gradient Descent (SGD) grants neural networks the ability to elude the time and memory bottlenecks. Thus, multi-layers architecture can be used to process large-scale databases. Second, neural networks are attractive for high-dimensional data since it is possible to project the samples in a lower-dimensional space. Third, the compositional aspect of natural datasets plays well with the hierarchical architecture of a deep neural network. Therefore, multi-layers architecture is suitable for processing high-semantic data. Despite all these advantages, discovering hidden data structures without leveraging any supervisory signal remains an open and challenging research area.</p><p>Most of the existing deep clustering methods harness an auto-encoding architecture <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. Some other approaches rely on an encoding network without a decoder <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>. The latter strategy consists of two alternative stages: grouping the embedded features based on a typical clustering algorithm (e.g., K-Means) and updating the encoding weights using the subsequent pseudo-labels as a supervisory signal. For the first strategy, the encoder training is regularized by a reconstruction cost. Hence, the decoder is used to alleviate the effect of training with pseudo-labels. However, eliminating the decoding network and training the encoder based on hypothetical similarities can easily corrupt the space topology. Thus, it is possible that the encoder generates random discriminative features, which do not reflect the real discriminative characteristics. This problem is called Feature Randomness <ref type="bibr" target="#b26">[27]</ref>.</p><p>To mitigate the effect of Feature Randomness, autoencoders are provided with their reconstruction capability, which captures prominent features without forcing any randomness. However, combining clustering and reconstruction is problematic due to the natural trade-off between them. In fact, while the clustering objective function aims to destroy non-discriminative details, the reconstruction objective function allows to preserve all information. Put it differently, all pixels have the same importance in the reconstruction cost regardless of their discriminative role. For instance, a picture of a plane and another of a bird both would contain many blue pixels and few ones representing the real objects. In such a case, the reconstruction would foster encoding information, which is irrelevant for clustering (i.e., the color of the sky). This problem is called Feature Drift <ref type="bibr" target="#b26">[27]</ref>.</p><p>To deal with Feature Randomness and Feature Drift, our proposed model has a dynamic loss function that allows to gradually and smoothly dispense with the reconstruction loss in favor of a construction one. Our experimental results show the suitability of our model when compared to the state-of-the-art clustering methods in terms of accuracy (ACC) and normalized mutual information (NMI). Furthermore, DynAE has reasonable dynamic hyperparameters, which are updated automatically following the dynamics of the learning system. The automatic update of the hyperparameters allows to circumvent cross-validation, which is impractical for unsupervised learning. The contributions of this work are as follows:</p><p>• Elaborating a novel deep clustering framework, namely, DynAE, which alleviates Feature Randomness.</p><p>• Using a dynamic loss function to overcome the clustering-reconstruction trade-off.</p><p>• An improved way of obtaining a K-Means friendly latent space compared to DCN <ref type="bibr" target="#b18">[19]</ref>.</p><p>• Establishing a better trade-off between Feature Randomness and Feature Drift compared to ADEC <ref type="bibr" target="#b26">[27]</ref>, by gradually and smoothly transforming a self-supervised objective into a pseudo-supervised one. • Achieving state-of-the-art clustering performance on real benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Most of the existing deep clustering strategies share two simple concepts. The first concept is that deep embedded representations are favorable to clustering. The second concept is that clustering assignments can be used as a supervisory signal to learn embedded representations. Based on that, the existing deep clustering methods can be classified into two main families.</p><p>For the first family, embedded learning and clustering are set apart. Particularly, embedded learning precedes clustering. However, the new obtained labels, after the clustering stage, are not used to learn better discriminative features. For instance, in <ref type="bibr" target="#b27">[28]</ref>, the data is first projected in a lower-dimensional space using an autoencoder, then K-Means clusters the embedded data. Some other interesting research studies revolve around this two-step strategy <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>. In <ref type="figure" target="#fig_0">Figure 1</ref>, we illustrate the general framework of this family. For the second family, embedded learning and clustering are performed jointly. A number of approaches fall under the scope of this group <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b24">25]</ref>. Among the common strategies, a classical clustering algorithm is applied to group the embedded data points into different clusters. After that, the encoding transformation is trained to push the embedded space to have a clustering-friendly representation based on the previously obtained clustering assignment. These two steps can be applied alternatively for a specific number of iterations or until meeting a convergence criterion. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the joint approach.</p><p>Haeusser et al. <ref type="bibr" target="#b21">[22]</ref> have proposed to freeze the first layers of famous models like VGG <ref type="bibr" target="#b32">[33]</ref> and Residual networks <ref type="bibr" target="#b33">[34]</ref> and build the clustering model on top of these layers. Although not using any label from the target training set, this approach strongly relies on features that are extracted in a supervised way (labels from other datasets). Since the low semantic features (e.g., edge detection) are similar across different datasets, we consider such a method to be out of the pure unsupervised learning realm.</p><p>Good results have been reported for approaches that heavily depend on strong assumptions for formulating the objective function (e.g., prior knowledge on the size of each cluster) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b34">35]</ref>. Such assumptions may have a considerable influence in clustering ambiguous samples. While these methods may perform well in specific scenarios, the solution is not general enough to be applicable to any dataset.</p><p>Deep Embedding for Clustering (DEC) <ref type="bibr" target="#b35">[36]</ref> projects the data points in a lower-dimensional space using an autoencoder. After that, the decoder is discarded and the encoder is trained to jointly improve the embedded representations and the clustering centers. DEC requires a pretraining phase before starting to cluster the data. Furthermore, it has no mechanism to avoid Feature Randomness after discarding the decoder. Hence, the mass of random labels can lead to the generation of random discriminative features. Besides, the contribution of each center to the loss function is normalized to block large clusters from altering the embedded representations. Therefore, DEC is more suitable for balanced datasets. Improved Deep Embedded Clustering (IDEC) <ref type="bibr" target="#b17">[18]</ref> is quite similar to DEC. The major contribution of IDEC is balancing the clustering cost with a reconstruction one after the pretraining phase. According to Xifeng et al. <ref type="bibr" target="#b17">[18]</ref>, eliminating the reconstruction during the clustering phase hampers the network from preserving the local structures. However, we argue that maintaining the reconstruction loss end-to-end is not as beneficial due to the inherent conflict between clustering and reconstruction. More precisely, embedded clustering does not take into consideration non-discriminative patterns that do not contribute to data categorization (e.g. between-class similarities), whereas reconstruction is mainly concerned with preserving all the information whether discriminative or not. Preserving non-discriminative features end-to-end implies a reduction in the overall discriminative ability.</p><p>Deep Clustering Network (DCN) <ref type="bibr" target="#b18">[19]</ref> is also an autoencoder clustering approach. Similar to DEC and IDEC, DCN has a joint optimization process. First, the autoencoder is pretrained to reduce the dataset dimensionality based on a reconstruction loss function. The ultimate goal of this approach is to get a K-Means-friendly representation at the end of the training process. To this end, a K-Means loss is applied along with the vanilla reconstruction. This method requires hard clustering assignments (as opposed to soft clustering assignments based on probabilities). That would induce a discrete optimization process, which is incongruous with the differential aspect of gradient descent. Similar to IDEC, DCN does not have any mechanism to mitigate the clustering-reconstruction trade-off.</p><p>Joint Unsupervised LEarning (JULE) <ref type="bibr" target="#b22">[23]</ref> is a deep recurrent framework for jointly learning unsupervised representations using CNN and clustering images using agglomerative clustering. The main contribution of JULE is the recurrent process that allows to merge clusters in multiple time steps. However, training a recurrent neural network, where the number of time-steps is equal to the number of data points, is not computationally efficient.</p><p>Deep Embedded Regularized Clustering (DEPICT) <ref type="bibr" target="#b31">[32]</ref> leverages a convolutional autoencoder for learning embedded representations and their clustering assignments. Similar to DEC, DEPICT has a relative cross-entropy (KL divergence) objective function. In addition, the loss function of DEPICT has a regularization term, which allows to explicitly impose the size of each cluster based on some prior knowledge. This avoids situations, where most of the data points are assigned to a few clusters. However, this prior knowledge (size of clusters) assumed by DEPICT is impractical for pure unsupervised problems. Added to that, DEPICT overlooked the clustering-reconstruction trade-off.</p><p>Variational Deep Embedding (VaDE) <ref type="bibr" target="#b30">[31]</ref> is a generative deep clustering method, inspired by Variational Autoencoder (VAE). It allows to couple clustering with data generation. The VaDE framework involves encoding the initial data distribution as a Gaussian Mixture distribution in the embedded space. In order to allow backpropagation, the Gaussian Mixture distribution is sampled using the reparameterization trick. VaDE relies on variational inference. Thus, the information loss induced by the mean-field approximation can harm the quality of the latent space, which in turn may deteriorate the clustering performance.</p><p>Adversarial Deep Embedded Clustering (ADEC) <ref type="bibr" target="#b26">[27]</ref> is an autoencoder-based clustering model. It is the first work to characterize and address the trade-off between Feature Randomness and Feature Drift. Similar to DEC, ADEC minimizes the Kullback-Leibler (KL) divergence to an auxiliary target distribution. Additionally, the clustering objective of ADEC is regularized by an adversarially constrained reconstruction. Based on adversarial training, the strong competition between the two objective functions is alleviated. However, adversarial training is still a challenging task due to its lack of stability. This instability can be explained by the following reasons: (1) Mode collapse <ref type="bibr" target="#b36">[37]</ref>: this happens when the generated data distribution only captures a local region from the real data support, which will induce restricted varieties of samples, (2) Failure to converge <ref type="bibr" target="#b37">[38]</ref>, and (3) Memorization: this problem takes place when the model can not synthesize new data points different from the ones fed to the network during the training process. By optimizing a dynamic objective function, our empirical results show that it is possible to find a better trade-off between Feature Randomness and Feature Drift compared to ADEC, without using adversarial training, and without adding an additional network (i.e., discriminator).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Motivations</head><p>In this section, we review the trade-off between Feature Randomness and Feature Drift <ref type="bibr" target="#b26">[27]</ref>, which serves as the motivation behind our proposed method. As mentioned before, the main challenge in unsupervised learning is that there is no obvious straightforward objective function that can learn high-level similarities without feeding semantic labels. Existing unsupervised representation learning strategies stem from two concepts: self-supervision and pseudosupervision.</p><p>Pseudo-supervision consists of training a model using pseudo-labels <ref type="bibr" target="#b38">[39]</ref> instead of the ground truth ones. Unlike self-supervision, a pseudo-supervised objective function targets explicitly the semantic categories without using any proxy. Similar to self-supervision, the computed labels are automatically extracted without any human intervention. In practice, the pseudo-labels are predicted based on uncertain assumptions and hypothetical similarities. Therefore, some of them mismatch the real ones. In this work, a pseudo-supervised loss is denoted by L P .</p><p>Self-supervision targets learning general-purpose features by solving a pretext task. To this end, the training data is automatically labeled by finding and exploiting simple intrinsic information (e.g., color, position, context). In practice, self-supervised approaches have competitive results on multiple benchmarks <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>. The success of self-supervision is linked to the selected pretext. In order to be solved, a good pretext problem is designed in a way that requires learning high-level features. Multiple pretext objectives were proposed in the literature. The simplest one is the reconstruction pretext. Also, popular pretext tasks include the adversarial objective <ref type="bibr" target="#b41">[42]</ref> that relies on distinguishing fake and real samples and the denoising objective <ref type="bibr" target="#b42">[43]</ref>. In computer vision, we can find the following pretexts: predicting the colorization <ref type="bibr" target="#b43">[44]</ref>, predicting unpainted patches <ref type="bibr" target="#b44">[45]</ref>, predicting the spatial relationship of different patches <ref type="bibr" target="#b45">[46]</ref>. An interesting overview of existing self-supervised methods can be found in <ref type="bibr" target="#b46">[47]</ref>. In this work, a self-supervised loss is denoted by L S .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature Randomness</head><p>Existing clustering models enable classifying the data without using labels. However, supervised learning approaches yield much better results than the clustering ones. This disparity can be explained by the few assumptions made by the existing clustering methods. These assumptions are rarely congruent with real data complexity. In the absence of concrete labels, it is possible to train a neural network using predicted labels that were extracted based on hypothetical assumptions. Obviously, these constructed labels are less effective than true labels because some of them mismatch the real categorization. Zhang et al. <ref type="bibr" target="#b47">[48]</ref> trained several standard deep neural networks architectures with different levels of random labels. The most important observation of this study is that all the trained models achieve a training error equal to zero regardless of the level of randomness. Surprisingly, increasing the portion of random labels does not cause any significant training time overhead. These findings confirm that a deep neural network can perfectly fit random labels when the number of its parameters exceeds the number of data points. An implication of this conclusion is that the capacity of a neural network is adequate to memorize the whole dataset. Furthermore, the correlation between the training samples and their corresponding labels has little to do with the training feasibility.</p><p>Feature Randomness occurs when a neural network is trained using pseudo-supervised labels. At every iteration, Feature Randomness is characterized by the deviation of the gradient of the real supervised objective function w.r.t the network parameters w after introducing pseudo-labels. Mathematically, Feature Randomness can be expressed as the cosine of the angle between the gradient of the real supervised objective function and the gradient of the unsupervised objective function. This characterization ∆ F R is described by <ref type="bibr">Equation 1</ref>, where x is the input data, L is the loss function, y true is the vector of true labels and y pseudo is the vector of pseudo labels.</p><formula xml:id="formula_0">∆ F R = cos( ∂L(x, y true , w) ∂w , ∂L(x, y pseudo , w) ∂w ).<label>(1)</label></formula><p>Training with pseudo-labels pushes the neural network to learn features that emphasize similarities between data points from different clusters. It also enforces learning to exclude points from their natural clusters and map them to irrelevant clusters. These implications give birth to features that contradict the data semanticity. Hence, they are considered to be random features.</p><p>We can compare ACC, which is the standard metric for evaluating deep clustering models, with ∆ F R . While ACC computes the similarity between the two scalar values y true and y pseudo , ∆ F R computes the similarity between the gradient vectors inherent to y true and y pseudo . Obviously, the gradient vector provides a better insight of the topological characteristics of the latent space. Hence, ∆ F R can be used to identify problems related to deep clustering (e.g., Feature Randomness), whereas ACC falls short of this capacity. Our experimental visualisations using both metrics strongly supports this intuition.</p><p>As mentioned before, a self-supervised objective function targets learning general-purpose features by solving a pretext task. Although the learned features are less discriminative than the ones learned based on categorical labels (i.e., labels that indicate the high semantic categories), for a self-supervised objective function, there are no pseudo-labels. Therefore, y true = y pseudo . Hence, ∆ F R is always equal to 1 and there is no possibility of Feature Randomness to take place. Thus, it is possible to mitigate Feature Randomness by combining a pseudo-supervised objective function with a self-supervised one. Furthermore, the self-supervised objective function can be used to incorporate relevant prior knowledge (e.g., invariance to small translations and rotations for images datasets).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Drift</head><p>State-of-the-art autoencoder-based clustering approaches rely on jointly performing representation learning and clustering based on a linear combination of two objective functions. The joint optimization process can be described as follows:</p><formula xml:id="formula_1">L = L 1 + γ L 2 .<label>(2)</label></formula><p>Where L 1 is the reconstruction loss function and L 2 is the embedded clustering loss. γ is a hyper-parameter, which is used to balance the two costs. It has been shown empirically <ref type="bibr" target="#b17">[18]</ref> that it is better to keep γ small in order to avoid having the clustering cost corrupt the latent space. The common network architecture of the autoencoder-based clustering approaches is illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>In the context of multi-objective optimization, decisions are made by taking into consideration trade-offs between conflicting objectives. Objective functions are said to be conflicting if there is no solution simultaneously optimizing every single objective function. Optimizing an objective function can degrade another one in value when they are in conflict. In such a case, it is possible to get an infinite number of Pareto optimal solutions. Therefore, additional subjective information is required to select a single solution. Without acquiring this information, all solutions are equally valid.</p><p>Feature Drift takes place when a neural network is trained to minimize a combination of two strongly conflicting loss functions. In the specific context of deep clustering, the two cost functions are the pseudo-supervised loss and the self-supervised one.</p><p>At every training iteration, Feature Drift is characterized by the degree of competition between the gradient of the self-supervised objective function and the gradient of the pseudo-supervised objective function w.r.t the network parameters w. Mathematically, Feature Drift can be expressed as the cosine of the angle between theses two gradient vectors. This characterization ∆ F D is described by <ref type="bibr">Equation 3</ref>, where y pretext is the self-acquired labels for the pretext task and y pseudo is the vector of pseudo labels. Training a neural network with two strongly conflicting objective functions have its drawbacks. In fact, the features learned by optimizing the main objective function can be easily drifted by updating the learning weights with respect to the secondary objective function. This can make the global optimization process fail. The illustrative example from <ref type="bibr" target="#b26">[27]</ref> offers a considerable insight into this problem.</p><formula xml:id="formula_2">∆ F D = cos( ∂L P (x, y pseudo , w) ∂w , ∂L S (x, y pretext , w) ∂w ).<label>(3)</label></formula><p>In a typical autoencoder-based clustering model, rising the balancing coefficient significantly makes the pseudosupervised objective function dominate the optimization process. In such a case, Feature Randomness increases. However, decreasing the balancing coefficient too much makes the self-supervised gradient dominate the competition. This means that the discriminative representations learned by pseudo-supervision can be easily drifted by the selfsupervised objective function. Hence, we try to balance the trade-off between Feature Randomness and Feature Drift in our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Dynamic Autoencoder Model</head><p>In this section, we present our double-stage deep clustering model. In section 4.1, we describe the pretraining phase. Pretraining allows us to learn general-purpose features to initialize the neural network. As stated before, pseudo-labels are unreliable when extracted from random latent representations. It is reasonable to predict that completely random pseudo-labels are not a good starting supervisory signal. It leads to excessive Feature Randomness, which in turn misleads the whole learning process. Hence, before starting to train using a pseudo-supervised objective function, the neural network can be pretrained to learn valuable information relying on some pretext task. After that, learning discriminative representations becomes more suitable by introducing effective pseudo-supervision. Based on that, any self-supervised loss is a candidate for the pretraining phase. In our case, we opted for reconstruction regularized by adversarially constrained interpolation and data augmentation for their competitive results compared to state-of-the-art self-supervised approaches. In Section 4.2, we describe our dynamic loss function, which is the main contribution of this work. Our dynamic learning mechanism offers a better trade-off between Feature Randomness and Feature Drift by gradually and smoothly eliminating the reconstruction objective function in favor of a construction one.</p><p>Before starting our methodology description, we establish some useful notations. Consider the problem of clustering</p><formula xml:id="formula_3">a dataset X = x i ∈ R d N i=1 of N data points in R d . This dataset can be grouped into K clusters {C k } K k=1</formula><p>. f θe : X → Z and g θ d : Z → X stand for the encoder and decoder mappings, respectively and θ e and θ d represent their learnable parameters, respectively. Let z i = f θe (x i ) ∈ R p be the latent representation of the data point x i and x i = g θ d (z i ) ∈ R d be the reconstructed representation of x i . The number of cluster K is provided as prior knowledge and Γ = {µ j ∈ R p } K j=1 is the set of latent centroids. In order to assess the similarity between the latent centroids µ j and the embedded data points z i , the Student's t-distribution is selected as a kernel. The same kernel was selected for other deep clustering approaches, such as, DEC <ref type="bibr" target="#b16">[17]</ref> and IDEC <ref type="bibr" target="#b17">[18]</ref>. Let q ij denotes the soft clustering assignments based on the Student's t-distribution kernel as shown in <ref type="bibr">Equation 4</ref>. It accounts for the probability of assigning an embedded point z i to the centroid µ j . α is a coefficient related to the Student's t-distribution. Based on the matrix Q = (q ij ) i=1...N,j=1...K , we define the function σ : X → Z, where σ(x i ) outputs the centroid with the highest clustering assignment. Hence, σ(x i ) = µ argmaxj {qij } .</p><formula xml:id="formula_4">q ij = (1 + zi−µj 2 α ) − α+1 2 j (1 + zi−µ j 2 α ) − α+1 2 ,<label>(4)</label></formula><p>For each data point x i , we define h ij as the j th maximal value of q ij . For example, h i1 is the maximal value of q ij and h i2 is the second maximal value of q ij . Mathematically, h ij can be formalized as shown in <ref type="bibr">Equation 5</ref>.</p><formula xml:id="formula_5">h ij = max j {q ij } , if j = 1, max j q ij | q ij &lt; h i(j −1) , otherwise.<label>(5)</label></formula><p>The ultimate goal of our methodology is to find θ e that allows the f transformation to project the data in a clusteringfriendly embedded space, according to the selected kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pretraining</head><p>Similar to all autoencoder-based clustering methods, our dynamic autoencoder model has a pretraining phase. Therefore, the encoder and decoder are trained to optimize a pretext objective. Then, the learning weights can be fine-tuned according to the main objective function. Previous deep clustering models, such as, <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b17">[18]</ref>, leverage a stacked denoising auto-encoding strategy for learning general-purpose representations. It is important to highlight that pretraining with a self-supervised objective function allows capturing embedded features related to the data distribution. It then allows avoiding extracting pseudo-labels from completely random latent representations. In other words, pretraining is a keystone in reducing Feature Randomness.</p><p>To better understand the purpose of a double-stage framework, we provide an analogy with signal processing. Extracting discriminative representations can be considered similar to a filtering operation. In signal processing, a filter allows to destroy irrelevant components and preserve pertinent patterns. To this end, the signal should be expressed in the frequency domain before filtering the undesired information. The Fourier transform is a bijective function. It allows mapping the initial signal to the frequency domain, where spectral components are expressed. Similar to the Fourier transform, the pretraining phase relies on a generative transformation, where the latent representations can be inverted to their initial form. Then, based on the obtained representations, discriminative patterns can be learned by bringing the embedded data points closer to their associated centroids. This leads to destroying unwanted information, namely, within-cluster similarities. This operation is similar to filtering in signal processing. The simple analogy described above is summarized in <ref type="table" target="#tab_0">Table 1</ref>. Unlike previous autoencoder-based clustering methods, our pretraining phase consists of optimizing a vanilla reconstruction objective function regularized by data augmentation (e.g., small random shifting and small random rotation) <ref type="bibr" target="#b35">[36]</ref> and an adversarially constrained interpolation <ref type="bibr" target="#b48">[49]</ref>. Both techniques showed competitive results in learning suitable unsupervised representations <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>The ACAI (i.e., Adversarially Constrained Autoencoder Interpolation) framework consists of a game competition between two adversarial networks, namely, an autoencoder and a critic. The purpose of this framework is to make the autoencoder generate samples that have a mixture of semantic characteristics from the inputs. For every training iteration, two coefficients α and γ are randomly sampled from the interval [0, 1]. Furthermore, a couple of data points x 1 and x 2 needs to be sampled randomly to compute x α = g θ d (αf θe (x 1 ) + (1 − α)f θe (x 2 )). As the mathematical equation indicates, x α represents the reconstructed data point whose latent representation is linearly interpolated from the embedded representation of x 1 and x 2 . c denotes the critic network and θ c denotes the learnable parameters of this network. t stands for the index of the iteration. While the critic is trained to regress the interpolation coefficient α fromx α in Equation 7, the main network is trained to reconstruct the input data and to fool the critic into considering the interpolated points to be realistic in Equation <ref type="bibr" target="#b5">6</ref>. The second term in Equation 7 enforces the critic to output 0 for non-interpolated inputs. This regularization technique makes the interpolants look realistic, which leads to a smooth latent space as shown by <ref type="bibr" target="#b48">[49]</ref>. To keep the notation simple, we consider that x represents the data samples after performing some random transformations (translation and rotation). The whole pretraining framework is shown in <ref type="figure">Figure 4</ref>.</p><formula xml:id="formula_6">L f,g (θ e (t), θ d (t)) = ||x −x|| 2 2 + λ ||c(x α )|| 2 2 ,<label>(6)</label></formula><formula xml:id="formula_7">L c (θ c (t)) = ||c(x α ) − α|| 2 2 + ||c(γx + (1 − γ)x)|| 2 2 .<label>(7)</label></formula><p>Figure 4: The pretraining phase of DynAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Clustering phase</head><p>After pretraining, we finetune the autoencoder weights by optimizing a dynamic loss. To this end, we use K-Means to initialize the embedded clustering centers. Apart from K-Means, there are multiple popular strategies for computing centroids' coordinates, such as k-medoids <ref type="bibr" target="#b49">[50]</ref> and clarans <ref type="bibr" target="#b50">[51]</ref>. In this work, for the sake of simplicity and since the goal is to show empirically that DynAE is a promising deep clustering strategy, K-Means is selected for initializing and updating the centroids. Similar to state-of-the-art autoencoder-based clustering models, our cost function has two parts. The first one makes up the reconstruction cost and the second one is the clustering objective function. <ref type="figure" target="#fig_3">Figure 5</ref> illustrates the general clustering architecture of DynAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">From reconstruction towards centroids construction</head><p>Our idea is to make the autoencoder output the centroid image of every sample instead of generating reconstructed images. To this end, the decoder can be used to generate the centers' images from the embedded centroids µ j . Then, we can feed them to the network as a supervisory signal. However, abrupt elimination of the self-supervised loss (i.e., reconstruction) can lead to Feature Randomness, whereas, preserving it during the whole training process causes Feature Drift. We propose to gradually and smoothly eliminate the reconstruction loss in favor of centroids construction. After the pretraining phase, some embedded data points z i have unreliable clustering assignments q ij . More explicitly, the probabilities of their highest assignments are very close to each other. Generally, these samples are located near the cluster boundaries. Therefore, it is hard to predict their corresponding centers confidently. We consider them as conflicted data points. At every training iteration, we characterize an unconflicted data point by a condition that controls the level of acceptable uncertainty. Mathematically, a conflicted data point belongs to the set S defined by Equation 8.</p><p>The hyperparameters β 1 and β 1 are controlling thresholds. They lie in the interval [0, 1]. β 1 stands for the minimal confidence threshold under which a data point is considered to be conflicted. β 2 is the minimal difference between the highest and the second-highest assignment probabilities (h i1 and h i2 , respectively, as defined by <ref type="formula" target="#formula_5">Equation 5</ref>). Based on our definition, a conflicted sample must have its highest assignment less than β 1 or the difference between its highest and second-highest assignments must be less than the threshold β 2 .</p><formula xml:id="formula_8">S = {x i ∈ X| h i1 &lt; β 1 or (h i1 − h i2 ) &lt; β 2 } .<label>(8)</label></formula><p>The first part of our dynamic loss function is described by <ref type="bibr">Equation 9</ref>. Reliable samples are selected for centroid construction. As for the conflicted data points, the reconstruction cost is applied until the model gains more confidence in their corresponding centers. So depending on the data sample, there are two possible training schemes: reconstruction or centroid construction as stated by <ref type="bibr">Equation 9</ref>.</p><formula xml:id="formula_9">L 1 (θ e (t), θ d (t)) = N i=1 ||x i −x i || 2 2 if x i ∈ S, ||g(σ(x i )) −x i || 2 2 otherwise.<label>(9)</label></formula><p>The centroids images, which are used as a supervisory signal, are generated using the decoder and do not represent real data points. In order to avoid blurry images, the first nearest neighbor (1-NN) of each embedded center µ j is selected as a substitute to the decoder's generated images. It is possible that pretraining with ACAI contributes to generating stable centroids by introducing continuity in the latent space <ref type="bibr" target="#b48">[49]</ref>.</p><p>Generally, hyperparameters are known to be dataset-specific. Besides, for real unsupervised applications, supervised cross-validation is impractical. Therefore, it is vital to make our method less sensitive to the choice of unpredictable hyperparameters. In our case, β 1 and β 2 are computed based on mathematical formulations. As shown by Equation 10, they depend on κ, which is the confidence threshold.</p><formula xml:id="formula_10">β 1 = κ K and β 2 = β 1 2 , κ ∈ [|1, K|].<label>(10)</label></formula><p>It is worth to note that κ is initialized in a way to ensure that β 1 and β 2 have high values. Thus, the controlling condition for unconflicted data becomes very difficult to satisfy. At the initial stage, most of the training set is devoted to being reconstructed and the rest is used for performing centroids construction. Starting with higher values would allow for more reconstruction and fewer centroids construction, which would only slow down convergence.</p><p>We update κ in a way that captures the dynamics of the number of conflicted data points. As shown by <ref type="bibr">Equation 11</ref>, we can describe the dynamics of the loss function by τ , which specifies the amount of reconstruction in Equation <ref type="bibr" target="#b8">9</ref>. τ is not a tunable hyperparameter, but instead just an indicator of the training progress.</p><formula xml:id="formula_11">τ = nb of reconstructed samples N = | S | N .<label>(11)</label></formula><p>During the training process, the number of conflicted points is supposed to decrease gradually. The dynamic loss function reaches stability when the number of conflicted data points does not decrease any more. At this level, τ remains constant.</p><p>The local convergence is characterized by the stability of the loss function. In order to escape local convergence, there are two options. The first option is to decrease the hyperparameters β 1 and β 2 and the second one consists of updating the centroids. In this work, we opt for both solutions to avoid local convergence. The hyperparameters β 1 and β 2 are dropped by κ K , where κ is the dropping rate of κ. We train our model until no reconstruction remains. At the end of the training process, each sample is mapped to its corresponding centroid. The output images of the network are smoother and easier to recognize as illustrated in <ref type="figure" target="#fig_4">Figure  6</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Embedded clustering</head><p>Embedded data points of each cluster are generally spread near non-linear manifolds. However, typical centroid-based clustering algorithms (e.g., K-Means) are only suitable for blob-like distributions. Minimizing the L 1 loss function does not make the embedded space clustering-friendly. To deal with this problem, an embedded clustering loss function L 2 is proposed to make the latent representations liable to centroid-based clustering. To this end, we propose an embedded clustering cost function that penalizes the distance between the data points and their associated centroids. Hence, the encoder learns to project the samples closer to their corresponding clustering representatives. This strategy was first introduced to train DCN <ref type="bibr" target="#b18">[19]</ref>. However, the aforementioned model has hard clustering assignments and does not consider any adaptive learning dynamics. All the embedded samples are pulled towards their corresponding centroids without considering the uncertainty of the clustering assignments.</p><p>Our proposed embedded clustering objective function is described by Equations 12 and 13. Compared to DCN, we use soft clustering assignments based on the Student's t-distribution. Moreover, our cost function is more suitable for handling the conflicted data points issue. Similar to the previous loss function in <ref type="bibr">Equation 9</ref>, the learning dynamics are controlled by the same confidence hyperparameters β 1 and β 2 . The set of reliable samples (i.e., unconflicted) is defined by Equation <ref type="bibr" target="#b12">13</ref>. The number of points belonging to this set increases automatically from one iteration to another. This happens even if we keep β 1 and β 2 constant during the whole training process. This result is confirmed by the experiments presented in the following section. In the beginning, simple patterns of each cluster are learned by attracting the most reliable examples to their corresponding centroids. Then, based on the knowledge acquired from clustering and attracting the most reliable samples, more difficult examples become reliable to be clustered. Unlike L 1 , conflicted data points are not exploited in L 2 until they become unconflicted.</p><formula xml:id="formula_12">L 2 (θ e (t), θ d (t)) = xi∈S f θe (x i ) − σ(x i )) 2 2 ,<label>(12)</label></formula><formula xml:id="formula_13">S = {x i ∈ X| h i1 ≥ β 1 and (h i1 − h i2 ) ≥ β 2 } .<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Joint clustering and centroids construction</head><p>The Complete dynamic objective function is defined in Equation <ref type="bibr" target="#b13">14</ref>. Similar to the pretraining phase, the loss function L is regularized by data augmentation. Unlike related works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32]</ref>, the balancing hyperparameter is unrequired in our case. DynAE aims to reach a better trade-off between Feature Randomness and Feature Drift using the learning dynamics (without any balancing hyperparameter). The whole clustering framework is shown in <ref type="figure" target="#fig_5">Figure 7</ref>. </p><formula xml:id="formula_14">L(θ e (t), θ d (t)) = L 1 (θ e (t), θ d (t)) + L 2 (θ e (t), θ d (t)).<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimization</head><p>The loss function 14 is optimized using mini-batch gradient descent and backpropagation to solve for the autoencoder's weights. We run the optimization process for M axIter batch iterations or until τ becomes lower than a specific amount tol of the total training set.</p><p>During DynAE training, our objective function moves smoothly and gradually from pure self-supervision towards pure pseudo-supervision. In the beginning, the model is pretrained with a purely self-supervised objective function.</p><p>In the end, the final objective function is almost purely pseudo-supervised (τ becomes very low). This transition from self-supervision towards pseudo-supervision includes transient objectives, where we combine both strategies. As the training progresses, pseudo-supervision increases and self-supervision decreases. The intuition behind our idea (described in detail earlier) can be summarized as: a) Pseudo-supervision is not reliable at the beginning due to a large number of fake labels. It leads to Feature Randomness. b) Self-supervision is great for learning general-purpose features, but it does not reflect our ultimate clustering objective. c) Combining pseudo-supervision and self-supervision can cause Feature Drift. d) Pseudo-supervision is very effective when we have reliable pseudo-labels. Our dynamic training strategy is illustrated in <ref type="figure" target="#fig_6">Figure 8</ref>.</p><p>Our method is illustrated in Algorithm 1. Without considering the pretraining phase, the computational complexity of DynAE is O(mLD 3 ), where m is the number of training iterations, L is the number of layers and D is the maximal number of neurons in the hidden layers. It is worth to mention that DEC, IDEC, DCN and DynAE, all have the same computational complexity. Therefore, for the same network architecture, the same batch size, the same optimizer and the same pretraining phase, the execution time of these four approaches can be strictly compared based on the number of iterations required for convergence.   </p><formula xml:id="formula_15">X, Γ, β 1 , β 2 ) if nbConf ≥ nbConfPrev then Γ ← updateCentroids(X, K) β 1 ← β 1 − 1 K κ β 2 ← β 2 − 1 K κ κ ← κ end if if</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>As explained in the previous section, our methodology consists of optimizing a dynamic objective function to gradually and smoothly reach a better trade-off between Feature Randomness and Feature Drift. In order to validate the suitability of smooth dynamics in solving the stated problem, we conduct extensive experiments. In section 5.1, we present the experimental settings. In section 5.2, we present our results, which strongly back-up our intuitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>All experiments were carried out on Google Colaboratory platform 1 . The code of our model DynAE is published on Github 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets and baselines</head><p>We compare DynAE with several clustering algorithms on four famous datasets: MNIST-full <ref type="bibr" target="#b51">[52]</ref>, MNIST-test, USPS <ref type="bibr" target="#b52">[53]</ref>, and Fashion-MNIST <ref type="bibr" target="#b53">[54]</ref>. All samples were normalized and flattened before feeding them to our fully-connected network. For convolutional deep clustering models, the input data is not flattened.</p><p>• MNIST-full <ref type="bibr" target="#b51">[52]</ref>: A 10 classes dataset of 70000 samples. Each sample is a 28 × 28 grayscale image of a handwritten digit.</p><p>• MNIST-test: A test subset of the MNIST-full dataset with 10000 data samples.</p><p>• USPS <ref type="bibr" target="#b52">[53]</ref>: A 10 classes dataset of 9298 samples. Each sample is a 16 × 16 grayscale digit image.</p><p>• Fashion-MNIST <ref type="bibr" target="#b53">[54]</ref>: A 10 classes dataset of 70000 samples. Each sample is a 28 × 28 grayscale image of a fashion product.</p><p>Our baselines include models from different clustering categories. For classical clustering, K-Means <ref type="bibr" target="#b4">[5]</ref>, Least Squares Non-negative Matrix Factorization (LSNMF) <ref type="bibr" target="#b54">[55]</ref>, Gaussian mixture models (GMM) <ref type="bibr" target="#b55">[56]</ref> and Agglomerative Clustering (AC) <ref type="bibr" target="#b56">[57]</ref> are selected. For subspace clustering, our baselines include two state-of-the-art subspace models. It is worth to note that most existing subspace algorithms are not scalable enough to handle databases with 70000 samples. Therefore, our choice was limited to Scalable Sparse Subspace Clustering by Orthogonal Matching Pursuit (SSC-OMP) <ref type="bibr" target="#b57">[58]</ref> and Scalable Elastic Net Subspace Clustering (EnSC) <ref type="bibr" target="#b58">[59]</ref>. For manifold clustering, we opted for normalized-cut spectral clustering (SC) <ref type="bibr" target="#b59">[60]</ref> and RBF K-Means <ref type="bibr" target="#b60">[61]</ref>. As for deep clustering, our experimental protocol include several approaches: JULE <ref type="bibr" target="#b22">[23]</ref>, DEC <ref type="bibr" target="#b16">[17]</ref>, IDEC <ref type="bibr" target="#b17">[18]</ref>, DEPICT <ref type="bibr" target="#b31">[32]</ref>, DCN <ref type="bibr" target="#b18">[19]</ref>, VaDE <ref type="bibr" target="#b30">[31]</ref>, SR-K-Means <ref type="bibr" target="#b34">[35]</ref> and DeepCluster <ref type="bibr" target="#b24">[25]</ref>. We have also compared our model against AE+K-Means and AE+FINCH where, the latent samples are clustered using K-Means and FINCH, respectively, after training an autoencoder to reconstruct the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Evaluation Metrics</head><p>ACC <ref type="bibr" target="#b61">[62]</ref> and NMI <ref type="bibr" target="#b62">[63]</ref> are the most utilized evaluation metrics in the deep clustering literature. Both of them lie in the range [0, 1]. The higher these values are the better our clustering results. Mathematically, ACC and NMI can be defined by Equations 15 and 16, respectively. In these equations, y true represents the vector of ground-truth labels and y pred is the vector of clustering indexes. I is the mutual information function and H denotes the entropy. Finally, T is the best one-to-one mapping that matches the clustering indexes to their corresponding ground truth labels. This mapping can be found using the Hungarian algorithm <ref type="bibr" target="#b63">[64]</ref>.</p><formula xml:id="formula_16">ACC(y pred , y true ) = max T N i=1 1 {y true (i) = T (y pred (i))} N ,<label>(15)</label></formula><p>N M I(y true , y true ) = I(y true , y pred ) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Implementation</head><p>For the sake of fair comparison, we opt for the same architecture proposed by a significant number of our deep clustering baselines <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b18">19]</ref>. Our encoder and decoder are fully connected neural networks. The autoencoder has 8 layers with dimensions d -500 -500 -2000 -10 -2000 -500 -500 -d. Except for the bottleneck layer and the last layer, all the other ones rely on ReLu <ref type="bibr" target="#b64">[65]</ref> activation functions. During the pretraining stage, the autoencoder is trained adversarially end-to-end in competition with a critic network for 13 × 10 4 iterations. For this phase, all the learnable parameters θ f , θ g and θ c are updated using Adam <ref type="bibr" target="#b65">[66]</ref> with a learning rate equal to 0.0001 and default values for β 1 , β 2 , and (here we are referring to the optimizer hyperparameters not to the ones of our model). The hyperparameters λ and α are set as described in <ref type="bibr" target="#b48">[49]</ref>. During the clustering phase, the autoencoder is trained until meeting the convergence criterion with a convergence threshold tol = 1% or reaching a maximal number of iterations M axIter = 10 5 . The confidence threshold is set to κ = 0.3 × K and its dropping rate is set to κ = 0.3 × κ. The training parameters θ f and θ g are updated using SGD with a learning rate ϑ = 0.001 and a momentum equal to 0.9. Both the pretraining and clustering phases are executed in batches of size 256 each. DynAE was implemented using Python and Tensorflow <ref type="bibr" target="#b66">[67]</ref>. The hyperparameters of our baselines are fixed to their default values provided by the authors of the related state-of-the-art works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Our experimental results can be divided into five sections. In the first section, we compare DynAE with state-of-the-ofart clustering approaches using the standard metrics. In the second section, we show the suitability of our gradual and smooth dynamics in learning unsupervised representations. In the third section, our experiments prove the ability of DynAE to reduce Feature Randomness and Feature Drift using our proposed metrics ∆ F R and ∆ F D . In the fourth section, for even fairer comparison, we introduce a balancing hyperparameter γ, similar to related works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32]</ref> that can balance between the two losses, to show that DynAE achieves state-of-the-art results for a wide range of γ as well. Finally, in the fifth section, we illustrate some qualitative results. In all the following experiments, approaches marked with '*' share the same architecture and the same pretraining weights with DynAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Comparing to state-of-the-art approaches</head><p>In table 2, we provide a comparative evaluation of our proposed DynAE to several clustering approaches from different categories. Our first evaluation aims to compare DynAE to the different approaches, in terms of clustering effectiveness, using the ACC and NMI metrics. First, we notice that the classical clustering approaches generally outperform the subspace methods. Although subspace clustering is designed to deal with high-dimensional data, it is well known that clusters from high-semantic datasets (e.g., images, sound, text etc) lie on non-linearly shaped manifolds. Subspace methods surmise that the clusters lie on a union of linear subspaces. This assumption contradicts the manifold hypothesis. Thus, it can be a possible explanation to the first observation. As a second observation, it is clear that AC has better ACC and NMI than the other classical methods. In fact, since high-semantic features are hierarchical, merging pairs of clusters gradually can probably help to find high-semantic similarities. Except for AC, we can see that the manifold clustering methods outperform the classical ones on all datasets. Furthermore, we can see from <ref type="table" target="#tab_3">Table 2</ref> that deep clustering methods outperform the other clustering methods significantly. This result confirms the convenience of processing high-dimensional, high-semantic, and large-scale data using deep neural networks. Comparing among the deep clustering strategies, DynAE beats its deep baselines on every dataset by a considerable margin. For example, we can observe that the ACC provided by DynAE is at least 2% higher than the ACC provided by DEPICT. Besides, the NMI provided by DynAE is at least 5% higher than the NMI provided by DEPICT. It is important to note that DEC and DEPICT have the same clustering strategy. The main difference between them is their neural architectures. More precisely, DEC leverages a simple fully-connected architecture, DEPICT makes use of a convolutional architecture. Generally speaking, each one of the compared models in <ref type="table" target="#tab_3">Table 2</ref> differs from the other ones in different aspects. Among these aspects: (1) the used architecture, (2) the integrated prior knowledge (e.g., invariance of the samples to small linear geometric transformations), (3) the selected objective function for the pretraining phase and (4) the learning dynamics. In order to show the importance of our learning dynamics, we should neutralize the other aspects. Therefore, we have reimplemented two famous deep clustering models, namely, DEC and IDEC, according to our architecture, integrated prior knowledge, and pretraining objective function. We denote the new obtained models DEC* and IDEC*. It is worth to note that DynAE already shares the same architecture with DEC* and IDEC*. Therefore, we should only pretrain these models to minimize an adversarially constrained interpolation loss regularized with data augmentation. In <ref type="table" target="#tab_4">Table 3</ref>, we illustrate our obtained results. Based on these results, we make the following observations. First, DEC* and IDEC* outperform their standard versions DEC and IDEC, respectively, by a significant margin. This result proves the importance of our pretraining strategy compared with the vanilla reconstruction performed by DEC and IDEC. Second, we observe that DynAE still outperforms DEC* and IDEC* on all datasets, in terms of ACC and NMI. This result shows the importance of our smooth dynamic objective function in learning discriminative unsupervised representations. In <ref type="table" target="#tab_5">Table 4</ref>, we compare DynAE to several deep clustering methods, in terms of run-time. In this comparison, we exclude the other clustering categories because of their less competitive results in <ref type="table" target="#tab_3">Table 2</ref>. Based on our comparison, we make the following observations. First, we can notice that the execution time of our model is higher than the execution time of DeepCluster, DCN, DEC, IDEC. Even so, the run-time of DynAE is on an equal footing with the ones of DEPICT, SR-Kmeans, and JULE on some datasets. Compared to VaDE, our model has a lower execution time on all evaluated datasets. In order to better evaluate the efficiency of our model, we compare its execution time with the ones of DEC* and IDEC*. Based on <ref type="table" target="#tab_6">Table 5</ref>, we make the following observations. First, the run-time of DEC and IDEC is significantly lower than the run-time of DEC* and IDEC*, respectively. Hence, we can conclude that the adversarial pretraining phase causes overhead. Second, we observe that the run-time of DynAE is on an equal footing with DEC* and IDEC* on all datasets. Thus, we can conclude that our dynamic clustering phase does not lead to any considerable increase in the execution time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Dynamic learning</head><p>In this section and the following two sections, we show results of a single dataset, namely, MNIST. The reader can refer to the supplementary material (A, B and C) to find results on other datasets. It is worth to note that the same conclusions can be drawn using MNIST-full or MNIST-test or USPS or Fashion-MNIST. In this part of our experimental protocol, we aim to show the effect of training using a smooth dynamic loss function. <ref type="figure" target="#fig_9">Figure 9</ref> illustrates the learning dynamics during training on MNIST. We can describe the dynamics of our learning system by the evolution of the optimized objective function, which in turn can be described by the amount of reconstruction τ . In <ref type="figure" target="#fig_9">Figure 9</ref>.a, we can clearly notice that the clustering loss decreases almost smoothly. Hence, we can conclude that the gradual change of our objective function does not perturb the learning process. In <ref type="figure" target="#fig_9">Figure 9</ref>.b, we draw the percentage of conflicted samples (respectively the percentage of unconflicted samples) against the number of iterations. At every iteration, the percentage of conflicted points represents the amount of reconstruction τ . As we can see from <ref type="figure" target="#fig_9">Figure 9</ref>.b, the percentage of conflicted points decreases smoothly until reaching the red circle. Close to iteration 5000, the dropping rate of the conflicted samples starts to slow down. At this stage, the model has reached local stability. In order to avoid the local optimum, the centroids, β 1 and β 2 are updated automatically at this stage. This update causes an abrupt decrease in the number of conflicted samples, as we can see inside the red circle. Although the centroids, β 1 , and β 2 are never updated before the red circle, the number of conflicted samples decreases smoothly from one iteration to another. This result confirms that the knowledge acquired from clustering the most reliable samples gradually makes more difficult samples (conflicted) become reliable for clustering (unconflicted).   <ref type="figure" target="#fig_0">Figure 10</ref> illustrates the evolution of ACC and NMI during training on MNIST. First, we observe that both metrics increase smoothly as computed using the whole training set. In <ref type="figure" target="#fig_0">Figure 10</ref>.a, we observe that the ACC and NMI of the unconflicted samples decrease slowly before reaching local stability between the iterations 4000 and 5000. This result is expected. In fact, as long as the number of reliable samples increases, there is a low probability of making some errors. These errors are associated with training using the newly clustered samples. Most interestingly, we observe that the accuracy of the unconflicted subset is greater than 99.8% at iteration 4000. At this stage, the size of the unconflicted subset constitutes more than 80% of the whole training set. In <ref type="figure" target="#fig_0">Figure 10</ref>.b, we observe that the ACC and NMI of the conflicted samples decrease rapidly. As the training progresses, the remaining conflicted points are more challenging than the newly clustered ones. Therefore, their ACC and NMI are gradually decreasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Feature Randomness and Feature Drift</head><p>To show the ability of our model to reduce Feature Randomness and Feature Drift, we propose to ablate the dynamic mechanism and compare the obtained model with DynAE. We denote the model obtained after performing ablation by DC*. DC* has the same optimizer and pretraining phase as DynAE. However, it is trained to optimize joint embedded K-Means and reconstruction. We also compare DynAE with IDEC* and ADEC. <ref type="figure" target="#fig_0">Figure 11</ref> illustrates the evolution of ∆ F R values for DynAE, ADEC, DC*, and IDEC* during training on MNIST. From this figure, we can see that the average ∆ F R for DynAE is higher than the average ∆ F R for ADEC and significantly higher than the average ∆ F R for DC* and IDEC*. At the beginning of the training process, we observe that the gradient of ADEC is a good approximation to the supervised gradient (∆ F R = 0.9). As the training progresses, ∆ F R for  DynAE tends to increase with some fluctuations. However, ∆ F R for ADEC decreases and ∆ F R for DC* and IDEC* does not seem to have a clear increasing tendency. At the end of the training process, ∆ F R for DynAE reaches a value greater than 0.9. This means that the direction of the gradient of DynAE becomes very close to the direction of the supervised gradient. Hence, we can confirm that our dynamic learning mechanism is suitable for mitigating the effect of Feature Randomness.  If we compare the learning curves of DynAE using both metrics ACC and ∆ F R , we observe that the learning curve evaluated based on ACC increases smoothly without any fluctuations. As opposed to that, the learning curve of DynAE evaluated based on ∆ F R oscillates. This result suggests that the evolution of ACC hide some important information related to the learning process. <ref type="figure" target="#fig_0">Figure 12</ref> illustrates the evolution of ∆ F D for DynAE, ADEC, DC*, and IDEC* during training on MNIST. From this figure, we observe that the average ∆ F D for DynAE is higher than the average ∆ F D for ADEC and considerably higher than the average ∆ F D for DC* and IDEC*. Furthermore, ∆ F D is always negative for DC* and IDEC*, with an average value around −0.7. This negative value reflects the strong competition between the gradient of the vanilla reconstruction and the gradient of the embedded clustering loss. Based on these observations, we can confirm that our dynamic learning mechanism is suitable for alleviating the effect of Feature Drift by gradually eliminating the reconstruction loss.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Effect of introducing a balancing hyperparameter</head><p>In order to evaluate the impact of a balancing hyperparameter γ on DynAE (similar to IDEC), we propose to change the objective function of our model to L = L 1 + γL 2 . <ref type="figure" target="#fig_0">Figure 13</ref> illustrates the effect of γ on the training of DynAE and IDEC*. In this experiment, we tried different γ values from the set 10 −3 , 10 −2 , 10 −1 , 1, 10, 10 2 , 10 3 . We found γ = 0.01 provides us the best learning curves for both models. For IDEC*, apart from γ = 0.01, all the other values make the learning curves detoriate drastically. Hence, we conclude that IDEC* is very sensitive to the setting of γ. However, DynAE almost reaches the same ACC at the end of the training process for 6 γ values out of 7. For γ = 0.001, γL 2 becomes significantly smaller compared to L 1 . Thus, the gradient of the self-supervised loss drifts the features learned in the direction of the embedded clustering loss γL 2 . For this reason, the learning curve of DynAE, for γ = 0.001, has a collapsing shape. As γ grows, γL 2 becomes significantly greater than L 1 . Hence, pseudo-supervision becomes dominant of the training process, leading to Feature Randomness. Going from 0.01 to 1000, we observe that the number of iterations required for convergence increases. Added to that, the final ACC of DynAE slightly decreases when γ increases. However, as we can see from the figure, it is apparent that DynAE is considerably less sensitive to the setting of γ when compared to IDEC*. This result confirms that our model offers a better trade-off between Feature Randomness and Feature Drift compared to IDEC*.  We further evaluate the impact of Feature Drift on ACC and NMI with γ = 0.01, which provides the best learning curves for both DynAE and IDEC*. In <ref type="figure" target="#fig_0">Figure 14</ref>, we draw the evolution of ACC and NMI for DynAE and IDEC* during training on MNIST with γ = 0.01. In <ref type="figure" target="#fig_0">Figure 16</ref> and 15, we zoom in to each curve separately to inspect better. We notice that the ACC and NMI curves of DynAE are nearly smoothly increasing during the training process. However, the ACC and NMI curves of IDEC* undergo noticeable fluctuations. A possible explanation of these fluctuations is the strong competition between embedded clustering and vanilla reconstruction, which is reduced in DynAE. We also see that the highest ACC value for DynAE during training on MNIST is 0.98861. Thus, it is likely possible to improve results reported in <ref type="table" target="#tab_3">Table 2</ref> further by tuning the balancing hyperparameter. However, the reported balancing hyperparameter-free DynAE (i.e., L = L 1 + L 2 ) achieves competitive results without the requirement of tuning due to the weaker competition between embedded clustering and vanilla reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Qualitative results</head><p>The discriminative ability of DynAE can be illustrated in <ref type="figure" target="#fig_0">Figure 17</ref>. In this figure, we visualize 2D embedded representations for each dataset. These representations are obtained by applying PCA to the latent representations at the end of the clustering phase. Based on our results, we can see that the clusters are well-separated for all datasets. In    <ref type="figure" target="#fig_0">Figure 16</ref>: NMI values during training on MNIST (γ = 0.01). <ref type="figure" target="#fig_0">Figure 18</ref>, the top 10 high-confidence images from each cluster are displayed in each row. As we can notice, DynAE has managed to capture semantic similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this article, we have introduced Dynamic Autoencoder, a deep clustering model that integrates smooth learning dynamics. Our proposition consists of gradually and smoothly transforming a self-supervised objective into a pseudosupervised one. Empirical studies show the effectiveness and suitability of our model in clustering benchmark datasets. In terms of ACC and NMI, DynAE achieves state-of-the-art results compared to the most relevant deep clustering methods. Added to that, experimental evaluations have shown that our approach offers a better trade-off between Feature Randomness and Feature Drift. We strongly believe that the simple but intuitive formulation of DynAE has a lot more potential. In future work, we would like to try a more sophisticated architecture (e.g., VGG, AlexNet, and ResNet32) to cluster larger datasets with higher semanticity. It is also interesting to investigate other techniques, apart from K-Means, for computing the embedded centroids. While jointly performing pseudo-supervision and self-supervision is               </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the first deep clustering family: embedded learning is performed before clustering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of the second deep clustering family: embedded learning and clustering are performed jointly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The common network structure of autoencoder-based clustering algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>The general clustering architecture of DynAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>The centroids construction from DynAE at the end of the training process. Top row: MNIST input; bottom row: Output images from DynAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>The clustering phase of DynAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>An illustration of our complete training strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 2 [</head><label>2</label><figDesc>H(y true ) + H(y pred )]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( a )</head><label>a</label><figDesc>Clustering loss. (b) Dynamics of the clustering loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Learning dynamics during training on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>ACC and NMI values during training on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(a) DynAE. (b) ADEC. (c) DC*. (d) IDEC*.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 :</head><label>11</label><figDesc>∆ F R values during training on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 12 :</head><label>12</label><figDesc>∆ F D values during training on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 13 :</head><label>13</label><figDesc>Effect of the balancing hyperparameter during training on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 14 :</head><label>14</label><figDesc>ACC and NMI during training on MNIST (γ = 0.01).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 15 :</head><label>15</label><figDesc>ACC values during training on MNIST (γ = 0.01).(a) DynAE. (b) IDEC*.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 17 :</head><label>17</label><figDesc>Visualizing 2D embedded subspaces to show the discriminative ability of DynAE. (a) MNIST. (b) Fashion MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 18 :</head><label>18</label><figDesc>Top 10 high-confidence images from each cluster displayed in each row. of paramount importance, it is still unclear if the linear combination used by state-of-the-art autoencoder-based models is the best formalism. Studying other possible formulations can be an interesting line of research. A Experimental Results on MNIST-test (a) Clustering loss. (b) Dynamics of the clustering loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 19 :</head><label>19</label><figDesc>Learning dynamics during training on MNIST-test.(a) Unconflicted data. (b) Conflicted data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 20 :</head><label>20</label><figDesc>ACC and NMI values during training on MNIST-test.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 21 :</head><label>21</label><figDesc>∆ F R values during training on MNIST-test.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 22 :</head><label>22</label><figDesc>∆ F D values during training on MNIST-test. B Experimental Results on USPS (a) Clustering loss. (b) Dynamics of the clustering loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 23 :</head><label>23</label><figDesc>Learning dynamics during training on USPS.(a) Unconflicted data. (b) Conflicted data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Figure 24 :</head><label>24</label><figDesc>ACC and NMI values during training on USPS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 25 :</head><label>25</label><figDesc>∆ F R values during training on USPS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 26 :</head><label>26</label><figDesc>∆ F D values during training on USPS. C Experimental Results on Fashion-MNIST (a) Clustering loss. (b) Dynamics of the clustering loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 27 :</head><label>27</label><figDesc>Learning dynamics during training on FMNIST.(a) Unconflicted data. (b) Conflicted data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 28 :</head><label>28</label><figDesc>ACC and NMI values during training on MNIST. (a) DynAE. (b) DC*.(c) IDEC*.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 29 :</head><label>29</label><figDesc>∆ F R values during training on Fashion-MNIST. (a) DynAE. (b) DC*.(c) IDEC*.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 30 :</head><label>30</label><figDesc>∆ F D values during training on Fashion-MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Analogy between autoencoder-based clustering and signal processing.</figDesc><table><row><cell>Signal processing</cell><cell>Autoencoder clustering</cell><cell>Transformation</cell><cell>Strategy</cell></row><row><cell>Fourier transform</cell><cell>Reconstruction</cell><cell>Generative transformation</cell><cell>Target patterns are more pronounced in the new space.</cell></row><row><cell>Filtering</cell><cell>Embedded clustering</cell><cell>Discriminative transformation</cell><cell>Non discriminative patterns are destroyed.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The ACC and NMI of different clustering approaches. Each category is separated from the other ones by a double horizontal line. -indicates that the program ran out of memory. Best method in bold, second best emphasized.</figDesc><table><row><cell>Method</cell><cell cols="2">MNIST-full</cell><cell cols="2">MNIST-test</cell><cell cols="2">USPS</cell><cell cols="2">Fashion-MNIST</cell></row><row><cell></cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell></row><row><cell>K-Means</cell><cell cols="7">0.532 0.500 0.546 0.501 0.668 0.627 0.474</cell><cell>0.512</cell></row><row><cell>GMM</cell><cell cols="7">0.433 0.366 0.540 0.493 0.551 0.530 0.556</cell><cell>0.557</cell></row><row><cell>LSNMF</cell><cell cols="7">0.540 0.455 0.550 0.463 0.575 0.551 0.549</cell><cell>0.523</cell></row><row><cell>AC</cell><cell cols="7">0.621 0.682 0.695 0.711 0.683 0.725 0.500</cell><cell>0.564</cell></row><row><cell>SSC-OMP</cell><cell cols="7">0.309 0.315 0.413 0.450 0.477 0.503 0.100</cell><cell>0.007</cell></row><row><cell>EnSC</cell><cell cols="7">0.111 0.014 0.603 0.591 0.610 0.684 0.629</cell><cell>0.636</cell></row><row><cell>SC</cell><cell cols="7">0.656 0.731 0.660 0.704 0.649 0.794 0.508</cell><cell>0.575</cell></row><row><cell>RBF K-Means</cell><cell>-</cell><cell>-</cell><cell cols="4">0.560 0.523 0.629 0.631</cell><cell>-</cell><cell>-</cell></row><row><cell>AE + K-Means</cell><cell cols="7">0.807 0.730 0.702 0.617 0.720 0.698 0.585</cell><cell>0.614</cell></row><row><cell>AE + FINCH</cell><cell>-</cell><cell>-</cell><cell cols="4">0.709 0.754 0.704 0.788</cell><cell>-</cell><cell>-</cell></row><row><cell>DeepCluster</cell><cell cols="7">0.797 0.661 0.854 0.713 0.562 0.540 0.542</cell><cell>0.510</cell></row><row><cell>DCN</cell><cell cols="7">0.830 0.810 0.802 0.786 0.688 0.683 0.501</cell><cell>0.558</cell></row><row><cell>DEC</cell><cell cols="7">0.863 0.834 0.856 0.830 0.762 0.767 0.518</cell><cell>0.546</cell></row><row><cell>IDEC</cell><cell cols="7">0.881 0.867 0.846 0.802 0.761 0.785 0.529</cell><cell>0.557</cell></row><row><cell>SR-KMeans</cell><cell cols="7">0.939 0.866 0.863 0.873 0.901 0.912 0.507</cell><cell>0.548</cell></row><row><cell>VaDE</cell><cell cols="7">0.945 0.876 0.287 0.287 0.566 0.512 0.578</cell><cell>0.630</cell></row><row><cell>JULE</cell><cell cols="7">0.964 0.913 0.961 0.915 0.950 0.913 0.563</cell><cell>0.608</cell></row><row><cell>DEPICT</cell><cell cols="7">0.965 0.917 0.963 0.915 0.899 0.906 0.392</cell><cell>0.392</cell></row><row><cell>DynAE</cell><cell cols="7">0.987 0.964 0.987 0.963 0.981 0.948 0.591</cell><cell>0.642</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The ACC and NMI of DEC*, IDEC* and DynAE. Best method in bold, second best emphasized.</figDesc><table><row><cell>Method</cell><cell cols="2">MNIST-full</cell><cell cols="2">MNIST-test</cell><cell cols="2">USPS</cell><cell cols="2">Fashion-MNIST</cell></row><row><cell></cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell></row><row><cell>DEC*</cell><cell cols="7">0.971 0.929 0.968 0.920 0.963 0.910 0.575</cell><cell>0.589</cell></row><row><cell>IDEC*</cell><cell cols="7">0.982 0.952 0.978 0.944 0.980 0.946 0.575</cell><cell>0.631</cell></row><row><cell>DynAE</cell><cell cols="7">0.987 0.964 0.987 0.963 0.981 0.948 0.591</cell><cell>0.642</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>The execution time (in seconds) of different deep clustering approaches.</figDesc><table><row><cell>Method</cell><cell cols="4">MNIST-full MNIST-test USPS Fashion-MNIST</cell></row><row><cell>DeepCluster</cell><cell>1375</cell><cell>74</cell><cell>64</cell><cell>1250</cell></row><row><cell>DCN</cell><cell>640</cell><cell>55</cell><cell>49</cell><cell>732</cell></row><row><cell>DEC</cell><cell>693</cell><cell>58</cell><cell>53</cell><cell>2384</cell></row><row><cell>IDEC</cell><cell>890</cell><cell>349</cell><cell>110</cell><cell>857</cell></row><row><cell>SR-KMeans</cell><cell>14872</cell><cell>1657</cell><cell>1655</cell><cell>4551</cell></row><row><cell>VaDE</cell><cell>123000</cell><cell>15000</cell><cell>13000</cell><cell>120000</cell></row><row><cell>JULE</cell><cell>12500</cell><cell>3247</cell><cell>2540</cell><cell>13100</cell></row><row><cell>DEPICT</cell><cell>9561</cell><cell>2320</cell><cell>1778</cell><cell>8581</cell></row><row><cell>DynAE</cell><cell>10808</cell><cell>9924</cell><cell>7910</cell><cell>10508</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>The execution time (in seconds) of DEC*, IDEC* and DynAE.</figDesc><table><row><cell>Method</cell><cell cols="4">MNIST-full MNIST-test USPS Fashion-MNIST</cell></row><row><cell>DEC*</cell><cell>9667</cell><cell>9092</cell><cell>7692</cell><cell>10840</cell></row><row><cell>IDEC*</cell><cell>9556</cell><cell>9160</cell><cell>7693</cell><cell>9623</cell></row><row><cell>DynAE</cell><cell>10808</cell><cell>9924</cell><cell>7910</cell><cell>10508</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https: // colab. research. google. com 2 https://github.com/nairouz/DynAE</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">3d data management: Controlling data volume, velocity and variety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Laney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
		<respStmt>
			<orgName>META group research note</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Imagenet: A large-scale hierarchical image database. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Discrete choice methods with simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kenneth E Train</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the fifth Berkeley symposium on mathematical statistics and probability</meeting>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hierarchical clustering schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="254" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="559" to="572" />
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Analysis of multivariate social science data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fiona</forename><surname>Bartholomew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irini</forename><surname>Galbraith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moustaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vin</forename><forename type="middle">De</forename><surname>Joshua B Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Trevor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Automatic subspace clustering of high dimensional data for data mining applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Gunopulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>ACM</publisher>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Kernel k-means: spectral clustering and normalized cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqiang</forename><surname>Inderjit S Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the tenth ACM SIGKDD international Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="551" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1753" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyi</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3861" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep discriminative latent space for clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Tzoreff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoni</forename><surname>Choukroun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10795</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atul</forename><surname>Sohil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01449</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Deep continuous clustering. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elie</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the German Conference on Pattern Recognition (GCPR)</title>
		<meeting>the German Conference on Pattern Recognition (GCPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning discrete representations via information maximizing self-augmented training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichi</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1558" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nairouz</forename><surname>Mrabah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Bouguessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riadh</forename><surname>Ksantini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11832</idno>
		<title level="m">Adversarial deep embedded clustering: on a better trade-off between feature randomness and feature drift</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep embedding network for clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep subspace clustering with sparsity prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijie</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1925" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Variational deep embedding: An unsupervised and generative approach to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuxi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huachun</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangsheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1965" to="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirhossein</forename><surname>Kamran Ghasedi Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5747" to="5756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Jabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amar</forename><surname>Mitiche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Ben Ayed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04246</idno>
		<title level="m">Deep clustering: On the link between discriminative models and k-means</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep embedded clustering with data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">En</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning (ACML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="550" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<title level="m">Soumith Chintala, and Léon Bottou. Wasserstein generative adversarial networks. International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<title level="m">Towards principled methods for training generative adversarial networks. International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning (ICML)</title>
		<meeting>the 25th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<title level="m">Colorful image colorization. European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Revisiting self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1920" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Understanding and improving interpolation in autoencoders via an adversarial regularizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Clustering by means of medoids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Rousseeuw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<pubPlace>North-Holland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Clarans: A method for clustering objects for spatial data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1003" to="1016" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Mnist handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist" />
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
		<respStmt>
			<orgName>AT&amp;T Labs</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A database for handwritten text recognition research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="550" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Projected gradient methods for nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation (NC)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2756" to="2779" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Data clustering: 50 years beyond k-means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters (PRL)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="651" to="666" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Scalable sparse subspace clustering by orthogonal matching pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">René</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3918" to="3927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Oracle based active set algorithm for scalable elastic net subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Guang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">René</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3928" to="3937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page">107</biblScope>
		</imprint>
	</monogr>
	<note>Departmental Papers (CIS)</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Nonlinear component analysis as a kernel eigenvalue problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation (NC)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1319" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Locally consistent concept factorization for document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="902" to="913" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Cluster ensembles-a knowledge reuse framework for combining multiple partitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="583" to="617" />
			<date type="published" when="2002-12" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harold W Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval Research Logistics (NRL)</title>
		<imprint>
			<date type="published" when="1955" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OSDI</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
