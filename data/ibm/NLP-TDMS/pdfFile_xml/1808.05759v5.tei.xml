<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Read + Verify: Machine Reading Comprehension with Unanswerable Questions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
							<email>huminghao09@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
							<email>fuwei@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
							<email>pengyuxing@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
							<email>huangzhen@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
							<email>dsli@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Read + Verify: Machine Reading Comprehension with Unanswerable Questions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine reading comprehension with unanswerable questions aims to abstain from answering when no answer can be inferred. In addition to extract answers, previous works usually predict an additional "no-answer" probability to detect unanswerable cases. However, they fail to validate the answerability of the question by verifying the legitimacy of the predicted answer. To address this problem, we propose a novel read-then-verify system, which not only utilizes a neural reader to extract candidate answers and produce noanswer probabilities, but also leverages an answer verifier to decide whether the predicted answer is entailed by the input snippets. Moreover, we introduce two auxiliary losses to help the reader better handle answer extraction as well as noanswer detection, and investigate three different architectures for the answer verifier. Our experiments on the SQuAD 2.0 dataset show that our system obtains a score of 74.2 F1 on test set, achieving state-of-the-art results at the time of submission (Aug. 28th, 2018).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The ability to comprehend text and answer questions is crucial for natural language processing. Due to the creation of various large-scale datasets <ref type="bibr" target="#b7">(Hermann et al. 2015;</ref><ref type="bibr" target="#b23">Nguyen et al. 2016;</ref><ref type="bibr" target="#b13">Joshi et al. 2017;</ref><ref type="bibr" target="#b15">Kočiskỳ et al. 2018</ref>), remarkable advancements have been made in the task of machine reading comprehension. Nevertheless, one important hypothesis behind current approaches is that there always exists a correct answer in the context passage. Therefore, the models only need to choose a most plausible text span based on the question, instead of checking if there exists an answer in the first place. Recently, a new version of Stanford Question Answering Dataset (SQuAD), namely SQuAD 2.0 (Rajpurkar, Jia, and Liang 2018), has been proposed to test the ability of answering answerable questions as well as detecting unanswerable cases. To deal with unanswerable cases, systems must learn to identify a wide range of linguistic phenomena such as negation, antonymy and entity changes between the passage and the question.</p><p>Previous works <ref type="bibr" target="#b17">(Levy et al. 2017;</ref><ref type="bibr" target="#b4">Clark and Gardner 2018;</ref><ref type="bibr" target="#b16">Kundu and Ng 2018)</ref> all apply a shared-normalization <ref type="figure">Figure 1</ref>: An overview of our approach. The reader first extracts a candidate answer and produces a no-answer probability (NA Prob). The answer verifier then checks whether the extracted answer is legitimate or not. Finally, the system aggregates previous results and outputs the final prediction. operation between a "no-answer" score and answer span scores, so as to produce a probability that a question is unanswerable as well as output a candidate answer. However, they have not considered further validating the answerability of the question by verifying the legitimacy of the predicted answer. Here, answerability denotes whether the question has an answer, and legitimacy means whether the extracted text can be supported by the passage and the question. Human, on the contrary, tends to first find a plausible answer given a question, and then checks if there exists any contradictory semantics.</p><p>To address the above issue, we propose a read-then-verify system that aims to be robust to unanswerable questions in this paper. As shown in <ref type="figure">Figure 1</ref>, our system consists of two components: (1) a no-answer reader for extracting candidate answers and detecting unanswerable questions, and (2) an answer verifier for deciding whether or not the extracted candidate is legitimate. The key contributions of our work are three-fold.</p><p>First, we augment existing readers with two auxiliary losses, to better handle answer extraction and no-answer detection respectively. Since the downstream verifying stage always requires a candidate answer, the reader must be able to extract plausible answers for all questions. However, previous approaches are not trained to find potential candidates for unanswerable questions. We solve this problem by introducing an independent span loss that aims to concentrate on the answer extraction task regardless of the answerability of the question. In order to not conflict with no-answer detection, we leverage a multi-head pointer network to generate two pairs of span scores, where one pair is normalized with the no-answer score and the other is used for our auxiliary loss. Besides, we present another independent noanswer loss to further alleviate the confliction, by focusing on the no-answer detection task without considering the shared normalization of answer extraction.</p><p>Second, in addition to the standard reading phase, we introduce an additional answer verifying phase, which aims at finding local entailment that supports the answer by comparing the answer sentence with the question. This is based on the observation that the core phenomenon of unanswerable questions usually occurs between a few passage words and question words. Take <ref type="figure">Figure 1</ref> for example, after comparing the passage snippet "Normandy, a region in France" with the question, we can easily determine that no answer exists since the question asks for an impossible condition 1 . This observation is even more obvious when antonym or mutual exclusion occurs, such as the question asks for "the decline of rainforests" but the passage mentions that "the rainforests spread out". Inspired by recent advances in natural language inference (NLI) <ref type="bibr">(Bowman et al. 2015)</ref>, we investigate three different architectures for the answer verifying task. The first one is a sequential model that takes two sentences as a long sequence, while the second one attempts to capture interactions between two sentences. The last one is a hybrid model that combines the above two models to test if the performance can be further improved.</p><p>Lastly, we evaluate our system on the SQuAD 2.0 dataset <ref type="bibr" target="#b30">(Rajpurkar, Jia, and Liang 2018)</ref>, a reading comprehension benchmark augmented with unanswerable questions. Our best reader achieves a F1 score of 73.7 and 69.1 on the development set, with or without ELMo embeddings <ref type="bibr" target="#b27">(Peters et al. 2018)</ref>. When combined with the answer verifier, the whole system improves to 74.8 F1 and 71.5 F1 respectively. Moreover, the best system obtains a score of 74.2 F1 on test set, achieving state-of-the-art results at the time of submission (Aug. 28th, 2018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Existing reading comprehension models focus on answering questions where a correct answer is guaranteed to exist. However, they are not able to identify unanswerable questions but tend to return an unreliable text span. Consequently, we first give a brief introduction on the unanswer-1 Impossible condition means that the question asks for something that is not satisfied by anything in the given passage. able reading comprehension task, and then investigate current solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Description</head><p>Given a context passage and a question, the machine needs to not only find answers to answerable questions but also detect unanswerable cases. The passage and the question are described as sequences of word tokens, denoted as P = {x p i } lp i=1 and Q = {x q j } lq j=1 respectively, where l p is the passage length and l q is the question length. Our goal is to predict an answer A, which is constrained as a segment of text in the passage: A = {x p i } l b i=la , or return an empty string if there is no answer, where l a and l b indicate the answer boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No-Answer Reader</head><p>To predict an answer span, current approaches first embed and encode both of passage and question into two series of fix-sized vectors. Then they leverage various attention mechanisms, such as bi-attention  or reattention <ref type="bibr" target="#b9">(Hu et al. 2018a)</ref>, to build interdependent representations for passage and question, which are denoted as</p><formula xml:id="formula_0">U = {u i } lp i=1 and V = {v j } lq j=1</formula><p>respectively. Finally, they summarize the question representation into a dense vector t, and utilize the pointer network <ref type="bibr" target="#b37">(Vinyals, Fortunato, and Jaitly 2015)</ref> to produce two scores over passage words that indicate the answer boundary <ref type="bibr" target="#b38">(Wang et al. 2017)</ref>:</p><formula xml:id="formula_1">o j = w T v v j , t = lq j=1 e oj lq k=1 e o k v j α, β = pointer network(U, t)</formula><p>where α and β are the span scores for answer start and end bounds.</p><p>In order to additionally detect if the question is unanswerable, previous approaches <ref type="bibr" target="#b17">(Levy et al. 2017;</ref><ref type="bibr" target="#b4">Clark and Gardner 2018;</ref><ref type="bibr" target="#b16">Kundu and Ng 2018)</ref> attempt to predict a special no-answer score z in addition to the distribution over answer spans. Concretely, a shared softmax function can be applied to normalize both of no-answer score and span scores, yielding a joint no-answer objective defined as:</p><formula xml:id="formula_2">L joint = − log (1 − δ)e z + δe αaβ b e z + lp i=1</formula><p>lp j=1 e αiβj where a and b are the ground-truth start and end positions, and δ is 1 if the question is answerable and 0 otherwise. At test time, a question is detected as being unanswerable once the normalized no-answer score exceeds some threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>In this section we describe our proposed read-then-verify system. The system first leverages a neural reader to extract a candidate answer and detect if the question is unanswerable. It then utilizes an answer verifier to further check the legitimacy of the predicted answer. We enhance the reader with two novel auxiliary losses, and investigate three different architectures for the answer verifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reader with Auxiliary Losses</head><p>Although previous no-answer readers are capable of jointly learning answer extraction and no-answer detection, there exists two problems for each individual task. For the answer extraction, previous readers are not trained to find candidate answers for unanswerable questions. In our system, however, the reader is required to extract a plausible answer that is fed to the downstream verifying stage for all questions.</p><p>As for no-answer detection, a confliction could be triggered due to the shared normalization between span scores and noanswer score. Since the sum of these normalized scores is always 1, an over-confident span probability would cause an unconfident no-answer probability, and vice versa. Therefore, inaccurate confidence on answer span, which has been observed by <ref type="bibr" target="#b4">Clark et al. (2018)</ref>, could lead to imprecise prediction on no-answer score. To address the above issues, we propose two auxiliary losses to optimize and enhance each task independently without interfering with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Independent Span Loss</head><p>This loss is designed to concentrate on answer extraction. In this task, the model is asked to extract candidate answers for all possible questions. Therefore, besides answerable questions, we also include unanswerable cases as positive examples, and consider the plausible answer as gold answer 2 . In order to not conflict with no-answer detection, we propose to use a multi-head pointer network to additionally produce another pair of span scores 2 In SQuAD 2.0, the plausible answer is annotated by human for every unanswerable question. A pre-trained reader can also be used to extract plausible answers if no annotation is provided.α andβ:õ</p><formula xml:id="formula_3">j =w T v v j ,t = lq j=1 eõ j lq k=1 eõ k v j α,β = pointer network(U,t)</formula><p>where multiple heads share the same network architecture but with different parameters. Then, we define an independent span loss as:</p><formula xml:id="formula_4">L indep−I = − log eαãβb lp i=1</formula><p>lp j=1 eα iβj whereã andb are the augmented ground-truth answer boundaries. The final span probability is obtained using a simple mean pooling over the two pairs of softmaxnormalized span scores.</p><p>Independent No-Answer Loss Despite a multi-head pointer network being used to prevent the confliction problem, no-answer detection can still be weakened since the no-answer score z is normalized with span scores. Therefore, we consider exclusively encouraging the prediction on no-answer detection. This is achieved by introducing an independent no-answer loss as:</p><formula xml:id="formula_5">L indep−II = −(1 − δ) log σ(z) − δ log(1 − σ(z))</formula><p>where σ is the sigmoid activation function. Through this loss, we expect the model to produce a more confident prediction on no-answer score z without considering the shared-normalization operation.</p><p>Finally, we combine the above losses as follows:</p><formula xml:id="formula_6">L = L joint + γL indep−I + λL indep−II</formula><p>where γ and λ are two hyper-parameters that control the weight of two auxiliary losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer Verifier</head><p>After the answer is extracted, an answer verifier is used to compare the answer sentence with the question, so as to recognize local textual entailment that supports the answer.</p><p>Here, we define the answer sentence as the context sentence that contains either gold answers or plausible answers. We explore three different architectures, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>:</p><p>(1) a sequential model that takes the inputs as a long sequence, (2) an interactive model that encodes two sentences interdependently, and (3) a hybrid model that takes both of the two approaches into account.</p><p>Model-I: Sequential Architecture In Model-I, we convert the answer sentence and the question along with the extracted answer into an ordered input sequence. Then we adapt the recently proposed Generative Pre-trained Transformer (OpenAI GPT) <ref type="bibr" target="#b28">(Radford et al. 2018)</ref> to perform the task. The model is a multi-layer Transformer decoder <ref type="bibr" target="#b18">(Liu et al. 2018a)</ref>, which is first trained with a language modeling objective on a large unlabeled text corpus and then finetuned on the specific target task. Specifically, given an answer sentence S, a question Q and an extracted answer A, we concatenate the two sentences with the answer while adding a delimiter token in between to get [S; Q; $; A]. We then embed the sequence with its word embedding as well as position embedding. Multiple transformer blocks are used to encode the sequence embeddings as follows:</p><formula xml:id="formula_7">h 0 = W e [X] + W p h i = transformer block(h i−1 ), ∀i ∈ [1, n]</formula><p>where X denotes the sequence's indexes in the vocab, W e is the token embedding matrix, W p is the position embedding matrix, and n is the number of transformer blocks. Each block consists of a masked multi-head self-attention layer <ref type="bibr" target="#b36">(Vaswani et al. 2017</ref>) and a position-wise feed-forward layer. Residual connection and layer normalization are used after each layer.</p><p>The last token's activation h lm n is then fed into a linear projection layer followed by a softmax function to output the no-answer probability y: p(y|X) = softmax(h lm n W y ) A standard cross-entropy objective is used to minimize the negative log-likelihood:</p><formula xml:id="formula_8">L(θ) = − (X,y) log p(y|X)</formula><p>Model-II: Interactive Architecture In Model-II, we consider an interactive architecture that aims to capture the interactions between two sentences, so as to recognize their local entailment relationships for verifying the answer. This model consists of the following layers: Encoding: We embed words using the GloVe embedding <ref type="bibr" target="#b26">(Pennington, Socher, and Manning 2014)</ref>, and also embed characters of each word with trainable vectors. We run a bidirectional LSTM (BiLSTM) <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber 1997)</ref> to encode the characters and concatenate two last hidden states to get character-level embeddings. In addition, we use a binary feature to indicate if a word is part of the answer. All embeddings along with the feature are then concatenated and encoded by a weight-shared BiLSTM, yielding two series of contextual representations:</p><formula xml:id="formula_9">s i = BiLSTM([word s i ; char s i ; fea s i ]), ∀i ∈ [1, l s ] q j = BiLSTM([word q j ; char q j ; fea q j ]), ∀j ∈ [1, l q ]</formula><p>where l s is the length of answer sentence, and [·; ·] denotes concatenation.</p><p>Inference Modeling: An inference modeling layer is used to capture the interactions between two sentences and produce two inference-aware sentence representations. We first compute the dot products of all tuples &lt; s i , q j &gt; as attention weights, and then normalize these weights so as to obtain attended vectors as follows:</p><formula xml:id="formula_10">a ij = s T i q j , ∀i ∈ [1, l s ], ∀j ∈ [1, l q ] b i = lq j=1 e aij lq k=1 e a ik q j , c j = ls i=1 e aij ls k=1 e a kj s i</formula><p>Here, b i refers to the attended vector from question Q for the i-th word in answer sentence S, and vice versa for c j . Next, in order to separately compare the aligned pairs</p><formula xml:id="formula_11">{(s i , b i )} ls i=1 and {(q j , c j )} lq j=1</formula><p>for finding local inference information, we use a weight-shared function F to model these aligned pairs as:</p><formula xml:id="formula_12">s i = F (s i , b i ) ,q j = F (q j , c j )</formula><p>F can have various forms, such as BiLSTM, multilayer perceptron, and so on. Here we use a heuristic function o = F (x, y) proposed by <ref type="bibr" target="#b9">Hu et al. (2018a)</ref>, which demonstrates good performances compared to other options:</p><formula xml:id="formula_13">r = gelu (W r [x; y; x • y; x − y]) g = σ (W g [x; y; x • y; x − y]) o = g • r + (1 − g) • x</formula><p>where gelu is the Gaussian Error Linear Unit <ref type="bibr" target="#b6">(Hendrycks and Gimpel 2016)</ref>, • is element-wise multiplication, and the bias term is omitted. Intra-Sentence Modeling: Next we apply an intra-sentence modeling layer to capture self correlations inside each sentence. The input are inference-aware vectorss i andq j , which are first passed through another BiLSTM layer for encoding. We then use the same attention mechanism described above, only now between each sentence and itself, and we set a ij = −inf if i = j to ensure that the word is not aligned with itself. Another function F is used to produce self-aware vectorsŝ i andq j respectively. Prediction: Before the final prediction, we apply a concatenated residual connection and model the sentences with a BiLSTM as:</p><formula xml:id="formula_14">s i = BiLSTM([s i ;ŝ i ]) ,q j = BiLSTM([q j ;q j ])</formula><p>A mean-max pooling operation is then applied to summarize the final representation of two sentences, namelys i andq j . All summarized vectors are then concatenated and fed into a feed-forward classifier that consists of a projection sublayer with gelu activation and a softmax output sublayer, yielding the no-answer probability. As before, we optimize the negative log-likelihood objective function.</p><p>Model-III: Hybrid Architecture To explore how the features extracted by Model-I and Model-II can be integrated to obtain better representation capacities, we investigate the combination of the above two models, namely Model-III. We merge the output vectors of two models into a single joint representation. An unified feed-forward classifier is then applied to output the no-answer probability. Such design allows us to test whether the performance can benefit from the integration of two different architectures. In practice we use a simple concatenation to merge the two sources of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup Dataset</head><p>We evaluate our approach on the SQuAD 2.0 dataset (Rajpurkar, Jia, and Liang 2018). SQuAD 2.0 is a new machine reading comprehension benchmark that aims to test the models whether they have truely understood the questions by knowing what they don't know. It combines answerable questions from the previous SQuAD 1.1 dataset (Rajpurkar et al. <ref type="bibr" target="#b25">2016</ref>) with 53,775 unanswerable questions about the same passages. Crowdsourcing workers craft these questions with a plausible answer in mind, and make sure that they are relevant to the corresponding passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Inference</head><p>Our no-answer reader is trained on context passages, while the answer verifier is trained on oracle answer sentences. Model-I follows a procedure of unsupervised pre-training and supervised fine-tuning. That is, the model is first optimized with a language modeling objective on a large unlabeled text corpus to initialize its parameters. Then it adapts the parameters to the answer verifying task with our supervised objective. For Model-II, we directly train it with the supervised loss. Model-III, however, consists of two different architectures that require different training procedures. Therefore, we initialize Model-III with the pre-trained parameters from both of Model-I and Model-II, and then finetune the whole model until convergence.</p><p>At test time, the reader first predicts a candidate answer as well as a passage-level no-answer probability. The answer verifier then validates the extracted answer along with its sentence and outputs a sentence-level probability. Following the official evaluation setting, a question is detected to be unanswerable once the joint no-answer probability, which is computed as the mean of the above two probabilities, exceeds some threshold. We tune this threshold to maximize F1 score on the development set, and report both of EM (Exact Match) and F1 metrics. We also evaluate the performance on no-answer detection with an accuracy metric (ACC), where its threshold is set as 0.5 by default. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation</head><p>We use the Reinforced Mnemonic Reader (RMR) <ref type="bibr" target="#b9">(Hu et al. 2018a</ref>), one of the state-of-the-art reading comprehension models on the SQuAD 1.1 dataset, as our base reader. The reader is configurated with its default setting, and trained with the no-answer objective with our auxiliary losses. ELMo (Embeddings from Language Models) <ref type="bibr" target="#b27">(Peters et al. 2018</ref>) is exclusively listed in our experimental configuration. We run a grid search on γ and λ among [0.1, 0.3, 0.5, 0.7, 1, 2]. Based on the performance on development set, we set γ as 0.3 and λ to be 1. As for answer verifiers, we use the original configuration from <ref type="bibr" target="#b28">Radford et al. (2018)</ref> for Model-I. For Model-II, the Adam optimizer (Kingma and Ba 2014) with a learning rate of 0.0008 is used, the hidden size is set as 300, and a dropout <ref type="bibr" target="#b34">(Srivastava et al. 2014</ref>) of 0.3 is applied for preventing overfitting. The batch size is 48 for the reader, 64 for Model-II, and 32 for Model-I as well as Model-III. We use the GloVe <ref type="bibr" target="#b26">(Pennington, Socher, and Manning 2014)</ref> 100D embeddings for the reader, and 300D embeddings for Model-II and Model-III. We utilize the nltk tokenizer 3 to preprocess passages and questions, as well as split sentences. The passages and the sentences are truncated to not exceed 300 words and 150 words respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Main Results</head><p>We first submit our approach on the hidden test set of SQuAD 2.0 for evaluation, which is shown in <ref type="table">Table 1</ref>. We use Model-III as the default answer verifier, and only report the best result. As we can see, our system obtains state-ofthe-art results by achieving an EM score of 71.7 and a F1 score of 74.2 on the test set. Notice that SLQA+ has reached a comparable result compared to our approach. We argue that its promising result is largely due to its superior perfor-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>Next, we do an ablation study on the SQuAD 2.0 development set to show the effects of our proposed methods for each individual component. <ref type="table">Table 2</ref> first shows the ablation results of different auxiliary losses on the reader. Removing the independent span loss (indep-I) results in a performance drop for all answerable questions (HasAns), indicating that this loss helps the model in better identifying the answer boundary. Ablating independent no-answer loss (indep-II), on the other hand, causes little influence on HasAns, but leads to a severe decline on no-answer accuracy (NoAns ACC). This suggests that a confliction between answer extraction and no-answer detection indeed happens. Finally, deleting both of two losses causes a degradation of more than 1.5 points on the overall performance in terms of F1, with or without ELMo embeddings. <ref type="table" target="#tab_2">Table 3</ref> details the results of various architectures for the answer verifier. Model-III outperforms all of other competitors, achieving a no-answer accuracy of 76.2. This illustrates that the combination of two different architectures can bring in further improvement. Adding ELMo embeddings, however, does not boost the performance. We hythosize that the bytepair encoding <ref type="bibr" target="#b32">(Sennrich, Haddow, and Birch 2016)</ref> from Model-I and the word/character embeddings from Model-II have provided enough representation capacities.</p><p>After doing separate ablations on each component, we then compare the performance of the whole system, as shown in   any answer verifier can always result in considerable performance gains, and combining the reader with Model-III obtains the best result. We find that the improvement on noanswer accuracy is significant. This metric raises from 73.1 to 77.1 after adding Model-III to RMR, increasing by 4 absolute points. Similar observation can be found when ELMo embeddings are used, demonstrating that the gains are consistent and stable. In order to investigate how the readers affect the overall performance, we fix the answer verifier as Model-III and use DocQA  as the base reader instead of RMR, as shown in <ref type="table" target="#tab_5">Table 5</ref>. We find that the absolute improvements are even larger: the no-answer accuracy roughly increases by 6 points when adding Model-III to DocQA (from 69.1 to 75.2), and 5.5 points when adding Model-III to DocQA + ELMo (from 70.6 to 76.1).</p><p>Finally, we plot the precision-recall curves of F1 score on the development set in <ref type="figure" target="#fig_1">Figure 3</ref>. We observe that RMR + ELMo + Verifier achieves the best precision when the recall is less than 80. After the recall exceeds 80, the precision of RMR + ELMo becomes slightly better. Ablating two auxiliary losses, however, leads to an overall degradation on the curve, but it still outperforms the baseline by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error Analysis</head><p>To perform error analysis, we first categorize all examples on the development set into 5 classes:</p><p>• Case1: the question is answerable, the no-answer proba-   bility is less than the threshold, and the answer is correct. • Case2: the question is unanswerable, and the no-answer probability is larger than the threshold. • Case3: almost the same as case1, except that the predicted answer is wrong. • Case4: the question is unanswerable, but the no-answer probability is less than the threshold. • Case5: the question is answerable, but the no-answer probability is larger than the threshold. We then show the percentage of each category in <ref type="table" target="#tab_7">Table  6</ref>. As we can see, the base reader trained with auxiliary losses is notably better at case2 and case4 compared to the baseline, implying that our proposed losses help the model mainly improve upon unanswerable cases. After adding the answer verifier, we observe that although the system's performance on unanswerable cases slightly decreases, the results on case1 and case5 have been improved. This demonstrates that the answer verifier does well on detecting answerable question rather than unanswerable one. Besides, we find that the error of answer extraction is relatively small (6.5% for Case3 in RMR + ELMo + Verifier). However, the classification error on no-answer detection is much larger. More than 20% of examples are misclassified even with our best system (10.3% for Case4 and 10.9% for Case5 in RMR + ELMo + Verifier). Therefore, we argue that the main performance bottleneck lies in no-answer detection instead of answer extraction.</p><p>Next, to understand the challenges our approach faces, we manually investigate 50 incorrectly predicted unanswerable   <ref type="table" target="#tab_9">Table 7</ref>. As we can see, our system is good at recognize negation and antonym. The frequency of negation decreases from 9% to 0% and only 4 antonym examples are predicted wrongly. We think that this is because the two types are relatively easier to identify. Both of negation and antonym only require to detect one single word in the question, such as "never" or "not" for negation and "increase" to "decrease" for antonym. However, impossible condition and other neutral types roughly acount for 46% of the error set, indicating that our system performs less effectively on these more difficult cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Reading Comprehension Datasets. Various large-scale reading comprehension datasets, such as cloze-style test <ref type="bibr" target="#b7">(Hermann et al. 2015)</ref>, answer extraction benchmark <ref type="bibr" target="#b29">(Rajpurkar et al. 2016;</ref><ref type="bibr" target="#b13">Joshi et al. 2017</ref>) and answer generation benchmark <ref type="bibr" target="#b23">(Nguyen et al. 2016;</ref><ref type="bibr" target="#b15">Kočiskỳ et al. 2018)</ref>, have been proposed. However, these datasets still guarantee that the given context must contain an answer. Recently, some works construct negative examples by retrieving passages for existing questions based on Lucene <ref type="bibr" target="#b35">(Tan et al. 2018</ref>) and TF-IDF (Clark and Gardner 2018), or using crowdworkers to craft unanswerable questions <ref type="bibr" target="#b30">(Rajpurkar, Jia, and Liang 2018)</ref>. Compared to automatically retrieved negative examples, human-annotated examples are more difficult to detect for two reasons: (1) the questions are relevant to the passage and (2) the passage contains a plausible answer to the question. Therefore, we choose to work on the SQuAD 2.0 dataset in this paper. Neural Networks for Reading Comprehension. Neural reading models typically leverage various attention mechanisms to build interdependent representations of passage and question, and sequentially predict the answer boundary <ref type="bibr" target="#b9">Hu et al. 2018a;</ref><ref type="bibr" target="#b38">Wang et al. 2017;</ref><ref type="bibr" target="#b40">Yu et al. 2018;</ref><ref type="bibr">Hu et al. 2018b</ref>). However, these approaches are not designed to handle no-answer cases. To address this problem, previous works <ref type="bibr" target="#b17">(Levy et al. 2017;</ref><ref type="bibr" target="#b4">Clark and Gardner 2018;</ref><ref type="bibr" target="#b16">Kundu and Ng 2018)</ref> predict a no-answer probability in addition to the distribution over answer spans, so as to jointly learn no-answer detection as well as answer extraction. Our no-answer reader extends existing approaches by introducing two auxiliary losses that enhance these two tasks independently.</p><p>Recognizing Textual Entailment. Recognizing textual entailment (RTE) <ref type="bibr" target="#b5">(Dagan et al. 2010;</ref><ref type="bibr" target="#b21">Marelli et al. 2014)</ref>, or known as natural language inference (NLI) <ref type="bibr">(Bowman et al. 2015)</ref>, requires systems to understand entailment, contradiction or semantic neutrality between two sentences. This task is strongly related to no-answer detection, where the machine needs to understand if the passage and the question supports the answer. To recognize entailment, various branches of works have been proposed, including encodingbased approach <ref type="bibr" target="#b2">(Bowman et al. 2016;</ref><ref type="bibr" target="#b22">Mou et al. 2015)</ref>, interaction-based approach <ref type="bibr">(Parikh et al. 2016;</ref><ref type="bibr" target="#b3">Chen et al. 2016)</ref> and sequence-based approach <ref type="bibr" target="#b28">(Radford et al. 2018)</ref>.</p><p>In this paper we investigate the last two branches and further propose a hybrid architecture that combines both of them properly. Answer Validation. Early answer validation task <ref type="bibr" target="#b20">(Magnini et al. 2002)</ref> aims at ranking multiple candidate answers to return a most reliable one. Later, the answer validation exercise <ref type="bibr" target="#b31">(Rodrigo, Peñas, and Verdejo 2008)</ref> has been proposed to decide whether an answer is correct or not according to a given supporting text and a question, but the dataset is too small for neural network-based approaches. Recently, <ref type="bibr" target="#b35">Tan et al. (2018)</ref> propose to validate the candidate answer for detecting unanswerable questions, by comparing the question with the passage. Our answer verifier, on the contrary, denoises the passage by comparing questions with answer sentences, so as to focus on finding local entailment that supports the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We proposed a read-then-verify system that is able to abstain from answering when a question has no answer given the passage. We first introduce two auxiliary losses to help the reader concentrate on answer extraction and no-answer detection respectively, and then utilize an answer verifier to validate the legitimacy of the predicted answer, in which three different architectures are investigated. Our system has achieved state-of-the-art results on the SQuAD 2.0 dataset at the time of submission (Aug. 28th, 2018). Looking forward, we plan to design new structures for answer verifiers to handle questions with more complicated inferences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>An overview of answer verifiers. (a) Input structures for running three different models. (b) Generative Pre-trained Transformer proposed by<ref type="bibr" target="#b28">Radford et al. (2018)</ref>. Here, "Masked Multi Self Attention" refers to multi-head self-attention function<ref type="bibr" target="#b36">(Vaswani et al. 2017</ref>) that only attends to previous tokens. "Add &amp; Norm" indicates residual connection and layer normalization. (c) Our proposed token-wise interaction model, which is designed to compare two sentences and aggregate the results for verifying the answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Precision-Recall curves of F1 score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of different architectures for the answer verifier.</figDesc><table /><note>mance compared to our base reader 4 .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>The combination of base reader with</figDesc><table><row><cell>4 SLQA+ achieves 87.0 F1 on the SQuAD 1.1 test set, while</cell></row><row><cell>RMR reaches 86.6.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="5">: Comparison of readers with different answer veri-</cell></row><row><cell>fiers.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Configuration</cell><cell>EM</cell><cell>All</cell><cell>F1</cell><cell>NoAns ACC</cell></row><row><cell>DocQA</cell><cell cols="3">61.9 64.8</cell><cell>69.1</cell></row><row><cell>+ Model-III</cell><cell cols="3">66.5 69.2</cell><cell>75.2</cell></row><row><cell cols="4">DocQA + ELMo 65.1 67.6</cell><cell>70.6</cell></row><row><cell>+ Model-III</cell><cell cols="3">68.0 70.7</cell><cell>76.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of different readers with fixed answer verifier.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Percentage of five categories. Correct predictions are denoted with , while wrong cases are marked with .</figDesc><table><row><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>40 50 60 70 Precision</cell><cell>0</cell><cell>20 DocQA + ELMo 40 Recall RMR + ELMo -both RMR + ELMo RMR + ELMo + Verifier</cell><cell>60</cell><cell>80</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>: Linguistic phenomena exhibited by all negative ex-</cell></row><row><cell>amples (statistics from Rajpurkar et al. (2018)) and sampled</cell></row><row><cell>error cases of RMR + ELMo + Verifier.</cell></row><row><cell>examples (based on F1) that are randomly sampled from the</cell></row><row><cell>development set. Following the types of negative examples</cell></row><row><cell>defined by Rajpurkar et al. (2018), we categorize the sam-</cell></row><row><cell>pled examples and show them in</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.nltk.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Pranav Rajpurkar and Robin Jia for their helps with SQuAD 2.0 submissions. This work is supported by the Major State Research Development Program (2016YFB0201305).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A fast unified model for parsing and sentence understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06021</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.06038</idno>
		<title level="m">Enhanced lstm for natural language inference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple and effective multiparagraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recognizing textual entailment: rational, evaluation and approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="105" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Bridging nonlinearities and stochastic regularizers with gaussian error linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08415</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reinforced mnemonic reader for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dongshengli</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attention-guided answer distillation for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fusionnet: fusing via fully-aware attention with application to machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Triviaqa: a large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
	</analytic>
	<monogr>
		<title level="m">CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The narrativeqa reading comprehension challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kočiskỳ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of ACL</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A nil-aware answer extraction framework for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4243" to="4252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Zeroshot relation extraction via reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04115</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.10198</idno>
		<title level="m">Generating wikipedia by summarizing long sequences</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stochastic answer networks for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Is it the right answer? exploiting web redundancy for answer validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prevete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A sick cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1512.08422</idno>
		<title level="m">Natural language inference by treebased convolution and heuristic matching</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Ms marco: a human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<idno type="arXiv">arXiv:1606.01933</idno>
		<title level="m">A decomposable attention model for natural language inference</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep contextualized word prepresentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Improving language understanding by generative pre-training</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Overview of the answer validation exercise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop of CLEF</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="296" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">I know there is no answer: modeling answer validation for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NLPCC</title>
		<meeting>NLPCC</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="85" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-granularity hierarchical attention fusion networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Qanet: combining local convolution with global self-attention for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
