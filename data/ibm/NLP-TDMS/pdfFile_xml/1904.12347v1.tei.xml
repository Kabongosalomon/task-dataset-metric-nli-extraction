<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Agnostic Learning with Disentangled Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchao</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximeng</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
						</author>
						<title level="a" type="main">Domain Agnostic Learning with Disentangled Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised model transfer has the potential to greatly improve the generalizability of deep models to novel domains. Yet the current literature assumes that the separation of target data into distinct domains is known as a priori. In this paper, we propose the task of Domain-Agnostic Learning (DAL): How to transfer knowledge from a labeled source domain to unlabeled data from arbitrary target domains? To tackle this problem, we devise a novel Deep Adversarial Disentangled Autoencoder (DADA) capable of disentangling domain-specific features from class identity. We demonstrate experimentally that when the target domain labels are unknown, DADA leads to stateof-the-art performance on several image classification datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Supervised machine learning assumes that training and testing data are sampled i.i.d from the same distribution, while in practice, the training and testing data are typically collected from related domains but under different distributions, a phenomenon known as domain shift <ref type="bibr" target="#b45">(Quionero-Candela et al., 2009)</ref>. To avoid the cost of annotating each new test domain, Unsupervised Domain Adaptation (UDA) tackles domain shift by aligning the feature distribution of the source domain with that of the target domain, resulting in domain-invariant features. However, current methods assume that target samples have domain labels and therefore can be isolated into separate homogeneous domains. For many practical applications, this is an overly strong assumption. For example, a hand-written character recognition system could encounter characters written by different people, on different materials, and under different lighting conditions; an image recognition system applied to images scraped from the web must handle mixed-domain data (e.g. paintings, sketches, clipart) without their domain labels.</p><p>In this paper, we consider Domain-Agnostic Learning (DAL), a more difficult but practical problem of knowledge transfer from one labeled source domain to multiple unlabeled target domains. The main challenges of domainagnostic learning are that: (1) the target data has mixed domains, which hampers the effectiveness of mainstream feature alignment methods <ref type="bibr" target="#b35">(Long et al., 2015;</ref><ref type="bibr" target="#b50">Sun &amp; Saenko, 2016;</ref><ref type="bibr" target="#b49">Saito et al., 2018)</ref>, and (2) class-irrelevant information leads to negative transfer <ref type="bibr" target="#b42">(Pan &amp; Yang, 2010)</ref>, especially when the target domain is highly heterogeneous.</p><p>Mainstream UDA methods align the source domain to the target domain by minimizing the Maximum Mean Discrepancy <ref type="bibr" target="#b35">(Long et al., 2015;</ref><ref type="bibr" target="#b51">Tzeng et al., 2014)</ref>, aligning highorder moments <ref type="bibr" target="#b50">(Sun &amp; Saenko, 2016;</ref><ref type="bibr" target="#b55">Zellinger et al., 2017)</ref>, or adversarial training <ref type="bibr" target="#b11">(Ganin &amp; Lempitsky, 2015;</ref><ref type="bibr" target="#b52">Tzeng et al., 2017)</ref>. However, these methods are designed for oneto-one domain alignment and do not account for multiple latent domains in the target. Multi-source domain adaptation <ref type="bibr" target="#b53">Xu et al., 2018;</ref><ref type="bibr" target="#b39">Mansour et al., 2009)</ref> considers adaptation between multiple sources and a single target domain and assumes domain labels on the source data. Continuous domain adaptation  aims to transfer knowledge to a continuously changing domain (e.g. cars in different decades), but in their scenario the target data are temporally related. Recently, domain generalization approaches <ref type="bibr" target="#b30">(Li et al., 2018a;</ref><ref type="bibr" target="#b5">Carlucci et al., 2018b;</ref><ref type="bibr" target="#b31">Li et al., 2018b)</ref> have been introduced to adapt from multiple labeled source domains to an unseen target domain. All of the above models make a strong assumption that the target data are homogeneously sampled from the same distribution, unlike the scenario we consider here.</p><p>We postulate that a solution to domain-agnostic learning should not only learn invariance between source and target, but should also actively disentangle the class-specific features from the remaining information in the image. Deep neural networks are known to extract features in which multiple hidden factors are highly entangled <ref type="bibr" target="#b2">(Bengio et al., 2013)</ref>. Recent work attempts to disentangle features in the latent space of autoencoders with adversarial training <ref type="bibr">(Cao et al., arXiv:1904</ref><ref type="bibr">.12347v1 [cs.CV] 28 Apr 2019</ref><ref type="bibr" target="#b34">Liu et al., 2018b;</ref><ref type="bibr" target="#b41">Odena et al., 2017;</ref><ref type="bibr" target="#b29">Lee et al., 2018)</ref>. However, the above models have limited capacity in transferring features learned from one domain to heterogeneous target domains. <ref type="bibr" target="#b32">Liu et al. (2018a)</ref> proposes a framework that takes samples from multiple domains as input, and derives a domain-invariant latent feature space via adversarial training. This model is limited by two factors when applied to the DAL task. First, it only disentangles the embeddings into domain-invariant features and domain-specific features such as weather conditions, and discards the latter, but does not explicitly try to separate class-relevant features from class-irrelevant features like background. Second, there is no guarantee that the domain-invariant features are fully disentangled from the domain-specific features.</p><p>To address the issues mentioned above, we propose a novel Deep Adversarial Disentangled Autoencoder (DADA), aiming to tackle domain-agnostic learning by disentangling the domain-invariant features from both domain-specific and class-irrelevant features simultaneously. First, in addition to domain disentanglement <ref type="bibr" target="#b32">(Liu et al., 2018a;</ref><ref type="bibr" target="#b3">Cao et al., 2018;</ref><ref type="bibr" target="#b29">Lee et al., 2018)</ref>, we employ class disentanglement to remove class-irrelevant features, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The class disentanglement is trained in an adversarial fashion: a class identifier is trained on the labeled source domain and the disentangler generates features to fool the class identifier. To the best of our knowledge, we are the first to show that class disentanglement boosts domain adaptation performance. Second, to enhance the disentanglement, we propose to minimize the mutual information between the disentangled features. We implement a neural network to estimate the mutual information between the disentangled feature distributions, inspired by a recently published theoretical work <ref type="bibr" target="#b0">(Belghazi et al., 2018)</ref>. Comprehensive experiments on standard image recognition datasets demonstrate that our derived disentangled representation achieves significant improvements over the state-of-the-art methods on the task of domain-agnostic learning.</p><p>The main contributions of this paper are highlighted as follows: (1) we propose a novel learning paradigm of domainagnostic learning; 2) we develop an end-to-end Deep Adversarial Disentangled Autoencoder (DADA) which learns a better disentangled feature representation to tackle the task; and (3) We propose class disentanglement to remove classirrelevant features, and minimize the mutual information to enhance the disentanglement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Domain Adaptation Unsupervised domain adaptation (UDA) aims to transfer the knowledge learned from one or more labeled source domains to an unlabeled target domain. Various methods have been proposed, including discrepancybased UDA approaches <ref type="bibr" target="#b37">(Long et al., 2017;</ref><ref type="bibr" target="#b51">Tzeng et al., 2014;</ref><ref type="bibr" target="#b12">Ghifary et al., 2014;</ref>, adversarybased approaches <ref type="bibr" target="#b33">(Liu &amp; Tuzel, 2016;</ref><ref type="bibr" target="#b52">Tzeng et al., 2017;</ref><ref type="bibr" target="#b32">Liu et al., 2018a)</ref>, and reconstruction-based approaches <ref type="bibr" target="#b54">(Yi et al., 2017;</ref><ref type="bibr" target="#b57">Zhu et al., 2017;</ref><ref type="bibr" target="#b19">Hoffman et al., 2018;</ref><ref type="bibr" target="#b22">Kim et al., 2017)</ref>. These models are typically designed to tackle single source to single target adaptation. Compared with single source adaptation, multi-source domain adaptation (MSDA) assumes that training data are collected from multiple sources. Originating from the theoretical analysis in <ref type="bibr" target="#b1">(Ben-David et al., 2010;</ref><ref type="bibr" target="#b39">Mansour et al., 2009;</ref><ref type="bibr" target="#b6">Crammer et al., 2008)</ref>, MSDA has been applied to many practical applications <ref type="bibr" target="#b53">(Xu et al., 2018;</ref><ref type="bibr" target="#b8">Duan et al., 2012;</ref>. Specifically, <ref type="bibr" target="#b1">Ben-David et al. (2010)</ref> introduce an H∆H-divergence between the weighted combination of source domains and a target domain. We propose a new and more practical learning paradigm, not yet considered in the UDA literature, where labeled data come from a single source domain but the testing data contain multiple unknown domains.</p><p>Representation Disentanglement The goal of learning disentangled representations is to model the factors of data variation. Recent works <ref type="bibr" target="#b40">(Mathieu et al., 2016;</ref><ref type="bibr" target="#b38">Makhzani et al., 2016;</ref><ref type="bibr" target="#b32">Liu et al., 2018a;</ref><ref type="bibr" target="#b41">Odena et al., 2017)</ref> aim at learning an interpretable representation using generative adversarial networks (GANs) <ref type="bibr" target="#b14">(Goodfellow et al., 2014;</ref> and variational autoencoders (VAEs) <ref type="bibr" target="#b24">Kingma &amp; Welling, 2013)</ref>. In a fully supervised setting, <ref type="bibr" target="#b29">Lee et al. (2018)</ref> proposes to disentangle the feature representation into a domain-invariant content space and a domain-specific attribute space, producing diverse outputs without paired training images. Another work <ref type="bibr" target="#b41">(Odena et al., 2017)</ref> proposes an auxiliary classifier GAN (AC-GAN) to achieve representation disentanglement. Despite promising performance, these methods focus on disentangling representation in a single domain. <ref type="bibr" target="#b32">Liu et al. (2018a)</ref> introduces a unified feature disentangler to learn a domain-invariant representation from data across multiple domains. However, their model assumes that multiple source domains are available during training, which limits its practical application. In contrast, our model disentangles the representation based on one source domain and multiple unknown target domains, and proposes an improved approach to disentanglement that considers the class label and mutual information between features.</p><p>Agnostic Learning There are several prior studies of agnostic learning that are related to our work. Model-Agnostic Meta-Learning (MAML) <ref type="bibr" target="#b9">(Finn et al., 2017)</ref> aims to train a model on a variety of learning tasks and solve a new task using only a few training examples. Different from MAML, our method mainly focuses on transferring knowledge to heterogeneous domains. <ref type="bibr" target="#b4">Carlucci et al. (2018a)</ref> proposes a learning framework to seamlessly extend the knowledge from multiple source domain to an unseen target domain by In addition to domain disentanglement (blue lines), we employ class disentanglement (red lines) to remove class-irrelevant features, both trained adversarially. We further apply a mutual information minimizer to strengthen the disentanglement. pixel-adaptation in an incremental architecture. <ref type="bibr" target="#b47">Romijnders et al. (2018)</ref> introduces a domain agnostic normalization layer for adversarial UDA and improves the performance of deep models on an unseen domain. Though the results are promising, we argue that only normalizing the feature representation is not enough for domain-agnostic learning, and that extracting disentangled domain-invariant and domainspecific features is also important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DADA: Deep Adversarial Disentangled Autoencoder</head><p>We define the domain-agnostic learning task as follows:</p><formula xml:id="formula_0">Given a source domain D s = {(x s i , y s i )} ns i=1</formula><p>with n s labeled examples, the goal is to minimize risk on N target domains D t = { D 1 , D 2 , ..., D N } without domain labels. We denote the target domains as D t = {x t j } nt j=1 with n t unlabeled examples. Empirically, we want to minimize the target risk t (θ) = Pr (x,y)∼ Dt [θ (x) = y], where θ (x) is the classifier.</p><p>We propose to solve the task by learning domain-invariant features that are discriminative of the class. <ref type="figure" target="#fig_0">Figure 1</ref> shows the proposed model. The feature generator G maps the input image to a feature vector f G , which has many highly entangled factors. The disentangler D is responsible for disentangling the features (f G ) into domain-invariant features (f di ), domain-specific features (f ds ), and class-irrelevant features (f ci ). The feature reconstructor R aims to recover f G from either (f di , f ds ) or (f di , f ci ). D and R are implemented as the encoder and decoder in a Variational Autoencoder. A mutual information minimizer is applied between f di and f ci , as well as between f di and f ds , to enhance the disentanglement. Adversarial training via a domain identifier aligns the source domain and the heterogeneous target domain in the f di space. A class identifier C is trained on the labeled source domain to predict the class distribution f C and to adversarially extract class-irrelevant features f ci . We next describe each component in detail.</p><p>Variational Autoencoders VAEs <ref type="bibr" target="#b24">(Kingma &amp; Welling, 2013</ref>) are a class of deep generative models that simultaneously train both a probabilistic encoder and decoder. The encoder is trained to generate latent vectors that roughly follow a Gaussian distribution. In our case, we learn each part of our disentangled representations by applying a VAE architecture with the following objective function:</p><formula xml:id="formula_1">L vae = f G − f G 2 F + KL(q(z|f G )||p(z)),<label>(1)</label></formula><p>where the first term aims at recovering the original features extracted by G, and the second term calculates Kullback-Leibler divergence which penalizes the deviation of latent features from the prior distribution p(z c ) (as z ∼ N (0, I)). However, this property cannot guarantee that domain-invariant features are well disentangled from the domain-specific features or from class-irrelevant features, as the loss function in Equation 1 only aligns the latent features to a normal distribution.</p><p>Class Disentanglement To address the above problem, we employ class disentanglement to remove class-irrelevant features, such as background, in an adversarial way. First, we train the disentangler D and the K-way class identifier C to correctly predict the labels, supervised by the crossentropy loss:</p><formula xml:id="formula_2">L ce = −E (xs,ys)∼ Ds K k=1 1[k = y s ]log(C(f D )) (2) where f D ∈ {f di , f ci }.</formula><p>In the second step, we fix the class identifier and train the disentangler D to fool the class identifier by generating classirrelevant features f ci . This can be achieved by minimizing the negative entropy of the predicted class distribution:</p><formula xml:id="formula_3">L ent = − 1 n s ns j=1 log C(f j ci ) − 1 n t nt j=1 log C(f j ci ) (3)</formula><p>where the first term and the second term indicate minimizing the entropy on the source domain and on heterogeneous target, respectively. The above adversarial training process forces the corresponding disentangler to extract classirrelevant features.</p><p>Domain Disentanglement To tackle the domain agnostic learning task, disentangling class-irrelevant features is not enough, as it fails to align the source domain with the target. To achieve better alignment, we further propose to disentangle the learned features into domain-specific and domaininvariant and to thus align the source with the target domain in the domain-invariant latent space. This is achieved by exploiting adversarial domain classification in the resulting latent space. Specifically, we leverage a domain identifier DI, which takes the disentangled feature (f di or f ds ) as input and outputs the domain label l f (source or target). The objective function of the domain identifier is as follows:</p><formula xml:id="formula_4">L DI = −E[l f log P (l f )] + E(1 − l f )[log P (1 − l f )], (4)</formula><p>Then the disentangler is trained to fool the domain identifier DI to extract domain-invariant features.</p><p>Mutual Information Minimization To better disentangle the features, we minimize the mutual information between domain-invariant and domain-specific features (f di , f ds ), as well as domain-invariant and class-irrelevant features (f di , f ci ):</p><formula xml:id="formula_5">I(D x ; D f di ) = X×Z log dP XZ dP X ⊗ P Z dP XZ ,<label>(5)</label></formula><p>where x ∈ {f ds , f ci }, P XZ is the joint probability distribution of (D x , D f di ), and P X = Z dP XZ and P Z = X dP XZ are the marginals. Despite being a pivotal measure across different domains, the mutual information is only tractable for discrete variables, or for a limited family of problems where the probability distributions are unknown <ref type="bibr" target="#b0">(Belghazi et al., 2018)</ref>. The computation incurs a complexity of O(n 2 ), which is undesirable for deep CNNs. Is this paper, we adopt the Mutual Information Neural Estimator (MINE) <ref type="bibr" target="#b0">(Belghazi et al., 2018)</ref> </p><formula xml:id="formula_6">I(X; Z) n = sup θ∈Θ E P (n) XZ [T θ ] − log(E P (n) X ⊗ P (n) Z [e T θ ]). (6)</formula><p>which provides unbiased estimation of mutual information on n i.i.d samples by leveraging a neural network T θ .</p><p>Practically, MINE (6) can be computed as <ref type="bibr">x,z,θ)</ref> ). Additionally, to avoid computing the integrals, we leverage Monte-Carlo integration:</p><formula xml:id="formula_7">I(X; Z) = P n XZ (x, z)T (x, z, θ) -log( P n X (x)P n Z (z)e T (</formula><formula xml:id="formula_8">I(X, Z) = 1 n n i=1 T (x, z, θ) − log( 1 n n i=1</formula><p>e T (x,z ,θ) ) (7)</p><p>Algorithm 1 Learning algorithm for DADA Input: source labeled datasets {(x s i , y s i )} ns i=1 ; heterogeneous target dataset {x t j } n t j=1 ; feature extractor G; disentangler D; category identifier C, domain identifier DI, mutual information estimator M , and reconstructor R. Output: well-trained feature extractorĜ, well-trained disentan-glerD, and class identifierĈ.</p><p>1: while not converged do 2:</p><formula xml:id="formula_9">Sample mini-batch from {(x s i , y s i )} ns i=1 and {x t j } n t j=1 ; 3:</formula><p>Class Disentanglement: 4:</p><p>for 1:iter do 5:</p><p>Update G, D, C by Eq.2; 6:</p><p>Update D by Eq.3; 7:</p><p>end for 8:</p><p>Domain Disentanglement: 9:</p><p>Update D and DI by Eq.4; 10:</p><p>Mutual Information Minimization: 11:</p><p>Calculate mutual information between the disentangled feature pair (f di , f ds ), as well as (f di ,fci) with M ; 12:</p><p>Update D, M by Eq.7; 13:</p><p>Reconstruction: 14:</p><p>Reconstruct where (x, z) are sampled from the joint distribution and z is sampled from the marginal distribution. We implement a neural network to perform the Monte-Carlo integration defined in Equation 7.</p><p>Ring-style Normalization Conventional batch normalization <ref type="bibr" target="#b20">(Ioffe &amp; Szegedy, 2015)</ref> diminishes internal covariate shift by subtracting the batch mean and dividing by the batch standard deviation. Despite promising results on domain adaptation, batch normalization alone is not enough to guarantee that the embedded features are well normalized in the scenario of heterogeneous domains. The target data are sampled from multiple domains and their embedded features are scattered irregularly in the latent space. <ref type="bibr" target="#b56">Zheng et al. (2018)</ref> proposes a ring-style norm constraint to maintain a balance between the angular classification margins of multiple classes. Its objective is as follows:</p><formula xml:id="formula_10">L ring = 1 2n n i=1 (||T (x i )|| 2 −R) 2<label>(8)</label></formula><p>where R is the learned norm value. However, ring loss is not robust and may cause mode collapse if the learned R is small. Instead, we incorporate the ring loss into a Geman-McClure model and minimize the following loss function:</p><formula xml:id="formula_11">L GM ring = n i=1 (||T (x i )|| 2 −R) 2 2nβ + n i=1 (||T (x i )|| 2 −R) 2<label>(9)</label></formula><p>where β is the scale factor of the Geman-McClure model. Optimization Our model is trained in an end-to-end fashion. We train the class and domain disentanglement component, MINE and the reconstruction component iteratively with Stochasitc Gradient Descent <ref type="bibr" target="#b21">(Kiefer et al., 1952)</ref> or Adam <ref type="bibr" target="#b23">(Kingma &amp; Ba, 2014)</ref> optimizer. We employ the popular neural networks (e.g. LeNet, AlexNet, or ResNet) as our feature generator G. The detailed training procedure is presented in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We compare the DADA model to state-of-the-art domain adaptation algorithms on the following tasks: digit classification (MNIST, SVHN, USPS, MNIST-M, Synthetic Digits) and image recognition (Office-Caltech10 <ref type="bibr" target="#b13">(Gong et al., 2012)</ref>, DomainNet ). Sample images of these datasets can be seen in <ref type="figure" target="#fig_2">Figure 2</ref>. <ref type="table" target="#tab_7">Table 6 (suppementary  material)</ref> shows the detailed number of images we use in our experiments. In the main paper, we only report major results; more implementation details are provided in the supplementary material. All of our experiments are implemented in the PyTorch 1 platform.  <ref type="bibr" target="#b15">(Gretton et al., 2007)</ref> to align the source domain with the target domain in reproducing kernel Hilbert space. DANN and ADDA align the source domain with target domain by adversarial loss. MCD is a domain adaptation framework which incorporates two classifiers. UFDN employs a variational autoencoder <ref type="bibr" target="#b24">(Kingma &amp; Welling, 2013)</ref> to disentangle domain-invariant representations. When conducting the baseline experiments, we utilize the code provided by the authors and keep the original experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiments on Digit Recognition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head><p>The experimental results on the "Digit-Five" dataset are shown in <ref type="table" target="#tab_2">Table 1</ref>. From these, we can make the following observations. (1) Model IV achieves 62.3% average accuracy, significantly outperforming other baselines on most of the domain-agnostic tasks.</p><p>(2) The results of model I and II demonstrate the effectiveness of class disentanglement and domain disentanglement. Without minimizing the mutual information between disentangled features, UFDN performs poorly on this task.</p><p>(3) In model III, the ring loss boost the performance by three percent, demonstrating that feature normalization is essential in domain-agnostic learning.</p><p>To dive deeper into the disentangled features, we plot in <ref type="figure" target="#fig_3">Figure 3</ref>(a)-3(d) the t-SNE embeddings of the feature representations learned on the sv→mm,mt,up,sy task with sourceonly features, UFDN features, MCD features, and DADA features, respectively. We observe that the features derived by our model are more separated between classes than UFDN and MCD features.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiments on Office-Caltech10</head><p>Office-Caltech10 <ref type="bibr" target="#b13">(Gong et al., 2012)</ref> This dataset includes 10 common categories shared by Office-31 <ref type="bibr" target="#b48">(Saenko et al., 2010)</ref> and Caltech-256 datasets <ref type="bibr" target="#b16">(Griffin et al., 2007)</ref>. It contains four domains: Caltech (C), which are sampled from Caltech-256 dataset, Amazon (A), which contains images collected from amazon.com, Webcam (W) and DSLR (D), which are images taken by web camera and DSLR camera under office environment. In our experiments, we take turns to set one domain as the source domain and the rest as the heterogeneous target domain, leading to four DAL tasks.</p><p>In our experiments, we leverage two popular networks, AlexNet <ref type="bibr" target="#b26">(Krizhevsky et al., 2012)</ref> and ResNet <ref type="bibr" target="#b17">(He et al., 2016)</ref>, as the backbone of the feature generator G. Both the networks are pre-trained on ImageNet <ref type="bibr" target="#b7">(Deng et al., 2009</ref>). Other components are randomly initialized with normal distribution. In the optimization procedure, we set the learning rate of randomly initialized parameters ten times of the pretrained parameters. The architecture of other components can be seen in <ref type="table" target="#tab_8">Table 7</ref> (supplementary material).</p><p>In addition to the baselines mentioned in Section 4.1, we add three baselines: Residual Transfer Network (RTN) <ref type="bibr" target="#b36">(Long et al., 2016)</ref>, Joint Adaptation Network (JAN) <ref type="bibr" target="#b37">(Long et al., 2017)</ref> and Self Ensembling <ref type="bibr" target="#b10">(French et al., 2018)</ref>. Specifically, RTN employs residual layer <ref type="bibr" target="#b17">(He et al., 2016)</ref> for better knowledge transfer, based on DAN <ref type="bibr" target="#b35">(Long et al., 2015)</ref>. JAN leverages a joint MMD-loss layer to align the features in two consecutive layers. SE applies self-ensembling learning based on a teacher-student model and was the winner of the Visual Domain Adaptation Challenge 2 . We do not apply these methods in digit recognition because the LeNet-based model <ref type="bibr" target="#b27">(LeCun et al., 1989)</ref> is too simple to add a residual or joint training layer. We also omit ADDA and UFDN baselines as these models fail to converge while training on Office-Caltech10 under the domain-agnostic setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The experimental results on Office-Caltech10 dataset are shown in <ref type="table">Table 2</ref>. For fair comparison, we utilize the same backbone as the baselines and separately show the results. From these results, we make the following observations.</p><p>(1) Our model achieves 89.8% accuracy with <ref type="table">Table 2</ref>. Accuracy on Office-Caltech10 dataset with DAL protocal. The methods in the above table are based on "AlexNet" backbone and the methods below are based on the "ResNet" backbone. For both backbones, our model outperforms other baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>A → C,D,W C → A,D,W D → A,C,W W → A,C,D Average AlexNet <ref type="bibr" target="#b26">(Krizhevsky et al., 2012)</ref> 83   an AlexNet backbone <ref type="bibr" target="#b26">(Krizhevsky et al., 2012)</ref> and 92.9% accuracy with a ResNet backbone, outperforming the corresponding baselines on most shifts.</p><p>(2) The adversarial method (DANN) works better than the feature alignment methods (DAN, RTN, JAN). More interestingly, negative transfer <ref type="bibr" target="#b42">(Pan &amp; Yang, 2010)</ref> occurs for feature alignment methods. This is somewhat expected, as these models align the entangled features directly, including the class-irrelevant features.</p><p>(3) From the ResNet results, we observe limited improvements for the baselines from the source-only model, especially for boosting-based SE method. This phenomenon suggests that the boosting procedure works poorly when the target domain is heterogeneously distributed.</p><p>To better analyze the error modes, we plot the confusion matrices for MCD (84.3% accuracy) and DADA (93.1% accuracy) on W→A,C,D task in <ref type="figure" target="#fig_5">Figure 4</ref>(c)-4(d). The figures illustrate MCD mainly confuses "calculator" vs. "keyboard", "backpack" vs. "headphones", and "monitor" vs. "projector", while DADA is able to distinguish them with disentangled features. Convergence Analysis As DADA involves multiple losses and a complex learning procedure including adversarial learning and disentanglement, we analyze the convergence performance for the C→A,D,W task, as showed in <ref type="figure" target="#fig_5">Figure 4(b)</ref> (lines are smoothed for easier analysis). We plot the cross-entropy loss on the source domain, ring loss defined by Equation 9, mutual information defined by Equation 7, and the accuracy in the <ref type="figure" target="#fig_5">figure. Figure 4(b)</ref> illustrates that the training losses gradually converge and the accuracy become steady after about 20 epochs of training. <ref type="table">Table 3</ref>. Accuracy on the DomainNet dataset  dataset with DAL protocol. The table below shows the results based on AlexNet <ref type="bibr" target="#b26">(Krizhevsky et al., 2012)</ref> backbone and the below are the results of ResNet <ref type="bibr" target="#b17">(He et al., 2016)</ref>    This dataset contains approximately 0.6 million images distributed among 345 categories. It contains six distinct domains: Clipart (clp), a collection of clipart images; Infograph (inf), infographic images with specific object; Painting (pnt), artistic depictions of object in the form of paintings; Quickdraw (qdr), drawings from the worldwide players of game "Quick Draw!" 4 ; Real (rel, photos and real world images; and Sketch (skt), sketches of specific objects. It is very large-scale and includes rich informative vision cues across different domains, providing a good testbed for DAL. Sample images can be seen from <ref type="figure" target="#fig_2">Figure 2</ref>. Following Section 4.2, we take turns to set one domain as the source domain and the rest as the heterogeneous target domain, leading to six DAL tasks. performs poorly when the number of categories is large, which is in consistent with results in . <ref type="formula">(2)</ref> The adversarial alignment method (DANN) performs better than feature alignment methods in DAL, a similar trend to that in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A-Distance</head><p>One-to-one vs. one-to-many alignment In the DAL task, the UDA models are performing one-to-many alignment as the target data have no domain labels. However, traditional feature alignment methods such as DAN and JAN are designed for one-to-one alignment. To investigate the effectiveness of domain labels, we design a controlled experiment for DAN and JAN. First, we provide the domain labels and perform one-to-one unsupervised domain adaptation. Then we take away the domain labels and perform one-tomany domain-agnostic learning. The results are shown in <ref type="table">Table 4</ref>. We observe the one-to-one alignment does indeed outperform one-to-many alignment, even though the models in one-to-many alignment have seen more data. These results further demonstrate that DAL is a more challenging task and that traditional feature alignment methods need to be re-thought for this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we first propose a novel domain agnostic learning (DAL) schema and demonstrate the importance of DAL in practical scenarios. Towards tackling DAL task, we have proposed a novel Deep Adversarial Disentangled Autoencoders (DADA) to disentangle domain-invariant features in the latent space. We have proposed to leveraging class disentanglement and mutual information minimizer to enhance the feature disentanglement. Empirically, we demonstrate that the ring-loss-style normalization boosts the performance of DADA in DAL task. An extensive empirical evaluation on DAL benchmarks demonstrate the efficacy of the proposed model against several state-of-the-art domain adaptation algorithms.</p><p>We provide the detailed model architecture <ref type="table" target="#tab_8">(Table 5 and  Table 7</ref>) for each component in our model: Generator, Disentangler, Domain Classifier, Classifier and MINE. <ref type="table">Table 5</ref>. Model Architecture for 'Digit-Five'. For each convolution layer, we list the input dimension, output dimension, kernel size, stride, and padding. For the fully-connected layer, we provide the input and output dimensions. For drop-out layers, we provide the probability of an element to be zeroed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>layer configuration</head><p>Feature Generator 1</p><p>Conv2D <ref type="formula">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Details of datasets</head><p>We provide the detailed information of datasets <ref type="table" target="#tab_7">(Table 6)</ref>. For Digit-Five and the DomainNet dataset, we provide the train/test split for each domain and for Office-Caltech10, we provide the number of images in each domain.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Our DADA architecture learns to extract domain-invariant features of visual categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>fG by (f di ,fci) and (f di , f ds ) with R; 15: Update D, R by Eq.1 16: end while 17: returnĜ = G;Ĉ = C;D = D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>We demonstrate the effectiveness of DADA on three dataset: Digit-Five, Office-Caltech10<ref type="bibr" target="#b13">(Gong et al., 2012)</ref> and Domain-Net dataset. The Digit-Five dataset includes: MNIST (mt), MNIST-M (mm), SVHN (sv), Synthetic (syn), and USPS (up). The Office-Caltech10 dataset contains: Amazon (A), Caltech (C), DSLR (D), and Webcam (W). The DomainNet dataset includes: clipart (clp), infograph (inf ), painting (pnt), quickdraw (qdr), real (rel), and sktech (skt).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Feature visualization: t-SNE plot of source features, UFDN (Liu et al., 2018a) features, MCD (Saito et al., 2018) features and DADA features on agnostic target domain in sv →mm,mt,up,sy setting. We use different markers and different colors to denote different categories. (Best viewed in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Empirical analysis: (a)A-Distance of ResNet, MCD and DADA features on two different tasks; (b) training errors and accuracy on C→A,D,W task. (c)-(d) confusion matrices of MCD, and DADA models on W→A,C,D task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Computer Science Department, Boston University; 111 Cummington Mall, Boston, MA 02215, USA; email:xpeng@bu.edu 2 Columbia Unversity and MADO AI Research; 116th St and Broadway, New York, NY 10027, USA; email:zijun.huang@columbia.edu. Correspondence to: Kate Saenko &lt;saenko@bu.edu&gt;. Proceedings of the 36 th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019. Copyright 2019 by the author(s).</figDesc><table /><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>SVHN, and USPS. In our experiments, we take turns setting one domain as the source domain and the rest as the mixed target domain (discarding both the class and the domain labels), leading to five transfer tasks. To explore the effectiveness of each component in our model, we propose four different ablations, i.e. model</figDesc><table><row><cell>Digit-Five This dataset is a collection of five benchmarks for digit recognition, namely MNIST (LeCun et al., 1998), Synthetic Digits (Ganin &amp; Lempitsky, 2015), MNIST-M (Ganin &amp; Lempitsky, 2015), We compare our model to state-of-the-art baselines: Deep Adaptation Network (DAN) (Long et al., 2015), Domain Adversarial Neural Network (DANN) (Ganin &amp; Lempit-sky, 2015), Adversarial Discriminative Domain Adaptation (ADDA) (Tzeng et al., 2017), Maximum Classifier Dis-crepancy (MCD) (Saito et al., 2018), and Unified Feature Disentangler Network (UFDN) (Liu et al., 2018a). Specifi-cally, DAN applies MMD loss</cell></row></table><note>I: with class disentanglement; model II: I + domain dis- entanglement; model III: II + ring loss; model IV: III + reconstruction loss. The detailed architecture of our model can be seen in Table 5 (supplementary material).1 http://pytorch.org</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Accuracy on "Digit-Five" dataset with domain agnostic learning protocol. DADA achieves 62.3% accuracy, significantly outperforming other baselines. We incrementally add each component to our model, aiming to study their effectiveness on the final results. (model I: with class disentanglement; model II: I + domain disentanglement; model III: II + ring loss; model IV: III + reconstruction loss. mt, up, sv, sy, mm are abbreviations for MNIST, USPS, SVHN, Synthetic Digits, MNIST-M.)</figDesc><table><row><cell>Models</cell><cell>mt→mm,sv,sy,up</cell><cell>mm→mt,sv,sy,up</cell><cell>sv→mt,mm,sy,up</cell><cell>sy→mt,mm,sv,up</cell><cell>up→mt,mm,sv,sy</cell><cell>Avg</cell></row><row><cell>Source Only</cell><cell>20.5±1.2</cell><cell>53.5±0.9</cell><cell>62.9±0.3</cell><cell>77.9±0.4</cell><cell>22.6±0.4</cell><cell>47.5</cell></row><row><cell>DAN (Long et al., 2015)</cell><cell>21.7±1.0</cell><cell>55.3±0.7</cell><cell>63.2±0.5</cell><cell>79.3±0.2</cell><cell>40.2±0.4</cell><cell>51.9</cell></row><row><cell>DANN (Ganin &amp; Lempitsky, 2015)</cell><cell>22.8±1.1</cell><cell>45.2±0.6</cell><cell>61.8±0.2</cell><cell>79.3±0.3</cell><cell>38.7±0.6</cell><cell>49.6</cell></row><row><cell>ADDA (Tzeng et al., 2017)</cell><cell>23.4±1.3</cell><cell>54.8±0.8</cell><cell>63.5±0.4</cell><cell>79.6±0.3</cell><cell>43.5±0.5</cell><cell>52.9</cell></row><row><cell>UFDN (Liu et al., 2018a)</cell><cell>20.2±1.5</cell><cell>41.6±0.7</cell><cell>64.5±0.4</cell><cell>60.7±0.3</cell><cell>44.6±0.2</cell><cell>46.3</cell></row><row><cell>MCD (Saito et al., 2018)</cell><cell>28.7±1.3</cell><cell>43.8±0.8</cell><cell>75.1±0.3</cell><cell>78.9±0.3</cell><cell>55.3±0.4</cell><cell>56.4</cell></row><row><cell>DADA+class (I)</cell><cell>28.9±1.2</cell><cell>50.1±0.9</cell><cell>65.4±0.2</cell><cell>79.8±0.1</cell><cell>50.4±0.3</cell><cell>54.9</cell></row><row><cell>DADA+domain (II)</cell><cell>34.1±1.7</cell><cell>57.1±0.4</cell><cell>71.3±0.4</cell><cell>82.5±0.3</cell><cell>45.4±0.4</cell><cell>57.5</cell></row><row><cell>DADA+ring (III)</cell><cell>35.3±1.5</cell><cell>57.5±0.6</cell><cell>80.1±0.3</cell><cell>82.9±0.2</cell><cell>46.2±0.3</cell><cell>60.4</cell></row><row><cell>DADA+rec (IV)</cell><cell>39.4±1.4</cell><cell>61.1±0.7</cell><cell>80.1±0.4</cell><cell>83.7±0.2</cell><cell>47.2±0.4</cell><cell>62.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>A for the two tasks with raw ResNet features, MCD features, and DADA features, respectively. We observe that thed A for both MCD features and DADA features are smaller than ResNet features, and thed A on DADA features is smaller thand A on MCD features, which is in consistent with the quantitative results, demonstrating the effectiveness of our disentangled features.</figDesc><table><row><cell>et al. (2015), we calculate the approximate A-distancê</cell></row><row><cell>d A = 2 (1 − 2 ) for W→A,C,D and D→A,C,W tasks,</cell></row><row><cell>where is the generalization error of a two-sample classifier</cell></row><row><cell>(kernel SVM) trained on the binary problem to distinguish</cell></row><row><cell>input samples between the source and target domains. Fig-</cell></row><row><cell>ure 4(a) displaysd</cell></row><row><cell>Ben-David et al. (2010) suggests A-distance</cell></row><row><cell>as a measure of domain discrepancy. Following Long</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>backbone. For both setting, our model outperforms other baselines.</figDesc><table><row><cell></cell><cell>Models</cell><cell></cell><cell></cell><cell>clp→inf,pnt qdr,rel,skt</cell><cell></cell><cell>inf→clp,pnt, qdr,rel,skt</cell><cell>pnt→clp,inf, qdr,rel,skt</cell><cell>qdr→clp,inf, pnt,rel,skt</cell><cell>rel→clp,inf, pnt,qdr,skt</cell><cell>skt→clp,inf, pnt,qdr,rel</cell><cell>Avg</cell></row><row><cell cols="4">AlexNet (Krizhevsky et al., 2012)</cell><cell>22.5±0.4</cell><cell></cell><cell>15.3±0.2</cell><cell>21.2±0.3</cell><cell>6.0±0.2</cell><cell>17.2±0.3</cell><cell>21.8±0.3</cell><cell>17.3</cell></row><row><cell cols="4">DAN (Long et al., 2015)</cell><cell>23.7±0.3</cell><cell></cell><cell>14.9±0.4</cell><cell>22.7±0.2</cell><cell>7.6±0.3</cell><cell>19.4±0.4</cell><cell>23.4±0.5</cell><cell>18.6</cell></row><row><cell cols="4">RTN (Long et al., 2016)</cell><cell>21.4±0.3</cell><cell></cell><cell>14.2±0.3</cell><cell>21.0±0.4</cell><cell>7.7±0.2</cell><cell>17.8±0.3</cell><cell>20.8±0.4</cell><cell>17.2</cell></row><row><cell cols="4">JAN (Long et al., 2017)</cell><cell>21.1±0.4</cell><cell></cell><cell>16.5±0.2</cell><cell>21.6±0.3</cell><cell>9.9±0.1</cell><cell>15.4±0.2</cell><cell>22.5±0.3</cell><cell>17.8</cell></row><row><cell cols="4">DANN (Ganin &amp; Lempitsky, 2015)</cell><cell>24.1±0.2</cell><cell></cell><cell>15.2±0.4</cell><cell>24.5±0.3</cell><cell>8.2±0.4</cell><cell>18.0±0.3</cell><cell>24.1±0.4</cell><cell>19.1</cell></row><row><cell cols="3">DADA (Ours)</cell><cell></cell><cell>23.9±0.4</cell><cell></cell><cell>17.9±0.4</cell><cell>25.4±0.5</cell><cell>9.4±0.2</cell><cell>20.5±0.3</cell><cell>25.2±0.4</cell><cell>20.4</cell></row><row><cell cols="4">ResNet101 (He et al., 2016)</cell><cell>25.6±0.2</cell><cell></cell><cell>16.8±0.3</cell><cell>25.8±0.4</cell><cell>9.2±0.2</cell><cell>20.6±0.5</cell><cell>22.3±0.1</cell><cell>20.1</cell></row><row><cell cols="4">SE (French et al., 2018)</cell><cell>21.3±0.2</cell><cell></cell><cell>8.5±0.1</cell><cell>14.5±0.2</cell><cell>13.8±0.4</cell><cell>16.0±0.4</cell><cell>19.7±0.2</cell><cell>15.6</cell></row><row><cell cols="4">MCD (Saito et al., 2018)</cell><cell>25.1±0.3</cell><cell></cell><cell>19.1±0.4</cell><cell>27.0±0.3</cell><cell>10.4±0.3</cell><cell>20.2±0.2</cell><cell>22.5±0.4</cell><cell>20.7</cell></row><row><cell cols="3">DADA (Ours)</cell><cell></cell><cell>26.1±0.4</cell><cell></cell><cell>20.0±0.3</cell><cell>26.5±0.4</cell><cell>12.9±0.4</cell><cell>20.7±0.4</cell><cell>22.8±0.2</cell><cell>21.5</cell></row><row><cell cols="7">Table 4. One-to-one (o-o) vs. one-to-many alignment (o-m). We</cell><cell></cell></row><row><cell cols="7">only show the source domain in the table, the remaining five</cell><cell></cell></row><row><cell cols="4">domains set as the target domain.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Source</cell><cell>clp</cell><cell>inf</cell><cell>pnt qdr</cell><cell>rel</cell><cell>skt</cell><cell>Avg</cell><cell></cell></row><row><cell cols="7">DAN (o-o) 25.2 14.9 24.1 7.8 20.4 25.2 19.6</cell><cell></cell></row><row><cell cols="7">DAN (o-m) 23.7 14.9 22.7 7.6 19.4 23.4 18.6</cell><cell></cell></row><row><cell cols="7">JAN (o-o) 24.2 18.1 23.2 7.8 15.8 23.8 18.8</cell><cell></cell></row><row><cell cols="7">JAN (o-m) 21.1 16.5 21.6 9.9 15.4 22.5 17.8</cell><cell></cell></row><row><cell cols="5">4.3. Experiments on the DomainNet dataset</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DomainNet 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Detailed information for datasets</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Digit-Five</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Splits</cell><cell cols="2">mnist mnist˙m</cell><cell>svhn</cell><cell>syn</cell><cell>usps</cell><cell></cell><cell>Total</cell></row><row><cell cols="4">Train 55,000 55,000 25,000</cell><cell>25,000</cell><cell>7,348</cell><cell></cell><cell>167,348</cell></row><row><cell>Test</cell><cell cols="3">10,000 10,000 14,549</cell><cell>9,000</cell><cell>1,860</cell><cell></cell><cell>37,309</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Office-Caltech10</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Splits</cell><cell></cell><cell cols="2">amazon caltech</cell><cell>dslr</cell><cell>webcam</cell><cell></cell><cell>Total</cell></row><row><cell>Total</cell><cell></cell><cell>958</cell><cell>1,123</cell><cell>157</cell><cell>295</cell><cell></cell><cell>2,533</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">DomainNet</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Splits</cell><cell>clp</cell><cell>inf</cell><cell>pnt</cell><cell>qdr</cell><cell>rel</cell><cell>skt</cell><cell>Total</cell></row><row><cell cols="8">Train 34,019 37,087 52,867 120,750 122,563 49,115 416,401</cell></row><row><cell>Test</cell><cell cols="3">14,818 16,114 22,892</cell><cell>51,750</cell><cell cols="3">52,764 21,271 179,609</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>Model Architecture for 'Office-Caltech10' and 'Domain-Net'. For each convolution layer, we list the input dimension, output dimension, kernel size, stride, and padding. For the fullyconnected layer, we provide the input and output dimensions. For drop-out layers, we provide the probability of an element to be zeroed.</figDesc><table><row><cell cols="2">layer configuration</cell></row><row><cell></cell><cell>Feature Generator: ResNet101 or AlexNet</cell></row><row><cell></cell><cell>Disentangler</cell></row><row><cell>1</cell><cell>Dropout(0.5), FC (2048, 2048), BN, ReLU</cell></row><row><cell>2</cell><cell>Dropout(0.5), FC (2048, 2048), BN, ReLU</cell></row><row><cell></cell><cell>Domain Identifier</cell></row><row><cell>1</cell><cell>FC (2048, 256), LeakyReLU</cell></row><row><cell>2</cell><cell>FC (256, 2), LeakyReLU</cell></row><row><cell></cell><cell>Class Identifier</cell></row><row><cell>1</cell><cell>FC (2048, 10), BN, Softmax</cell></row><row><cell></cell><cell>Reconstructor</cell></row><row><cell>1</cell><cell>FC (4096, 2048)</cell></row><row><cell></cell><cell>Mutual Information Estimator</cell></row><row><cell cols="2">fc1 x FC (2048, 512)</cell></row><row><cell cols="2">fc1 y FC (2048, 512), LeakyReLU</cell></row><row><cell>2</cell><cell>FC (512,1)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://ai.bu.edu/visda-2017/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ResultsThe experimental results on DomainNet are shown inTable 3. The results shows our model achieves 21.5% accuracy with a ResNet backbone. Note that this dataset contains about 0.6 million images, and so a one percent accuracy improvement is not a trivial achievement. Our model gets comparable results with the bestperforming baseline when the source domain is pnt, or qdr and outperforms other baselines for the rest of the tasks. From the experimental results, we make two interesting observations. (1) In DAL, the SE model<ref type="bibr" target="#b10">(French et al., 2018)</ref> 3 http://ai.bu.edu/M3SDA/ 4 https://quickdraw.withgoogle.com/data</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We thank Saito Kuniaki, Ben Usman, Ping Hu for their useful discussions and suggestions. We thank anonymous reviewers and area chairs for their useful insight to improve this work. This work was partially supported by NSF and Honda Research Institute.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head><p>A. Model Architecture</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mutual information neural estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hjelm</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v80/belghazi18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Dy, J. and Krause, A.</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsmssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Katzir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dida</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08019</idno>
		<title level="m">Disentangled synthesis for domain adaptation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Agnostic domain generalization. CoRR, abs/1808.01102</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1808.01102" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Agnostic domain generalization. CoRR, abs/1808.01102</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1808.01102" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning from multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wortman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1757" to="1774" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploiting web images for event recognition in consumer videos: A multiple source domain adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1338" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/finn17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Precup, D. and Teh, Y. W.</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>International Convention Centre</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Selfensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkpoTaxA-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v37/ganin15.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<editor>Bach, F. and Blei, D.</editor>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="7" to="09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain adaptive neural networks for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Rim international conference on artificial intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="898" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A kernel method for the two-sampleproblem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Continuous manifold based adaptation for evolving visual domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CyCADA: Cycleconsistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v80/hoffman18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Dy, J. and Krause, A.</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsmssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stochastic estimation of the maximum of a regression function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kiefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wolfowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="462" to="466" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to discover cross-domain relations with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/kim17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Precup, D. and Teh, Y. W.</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>International Convention Centre</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Diverse image-to-image translation via disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename></persName>
		</author>
		<idno>978-3-030-01246-5</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2018</title>
		<editor>Ferrari, V., Hebert, M., Sminchisescu, C., and Weiss, Y.</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="36" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Domain generalization via conditional invariant representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A unified feature disentangler for multi-domain image translation and manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1809.01361</idno>
		<ptr target="http://arxiv.org/abs/1809.01361" />
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Detach and adapt: Learning crossdomain disentangled deep representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v37/long15.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<editor>Bach, F. and Blei, D.</editor>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="7" to="09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/long17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="page" from="2208" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<title level="m">Adversarial autoencoders. ICLR workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Domain adaptation with multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Koller, D., Schuurmans, D., Bengio, Y., and Bottou, L.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1041" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Disentangling factors of variation in deep representation using adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5040" to="5048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/odena17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Precup, D. and Teh, Y. W.</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>International Convention Centre</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Synthetic to real adaptation with generative correlation alignment networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="DOI">10.1109/WACV.2018.00219</idno>
		<ptr target="https://doi.org/10.1109/WACV.2018" />
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision</title>
		<meeting><address><addrLine>Lake Tahoe, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-03-12" />
			<biblScope unit="page" from="1982" to="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01754</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dataset Shift in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<idno>0262170051</idno>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
			<biblScope unit="page">9780262170055</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v32/rezende14.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning</title>
		<editor>Xing, E. P. and Jebara, T.</editor>
		<meeting>the 31st International Conference on Machine Learning<address><addrLine>Bejing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="22" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">A domain agnostic normalization layer for unsupervised adversarial domain adaptation. CoRR, abs/1809.05298</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Romijnders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meletis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dubbelman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1809.05298" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Deep CORAL: correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno>abs/1607.01719</idno>
		<ptr target="http://arxiv.org/abs/1607.01719" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Deep domain confusion: Maximizing for domain invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep cocktail network: Multi-source unsupervised domain adaptation with category shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3964" to="3973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unsupervised dual learning for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dualgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2868" to="2876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Central moment discrepancy (CMD) for domain-invariant representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zellinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lughofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Natschläger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saminger-Platz</surname></persName>
		</author>
		<idno>abs/1702.08811</idno>
		<ptr target="http://arxiv.org/abs/1702.08811" />
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Ring loss: Convex feature normalization for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00130</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
