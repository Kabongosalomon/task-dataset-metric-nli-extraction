<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">It is not the Journey but the Destination: Endpoint Conditioned Trajectory Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
							<email>mangalam@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshayu</forename><surname>Girase</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Agarwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Hui</forename><surname>Lee</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Toyota Research Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Toyota Research Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">It is not the Journey but the Destination: Endpoint Conditioned Trajectory Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Multimodal Trajectory Prediction, Social Pooling</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Human trajectory forecasting with multiple socially interacting agents is of critical importance for autonomous navigation in human environments, e.g., for self-driving cars and social robots. In this work, we present Predicted Endpoint Conditioned Network (PECNet) for flexible human trajectory prediction. PECNet infers distant trajectory endpoints to assist in long-range multi-modal trajectory prediction. A novel nonlocal social pooling layer enables PECNet to infer diverse yet socially compliant trajectories. Additionally, we present a simple "truncationtrick" for improving diversity and multi-modal trajectory prediction performance. We show that PECNet improves state-of-the-art performance on the Stanford Drone trajectory prediction benchmark by ∼ 20.9% and on the ETH/UCY benchmark by ∼ 40.8% 4 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Predicting the movement of dynamic objects is a central problem for autonomous agents, be it humans, social robots <ref type="bibr" target="#b0">[1]</ref>, or self-driving cars <ref type="bibr" target="#b1">[2]</ref>. Anticipation by prediction is indeed required for smooth and safe path planning in a changing environment. One of the most frequently encountered dynamic objects are humans. Hence, predicting human motion is of paramount importance for navigation, planning, human-robot interaction, and other critical robotic tasks. However, predicting human motion is nuanced, because humans are not inanimate entities evolving under Newtonian laws <ref type="bibr" target="#b2">[3]</ref>. Rather, humans have the will to exert causal forces to change their motion and constantly adjust their paths as they navigate around obstacles to achieve their goals <ref type="bibr" target="#b3">[4]</ref>. This complicated planning process is partially internal, and thus makes predicting human trajectories from observations challenging. Hence, a multitude of aspects should be taken into account beyond just past movement history, for instance latent predetermined goals, other moving agents in the scene, and social behavioral patterns.</p><p>In this work, we propose to address human trajectory prediction by modeling intermediate stochastic goals we call endpoints. We hypothesize that three separate factors interact to shape the trajectory of a pedestrian. First, we posit that pedestrians have some understanding of their long-term desired destination. We extend this hypothesis to sub-trajectories, i.e. the pedestrian has one or multiple intermediate destinations, which we define as potential endpoints of the local trajectory. These sub-goals can be more easily correlated with past observations to predict likely next steps and disentangle potential future trajectories.</p><p>Second, the pedestrian plans a trajectory to reach one of these sub-goals, taking into account the present scene elements. Finally, as the agent go about executing a plan, the trajectory gets modified to account for other moving agents, respecting social norms of interaction.</p><p>Following the aforementioned intuition, we propose to decompose the trajectory prediction problem into two sub-problems that also motivate our proposed architecture ( <ref type="figure" target="#fig_0">Figure 1</ref>). First, given the previous trajectories of the humans in the scene, we propose to estimate a latent belief distribution modeling the pedestrians' possible endpoints. Using this estimated latent distribution, we sample plausible endpoints for each pedestrian based on their observed trajectory. A socially-compliant future trajectory is then predicted, conditioned not only on the pedestrian and their immediate neighbors' histories (observed trajectories) but also everybody's estimated endpoints.</p><p>In conclusion, our contribution in this work is threefold. First, we propose a socially compliant, endpoint conditioned variational auto-encoder that closely imitates the multi-modal human trajectory planning process. Second, we propose a novel self-attention based social pooling layer that generalizes previously proposed social pooling mechanisms. Third, we show that our model can predict stable and plausible intermediate goals that enable setting a new state-of-the-art on several trajectory prediction benchmarks, improving by 20.9% on SDD <ref type="bibr" target="#b4">[5]</ref> &amp; 40.8% on ETH <ref type="bibr" target="#b5">[6]</ref> &amp; UCY <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>There have been many previous studies <ref type="bibr" target="#b7">[8]</ref> on how to forecast pedestrians' trajectories and predict their behaviors. Several previous works propose to learn statistical behavioral patterns from the observed motion trajectories <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> for future trajectory prediction. Since then, many studies have developed models to account for agent interactions that may affect the trajectory -specifically, through scene and/or social information. Recently, there has been a significant focus on multi-modal trajectory prediction to capture different possible future trajectories given the past. There has also been some research on goal-directed path planning, which consider pedestrians' goals while predicting a path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Context-Based Prediction</head><p>Many previous studies have imported environment semantics, such as crosswalks, road, or traffic lights, to their proposed trajectory prediction scheme. Kitani et al. <ref type="bibr" target="#b18">[19]</ref> encode agent-space interactions by a Markov Decision Process (MDP) to predict potential trajectories for an agent. Ballan et al. <ref type="bibr" target="#b19">[20]</ref> leverage a dynamic Bayesian network to construct motion dependencies and patterns from training data and transferred the trained knowledge to testing data. With the great success of the deep neural network, the Recurrent Neural Network (RNN) has become a popular modeling approach for sequence learning. Kim et al. <ref type="bibr" target="#b20">[21]</ref> train a RNN combining multiple Long Short-term Memory (LSTM) units to predict the location of nearby cars. These approaches incorporate rich environment cues from the RGB image of the scene for pedestrians' trajectory forecasting.</p><p>Behaviour of surrounding dynamic agents is also a crucial cue for contextual trajectory prediction. Human behavior modeling studied from a crowd perspective, i.e. , how a pedestrian interacts with other pedestrians, has also been studied widely in human trajectory prediction literature. Traditional approaches use social forces <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref> to capture pedestrians' trajectories towards their goals with attractive forces, while avoiding collisions in the path with repulsive forces. These approaches require hand-crafted rules and features, which are usually complicated and insufficiently robust for complicated high-level behavior modeling. Recently, many studies applied Long Short Term Memory (LSTM <ref type="bibr" target="#b25">[26]</ref>) networks to model trajectory prediction with the social cues. Alahi et al. <ref type="bibr" target="#b26">[27]</ref> propose a Social LSTM which learns to predict a trajectory with joint interactions. Each pedestrian is modeled by an individual LSTM, and LSTMs are connected with their nearby individual LSTMs to share information from the hidden state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multimodal Trajectory Prediction</head><p>In <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, the authors raise the importance of accounting for the inherent multimodal nature of human paths i.e. , given pedestrians' past history, there are many plausible future paths they can take. This shift of emphasis to plan for multiple future paths has led many recent works to incorporate multi-modality in their trajectory prediction models. Lee et al. <ref type="bibr" target="#b27">[28]</ref> propose a conditional variational autoencoder (CVAE), named DESIRE, to generate multiple future trajectories based on agent interactions, scene semantics and expected reward function, within a sampling-based inverse optimal control (IOC) scheme. In <ref type="bibr" target="#b28">[29]</ref>, Gupta et al. propose a Generative Adversarial Network (GAN) <ref type="bibr" target="#b29">[30]</ref> based framework with a novel social pooling mechanism to generate multiple future trajectories in accordance to social norms. In <ref type="bibr" target="#b30">[31]</ref>, Sadeghian et al. also propose a GAN based framework named SoPhie, which utilizes path history of all the agents in a scene and the scene context information. SoPhie employs a social attention mechanism with physical attention, which helps in learning social information across the agent interactions. However, these socially-aware approaches do not take into account the pedestrians' ultimate goals, which play a key role in shaping their movement in the scene. A few works also approach trajectory prediction via an inverse reinforcement learning (IRL) setup. Zou et al. <ref type="bibr" target="#b31">[32]</ref> applies Generative Adversarial Imitation Learning (GAIL) <ref type="bibr" target="#b32">[33]</ref> for trajectory prediction, named Social-Aware GAIL (SA-GAIL). With IRL, the authors model the human decision-making process more closely through modeling humans as agents with states (past trajectory history) and actions (future position). SA-GAIL generates socially acceptable trajectories via a learned reward function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Conditioned-on-Goal</head><p>Goal-conditioned approaches are regarded as inverse planning or prediction by planning where the approach learns the final intent or goal of the agent before predicting the full trajectory. In <ref type="bibr" target="#b33">[34]</ref>, Rehder et al. propose a particle filtering based approach for modeling destination conditioned trajectory prediction and use explicit Von-Mises distribution based probabilistic framework for prediction. Later in a follow-up work, <ref type="bibr" target="#b34">[35]</ref> Rehder et al. further propose a deep learning based destination estimation approach to tackle intention recognition and trajectory prediction simultaneously. The approach uses fully Convolutional Neural Networks (CNN) to construct the path planning towards some potential destinations which are provided by a recurrent Mixture Density Network (RMDN). While both the approaches make an attempt for destination conditioned prediction, a fully probabilistic approach trains poorly due to unstable training and updates. Further, they ignore the presence of other pedestrians in the scene which is key for predicting shorter term motions which are missed by just considering the environment. Rhinehart et al. <ref type="bibr" target="#b35">[36]</ref> propose a goal-conditioned multi-agent forecasting approach named PRECOG, which learns a probabilistic forecasting model conditioned on drivers' actions intents such as ahead, stop, etc. However, their approach is designed for vehicle trajectory prediction, and thus conditions on semantic goal states. In our work, we instead propose to utilize destination position for pedestrian trajectory prediction.</p><p>In <ref type="bibr" target="#b36">[37]</ref>, Li et al. posit a Conditional Generative Neural System (CGNS), the previous established state-of-the-art result on the ETH/UCY dataset. They propose to use variational divergence minimization with soft-attention to predict feasible multi-modal trajectory distributions. Even more recently, Bhattacharyya et al. <ref type="bibr" target="#b37">[38]</ref> propose a conditional flow VAE that proposed a general normalizing flow for structured sequence prediction and applies it to the problem of trajectory prediction. Concurrent to our work, Deo et al. <ref type="bibr" target="#b38">[39]</ref> propose P2TIRL, a Maximum Entropy Reinforcement Learning based trajectory prediction module over a discrete grid. The work <ref type="bibr" target="#b37">[38]</ref> shares state-of-the-art with <ref type="bibr" target="#b38">[39]</ref> on the Stanford Drone Dataset (SDD) with the TrajNet <ref type="bibr" target="#b39">[40]</ref> split. However, these works fail to consider the human aspect of the problem, such as interaction with other agents. We compare our proposed PECNet with all three of the above works on both the SDD &amp; ETH/UCY datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>In this work, we aim to tackle the task of human trajectory prediction by reasoning about all the humans in the scene jointly while also respecting social norms. Suppose a pedestrian p k enters a scene I. Given the previous trajectory of p for past t p steps, as a sequence of coordinates T k p :</p><formula xml:id="formula_0">= {u k } tp i=1 = {(x k , y k )} tp i=1</formula><p>, the problem requires predicting the future position of p k on I for next t f steps,</p><formula xml:id="formula_1">T k f := {u k } tp+t f i=tp+1 = {(x, y)} tp+t f i=tp+1</formula><p>. As mentioned in Section 1, we break the problem into two daisy chained steps. First, we model the sub-goal of p k , i.e. the last observed trajectory points of p k say, G k = u k | tp+t f as a representation of the predilection of p k to go its pre-determined route. This sub-goal, also referred to as the endpoint of the trajectory, the pedestrian's desired end destination for the current sequence. Then in the second step, we jointly consider the past histories {T k p } α k=1 of all the pedestrians {p k } α k=1 present in the scene and their estimated endpoints {G k } α k=1 for predicting socially compliant future trajectories T k f . In the rest of this section we describe in detail, our approach to achieve this, using the endpoint estimation VAE for sampling the future endpoints G and a trajectory prediction module to use the sampled endpointsĜ k to predict T f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Endpoint VAE</head><p>We propose to model the predilection of the pedestrian as a sub-goal endpoint G := u t f = (x t f , y t f ) which is the last observed trajectory point for pedestrian p k . First, we infer a distribution on G based on the previous location history T i of p k using the Endpoint VAE. As illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>, we extract the previous history T k i and the ground truth endpoint G k for all pedestrian p k in the scene. We encode the past trajectory T k i of all p k independently using a past trajectory encoder E past . This yields us E past (T i ), a representation of the motion history. Similarly, the future endpoint G k is encoded with an Endpoint encoder E end to produce E end (G k ) independently for all k. These representations are concatenated together and passed into the latent encoder E latent which produces parameter (µ, σ) for encoding the latent variable z = N (µ, σ) of the VAE. Finally, we sample possible latent future endpoints from N (µ, σ), concatenate it with E past (T i ) for past context and decode using the latent decoder D latent to yield our guesses forĜ k . Since the ground truth G k belongs to the future, and is unavailable at test time, during evaluation we sample z from N (0, σ T I), concatenate with E past (T i ) (as done in training) and then use the learned D latent to estimate the futureĜ k . This is illustrated in <ref type="figure" target="#fig_1">Figure 2</ref> where the red connections are only used in the training and not in the evaluation phase.</p><p>Truncation trick: In <ref type="bibr" target="#b40">[41]</ref>, Brock et al. introduce the 'Truncation Trick' as a method of trade-off between the fidelity and variety of samples produced by the generator in BigGAN. In this work, we propose an analogous trick for evaluation phase in multi-modal trajectory forecasting where the variance of the latent endpoint sampling distribution is changed according to the number of samples (K) allowed for multi-modal prediction. In a situation requiring few shot multi-modal prediction, such as under computation constraints, where only a few samples (K = 1, 2 or 3) are permissible, we propose to use σ T = 1 and truncate the sampling distribution at ±c √ K − 1. In contrast, in situations where a high number of predictions are to be generated (such as K = 20, a standard setting on benchmarks) we propose to use σ T &gt; 1 with no truncation. We posit that this procedure allows simple adjustment of prediction diversity in favor of overall performance for different K, thereby providing a simple method of achieving good performance in all settings without requiring any retraining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Endpoint conditioned Trajectory Prediction</head><p>Using the sampled estimate of the endpointsĜ from Endpoint VAE, we employ the endpoint encoder E end once again (within the same forward pass) to obtain encodings for the sampled endpoints E end (Ĝ k ). This is used along with prediction network to plan the path T f starting to G thereby predicting the future path.</p><p>Note that, another design choice could have been that even during training, the ground truth E end (G k ) are used to predict the future T f . This seems reasonable as well since it provides cleaner, less noisy signals for the downstream social pooling &amp; prediction networks while still training the overall module end to end (because of coupling through E past ). However, such a choice will decouple training of the Endpoint VAE (which would then train only with KL Divergence and AWL loss, refer Section 3.3) and social pooling network (which would then train only with ATL loss, refer 3.3) leading to inferior performance empirically.</p><p>The sampled endpoints' representations E end (Ĝ k ) are then concatenated with corresponding E past (T i ) (as in Section 3.1) and passed through N rounds of social pooling using a social pooling mask M for all the pedestrians in the scene jointly. The social pooling mask M is α × α block diagonal matrix denoting the social neighbours for all {p i } α i=1 pedestrians in the scene. Mathematically,</p><formula xml:id="formula_2">M[i, j] =          0 if min 1≤m,n≤tp u i m − u j n 2 &gt; t dist 0 if min 1≤m≤tp |F(u i 0 ) − F(u j m )| * min 1≤m≤tp |F(u i m ) − F(u j 0 )|) &gt; 0 1 otherwise (1)</formula><p>where F(.) denoted the actual frame number the trajectory was observed at. Intuitively, M defines the spatio-temporal neighbours of each pedestrian p i using proximity threshold t dist for distance in space and ensure temporal overlap. Thus, the matrix M encodes crucial information regarding social locality of different trajectories which gets utilized in attention based pooling as described below. Social Pooling: Given the concatenated past history and sampled way-point representations X</p><formula xml:id="formula_3">(1) k = (E past (T k p ), E end (Ĝ k ))</formula><p>we do N rounds of social pooling where the (i+1)th round of pooling recursively updates the representations X (i) k from the last round according to the non-local attention mechanism <ref type="bibr" target="#b41">[42]</ref>:</p><formula xml:id="formula_4">X (i+1) k = X (i) k + 1 α j=1 M ij · e φ(X (i) k ) T θ(X (i) j ) α j=1 M ij · e φ(X (i) k ) T θ(X (i) j ) g(X (i) k ) (2)</formula><p>where {θ, φ} are encoders of X k to map to a learnt latent space where the representation similarity between p i and p j trajectories is calculated using the embedded gaussian exp(φ(X k ) T θ(X j )) for each round of pooling. The social mask, M is used point-wise to allow pooling only on the spatio-temporal neighbours masking away other pedestrians in the scene. Finally, g is a transformation encoder for X k used for the weighted sum with all other neighbours. The whole procedure, after being repeated N times yields X (N ) k , the pooled prediction features for each pedestrian with information about the past positions and future destinations of all other neighbours in the scene.</p><p>Our proposed social pooling is a novel method for extracting relevant information from the neighbours using non-local attention. The proposed social non local pooling (S-NL) method is permutation invariant to pedestrian indices as a useful inductive bias for tackling the social pooling task. Further, we argue that this method of learnt social pooling is more robust to social neighbour mis-identification such as say, mis-specified distance (t dist ) threshold compared to previously proposed method such as max-pooling <ref type="bibr" target="#b28">[29]</ref>, sorting based pooling <ref type="bibr" target="#b30">[31]</ref> or rigid grid-based pooling <ref type="bibr" target="#b26">[27]</ref> since a learning based method can ignore spurious signals in the social mask M.</p><p>The pooled features X (N ) k are then passed through the prediction network P future to yield our estimate of rest of trajectory {u k } tp+t f k=tp+1 which are concatenated with sampled endpointĜ yieldsT f . The complete network is trained end to end with the losses described in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Loss Functions</head><p>For training the entire network end to end we use the loss function,</p><formula xml:id="formula_5">L P ECN et = λ 1 D KL (N (µ, σ) N (0, I)) KL Div in latent space +λ 2 Ĝ c − G c 2 2 AEL + T f − T f 2 AT L (3)</formula><p>where the KL divergence term is used for training the Variational Autoencoder, the Average endpoint Loss (AEL) trains E end , E past , E latent and D latent and the Average Trajectory Loss (ATL) trains the entire module together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Stanford Drone Dataset: Stanford Drone Dataset <ref type="bibr" target="#b4">[5]</ref> is a well established benchmark for human trajectory prediction in bird's eye view. The dataset consists of 20 scenes captured using a drone in top down view around the university campus containing several moving agents like humans and vehicles. It consists of over 11, 000 unique pedestrians capturing over 185, 000 interactions between agents and over 40, 000 interactions between the agent and scene <ref type="bibr" target="#b4">[5]</ref>. We use the standard test train split as used in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b38">39]</ref> and other previous works. ETH/UCY: Second is the ETH <ref type="bibr" target="#b5">[6]</ref> and UCY <ref type="bibr" target="#b6">[7]</ref> dataset group, which consists of five different scenes -ETH &amp; HOTEL (from ETH) and UNIV, ZARA1, &amp; ZARA2 (from UCY). All the scenes report the position of pedestrians in world-coordinates and hence the results we report are in metres. The scenes are captured in unconstrained environments with few objects blocking pedestrian paths. Hence, scene constraints from other physical non-animate entities is minimal. For bench-marking, we follow the commonly used leave one set out strategy i.e., training on four scenes and testing on the fifth scene <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>Network Architecture  <ref type="table">Table 4</ref>.1. The entire network is trained end to end with the L E-VAE loss using an ADAM optimizer with a batch size of 512 and learning rate of 3 × 10 −4 for all experiments. For the loss coefficient weights, we set λ 1 = λ 2 = 1. We use N = 3 rounds of social pooling for Stanford Drone Dataset and N = 1 for ETH &amp; UCY scenes. Using social masking, we perform the forward pass in mini-batches instead of processing all the pedestrians in the scene in a single forward pass (to aboid memory overflow) constraining all the neighbours of a pedestrian to be in the same mini-batch. Metrics: For prediction evaluation, we use the Average Displacement Error (ADE) and the Final Displacement Error (FDE) metrics which are commonly used in literature <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref>. ADE is the average 2 distance between the predictions and the ground truth future and FDE is the 2 distance between the predicted and ground truth at the last observed point. Mathematically,</p><formula xml:id="formula_6">E way 2 → 8 → 16 → 16 E past 16 → 512 → 256 → 16 E latent 32 → 8 → 50 → 32 D latent 32 → 1024 → 512 → 1024 → 2 φ, θ 32 → 512 → 64 → 128 g 32 → 512 → 64 → 32 P predict 32 → 1024 → 512 → 256 → 22</formula><formula xml:id="formula_7">ADE = tp+t f +1 j=ti+1 û j − u j 2 t f FDE = û tp+t f +1 − u tp+t f +1 2<label>(4)</label></formula><p>where u j ,û j are the ground truth and our estimated position of the pedestrian at future time step j respectively. Baselines: We compare our PECNet against several published baselines including previous state-of-the-art methods briefly described below.</p><p>-Social GAN (S-GAN) <ref type="bibr">[</ref>  <ref type="table" target="#tab_1">Table 1</ref>. Comparison of our method against several recently published multi-modal baselines and previous state-of-the-art method (denoted by *) on the Stanford Drone Dataset <ref type="bibr" target="#b4">[5]</ref>. '-S' &amp; '-TT' represents ablations of our method without social pooling &amp; truncation trick. We report results for in pixels for both K = 5 &amp; 20 and for several other K in <ref type="figure" target="#fig_5">Figure 5</ref>. † denotes concurrent work. Lower is better. use additional 3D multi-view simulation data adversarially, for novel camera view adaptation. <ref type="bibr" target="#b42">[43]</ref> improves upon the P2TIRL as well, with performance close to PECNet's base model. However our best model (with pooling and truncation) still achieves a better ADE/FDE performance. -Ours-TT: This represents an ablation of our method without using the truncation trick. In other words, we set σ T to be identically 1 for all K settings. Truncation trick ablations with different K are shown in <ref type="figure" target="#fig_0">Fig 5 &amp; Table 1</ref>. -Ours-S-TT: This represents an ablation of our method without using both the social pooling module and the truncation trick i.e. the base PECNet. We set σ T = 1 and N = 0 for the number of rounds of social pooling and directly transmit the representations to P future , the prediction sub-network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Quantitative Results</head><p>In this section, we compare and discuss our method's performance against above mentioned baselines on the ADE &amp; FDE metrics.  As observed by the difference in performance between Ours-S-TT and Our-TT, the social pooling module also plays a crucial role, boosting performance by 0.33 ADE (∼ 2.1%). Note that, while both P2TIRL <ref type="bibr" target="#b38">[39]</ref> &amp; SimAug <ref type="bibr" target="#b42">[43]</ref> are concurrent works, we compare with their methods' performance as well in <ref type="table" target="#tab_1">Table 1</ref> for experimental comprehensiveness. All reported results averaged for 100 trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stanford Drone Dataset:</head><p>ETH/UCY: <ref type="table">Table 2</ref> shows the results for evaluation of our proposed method on the ETH/UCY scenes. We follow the leave-one-out evaluation protocol with K = 20 as in CGNS <ref type="bibr" target="#b36">[37]</ref>/Social-GAN <ref type="bibr" target="#b28">[29]</ref>. All reported numbers are without the truncation trick. In this setting too, we observe that our method outperforms previously proposed methods, including the previous state-of-the-art <ref type="bibr" target="#b36">[37]</ref>. We push the state-of-the-art on average by ∼ 40.8% with the effect being the most on HOTEL (74.2%) and least on ETH (12.9%). Also, without the social pooling &amp; truncation trick (OUR-S-TT) the performance is still superior to the stateof-the-art by 34.6%, underlining the usefulness of conditioning on the endpoint in PECNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditioned Way-point positions &amp; Oracles:</head><p>For further evaluation of our model, we condition on future trajectory points other than the last observed point which we refer to as way-points. Further, to decouple the errors in inferring the conditioned position from errors in predicting a path to that position, we use a destination (endpoint) oracle. The destination oracle provides ground truth information of the conditioned position to the model, which uses it to predict the rest of the trajectory. All of the models, with and without the destination oracle are trained from scratch for each of the conditioning positions.</p><p>Referring to <ref type="figure" target="#fig_4">Figure 4</ref>, we observe several interesting and informative trends that support our earlier hypotheses. (A) As a sanity check, we observe that as we condition on positions further into the future, the FDE for both the Oracle model &amp; the proposed model decrease with a sharp trend after the 7th future position. This is expected since points further into the future provide more information for the final observed point. (B) The ADE error curves for both the oracle and the proposed model have the same decreasing trend albeit with a gentler slope than FDE because the error in predicting the other points (particularly the noisy points in the middle of the trajectory) decreases the gradient. (C) Interestingly, our model's ADE and FDE is not significantly different from that of the Oracle model for points close in the future and the error in the two models are approximately the same until about the 7th future position. This suggests that till around the middle of the future, the conditioned way-points do not hold significant predictive power on the endpoint and hence using our noisy guesses vs. the oracle's ground truth for their position does not make a difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Way-point Prediction Error:</head><p>The way-point position error is the 2 distance between the prediction of location of the conditioned position and its ground truth location (in the future). Referring to <ref type="figure" target="#fig_4">Figure 4</ref>, we observe an interesting trend in the waypoint error as we condition on points further into the future. The way-point prediction error increases at the start which is expected since points further into the future have a higher variance. However, after around the middle (7th point) the error plateaus and then even slightly decreases. This lends support to our hypothesis that pedestrians, having predilection towards their destination, exert their will towards it. Hence, predicting the last observed way-point allows for lower prediction error than way-points in the middle! This in a nutshell, confirms the motivation of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Number of samples (K):</head><p>All the previous works use K = 20 samples (except DESIRE which uses K = 5) to evaluate the multi-modal predictions for metrics ADE &amp; FDE. Referring to <ref type="figure" target="#fig_5">Figure 5</ref>, we see the expected decreasing trend in ADE &amp; FDE with time as K increases. Further, we observe that our proposed method achieves the same error as the previous works with much smaller K. Previous state-of-the-art achieves 12.58 <ref type="bibr" target="#b38">[39]</ref> ADE using K = 20 samples which is matched by PECNet at half the number of samples, K = 10. This further lends support to our hypothesis that conditioning on the inferred waypoint significantly reduces the modeling complexity for multi-modal trajectory forecasting, providing a better estimate of the ground truth. Lastly, as K grows large (K → ∞) we observe that the FDE slowly gets closer to 0 with more number of samples, as the ground truth G c is eventually found. However, the ADE error is still large (6.49) because of the errors in the rest of the predicted trajectory. This is in accordance with the observed ADE (8.24) for the oracle conditioned on the last observed point (i.e. 0 FDE error) in <ref type="figure" target="#fig_4">Fig. 4</ref>.</p><p>Design choice for VAE: We also evaluate our design choice of using the inferred future way-pointsĜ c for training subsequent modeules (social pooling &amp; prediction) instead of using the ground truth G c . As mentioned in Section 3.2, this is also a valid choice for training PECNet end to end. Empirically, we find  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Qualitative Results</head><p>In <ref type="figure" target="#fig_6">Figure 6</ref>, we present several visualizations of the predictions from PECNet. As shown, PECNet produces multi-moda diverse predictions conditioning on inferred endpoints. In <ref type="figure" target="#fig_7">Figure 7</ref>, we present animations of several socially compliant predictions. The visualizations show that along with producing state-of-the-art results, PECNet can also perform rich multi-modal multi-agent forecasting. Stanford Drone Dataset <ref type="bibr" target="#b4">[5]</ref>, ETH <ref type="bibr" target="#b5">[6]</ref> &amp; UCY <ref type="bibr" target="#b6">[7]</ref> in all of which PECNet achieved state-of-the-art performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Imitating the Human Path Planning Process. Our proposed approach to model pedestrian trajectory prediction (top left) breaks down the task in two steps: (a) inferring the local endpoint distribution (top right), and then (b) conditioning on sampled future endpoints (bottom left) for jointly planning socially compliant trajectories for all the agents in the scene (bottom right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Architecture of PECNet: PECNet uses past history, Ti along with ground truth endpoint Gc to train a VAE for multi-modal endpoint inference. Ground-truth endpoints are denoted by whereas x denote the sampled endpointsĜc. The sampled endpoints condition the social-pooling &amp; predictor networks for multi-agent multimodal trajectory forecasting. Red connections denote the parts utilized only during training. Shades of the same color denote spatio-temporal neighbours encoded with the block diagonal social mask in social pooling module. Further Details in Section 3.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Network architecture details for all the sub-networks used in the module. All the sub-networks used in proposed module are Multi-Layer perceptrons with ReLU non-linearity. Network architecture for each of the subnetworks are mentioned in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>-</head><label></label><figDesc>SoPhie [31]: Sadeghian et al. propose a GAN employing attention on social and physical constraints from the scene to produce human-like motion. -CGNS [37]: Li et al. posit a Conditional Generative Neural System (CGNS) that uses conditional latent space learning with variational divergence minimization to learn feasible regions to produce trajectories. They also established the previous state-of-the-art result on the ETH/UCY datasets. -DESIRE [28]: Lee et al. propose an Inverse optimal control based trajectory planning method that uses a refinement structure for predicting trajectories. -CF-VAE [38]: Recently, a conditional normalizing flow based VAE proposed by Bhattacharyya et al. pushes the state-of-the-art on SDD further. Notably, their method also does not also rely on the RGB scene image. -P2TIRL [39]: A concurrent work by Deo et al. proposes a method for trajectory forecasting using a grid based policy learned with maximum entropy inverse reinforcement learning policy. They closely tie with the previous state-of-the-art [38] in ADE/FDE performance. -SimAug [43]: More recently, a concurrent work by Liang et al. proposes to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Conditioned Way-point positions &amp; Oracles: We evaluate the performance of the proposed method against the choice of future conditioning position on ADE &amp; FDE metrics. Further, we evaluate the performance of a destination oracle version of the model that receives perfect information on conditioned position for predicting rest of the trajectory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Performance across K: ADE &amp; FDE performance of our method against number of samples used for evaluation. Several previous baselines are mentioned as well with their number of samples used. Our method significantly outperforms the stateof-the-art reaching their performance with much lesser number of samples &amp; performing much better with same number of samples as theirs (K = 20).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Visualizing Multimodality: We show visualizations for some multi-modal and diverse predictions produced by PECNet. White represents the past 3.2 seconds while red &amp; cyan represents predicted &amp; ground truth future respectively over next 4.8 seconds. Predictions capture a wide-range of plausible trajectory behaviours while discarding improbable ones like, endpoints opposite to pedestrian's direction of motion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Diverse Mutltimodal &amp; Social Interactions: Visualizations denoting multiple socially compliant trajectories predicted with PECNet. Left pane shows future trajectories for 9.6 seconds predicted in a recurrent input fashion. Right pane shows the predicted trajectories for future 4.8 seconds at an intersection. Solid circles represent the past input &amp; stars represent the future ground truth. Predicted multi-modal trajectories are shown as translucent circles jointly for all present pedestrians. Animation is best viewed in Adobe Acrobat Reader. More video visualizations available at project homepage: https://karttikeya.github.io/publication/htf/ that such a design achieves 10.87 ADE and 17.03 FDE. This is worse (∼ 8.8%) than usingĜ c which motivates our design choice for usingĜ c (Section 3.2). Truncation Trick: Fig. 5 shows the improvements from the truncation trick for an empirically chosen hyperparameter c ≈ 1.2. As expected, small values of K gain the most from truncation, with the performance boosting from 22.85 ADE (48.8 FDE) to 17.29 ADE (35.12 FDE) for K = 1 (∼ 24.7%).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>29]: Gupta et al. propose a multi-modal human trajectory prediction GAN trained with a variety loss to encourage diversity.</figDesc><table><row><cell></cell><cell cols="10">SoPhie S-GAN DESIRE CF-VAE* P2TIRL  † SimAug  † O-S-TT O-TT Ours PECNet (Ours)</cell></row><row><cell>K</cell><cell>20</cell><cell>20</cell><cell>5</cell><cell>20</cell><cell>20.</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>5</cell><cell>20</cell></row><row><cell cols="3">ADE 16.27 27.23</cell><cell>19.25</cell><cell>12.60</cell><cell>12.58</cell><cell>10.27</cell><cell cols="3">10.56 10.23 12.79</cell><cell>9.96</cell></row><row><cell cols="3">FDE 29.38 41.44</cell><cell>34.05</cell><cell>22.30</cell><cell>22.07</cell><cell>19.71</cell><cell cols="3">16.72 16.29 25.98</cell><cell>15.88</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>shows the results of our proposed method</cell></row><row><cell>against the previous baselines &amp; state-of-the-art methods. Our proposed method</cell></row><row><cell>achieves a superior performance compared to the previous state-of-the-art [38,</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Code available at project homepage: https://karttikeya.github.io/publication/htf/ arXiv:2004.02025v3 [cs.CV] 18 Jul 2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">ConclusionIn this work we present PECNet, a pedestrian endpoint conditioned trajectory prediction network. We show that PECNet predicts rich &amp; diverse multi-modal socially compliant trajectories across a variety of scenes. Further, we perform extensive ablations on our design choices such as endpoint conditioning position, number of samples &amp; choice of training signal to pinpoint achieved performance gains. We also introduce a "truncation trick" for trajectory prediction, a simple method for adjusting diversity for performance in trajectory prediction without retraining. Finally, we benchmark PECNet across multiple datasets including</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning motion patterns of persons for mobile service robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maren</forename><surname>Bennewitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292)</title>
		<meeting>2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3601" to="3606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Probabilistic robotics (intelligent robotics and autonomous agents series), ser. intelligent robotics and autonomous agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Action understanding as inverse planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="349" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Planning-based prediction for pedestrians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garratt</forename><surname>Ratliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srinivasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3931" to="3936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving data association by joint modeling of pedestrian trajectories and groupings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="452" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiorgos</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><forename type="middle">O</forename><surname>Gavrila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arras</surname></persName>
		</author>
		<title level="m">Human Motion Trajectory Prediction: A Survey</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Camera-based observation of obstacle motions to derive statistical data for mobile robot motion planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eckhard</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No. 98CH36146)</title>
		<meeting>1998 IEEE International Conference on Robotics and Automation (Cat. No. 98CH36146)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="662" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Voronoi tracking: Location estimation using sparse and noisy sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Hightower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003)(Cat. No. 03CH37453)</title>
		<meeting>2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003)(Cat. No. 03CH37453)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="723" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning motion patterns of people for compliant robot motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maren</forename><surname>Bennewitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Cielniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="48" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelling smooth paths using gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng Keat</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Laugier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Field and Service Robotics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="381" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recognition of situation classes at road intersections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Käfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Hermes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Wöhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Kummert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<biblScope unit="page" from="3960" to="3965" />
			<date type="published" when="2010" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mobile agent trajectory prediction using bayesian nonparametric reachability trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georges</forename><surname>Aoude</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>How</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Infotech@ Aerospace</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">1512</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Will the pedestrian cross? a study on pedestrian path prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Christoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="494" to="506" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pedestrian&apos;s trajectory forecast in public traffic with artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Goldhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Doll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Brunsmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Gensler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 22nd International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4110" to="4115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised robot learning to predict person motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Folkesson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="691" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Enabling flow awareness for mobile robots in partially observable environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Tomasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kucner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Schaffernicht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achim J</forename><surname>Hernandez Bennetts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lilienthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1093" to="1100" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Activity forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Andrew</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="201" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Knowledge transfer for scene-specific motion prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lamberto</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Castaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="697" to="713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic vehicle trajectory prediction over occupancy grid map via recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeoungdo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">Mook</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaekyum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung Hi</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><forename type="middle">Choo</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun Won</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="399" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Who are you with and where are you going?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kota</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">E</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1345" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Socially-aware large-scale crowd forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2203" to="2210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriaki</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding human behaviors in crowds by imitating the decision-making process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haosheng</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihong</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generative adversarial imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4565" to="4573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Goal-directed pedestrian prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eike</forename><surname>Rehder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Kloeden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="50" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pedestrian prediction by planning using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eike</forename><surname>Rehder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Wirth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2018" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01296</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01631</idno>
		<title level="m">Conditional generative neural system for probabilistic trajectory prediction</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apratim</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hanselmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09008</idno>
		<title level="m">Bernt Schiele, and Christoph-Nikolas Straehle. Conditional flow variational autoencoders for structured sequence prediction</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00735</idno>
		<title level="m">Trajectory forecasts in unknown environments conditioned on grid-based plans</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Trajnet: Towards a benchmark for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Simaug: Learning robust representations from 3d simulation for pedestrian trajectory prediction in unseen cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
