<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pyramid Mask Text Detector</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingchao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuebo</forename><surname>Liu</surname></persName>
							<email>liuxuebo@sensetime.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Sheng</surname></persName>
							<email>jie.sheng0112@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
							<email>liangding@sensetime.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
							<email>lixin@se.cuhk.edu.hk</email>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingjie</forename><surname>Liu</surname></persName>
							<email>qingjie.liu@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sensetime</forename></persName>
						</author>
						<title level="a" type="main">Pyramid Mask Text Detector</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scene text detection, an essential step of scene text recognition system, is to locate text instances in natural scene images automatically. Some recent attempts benefiting from Mask R-CNN formulate scene text detection task as an instance segmentation problem and achieve remarkable performance. In this paper, we present a new Mask R-CNN based framework named Pyramid Mask Text Detector (PMTD) to handle the scene text detection. Instead of binary text mask generated by the existing Mask R-CNN based methods, our PMTD performs pixel-level regression under the guidance of location-aware supervision, yielding a more informative soft text mask for each text instance. As for the generation of text boxes, PMTD reinterprets the obtained 2D soft mask into 3D space and introduces a novel plane clustering algorithm to derive the optimal text box on the basis of 3D shape. Experiments on standard datasets demonstrate that the proposed PMTD brings consistent and noticeable gain and clearly outperforms state-of-the-art methods. Specifically, it achieves an F-measure of 80.13% on ICDAR 2017 MLT dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Scene text detection has attracted growing research interests in the computer vision community, due to its numerous practical applications in scene understanding, license plate recognition, autonomous driving, and document analysis, etc. Recently, many works <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b13">14]</ref> view scene text detection as an instance segmentation problem, and several Mask R-CNN <ref type="bibr" target="#b5">[6]</ref> based methods were proposed and achieved remarkable performance. However, there are several drawbacks in these works:</p><p>Over-simplified supervision: The common observation that most text areas in natural scenes are quadrilateral is supposed to be useful for text detection. However, the Mask R-CNN based methods, aiming for differentiating the text region from the background region rather than generating a text mask of a specific shape, ignore the consideration of * indicates equal contribution.</p><p>(a) Examples with imprecise segmentation labels. The area within green box denotes the manually annotated text instance. Many background pixels not belonging to the text instance are mislabeled as the foreground pixels, especially at the border of the text box, which may hurt the performance of the Mask R-CNN based methods.</p><p>Baseline PMTD <ref type="bibr">(b)</ref> The red box is the predicted bounding box and the green box refers to the predicted text box. The existing Mask R-CNN based methods suffer from the errors of bounding box detection while PMTD can regress more accurate text box with the help of the informative soft text mask. <ref type="figure" target="#fig_4">Figure 1</ref>: Imprecise segmentation labels and imprecise bounding box are detrimental to previous methods. such kind of information and therefore can not take advantage of the given label.</p><p>Imprecise segmentation labels: Converting the quadrilateral text area into a pixel-level binary supervision signals for semantic segmentation enables directly applying Mask R-CNN to scene text detection. However, the quality of the generated pixel-level labels is unsatisfactory. As shown in <ref type="figure" target="#fig_4">Fig.1(a)</ref>, many background pixels not belonging to the text region are incorrectly regarded as the foreground pixels. Trained on noisy data, the semantic segmentation based text detector is prone to generate mistakes.</p><p>Error propagation: The Mask R-CNN based methods firstly predict text bounding boxes and then perform semantic segmentation within the bounding box. Such strategy is usually reasonable for simple scenes but rather fragile when the predicted bounding box fails to cover the whole text re-gion. The reason is because determining the text box with only the text region inside the bounding box tends to exclude the outside part (See <ref type="figure" target="#fig_4">Fig. 1(b)</ref>). In other words, the errors from the object detection may be propagated to the process of finding text box, leading to performance degradation of scene text detection. We also observe that the effect of the error propagation will be amplified with the increasing of the IoU threshold for true positive text instances (quantitative results and qualitative analysis are detailed in Sec. 4.3).</p><p>In this paper, we propose the Pyramid Mask Text Detector (PMTD) to address the above problems. As depicted in <ref type="figure" target="#fig_0">Fig. 2</ref>, instead of pixel-level binary classification as done in the existing Mask R-CNN based methods, we propose to perform "soft" semantic segmentation between the text region and the background region. Explicitly, we assign a soft pyramid label (i.e., a real value between 0 and 1) for each pixel within text instance. The value of the soft pyramid label is determined by the distance to the boundary of the text box, which implicitly encoding the shape and location information into the training data. By fitting such soft text mask, the quadrilateral property of the text instance is naturally considered during training. Besides, introducing the location-aware segmentation labels reduces the impact of mislabeled pixels near the boundary of the text box.</p><p>During the test phase, with the extended z-axis characterizing the value of the pixel-level segmentation output, we reinterpret the 2D predicted text mask into a set of 3D points. A plane clustering algorithm is proposed to regress the optimal pyramid from these 3D points. Specifically, launched with four initialized supporting planes of a pyramid, the plane clustering algorithm iteratively groups the nearest points for each supporting planes, and then updates the supporting planes by the clustered points. After the iterations, an accurate bounding pyramid is obtained and its bottom face is regarded as the output text box. Since it is not the boundary pixels but the supporting plane that gets involved in finding the text box, the error propagation issue can be alleviated, and more accurate text box can be obtained.</p><p>Our pipeline is shown in <ref type="figure" target="#fig_1">Fig.3</ref>. As there exist differences between text detection datasets and object detection datasets, such as the different distribution of aspect ratios and scales, we tailor-make a Mask R-CNN based baseline for text detection, which outperforms all previous methods on ICDAR 2017 MLT dataset. Furthermore, the proposed PMTD raises the F-measure to 80.13%. The main contributions of this paper are three-fold:</p><p>• We propose the Pyramid Mask Text Detector for scene text detection, and extensive experiments demonstrate its state-of-the-art performance on several benchamark datasets. • We propose to perform "soft" segmentation between text region and non-text region, incorporating the shape and location information into the model training and alleviating the inaccuracy labeling for the instance boundary.</p><p>• We introduce a novel plane clustering algorithm to find better text box with the 3D coordinate, which predicts more accurate text box and improves the robustness to imprecise bounding box predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Scene text detection has received significant attention over the past few years, and numerous deep learning based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref> have been reported in the literature. Comprehensive reviews and detailed analyses can be found in survey papers <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>Earlier text detection works including <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15]</ref> are among the first deep neural network based methods. They usually consist of multiple stages, such as candidate aggregation, word partition and false positive removal by postprocessing filtering. Huang et al. <ref type="bibr" target="#b12">[13]</ref> first apply the MSERs operator on the input image to generate some text candidates, then use a CNN classifier to generate a confidence map which was later used for constructing text-lines. Jaderberg et al. <ref type="bibr" target="#b15">[16]</ref> train a strongly supervised character classifier to generate text saliency map, then combines bounding boxes at multiple scales and undergoes filtering and nonmaximal suppression. In a later work <ref type="bibr" target="#b14">[15]</ref>, they leverage a CNN for bounding box regression and a random forest classifier for reducing the number of false-positive detections.</p><p>Recent works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b44">45]</ref> regard text words or lines as objects and adapt the pipeline of general object detection, e.g., Faster R-CNN <ref type="bibr" target="#b35">[36]</ref>, SSD <ref type="bibr" target="#b24">[25]</ref> and YOLO <ref type="bibr" target="#b34">[35]</ref> into text detection. They regress the offsets from a proposal region or a single pixel in the feature map to a horizontal rectangle and obtain good performance with well-designed modifications on horizontal text detection. Gupta et al. <ref type="bibr" target="#b4">[5]</ref> improves over the YOLO network and Fully Convolutional Networks (FCN) <ref type="bibr" target="#b27">[28]</ref> for text prediction densely, while further adopts the filter and regression steps for removing the false positives. TextBoxes <ref type="bibr" target="#b22">[23]</ref> modifies SSD by using irregular convolutional kernels and long default anchors according to the characteristic of scene text. Built on top of Faster R-CNN, CTPN <ref type="bibr" target="#b38">[39]</ref> develops a vertical anchor mechanism that pre- dicts location and text/non-text score of each fixed-width proposal simultaneously, then connects the sequential proposals by a recurrent neural network. FEN <ref type="bibr" target="#b44">[45]</ref> improves text recall with a feature enhancement RPN and hyper feature generation for text detection refinement.</p><p>Considering that scene texts are with arbitrary orientations, works in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b8">9]</ref> make the above methods possible for multi-oriented text detection. RRPN <ref type="bibr" target="#b31">[32]</ref> introduces inclined anchors with angle information for arbitrary-oriented text prediction and rotated RoI pooling layer to project arbitrary-oriented proposals to the feature map for a text region classifier. TextBoxes++ <ref type="bibr" target="#b21">[22]</ref> improves TextBoxes by regressing horizontal anchors to more general quadrilaterals enclosing oriented texts. It also proposes an efficient cascaded non-maximum suppression for quadrilaterals or rotated rectangles. With dense predictions and one step post processing, EAST <ref type="bibr" target="#b45">[46]</ref> and DDR <ref type="bibr" target="#b9">[10]</ref> both directly produce the rotated boxes or quadrangles of text at each point in the text region. Recent text spotting methods like FOTS <ref type="bibr" target="#b25">[26]</ref> and He et al. <ref type="bibr" target="#b8">[9]</ref> show that training text detection and recognition simultaneously could greatly boost detection performance.</p><p>Except for the above regression-based methods, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref> cast text detection as a segmentation problem. Pix-elLink <ref type="bibr" target="#b2">[3]</ref> first segments out text regions by linking pixels within the same instance, then extracts text bounding boxes directly from the segmentation without location regression. TextSnake <ref type="bibr" target="#b28">[29]</ref> employs an FCN <ref type="bibr" target="#b27">[28]</ref> model to estimate the geometry attributes of text instances and uses a striding algorithm to extract the central axis point lists and finally reconstruct the text instances. Segmentation based methods tend to link adjacent text regions together incorrectly. To address this problem, PSENet <ref type="bibr" target="#b19">[20]</ref> finds text kernels with various scales and proposes a progressive scale expansion algorithm to separate text instances standing close to each other accurately. SPCNET <ref type="bibr" target="#b40">[41]</ref> views text detection as an instance segmentation problem, based on Mask R-CNN, it proposes a text context module and a re-score mechanism to suppress false positives.</p><p>Although Curved text detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b43">44]</ref> has attracted growing research interests recently, quadrilateral text detection is still a fundamental and challenging problem to be solved. PMTD is designed specially for quadrilateral text detection and significantly improves the state-of-the-art result from 74.3% <ref type="bibr" target="#b13">[14]</ref> to 80.13% on ICDAR 2017 MLT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>In this section, we firstly introduce a strong baseline. Then the soft pyramid label is proposed, which encodes the shape and location information into the training data. Finally, a new boundary regression algorithm, namely, plane clustering, is introduced to find the most fitting pyramid of the predicted soft text mask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Our Baseline</head><p>Our baseline is based on Mask R-CNN with ResNet50 backbone <ref type="bibr" target="#b6">[7]</ref>. In the training stage, we treat the axis-aligned bounding rectangle of the text region as the ground-truth bounding box and assign pixels inside text boundary to positive segmentation label. In the test stage, we firstly find all the connected areas in the predicted mask, then select the one with the maximum area, and finally obtain the output text box by finding the minimum bounding rectangle of this connected area.</p><p>We design a strong baseline by making the following three modifications:</p><p>Data augmentation: To enhance the generalization ability to various scales and aspect ratios, we apply data augmentations to enlarge scene text datasets:</p><p>1. Random horizon flip with a probability of 0.5. 2. Random resize the height and width of images to 640-2560 individually, without keeping the original aspect ratio.</p><p>3. Random select one 640 × 640 crop region from the resized image. RPN Anchor: When adopting the FPN module, we can quantify the anchor by three parameters: the base scale of anchors, the feature maps where anchors searched, and the aspect ratios of anchors.</p><p>First of all, based on statistics of the data-augmented ground truth bounding box's height and width, we set the base scale of the anchor to 4 × 4 among all the four feature maps {1/4, 1/8, 1/16, 1/32} uniformly.</p><p>For the anchor's aspect ratio, we calculate out five dedicated aspect ratios: {0.17, 0.44, 1.13, 2.90, 7.46}. The detail of generating aspect ratios is as follows: first, analyze the data-augmented ground truth bounding box's aspect ratio, then get the 5% quantile 0.17 and 95% quantile 7.46, finally insert three values in equal proportion between the 5% and 95% quantiles to form the final aspect ratio list.</p><p>OHEM: In the bounding box branch, we adopt the OHEM <ref type="bibr" target="#b37">[38]</ref> to learn the hard samples. In our settings, we first sort the samples provided by RPN in the descending order of the sum of classification loss and location loss, then select the top 512 difficult samples to update the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Motivation</head><p>Although our baseline achieves remarkable performance, it still has the same drawbacks as other Mask R-CNN based methods, as mentioned in Sec. 1:</p><p>• These methods are not considering the common observation that most text areas in natural scenes are quadrilateral. They break down the quadrilateral structure into a pixle-wise classification problem which losses the shape information of the mask.</p><p>• Converting the quadrilateral text areas into pixel-level supervision is imprecise. Many background pixels not belonging to the text region are incorrectly regarded as the foreground pixels, as shown in <ref type="figure" target="#fig_4">Fig. 1(a)</ref>. The mislabeled boundary pixels may cause an unexpectedly misjudged loss.</p><p>• Mask R-CNN based methods firstly predict bounding boxes and then predict text mask for every bounding box. The imprecisely predicted bounding box limits the mask branch to generate accurate text mask. In other words, the errors from the object detection will be propagated to the following steps, as shown in <ref type="figure" target="#fig_4">Fig. 1(b)</ref>.</p><p>These problems motivate us to build pyramid mask text detector (PMTD), a new pipeline for scene text detection. The PMTD predicts a soft text mask for each text region and apply plane clustering algorithm to convert the predicted soft mask to the pyramid mask. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Pyramid Label</head><p>We refines the mask's hard label of the class ∈ {0, 1} to the soft pyramid label of the score ∈ [0, 1] so that the PMTD can capture the shape and location information from the data. Specifically, we assign the center of text region as the apex of the pyramid with an ideal value score = 1 and the boundary of text region as the bottom edge of the pyramid. We use the linear interpolation to fill each triangle side of the pyramid, as illustrated in <ref type="figure" target="#fig_2">Fig.4</ref>.</p><p>Formally, given the four corner points A(x a , y a ), B(x b , y b ), C(x c , y c ), D(x d , y d ) of a quadrilateral, the value score p for the point P (x p , y p ) can be calculated as follows. First, the center of text region O(x o , y o ) can be obtained by:</p><formula xml:id="formula_0">x o = (x a + x b + x c + x d )/4 (1) y o = (y a + y b + y c + y d )/4<label>(2)</label></formula><p>For every region R OM N (region between two rays OM and ON ) from R OAB , R OBC , R OCD , R ODA , the − − → OP can be decomposed uniquely:</p><formula xml:id="formula_1">− − → OP = α − − → OM + β − − → ON (3) x p − x o y p − y o = x m − x o x n − x o y m − y o y n − y o α β<label>(4)</label></formula><p>Then, α and β can be obtained by</p><formula xml:id="formula_2">α β = x m − x o x n − x o y m − y o y n − y o −1 x p − x o y p − y o<label>(5)</label></formula><p>The region R which P belongs to needs to satisfy the following condition:</p><p>α ≥ 0 and β ≥ 0</p><p>Then the score p can be calculated by:</p><formula xml:id="formula_4">score p = max(1 − (α + β), 0)<label>(7)</label></formula><p>deconvolution bilinear interpolation <ref type="figure">Figure 5</ref>: Deconvolution causes checkerboard pattern in our experiment, so we use bilinear interpolation for upsample to get a more accurate mask.</p><p>During the training stage, such supervision is reasonable. If one pixel locates near the center of the instance, its receptive field will be filled with positive pixels and deserves a higher score consequently. While the receptive field of the pixels near the boundary will contain much background context, and the scores of these pixels should be close to 0. In this respect, a larger receptive field is vital for PMTD to attain more precise results. So in the mask head, we replace the first four convolution layers to dilated convolution with stride 2 to enlarge receptive field.</p><p>Moreover, as mentioned in <ref type="bibr" target="#b33">[34]</ref>, deconvolution may cause the checkerboard pattern, which is harmful to the pixelwise regression, as illustrated in <ref type="figure">Fig. 5</ref>. To avoid this, we replace the deconvolution layer in the mask head to bilinear interpolation and a followed convolution layer.</p><p>We employ pixelwise L 1 loss to optimize the predicted text mask. Following the design in Mask R-CNN, the loss function of the whole network is as follows:</p><formula xml:id="formula_5">L = L rpn + λ 1 L cls + λ 2 L box + λ 3 L pyramid mask<label>(8)</label></formula><p>λ 1 , λ 2 and λ 3 are set to 1, 1, 5 respectively in our experiments.</p><p>Training with this new style label alleviates the pixel mislabeling problem. Taking a background pixel near the boundary as an example. Although it is mistakenly regarded as the foreground, its ground truth in our methods is still close to 0, while in previous Mask R-CNN based methods, this pixel is labeled as 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Plane Clustering</head><p>In this section, we will illustrate the plane clustering algorithm in details, which is an iteratively updated clustering algorithm for regressing the most fitting text box from the predicted soft text mask.</p><p>As a reverse process of generating a pyramid label from text region, we will first construct the pyramid from the text mask, then take the bottom edge of the pyramid as the output text box. Hence, the critical point is to parameterize and rebuild the pyramid. Formally, the pyramid is composed of four supporting planes and one base plane. In the context of pyramid mask, we can convert the predicted soft mask into a point set of (x, y, z), in which the (x, y) denotes the location and z stands for the predicted score of this pixel. The base plane is formulated as the plane z = 0, and each supporting plane can be uniquely determined by the equation Ax + By + Cz + D = 0, C = 1. Consequently, the task of the plane clustering algorithm is reduced to find the optimal parameter {A, B, D} for each supporting plane, see Algorithm 1 for details. In the initialization stage, the positive points set P is built by the condition z &gt; 0.1. Then the apex of the initial pyramid is assigned as the center of P , with an ideal score z = 1. The four vertexes of the pyramid in the bottom face are initialized as four corner points of the predicted text bounding box, shown in the left image in <ref type="figure" target="#fig_3">Fig.6</ref>. After initializing the pyramid, an iterative updating scheme is implemented for clustering points, which is shown in <ref type="figure" target="#fig_3">Fig.6</ref>. In the assignment step, we partition each point to the nearest plane, and in the update step, we employ the robust least square algorithm (RLS) <ref type="bibr" target="#b10">[11]</ref> to regress four supporting planes from the clustered points respectively, which is robust to the noise in the predicted text mask.</p><p>When the iteration reaches the max iteration or the regression residuals returned by RLS is small enough, the final quadrangular pyramid is obtained. Then the text box can be calculated out by the intersection of four supporting planes and the plane z = 0. In our experiment, the max iteration and the residual threshold is assigned to 10 and 1e-4 respectively.</p><p>Thanks to the more informative soft text mask, the plane clustering algorithm takes advantage of the whole soft mask's information to regress the most fitting pyramid. As the final text box is obtained from the supporting plane rather than the boundary pixels, PMTD is robust to imprecise bounding boxes, and naturally regress more accurate text boundary, detailed in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, We evaluate our approach on ICDAR 2017 MLT <ref type="bibr" target="#b32">[33]</ref>, ICDAR 2015 <ref type="bibr" target="#b17">[18]</ref> and ICDAR 2013 <ref type="bibr" target="#b18">[19]</ref>. Experiment results demonstrate that the proposed PMTD brings consistent and noticeable gain, and clearly outperforms the state-of-the-art methods. Furthermore, the ablation study shows PMTD is robust to imprecise bounding box predictions and predicts more accurate text boxes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>ICDAR 2017 MLT is a multi-oriented, multi-scripting, and multi-lingual scene text dataset. It consists of 7200 training images, 1800 validation images, and 9000 test im-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Precision Recall F-measure SegLink <ref type="bibr" target="#b36">[37]</ref> 73.10 76.80 75.00 SSTD <ref type="bibr" target="#b7">[8]</ref> 80.00 73.00 77.00 WordSup <ref type="bibr" target="#b11">[12]</ref> 79.33 77.03 78.16 EAST * <ref type="bibr" target="#b45">[46]</ref> 83.27 78.33 80.72 R2CNN <ref type="bibr" target="#b16">[17]</ref> 85.62 79.68 82.54 DDR <ref type="bibr" target="#b9">[10]</ref> 82.00 80.00 81.00 Lyu et al. * <ref type="bibr" target="#b30">[31]</ref> 89.50 79.70 84.30 RRD * <ref type="bibr" target="#b23">[24]</ref> 88.00 80.00 83.80 TextBoxes++ * <ref type="bibr" target="#b21">[22]</ref> 87.80 78.50 82.90 PixelLink <ref type="bibr" target="#b2">[3]</ref> 85.50 82.00 83.70 FOTS <ref type="bibr" target="#b25">[26]</ref> 91.00 85.17 87.99 IncepText * <ref type="bibr" target="#b41">[42]</ref> 89.40 84.30 86.80 TextSnake <ref type="bibr" target="#b28">[29]</ref> 84.90 80.40 82.60 FTSN <ref type="bibr" target="#b1">[2]</ref> 88.60 80.00 84.10 SPCNET <ref type="bibr" target="#b40">[41]</ref> 88  ages. The text regions are annotated by four vertices of the quadrilateral. It is one of the largest and most challenging scene text detection datasets. ICDAR 2015 is another multi-oriented text detection dataset only for English, which includes 1000 training images and 500 testing images. Similar to ICDAR 2017 MLT, the text region is also annotated as a quadrilateral.</p><p>ICDAR 2013 is a dataset that points at the horizontal text in the natural scene. This dataset consists of 229 training images and 233 testing images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparisons with Other Methods</head><p>In this section, we compare PMTD with state-of-the-art methods on standard datasets. As shown in Tab. 1, 2, 3, our method outperforms others in all datasets.</p><p>ICDAR 2017 MLT: ImageNet <ref type="bibr" target="#b3">[4]</ref> pre-trained ResNet50 is adapted to initialize network parameter. We train our model using ICDAR 2017 MLT training and validation images for 160 epochs. We use SGD as our optimizer with batch size 64. The initial learning rate is 0.08 and decays to one-tenth of the previous at the 80th and 128th epoch. During the training stage, images are cropped to 640 × 640 patches as described in Sec. 3.1. Results are shown in Tab. 1. For single scale testing, with resizing images' long side to 1600, PMTD achieves an F-measure of 78.48%. We also resize the long side to 1600 and 2560 for multi-scale testing, and it achieves 80.13% F-measure, which outperforms the state-of-the-art method by 5.83%. Qualitative results are shown in <ref type="figure" target="#fig_5">Fig. 7</ref>.</p><p>ICDAR 2015: For ICDAR 2015, we use the pre-trained model from ICDAR 2017 MLT, and finetune another 40 Method ICDAR13 Eval DetEval CTPN <ref type="bibr" target="#b38">[39]</ref> 85.00 86.00 SegLink <ref type="bibr" target="#b36">[37]</ref> -85.30 TextBoxes * <ref type="bibr" target="#b22">[23]</ref> 85.00 86.00 SSTD <ref type="bibr" target="#b7">[8]</ref> 87.00 88.00 WordSup <ref type="bibr" target="#b11">[12]</ref> -90.34 R2CNN <ref type="bibr" target="#b16">[17]</ref> 87.73 -DDR <ref type="bibr" target="#b9">[10]</ref> -86.00 MCN <ref type="bibr" target="#b26">[27]</ref> 88.00 -Lyu et al. * <ref type="bibr" target="#b30">[31]</ref> 88.00 -RRD * <ref type="bibr" target="#b23">[24]</ref> 89.00 -TextBoxes++ * <ref type="bibr" target="#b21">[22]</ref> 88.00 89.00 PixelLink *   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>In this section, we conduct a series of comparative experiments. Experiment results show that our method achieves better performance and predicts more accurate text boxes.</p><p>Better performance: We first compare the performance of the baseline and PMTD on ICDAR 2017 MLT dataset. Results are shown in Tab. 4.</p><p>Baseline: Mask R-CNN baseline as described in Sec. 3.1, is a solid baseline that significantly outperforms state-of-the-art methods.</p><p>Baseline+DC+BU: As described in Sec. 3.3, we use dilated convolution (DC) and bilinear upsampling (BU) to predict more accurate soft text mask. We also use these two parts for our baseline to measure their gains. Experiment result indicates that dilated convolution and bilinear upsampling only increase baseline by 0.41%. PMTD: Our proposed method. It achieves an im-    More accurate prediction: As mentioned in Sec. 1, with the help of the informative soft text mask, the plane clustering algorithm can regress more accurate text boundary and is more robust to imprecise predicted bounding box. However, the current evaluation cannot clearly reflect these two advantages due to the moderate evaluation (only require IoU ≥ 0.5 on ICDAR 2015 and ICDAR 2017 MLT). So we evaluate PMTD and baseline under a higher IoU threshold.</p><p>Experiments are constructed on ICDAR 2015 test set for the absence of the label for ICDAR 2017 MLT test set. Results are summarized in Tab. 5. We can see PMTD outperforms baseline by a larger margin when the IoU threshold is 0.8. Especially, PMTD increases F-measure by 18.14% under 0.8 IoU threshold. Distribution of the true positive samples in different IoU are also illustrated in <ref type="figure" target="#fig_7">Fig. 8</ref>, which indicates a denser distribution in the high IoU interval for the PMTD.</p><p>Qualitative results are also shown in <ref type="figure" target="#fig_5">Fig. 7</ref> and <ref type="figure">Fig. 9</ref>. From <ref type="figure" target="#fig_5">Fig. 7</ref> we can see that PMTD can predict satisfactory text boxes, especially for text regions with strange shapes such as trapezoids and curves. Moreover, thanks to the gra- <ref type="figure">Figure 9</ref>: PMTD is robust to imprecise predicted bounding box. From left to right: imprecise bounding box, predicted soft text mask, regression text box. It is worth noting that the soft text mask contains gradient information, which helps plane clustering algorithm to regress text box correctly. dient information provided by the soft text mask, PMTD shows the robustness to imprecise predicted bounding boxes as shown in the <ref type="figure">Fig. 9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we presented the Pyramid Mask Text Detector (PMTD), which encodes the shape and location information into the supervision and predicts a soft text mask for each text instance. A plane clustering algorithm is introduced to find the most fitting pyramid mask of the predicted soft text mask. Experiments on standard datasets demonstrate the effectiveness of our method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Previous methods aim to find {0, 1} label for each pixel while PMTD assigns a soft pyramid label of the value ∈ [0, 1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Overall architecture of PMTD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Generation of soft pyramid label. For a pixel in the text area, its label is the height of the pyramid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Illustration of the plane clustering algorithm. Every positive point in the predicted soft mask is assigned to one of four different colors, which indicates the supporting plane the point belongs to. The dashed lines are the intersection of supporting planes and the bottom plane, which form the predicted text box together. The supporting planes are refined from left to right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1</head><label>1</label><figDesc>Plane Clustering input: point : location = (x, y), predicted score = z points = [point num = H * W, (x, y, z)] output: plane : Ax + By + Cz + D = 0, C = 1 planes = [plane num = 4, (A, B, D)] function PLANE CLUSTERING(points) P ← SELECTPOSITIVE(points) apex.(x, y) ← MEAN(P ).(x, y) apex.z ← 1 planes ← INITPLANES(apex) while iter &lt; max iter and REJECT(residuals) do G ← ∅ × plane num for p ∈ P do plane i ← NEARESTPLANE(p, planes) G[plane i] ← G[plane i] ∪ {p} end for planes, residuals ← RLS(G) end while return planes end function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Detection results of PMTD. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Distribution of predicted text boxes with different IoU. PMTD clearly predicts more accurate text boxes than baseline. provement of 1.6% compared with the baseline. And in Sec. 4.2, experiments on ICDAR 2013 and ICDAR 2015 show PMTD brings consistent gains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison with other results on ICDAR 2017 MLT.</figDesc><table><row><cell>Method</cell><cell cols="3">Precision Recall F-measure</cell></row><row><cell>FOTS [26]</cell><cell>80.95</cell><cell>57.51</cell><cell>67.25</cell></row><row><cell>FOTS  *  [26]</cell><cell>81.86</cell><cell>62.30</cell><cell>70.75</cell></row><row><cell>Lyu et al. [31]</cell><cell>83.80</cell><cell>55.60</cell><cell>66.80</cell></row><row><cell>Lyu et al.  *  [31]</cell><cell>74.30</cell><cell>70.60</cell><cell>72.40</cell></row><row><cell>PSENet [20]</cell><cell>77.01</cell><cell>68.40</cell><cell>72.45</cell></row><row><cell>Pixel-Anchor [21]</cell><cell>79.54</cell><cell>59.54</cell><cell>68.10</cell></row><row><cell>Pixel-Anchor  *  [21]</cell><cell>83.90</cell><cell>65.80</cell><cell>73.76</cell></row><row><cell>SPCNET [41]</cell><cell>66.90</cell><cell>73.40</cell><cell>70.00</cell></row><row><cell>SPCNET  *  [41]</cell><cell>68.60</cell><cell>80.60</cell><cell>74.10</cell></row><row><cell>Huang et al. [14]</cell><cell>80.00</cell><cell>69.80</cell><cell>74.30</cell></row><row><cell>Baseline</cell><cell>84.72</cell><cell>70.37</cell><cell>76.88</cell></row><row><cell>PMTD</cell><cell>85.15</cell><cell>72.77</cell><cell>78.48</cell></row><row><cell>PMTD  *</cell><cell>84.42</cell><cell>76.25</cell><cell>80.13</cell></row></table><note>* means multi scale testing.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison with other results on ICDAR 2015.</figDesc><table /><note>* means multi scale testing. For PMTD, we only report single scale testing result.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison with other results on ICDAR 2013. * means multi scale testing. For PMTD, we only report single scale testing result.</figDesc><table><row><cell>epochs using ICDAR 2015 training data. Learning rate</cell></row><row><cell>is set to 0.0008 and unchanged during training. For test-</cell></row><row><cell>ing, images' long side are resized to 1920. As shown in</cell></row><row><cell>Tab. 2, PMTD outperforms all other methods and achieves</cell></row><row><cell>1.19% higher F-measure than our baseline, which demon-</cell></row><row><cell>strates the proposed PMTD brings consistent gain on differ-</cell></row><row><cell>ent datasets.</cell></row><row><cell>ICDAR 2013: Similar to ICDAR 2015, we finetune 40</cell></row><row><cell>epochs on ICDAR 2017 MLT pre-trained model using IC-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Results of our models with different settings on ICDAR 2017 MLT dataset. PMTD clearly outperforms our baseline.DAR 2013 training data, with fixed 0.0008 learning rate. We resize images' long size to 960 during testing. As shown in Tab. 3, PMTD surpasses all previous methods once more and gains 1.67% improvement to the baseline on this dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Number of true positives and F-measure under different IoU threshold on ICDAR 2015. PMTD outperforms baseline significantly when IoU threshold is high.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Total-text: A comprehensive dataset for scene text detection and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Ch&amp;apos;ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fused text segmentation networks for multi-oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3604" to="3609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pixellink: Detecting scene text via instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Synthetic data for text localisation in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2315" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mask rcnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollá</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Single shot text detector with regional attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An end-to-end textspotter with explicit alignment and attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5020" to="5029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep direct regression for multi-oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="745" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robust regression using iteratively reweighted least-squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-theory and Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="813" to="827" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wordsup: Exploiting word annotations for character based text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust scene text detection with convolution neural network induced mser trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="497" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Mask r-cnn with pyramid attention network for scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.09058</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reading text in the wild with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep features for text spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="512" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">R2cnn: rotational region cnn for orientation robust scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09579</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Icdar 2015 competition on robust reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gomez-Bigorda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1156" to="1160" />
		</imprint>
		<respStmt>
			<orgName>IC-DAR</orgName>
		</respStmt>
	</monogr>
	<note>13th International Conference on</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Icdar 2013 robust reading competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Bigorda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Mestre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Mota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Almazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>De Las Heras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), 2013 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1484" to="1493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Shape robust text detection with progressive scale expansion network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02559</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Pixelanchor: A fast oriented scene text detector with combined networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.07432</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Textboxes++: A single-shot oriented scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on image processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3676" to="3690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Textboxes: A fast text detector with a single deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rotationsensitive regression for oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fots: Fast oriented text spotting with a unified network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning markov clustering networks for scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Goh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08365</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Textsnake: A flexible representation for detecting text of arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mask textspotter: An end-to-end trainable neural network for spotting text with arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="67" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-oriented scene text detection via corner localization and region segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented scene text detection via rotation proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Icdar2017 robust reading challenge on multi-lingual scene text detection and script identification-rrc-mlt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bizid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rigaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chazalon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1454" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deconvolution and checkerboard artifacts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Detecting oriented text in natural images by linking segments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Training regionbased object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Detecting text in natural image with connectionist text proposal network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Text localization and recognition in images and video. Handbook of Document Image Processing and Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="843" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Scene text detection with supervised pyramid context network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08605</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Inceptext: a new inception-text module with deformable psroi pooling for multi-oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.01167</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Text detection and recognition in imagery: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1480" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuliang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lianwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shuaitao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02170</idno>
		<title level="m">Detecting curve text in the wild: New dataset and new solution</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Feature enhancement network: A refined scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">East: an efficient and accurate scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Scene text detection and recognition: Recent advances and future trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Computer Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="36" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
