<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Graph-Convolutional Image Denoising</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Valsesia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giulia</forename><surname>Fracastoro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Magli</surname></persName>
						</author>
						<title level="a" type="main">Deep Graph-Convolutional Image Denoising</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph neural networks</term>
					<term>image denoising</term>
					<term>graph con- volution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Non-local self-similarity is well-known to be an effective prior for the image denoising problem. However, little work has been done to incorporate it in convolutional neural networks, which surpass non-local model-based methods despite only exploiting local information. In this paper, we propose a novel end-to-end trainable neural network architecture employing layers based on graph convolution operations, thereby creating neurons with non-local receptive fields. The graph convolution operation generalizes the classic convolution to arbitrary graphs. In this work, the graph is dynamically computed from similarities among the hidden features of the network, so that the powerful representation learning capabilities of the network are exploited to uncover self-similar patterns. We introduce a lightweight Edge-Conditioned Convolution which addresses vanishing gradient and over-parameterization issues of this particular graph convolution. Extensive experiments show state-of-the-art performance with improved qualitative and quantitative results on both synthetic Gaussian noise and real noise.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Denoising is a staple among image processing problems and its importance cannot be overstated. Despite decades of work and countless methods, it still remains an active research topic because its purpose goes far beyond generating visually pleasing pictures. Denoising is fundamental to enhance the performance of higher-level computer vision tasks such as classification, segmentation or object recognition, and is a building block in the solution to various problems <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>. The recent successes achieved by convolutional neural networks (CNNs) extended to this problem as well and have brought a new generation of learning-based methods that is redefining the state of the art. However, it is important to learn the lessons of past research on the topic and integrate them with the new deep learning techniques. In particular, classic denoising methods such as BM3D <ref type="bibr" target="#b4">[5]</ref> showed the importance of exploiting nonlocal self-similar patterns. However, the convolution operation underpinning all CNNs architectures <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref> is unable to capture such patterns because of the locality of the convolution kernels. Only very recently, some works started addressing the integration of non-local information into CNNs <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b13">[13]</ref>.</p><p>This paper presents a denoising neural network, called GCDN, where the convolution operation is generalized by means of graph convolution, which is used to create layers with hidden neurons having non-local receptive fields that successfully capture self-similar information. Graph convolution is a The authors are with Politecnico di Torino -Department of Electronics and Telecommunications, Italy. email: {name.surname}@polito.it. This research has been partially funded by the SmartData@PoliTO center for Big Data and Machine Learning technologies. We thank Nvidia for donating a Quadro P6000 GPU. generalization of the traditional convolution operation when the data are represented as sitting over the vertices of a graph. In this work, every pixel is a vertex and the edges in the graph are dynamically computed from the similarities in the feature space of the hidden layers of the network. This allows us to exploit the powerful representational features of neural networks to discover and use latent self-similarities. With respect to other CNNs integrating non-local information for the denoising task, the proposed approach has several advantages: i) it creates an adaptive receptive field for the pixels in the hidden layers by dynamically computing a nearest-neighbor graph from the latent features; ii) it creates dynamic non-local filters where feature vectors that may be spatially distant but close in a latent vector space are aggregated with weights that depend on the features themselves; iii) the aggregation weights are estimated by a fully-learned operation, implemented as a subnetwork, instead of a predefined parameterized operation, allowing more generality and adaptability. Starting from the Edge-Conditioned Convolution (ECC) definition of graph convolution, we propose several improvements to address stability, over-parameterization and vanishing gradient issues. Finally, we also propose a novel neural network architecture which draws from an analogy with an unrolled regularized optimization method.</p><p>A preliminary version of this work appeared in <ref type="bibr" target="#b14">[14]</ref>. There are several differences with the work in this paper. The architecture of the network is improved by drawing an analogy with proximal gradient descent methods, and it is significantly deeper. Moreover, we propose several solutions to address the ECC overparameterization and computational issues. Finally, we also present an in-depth analysis of the network behavior and greatly extended experimental results. This paper is structured as follows. Sec. II provides some background material on graph-convolutional neural networks and state-of-the-art denoising approaches. Sec. III describes the proposed method. Sec. IV analyzes the characteristics of the proposed method and experimentally compares it with stateof-the-art approaches. Finally, Sec. V draws some conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. Graph neural networks</head><p>Inspired by the overwhelming success of deep neural networks in computer vision, a significant research effort has recently been made in order to develop deep learning methods for data that naturally lie on irregular domains. One case is when the data domain can be structured as a graph and the data are defined as vectors on the nodes of this graph. Extending CNNs from signals with a regular structure, such as images and video, to graph-structured signals is not straightforward, since even simple operations such as shifts are undefined over graphs.</p><p>One of the major challenges in this field is defining a convolution-like operation for this kind of data. Convolution has a key role in classical CNNs, thanks to its properties of locality, stationarity, compositionality, which well match prior knowledge on many kinds of data and thus allow effective weight reuse. For this reason, defining an operation with similar characteristics for graph-structured data is of primary importance in order to obtain effective graph neural networks. The literature has identified two main classes of approaches to tackle this problem, namely spectral or spatial. In the former case <ref type="bibr" target="#b15">[15]</ref>- <ref type="bibr" target="#b17">[17]</ref>, the convolution is defined in the spectral domain through the graph Fourier transform <ref type="bibr" target="#b18">[18]</ref>. Fast polynomial approximations <ref type="bibr" target="#b16">[16]</ref> have been proposed in order to obtain an efficient implementation of this operation. Graphconvolutional neural networks (GCNN) with this convolution operator have been successfully applied in problems of semisupervised node classification and link prediction <ref type="bibr" target="#b17">[17]</ref>, <ref type="bibr" target="#b19">[19]</ref>. The main drawback of these methods is that the graph is supposed to be fixed and it is not clear how to handle the cases where the structure varies. The latter class of approaches overcomes this issue by defining the convolution operator in the spatial domain <ref type="bibr" target="#b20">[20]</ref>- <ref type="bibr" target="#b25">[25]</ref>. In this case, the convolution is performed by local aggregations, i.e. a weighted combination of the signal values over neighboring nodes. Since in this case the operation is defined at a neighborhood level, the convolution remains well-defined even when the graph structure varies. Many of the spatial approaches present in the literature <ref type="bibr" target="#b22">[22]</ref>- <ref type="bibr" target="#b24">[24]</ref> perform local aggregations with scalar weights. Instead, <ref type="bibr" target="#b20">[20]</ref> proposes to weight the contributions of the neighbors using edge-dependent matrices. This makes the convolution a more general function, increasing its descriptive power. For this reason, in this paper we employ the convolution operator proposed in <ref type="bibr" target="#b20">[20]</ref>. However, in order to obtain an efficient operation, we introduce several approximations that reduce its computation complexity, memory occupation, and mitigate vanishing gradient issues that arise when trying to build very deep architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Image denoising</head><p>The literature on image denoising is vast, as it is one of most classic problems in image processing. Focusing on the recent developments, we can broadly define two categories of methods: model-based approaches and learning-based approaches.</p><p>Model-based approaches traditionally focused on defining hand-crafted priors to carefully capture the salient features of natural images. Early works in this category include total variation minimization <ref type="bibr" target="#b26">[26]</ref>, and bilateral filtering <ref type="bibr" target="#b27">[27]</ref>. Nonlocal means <ref type="bibr" target="#b28">[28]</ref> introduced the idea of non-local averaging according to the similarity of local neighborhood. The popular BM3D <ref type="bibr" target="#b4">[5]</ref> expanded on the idea by collaborative filtering of the matched patches. WNNM <ref type="bibr" target="#b29">[29]</ref> used nuclear norm minimization to enforce a low-rank prior. Finally, some works recently introduced graph-based regularizers <ref type="bibr" target="#b30">[30]</ref> to enforce a measure of smoothness of the signal across the edges of a graph of patch or pixel similiarities. Many of the most successful model-based approaches are non-local, i.e., they exploit the concept of self-similarity among structures in the image beyond the local neighborhood.</p><p>Learning-based approaches use training data to learn a model for natural images. The popular K-SVD algorithm <ref type="bibr" target="#b31">[31]</ref> learns a dictionary in which natural patches have a sparse representation, and therefore casts image denoising as a sparse coding problem on this learned dictionary. The TNRD method <ref type="bibr" target="#b32">[32]</ref> uses a nonlinear reaction diffusion model with trainable filters. An early work with neural networks <ref type="bibr" target="#b33">[33]</ref> used a multilayer perceptron discriminatively trained on synthetic Gaussian noise and showed significant improvements over model-based methods. More recently, CNNs have achieved remarkable performance. Zhang et al. <ref type="bibr" target="#b5">[6]</ref> showed that the residual structure and the use of batch normalization <ref type="bibr" target="#b34">[34]</ref> in their DnCNN greatly helps the denoising task. Following the DnCNN, many other architectures have been proposed, such as RED <ref type="bibr" target="#b6">[7]</ref>, MemNet <ref type="bibr" target="#b7">[8]</ref> and a CNN working on wavelet coefficients <ref type="bibr" target="#b8">[9]</ref>. However, those CNN-based methods are limited by the local nature of the convolution operation, which is unable to increase the receptive field of a neuronpixel to model non-local image features. This means that CNNs are unable to exploit the self-similar patterns that were proven to be highly successful in model-based methods. Very recently, a few works started addressing this issue by trying to incorporate non-local information in a CNN. NN3D <ref type="bibr" target="#b9">[10]</ref> uses a global post-processing stage based on a non-local filter after the output of a denoising CNN. This stage performs block matching and filtering over the whole image denoised by the CNN. This is clearly suboptimal as the non-local information does not contribute to the training of the CNN. UNLNet <ref type="bibr" target="#b10">[11]</ref> introduces a trainable non-local layer which collaboratively filters image blocks. However, performance is limited by the selection of matching blocks from the noisy input image instead of the feature space, and ultimately UNLNet does not improve over the performance of the simpler DnCNN. N 3 Net <ref type="bibr" target="#b11">[12]</ref> introduces a continuous nearest-neighbor relaxation to create a non-local layer. Finally, NLRN <ref type="bibr" target="#b13">[13]</ref> proposes a nonlocal module that uses the distances among hidden feature vectors of a search window around the pixel of interest to aggregate such vectors and return the output features of the pixel. However, there are significant differences with respect to the work in this paper. First, they use all the pixels in the search window instead of only a number of nearest neighbors, which means that their receptive field cannot dynamically adapt to the content of the image. Then, while in both works the feature aggregation weights are dynamically computed from the features themselves, NLRN uses an explicitly-parameterized function with learnable parameters, in contrast to this work where the function is fully learned as a dedicated sub-network. These choices increase the adaptivity of the proposed non-local operations, which result in better performance around edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED DENOISER A. Overview</head><p>An overview of the proposed graph-convolutional denoiser network (GCDN) can be seen in <ref type="figure" target="#fig_0">Fig. 1</ref>. The structure will be explained more in detail in Sec. III-D where an analogy is drawn between unrolled proximal gradient descent with a graph total variation regularizer and the proposed network architecture. At a first glance, the network has a global inputoutput residual connection whereby the network learns to estimate the noise rather than successively clean the image. This has been shown <ref type="bibr" target="#b5">[6]</ref> to improve training convergence for the denoising problem.</p><p>The main feature of the proposed network is the use of graph-convolutional layers where the graphs are dynamically computed from the feature space. The graph-convolutional layer, described in Sec. III-B, creates a non-local receptive field for each pixel-neuron, so that pixels that are spatially distant but similar in the feature space created by the network can be merged.</p><p>An important block of the proposed network is the preprocessing stage at the input. It can be noticed that the first layers of the network are classic 2D convolutions rather than graph convolutions. This is done to create an embedding over a receptive field larger than a single pixel and stabilize the graph construction operation, which would otherwise be affected by the input noise. The preprocessing stage has three parallel branches that operate on multiple scales, in a fashion similar to the architectures in <ref type="bibr" target="#b35">[35]</ref> and <ref type="bibr" target="#b36">[36]</ref>. The multiscale features are extracted by a sequence of three convolutional layers with filters of size 3 × 3, 5 × 5, and 7 × 7, depending on the branch. After a final graph-convolutional layer, the features are concatenated.</p><p>The remaining network layers are grouped into an HPF block and multiple LPF blocks, named after the analogy with highpass and lowpass graph filters described in Sec. III-D. These blocks have an initial 3×3 convolutional layer followed by three graph-convolutional layers sharing the same graph constructed from the output of the convolutional layer. All layers are interleaved by Batch Normalization operations <ref type="bibr" target="#b34">[34]</ref> and leaky ReLU nonlinearities. Notice that the LPF blocks have themselves a residual connection to help backpropagation, as in ResNet architectures <ref type="bibr" target="#b37">[37]</ref>. The final layer is a graphconvolutional layer mapping from feature space to the image space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph-convolutional layer</head><p>The operation performed by the graph-convolutional layer is summarized in <ref type="figure" target="#fig_1">Fig. 2</ref>. The two inputs to the graphconvolutional layer are the feature vectors H l ∈ R F l ×N associated to the N image pixels at layer l and the adjacency matrix of a graph connecting image pixels. In this work, the graph is constructed as a K-nearest neighbor graph in the feature space. For each pixel, the Euclidean distances between its feature vector and the feature vectors of pixels inside a search window are computed and an edge is drawn between the pixel and the K pixels with smallest distance. Using this method, we obtain a K-regular graph G l (V, E l ), where V is the set of vertices with |V| = N and E l ⊆ V × V is the set of edges. We also assume that the edges of G l are labeled, i.e. there exists a function L : E l → R F l that assigns a label to each edge. In this work, we define the edge labeling function as the difference between the two feature vectors, i.e. L(i, j) = H l j − H l i = d l,j→i . A classic 3 × 3 local convolution processes the local neighborhood to provide its estimate of the output feature vector for the current pixel, while the feature vectors of the non-local pixels connected by the graph are aggregated by means of the edge-conditioned convolution (ECC) <ref type="bibr" target="#b20">[20]</ref>. Notice that the 8 local neighbors of the pixel are excluded from graph construction as they are already used by the local convolution. The non-local aggregation is computed as:</p><formula xml:id="formula_0">H l+1,NL i = j∈S l i γ l,j→i F l w l d l,j→i H l j |S l i | = j∈S l i γ l,j→i Θ l,j→i H l j |S l i | ,<label>(1)</label></formula><p>where F l w l : R F l → R F l+1 ×F l is a fully-connected network that takes as input the edge labels and outputs the corresponding weight matrix Θ l,j→i = F l w l (L(i, j)) ∈ R F l+1 ×F l , w l are the weights parameterizing network F l , and S l i is the set of neighbors of node i in the graph G l . The scalar γ j→i is an edge-attention term computed as:</p><formula xml:id="formula_1">γ l,j→i = exp − d l,j→i 2 2 /δ (2)</formula><p>where δ is a cross-validated hyper-parameter. This term is reminiscent of the edge attention mechanism from the graph neural network literature <ref type="bibr" target="#b38">[38]</ref> and it serves the purpose of stabilizing training by underweighting the edges that connect nodes with distant feature vectors. Note that this term could, in principle, be learned by the F network but we found that decoupling it and making it explicitly dependent on feature distances in an exponential way, accelerated and stabilized training. Also notice that in Sec. IV we show that this term alone, i.e. without weight matrices Θ, is not powerful enough to reach good performance. Moreover, it is worth mentioning that the edge weights Θ and the edge-attention term γ depend only on the edge labels. This means that two pairs of nodes with the same edge labels will have the same weights, resulting in a behaviour similar to weight sharing in classical CNNs. Finally, we combine the feature vector estimated by the non-local aggregation with the one produced by the local convolution to provide the output features as follows</p><formula xml:id="formula_2">H l+1 i = H l+1,NL i + H l+1,L i 2 + b l , where H l+1,L i</formula><p>is the output of the 3 × 3 local convolution for the node i and b l ∈ R F l is the bias. The advantages of the ECC with respect to other definitions of graph convolution are trifold: i) the edge weights depend on the edge label, ii) it allows to compute an affine transformation along every edge, and iii) the edge weight function is highly general since it does not have a predefined structure. By making the edge weights depend on the input features, the ECC implements an adaptive filter which can be more complex than the non-adaptive local filters. Moreover, the second advantage is due to the fact that Θ l,j→i is an edge-dependent matrix, making the convolution operation more general than other nonlocal aggregation methods using scalar edge weights. Among such methods we can find GCN <ref type="bibr" target="#b17">[17]</ref>, GIN <ref type="bibr" target="#b22">[22]</ref>, MoNet <ref type="bibr" target="#b23">[23]</ref>, and FeastNet <ref type="bibr" target="#b24">[24]</ref>. Finally, the F function is a general function which can be learned to be the optimal one for the denoising task by the function approximation capability of the subnetwork implementing it. This is in contrast with other methods where the function predicting the edge weights is fixed with some learnable parameters. For example, FeastNet <ref type="bibr" target="#b24">[24]</ref> employs scalar edge weights computed using the following function</p><formula xml:id="formula_3">f (H l i , H l j ) ∝ exp u T H l i + v T H l j + c ,</formula><p>where u, v ∈ R F l and c ∈ R are learnable parameters. Instead, MoNet <ref type="bibr" target="#b23">[23]</ref> employs a Gaussian kernel as follows</p><formula xml:id="formula_4">f (H l i , H l j ) = exp − 1 2 (d l,j→i − µ) T Σ −1 (d l,j→i − µ) ,</formula><p>where Σ ∈ R F l ×F l and µ ∈ R F l are learnable parameters. Also NLRN <ref type="bibr" target="#b13">[13]</ref> uses a Gaussian kernel to perform nonlocal aggregations. We can consider this operation as a graph convolution where each pixel is connected to all the other pixels in its search window and the edge weights are defined as follows</p><formula xml:id="formula_5">f (H l i , H l j ) = exp H lT i W T θ W φ H l j j∈Si exp H lT i W T θ W φ H l j W g , where W θ , W φ ∈ R t×F l and W g ∈ R F l+1 ×F l are learnable parameters.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Lightweight Edge-Conditioned Convolution</head><p>As seen in the previous section, the function F has a key role in the ECC because it defines the weights for the neighborhood aggregation. In the original definition of ECC <ref type="bibr" target="#b20">[20]</ref>, the function F is implemented as a two-layer fully connected network. This definition raises some relevant issues. In the following, we will describe in detail these issues and present two possible solutions.</p><p>1) Circulant approximation of dense layer: The first issue is related to the risk of over-parameterization. The dimension of the input of the F network is F l , while the dimension of its output is F l+1 × F l . This means that the number of weights of the network depends cubically on the number of features. Therefore, the number of parameters quickly becomes excessively large, resulting in vanishing gradients or overfitting.</p><p>To address the over-parameterization problem we propose to use a partially-structured matrix for the last layer, instead of an unstructured one. We impose that this matrix is composed of multiple stacked partial circulant matrices, i.e., matrices where only a few shifted versions of the first row are used instead of all the possible ones of the full square matrix. <ref type="figure" target="#fig_2">Fig. 3</ref> shows the structure of the approximated matrix. Using this approximation, the only free parameters are in the first row of each partial circulant matrix. If only m shifts per partial circulant matrix are allowed, we reduce the number of parameters by a factor m. Thus, if the unstructured dense matrix has F l F l+1 × F l parameters, with the proposed approximation the number of parameters drops to F l F l+1 m × F l . Similar approaches to approximate fully connected layers have already been studied in the literature <ref type="bibr" target="#b39">[39]</ref>, <ref type="bibr" target="#b40">[40]</ref>. In particular, <ref type="bibr" target="#b39">[39]</ref> shows that imposing a partial circulant structure does not significantly impact the final performance in a classification problem. Indeed, there are connections with results stating that random partial circulant matrices implement stable embeddings almost as well as fully random matrices <ref type="bibr" target="#b41">[41]</ref>- <ref type="bibr" target="#b44">[43]</ref>. 2) Low-rank node aggregation: The second issue related to the F network regards memory occupation and computations. In order to perform the ECC operation, we have to compute a weight matrix Θ l,j→i for each edge j of every neighborhood N i of every image in the batch. If we consider a K-regular graph and a batch of B images with N pixels each, the memory occupation needed to store all the matrices Θ l,j→i as single-precision floating point tensors is equal to B × N × K × F l+1 × F l × 4 bytes and this quantity can easily become unmanageable. To give an idea of the required amount of memory, let us consider an example with B = 16, N = 1024, K = 8, F l = F l+1 = 66, then the memory required to store all the matrices Θ l,j→i for only one graphconvolutional layer is around 2 GB.</p><p>In order to solve this issue, we propose to impose a lowrank approximation for Θ l,j→i . Let us consider the singular value decomposition of a matrix</p><formula xml:id="formula_6">A = ΦΛΨ T = s λ s φ s ψ T s ,</formula><p>where φ s and ψ s are the left and right singular vectors and λ s the singular values. We can obtain a low-rank approximation of rank r by keeping only the r largest singular values and setting the others to zero. Therefore, the approximation is reduced to a sum of r outer products. Inspired by this fact, we define Θ l,j→i as follows</p><formula xml:id="formula_7">Θ l,j→i = r s=1 κ j→i s θ j→i,L s θ j→i,R T s ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_8">θ j→i,L s ∈ R F l , θ j→i,R s ∈ R F l+1 , κ j→i s ∈ R and 1 ≤ r ≤ F l .</formula><p>Notice that the approximation in (3) ensures that the rank is at most r rather than exactly enforcing a rank-r structure, because we do not impose orthogonality between θ j→i,L s and θ j→i,R s , even though random initialization makes them quasi-orthogonal. Using this approximation, we can redefine the F network in such a way that it outputs θ j→i,L s , θ j→i,R s , κ j→i s for s = 1, 2, . . . , r. In particular, we redefine the second layer of the F network: instead of having a single fully connected layer that outputs the entire matrix Θ l,j→i , we have three parallel fully connected layers that separately output θ j→i,L s , θ j→i,R s and κ j→i s , as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. The advantage of this approximation is that we only need to store θ j→i,L s , θ j→i,R s and κ j→i s instead of the entire matrix Θ l,j→i , drastically reducing the memory occupation to B × N × K × r(2F l + 1) × 4 bytes. If we consider the example presented above and set r = 10, the memory requirement drops from 2 GB to 700 MB. Another advantage of this approximation is that it also leads to a significant reduction of the computation burden, because we never have to actually compute all the matrices Θ l,j→i . In fact, the neighborhood aggregation can be reduced as follows</p><formula xml:id="formula_9">H l+1,NL i = j∈S l i γ l,j→i Θ l,j→i H l j |S l i | = j∈S l i γ l,j→i r s=1 κ j→i s θ j→i,L s θ j→i,R T s H l j |S l i | ,<label>(4)</label></formula><p>where the computational cost of the full operation on the first line is O(F l F l+1 ), instead the cost of the decoupled operation on the second line is O(r(F l + F l+1 )). Finally, this approximation also helps to reduce the number of parameters of the last layer of the F network since the output has size</p><formula xml:id="formula_10">r(F l + F l+1 + 1) instead of F l+1 F l .</formula><p>When we employ the new structure of the F network, we need to pay special attention to the weight initialization. In particular, we have to carefully define the variance of the random weight initialization of the three parallel layers to avoid scaling problems. We define W 0 as the weight matrix of the first layer of the F network, and W L , W R and W κ as the weight matrices of the three parallel fully connected layers. Let us suppose that d j→i t has been normalized to be approximately a standard Gaussian, i.e., d j→i t ∼ N (0, 1) for t = 1, . . . , F l , and that W 0 has been initialized using Glorot initialization <ref type="bibr" target="#b45">[44]</ref>, i.e., W 0 uv ∼ N 0, 1 F l with u, v = 1, . . . , F l . Let us also assume that W L uv ∼ N (0, σ 2 L ), W R uv ∼ N (0, σ 2 R ), and W κ u ∼ N (0, σ 2 κ ). Then, we obtain θ j→i,L s,u</p><formula xml:id="formula_11">∼ N (0, F l σ 2 L ), θ j→i,R s,u ∼ N (0, F l σ 2 R ), κ j→i s ∼ N (0, F l σ 2 κ )</formula><p>, where s = 1, . . . , r. Finally, considering the aggregation formula in Eq. (4) leads to the following result:</p><formula xml:id="formula_12">H l+1,NL i,u ∼ N 0, 1 2 rF l 4 σ 2 L σ 2 R σ 2 κ ,<label>(5)</label></formula><p>with u = 1, . . . , F l+1 . In Eq. (5), we can observe that the variance of H l+1,NL i,u depends on the fourth power of the number of features. This term can easily become extremely large, therefore it is important to set σ 2 L , σ 2 R and σ 2 κ in such a way that they can balance it. In this work, we set σ 2 L = σ 2 R = 1 F l 2 and σ 2 κ = 2 r . This allows us to obtain H l+1,NL i,u ∼ N (0, 1) with u = 1, . . . , F l+1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Analogy with unrolled graph smoothness optimization</head><p>The neural network architecture presented in Sec. III-A can be seen as a generalization of few iterations of an unrolled proximal gradient descent optimization method, which is widely used to solve linear inverse problems in the form of</p><formula xml:id="formula_13">y = Ax + n<label>(6)</label></formula><p>being x the clean image, A a forward model (e.g., a degradation such as blurring, downsampling, compressed sensing, etc.) and n a noise term. A well-known technique to recover x from y is to cast the problem as a least-squares minimization problem with a regularization term that models some prior knowledge about the image. One such regularizer is graph smoothness. Considering a graph with Laplacian matrix L where edges connect pixels that are deemed correlated according to some criterion, the graph smoothness x T Lx is the graph equivalent of the total variation measure, indicating how much x varies across the edges of the graph. Natural images where the graph connects the local neighborhood typically have lowpass behavior, resulting in a low graph smoothness value. Reconstruction is therefore cast as:</p><formula xml:id="formula_14">x = argmin x 1 2 y − Ax 2 2 + β 2 x T Lx (7)</formula><p>The functional in Eq. <ref type="formula">(7)</ref> is in the form of a sum of two terms (f (x) + g(x)) and can be minimized by means of proximal gradient descent <ref type="bibr" target="#b46">[45]</ref> which alternates a gradient descent step over f and a proximal mapping over g:</p><formula xml:id="formula_15">x (t+1) = prox g x (t) − α∇ ν f = prox g (I − αA T A)x (t) + αA T y prox g (µ) = argmin z z − µ 2 2 + β 2 z T Lz .</formula><p>Solving for the proximal mapping operator results in the following update equation:</p><formula xml:id="formula_16">x (t+1) = (I + βL) −1 (I − αA T A)x (t) + αA T y . (8)</formula><p>In order to match the framework of residual networks, let us define the least-squares solution x n = A + y = A T A −1 A T y and perform a change of variable whereby the optimization estimates the residual of the least squares solution, i.e., ν (t) = x n − x (t) . Hence, we can rewrite Eq. (8) as:</p><formula xml:id="formula_17">x n − ν (t+1) = (I + βL) −1 I − αA T A x n − ν (t) + αA T y .</formula><p>Finally, the following update equation can be derived:</p><formula xml:id="formula_18">ν (t+1) = (I + βL) −1 I − αA T A ν (t) + βLx n . (9)</formula><p>This update can be visualized as in <ref type="figure" target="#fig_4">Fig. 5a</ref> and is composed of two major operations involving the signal prior: 1) Lx n : the graph Laplacian can be seen as a graph highpass filter applied to x n ; 2) (I + βL) −1 : this term can be seen as a graph lowpass filter. In order to see this, let us use the matrix inversion lemma as (I + βL)</p><formula xml:id="formula_19">−1 = I + βUΛU H −1 = I − U β −1 Λ −1 + I −1 U H = U I − β −1 Λ −1 + I −1 U H , where U is the graph Fourier transform. The term I − β −1 Λ −1 + I −1 is a</formula><p>diagonal matrix whose entries are equal to 1 βλi+1 where λ i are the eigenvalues of the graph Laplacian, and the lowpass behavior is due to decreasing value of such entries for increasing λ. For the denoising problem, we can set A = I and obtain the update shown in <ref type="figure" target="#fig_4">Fig.5b</ref>. The network architecture proposed in Sec. III-A draws from this derivation by unrolling a finite number of Eq. (9) iterations and generalizing the lowpass and highpass filters with learned graph filters interleaved by nonlinearities. In Sec. IV we experimentally show that the learned filters actually show an approximate highpass and lowpass behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training details</head><p>The training protocol follows the one used in <ref type="bibr" target="#b5">[6]</ref>. The network is trained with patches of size 42 × 42 randomly extracted from 400 images from the train and test partitions of the Berkeley Segmentation Dataset (BSD) <ref type="bibr" target="#b47">[46]</ref>, withholding the 68 images in the validation set for testing purposes (BSD68 dataset). The loss function is the mean squared error (MSE) between the denoised patch output by the network and the ground truth. Each model is trained for approximately 800000 iterations with a batch size of 8. The Adam optimizer <ref type="bibr" target="#b48">[47]</ref> has been used with an exponentially decaying learning rate between 10 −4 and 10 −5 . The behavior of the graph-convolutional layer is slightly different between training and testing for efficiency reasons. During training all pairwise distances are computed among the feature vectors corresponding to the pixels in the patch. On the other hand, testing is "fully convolutional", as every pixel has a search window centered around it and neighbors are identified as the closest pixels in such search window. The search window size is 43 × 43, roughly comparable to the patch size used in training. This procedure is slightly suboptimal as some pixels might suffer from border effects during training (their search windows are not centered around them) but it is advantageous in terms of speed and memory requirements. Reflection padding is used for all 2D convolutions to avoid border effects. The δ parameter in the edge attention term in Eq. (2) is set to a value equal to 10. The number of features used in all convolutional layers is 132, except for the three parallel branches of the preprocessing stage which have 44 features. The number of circulant rows in the circulant approximation of dense layers in the F network is m = 3. The low-rank approximation uses r = 11 terms. During training, we noticed that the proposed lightweight ECC presented in Sec. III-C is extremely useful. In fact, without it, the network suffered from vanishing gradient problems even with a significantly lower number of layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Feature analysis</head><p>In this section we study the properties of the features in the hidden layers of the network.</p><p>1) Adaptive receptive field: We first analyze the characteristics of the receptive field of a single pixel. Since the proposed network employs graph-convolutional layers, the shape of the receptive field is not fixed as in classical CNNs, but it depends on the structure of the graph. In <ref type="figure" target="#fig_5">Fig. 6</ref> we show two examples of the receptive field of a single pixel for the graphconvolutional layers in an LPF block with respect to the input of the block. Instead, in <ref type="figure">Fig. 7</ref> we show the receptive field of a single pixel for the layers in the HPF and in the first LPF blocks with respect to the output of the preprocessing block. We can clearly see that the receptive field is adapted to the characteristics of the image: if we consider a pixel in a uniform area, its receptive field will mostly contain pixels that belong to similar regions; instead if we consider a pixel on an edge, its receptive field will be mainly composed of other edge pixels. This is beneficial to the denoising task as it allows to exploit self-similarity and it descends from the use of a nearest neighbor graph, connecting each pixel to other pixels with similar features. Notice that differently from algorithms performing block matching in the pixel space, we compute distances between feature vectors which can capture more complex image characteristics. This can be seen in <ref type="figure" target="#fig_6">Fig. 8</ref> where we compute the Euclidean distances between the feature vector of the central pixel and the feature vectors of the other pixels in the search window. We notice that the distances reflect the type of edge that includes the central pixel, e.g., a pixel sitting on a horizontal edge will detect as closest other pixels sitting on horizontal edges. This is due to the visual features learned by the network and would not happen in pixel-space matching. Thanks to the adaptability of the receptive field, graph convolution can be interpreted as a generalization of the block matching operation performed in other non-local denoising methods, such as BM3D <ref type="bibr" target="#b4">[5]</ref>.</p><p>2) Filter analysis: We also study the behavior of the LPF and HPF operators. In particular, we are interested in validating the analogy made in Sec. III-D. We compute the discrete Fourier transform (DFT) of the feature maps at the output of these operators. As an example, <ref type="figure" target="#fig_7">Fig. 9</ref> shows the logmagnitude of the coefficients of three feature maps at the output of the HPF block and of the first LPF block. The energy of the DFT coefficients of the LPF feature maps is concentrated in the low frequencies, thus showing a lowpass behavior. Instead, the coefficients of the HPF feature maps show a typical highpass behavior, having the energy concentrated along few directions. This substantiates our claim that the learned convolutional layers actually approximate nonlinear highpass and lowpass operators. 3) Edge prediction: Lastly, we measure how much the true graph constructed by pixel or patch similarities on the noiseless image is successfully predicted by the graph constructed from the feature vectors in the hidden layers. In order to construct the true graph of the image, we first compute the average pixel value of a 5×5 window centered at the considered pixel, for every pixel in the image, and then we use the obtained values to compute a nearest neighbor graph with Euclidean distances. We then compare the true graph with the graph computed in the hidden layers of the network. <ref type="figure" target="#fig_0">Fig. 10</ref> shows the percentage of edges correctly identified as function of the number of neighbors considered for the true graph. We can notice that the accuracy of the prediction decreases in layers closer to the output. This is due to the fact that we use a residual network that estimates the noise instead of approximating the clean image. In fact, the network learns to successively remove the latent correlations in the feature space, and as a consequence, the graph becomes more random in the later layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation studies</head><p>We study the impact of various design parameters on denoising performance. First, <ref type="table" target="#tab_0">Table I</ref> shows the PSNR on the Set12 testing set as function of the number of neighbors used by the graph convolution operation for several values of the noise standard deviation σ. Each model has been independently trained for the specified number of neighbors. It can be noticed that increasing the number of neighbors improves the denoising performance up to a saturation point, and then the performance slightly decreases. This shows that there an optimal neighborhood size and that it is important to employ only a small number of neighbors, in order to select only pixels with similar characteristics. This is in contrast with the NLRN method which uses all the pixels in the search window.</p><p>Then, we study the relative impact on performance of the edge aggregation matrices Θ in Eq. (1) with respect to using <ref type="bibr">Figure 7</ref>. Receptive field (green) of a single pixel (red) for the layers in the HPF and LPF 1 blocks in the same order as a forward pass, with respect to the output of the preprocessing block.  only the edge attention scalar γ. <ref type="table" target="#tab_0">Table II</ref> reports the PSNR achieved on Set12 by the proposed method with the non-local aggregation performed as in Eq. (1) and a variant where the aggregation is computed as:</p><formula xml:id="formula_20">H l+1,NL i = j∈S l i γ j→i H l j .</formula><p>Both methods use a non-local graph with 8 nearest neighbors. We can notice that the edge attention term alone achieves a worse PSNR with respect to GCDN by approximately 0.2 dB, even though it improves over a model without non-local neighbors (see <ref type="table" target="#tab_0">Table I</ref> for the corresponding 0-NN value). This shows the advantage of using a trainable affine transformation, such as Θ in Eq. (1), instead of a scalar weight function with a predefined structure.  Finally, we remark that we do not compare with respect to the full ECC without the approximations introduced in Sec. III-C because it suffers from vanishing gradient problems, rendering training unstable even for a much smaller number of layers, and it would be computationally prohibitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison with state of the art</head><p>In this section we compare the proposed network with stateof-the-art models for the Gaussian denoising task of grayscale images. We train an independent model for each noise standard deviation, which is assumed to be known a priori for all methods. We fix the number of neighbors for the proposed method to 16. The reference methods can be classified into model-based algorithms such as BM3D <ref type="bibr" target="#b4">[5]</ref>, WNNM <ref type="bibr" target="#b29">[29]</ref>, TNRD <ref type="bibr" target="#b32">[32]</ref> and recent deep-learning methods such as DnCNN  It can be seen that the proposed method achieves state-of-the art performance and works especially well at low to medium levels of noise. This can be explained by a higher difficulty in constructing a meaningful graph from the noisy image at higher noise levels. We also notice that the proposed method achieves strong results on the Urban dataset. This dataset contains higher resolution images with respect to the other two and is mainly composed of photos of buildings and other regular structures where exploiting self-similarity is very important. In addition, it is also worth mentioning that the proposed method provides a better visual quality. In many cases, the proposed method has a higher SSIM score, even if NRLN has better performance in terms of PSNR. This can also be noticed in <ref type="figure" target="#fig_0">Fig. 11</ref>, which shows a visual comparison on an image from the Urban100 dataset. In general, the images produced by the proposed algorithm present sharper edges and smoother content in uniform areas. We can notice that many areas in the photos from Urban100 have approximately piecewise smooth characteristics. It is well known that image processing algorithms based on graphs are well suited for piecewise smooth content (see, e.g., <ref type="bibr" target="#b49">[48]</ref>, <ref type="bibr" target="#b50">[49]</ref> in the context of compression and <ref type="bibr" target="#b30">[30]</ref> for denoising). To further show this point, we study the performance of the proposed method for denoising of depth maps, e.g., generated by time-of-flight cameras. The OGLR algorithm <ref type="bibr" target="#b30">[30]</ref> based on a graph smoothness regularizer achieved state-of-the-art results among model-based algorithms for this specific task where it is essential to preserve edge sharpness while simultaneously smoothing the flat areas. <ref type="table" target="#tab_0">Table IV</ref> reports the PSNR and SSIM results achieved on a standard set of depth maps 1 . It can be seen that the proposed method outperforms both NLRN and OGLR, even at high levels of noise. Also, we can notice that OGLR displays competitive performance at low noise levels, but its visual quality significantly degrades when in presence of stronger noise. <ref type="figure" target="#fig_0">Fig. 12</ref> shows a visual comparison where it can be seen that GCDN produces sharper edges while also providing a very smooth background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Real image denoising</head><p>Real image noise is generally more challenging than synthetic Gaussian noise. There are multiple contributions such as quantization noise, shot noise, fixed-pattern noise <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b51">[50]</ref>, dark current, etc. that make it overall signal-dependent. It has been observed <ref type="bibr" target="#b52">[51]</ref>, <ref type="bibr" target="#b53">[52]</ref> that deep learning methods trained on synthetic Gaussian noise perform poorly in presence of real noise. However, suitable retraining with real data generally improves their performance. In this section, we study the behavior of the proposed network in a blind denoising setting with real noisy images acquired by smartphones. We retrain the proposed method, NLRN and DnCNN on the SIDD dataset <ref type="bibr" target="#b53">[52]</ref> composed of 30000 high-resolution images acquired by smartphone cameras at varying illumination and ISO levels. The authors provide clean and carefully registered ground truths for all the available scenes, so that it is possible to perform a supervised training. We create training and testing subsets from the sRGB images in the SIDD dataset by selecting a range of noise levels. Our training set is composed of 3500 crops of size 512 × 512 whose RMSE with respect to the ground truth is below 15. The testing set is composed of 25 random crops of size 512 × 512 with noise in the same range as the training set. <ref type="table" target="#tab_3">Table V</ref> reports the results for CBM3D <ref type="bibr" target="#b54">[53]</ref>, DnCNN, NLRN and the proposed GCDN. Notice that CBM3D is not a blind method, so we provide an estimate of the noise standard deviation, as computed by a noise   estimation algorithm <ref type="bibr" target="#b55">[54]</ref>. We can notice that the proposed method achieves better results and this is confirmed by the visual comparison in <ref type="figure" target="#fig_0">Fig. 13</ref>.</p><p>V. CONCLUSIONS In this paper, we presented a graph-convolutional neural network targeted for image denoising. The proposed graphconvolutional layer allows to exploit both local and nonlocal similarities, resulting in an adaptive receptive field. We showed that the proposed architecture can outperform stateof-the-art denoising methods, achieving very strong results on piecewise smooth images. Finally, we have also considered a real image denoising setting, showing that the proposed method can provide a significant performance gain. Future work will focus on extending the proposed architecture to other inverse problems, such as super-resolution <ref type="bibr" target="#b56">[55]</ref>, <ref type="bibr" target="#b57">[56]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>GCDN architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>GCONVFigure 2 .</head><label>2</label><figDesc>Graph-convolutional layer. The operation has a receptive field with a local component (3 × 3 2D convolution) and a non-local component (pixels selected as nearest neighbors in the feature space).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Circulant approximation of a fully-connected layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>F network. FC 0 is a fully-connected layer followed by a leaky ReLU non-linearity. The FC R , FC L , FCκ do not have any output nonlinearities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Single iteration. LPF is graph lowpass filter, HPF is a graph highpass filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Receptive field (green) of a single pixel (red) for the three graphconvolutional layers in the LPF 1 block with respect to the input of the first graph-convolutional layer in the block. Top row: gray pixel on an edge. Bottom row: white pixel in a uniform area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Euclidean distances between feature vectors of the central pixel and all the pixels in the search window (input of first graph-convolutional layer of LPF 1 ). Left to right: pixel on a horizontal edge, pixel on a vertical edge, pixel on a diagonal edge. Blue represents lower distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Log-magnitude of discrete Fourier transform of three feature maps at the output of the LPF 1 block (top) and HPF block (bottom). Blue is lower magnitude.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Accuracy of edge prediction from hidden layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 .</head><label>11</label><figDesc>Extract from Urban100 scene 13, σ = 25. Left to right: ground truth, noisy (20.16 dB), BM3D (30.40 dB), DnCNN (30.71 dB), NLRN (31.41 dB), GCDN (31.53 dB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 .</head><label>12</label><figDesc>aloe depthmap denoising, σ = 50. Left to right: ground truth, noisy (14.16 dB), OGLR (32.24 dB), NLRN (33.23 dB), GCDN (33.37 dB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table I</head><label>I</label><figDesc></figDesc><table><row><cell>.</cell><cell cols="6">PSNR (DB) V. NON-LOCAL NEIGHBORHOOD SIZE (SET12)</cell></row><row><cell>σ</cell><cell>0-NN</cell><cell>4-NN</cell><cell>8-NN</cell><cell>12-NN</cell><cell>16-NN</cell><cell>20-NN</cell></row><row><cell>15</cell><cell>32.91</cell><cell>33.09</cell><cell>33.11</cell><cell>33.13</cell><cell>33.14</cell><cell>33.13</cell></row><row><cell>25</cell><cell>30.50</cell><cell>30.70</cell><cell>30.74</cell><cell>30.75</cell><cell>30.78</cell><cell>30.78</cell></row><row><cell>50</cell><cell>27.28</cell><cell>27.52</cell><cell>27.58</cell><cell>27.58</cell><cell>27.60</cell><cell>27.59</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table II .</head><label>II</label><figDesc>EDGE ATTENTION V. ECC + EDGE ATTENTION (8-NN). PSNR (DB).</figDesc><table><row><cell>σ</cell><cell>Edge attention only</cell><cell>Proposed</cell></row><row><cell>25</cell><cell>30.53</cell><cell>30.74</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table III .Table IV .</head><label>IIIIV</label><figDesc>NATURAL IMAGE DENOISING RESULTS. METRICS ARE PNSR (DB) AND SSIM. DEPTH MAP DENOISING RESULTS. METRICS ARE PNSR (DB) AND SSIM. 0.9873 40.66 / 0.9886 41.64 / 0.9917 39.29 / 0.9832 40.70 / 0.9830 41.97 / 0.9842 42.07 / 0.9877 42.62 / 0.9915 41.21 / 0.9872 NLRN 40.50 / 0.9844 40.48 / 0.9858 41.76 / 0.9899 39.50 / 0.9814 40.69 / 0.9800 41.96 / 0.9814 42.01 / 0.9848 42.44 / 0.9880 41.17 / 0.9845 OGLR 40.82 / 0.9801 40.77 / 0.9821 40.90 / 0.9806 39.65 / 0.9774 40.41 / 0.9756 41.32 / 0.9764 41.48 / 0.9793 41.72 / 0.9823 40.88 / 0.9792 25 GCDN 37.12 / 0.9771 37.15 / 0.9788 37.50 / 0.9814 35.88 / 0.9697 37.05 / 0.9705 38.62 / 0.9730 38.39 / 0.9786 38.80 / 0.9836 37.56 / 0.9766 NLRN 37.08 / 0.9720 37.01 / 0.9734 37.37 / 0.9797 36.09 / 0.9661 37.01 / 0.9646 38.42 / 0.9679 38.33 / 0.9723 38.65 / 0.9786 37.50 / 0.9718 OGLR 36.67 / 0.9592 36.68 / 0.9649 36.29 / 0.9594 35.51 / 0.9545 36.41 / 0.9541 37.44 / 0.9541 37.17 / 0.9575 37.86 / 0.9655 36.75 / 0.9587 50 GCDN 33.37 / 0.9522 33.18 / 0.9536 32.23 / 0.9468 31.61 / 0.9379 32.37 / 0.9417 34.07 / 0.9526 33.73 / 0.9567 34.35 / 0.9672 33.11 / 0.9511 NLRN 33.23 / 0.9444 32.86 / 0.9448 32.42 / 0.9534 31.53 / 0.9304 32.40 / 0.9347 34.15 / 0.9459 33.58 / 0.9475 34.37 / 0.9603 33.07 / 0.9452 OGLR 32.24 / 0.9121 31.92 / 0.9129 31.23 / 0.9027 30.21 / 0.8926 31.44 / 0.8999 32.85 / 0.9051 32.46 / 0.9093 32.99 / 0.9191 31.92 / 0.9067<ref type="bibr" target="#b5">[6]</ref>, N 3 Net<ref type="bibr" target="#b11">[12]</ref> and NLRN<ref type="bibr" target="#b13">[13]</ref>. In particular, among the deep-learning methods, N 3 Net and NLRN propose non-local approaches. All results have been obtained running the pretrained models provided by the authors, except for N 3 Net at σ = 15 which is unavailable.Table IIIreports the PSNR and SSIM values obtained for the Set12, BSD68 and Urban100 standard test sets.</figDesc><table><row><cell>Dataset</cell><cell>Noise σ</cell><cell>BM3D</cell><cell>WNNM</cell><cell>TNRD</cell><cell>DnCNN</cell><cell></cell><cell>N 3 Net</cell><cell>NLRN</cell><cell>GCDN</cell></row><row><cell></cell><cell>15</cell><cell>32.37 / 0.8952</cell><cell>32.70 / 0.8982</cell><cell>32.50 / 0.8958</cell><cell cols="2">32.86 / 0.9031</cell><cell>-/ -</cell><cell>33.16 / 0.9070</cell><cell>33.14 / 0.9072</cell></row><row><cell>Set12</cell><cell>25</cell><cell>29.97 / 0.8504</cell><cell>30.28 / 0.8557</cell><cell>30.06 / 0.8512</cell><cell cols="2">30.44 / 0.8622</cell><cell>30.55 / -</cell><cell>30.80 / 0.8689</cell><cell>30.78 / 0.8687</cell></row><row><cell cols="2">50 σ Method aloe</cell><cell>art</cell><cell>baby</cell><cell>cones</cell><cell>dolls</cell><cell cols="2">laundry</cell><cell>moebius</cell><cell>reindeer</cell><cell>Average</cell></row><row><cell>GCDN 40.74 /</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table V .</head><label>V</label><figDesc>REAL IMAGE DENOISING (SIDD DATASET)</figDesc><table><row><cell></cell><cell>CBM3D</cell><cell>DnCNN</cell><cell>NLRN</cell><cell>GCDN</cell></row><row><cell>PSNR</cell><cell>38.73 dB</cell><cell>39.98 dB</cell><cell>41.24 dB</cell><cell>41.48 dB</cell></row><row><cell>SSIM</cell><cell>0.9587</cell><cell>0.9605</cell><cell>0.9652</cell><cell>0.9697</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://vision.middlebury.edu/stereo/data/.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Digital camera identification from sensor pattern noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lukáš</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goljan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="214" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Compressed fingerprint matching and camera identification via random projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coluccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1472" to="1485" />
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The little engine that could: Regularization by denoising (red)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1804" to="1844" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Block coordinate regularization by denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">S</forename><surname>Kamilov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05113</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond a Gaussian denoiser: residual learning of deep CNN for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-B</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2802" to="2810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Memnet: A persistent memory network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4539" to="4547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Beyond deep residual learning for image restoration: Persistent homology-guided manifold simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="1141" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nonlocalityreinforced convolutional neural networks for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1216" to="1220" />
			<date type="published" when="2018-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Universal denoising networks: a novel CNN architecture for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefkimmiatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3204" to="3213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural nearest neighbors networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Plötz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1087" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Left to right: ground truth, noisy</title>
		<imprint/>
	</monogr>
	<note>Real image denoising. 80 dB), CBM3D (34.84 dB), DnCNN (36.05 dB), NLRN (37.15 dB), GCDN (37.33 dB</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Non-local recurrent network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1673" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image denoising with graph-convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fracastoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 26th IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending highdimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic edge-conditioned filters in convolutional neural networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07829</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">in International Conference on Learning Representations (ICLR) 2019</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5115" to="5124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Feastnet: Feature-steered graph convolutions for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2598" to="2606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning localized generative models for 3d point clouds via graph convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fracastoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR) 2019</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: nonlinear phenomena</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2862" to="2869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Graph Laplacian regularization for image denoising: analysis in the continuous domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1770" to="1785" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with BM3D?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3045118.3045167" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32Nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32Nd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
	<note>ser. ICML&apos;15. JMLR.org</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Image denoising via CNNs: an adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Divakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Trends in Image Restoration and Enhancement, CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exploiting edge features for graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9211" to="9219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An exploration of parameter redundancy in deep networks with circulant projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Compression of fully-connected layer in neural network by kronecker product</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)</title>
		<imprint>
			<date type="published" when="2016-02" />
			<biblScope unit="page" from="173" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Johnson-lindenstrauss lemma for circulant matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vybíral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Random Structures &amp; Algorithms</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="398" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">User authentication via prnu-based physical unclonable functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coluccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1941" to="1956" />
			<date type="published" when="2017-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Binary adaptive embeddings from order statistics of random projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="111" to="115" />
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>PMLR, 13-15</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, ser. Proceedings of Machine Learning</title>
		<editor>Research, Y. W. Teh and M. Titterington</editor>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics, ser. Machine Learning<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Chia Laguna Resort</publisher>
			<date type="published" when="2010-05" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Proximal splitting methods in signal processing,&quot; in Fixed-point algorithms for inverse problems in science and engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Pesquet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="185" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int&apos;l Conf. Computer Vision</title>
		<meeting>8th Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multiresolution graph fourier transform for compression of piecewise smooth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">C</forename><surname>Au</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="419" to="433" />
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Graph-based transform coding with application to image compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fracastoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thanou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.06393</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">CCD arrays, cameras, and displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Holst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>JCD Publishing SPIE Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Benchmarking denoising algorithms with real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Plotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1586" to="1595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A high-quality denoising dataset for smartphone cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdelhamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Color image denoising via sparse 3d collaborative filtering with grouping constraint in luminance-chrominance space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="313" to="316" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">An efficient statistical method for image noise level estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="page" from="477" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="184" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Deepsum: Deep neural network for super-resolution of unregistered multitemporal images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Molini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fracastoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.06490</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
