<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Beyond Deep Residual Learning for Image Restoration: Persistent Homology-Guided Manifold Simplification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woong</forename><surname>Bae</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Bio Imaging Signal Processing Lab Korea Ad. Inst. of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>291 Daehak-ro, Yuseong-gu</addrLine>
									<postCode>34141</postCode>
									<settlement>Daejeon</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaejun</forename><surname>Yoo</surname></persName>
							<email>jaejun2004@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Bio Imaging Signal Processing Lab Korea Ad. Inst. of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>291 Daehak-ro, Yuseong-gu</addrLine>
									<postCode>34141</postCode>
									<settlement>Daejeon</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Chul</forename><surname>Ye</surname></persName>
							<email>jong.ye@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Bio Imaging Signal Processing Lab Korea Ad. Inst. of Science &amp; Technology (KAIST)</orgName>
								<address>
									<addrLine>291 Daehak-ro, Yuseong-gu</addrLine>
									<postCode>34141</postCode>
									<settlement>Daejeon</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Beyond Deep Residual Learning for Image Restoration: Persistent Homology-Guided Manifold Simplification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>* denotes co-first authors</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The latest deep learning approaches perform better than the state-of-the-art signal processing approaches in various image restoration tasks. However, if an image contains many patterns and structures, the performance of these CNNs is still inferior. To address this issue, here we propose a novel feature space deep residual learning algorithm that outperforms the existing residual learning. The main idea is originated from the observation that the performance of a learning algorithm can be improved if the input and/or label manifolds can be made topologically simpler by an analytic mapping to a feature space. Our extensive numerical studies using denoising experiments and NTIRE single-image super-resolution (SISR) competition demonstrate that the proposed feature space residual learning outperforms the existing state-of-the-art approaches. Moreover, our algorithm was ranked third in NTIRE competition with 5-10 times faster computational time compared to the top ranked teams. The source code is available on page : https://github.com/iorism/CNN.git</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image restoration tasks such as denoising and superresolution are essential steps in many practical image processing applications. Over the last few decades, various algorithms have been developed, which include non-local self-similarity (NSS) models <ref type="bibr" target="#b1">[2]</ref>, total variation (TV) approaches <ref type="bibr" target="#b21">[22]</ref>, and sparse dictionary learning models <ref type="bibr" target="#b8">[9]</ref>. Among them, the block matching 3D filter (BM3D) <ref type="bibr" target="#b6">[7]</ref> is considered as the state-of-the art algorithm. In general, these methods are dependent on the noise model. Moreover, these algorithms are usually implemented in an iterative manner, so they require significant computational resources.</p><p>Recently, deep learning approaches have achieved tremendous success in classification <ref type="bibr" target="#b18">[19]</ref> as well as lowlevel computer vision problems <ref type="bibr" target="#b23">[24]</ref>. In image denoising and super-resolution tasks, many state-of-the-art CNN algorithms <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b31">32]</ref> have been proposed. Although the performance of these algorithms usually outperforms the non-local and collaboration filtering approaches such as BM3D, in case of certain images that have many patterns (such as Barbara image), CNN approaches are still inferior to BM3D. Therefore, one of the main motivations of this work is to develop a new CNN architecture that overcomes the limitation of the state-of-the-art CNN approaches. The proposed network architectures are motivated from a novel persistent homology analysis <ref type="bibr" target="#b10">[11]</ref> on residual learning for image processing tasks. Specifically, we show that the residual manifold is topologically simpler than the original image manifold, which may have attributed the success of residual learning. Moreover, this observation leads us to a new network design principle using manifold simplification. Specifically, our design goal is to find mappings for input and/or label datasets to feature spaces, respectively, such that the new datasets become topologically simpler and easier to learn. In particular, we show that the wavelet transform provides topologically simpler manifold structures while preserving the directional edge information.</p><p>Contribution: In summary, our contributions are as following. First, a novel network design principle using manifold simplification is proposed. Second, using a recent computational topology tool called the persistent homology, we show that the existing residual learning is a special case of manifold simplification and then propose a wavelet transform to simplify topological structures of input and/or label manifolds.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>One of the classical approaches for image denoising is a wavelet shrinkage approach <ref type="bibr" target="#b9">[10]</ref>, which decomposes an image into low and high frequency subbands and applies thresholding in the high frequency coefficients <ref type="bibr" target="#b22">[23]</ref>. Advanced algorithms in this field are to exploit the intra-and inter-correlations of the wavelet coefficients <ref type="bibr" target="#b5">[6]</ref>.</p><p>In neural network literature, the work by Berger et al <ref type="bibr" target="#b2">[3]</ref> was the first which demonstrated similar denoising performance to BM3D using multi-layer perceptron (MLP). Chen et al. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> proposed a deep learning approach called trainable nonlinear reaction diffusion (TNRD) that can train filters and influence functions by unfolding a variational optimization approach. Recently, based on skipped connec-tion and encoder-decoder architecture, a very deep residual encoder-decoder networks (RED-Net) was proposed for image restoration problems <ref type="bibr" target="#b20">[21]</ref>.</p><p>Residual learning has multiple realizations. The first approach is using a skipped connection that bypasses input data of a certain layer to another layer during forward and backward propagations. This type of residual learning concept was first introduced by He et al. <ref type="bibr" target="#b12">[13]</ref> for image recognition. In low-level computer vision problems, Kim et al. <ref type="bibr" target="#b17">[18]</ref> employed a residual learning for a super-resolution method. In these approaches, the residual learning was implemented by a skipped connection corresponding to an identity mapping. In another implementation, the label data is transformed into the difference between the input data and clean data. For example, Zhang et al. <ref type="bibr" target="#b31">[32]</ref> proposed a denoising convolutional neural networks (DnCNNs) <ref type="bibr" target="#b31">[32]</ref>, which has inspired our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Theory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Generalization bound</head><p>Let X ∈ X and Y ∈ Y denote the input and label data and f : X → Y denotes a function living in a functional space F. Then, one is interested in the minimization problem:</p><formula xml:id="formula_0">min f ∈F L(f ), where L(f ) = E D Y − f (X) 2 de- notes the risk.</formula><p>A major technical issue is, however, that the associated probability distribution D is unknown. Thus, an upper bound is used to characterize the generalization performance. Specifically, with probability ≥ 1 − δ with a small δ &gt; 0, for every function f ∈ F,</p><formula xml:id="formula_1">L(f ) ≤L n (f ) empirical risk + 2R n (F) complexity penalty +3 ln(2/δ) n<label>(1)</label></formula><p>whereR n (F) denotes the Rademacher complexity <ref type="bibr" target="#b0">[1]</ref>. In neural network, empirical risk is determined by the representation power or capacity of a network <ref type="bibr" target="#b26">[27]</ref>, and the complexity penalty is determined by the structure of a network. It was shown that the capacity of representation power grows exponentially with respect to the number of layers <ref type="bibr" target="#b26">[27]</ref>, which justifies the use of a deep network compared to shallow ones. However, the complexity penalty in (1) also increases with a complicated network structure. The main remedy for this trade-off is to use large number of training dataset such that the contribution of the complexity penalty reduces much more quickly so that the empirical risk minimization (ERM) converges consistently to the risk minimization <ref type="bibr" target="#b27">[28]</ref>.</p><p>However, for the intermediate size of the training data, there still exist gaps between the ERM and the risk minimization. One of the most important contributions of this paper is to reduce the gap by using a relatively simpler network, by reducing the complexity of the data manifold.</p><p>Specifically, for a given deep network f : X → Y , our design goal is to find mappings Φ and Ψ to the feature spaces for the input and label datasets, respectively. Then, the resulting datasets composed of X = Φ(X) and Y = Ψ(Y ) may have simpler manifold structures. This can be shown in the following diagram:</p><formula xml:id="formula_2">X f / / Φ Y Ψ X Φ −1 O O g / / Y Ψ −1 O O</formula><p>from which our goal is to find an equivalent neural network g : X → Y that has a better performance than the original network f : X → Y .</p><p>For example, in recent deep residual learning <ref type="bibr" target="#b31">[32]</ref>, the input transform T is an identity mapping and the label transform is given by Y = Ψ(Y ) = Y − X . Using persistent homology analysis, Section 1 in the supplementary material shows that the label manifold of the residual is topologically simpler than that of Y . Accordingly, the upper bound of the risk of g : X → Y can be reduced compared to that of f : X → Y .</p><p>Inspired by this finding, this paper proposes a wavelet transform as a good transform to reduce the topological complexity of resulting input and label manifolds. More specifically, thanks to the vanishing moments of wavelets, the wavelet transform can annihilate the smoothly varying signals while retaining the image edges <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20]</ref>, which results in the dimensional reduction and manifold simplification. Indeed, this property of the wavelet transform has been extensively exploited in wavelet-based image compression tools such as JPEG2000 <ref type="bibr" target="#b25">[26]</ref>, and this paper shows that this property also improves the performance of deep network for image restoration tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Persistent homology</head><p>The complexity of a manifold is a topological concept. Thus, it should be analyzed using topological tools. In algebraic topology, Betti numbers (β m ) represent the number of m-dimensional holes of a manifold. For example, β 0 and β 1 are the number of connected components and cycles, respectively. They are frequently used to investigate the characteristics of underlying manifolds <ref type="bibr" target="#b10">[11]</ref>. Specifically, we can infer the topology of our data manifold by varying the similarity measure between the data points and tracking the changes of Betti numbers. As allowable distance increases, data point clouds merge together and finally become a single cluster ( <ref type="figure" target="#fig_1">Fig. 2(a)</ref>). Therefore, the point clouds with high diversity will merge slowly and this will be represented as a slow decrease in Betti numbers. For example, in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>, the dataset Y 1 is a doughnut with a hole (i.e. β 0 = 1 and β 1 = 1) whereas Y 2 is a sphere-like cluster (i.e. β 0 = 1 and β 1 = 0). Accordingly, Y 1 has longer zero dimensional barcodes persisting over in <ref type="figure" target="#fig_1">Fig. 2(b)</ref>. This persistence of Betti number is an important topological feature and the recent persistent homology analysis utilizes this to investigate the topology of the data manifold <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed architecture</head><p>This section describes two network structures based on the manifold simplificaiton. One is the primary architecture used for Gaussian denoising and the other is our NTIRE 2017 competition architecture used for RGB based SISR problems, which has been developed based on the primary architecture. For the wavelet transform, we used one level discrete wavelet transform using Haar wavelet filter.</p><p>Denoising architecture: The input and the clean label images are first decomposed into four subbands (i.e. LL, LH, HL, and HH) using the wavelet transform. The wavelet residual images, which are now used as our new labels, are obtained by the difference between the input and the clean label images in the wavelet domain. Then, the network is trained to learn multi-input and multi-output functional relationship between these newly processed input and label. Here, four patches at the same locations in each wavelet subband are extracted and used for training. For Gaussian denoising, 40 × 40 image patches are used, resulting in 40 × 40 × 4 patches.</p><p>The proposed denoising network architecture is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. It consists of five modules between the first and the last stages. Each module has one bypass connection, three convolution layers, three batch normalizations <ref type="bibr" target="#b16">[17]</ref>, and three Rectified Linear Unit (ReLU) <ref type="bibr" target="#b11">[12]</ref> layers. The bypass connection was used for an efficient network training because it is helpful for training a deep network by alleviating the gradient vanishing problem <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>. The first stage contains two layers: one with a convolution layer with ReLU which is followed by the other convolution layer with batch normalization and ReLU. The last stage is composed of three layers: two layers with a convolution, batch normalization, and ReLU and the last layer with a convolution layer. Accordingly, the total number of convolution layers is 20. The convolution filter size is 3 × 3 × 320 × 320. During the convolution, we used zero padding to maintain the image size and reduce the boundary effect <ref type="bibr" target="#b17">[18]</ref>.</p><p>In addition to the aforementioned advantage of the wavelet transform for feature space mapping, there are two more advantages to perform the wavelet transform. As shown in <ref type="figure" target="#fig_2">Fig.3</ref>, the first advantage is that the patch size can be reduced by half. It can reduce the runtime of the network due to the size of the output images of layers being halved. The second one is that the minimum required size of receptive field can be reduced to obtain a good performance. Since the number of convolutions is related to the runtime and learning time, the smaller the required receptive field size, the more effective it is to reduce the computation time.</p><p>NTIRE SISR competition architecture: The proposed networks for NTIRE 2017 SISR competition are shown in <ref type="table" target="#tab_0">Table 1</ref>. These architectures are extended from the primary denoising architecture. Depending on the decimation schemes (bicubic x2, x3, x4, and unknown x2, x3, and x4) for low resolution dataset, we implemented three different architectures.</p><p>Specifically, for the bicubic cases, we first generated the upsampled image using bicubic interpolation and the extended denoising network structures with the wavelet transform were used for manifold simplification. For the unknown decimation scheme, however, we employed the subpixel shuffling scheme <ref type="bibr" target="#b24">[25]</ref> as the input and label transform to save the memory and augment the input data to a bigger image size. As will be shown later in persistent homology analysis in the supplementary material, this sub-pixel shuffling transform does not reduce the manifold complexity by itself. Still, we could exploit the manifold simplification from the residual learning in sub-pixel shuffling domain as shown in <ref type="figure" target="#fig_3">Fig. 4</ref> and <ref type="table" target="#tab_1">Table 2</ref> .  All three SISR architectures have 41 convolution layers to deal with the dataset composed of 800 high resolution images. In every case, we used 20 × 20 patch size. After the first two layers, a basic module is repeated twelve times, which is followed by three convolution layers. To reconstruct the bicubic x2 downsampled dataset, we included two long bypass connections between six basic modules in the network and the number of channels were 256. For the other datasets, we did not use the long bypass connection and the number of channels were 320. The long bypass connection allows faster computation and less parameter size than using the concatenation layer. Although concatenation layer is good for reducing the depth of convolution layer, it is very slow because of inefficient GPU memory usage. Thus, the long bypass connection is more efficient for SISR problem. <ref type="table" target="#tab_2">Table 3</ref> shows the effectiveness of the long bypass connection.</p><p>We used RGB data for different channels rather than luminance channel, because RGB based learning has the effect of data augmentation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Dataset</head><p>Dataset for denoising network: We used publicly available Berkeley segmentation (BSD500) <ref type="bibr" target="#b3">[4]</ref> and Urban100 <ref type="bibr" target="#b15">[16]</ref> datasets. Specifically, we used 400 images of BSD500 and Urban100 datasets for training in the Gaussian denoising task. In addition, we generated 4000 training images by using data augmentation via image flipping, rotation, and cropping. To get various noise patterns and avoid overfitting, we re-generated the Gaussian noise in every other epoch during training. For the test dataset, BSD68 and Set12 datasets were used. All the images were encoded with eight bits, so the pixel values are within [0, 255]. For training and validation, Gaussian noises with σ = 15, 30, and 50 were added.</p><p>Dataset for NTIRE competition: We used only 800 training dataset of DIV2K for each SISR problem. Instead of using cropped images, we cropped (20 × 20) patches randomly from a full image and performed data augmentation using image flipping, rotation, and downsampling with the corresponding scale factors of x2, x3, and x4 for each epoch. It helps to create more diverse patterns of images. For training dataset with bicubic x3 and x4 decimation, we used all bicubic x2,x3 and x4 images of DIV2K datasets together as a kind of data augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Network training</head><p>Denoising network: The network parameters were initialized using the Xavier method <ref type="bibr" target="#b13">[14]</ref>. We used the regression loss across four wavelet subbands under l 2 penalty and the proposed network was trained by using the stochastic gradient descent (SGD). The regularization parameter (λ) was 0.0001 and the momentum was 0.9. The learning rate was set from 10 −1 to 10 −4 which was reduced in log scale at each epoch. The mini-batch size for batch normalization was 32 where the images were selected randomly at every epoch <ref type="bibr" target="#b16">[17]</ref>. To use a high learning rate and guarantee a stable learning, we employed the gradient clipping technique <ref type="bibr" target="#b17">[18]</ref> so that the maximum and minimum values of the update parameter are bounded by the predefined range. These parameter settings were equally applied to all experiments of the image denoising. We used 40 × 40 patch size and the network was trained using 53 epochs.</p><p>The network was implemented using MatConvNet toolbox (beta.20) <ref type="bibr" target="#b28">[29]</ref> in MATLAB 2015a environment (Math-Works, Natick). We used a GTX 1080 graphic processor and i7-4770 CPU (3.40GHz). The Gaussian denoising network took about two days for training.</p><p>Training for NTIRE competition: We used 20 × 20 patch size and trained the network for 150 epochs. We used 64 mini-batch size and learning rate of (0.1, 0.00001) in log scale for 150 epochs with 0.05 gradient clipping factor. For each epoch, to train more various patterns, we used subepoch system that repeats forward and back propagation 512 times by randomly cropping patches from a full size image. For the bicubic x3 and x4 cases, we trained the network with the bicubic x2, x3, and x4 datasets together to in-  <ref type="table">Table 4</ref>. Performance comparison in terms of PSNR for "Set12" dataset in the Gaussian denoising task. The primary architecture was used.  <ref type="table">Table 5</ref>. Performance comparison in terms of SSIM for "Set12" dataset in the Gaussian denoising task. The primary architecture was used. crease the performance of x3 and x4 cases <ref type="bibr" target="#b17">[18]</ref>. Other hyper parameters are remained same with the denoising network. Using GTX 1080ti, the training of networks for the bicubic x2 and bicubic x3, x4 and unknown x2, x3, x4 datasets took almost six days, 21 days and seven days, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Persistent homology results</head><p>To show the correlation between the network performance and manifold simplification, we compared the topology of the input and the label manifolds in both image and wavelet domains. The results in the supplementary material clearly showed that feature space mappings provide simpler data manifolds. Specifically, the proposed denoising and super-resolution algorithms can be benefited from simpler input manifold from a feature space mapping using wavelet transform as well as additional simpler label manifold from residual learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Experimental Results</head><p>Denoising: For the quantitative comparison of the denoising performance, we used the objective measures such as the peak signal to noise ratio (PSNR) and the structural similarity index measure (SSIM) <ref type="bibr" target="#b30">[31]</ref>. <ref type="table">Table 4</ref>, 5 show that the proposed network outperforms the state-of-the-art denoising methods in terms of PSNR and SSIM for all Set12 images. Especially, in the patterned images such as Barbara and House, we attained better performance than using BM3D in terms of PSNR (0.1dB and 0.8dB, respectively). <ref type="figure" target="#fig_4">Fig. 5</ref> shows the denoising examples in various images. The proposed methods showed the best visual quality especially in the edge regions. Moreover, as shown in <ref type="table" target="#tab_6">Table 6</ref>, the proposed method showed superior results to the state-of-the-art approaches in the experiments with BSD68 dataset which contains diverse patterned images. For 512x512 image size, the proposed network took only 0.157 seconds even with the current MATLAB implementation. This is comparable or even better than the existing approaches.</p><p>To further demonstrate the importance of the wavelet decomposition, additional comparative studies with the baseline network were performed. Here, an input image is decomposed to four channels using so-called polyphase quadrature filter (PQF) bank <ref type="bibr" target="#b29">[30]</ref>. Specifically, the PQF just splits an input image into four equidistant sub-bands with distinct horizontal and vertical offset without wavelet filtering. Therefore, it is equivalent to the sub-pixel shuffling scheme in <ref type="bibr" target="#b24">[25]</ref> except that input image is first interpolated. Accordingly, the networks using PQF have the exactly same architecture except the input and label images so that we can investigate the effect of the wavelet transform. <ref type="figure">Fig. 6</ref> clearly shows that the wavelet transform can improve the performance compared to the baseline network. <ref type="figure">Figure 6</ref>. Importance of the wavelet transform for manifold simplification. Here, the Gaussian denoising algorithms with σ = 30. Barbara and Set12 images were used. In the case of BM3D, Barbara image was used for comparison.   NTIRE SISR competition: Our proposed networks were ranked third in NTIRE SISR competition. In particular, our networks were competitive in both performance and speed. More specifically, compared to the 14-67 seconds computational time by the top ranked groups' results, our computational time was only 4-5 seconds for each frame. Since the wavelet transform is effective in reducing the manifold complexity compared to the sub-pixel shuffling scheme, in terms of dataset specific ranking, our ranking with the bicubic SISR dataset was better than with the unknown decimation dataset where we just exploited the manifold simplification from the residual learning. <ref type="figure" target="#fig_5">Figs. 7, 8</ref> clearly show the performance of our network in various SISR problems. We also confirmed that our network outperforms the existing state-of-the-art CNN approaches for various dataset in <ref type="table" target="#tab_7">Table 7</ref>. In particular, the proposed methods exhibited outstanding performance in the edge areas. We provide more comparative examples in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we proposed a feature space deep residual learning algorithm that outperforms the existing residual learning approaches. In particular, using persistent homology analysis, we showed that the wavelet transform and/or  residual learning results in simpler data manifold. This finding as well as the experimental results of Gaussian denoising and NTIRE SISR competition results confirmed that the proposed approach is quite competitive in terms of performance and speed. Moreover, we believe that the persistent homology-guided manifold simplification provides a novel design tool for general deep learning networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgement</head><p>This work is supported by Korea Science and Engineering Foundation, Grant number NRF-2013M3A9B2076548.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.">Persistent homology results</head><p>For the denoising task, total 4500 numbers of 40 × 40 patches with four components of the wavelet transformed data and 80 × 80 patches of the image domain data were set to a set of point clouds in R 6400 vector space of both image and wavelet domain manifolds. Note that the patch size of the image domain is doubled to match the size of the receptive field. For the super-resolution experiments, a set of 20 × 20 patches was cropped to generate a point cloud in both bicubic and unknown datasets. Similarly, 40 × 40 image patch was used for image domain approaches.</p><p>To investigate the topology of the dataset, a metric should be defined. Since we used the l 2 regression error as the loss, the natural choice should be l 2 distance, i.e. d 2 (X i , X j ) = X i − X j 2 . However, care need to be taken for the input dataset, because the data should pass through the batch-normalization which changes their mean and variance. Note the distance metric that is invariant under batch normalization is the correlation-based metric: d corr (X i , X j ) = 1 − corr(X i , X j ), where corr(X i , X j ) denotes the normalized Pearson's correlation between X i and X j . Therefore, we used the d corr as the metric for the input space, whereas d 2 was used as a metric for the label space.</p><p>To show that the advantages of residual learning comes from the simpler topology of residual labels, we first calculated the barcodes of the original images and residuals. We calculated Betti numbers and barcodes using a toolbox called JAVAPLEX (http://appliedtopology.github.io/ javaplex/). The barcodes in the left column of the <ref type="figure" target="#fig_7">Fig. 9</ref> clearly show that the topology of the label manifold composed of residual image patches is much simpler. The point clouds of the residual image patches merged earlier than that of the original ones. Note that the residual manifolds of both image and wavelet domains have an identical topological complexity in the image domain residual due to the orthogonal Haar wavelet transform. The barcodes of residual manifolds in Gaussian denoising case showed rapid drops at = 0.17, which is related to the noise standard deviation. These results imply that the label manifold for residual has much simpler topology than that of original one. We believe that this is the main reason for the success of deep residual learning.</p><p>Next, we investigated the advantages of wavelet transform which further reduces the topological complexity of the input spaces in both Gaussian denoising and superresolution datasets (the right column of <ref type="figure" target="#fig_7">Fig. 9</ref>). While the residual manifolds of both image and wavelet domains had a very similar topological complexity represented by barcodes, the input manifold of the wavelet transformed images had simpler topology than the original images. How- ever, the sub-pixel shuffling in the unknown decimation case does not change the manifold structure because it merely shuffles the order of the pixels. Accordingly, the topology of the input manifold does not change, but the residual learning in sub-pixel shuffling domain reduces the complexity of the label manifold.</p><p>Accordingly, we expect that the proposed denoising and super-resolution algorithms are benefited from the simpler input manifolds from feature space mapping as well as additional simpler label manifold from residual learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.">Additional Results from Gaussian denoising and NTIRE SISR competition</head><p>In this section, we provide more results for Gaussian denoising and SISR reconstruction from NTIRE competition dataset.          </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Proposed wavelet domain deep residual learning network for the Gaussian denoising task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a) Point cloud data K of true space Y and its configuration over distance filtration. Y 1 is a doughnut and Y 2 is a sphere shaped space each of which represents a complicated space and a simpler space, respectively. (b) Zero and one dimensional barcodes of K1 and K2. Betti number can be easily calculated by counting the number of barcodes at each filtration value .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Wavelet decomposition reduces the patch size to a quater.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Residual based sub-pixel shuffling. Label image set Original Residual Unknown x3 29.1242 / 0.8327 30.3025 / 0.8572</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Denoising results of Barbara, Boats, and Lena images using various methods. [PSNR/SSIM] values are displayed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Performance comparison of SISR at scale factor of 4 of bicubic downsampling. The proposed network is RGB based competition network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Performance comparison of SISR at scale factor of 4 of unknown downsampling. The proposed network is RGB based competition network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>(Left) Persistent homology analysis of label manifold. Zero dimensional barcodes of the label manifolds between the original and residual images are compared for (a) Gaussian denoising , (b) super-resolution (bicubic decimation), and (c) superresolution (unknown decimation) tasks. (Right) Persistent homology analysis of input manifold. Zero dimensional barcodes of the input manifolds between the original and feature space mappings are compared for (a) Gaussian denoising, and (b) super-resolution (bicubic decimation), and (c) super-resolution (unknown decimation) tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Denoising performance comparison. PSNR/SSIM values are displayed. Gaussian noise with σ=30 were added. .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 .</head><label>11</label><figDesc>Denoising performance comparison. PSNR/SSIM values are displayed. Gaussian noise with σ=30 were added. .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 .</head><label>12</label><figDesc>Denoising performance comparison. PSNR/SSIM values are displayed. Gaussian noise with σ=30 were added. .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 .</head><label>13</label><figDesc>Performance comparison of SISR at scale factor of 4 of unknown downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 14 .</head><label>14</label><figDesc>Performance comparison of SISR at scale factor of 4 of unknown downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 15 .</head><label>15</label><figDesc>Performance comparison of SISR at scale factor of 4 of unknown downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 16 .</head><label>16</label><figDesc>Performance comparison of SISR at scale factor of 4 of bicubic downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 17 .</head><label>17</label><figDesc>Performance comparison of SISR at scale factor of 4 of bicubic downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 18 .</head><label>18</label><figDesc>Performance comparison of SISR at scale factor of 4 of bicubic downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 19 .</head><label>19</label><figDesc>Performance comparison of SISR at scale factor of 4 of bicubic downsampling. The proposed network is RGB based network. Left : input, Center : restoration result, Right : label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Haar Wavelet Transform, BU: Bicubic Upsampling, LR: Low Resolution image, HR: High Resolution image, Conv: 3 × 3 Convolution, BN: Batch Normalization, BypassM: Sending output of previous layer to last layer of module(M is module number), SumF: Sum of output of previous layer and BypassM output, COPY ch: Copy input image (scale x scale) times on channel direction, PS: sub-Pixel Shuffling, IPS: Inverse sub-Pixel Shuffling, IWT: Inverse Wavelet Transform Proposed network architectures for NTIRE SISR competition from bicubic and unknown downsampling schemes.</figDesc><table><row><cell></cell><cell>Bicubic x2 (256ch)</cell><cell>Bicubic x3,x4 (320ch)</cell><cell>Unknown x2,x3,x4 (320ch)</cell></row><row><cell>Input</cell><cell cols="2">WT( BU(LR) )</cell><cell>COPY ch(LR)</cell></row><row><cell>Label</cell><cell cols="2">Input -WT(HR)</cell><cell>Input -PS(HR)</cell></row><row><cell>1st layer</cell><cell cols="2">Conv → ReLU</cell><cell>Conv → ReLU</cell></row><row><cell>2nd layer</cell><cell cols="2">Conv → BN → ReLU</cell><cell>Conv → BN → ReLU</cell></row><row><cell>Long bypass layer</cell><cell>LongBypass(1)</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>BypassM1 →</cell><cell>BypassM1 →</cell><cell>BypassM1 →</cell></row><row><cell></cell><cell>Conv→BN→ReLU→</cell><cell>Conv→BN→ReLU→</cell><cell>Conv→BN→ReLU→</cell></row><row><cell>1st module</cell><cell>Conv→BN→ReLU→ Conv →BN→</cell><cell>Conv→BN→ReLU→ Conv →BN→</cell><cell>Conv→BN→ReLU→ Conv →BN→</cell></row><row><cell></cell><cell>SumF(BypassM) →</cell><cell>SumF(BypassM) →</cell><cell>SumF(BypassM) →</cell></row><row><cell></cell><cell>ReLU</cell><cell>ReLU</cell><cell>ReLU</cell></row><row><cell>Repeat 1st module</cell><cell>5 times (2th∼6th module)</cell><cell>11 times (2th∼12th module)</cell><cell>12 times (2th∼12th module)</cell></row><row><cell></cell><cell>Sum of "LongBypass(1)" and</cell><cell></cell><cell></cell></row><row><cell>Long bypass &amp; catch layer</cell><cell>"Output of 6th module"</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>→ BN→ ReLU</cell><cell></cell><cell></cell></row><row><cell>Long bypass layer</cell><cell>LongBypass(2)</cell><cell>-</cell><cell>-</cell></row><row><cell>Repeat 1st module</cell><cell>6 times (7th∼12th modules)</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Sum of "LongBypass(2)" and</cell><cell></cell><cell></cell></row><row><cell>Long bypass &amp; catch layer</cell><cell>"Output of 12th module"</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>→ BN→ ReLU</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Conv→BN→ReLU→</cell><cell>Conv→BN→ReLU→</cell><cell>Conv→BN→ReLU→</cell></row><row><cell>Last layer</cell><cell>Conv→BN→ReLU→</cell><cell>Conv→BN→ReLU→</cell><cell>Conv→BN→ReLU→</cell></row><row><cell></cell><cell>Conv</cell><cell>Conv</cell><cell>Conv</cell></row><row><cell>Restoration</cell><cell cols="2">IWT(Input-Output)</cell><cell>IPS(Input-Output)</cell></row><row><cell>* WT:</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table /><note>The effectiveness of the residual based sub-pixel shuffling in terms of PSNR/SSIM for "Unknown x3' datset in the super- resolution task. The training step was stopped at epoch 50 and the results are calculated from 100 validation data of DIV2K dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>The effectiveness of the long bypass layer in terms of PSNR/SSIM. This result was calculated from 50 validation data of DIV2K dataset.</figDesc><table><row><cell>Problem</cell><cell>Without LongBypass</cell><cell>LongBypass</cell></row><row><cell>Bicubic x2</cell><cell>35.3436 / 0.9426</cell><cell>35.3595 / 0.9427</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>32.1417 29.2140 27.6354 28.3458 27.4857 28.0707 31.2388 29.7894 29.0465 28.8016 28.8417 29.1041 DnCNN-S 29.2748 32.3199 29.8497 28.3970 29.3165 28.1570 28.5375 31.6104 28.8925 29.3117 29.2492 29.2091 29.5105 Proposed(Primary) 29.6219 32.9357 30.1054 29.0584 29.5597 28.3288 28.6770 32.0163 29.8941 29.6107 29.4065 29.5563 29.8976</figDesc><table><row><cell>Images</cell><cell>C.man</cell><cell>House</cell><cell>Peppers Starfish</cell><cell>Monar.</cell><cell>Airpl.</cell><cell>Parrot</cell><cell>Lena</cell><cell>Barbara</cell><cell>Boat</cell><cell>Man</cell><cell>Couple Average</cell></row><row><cell>Algorithm</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Noise Level: σ = 30</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BM3D</cell><cell>28.6376</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>.8722 31.7202/0.8901 31.8607/0.8941 30 27.7492/0.7735 28.3324/0.8003 28.5599/0.8092 50 25.6103/0.6868 26.2275/0.7163 26.3577/0.7270</figDesc><table><row><cell>Noise (σ)</cell><cell>BM3D</cell><cell>DnCNN-S</cell><cell>Proposed</cell></row><row><cell>15</cell><cell>31.0761/0</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Performance comparison in terms of PSNR/SSIM for "BSD68" dataset in the Gaussian denoising task.</figDesc><table><row><cell>Dataset (scale)</cell><cell>VDSR</cell><cell>DnCNN-3</cell><cell>Proposed-P</cell><cell>Proposed</cell></row><row><cell>Set5 (2)</cell><cell cols="4">37.53/0.9586 37.53/0.9582 37.57/0.9586 38.06/0.9602</cell></row><row><cell>Set14 (2)</cell><cell cols="4">33.03/0.9124 33.08/0.9126 33.09/0.9129 34.04/0.9205</cell></row><row><cell>BSD100 (2)</cell><cell cols="4">31.90/0.8960 31.90/0.8956 31.92/0.8965 32.26/0.9006</cell></row><row><cell cols="5">Urban100 (2) 30.76/0.9140 30.75/0.9134 30.96/0.9169 32.63/0.9330</cell></row><row><cell>Average (2)</cell><cell cols="4">33.30/0.9202 33.31/0.9199 33.39/0.9212 34.25/0.9286</cell></row><row><cell>Set5 (3)</cell><cell cols="4">33.66/0.9213 33.73/0.9212 33.86/0.9228 34.45/0.9272</cell></row><row><cell>Set14 (3)</cell><cell cols="4">29.77/0.8314 29.83/0.8321 29.88/0.8331 30.56/0.8450</cell></row><row><cell>BSD100 (3)</cell><cell cols="4">28.82/0.7976 28.84/0.7976 28.86/0.7987 29.18/0.8071</cell></row><row><cell cols="5">Urban100 (3) 27.14/0.8279 27.15/0.8272 27.28/0.8334 28.50/0.8587</cell></row><row><cell>Average (3)</cell><cell cols="4">29.85/0.8445 29.89/0.8445 29.97/0.8470 30.67/0.8595</cell></row><row><cell>Set5 (4)</cell><cell cols="4">31.35/0.8838 31.40/0.8837 31.52/0.8864 32.23/0.8952</cell></row><row><cell>Set14 (4)</cell><cell cols="4">28.01/0.7674 28.07/0.7681 28.11/0.7699 28.80/0.7856</cell></row><row><cell>BSD100 (4)</cell><cell cols="4">27.29/0.7251 27.29/0.7247 27.32/0.7266 27.66/0.7380</cell></row><row><cell cols="5">Urban100 (4) 25.18/0.7524 25.21/0.7518 25.36/0.7614 26.42/0.7940</cell></row><row><cell>Average (4)</cell><cell cols="4">27.95/0.7821 27.99/0.7820 28.08/0.7861 28.78/0.8032</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc></figDesc><table><row><cell>Performance comparison in terms of luminance</cell></row><row><cell>PSNR/SSIM for various datasets in SISR tasks. The VDSR,</cell></row><row><cell>DnCNN-3, Proposed-P(primary) networks are 291 dataset[18]</cell></row><row><cell>luminance-trained network whereas the proposed network is</cell></row><row><cell>trained using RGB of DIV2K dataset. For fair comparison, re-</cell></row><row><cell>stored RGB was used to calculate the luminance PSNR/SSIM val-</cell></row><row><cell>ues.</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rademacher and Gaussian complexities: Risk bounds and structural results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="463" to="482" />
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nonlocal image and movie denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="139" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with BM3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.02848</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On learning optimized reaction diffusion processes for effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5261" to="5269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wavelet-based statistical signal processing using hidden Markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Crouse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="886" to="902" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<idno>1992. 3</idno>
	</analytic>
	<monogr>
		<title level="j">Ten lectures on wavelets</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">De-noising by soft-thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Persistent homologya survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemporary Mathematics</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="page" from="257" to="282" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aistats</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">275</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.05027</idno>
		<title level="m">Identity mappings in deep residual networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Single image super-resolution from transformed self-exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5197" to="5206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04587</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A wavelet tour of signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Academic press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Image denoising using very deep fully convolutional encoder-decoder networks with symmetric skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-B</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09056</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An iterative regularization method for total variationbased image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Modeling &amp; Simulation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="460" to="489" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Image denoising using scale mixtures of Gaussians in the wavelet domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The JPEG 2000 still image compression standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Skodras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Christopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal processing Magazine</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="36" to="58" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Telgarsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.04485</idno>
		<title level="m">Benefits of depth in neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Matconvnet: Convolutional neural networks for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM international conference on Multimedia</title>
		<meeting>the 23rd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Wavelets and subband coding. Number LCAV-BOOK-1995-001</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kovacevic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Beyond a Gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03981</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
