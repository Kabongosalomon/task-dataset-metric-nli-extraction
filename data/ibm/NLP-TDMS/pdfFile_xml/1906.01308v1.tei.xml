<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards better Validity: Dispersion based Clustering for Unsupervised Person Re-identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Ding</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenmin</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
						</author>
						<title level="a" type="main">Towards better Validity: Dispersion based Clustering for Unsupervised Person Re-identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>JOURNAL OF L A T E X CLASS FILES, VOL. XX, NO. X, AUGUST 2019 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-person re-identification</term>
					<term>neural networks</term>
					<term>clus- tering</term>
					<term>unsupervised learning</term>
					<term>self learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Person re-identification aims to establish the correct identity correspondences of a person moving through a nonoverlapping multi-camera installation. Recent advances based on deep learning models for this task mainly focus on supervised learning scenarios where accurate annotations are assumed to be available for each setup. Annotating large scale datasets for person re-identification is demanding and burdensome, which renders the deployment of such supervised approaches to realworld applications infeasible. Therefore, it is necessary to train models without explicit supervision in an autonomous manner.</p><p>In this paper, we propose an elegant and practical clustering approach for unsupervised person re-identification based on the cluster validity consideration. Concretely, we explore a fundamental concept in statistics, namely dispersion, to achieve a robust clustering criterion. Dispersion reflects the compactness of a cluster when employed at the intra-cluster level and reveals the separation when measured at the inter-cluster level. With this insight, we design a novel Dispersion-based Clustering (DBC) approach which can discover the underlying patterns in data. This approach considers a wider context of samplelevel pairwise relationships to achieve a robust cluster affinity assessment which handles the complications may arise due to prevalent imbalanced data distributions. Additionally, our solution can automatically prioritize standalone data points and prevents inferior clustering. Our extensive experimental analysis on image and video re-identification benchmarks demonstrate that our method outperforms the state-of-the-art unsupervised methods by a significant margin. Code is available at https: //github.com/gddingcs/Dispersion-based-Clustering.git.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-Person re-identification aims to establish the correct identity correspondences of a person moving through a nonoverlapping multi-camera installation. Recent advances based on deep learning models for this task mainly focus on supervised learning scenarios where accurate annotations are assumed to be available for each setup. Annotating large scale datasets for person re-identification is demanding and burdensome, which renders the deployment of such supervised approaches to realworld applications infeasible. Therefore, it is necessary to train models without explicit supervision in an autonomous manner.</p><p>In this paper, we propose an elegant and practical clustering approach for unsupervised person re-identification based on the cluster validity consideration. Concretely, we explore a fundamental concept in statistics, namely dispersion, to achieve a robust clustering criterion. Dispersion reflects the compactness of a cluster when employed at the intra-cluster level and reveals the separation when measured at the inter-cluster level. With this insight, we design a novel Dispersion-based Clustering (DBC) approach which can discover the underlying patterns in data. This approach considers a wider context of samplelevel pairwise relationships to achieve a robust cluster affinity assessment which handles the complications may arise due to prevalent imbalanced data distributions. Additionally, our solution can automatically prioritize standalone data points and prevents inferior clustering. Our extensive experimental analysis on image and video re-identification benchmarks demonstrate that our method outperforms the state-of-the-art unsupervised methods by a significant margin. Code is available at https: //github.com/gddingcs/Dispersion-based-Clustering.git.</p><p>Index Terms-person re-identification, neural networks, clustering, unsupervised learning, self learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The goal of the person re-identification (re-ID) is to find the correspondences of the same person across a system of nonoverlapping cameras. It has critical applications such as people tracking and mobility analysis in multi-camera streams. To this end, plenty of research work in recent years investigated supervised learning schemes, mainly leveraging on neural networks models, which led to remarkable performance gains <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. However, supervised learning requires large annotated datasets with manually labeled identities, which is a laborious undertaking for complex scenes. This motivated unsupervised <ref type="bibr">Guodong</ref>  approaches that are often based on handcrafted features <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>, saliency indicators <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> and sparsity constraints <ref type="bibr" target="#b12">[13]</ref>. These attempts, on the other hand, attain inferior performance compared to fully supervised models.</p><p>As an alternative, a variety of methods treats the person re-ID as an unsupervised domain adaptation task <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>. The main idea is first to learn an identity embedding using an auxiliary dataset where the ground truth labels are available, and later transfer these learned feature representations onto an unlabeled target dataset. However, this strategy relies on the premise that these two domains share the same identity label space. For person re-ID, this assumption does not always hold since the identities from two different datasets are usually disjoint.</p><p>Clustering based techniques have also been studied within the context of person re-ID. For instance, Fan et al. <ref type="bibr" target="#b13">[14]</ref> proposed pre-training a convolutional neural network (CNN) model on an external re-ID dataset where they apply k-means clustering on the features extracted from a target dataset to progressively select highly reliable data points for updating the model. One shortcoming of this approach is that the number of clusters, which dictates to the number of people, is preset and its right choice is unknown in the runtime.</p><p>Person re-ID methods based on clustering schemes often have a hierarchical nature, and some can also avoid the use of external datasets. As an example, the inspiring work in Lin et al. <ref type="bibr" target="#b16">[17]</ref> presented a bottom-up clustering (BUC) approach that alternatively trains a CNN model and performs merging without any dependence on auxiliary data samples. It uses the minimum distance between images in two clusters as the similarity measure for the merging operation. However, such a naive heuristic is suboptimal since it only considers one pair of images from two clusters discarding other potentially useful cues. This naive scheme may merge distinct identity groups by forming elongated clusters, which result in poor performance. Besides, it uses a diversity regularization term, which is defined as the number of samples in a cluster, to impose isometric clusters. In reality, data distribution over classes (identities) is usually imbalanced with a long tail; thus such a regularization term can be error-prone and invalid. To illustrate this issue, we show the number of samples per class on two re-ID datasets Market-1501 and DukeMTMC-reID in <ref type="figure" target="#fig_0">Fig. 1</ref>. As visible, the isometric cluster presumption does not hold for person re-ID scenarios.</p><p>We tackle this challenging problem by incorporating a cluster validity criterion. Cluster validity is a measure to assess the quality of clustering results. We consider a clustering to be valid if it satisfies two dispersion based properties. In statistics, arXiv:1906.01308v1 [cs.CV] 4 Jun 2019 dispersion is the extent to which a distribution is stretched or compressed; thus, it characterizes the clustering quality. Low intra-dispersion and high inter-dispersion are the indicators of valid and questionable clusters.</p><p>Motivated by this, we employ this elegant and straightforward criterion as our merging rule. It consists of two balancing objectives: an inter-cluster dispersion term and an intra-cluster dispersion term. The inter-cluster term quantifies the average linkage between the clusters while measuring their separation in a designated feature space; hence, the clusters with low dispersion are placed higher in the merging list. We empirically show that the average linkage models a broader context, which makes it superior to single linkage strategy used in <ref type="bibr" target="#b16">[17]</ref>. The intra-cluster term evaluates the compactness of candidate clusters and serves as a regularizer complementing the former term. Different from <ref type="bibr" target="#b16">[17]</ref>, which considers a cluster size constraint, we note that the number of samples should not be the primary concern as long as they are close enough to be considered as the same identity. As such, the intra-dispersion also helps to bypass the potential class imbalance issue.</p><p>In addition to introducing the above dispersion based criterion, we employ an agglomerative and alternating learning procedure tailored for the person re-ID task. The images of people moving in a non-overlapping multi-camera system typically constitute compact clusters according to their identities and acquisition conditions for each camera. However, viewpoint variations cause significant intra-class variations alongside. To address this challenge, we exploit a feature learning framework that trains CNN models and performs clustering in an alternating fashion. For CNN model training, we utilize the repelled loss that can incorporate both interclass and intra-class variances to obtain invariant feature representations. With one accord, our clustering reduces intracluster dispersion while maximizing inter-cluster dispersion. The resulting clusters attain more refined structures, which further enhances the representation capability of the CNN model. Therefore, CNN model training and clustering leverage each other in a reciprocal exchange.</p><p>The cluster dispersion term brings two significant advantages to our approach. It allows automatically prioritizing singletons and preventing inadequate clustering. Singleton refers to a cluster with only one sample. Ideally, in a multi-camera system designed to re-identify people, a singleton cluster should not exist. Our approach selectively assigns a higher priority to a singleton cluster when the candidate clusters have equal inter-dispersion since a singleton has no intra-dispersion. Our criterion also minimizes potentially incorrect decisions of the agglomerative merging steps by deferring high intradispersion clusters form merging.</p><p>Our contributions are three-fold:</p><p>• We propose to use cluster validity as the guidance and derive a dispersion based criterion which promotes compact and well-separated clusters. • The proposed criterion automatically handles singleton cluster problem and can prevent poor clusters. Furthermore, our approach has a faster learning speed and is more stable than its counterpart BUC <ref type="bibr" target="#b16">[17]</ref>. • The experimental results demonstrate that our approach outperforms the state-of-the-art unsupervised methods on both image-based and video-based re-ID datasets by a significant margin. The remainder of this paper is organized as follows. In Section II, we review related work. In Section III, we provide details of our proposed unsupervised approach with cluster dispersion followed by a discussion on why DBC works better. Section IV demonstrates the effectiveness of proposed approach on both image-based and video-based person re-ID datasets along with an extensive ablation study. We conclude our work in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Top-performing deep architectures are trained on massive amounts of labeled data. Most existing re-ID models are trained with human annotated ID labels in a supervised mode. Therefore, their deployment in real-world applications is usually hindered by lack of large-scale annotated training sets. To learn models without explicit supervision has therefore been extensively studied in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Traditional Unsupervised Solutions</head><p>Some unsupervised methods with hand-crafted features have been proposed in recent years <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref>. However, they achieve inadequate re-ID performance when compared to the supervised learning methods. Specifically, Farenzena et al. <ref type="bibr" target="#b7">[8]</ref> exploited the property of symmetry in person images to deal with view variances. To handle the illumination changes and cluttered background, Ma et al. <ref type="bibr" target="#b25">[26]</ref> proposed to combine the Gabor filters and the covariance descriptor. Fisher Vector is explored in <ref type="bibr" target="#b26">[27]</ref> to encode higher order statistics of local features. Kodvirov et al. <ref type="bibr" target="#b12">[13]</ref> proposed to combine a laplacian regularization term with conventional dictionary learning formulation to encode cross-view correspondences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unsupervised Domain Adaption</head><p>In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain is available. A main practice for adaptation is to align the feature <ref type="figure">Fig. 2</ref>. The overall framework for the unsupervised learning. The left part shows the iterative process of our approach. The framework first extracts image features with a CNN model, then clustering is performed by the feature similarities and lastly image labels are updated with new cluster set to retrain the feature extractor. After the training is finished, the CNN extracts features on both query and gallery samples and then performs a distance based retrieval. The right part exhibits two properties of our dispersion criterion. (a) Singleton cluster priority. In this case, green sample is merged with black sample as it has less (zero) dispersion compared with that of orange cluster. (b) Poor clustering prevention. We consider a cluster poorly merged when it has high dispersion.</p><p>The blue cluster is prevented from merging with brown because the resulting cluster would have a high dispersion. Instead the brown cluster is merged with the green one which together have less intra-dispersion. (Best viewed in color) distribution between the source and target domain <ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref>. Likewise, some unsupervised cross-domain transfer learning methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33]</ref> have been studied in the field of person re-ID to deal with the misalignment between identities among different datasets. To better bridge this gap, Wang et al. <ref type="bibr" target="#b33">[34]</ref> first train with attributes on source domain and then learn a joint feature representation of both identity and attribute. A hetero-homogeneous learning approached is introduced in <ref type="bibr" target="#b34">[35]</ref> to align domain distributions. Another stream of work uses generative adversarial networks (GAN) to generate augmented images to reduce the dataset differences <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">33]</ref>. Deng et al. <ref type="bibr" target="#b15">[16]</ref> explored image self-similarity and cross-domain dissimilarity for a target domain image translation. Differently, Zhong et al. <ref type="bibr" target="#b32">[33]</ref> exploited camera-to-camera alignment to perform image translation. These domain adaptation methods are all focused on the label estimation of target domain. One can see that the success of this category of approaches is based on an auxiliary labeled dataset. Compared to them, the unsupervised learning approach in this paper does not use any external data or annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Clustering Analysis</head><p>Clustering analysis is a long-standing approach to unsupervised machine learning. With the surge of deep learning techniques, recent studies have attempted to optimize clustering analysis and representation learning jointly for maximizing their complementary benefits <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref>. Fan et al. <ref type="bibr" target="#b13">[14]</ref> combines domain transfer and clustering for unsupervised re-ID task. They first train the model on an external labeled dataset which is used as a good model initialization. After that, unlabeled data samples are progressively selected for training according to their credibility defined as their distance to cluster centroids. However, this work relies on a strong assumption about the total number of identities. Aside from these methods that require auxiliary datasets or assumptions, Lin et al. <ref type="bibr" target="#b16">[17]</ref> proposed to apply a bottom-to-up framework for clustering, which hierarchically combines clusters according to a predefined criterion. The merging in <ref type="bibr" target="#b16">[17]</ref> is based on a very simple minimum distance criterion with a cluster size regularization term. Different from their work, our dispersion criterion exploits feature affinities within and between clusters, which also has mutual interaction with the CNN model training process to reciprocate the model strength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CLUSTER DISPERSION CRITERION</head><p>In this section, we start with some preliminaries followed by our proposed criterion described in detail, and end with discussions and comparisons with close work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preliminaries</head><p>Given an unlabeled training set D = {x i } N i=1 containing N cropped person images, we aim to learn a feature embedding function φ(x i ; θ) from D without any available annotations. The parameters θ are optimized iteratively using an objective function. This feature extractor can be later applied to the gallery set {x g i } Ng i=1 and the query set</p><formula xml:id="formula_0">{x q i } Nq i=1</formula><p>to obtain their feature representations for a distance based retrieval. The distance between each pair of images is defined as,</p><formula xml:id="formula_1">dist(x q i , x g i ) = φ(x q i ; θ) − φ(x g i ; θ)</formula><p>. For a higher distance based rank of a given pair, it is more likely that the pair belongs to the same identity.</p><p>Supervised learning provides person identity labels y i for each input image x i , and the feature embedding function is appended by a classifier f (φ; w) parameterized by w. Thus, φ(; θ) can be learnt by optimizing the following objective function:</p><formula xml:id="formula_2">min θ,w N i=1 l(f (φ(x q i , θ); w), y i )<label>(1)</label></formula><p>where l is the cross-entropy (CE) loss for classification. One shortcoming of CE loss is it does not explicitly minimizes the intra-class distances. To this end, center loss is proposed that seeks to achieve within class compactness. Similar to center loss <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>, repelled loss <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b41">42]</ref> can act as a classifier f which has the ability to jointly consider inter-class and intra-class variances by computing probability based on the feature similarity as follows:</p><formula xml:id="formula_3">p(y|x, V ) = exp(V T y v/τ ) Σ N j=1 exp(V T j y/τ ) ,<label>(2)</label></formula><p>where τ is a temperature parameter that controls the softness of probability distribution over classes, v is the l 2 normalized image feature obtained from φ(x; θ), while V is a lookup table (LUT) containing the centroid feature of each class. This LUT is updated on the fly by exponential moving average <ref type="bibr" target="#b42">[43]</ref> over training iterations, thus avoiding exhaustive feature extraction that is more computation intensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Validity Guided Dispersion Criterion</head><p>The main challenge towards using the above framework for an unsupervised setting lies in automatic label assignment for unlabeled data. Here, clustering comes as a natural choice as it aims to group similar entities together. In this paper, we propose a novel dispersion based agglomerative clustering approach based on a cluster validity consideration. The choice of affinity/dissimilarity measure between two clusters is the key to our proposed algorithm. In the task of person re-ID, which focuses on identifying images of the same identity, the inter and intra-cluster similarity should be considered for a reasonable merging. This requisite is fulfilled by a novel merging criterion used in our agglomerative clustering approach.</p><p>Given a cluster C scattered in feature space, we define its dispersion d(C) as the average pairwise distance within:</p><formula xml:id="formula_4">d(C) = 1 n i,j∈C dist(C i , C j ),<label>(3)</label></formula><p>where n is the cardinality of cluster C. As such, the dispersion between clusters can be written as follows:</p><formula xml:id="formula_5">d(C a , C b ) = 1 n a n b i∈Ca,j∈C b dist(C ai , C bj )<label>(4)</label></formula><p>To jointly consider both intra-and inter-cluster dispersion, we have the dissimilarity between clusters C a and C b formulated as:</p><formula xml:id="formula_6">D ab = d ab + λ(d a + d b )<label>(5)</label></formula><p>where d ab and d a are used in place of d(C a , C b ) and d(C a ) for notation simplicity, and λ is the trade-off parameter between two components. The former component d ab in Eq. (5), dispersion between clusters, is a measure for cluster dissimilarity. A cluster with low dispersion should be considered for merging as features from the same identity should be close in the feature space. The later component d a + d b , which is the sum of dispersion of both candidate clusters, serves as a regularizer to the former component. On one hand, it can help prioritize standalone data points for merging at the starting stages. On the other</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Dispersion based Clustering Algorithm</head><p>Input: hand, this term can prevent escalating "poor" clustering as the high dispersion within-cluster can overbalance the inter-cluster term. In fact, this candidate cluster selection strategy controls the trade-off between the tendency to select spatially closer clusters (λ → 0) or more compact clusters (λ → +∞).</p><formula xml:id="formula_7">Training data D = {x i } N i=1 , merging percentage m ∈ (0, 1), trade-off parameter λ, CNN model φ(·, θ 0 ) Output: Optimized model φ(·;θ) Initialize label Y = {y i = i} N i=1 , Cluster number C = N , merge batch k = N * m while C &gt; k do</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Matrix Update</head><p>Proposed dispersion criterion can be calculated with a matrix updating algorithm. The input to this clustering process is the dissimilarity matrix P(C), also referred as the proximity matrix. It is a C × C matrix whose (i, j) th element equals the inter cluster dispersion d(C i , C j ) between C i and C j . P(C) can be efficiently computed by first calculating an image pairwise distance matrix which is the outer product of stacked feature vectors obtained from deep networks and then aggregate them by cluster IDs.</p><p>At each clustering step, when two candidate clusters selected by Eq. (5) are merged, the size of dissimilarity matrix P becomes (C − 1) × (C − 1). In one operation, two rows and columns of corresponding merged clusters C a and C b are deleted and a new row and a new column are added that contain the updated dissimilarity between the newly formed cluster C q and an old cluster C s . The dissimilarity between C q and C s can be found using our dispersion definition, as follows:</p><formula xml:id="formula_8">d qs = n a n a + n b d as + n b n a + n b d bs .<label>(6)</label></formula><p>Correspondingly, the intra-cluster dispersion of the newly formed cluster C q is written as: </p><formula xml:id="formula_9">d q = n a d a + n b d b + n a n b d ab n a + n b + n a n b .<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Learning Paradigm</head><p>The overall learning paradigm with proposed criterion is presented as the left part in <ref type="figure">Fig. 2</ref>, where two stages, i.e., embedding learning and clustering, take place on an alternating basis. This paradigm initiates with the embedding learning stage where each data point x i assigned a unique label y i and the CNN model is trained for a few epochs to learn the mapping. This choice of considering every single sample as an independent class is often referred as 'sample specificity learning'. The key idea is that even with this naive supervision, neural networks still can automatically reveal the visual similarity correlation between different classes and yield a decent CNN initialization.</p><p>In between embedding learning is the clustering stage. We consider a clustering stage to have k steps, where top-k cluster pairs with least dissimilarity defined by Eq. (5) are to be merged. The k is defined as the product k = m * N , controlled by a merging percent parameter m (set of 0.05 percent of total number of samples in our experiments). After each step, the proximity matrix P(C) is updated with Eq. (6) and Eq. (7) introduced above. Before entering the next stage of CNN model training, samples in the entire training set are designated new labels according to their belonging to the resulting clusters as follows:</p><formula xml:id="formula_10">Y = {y i = j, ∀x i ∈ C j } N i=1 .<label>(8)</label></formula><p>The whole training procedure of our unsupervised person re-ID learning is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Complexity Analysis</head><p>We analyze the per-stage complexity cost induced by the new criterion. For a clustering stage which performs k merging operations, the computation complexity for image pairwise distance computation is O(N 2 ) and O(C 2 ) for cluster pairwise dissimilarity calculation. Afterwards, a cost of O(C log C) is required for ranking and candidate selection. Lastly, a cost of O(kC) for k step merging and proximity matrix update is incurred. So the total computation complexity for the whole stage comes together to O(N 2 +C 2 +C log C+kC). Notice that since the cluster number C decreases as the learning paradigm progresses, the computation complexity also decreases. Accordingly, the overall complexity is O(N 2 ), which means the main complexity comes from the inevitable sample-wise similarity calculation. All operations mentioned above can be computed by matrix manipulation on GPUs and one can use multiple GPUs for acceleration since our algorithm is suitable for parallelism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Discussion.</head><p>The regularization term. The combination of the second component in Eq. <ref type="bibr" target="#b4">(5)</ref> brings two advantages to the clustering process stated as follows:</p><p>1) Singleton cluster priority. Recall that each sample is assigned a unique label in the first round of CNN training in Sec III-D, yielding all singleton clusters, i.e., clusters with only a single sample. However, the intrinsic matching and association property of the re-ID task requires that there exists at least two samples for a given identity. Therefore, singleton clusters cannot emerge during clustering by the problem definition and must be explicitly taken care of. Importantly, they should be dealt with at the first few clustering stages as they may be further pushed away from points of their own identity as the CNN is trained to separate them. The priority shifting happens when two merging options have identical inter dispersion d ab , consequently the standalone data point with less (zero) intra-cluster dispersion (d a = 0 or d b = 0) gets promoted. An illustration can be found in <ref type="figure">Fig. 2(a)</ref>.</p><p>2) Poor clustering prevention. One disadvantage of the nesting property of agglomerative clustering is that there is no way to recover from a 'poor' clustering that may have occurred in previous levels of the hierarchy <ref type="bibr" target="#b47">[48]</ref>. The addition of the regularization term helps to avoid this. Consider the case where a poor cluster formed in previous merging step, the high intra-cluster dispersion would prevent it from being selected for merging in the following turns, albeit it may have high rankings in intra-cluster dispersion based merging list. An illustration can be found in <ref type="figure">Fig. 2(b)</ref>, brown cluster is merged with more distanced green cluster for their lower intradispersion.</p><p>Comparison with close work. Our work shares a similar spirit as that of Bottom-up Clustering (BUC) <ref type="bibr" target="#b16">[17]</ref> and adopts an agglomerative clustering framework for the task of unsupervised person re-ID. We differ substantially in terms of cluster merge criterion. On one hand, Lin et al. <ref type="bibr" target="#b16">[17]</ref> adopted minimum distance between cross cluster samples to measure their dissimilarity. It is known that the single linkage algorithm has a chaining effect, i.e., the dissimilarity d qs is obtained from d as and d bs whichever is smaller (d qs = min{d as , d bs }). This implies it has a tendency to favor elongated clusters. Stretched clusters may hinder next iteration of model training with repelled loss which favours compact groups. On the other hand, based on the presumption that training samples are evenly distributed among identities, Lin et al. <ref type="bibr" target="#b16">[17]</ref> proposed to use cluster cardinality as a diversity regularization term, however, this is also error-prone. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, the equal distribution of identity samples can hardly be assured in person re-ID. In contrast, our criterion works on the pairwise distance between individual data point which exploits the intra-cluster relations and bypasses the imbalanced data situation. Also, our criterion formulation can help in forming compact and well-separated clusters, which serves the same purpose as the repelled loss used in CNN model training. Two alternating stages pursuing the same goal of lower intra-cluster variation and higher inter-cluster separation form a reciprocal effect and speeds up the training process. The superiority of our proposed cluster dispersion criterion is evidenced through the numeric results provided in Sec. IV-D. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we perform experiments on four large-scale person re-ID datasets to evaluate the effectiveness of our proposed approach. MARS <ref type="bibr" target="#b45">[46]</ref> is a large-scale video-based dataset for person re-ID, which contains 17,503 video clips of 1,261 identities. The training set comprises of 625 identities while testing set comprises 636 identities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Market</head><p>DukeMTMC-VideoReID <ref type="bibr" target="#b46">[47]</ref> is a large-scale video-based dataset for person re-ID derived from DukeMTMC dataset. It has 2,196 tracklets of 702 identities for training, 2,636 tracklets of 702 identities for testing.</p><p>We list the statistics and some samples of these four datasets in <ref type="table" target="#tab_2">Table I</ref> and <ref type="figure" target="#fig_1">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Protocols</head><p>Training. To perform unsupervised learning on above mentioned person re-ID datasets, the training protocols are changed as described next. For image-based datasets, i.e., Market1501 and DukeMTMC-reID, training split remains the same except for the removal of identity labels. Similarly, for video-based datasets, i.e., MARS and DukeMTMC-VideoReID, the training samples are the tracklets of identities and each tracklet is treated as an individual. Note that no extra annotation information are used for model initialization or during our unsupervised feature learning.</p><p>Testing. When training is done, the CNN model with trained parameters is used as the feature extractor. The output activations from the penultimate layer of ResNet-50 are used as the person descriptor for image inputs, while the person descriptor for a tracklet input is the average of its frame features. These person descriptors are then used for a Euclidean distance based retrieval.</p><p>Evaluation Metrics. We evaluate our methods with rankk accuracy and mean average precision (mAP) on all four datasets. The rank-k accuracy means that the correct match gets to be in the top-k ranked list to count as 'correct'. It represents the retrieval precision. The mAP value reflects the overall precision and recall rates. These two metrics provide a more comprehensive evaluation of the approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation details</head><p>In our experiments, we conventionally adopt ResNet-50 <ref type="bibr" target="#b50">[51]</ref> as the backbone architecture with pre-trained weights on ImageNet <ref type="bibr" target="#b51">[52]</ref>. A two layer fully connected layer is added on top of the penultimate layer (2048-d) of ResNet-50 for smaller feature embedding (1024-d). The last classification layer is replaced by the implementation of Eq. (2) with varying cluster numbers. All datasets share the exact same set of hyper-parameters if not specified. For CNN model training, we set the total training epoch is to be 20, batch size to be 16, dropout rate to be 0.5. The CNN model is optimized by Stochastic Gradient Descent (SGD) with momentum set to 0.9. Learning rate for parameters is initialized to 0.1 and decreased to 0.01 after 15 epochs. For clustering stages, the batch merging parameter m is set to be 0.05 and the trade-off parameter λ in Eq. (5) is set to be 0.5. On image-based re-ID datasets, i.e., Market-1501 and DukeMTMC-reID, the whole training process takes less than 3 hours to finish with a Tesla V100 GPU. For video-based re-ID datasets, i.e., MARS and DukeMTMC-VideoReID, it takes about 4 hours for complete training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablation Study</head><p>We evaluate the effectiveness of our proposed clustering criterion on all datasets and <ref type="table" target="#tab_2">Table II</ref> summarizes the numerical results.</p><p>The effectiveness of the inter-cluster dispersion term. We evaluate the effectiveness of our inter-cluster dispersion term by comparing to a very close work BUC <ref type="bibr" target="#b16">[17]</ref>. For fair comparison, we report results of BUC without its size regularization term in the first row of <ref type="table" target="#tab_2">Table II and our proposed  TABLE II  THE EFFECTIVENESS OF OUR DISPERSION BASED CRITERION AND COMPARISON WITH MINIMUM DISTANCE CRITERION.THE REGULARIZATION TERMS  ARE CLUSTER SIZE IN BUC AND INTRA-</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Venue Labels</head><p>Market-1501 DukeMTMC-reID rank-1 rank-5 rank-10 mAP rank-1 rank-5 rank-10 mAP BOW <ref type="bibr" target="#b43">[44]</ref> ICCV   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Venue Labels MARS DukeMTMC-VideoReID rank-1 rank-5 rank-10 mAP rank-1 rank-5 rank-10 mAP OIM <ref type="bibr" target="#b41">[42]</ref> CVPR criterion without intra regularization is shown in the third row. It can be observed that, across all four datasets, our method outperforms BUC by a large margin of around 6% in rank-1 accuracy and 7% in mAP. This performance gain comes solely from the difference in cluster linkage criterion. Single linkage based minimum distance criterion essentially forms stretched and elongated clusters. While ours average pairwise distance has the capability to take into consideration wider context. This type of full linkage algorithm better discovers patterns underlying the dataset. Notably, our model without the second term manages to achieve comparable results to that of full BUC model (second row).</p><p>The effectiveness of the intra-cluster dispersion term. We further study the effects of the intra-cluster dispersion regularization term. Results of our full model can be found in the fourth row. The numerical increase indicates that the regularization term is helpful to further boost the performance. On Market-1501, the rank-1 accuracy is increased from 66.2% to 69.2% and mAP from 38.7% to 41.3%. Similar trend is observed across all datasets which advocates its effectiveness.</p><p>The alliance of intra and inter dispersion in the full model can lead to a better feature representation learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Algorithm Analysis</head><p>Analysis on the trade-off parameter. The regularization parameter λ in Eq. (5) balances the importance of the intracluster and inter-cluster dispersion. We report results on Market-1501 dataset with varying λ values in <ref type="figure" target="#fig_4">Fig. 4</ref>. It can be seen that the rank-1 accuracy first increases to its peak when λ = 0.1 and then experiences a decline as shown in <ref type="figure" target="#fig_4">Fig. 4(a)</ref>. A similar trend can be also found for mAP scores given in <ref type="figure" target="#fig_4">Fig. 4(b)</ref>. It is plausible since this parameter can be interpreted as the preference in candidate cluster selection which emphasizes more on selecting clusters that are spatially close in feature space when λ is relatively small, but more on selecting compact candidates as λ increases. The best performance with λ = 0.1 resonates with the empirical evidence that the inter dispersion should be the main clustering indicant coupled with reasonable regularization. Robustness. We further provide an analysis on the performance change over clustering iterations throughout the learning process to study its learning speed and robustness. Performance change with regards to clustering stages is shown in <ref type="figure" target="#fig_5">Fig. 5</ref>. One can see that we achieved best rank-1 accuracy at the 12 th clustering stage, one stage ahead of BUC. On DukeMTMC-VideoReID, one stage comprised of 100 pairs of merging; while on DukeMTMC-reID, one stage later convergence equates to 800+ more merging operations. This indicates that our algorithm has faster learning speed.</p><p>It can also be observed that the performances from both approaches intertwined with each other before the 11 th clustering stage but diverged afterwards, with ours outperforming BUC by a relatively large margin. The tangled stages are the beginning stages where smaller clusters are being formed, progressively building up trustworthy identities and stimulating stable performance increase. After that, the algorithms started merging larger-sized clusters, during which inaccurate cluster merging could have a big influence on the performance. Those performance differences in the figure basically demonstrate the superiority of our approach. Another noticeable fact is that the performance of BUC dropped immediately after its peak while ours remained at the same level for few following stages before its decline. This phenomenon exhibited that our algorithm have better robustness to the resulting clustering numbers.</p><p>Finally, the performance decline in the last few stages for both approaches is caused by the over-clustering of images from distinct identities since the resulting cluster number is far less than ground-truth identity number. <ref type="figure">Fig. 6</ref>. Qualitative illustration of clustering on a reduced training set sampled from Market-1501 (100 identities, 1,657 images). T-SNE is adopted to visualize feature embeddings. Same color denotes same identity. The circled regions show two clustering cases i.e., negative (on left) and positive (on right) merging. We also show identity samples pointed by an arrow. For the negative sample, it can be seen that two visually alike person are merged together.</p><p>Qualitative Analysis. We further provide a qualitative analysis to gain a better understanding of the clustering results by our proposed approach. In <ref type="figure">Fig 6</ref>, T-SNE <ref type="bibr" target="#b52">[53]</ref> is used to visualize the clustering results on a reduced dataset, which contains 1,657 images of 100 identities randomly sampled from Market-1501. It can be seen that in most cases, samples from the same identity are group together (see collections of same colored points). At the same time, there are some incorrect merging of identities. For example, see bottom left box in <ref type="figure">Fig 6</ref> where two ladies with similar appearance (white t-shirts and dark sports wear) are clustered together. This highlights the fact that visually alike identities are very difficult to disambiguate without any supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Comparison with state-of-the-art</head><p>We evaluate our approach on both image-based and videobased person re-ID datasets and numerical results are reported in <ref type="table" target="#tab_2">Table III and Table IV,</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>respectively.</head><p>Image-based Person re-ID. <ref type="table" target="#tab_2">Table III</ref> summarizes the stateof-the-art unsupervised person re-ID results on Market-1501 and DukeMTMC-reID datasets. On Market-1501, we achieve the best performance among all listed approaches with rank-1 = 69.2%, mAP = 41.3%. Among the compared methods, OIM <ref type="bibr" target="#b41">[42]</ref> and BUC <ref type="bibr" target="#b16">[17]</ref> are evaluated under the fully unsupervised setting. It can be seen that our approach outperforms the stateof-the-art BUC by a margin of 3%. Similar performance improvements can be observed on the DukeMTMC-reID dataset.</p><p>Performance of some domain adaption and one-shot learning approaches are also reported, e.g. TJ-AIDL <ref type="bibr" target="#b33">[34]</ref> and EUG <ref type="bibr" target="#b46">[47]</ref>. TJ-AIDL <ref type="bibr" target="#b33">[34]</ref> trains with attribute labels to learn a robust embedding encoding extra attribute information which is transferable, while EUG <ref type="bibr" target="#b46">[47]</ref> initializes model with one example labels and then progressively selects samples for training. In our experiment, we still surpass them by a relatively large margin (11% and 13.4% in rank-1 accuracy) even though external supervisions are provided in their settings.</p><p>Video-based Person re-ID. The comparisons with stateof-the-art algorithms on video-based person re-ID datasets, MARS and DukeMTMC-VideoReID are reported in <ref type="table" target="#tab_2">Table IV</ref>. On DukeMTMC-VideoReID, we achieved rank-1=75.2%, mAP=66.1%, exceeding our competitor BUC <ref type="bibr" target="#b16">[17]</ref> by 6% and 4.2% in rank-1 accuracy and mAP, respectively. This demonstrates a more stable generalization ability of our proposed clustering algorithm to different data distributions. We also managed to outperform all other competitive methods on MARS dataset with rank-1=64.3%, mAP=43.8%. These results illustrate the effectiveness of our proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we highlight the importance of quantifying cluster validity using robust statistical measures. We consider the problem of unsupervised person re-ID and propose a dispersion based criterion to assess the quality of automatically generated clusters. On one hand, the proposed criterion considers both intra-and inter-cluster dispersion and can achieve better clustering. The former dispersion term enforces compact clusters, while the latter ensures the separation between them. On the other hand, the proposed criterion can handle singleton clusters and prevent poor clustering. The overall extensive performance evaluations and ablation study illustrates the effectiveness of our proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The number of classes vs. the number of images per class for Market-1501 and DukeMTMC-reID datasets. The distributions are imbalanced, which is common for person re-ID scenarios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Examples of person images from Market-1501, DukeMTMC-reID, MARS and DukeMTMC-VideoReID.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>III COMPARISON WITH THE STATE-OF-THE-ART METHODS ON TWO IMAGE-BASED LARGE-SCALE RE-ID DATASETS. THE COLUMN "LABELS" LISTS THE SUPERVISION USED BY THE CORRESPONDING METHOD. "TRANSFER" MEANS IT USES AN EXTERNAL DATASET WITH ANNOTATIONS. "ONEEX" DENOTES THAT ONLY ONE IMAGE OF EACH IDENTITY IS LABELED. "NONE" DENOTES NO EXTRA INFORMATION IS USED.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>IV RESULTS ON TWO VIDEO-BASED PERSON RE-IDENTIFICATION DATASETS, MARS AND DUKEMTMC-VIDEOREID. THE COLUMN "LABELS" LISTS THE SUPERVISION USED BY THE CORRESPONDING METHOD. "ONEEX" DENOTES THE EACH PERSON IN THE DATASET IS ANNOTATED WITH ONE LABELED EXAMPLE. "NONE" DENOTES NO EXTRA INFORMATION IS USED.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>(a) Rank-1 accuracy (b) mAP scores Parameter study on Market-1501. We set varying values for trade-off parameter λ and report Rank-1 accuracy and mAP changes in (a) and (b), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>The rank-1 accuracy performance with respect to clustering stages on DukeMTMC-VideoReID. Our proposed criterion demonstrates a faster learning process and better robustness to cluster numbers, compared to BUC<ref type="bibr" target="#b16">[17]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Ding and Zhenmin Tang are with the School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China. e-mails: guodong.ding@njust.edu.cn and tzm.cs@njust.edu.cn. Salman Khan is with the College of Engineering and Computer Science, Australian National University, Australia. e-mail: salman.khan@anu.edu.au Jian Zhang is with the School of Electrical and Data Engineering, University of Technology Sydney, Australia. e-mail: jian.zhang@uts.edu.au Fatih Porikli is with the Research School of Engineering, Australian National University, Australia. e-mail: fatih.porikli@anu.edu.au</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Train model with {x i } and {y i } with Eq.</figDesc><table><row><cell>(1)</cell></row><row><cell>Calculate cluster dissimilarity matrix P(C)</cell></row><row><cell>for 1:k do</cell></row><row><cell>Select candidate clusters according to Eq. (5) and</cell></row><row><cell>merge them</cell></row><row><cell>Update matrix P(C) with Eq. (6) and Eq. (7)</cell></row><row><cell>C ← C − 1</cell></row><row><cell>end for</cell></row><row><cell>Update Y with new cluster C using Eq. (8)</cell></row><row><cell>Evaluate Performance P erf on validation set.</cell></row><row><cell>if P erf &gt; P erf</cell></row></table><note>* then P erf* = P erf Best model = φ(·;θ) end if end while</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I STATISTICS</head><label>I</label><figDesc>OF FOUR DATASETS USED IN OUR EXPERIMENT SETTINGS. "# SAMPLES" STANDS FOR THE NUMBER OF IMAGES FOR IMAGE-BASED DATASETS AND NUMBER OF TRACKLETS FOR VIDEO-BASED DATASETS.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Training</cell><cell></cell><cell cols="2">Testing</cell><cell></cell></row><row><cell>Dataset</cell><cell>Category</cell><cell cols="2"># ID # Samples</cell><cell cols="2">Query # ID # Samples</cell><cell># ID</cell><cell>Gallery # Samples</cell></row><row><cell>Market-1501 [44]</cell><cell>Image-based</cell><cell>751</cell><cell>16,522</cell><cell>750</cell><cell>3,368</cell><cell>750</cell><cell>19,732</cell></row><row><cell>DukeMTMC-reID [45]</cell><cell>Image-based</cell><cell>702</cell><cell>16,522</cell><cell>702</cell><cell>2,228</cell><cell>1,110</cell><cell>17,661</cell></row><row><cell>MARS [46]</cell><cell>Video-based</cell><cell>625</cell><cell>8,298</cell><cell>626</cell><cell>1,980</cell><cell>636</cell><cell>12,180</cell></row><row><cell>DukeMTMC-VideoReID [47]</cell><cell>Video-based</cell><cell>702</cell><cell>2,196</cell><cell>702</cell><cell>702</cell><cell>801</cell><cell>2,636</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>-1501 [44] consists of 1,501 identities and 32,688 labeled images, among which 12936 images of 751 identities are used for training and 19,732 images of 750 identities are used for testing. DukeMTMC-reID [45] contains 36,411 labeled images of 1,404 identities. Similar to Market1501, 702 identities are used for training and remaining identities as testing. Specifically, 16,522 training images, 2,228 query images and 17,661 gallery images.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>CLUSTER DISPERSION IN OURS.</figDesc><table><row><cell>Methods</cell><cell cols="2">Market-1501 rank-1 mAP</cell><cell cols="2">DukeMTMC-reID rank-1 mAP</cell><cell cols="2">MARS rank-1 mAP</cell><cell cols="2">DukeMTMC-VideoReID rank-1 mAP</cell></row><row><cell>BUC w/o regularization [17]</cell><cell>62.9</cell><cell>33.8</cell><cell>41.3</cell><cell>22.5</cell><cell>55.5</cell><cell>31.9</cell><cell>60.7</cell><cell>50.8</cell></row><row><cell>BUC with regularization[17]</cell><cell>66.2</cell><cell>38.3</cell><cell>47.4</cell><cell>27.5</cell><cell>61.1</cell><cell>38.0</cell><cell>69.2</cell><cell>61.9</cell></row><row><cell>Ours w/o regularization</cell><cell>66.2</cell><cell>38.7</cell><cell>48.2</cell><cell>27.5</cell><cell>59.8</cell><cell>37.2</cell><cell>71.8</cell><cell>63.2</cell></row><row><cell>Ours with regularization</cell><cell>69.2</cell><cell>41.3</cell><cell>51.5</cell><cell>30.0</cell><cell>64.3</cell><cell>43.8</cell><cell>75.2</cell><cell>66.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Person re-identification with metric learning using privileged information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="791" to="805" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pamm: Pose-aware multi-shot matching for improving person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3739" to="3752" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning view-specific deep networks for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3472" to="3483" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Part-aligned bilinear representations for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Svdnet for pedestrian retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spindle net: Person re-identification with human body region guided feature decomposition and fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Point to set similarity based deep feature learning for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Person re-identification by symmetry-driven accumulation of local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farenzena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Person re-identification by local maximal occurrence representation and metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Person re-identification by iterative re-weighted sparse ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lisanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1629" to="1642" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised salience learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised learning of generative topic saliency for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dictionary learning with iterative laplacian regularisation for unsupervised person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised person re-identification: Clustering and fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Multimedia Comput., Commun. Appl</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">83</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised cross-dataset transfer learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A bottom-up clustering approach to unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised data association for metric learning in the context of multi-shot person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bremond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AVSS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Person reidentification by unsupervised l1 graph learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stepwise metric promotion for unsupervised video person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Person re-identification by unsupervised video matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-M</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="197" to="210" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards unsupervised open-set person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic graph co-matching for unsupervised video-based person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Person re-identification by saliency learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Oyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="356" to="370" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep representation learning with part loss for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bicov: a novel image representation for person re-identification and face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Local descriptors encoded by fisher vectors for person re-identification</title>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Return of frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Camstyle: a novel data augmentation method for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1176" to="1190" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Transferable joint attribute-identity deep learning for unsupervised person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Generalizing a person retrieval model hetero-and homogeneously</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Feature affinity based pseudo labeling for semi-supervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Joint detection and identification feature learning for person search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Exponentially weighted moving average control schemes: properties and enhancements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Saccucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unlabeled samples generated by gan improve the person re-identification baseline in vitro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mars: A video benchmark for large-scale person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Progressive learning for person re-identification with one example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A comparison of some methods of cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Gower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="page" from="623" to="637" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Robust anchor embedding for unsupervised video person re-identification in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep association learning for unsupervised video person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in BMVC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
