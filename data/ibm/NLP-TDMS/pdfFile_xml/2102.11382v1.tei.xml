<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sandwich Batch Normalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
						</author>
						<title level="a" type="main">Sandwich Batch Normalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Codes are available at https://github.com/VITA-Group/Sandwich-Batch-Normalization.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present Sandwich Batch Normalization (SaBN), an embarrassingly easy improvement of Batch Normalization (BN) with only a few lines of code changes. SaBN is motivated by addressing the inherent feature distribution heterogeneity that one can be identified in many tasks, which can arise from data heterogeneity (multiple input domains) or model heterogeneity (dynamic architectures, model conditioning, etc.). Our SaBN factorizes the BN affine layer into one shared sandwich affine layer, cascaded by several parallel independent affine layers. Concrete analysis reveals that, during optimization, SaBN promotes balanced gradient norms while still preserving diverse gradient directions -a property that many application tasks seem to favor. We demonstrate the prevailing effectiveness of SaBN as a drop-in replacement in four tasks: neural architecture search (NAS), conditional image generation, adversarial training, and arbitrary style transfer. Leveraging SaBN immediately achieves better Inception Score and FID on CIFAR-10 and ImageNet conditional image generation with three state-of-the-art GANs; boosts the performance of a state-of-the-art weight-sharing NAS algorithm significantly on NAS-Bench-201; substantially improves the robust and standard accuracies for adversarial defense; and produces superior arbitrary stylized results. We also provide visualizations and analysis to help understand why SaBN works. Codes are available at https://github.com/VITA-Group/Sandwich-Batch-Normalization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper presents a simple, light-weight, and easy-toimplement modification of Batch Normalization (BN) <ref type="bibr" target="#b23">(Ioffe &amp; Szegedy, 2015)</ref>, yet strongly motivated by various observations <ref type="bibr" target="#b59">(Zając et al., 2019;</ref><ref type="bibr" target="#b8">Deecke et al., 2018;</ref> drawn from several application fields, that BN has troubles standardizing hidden features with a heterogeneous, multi-modal distribution. We call this phenomenon feature distribution heterogeneity. Such heterogeneity of hidden features could arise from multiple causes, often application-dependent:</p><p>• One straightforward cause is the input data heterogeneity.</p><p>For example, when training a deep network on a diverse set of visual domains, that possess significantly different statistics, BN is found to be ineffective in normalizing the activations with only a single mean and variance <ref type="bibr" target="#b8">(Deecke et al., 2018)</ref>, and often needs to be re-set or adapted <ref type="bibr" target="#b34">(Li et al., 2016)</ref>.</p><p>• Another intrinsic cause could arise from the model heterogeneity, i.e., when the training is, or could be equivalently viewed as, on a set of different models. For instance, in neural architecture search (NAS) using weight sharing <ref type="bibr" target="#b37">(Liu et al., 2018;</ref><ref type="bibr" target="#b11">Dong &amp; Yang, 2019)</ref>, training the supernet during the search phase could be considered as training a large set of sub-models (with many overlapped weights) simultaneously. As another example, for conditional image generation , the generative model could be treated as a set of category-specific sub-models packed together, one of which would be "activated" by the conditional input each time.</p><p>The vanilla BN <ref type="figure" target="#fig_0">(Figure 1 (a)</ref>) fails to perform well when there is data or model heterogeneity. Recent trends split the affine layer into multiple ones and leverage input signals to modulate or select among them <ref type="bibr" target="#b7">(De Vries et al., 2017;</ref><ref type="bibr" target="#b8">Deecke et al., 2018)</ref>  <ref type="figure" target="#fig_0">(Figure 1 (b)</ref>); or even further, utilize several independent BNs to address such disparity <ref type="bibr" target="#b59">(Zając et al., 2019;</ref><ref type="bibr" target="#b57">Yu et al., 2018)</ref>. While those relaxations alleviate the data or model heterogeneity, we suggest that they might be "too loose" in the normalization or regularization effects.</p><p>Let us take the conditional image generation task of GANs as a concrete motivating example to illustrate our rationale. A GAN model is trained with an image dataset containing various image classes, tending to capture the distribution of real samples to produce similar image examples. As a helpful remedy for the generator to encode class-specific information, Categorical Conditional Batch Normalization arXiv:2102.11382v1 [cs.CV] 22 Feb 2021 <ref type="bibr">(CCBN)</ref>, is widely used in the conditional image generation <ref type="bibr" target="#b4">(Brock et al., 2018;</ref>. It is composed of a normalization layer and a number of following separate affine layers for different image classes, which allows class-specific information to be encoded separately, thus enables the generator to generate more vivid examples.</p><p>But what might be missing? Unfortunately, using separate affines ignores one important fact that different image classes, while being different, are not totally independent.</p><p>Considering that images from the same dataset share some common characteristic (e.g., the object-centric bias for CI-FAR images), it is convincing to hypothesize the different classes to be largely overlapped at least (i.e., they still share some hidden features despite the different statistics). To put it simply: while it is oversimplified to normalize the different classes as "the same one", it is also unfair and unnecessary to treat them as "totally disparate".</p><p>More application examples can be found that all share this important structural feature prior. <ref type="bibr" target="#b37">(Liu et al., 2018;</ref><ref type="bibr" target="#b11">Dong &amp; Yang, 2019;</ref><ref type="bibr" target="#b57">Yu et al., 2018)</ref> train a large variety of child models, constituting model heterogeneity; but most child architectures inevitably have many weights in common since they are sampled from the same supernet. Similarly, in adversarial training, the model is trained by a mixture of the original training set ("clean examples") and its attacked counterpart with some small perturbations applied ("adversarial examples"). But the clean examples and adversarial examples could be largely overlapped, considering that all adversarial images are generated by perturbing clean counterparts only minimally.</p><p>Our Contributions: Recognizing the need to address feature normalization with "harmony in diversity", we propose a new SaBN as illustrated in <ref type="figure" target="#fig_0">Fig 1 (c)</ref>. SaBN modifies BN in an embarrassingly simple way: it is equipped with two cascaded affine layers: a shared unconditional sandwich affine layer, followed by a set of independent affine layers that can be conditioned. Compared to CCBN, the new sandwich affine layer is designed to inject an inductive bias, that all re-scaling transformations will have a shared factor, indicating the commodity.</p><p>We then dive into a detailed analysis of why SaBN shows to be effective, and illustrate that during optimization, SaBN promotes balanced gradient norms (leading to more fair learning paces among heterogeneous classes and features), while still preserving diverse gradient directions (leading to each class leaning towards discriminative feature clusters): a favorable inductive bias by many applications.  in GAN and the search performance in NAS in a plugand-play fashion. To better address the data heterogeneity altogether, SaBN could further integrate the idea of split/auxiliary BNs <ref type="bibr" target="#b59">(Zając et al., 2019;</ref><ref type="bibr" target="#b57">Yu et al., 2018)</ref>, to decompose the normalization layer into multiple parallel ones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Normalization in Deep Learning</head><p>Batch Normalization (BN) <ref type="bibr" target="#b23">(Ioffe &amp; Szegedy, 2015)</ref> made critical contributions to training deep convolutional networks and nowadays becomes a cornerstone of the latter for numerous tasks. BN normalizes the input mini-batch of samples by the mean and variance, and then re-scales them with learnable affine parameters. The success of BNs was initially attributed to overcoming internal covariate shift <ref type="bibr" target="#b23">(Ioffe &amp; Szegedy, 2015)</ref>, but later on raises many open discussions on its effect of improving landscape smoothness <ref type="bibr" target="#b48">(Santurkar et al., 2018)</ref>; enabling larger learning rates <ref type="bibr" target="#b3">(Bjorck et al., 2018)</ref> and reducing gradient sensitivity <ref type="bibr" target="#b1">(Arora et al., 2018)</ref>; preserving the rank of pre-activation weight matrices <ref type="bibr" target="#b6">(Daneshmand et al., 2020)</ref>; decoupling feature length and direction <ref type="bibr" target="#b28">(Kohler et al., 2018)</ref>; capturing domain-specific artifacts <ref type="bibr" target="#b34">(Li et al., 2016)</ref>; reducing BN's dependency on batch size <ref type="bibr" target="#b22">(Ioffe, 2017;</ref><ref type="bibr" target="#b49">Singh &amp; Krishnan, 2020)</ref>; preventing elimination singularities <ref type="bibr" target="#b46">(Qiao et al., 2019)</ref>; and even characterizing an important portion of network expressivity <ref type="bibr" target="#b14">(Frankle et al., 2020)</ref>.</p><p>Inspired by BN, a number of task-specific modifications exploit different normalization axes, such as Instance Normalization (IN) <ref type="bibr" target="#b50">(Ulyanov et al., 2016)</ref> for style transfer; Layer Normalization (LN) <ref type="bibr" target="#b2">(Ba et al., 2016)</ref> for recurrent networks; Group Normalization (GN) <ref type="bibr" target="#b52">(Wu &amp; He, 2018)</ref> for tackling small batch sizes; StochNorm <ref type="bibr" target="#b29">(Kou et al., 2020)</ref> for fine-tuning; Passport-aware Normalization  for model IP protection; and <ref type="bibr" target="#b32">(Li et al., 2019a;</ref><ref type="bibr" target="#b51">Wang et al., 2020;</ref><ref type="bibr" target="#b63">Zheng et al., 2020)</ref> for image generation.</p><p>Several normalization variants have been proposed by modulating BN parameters, mostly the affine layer (mean and variance), to improve the controlling flexibility for more sophisticated usages. For example, Harm et al. <ref type="bibr" target="#b7">(De Vries et al., 2017)</ref> presented Conditional BN, whose affine parameters are generated as a function of the input. Similarly, Conditional IN <ref type="bibr" target="#b13">(Dumoulin et al., 2016)</ref> assigned each style with independent IN affine parameters. In , the authors developed Categorical Conditional BN for conditional GAN image generation, where each generated class has its independent affine parameters. <ref type="bibr" target="#b21">Huang &amp; Belongie (Huang &amp; Belongie, 2017)</ref> presented Adaptive IN (AdaIN), which used the mean and variance of style image to replace the original affine parameter, achieving arbitrary style transfer. Spatial adaptivity <ref type="bibr" target="#b44">(Park et al., 2019)</ref> and channel attention <ref type="bibr" target="#b33">(Li et al., 2019b)</ref> managed to modulate BN with higher complexities.</p><p>A few latest works investigate to use multiple normalization layers instead of one in BN. <ref type="bibr" target="#b8">(Deecke et al., 2018)</ref> developed mode normalization by employing a mixture-of-experts to separate incoming data into several modes and separately normalizing each mode. <ref type="bibr" target="#b59">(Zając et al., 2019)</ref> used two separate BNs to address the domain shift between labeled and unlabeled data in semi-supervised learning. Very recently,  revealed the twodomain issue in adversarial training and find improvements by using two separate BNs (AuxBN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Brief Backgrounds for Related Applications</head><p>We use four important applications as testbeds. All of them appear to be oversimplified by using the vanilla BN, where the feature homogeneity and heterogeneity are not properly handled. We briefly introduce them below, and will concretely illustrate where the heterogeneity comes from and how our methods resolve the bottlenecks in Sec. 3.</p><p>Generative Adversarial Network GAN has been prevailing since its origin <ref type="bibr" target="#b16">(Goodfellow et al., 2014a)</ref> for image generation. Many efforts have been made to improve GANs, such as modifying loss function <ref type="bibr" target="#b18">Gulrajani et al., 2017;</ref><ref type="bibr" target="#b25">Jolicoeur-Martineau, 2018)</ref>, improving network architecture <ref type="bibr" target="#b61">(Zhang et al., 2018;</ref><ref type="bibr" target="#b27">Karras et al., 2019;</ref><ref type="bibr" target="#b15">Gong et al., 2019)</ref> and adjusting training procedure <ref type="bibr" target="#b26">(Karras et al., 2017)</ref>. Recent works also tried to improve the generated image quality by proposing new normalization modules, such as Categorical Conditional BN and spectral normalization .</p><p>Neural Architecture Search (NAS) The goal of NAS is to automatically search for an optimal model architecture for the given task and dataset. It was first proposed in <ref type="bibr" target="#b64">(Zoph &amp; Le, 2016)</ref> where a reinforcement learning algorithm iteratively samples, trains and evaluates candidate models from the search space. Due to its prohibitive time cost, the weightsharing mechanism was introduced <ref type="bibr" target="#b45">(Pham et al., 2018)</ref> and becomes a popular strategy to accelerate the training of sampled models <ref type="bibr" target="#b37">(Liu et al., 2018)</ref>. However, weight-sharing causes performance deterioration due to unfair training <ref type="bibr" target="#b5">(Chu et al., 2019)</ref>. In addition, a few NAS benchmarks <ref type="bibr" target="#b56">(Ying et al., 2019;</ref><ref type="bibr" target="#b12">Dong &amp; Yang, 2020;</ref><ref type="bibr" target="#b60">Zela et al., 2020)</ref> were recently released, with ground-truth accuracy for candidate models pre-recorded, enabling researchers to evaluate the performance of the search method more easily.</p><p>Adversarial Robustness Deep networks are notorious for the vulnerability to adversarial attacks <ref type="bibr" target="#b17">(Goodfellow et al., 2014b)</ref>. In order to enhance adversarial robustness, countless defense approaches have been proposed. <ref type="bibr" target="#b10">(Dhillon et al., 2018;</ref><ref type="bibr" target="#b43">Papernot &amp; McDaniel, 2017;</ref><ref type="bibr" target="#b55">Xu et al., 2017;</ref><ref type="bibr" target="#b39">Meng &amp; Chen, 2017;</ref><ref type="bibr" target="#b35">Liao et al., 2018;</ref><ref type="bibr" target="#b38">Madry et al., 2017)</ref>. Among them, adversarial training (AT) <ref type="bibr" target="#b38">(Madry et al., 2017)</ref> is arguably the strongest, which trains the model over a mixture of clean and perturbed data. The normalization in AT had not been studied in-depth until the pioneering work  introduced an auxiliary batch norm (AuxBN) to improve the clean image recognition accuracy.</p><p>Neural Style Transfer Style transfer generates a stylized image, by combining the content of one image with the style of another. Various improvements are made on the normalization methods here. <ref type="bibr" target="#b50">(Ulyanov et al., 2016)</ref> proposed Instance Normalization (IN), improving the stylized quality of generated images. Conditional Instance Normalization (CIN) <ref type="bibr" target="#b13">(Dumoulin et al., 2016)</ref> and Adaptive Instance Normalization (AdaIN) <ref type="bibr" target="#b21">(Huang &amp; Belongie, 2017</ref>) enable a single network to perform multiple/arbitrary style transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Sandwich Batch Normalization</head><p>Given the input feature x ∈ R N ×C×H×W (N denotes the batch size, C the number of channels, H the height, W the width), the vanilla Batch Normalization (BN) works as:</p><formula xml:id="formula_0">h = γ( x − µ(x) σ(x) ) + β,<label>(1)</label></formula><p>where µ(x) and σ(x) are the running estimates (or batch statistics) of input x's mean and variance along (N , H, W ) dimensions. γ and β are the learnable parameters of the affine layer, and both are of shape C. However, the vanilla BN only has a single re-scaling transform and will treat any latent feature from one single distribution.</p><p>(a) Inter-class gradient magnitude standard deviation (b) Inter-class gradient cosine similarity <ref type="figure">Figure 2</ref>. The visualization of standard deviations of gradient magnitudes (the lower the better, i.e., more balanced optimization paces) and cosine similarity across different classes (the lower the better, i.e., more diverse features learned). The x-axis of each plot denotes the depth of generator network, where each generator is composed of four stages of convolution blocks.</p><p>As an improved variant, Categorical Conditional BN (CCBN)  is proposed to remedy the heterogeneity issue in the task of conditional image generation, boosting the quality of generated images. CCBN has a set of independent affine layers, whose activation is conditioned by the input domain index and each affine layer is learned to capture the class-specific information. It can be expressed as:</p><formula xml:id="formula_1">h = γ i ( x − µ(x) σ(x) ) + β i , i = 1, ..., C,<label>(2)</label></formula><p>where γ i and β i are parameters of the i-th affine layer. Concretely, i is the expected output class in the image generation task . However, we argue that this "separate/split" modification might cause imbalanced learning for different classes. Due to the fact that the training data from each class might vary a lot (different number of examples, complicated/simple textures, large/small innerclass variation, etc.), different individual affine layers might have significantly diverged convergence speed, impeding the proper training of the whole network. Dominant classes will introduce stronger inductive biases on convolutional layers than minor classes.</p><p>To better handle the imbalance, we present Sandwich BN (SaBN), that is equipped with a shared sandwich affine layer and a set of independent affine layers:</p><formula xml:id="formula_2">h = γ i (γ sa ( x − µ(x) σ(x) ) + β sa ) + β i , i = 1, ..., C.<label>(3)</label></formula><p>As depicted in <ref type="figure" target="#fig_0">Fig. 1 (d)</ref>, γ sa and β sa denote the new sandwich affine layer, while γ i and β i are the i-th affine param-eters, conditioned on categorical inputs. Implementationwise, SaBN only takes a few lines of code changes over BN: please see supplement for pseudo codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Why SaBN meaningfully works?</head><p>One might be curious about the effectiveness of SaBN, since at the inference time, the shared sandwich affine layer can be multiplied/merged into the independent affine layers, making the inference form of SaBN completely identical to CCBN. So where is its real advantage?</p><p>By the analysis below, we argue that: SaBN provides a favorable inductive bias for optimization. During training, we observe that SaBN promotes balanced gradient norms (leading to more fair learning paces among heterogeneous classes and features), while still preserving diverse gradient directions (leading to each class leaning towards discriminative feature clusters).</p><p>We take the training of the conditional image generation task as an example. As one of the state-of-the-art GANs, SNGAN  successfully generates highquality images in the conditional image generation task with CCBN. Intuitively, it uses independent affine layers to disentangle the image generation of different classes. We consider analyzing the following two models: 1) SNGAN (original); 2) SNGAN-SaBN (simply replaces CCBN with our SaBN). Both of them are trained on the same subset of ImageNet, with the same training recipe (see Sec. 4.1 for details). Here we analyze the difference of inter-class gradients of the generator in two aspects: (1) gradient magnitude and (2) gradient direction. SaBN Encourages Balanced Gradient Magnitudes. For the first aspect, we analyze the standard deviation of the l 2 -norm (magnitude) of generator's gradients among different classes in <ref type="figure">Fig. 2 (a)</ref>. Concretely, we take the gradients from weights of convolution layers, which are right before the normalization modules. We observe that the gradient norms from SNGAN-SaBN mostly have lower standard deviations, indicating that the gradient magnitudes of different classes in SNGAN-SaBN are more balanced. A balanced distribution of gradient magnitudes is found to be preferred for model training, avoiding some features dominating the others, and facilitating the optimization of all sub-tasks at similar paces .</p><p>SaBN Preserves Diversity of Gradient Directions. We then visualize the averaged cosine similarity of generator's gradients from different classes during training in <ref type="figure">Fig. 2  (b)</ref>. Specifically, we define the inter-class gradient similarity g inter , which aims to measure the divergence of gradients from different input class labels y and averaged over latent vectors (z):</p><formula xml:id="formula_3">g l inter = 1 m m−1 i=0 C ∇ θ l L(G(z i , y j ))| n−1 j=0<label>(4)</label></formula><p>Here the generator is denoted by G, and ∇ θ l L(G(z i , y j )) represents the gradients on convolution layers of the l-th stage of the generator (i.e., the derivative of loss L with respect to parameters in l-th stage θ l ; we omit the discriminator here). m and n are the total number of latent vectors z and class labels y, respectively. Function C calculates the averaged pair-wise cosine similarity of inputs:</p><formula xml:id="formula_4">C v i | N i=1 = 1 N (N − 1) N i=1 N j=1,j =i v i · v j v i v j .<label>(5)</label></formula><p>We can see that SNGAN-SaBN has lower g inter , indicating the gradients from different classes are more diverse in their directions. This enables the generator to capture richer discriminative information among different classes and contribute to a visually more diverse generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary:</head><p>The above two characteristics brought by SaBN, i.e., overall more balanced gradient norms, and inter-class more diverse gradient directions, together draw the big picture why SaBN facilitates the optimization especially in the presence of heterogeneous or multi-domain features. <ref type="figure" target="#fig_1">Fig. 3</ref> visualizes GAN training with and without SaBN: SNGAN with SaBN can achieve much lower generator loss L G (Eq. 6) than the original SNGAN ( <ref type="figure" target="#fig_1">Fig. 3 left)</ref>, and the generation quality of the former consistently outperforms the latter (by Inception Score <ref type="bibr" target="#b47">(Salimans et al., 2016)</ref>, <ref type="figure" target="#fig_1">Fig. 3 right)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Sandwich Batch Normalization is an effective plug-and-play module. In this section, we present the experiment results of naively applying it into two different tasks: conditional image generation and neural architecture search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Conditional Image Generation with SaBN</head><p>Following the discussion in the previous section, we present detailed settings and main results on the conditional image generation task using SaBN in this section. We choose three representative GAN models, SNGAN, BigGAN <ref type="bibr" target="#b4">(Brock et al., 2018)</ref> and AutoGAN-top1 , as our baselines. The generator of SNGAN and BigGAN are equipped with CCBN originally. AutoGAN-top1 does not have any normalization layer and is designed for unconditional image generation, thus we manually insert CCBN into its generator to adapt it to the conditional image generation task. We then construct SNGAN-SaBN, BigGAN-SaBN, and AutoGAN-top1-SaBN, by simply replacing all CCBN in the above baselines with our proposed SaBN.</p><p>GAN models in our paper are all trained with the hinge version adversarial loss <ref type="bibr" target="#b4">Brock et al., 2018)</ref>:</p><formula xml:id="formula_5">L D = − E (x,y)∼pdata [min(0, −1 + D(x, y))]</formula><p>− E z∼pz,y∼pdata [min(0, −1 − D(G(z, y), y))],</p><formula xml:id="formula_6">L G = − E z∼pz,y∼pdata D(G(z, y), y),<label>(6)</label></formula><p>where L D and L G denote discriminator loss and generator loss respectively.</p><p>We test all the above models on CIFAR-10 dataset <ref type="bibr" target="#b30">(Krizhevsky et al., 2009</ref>) (10 categories, resolution 32 × 32). Furthermore, we test SNGAN and SNGAN-SaBN on highresolution conditional image generation task with ImageNet <ref type="bibr" target="#b9">(Deng et al., 2009)</ref>, using the subset of all 143 classes belonging to the dog and cat super-classes, cropped to resolution 128 × 128) following 's setting. Inception Score <ref type="bibr" target="#b47">(Salimans et al., 2016)</ref> (the higher the bet-  ter) and FID <ref type="bibr" target="#b20">(Heusel et al., 2017)</ref> (the lower the better) are adopted as evaluation metrics. We summarize the best performance the models have achieved during training into <ref type="table" target="#tab_2">Table 1</ref>. We find that SaBN can consistently boost the generative quality of all three baseline GAN models, which demonstrates the effectiveness of the injected shared sandwich affine layer.</p><p>We also provide visualization results of generated images in <ref type="figure" target="#fig_2">Fig. 4</ref>. Since images of CIFAR-10 dataset <ref type="bibr" target="#b30">(Krizhevsky et al., 2009)</ref> are too small to tell difference, we only visualize the results on ImageNet <ref type="bibr" target="#b9">(Deng et al., 2009)</ref>. Specifically, we compare the generation results of SNGAN and SNGAN-SaBN. The images generated by SNGAN-SaBN are more visual appealing, showing better quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Architecture Heterogeneity in Neural Architecture Search (NAS)</head><p>Recent NAS works formulate the search space as a weightsharing supernet that contains all candidate operations and architectures, and the goal is to find a sub-network that of the optimal performance. As one of the representative works in NAS, DARTS <ref type="bibr" target="#b37">(Liu et al., 2018)</ref> solves the search problem by assigning each candidate operation a trainable architecture parameter α. Model weights ω and architecture parameters α are optimized to minimize the cross-entropy loss in an alternative fashion. After searching, the final architecture is derived by choosing the operation with the  However, such formulation introduces a strong model heterogeneity. As shown in <ref type="figure" target="#fig_3">Fig. 5</ref>, the output of each layer is the sum of all operations' output, weighted by associated architecture parameters α. Such mixed model heterogeneity could be harmful to the search, making the algorithm hard to distinguish the contribution of each operation. Inspired by the application of CCBN in GANs, we preliminarily attempt to use CCBN disentangling the mixed model heterogeneity from the previous layer, by replacing the BN in each operation path with a CCBN (namely DARTS-CCBN). The total number of affine paths is equal to the number of candidate operations in the previous layer, and the conditional index i of CCBN is obtained by applying a multinomial sampling on the softmax of previous layers' architecture parameters (shown in <ref type="figure" target="#fig_3">Fig. 5</ref>). The search results of the vanilla DARTS and DARTS-CCBN are reported in Tab. 2. Compared with vanilla DARTS, DARTS-CCBN does not show consistent improvement w.r.t. the search results. We argue that the brutal "separate/split" modification in CCBN might cause imbalanced learning for different operations due to their intrinsic difference, therefore leading to unfair competition among candidate operations.</p><p>To better handle such an unbalanced issue, we consider using SaBN instead of CCBN (DARTS-SaBN). The injected shared sandwich affine layer is designed to balance the learning among different operations, imposing a more fair competition among candidate operations. As shown in Tab. 2, we can observe that DARTS-SaBN outperforms the vanilla DARTS and DARTS-CCBN significantly, whose performance is even close to the Bench optimal. The performance gap between DARTS-CCBN and DARTS-SaBN demonstrates the effectiveness of the sandwich affine layer. We further include an additional ablation variant DARTSaffine, which simply enables the affine layer of the BN in DARTS. DARTS-SaBN also outperforms DARTS-affine with a considerable margin, implying the independent conditional affine layers are also important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Extended Applications of Sandwich Batch Normalization</head><p>In this section, we explore the possibility to extend the applications of Sandwich Batch Normalization to more tasks with minor modifications. Concretely, we apply two variants of SaBN on adversarial robustness and style transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Sandwich Auxiliary Batch Norm (SaAuxBN) in Adversarial Robustness</head><p>AdvProp   </p><formula xml:id="formula_7">L total = L(f clean (x clean ), y) + L(f adv (x adv ), y),<label>(7)</label></formula><p>where f denotes the model and x, y denotes the input data, label respectively. L is the cross entropy loss. Therefore, f clean denotes the model is using the clean branch BN. x adv is the corresponding adversarial mini-batch generated by the model using adversarial branch BN. For simplicity, we call the two loss terms in Eq. 7 as clean loss and adversarial loss respectively.</p><p>However, one thing missed is that the domains of clean and adversarial images overlap largely, as adversarial images are generated by perturbing clean counterparts minimally. This inspires us to present a novel SaAuxBN, by leveraging domain-specific normalization and affine layers, and also a shared sandwich affine layer for homogeneity preserving.   SaAuxBN can be defined as:</p><formula xml:id="formula_8">h = γ i (γ sa ( x − µ i (x) σ i (x) ) + β sa ) + β i , i = 0, 1.<label>(8)</label></formula><p>µ i (x) and σ i (x) denote the i-th (moving) mean and variance of input, where i = 0 for adversarial images and i = 1 for clean images. We use independent normalization layer to decouple the data from two different distributions, i.e., the clean and adversarial.</p><p>We replace AuxBN with SaAuxBN in AdvProp  and find it can further improve SA of the network with its clean branch. The experiments are conducted on CIFAR-10 ( <ref type="bibr" target="#b30">Krizhevsky et al., 2009)</ref> with ResNet-18 <ref type="bibr" target="#b19">(He et al., 2016)</ref> backbone. For a fair comparison, we follow the settings in <ref type="bibr" target="#b38">(Madry et al., 2017)</ref>. In the adversarial training, we adopt ∞ based 10 steps Projected Gradient Descent (PGD) <ref type="bibr" target="#b38">(Madry et al., 2017)</ref> with step size α = 2 255 and maximum perturbation magnitude = 8 255 ; As for assessing RA, PGD-20 with the same configuration is adopted. The results are presented in Tab. 3.</p><p>We further conduct an experiment to test the Standard Testing Accuracy (SA) and Robust Testing Accuracy (RA) of the network using the adversarial branch of AuxBN and SaAuxBN. The comparison results are presented in Tab. 4. We can see that BN still achieves the highest performance on SA, but falls a lot on RA compared with other methods. Our proposed SaAuxBN is on par with the vanilla BN in terms of SA, while has significantly better results on RA than any other approaches. Compared with SaAuxBN, AuxBN suffers from both worse SA and RA.</p><p>We also visualize the testing clean loss and adversarial loss of models with AuxBN and SaAuxBN in <ref type="figure" target="#fig_4">Fig. 6</ref>, showing that the model with SaAuxBN achieves lower value on both.</p><p>We additionally include ModeNorm <ref type="bibr" target="#b8">(Deecke et al., 2018)</ref> as an ablation in our experiments, which was proposed to deal with multi-modal distributions inputs, i.e., data heterogeneity. It shares some similarity with AuxBN as both consider multiple independent norms. ModeNorm achieves fair performance on both SA and RA, while still lower than SaAuxBN. The reason might be the output of ModeNorm is a summation of two features weighted by a set of learned gating functions, which still mixes the statistics from two domains, leading to inferior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Arbitrary Style Transfer with Sandwich Adaptive</head><p>Instance Normalization (SaAdaIN)</p><p>Huang &amp; Belongie <ref type="bibr" target="#b21">(Huang &amp; Belongie, 2017)</ref> achieves arbitrary style transfer by introducing Adaptive Instance Norm (AdaIN), which is an effective module to encode style information into feature space. The AdaIN framework is composed of three parts: Encoder, AdaIN, and Decoder. Firstly, the Encoder will extract content features and style features from content and style images. Then, the AdaIN is leveraged to perform style transfer on feature space, producing a stylized content feature. The Decoder is learned to decode the stylized content feature to stylized images. This framework is trained end-to-end with two loss terms, a content loss and a style loss. Concretely, AdaIN firstly performs a normalization on the content feature, then re-scale the normalized content feature with style feature's statistic. It can be formulated as:</p><formula xml:id="formula_9">h = σ(y)( x − µ(x) σ(x) ) + µ(y),<label>(9)</label></formula><p>where y is the style input, x is the content input. Note that µ and σ here are quite different from BN, which are performed along the spatial axes (H, W ) for each sample and each channel. The goal of style transfer is to extract the style information from the style input and render it to the content input. Obviously, style-dependent re-scale may be too loose and might further amplify the intrinsic data heterogeneity brought by the variety of the input content images, undermining the network's ability of maintaining the content information in the output. In order to reduce the data heterogeneity, we propose to insert a shared sandwich affine layer after the normalization, which introduce homogeneity for the style-dependent re-scaling transformation. Hereby, we present SaAdaIN: h = σ(y)(γ sa ( x − µ(x) σ(x) ) + β sa ) + µ(y),</p><p>Besides AdaIN, we also include Instance-Level Meta Normalization with Instance Norm (ILM+IN) proposed by (Jia <ref type="figure">Figure 7</ref>. The content loss and the style loss of using AdaIN, ILM+IN and SaAdaIN in training and validation set. In the first row, the noisy shallow-color curves are the original data, and the foreground smoothed curves are obtained via applying exponential moving average on the original data. et al., 2019) as a task-specific comparison baseline. Its style-independent affine is not only conditioned on style information but also controlled by the input feature.</p><p>Our training settings for all models are kept identical with <ref type="bibr" target="#b21">(Huang &amp; Belongie, 2017)</ref>. The network is trained with style loss and content loss. We use the training set of MS-COCO <ref type="bibr" target="#b36">(Lin et al., 2014)</ref> and WikiArt <ref type="bibr" target="#b42">(Nichol, 2016)</ref> as the training content and style images dataset, and the validation set of MS-COCO and testing set of WikiArt are used as our validation set.</p><p>We depict the loss curves of the training phase in <ref type="figure">Fig. 7</ref> (a). We can notice that both the content loss and style loss of the proposed SaAdaIN are lower than that of AdaIN and ILM+IN. This observation implies that the inserted sandwich affine layer makes the optimization easier. In <ref type="figure">Fig.  7 (b)</ref>, we show the content and style loss on validation set. In contrast with the AdaIN model, the network with SaAdaIN achieves lower validation content and style loss, indicating the inserted sandwich affine layer also benefits the model's generalizability. The qualitative visual results are provided in our supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We present SaBN and its variants as plug-and-play normalization modules, which are motivated by addressing model &amp; data heterogeneity issues. We demonstrate their effectiveness on several tasks, including neural architecture search, adversarial robustness, conditional image generation, and arbitrary style transfer. Our future work plans to investigate the performance of SaBN on more applications, such as semi-supervised learning <ref type="bibr" target="#b59">(Zając et al., 2019)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of (a) the original batch normalization (BN), composed of one normalization layer and one affine layer; (b) Categorical Conditional BN, composed of one normalization layer following a set of independent affine layers to intake conditional information; (c) our proposed Sandwich BN, sequentially composed of one normalization layer, one shared sandwich affine layer, and a a set of independent affine layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>(left) The generator loss LG of SNGAN and SNGAN-SaBN during training phase (ImageNet). (right) The Inception Score curves during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>The image generation results of SNGAN and SNGAN-SaBN on ImageNet. Each column is corresponding to a specific image class. Images are chosen without cherry-pick.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Two consecutive layers in the supernet. By default, a BN is integrated into each parameterized operation in vanilla DARTS. The output of each layer is the sum of all operation paths' output, weighted by their associated architecture parameter α.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>The clean loss L(fclean(xclean), y) and adversarial loss L(fadv(xadv), y) on testing set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>The best Inception Scores ("IS", ↑) and FIDs (↓) achieved by conditional SNGAN, BigGAN, and AutoGAN-top1, using CCBN and SaBN on CIFAR-10 and ImageNet (dogs &amp; cats).</figDesc><table><row><cell></cell><cell>CIFAR-10</cell><cell></cell><cell cols="2">ImageNet (dogs &amp; cats)</cell></row><row><cell>Model</cell><cell>IS</cell><cell>FID</cell><cell>IS</cell><cell>FID</cell></row><row><cell>AutoGAN-top1</cell><cell>8.43</cell><cell>10.51</cell><cell>-</cell><cell>-</cell></row><row><cell>BigGAN</cell><cell>8.91 1</cell><cell>8.57 1</cell><cell>-</cell><cell>-</cell></row><row><cell>SNGAN</cell><cell>8.76</cell><cell>10.18</cell><cell>16.75</cell><cell>79.14</cell></row><row><cell cols="3">AutoGAN-top1-SaBN 8.72(+0.29) 9.11(−1.40)</cell><cell>-</cell><cell>-</cell></row><row><cell>BigGAN-SaBN</cell><cell cols="2">9.01(+0.10) 8.03(−0.54)</cell><cell>-</cell><cell>-</cell></row><row><cell>SNGAN-SaBN</cell><cell cols="4">8.89(+0.13) 8.97(−1.21) 18.31(+1.56) 60.38(−18.76)</cell></row><row><cell cols="2">(a) SNGAN's results</cell><cell></cell><cell>(b) SNGAN-SaBN's results</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>The</figDesc><table><row><cell cols="3">ground-truth top-1 accuracy of the final searched</cell></row><row><cell cols="3">architecture on NAS-Bench-201. DARTS-SaBN achieves the</cell></row><row><cell cols="3">highest accuracy, with the lowest standard deviation. Bench opti-</cell></row><row><cell cols="3">mal denotes the best test accuracy achievable in NAS-Bench-201.</cell></row><row><cell>Method</cell><cell>CIFAR-100</cell><cell>ImageNet16-120</cell></row><row><cell>DARTS</cell><cell>44.05 ± 7.47</cell><cell>36.47 ± 7.06</cell></row><row><cell>DARTS-affine</cell><cell>63.46 ± 2.41</cell><cell>37.26 ± 7.65</cell></row><row><cell>DARTS-CCBN</cell><cell>62.16 ± 2.62</cell><cell>31.25 ± 6.20</cell></row><row><cell cols="2">DARTS-SaBN (ours) 71.56 ± 1.39</cell><cell>45.85 ± 0.72</cell></row><row><cell>Bench Optimal</cell><cell>73.51</cell><cell>47.31</cell></row><row><cell cols="2">highest α value on each edge.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Model performance (SA) using clean branch.</figDesc><table><row><cell>Evaluation</cell><cell>BN</cell><cell cols="3">ModeNorm AuxBN (clean branch) SaAuxBN (clean branch)</cell></row><row><cell cols="2">Clean (SA) 84.84</cell><cell>83.28</cell><cell>94.47</cell><cell>94.62</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Model performance (SA&amp;RA) using the adversarial branch.</figDesc><table><row><cell>Evaluation</cell><cell>BN</cell><cell cols="3">ModeNorm AuxBN (adv branch) SaAuxBN (adv branch)</cell></row><row><cell>Clean (SA)</cell><cell>84.84</cell><cell>83.28</cell><cell>83.42</cell><cell>84.08</cell></row><row><cell cols="2">PGD-10 (RA) 41.57</cell><cell>43.56</cell><cell>43.05</cell><cell>44.93</cell></row><row><cell cols="2">PGD-20 (RA) 40.02</cell><cell>41.85</cell><cell>41.60</cell><cell>43.14</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Department of Electrical and Computer Engineering, the University of Texas at Austin, TX, USA. Correspondence to: Xinyu Gong &lt;xinyu.gong@utexas.edu&gt;.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Results obtained by using the author's officially unofficial PyTorch BigGAN implementation..</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wasserstein Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Theoretical analysis of auto rate-tuning by batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.03981</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">E. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7694" to="7705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fairnas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01845</idno>
		<title level="m">Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Theoretical understanding of batchnormalization: A markov chain perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daneshmand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.01652</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modulating early visual processing by language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6594" to="6604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bilen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05466</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Mode normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kossaifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anandkumar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01442</idno>
		<title level="m">Stochastic activation pruning for robust adversarial defense</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Nas-bench-102: Extending the scope of reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00326</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A learned representation for artistic style</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.07629</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Schwab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Morcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Training</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00152</idno>
		<title level="m">On the expressive power of random features in cnns</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Autogan: Neural architecture search for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3224" to="3234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<title level="m">Explaining and harnessing adversarial examples</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in realtime with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Batch renormalization: Towards reducing minibatch dependence in batch-normalized models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1945" to="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Instance-level meta normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4865" to="4873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The relativistic discriminator: a key element missing from standard gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00734</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aila</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Exponential convergence rates for batch normalization: The power of length-direction decoupling in non-convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daneshmand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Neymeyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10694</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stochastic normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Crafting papers on machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Machine Learning</title>
		<editor>Langley, P.</editor>
		<meeting>the 17th International Conference on Machine Learning<address><addrLine>Stanford, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1207" to="1216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Positional normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1622" to="1634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1908.01259</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">T. Attentive normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Revisiting batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Defense against adversarial attacks using high-level representation guided denoiser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1778" to="1787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06083</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Magnet: a two-pronged defense against adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2017 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="135" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05637</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">cgans with projection discriminator. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshida</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05957</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Painter by numbers, wikiart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nichol</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/c/painter-by-numbers/overview" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05264</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Extending defensive distillation. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Semantic image synthesis with spatially-adaptive normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2337" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03268</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuille</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09738</idno>
		<title level="m">Rethinking normalization and elimination singularity in neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">How does batch normalization help optimization?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2483" to="2493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Filter response normalization layer: Eliminating batch dependence in the training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11237" to="11246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Instance normalization: The missing ingredient for fast stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attentive normalization for conditional image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5094" to="5103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Intriguing properties of adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03787</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09665</idno>
		<title level="m">Adversarial examples improve image recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01155</idno>
		<title level="m">Feature squeezing: Detecting adversarial examples in deep neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09635</idno>
		<title level="m">Nas-bench-101: Towards reproducible neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.08928</idno>
		<title level="m">Slimmable neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Gradient surgery for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.06782</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Split batch normalization: Improving semi-supervised learning under domain shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zając</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Żołna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzębski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03515</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Nas-bench-1shot1: Benchmarking and dissecting one-shot neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.10422</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Selfattention generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Passport-aware normalization for deep model protection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learning semantic-aware normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
