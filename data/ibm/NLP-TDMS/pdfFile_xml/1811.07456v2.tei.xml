<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Larger Norm More Transferable: An Adaptive Feature Norm Approach for Unsupervised Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data and Computer Science</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data and Computer Science</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data and Computer Science</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
							<email>linliang@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">School of Data and Computer Science</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">DarkMatter AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Larger Norm More Transferable: An Adaptive Feature Norm Approach for Unsupervised Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain adaptation enables the learner to safely generalize into novel environments by mitigating domain shifts across distributions. Previous works may not effectively uncover the underlying reasons that would lead to the drastic model degradation on the target task. In this paper, we empirically reveal that the erratic discrimination of the target domain mainly stems from its much smaller feature norms with respect to that of the source domain. To this end, we propose a novel parameter-free Adaptive Feature Norm approach. We demonstrate that progressively adapting the feature norms of the two domains to a large range of values can result in significant transfer gains, implying that those task-specific features with larger norms are more transferable. Our method successfully unifies the computation of both standard and partial domain adaptation with more robustness against the negative transfer issue. Without bells and whistles but a few lines of code, our method substantially lifts the performance on the target task and exceeds state-of-the-arts by a large margin (11.5% on Office-Home [45] and 17.1% on VisDA2017 [31]). We hope our simple yet effective approach will shed some light on the future research of transfer learning. Code is available at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks, driven by numerous labeled samples, have made remarkable progress in a wide range of computer vision tasks. However, those models are very vulnerable to generalize into new application scenarios. Even a subtle deviation from the training regime can lead to a drastic degradation of the model <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b48">49]</ref>. Therefore, with the strong motivation to safely transfer knowledge from a labelrich source domain to an unlabeled target domain, Unsupervised Domain Adaptation (UDA) attempts to train a classi- * Corresponding author is Guanbin Li.  on the Source Only model. This technique is widely used to characterize the feature embeddings under the softmax-related objectives <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b50">51]</ref>. Specifically, we set the task-specific features to be two-dimensional and retrain the model. Unlike t-SNE <ref type="bibr" target="#b26">[27]</ref> whose size of empty space does not account for the similarity between the two data points, this visualization map enables us to interpret the size of feature norms as well as inter-class and intra-class variances. As illustrated, target samples tend to collide in the small-norm (i.e., low-radius) regions which are vulnerable to slight angular variations of the decision boundaries and lead to erratic discrimination.</p><p>fier using source samples that can generalize well to the target domain while mitigating the domain shift between the two underlying distributions. Under the guidance of the theoretical upper bound in <ref type="bibr" target="#b0">[1]</ref>, the key idea of most existing DA algorithms is to capture not only the task-discriminative but the domain-invariant representations by simultaneously minimizing the source error and some specific statistical discrepancy across the two domains, e.g., H-divergence <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b42">43]</ref>, H∆H-divergence <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b34">35]</ref>, Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b22">23]</ref>, correlation distance <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref> and etc.</p><p>Adversarial domain adaptation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32]</ref>, which seeks to minimize an approximate domain discrepancy with an adversarial objective, has recently evolved into a dominant method in this field. To the best of our knowledge, RevGrad <ref type="bibr" target="#b8">[9]</ref> is the pioneer to empirically measure the H-divergence by a parametric domain discriminator and adversarially align the features via reverse gradient backpropagation. ADDA <ref type="bibr" target="#b42">[43]</ref> instead facilitates the adversarial alignment with GAN-based objective in an asymmetric manner. MCD <ref type="bibr" target="#b34">[35]</ref> places a min-max game between the feature generator and the two-branch classifiers to reduce the H∆H-divergence. On par with the feature-level alignment, generative pixel-level adaptation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32]</ref> utilizes Image-to-Image translation techniques to capture the low-level domain shifts.</p><p>While the notion of model degradation has been well recognized within the DA community <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b48">49]</ref>, little research work has been published to analyze the underlying cause of this phenomenon. Thus, existing statistic divergences may fail to precisely depict the domain shift and bridging such discrepancies may not guarantee the safe transfer across domains. For example, Shu et al. <ref type="bibr" target="#b36">[37]</ref> verify that bridging JensenShannon divergence between the two domains does not imply high accuracy on the target task. In this paper, we take a step towards unveiling the nature of model degradation from a solid empirical observation, which is highlighted by <ref type="figure" target="#fig_1">Fig. 1</ref>. This visualization map suggests that the excessively smaller norms of target-domain features with respect to that of the source domain account for their erratic discrimination. However, there remain two hypothetical interpretations from the current observation: 1) Misaligned-Feature-Norm Hypothesis: The domain shift between the source and target domains relies on their misaligned feature-norm expectations. Matching the mean feature norms of the two domains to an arbitrary shared scalar is supposed to yield similar transfer gains.</p><p>2) Smaller-Feature-Norm Hypothesis: The domain shift substantially relies on the excessively less-informative features with smaller norms for the target task. Despite nonrigorous alignment, adapting the target features far away from the small-norm regions can lead to safe transfer.</p><p>With these points in mind, we introduce our parameterfree Adaptive Feature Norm (AFN) approach. First, we propose a simple yet effective statistic distance to characterize the mean-feature-norm discrepancy across domains. Second, we design the Hard AFN to bridge this domain gap by restricting the expected feature norms of the two domains to approximate a shared scalar. It suggests that norm-aligned features can bring effective transfer yet the results can be further improved with a larger scalar. To explore a more sufficient large feature norm in a stable way, we propose the Stepwise AFN to encourage a progressive feature-norm enlargement for each individual sample across domains. As stepwise AFN reveals, the key to achieving successful trans-fer is to properly lift the target samples towards the largenorm regions while the rigorous alignment is superfluous.</p><p>This innovative discovery inspires us to revisit what features are transferable. We recognize that those task-specific features with larger norms imply more informative transferability. Similar findings are explored in the field of model compression in terms of the smaller-norm-less-informative assumption <ref type="bibr" target="#b47">[48]</ref>, which suggests that parameters or features with smaller norms play a less informative role during the inference. Like the two sides of a coin, in contrast to the model compression that prunes unnecessary computational elements or paths, we place the larger-norm constraint upon the task-specific features to facilitate the more informative and transferable computation on the target domain.</p><p>It is noteworthy that under the partial DA, the negative transfer is caused not only from the unrelated samples within the shared categories but also from the unrelated data from the source outlier categories. To this end, we propose meaningful protocols to evaluate the robustness w.r.t a specific algorithm to defense against these potential risks of negative transfer. With thorough evaluation, it reveals that our fairly novel feature-norm-adaptive manner is more robust to safely transfer knowledge from the source domain.</p><p>We summarize our contributions as follows: i) We empirically unveil the nature of model degradation from a solid observation that the excessively smaller norms of the target-domain features with respect to that of the source domain account for their erratic discrimination.</p><p>ii) We propose a novel AFN approach for UDA by progressively adapting the feature norms of the two domains to a large range of scalars. Our approach is fairly simple yet effective and is translated into a few lines of code.</p><p>iii) We succeed in unifying the computation for both vanilla and partial DA and the feature-norm-adaptive manner is more robust to defense against the negative transfer. iv) Extensive experimental results have demonstrated the promise of our approach by exceeding state-of-the-arts across a wide range of visual DA benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Domain adaptation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b40">41]</ref> generalizes the learner across different domains by mitigating the domain shift problem. Supervised DA <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28]</ref> exploits a few labeled data in the target domain while unsupervised DA has no access to that. We focus on the latter scenario in our paper.</p><p>Under the guidance of the theoretical upper bound proposed in <ref type="bibr" target="#b0">[1]</ref>, existing methods explore domain-invariant structures by minimizing some specific statistic distances between the two domains. For example, Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b2">[3]</ref> based methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b43">44]</ref> learn transferable features by minimizing the MMD of their kernel embeddings. Deep correlation alignment <ref type="bibr" target="#b39">[40]</ref> proposes to match the mean and covariance of the two distri-butions. <ref type="bibr" target="#b0">[1]</ref> introduces Hand H∆H-divergence to characterize the domain discrepancy, which are further developed into matching the corresponding deep representations by <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43]</ref> and <ref type="bibr" target="#b34">[35]</ref> respectively. Regarding the methodology, kernel-based DA <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref> and adversarial DA <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32]</ref> are widely-used in the field. Inspired by GANs <ref type="bibr" target="#b13">[14]</ref>, adversarial DA involves a subnetwork as the domain classifier to discriminate features of different domains while the deep learner tries to generate the features that deceive the domain classifier. For example, RevGrad <ref type="bibr" target="#b8">[9]</ref> utilize a parametric subnetwork as the domain discriminator and adversarially align the features via reverse gradient backpropagation. ADDA <ref type="bibr" target="#b42">[43]</ref> instead facilitates the adversarial alignment with GAN-based objectives in an asymmetric manner. MCD <ref type="bibr" target="#b34">[35]</ref> conducts a min-max game between the feature generator and the two-branch classifiers in order to reduce the H∆H-divergence. On par with the feature-level adversarial alignment, generative pixel-level adaptation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32]</ref> utilizes Image-to-Image translation techniques to capture the low-level domain shifts.</p><p>In addition, other methods are proposed to learn targetspecific structures. DRCN <ref type="bibr" target="#b10">[11]</ref> involves a reconstruction penalty on target samples. <ref type="bibr" target="#b33">[34]</ref> utilizes tri-training to obtain target pseudo labels. <ref type="bibr" target="#b36">[37]</ref> refines the target decision boundary based on the cluster assumption. iCAN <ref type="bibr" target="#b49">[50]</ref> iteratively applies sample selection on pseudo-labeled target samples and retrains the network.</p><p>Standard domain adaptation assumes that the two domains share the identical label space. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> further open up the partial setting where source label space subsumes the target one, However, it is not trivial to directly migrate the current models in the standard DA as they are prone to suffer from the negative transfer effect. PADA <ref type="bibr" target="#b6">[7]</ref> attempts to alleviate this issue by detecting and down-weighting samples belonging to the source outlier classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><formula xml:id="formula_0">Given a source domain D s = {(x s i , y s i )} ns i=1 of n s la- beled samples associated with |C s | categories and a target domain D t = {x t i } nt i=1</formula><p>of n t unlabeled samples associated with |C t | categories. DA occurs when the underlying distributions corresponding to the source and target domains in the shared label space are different but similar <ref type="bibr" target="#b1">[2]</ref> to make sense the transfer. Unsupervised DA considers the scenario that we have no access to any labeled target examples.</p><p>Vanilla Setting Under this setting, the source and target domains share the identical label space, i.e., C s = C t .</p><p>Partial Setting The source label space subsumes the target one, i.e., C s ⊃ C t . The source labeled data belonging to the outlier categories C s \C t are unrelated to the target task.  <ref type="figure">Figure 2</ref>: The overall framework of our proposed Adaptive Feature Norm approach. The backbone network G denotes the general feature extraction module. F is employed as the taskspecific classifier with l layers, each of which is organized in the FC-BN-ReLU-Dropout order. During each iteration, we apply the feature norm adaptation upon the task-specific features along with the source classification loss as our optimization objective. For the Hard variant of AFN, the mean feature norms of source and target samples are constrained to a shared scalar. For the Stepwise variant, we encourage a progressive feature-norm enlargement with respect to each individual example at the step size of ∆r. To this end, far away from the small-norm regions after the adaptation, the target samples can be correctly classified without any supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">L 2 -preserved Dropout</head><p>In this part, we first prove that the standard Dropout operator is L 1 -preserved. As our algorithm is computed based on the L 2 norms of the hidden features, we introduce the following L 2 -preserved Dropout operation to meet our goal.</p><p>Dropout is a widely-used regularization technique in deep neural networks <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b17">18]</ref>. Given a d-dimensional input vector x, in the training phase, we randomly zero the element x k , k = 1, 2,. . . , d with probability p by samples a k ∼ P that are generated from the Bernoulli distribution:</p><formula xml:id="formula_1">P (a k ) = p, a k = 0 1 − p, a k = 1<label>(1)</label></formula><p>To compute an identity function in the evaluation stage, the outputs are further scaled by a factor of 1 1−p and thuŝ</p><formula xml:id="formula_2">x k = a k 1 1 − p x k ,<label>(2)</label></formula><p>which implicitly preserves the L 1 -norm in both of the training and evaluation phases since x k and a k are independent:</p><formula xml:id="formula_3">E[|x k |] = E[|a k 1 1 − p x k |] = 1 1 − p E[a k ]E[|x k |] = E[|x k |] .</formula><p>(3) However, as we are in pursuit of adaptive L 2 feature norm, we instead scale the output by a factor of 1 √ 1−p and obtain</p><formula xml:id="formula_4">x k = a k 1 √ 1 − p x k ,<label>(4)</label></formula><p>which satisfies</p><formula xml:id="formula_5">E[|x k | 2 ] = E[|a k 1 √ 1 − p x k | 2 ] = 1 1 − p E[a 2 k ]E[|x k | 2 ] = E[|x k | 2 ] .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Framework</head><p>As indicated in <ref type="figure">Fig. 2</ref>, our framework consists of a backbone network G and a classifier F . Existing findings reveal that deep features eventually transit from general to specific along the network and feature transferability significantly drops in higher layers <ref type="bibr" target="#b48">[49]</ref>. In our case, G is regarded as the general feature extraction module that inherits from the prevailing network architecture such as ResNet <ref type="bibr" target="#b15">[16]</ref>. F represents the task-specific classifier that has l fully-connected layers. We denotes the first l − 1 layers of the classifier as F f , which results in the so-called bottleneck feature embeddings f <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">26]</ref>. Those features computed by F f depend greatly on the specific domain and are not safely transferable to a novel domain. Eventually, we calculate the class probabilities along the last layer F y , which is followed by a softmax operator. We denote the parameters of G, F f , F y with θ g , θ f and θ y respectively. Our intention is to explore an adaptive algorithm to compute the domain-transferable features f = F f (G(·)) using only source domain supervision. On the other side, as we are unifying the computation with respect to both vanilla and partial DA, it raises an interleaving challenge to defense against the negative transfer effect caused by the outlier categories in the source domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Hard Adaptive Feature Norm</head><p>Based on our Misaligned-Feature-Norm Hypothesis, we propose the Maximum Mean Feature Norm Discrepancy (MMFND) to characterize the mean-feature-norm distance between the two distributions and verify whether bridging this statistical domain gap can result in appreciable transfer gains. MMFND is defined by Eq. <ref type="formula" target="#formula_7">(6)</ref>, where the function class H is the combination of all the possible functions composited by the L 2 -norm operator with the deep representation module, i.e., h(</p><formula xml:id="formula_6">x) = ( · 2 • F f • G)(x). MMFND[H, Ds, Dt] := sup h∈H (</formula><p>1 ns</p><formula xml:id="formula_7">x i ∈Ds h(xi) − 1 nt x i ∈D t h(xi)) .<label>(6)</label></formula><p>Intuitively, the functions class H are rich enough to contain substantial positive real valued functions on the input x and the upper bound will greatly deviate from zero if there is no restriction on the function type. In order to avoid this happening, we place a restrictive scalar R to match the corresponding mean feature norms. By restricting both the mean feature norms of the two domains respectively converging towards the shared equilibrium R, the domain gap in terms of MMFND will vanish to zero. We implement this via the Hard Adaptive Feature Norm (HAFN) algorithm, which is illustrated by Eq. <ref type="bibr" target="#b6">(7)</ref>.</p><formula xml:id="formula_8">C1(θg, θ f , θy) = 1 ns (x i ,y i )∈Ds Ly(xi, yi) +λ(L d ( 1 ns x i ∈Ds h(xi), R) + L d ( 1 nt x i ∈D t h(xi), R)) .<label>(7)</label></formula><p>The optimization objective consists of two terms: the source classification loss L y in order to obtain the taskdiscriminative features by minimizing the softmax cross entropy on the source labeled samples, which is indicated by Eq. (8), where p = p 1 , . . . , p |Cs| is the softmax of the activations predicted by the classifier, i.e., p = sof tmax(F (G(x))); the feature-norm penalty in order to obtain the domain-transferable features by minimizing the feature-norm discrepancy between the two domains, where L d (·, ·) is taken as the L 2 -distance and λ is a hyperparameter to trade off the two objectives.</p><formula xml:id="formula_9">L y (x s i , y s i ; θ g , θ f , θ y ) = − |Cs| k=1 1 [k=y s i ] log p k . (8)</formula><p>Simple yet effective, MMFND appears to be a novel and superior statistical distance to characterize the cross-domain shift. And by bridging this feature-norm discrepancy with only source-domain supervision through executing HAFN, we can finally achieve the task-discriminative as well as domain-transferable features.</p><p>However, the preference setting of R still remains unsettled. As the Misaligned-Feature-Norm Hypothesis suggests, matching feature-norm expectations of the two domains to an arbitrary shared positive real value is supposed to yield similar transfer gains. But this assertion is found not to be true by our empirical results. Specifically, although restricting the mean feature norms of the two domains to even a fairly small value (e.g., R = 1, that is, feature normalization) has shown effective results, however, with R gradually increases, the obtained models are still prone to achieve higher accuracies on the target task. To this end, it is natural to explore a sufficiently large R and verify whether the rigorous alignment between the feature-norm expectations is necessary, which is revealed by our Smaller-Feature-Norm Hypothesis. In fact, it is unfortunate that HAFN fails to set an extremely large R as the gradients generated by the feature-norm penalty may eventually lead to an explosion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Stepwise Adaptive Feature Norm</head><p>To break the aforementioned bottleneck, we introduce an improved variant called Stepwise Adaptive Feature Norm (SAFN) in order to encourage the model to learn taskspecific features with larger norms in a progressive manner,  </p><formula xml:id="formula_10">+ λ ns + nt x i ∈Ds∪D t L d (h(xi; θ0) + ∆r, h(xi; θ)) ,<label>(9)</label></formula><p>where θ = θ g ∪ θ f . θ 0 and θ represent the updated and updating model parameters in the last and current iterations respectively. ∆r denotes the positive residual scalar to control the feature-norm enlargement. During each iteration, the second penalty in SAFN encourages a feature-norm enlargement at the step size of ∆r with respect to individual examples, based on their feature norms calculated by the past model parameters in the last iteration. Instead of assigning a hard value, SAFN enables the optimization process more stable and fairly easy to trade off between the two objectives. To this end, executing SAFN can lead to higher accuracies on the target task by generating more informative features with larger norms. It is noteworthy that SAFN does not rigorously bridge the mean-feature-norm discrepancy, yet one can alternatively place a terminal R to restrict the endless enlargement, which is indicated by Eq. (10). However, our empirical results revealed that Eq. (10) has slightly different result as to replace the second term in Eq. (9). As the Smaller-Feature-Norm hypothesis suggests, once we properly adapt the target samples towards the large-norm regions, the rigorous alignment becomes superfluous. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Model Robustness Evaluation</head><p>Though the notion of negative transfer has been well recognized within the DA community <ref type="bibr" target="#b29">[30]</ref>, its rigorous definition is still unclear <ref type="bibr" target="#b45">[46]</ref>. A widely accepted description of negative transfer <ref type="bibr" target="#b29">[30]</ref> is stated as transferring knowledge from the source can have a negative impact on the target learner. While intuitive, how to evaluate it still remains open. Inspired by <ref type="bibr" target="#b45">[46]</ref>, we propose meaningful protocols to evaluate the robustness of a given algorithm especially under the more general partial setting. It is noteworthy that in this setting, the negative transfer is caused not only from the unrelated samples within the shared categories but also from the unrelated data from the source outlier classes. Let A l% T |C t | , A S |C t | →T |C t | and A S |Cs| →T |C t | denote the accuracies by using just l% target labeled data, transferring without and with source outlier classes w.r.t an identical algorithm. We define i) A l% T |C t | − A S |C t | →T |C t | (Closed Negative Gap, CNG): the negative impact occurs if the algorithm cannot obtain more transfer gains over the negative influences from another domain than even just labeling a few (e.g., 1%) target data, which is valueless when deployed in the wild. ii) A S |C t | →T |C t | − A S |Cs| →T |C t | (Outlier Negative Gap, ONG): especially measures the negative influences that are caused by the source unrelated categories. iii) A l% T |C t | −A S |Cs| →T |C t | (Partial Negative Gap, PNG): reveals whether it is valuable for an algorithm to access and transfer from those available large domains with the potential risks of CNG and ONG. We say that the negative effect exceeds the positive gains once the gap value is positive and vice versa. The larger absolute value suggests more desperate negative influences or more encouraging positive gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>VisDA2017 <ref type="bibr" target="#b30">[31]</ref> is the challenging large-scale benchmark that attempts to bridge the significant synthetic-to-  real domain gap with over 280K images across 12 object categories. The source domain has 152,397 synthetic images generated by rendering from 3D models. The target domain has 55,388 real object images collected from Microsoft COCO <ref type="bibr" target="#b18">[19]</ref>. Under the partial setting, we follow <ref type="bibr" target="#b6">[7]</ref> to choose (in alphabetic order) the first 6 categories as target categories and conduct the Synthetic-12 → Real-6 task.</p><p>Office-Home <ref type="bibr" target="#b44">[45]</ref> is another challenging dataset that collects images of everyday objects to form four domains: Artistic images (Ar), Clipart images (Cl), Product images (Pr) and Real-World images (Rw). Each domain contains 65 object categories and they amount to around 15,500 images. Under the partial setting, we follow <ref type="bibr" target="#b6">[7]</ref> to choose (in alphabetic order) the first 25 categories as target categories.</p><p>Office-31 <ref type="bibr" target="#b32">[33]</ref> is a widely-used benchmark for visual DA. It contains 4,652 images of 31 office environment categories from three domains: Amazon (A), DSLR (D) and Webcam (W), which correspond to online website, digital SLR camera and web camera images respectively.</p><p>ImageCLEF-DA is built for ImageCLEF 2014 domain adaptation challenge 1 and consists of 12 common categories shared by three public datasets: Caltech-256 (C), ImageNet 1 http://imageclef.org/2014/adaptation ILSVRC2012 (I) and Pascal VOC 2012 (P). There are 50 images in each category and 600 images in each domain.</p><p>Implementation Details We follow the standard protocol <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b42">43]</ref> to utilize all labeled source data and unlabeled target data that belongs to their own label spaces. We implement our experiments on the widely-used PyTorch 2 platform. For fair comparison, our backbone network is identical to the competitive approaches and is also fine-tuned from the ImageNet <ref type="bibr" target="#b7">[8]</ref> pre-trained model. We adopted a unified set of hyper-parameters throughout the Office-Home, Office-31 and ImageCLEF-DA datasets under both settings, where λ = 0.05, R = 25 in HAFN and ∆r = 1.0 in SAFN. Since the synthetic domain on VisDA2017 is easy to converge, we applied a slightly smaller λ and ∆r that equal to 0.01 and 0.3 respectively. We used mini-batch SGD optimizer with learning rate 1.0 × 10 −3 on all benchmarks. We used center-crop images for the reported results. For each transfer task, we reported the average accuracy over three random repeats. For fairer comparison with those methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24]</ref> which used ten-crop images at the evaluation phase with the best-performing models, we also included our corresponding results with the notion of {method}* to benefit the future comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Result Analysis</head><p>Results on Office-Home, VisDA2017, ImageCLEF-DA and Office-31 under the vanilla setting are reported in <ref type="table" target="#tab_0">Table 1</ref>, 2, 3, 4 respectively. Results on Office-Home and VisDA2017 under the partial setting are reported in Table 5, 7. Robustness evaluations in terms of CNG, ONG and PNG are shown in <ref type="table" target="#tab_5">Table 6</ref>. As illustrated, our methods significantly outperform the state-of-the-arts throughout all experiments, where SAFN is the top-performing variant.</p><p>Results on VisDA2017 reveal some interesting observations: i) Adversarial based models such as DANN may not effectively learn a diverse transformation across domains on this extremely large-scale transfer task and is prone to suffer from the risk of mode mismatch. However, our encouraging results prove the efficacy of AFN to work reasonably on this large-scale dataset and bridge the significant synthetic-to-real domain gap. ii) Note that existing methods usually mix and optimize multiple learning objectives, and it is not always easy to get an optimal solution. For example, MCD <ref type="bibr" target="#b34">[35]</ref> incorporates another class balance objective to align target samples in a balanced way. Nevertheless, our method yields superior performance on most categories, revealing that it is robust to the unbalanced issue without any other auxiliary constraint. iii) Our model is parameter-free thus is more lightweight than the compared methods.</p><p>As indicated in <ref type="table" target="#tab_0">Table 1</ref>, 3 and 4, our methods achieve new state-of-the-arts on these three benchmarks, and with larger rooms of improvement for those hard transfer tasks,    <ref type="table" target="#tab_4">Table 5</ref> and 7, our models obtain substantial improvements for partial DA, with 11.5% gain on Office-Home and 17.1% gain on VisDA2017. Plain domainadversarial networks, e.g., DANN, seriously suffer from the mismatch from the source outlier classes and perform even worse than the Source Only variant. An intuitive solution, e.g., PADA <ref type="bibr" target="#b6">[7]</ref>, is to detect and down-weight the outlier categories during the domain alignment. However, without any heuristic reweighting mechanism, our featurenorm-adaptive manner exhibits stronger robustness against the unrelated data from the source domain. We testify this point via more thorough evaluation in <ref type="table" target="#tab_5">Table 6</ref>. Besides, our method works stably and does not require to adjust different hyper-parameters for different subtasks within the same dataset as was done in PADA.</p><p>We carefully conduct robustness evaluation for the most challenging transfer tasks, e.g., Ar65 → Rw25, Synthetic-12 → Real-6 and etc. As described in Section 3.6, the positive gap implies more negative impacts over the positive gains and vice versa. The target labeled ratio is 5% and 1% for the two benchmarks. Results in <ref type="table" target="#tab_5">Table 6</ref> reveal some interesting observations: i) Throughout all evaluation met-rics on all transfer tasks, we can either achieve the largest transfer gains or smallest negative influences. ii) All the methods, including ours, are inevitable to the positive ONG under the more challenging partial setting, while SAFN alleviates the outlier negative impact to the utmost extent. iii) For the Cl → Rw transfer task, the comparison methods all have positive PNG, suggesting that they are unable to obtain more transfer gains from the Cl65 domain than using only 5% Rw25 labeled samples. However, we still derive encouraging result in this task. iv) It is noteworthy that on the most challenging VisDA2017 dataset with the significant synthetic-to-real gap, current approaches, including ours, all fail to distill more positive knowledge from the synthetic domain than just labeling 1% real samples. It remains a big challenge for the future development of DA community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Ablation Study</head><p>Feature Visualization: Although testifying the efficacy of a DA algorithm via t-SNE <ref type="bibr" target="#b26">[27]</ref> embeddings is considered over-interpreted, <ref type="bibr" target="#b2">3</ref> we still follow the de facto practice to provide the intuitive understanding. We randomly select 2000 samples across 12 categories from the source and target domains on VisDA2017 and visualize their task-specific features by t-SNE. As shown in <ref type="figure" target="#fig_4">Fig. 4(a)</ref>, the ResNet features of target samples collide into a mess because of extremely large synthetic-to-real domain gap. After adaptation, as illustrated in <ref type="figure" target="#fig_4">Fig. 4(b)</ref>, our method succeeded in separating target domain samples and better aligning them to the corresponding source domain clusters.</p><p>Sample Size of Target Domain: In this part, we empirically demonstrate that our approach is scalable and datadriven with respect to the increase of unlabeled target sam-  ples, which exposes the appealing capacity in practice. It is not necessarily intuitive for adversarial learning based methods to optimize and obtain a diverse transformation upon large volumes of unlabeled target samples. Specifically, we shuffle the target domain on VisDA2017 and sequentially access the top 25%, 50%, 75% and 100% of the dataset. We train and evaluate our approach on these four subsets. As illustrated in <ref type="figure">Fig. 3(a)</ref>, with the sample size gradually increases, the classification accuracy of the corresponding target domain grows accordingly. It shows that the more unlabeled target data are involved in the feature norm adaptation, the more transferable classifier can be obtained. Complementary with Other Methods: In this part, we demonstrate that our approach can be used in combination with other DA techniques. Because of limited space, we particularly exploit ENTropy minimization (ENT) <ref type="bibr" target="#b14">[15]</ref>, a low-density separation technique, for demonstration. ENT is widely applied in DA community <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b21">22]</ref> to encourage the decision boundary to pass through the target lowdensity regions by minimizing the conditional entropy of target samples. We conduct this case study on ImageCLEF-DA and Office-31 datasets and report the accuracies in Table 3 and 4 respectively. As indicated, with ENT to fit the target-specific structure, we further boost the recognition performance by 0.8% and 1.4% on these two datasets.</p><p>Sensitivity of R and ∆r: We conduct case studies to investigate the sensitivity of parameter R in HAFN and parameter ∆r in SAFN. We select VisDA2017 and task A→W for demonstration. The results are shown in <ref type="figure">Fig. 3(b)</ref> and <ref type="figure">Fig. 3(c)</ref>, by varying R ∈{5, 10, 15, 20, 25, 30, 35} on both datasets, ∆r ∈ {0.2, 0.3, 0.4, 0.5} on VisDA2017 and ∆r ∈ {0.5, 1.0, 1.5, 2.0} on task A→W. For parameter R, the accuracy first gradually increases with larger values of R and then begins to decrease as the feature-norm penalty in HAFN may explode. As shown in <ref type="figure">Fig. 3(c)</ref>, the accuracies stay almost the same as parameter ∆r varies, revealing that SAFN works reasonably stable on these two tasks.</p><p>Sensitivity of Embedding Size: We investigate the sensitivity of embedding size of the task-specific features as it plays a significant role in norm computation. We conduct this case study on both VisDA2017 and A→W transfer tasks. We report the average accuracy over three random repeats for those embedding sizes varying in {500, 1000, 1500, 2000}. As illustrated in <ref type="figure">Fig. 3(d)</ref>, the accuracy stays almost the same and achieves slightly higher when the embedding size is set to 1000, indicating that our approach is robust to a wide range of feature space dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented an innovative discovery for UDA, revealing that the model degradation on the target domain mainly stems from its much smaller feature norms with respect to that of the source domain. To this end, we demonstrated that progressively adapting the feature norms of the two domains to a large range of values can result in significant transfer gains, implying that those task-specific features with larger norms are more transferable. Our method is parameter-free, easy to implement and performs stably. In addition, we successfully unify the computation of both standard and partial DA, and thorough evaluations revealed that our feature-norm-adaptive manner is more robust against the negative transfer. Extensive experimental results have validated the virtue of our proposed approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Feature visualization of source and target samples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>L</head><label></label><figDesc>d (max(h(xi; θ0) + ∆r, R), h(xi; θ)) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>(a) and (b) correspond to the t-SNE embedding visualization of the Source Only and SAFN models on VisDA2017. The triangle and star markers denote the source and target samples respectively. Different colors indicate different categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Accuracy (%) on Office-Home under vanilla setting (ResNet-50) Method Ar→Cl Ar→Pr Ar→Rw Cl→Ar Cl→Pr Cl→Rw Pr→Ar Pr→Cl Pr→Rw Rw→Ar Rw→Cl Rw→Pr Avg ±0.2 70.1 ±0.2 76.6 ±0.3 61.1 ±0.4 68.0 ±0.1 70.7 ±0.2 59.5 ±0.2 48.4 ±0.3 77.3 ±0.2 69.4 ±0.0 53.0 ±0.6 80.2 ±0.3 65.4 SAFN 52.0 ±0.1 71.7 ±0.6 76.3 ±0.3 64.2 ±0.3 69.9 ±0.6 71.9 ±0.6 63.7 ±0.4 51.4 ±0.2 77.1 ±0.0 70.9 ±0.4 57.1 ±0.1 81.5 ±0.0 67.3</figDesc><table><row><cell>ResNet [16]</cell><cell>34.9</cell><cell>50.0</cell><cell>58.0</cell><cell>37.4</cell><cell>41.9</cell><cell>46.2</cell><cell>38.5</cell><cell>31.2</cell><cell>60.4</cell><cell>53.9</cell><cell>41.2</cell><cell>59.9 46.1</cell></row><row><cell>DAN [23]</cell><cell>43.6</cell><cell>57.0</cell><cell>67.9</cell><cell>45.8</cell><cell>56.5</cell><cell>60.4</cell><cell>44.0</cell><cell>43.6</cell><cell>67.7</cell><cell>63.1</cell><cell>51.5</cell><cell>74.3 56.3</cell></row><row><cell>DANN [10]</cell><cell>45.6</cell><cell>59.3</cell><cell>70.1</cell><cell>47.0</cell><cell>58.5</cell><cell>60.9</cell><cell>46.1</cell><cell>43.7</cell><cell>68.5</cell><cell>63.2</cell><cell>51.8</cell><cell>76.8 57.6</cell></row><row><cell>JAN [26]</cell><cell>45.9</cell><cell>61.2</cell><cell>68.9</cell><cell>50.4</cell><cell>59.7</cell><cell>61.0</cell><cell>45.8</cell><cell>43.4</cell><cell>70.3</cell><cell>63.9</cell><cell>52.4</cell><cell>76.8 58.3</cell></row><row><cell cols="2">CDAN* [24] 49.0</cell><cell>69.3</cell><cell>74.5</cell><cell>54.4</cell><cell>66.0</cell><cell>68.4</cell><cell>55.6</cell><cell>48.3</cell><cell>75.9</cell><cell>68.4</cell><cell>55.4</cell><cell>80.5 63.8</cell></row><row><cell cols="2">HAFN 50.2 SAFN* 54.4</cell><cell>73.3</cell><cell>77.9</cell><cell>65.2</cell><cell>71.5</cell><cell>73.2</cell><cell>63.6</cell><cell>52.6</cell><cell>78.2</cell><cell>72.3</cell><cell>58.0</cell><cell>82.1 68.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Accuracy (%) on VisDA2017 under vanilla setting (ResNet-101) ±0.7 55.4 ±4.1 82.4 ±2.6 70.9 ±1.2 93.2 ±0.9 71.2 ±3.9 90.8 ±0.5 78.2 ±1.3 89.1 ±0.7 50.2 ±2.4 88.9 ±0.8 24.5 ±0.5 73.9 SAFN 93.6 ±0.2 61.3 ±4.0 84.1 ±0.5 70.6 ±2.2 94.1 ±0.5 79.0 ±4.1 91.8 ±0.5 79.6 ±1.3 89.9 ±0.7 55.6 ±3.4 89.0 ±0.3 24.4 ±2.9 76.</figDesc><table><row><cell>Method</cell><cell>plane</cell><cell>bcycl</cell><cell>bus</cell><cell>car</cell><cell>horse</cell><cell>knife</cell><cell cols="2">mcycl person</cell><cell>plant</cell><cell>sktbrd</cell><cell>train</cell><cell cols="2">truck Per-class</cell></row><row><cell cols="2">ResNet [16] 55.1</cell><cell>53.3</cell><cell>61.9</cell><cell>59.1</cell><cell>80.6</cell><cell>17.9</cell><cell>79.7</cell><cell>31.2</cell><cell>81.0</cell><cell>26.5</cell><cell>73.5</cell><cell>8.5</cell><cell>52.4</cell></row><row><cell>DAN [23]</cell><cell>87.1</cell><cell>63.0</cell><cell>76.5</cell><cell>42.0</cell><cell>90.3</cell><cell>42.9</cell><cell>85.9</cell><cell>53.1</cell><cell>49.7</cell><cell>36.3</cell><cell>85.8</cell><cell>20.7</cell><cell>61.1</cell></row><row><cell cols="2">DANN [10] 81.9</cell><cell>77.7</cell><cell>82.8</cell><cell>44.3</cell><cell>81.2</cell><cell>29.5</cell><cell>65.1</cell><cell>28.6</cell><cell>51.9</cell><cell>54.6</cell><cell>82.8</cell><cell>7.8</cell><cell>57.4</cell></row><row><cell>MCD [35]</cell><cell>87.0</cell><cell>60.9</cell><cell>83.7</cell><cell>64.0</cell><cell>88.9</cell><cell>79.6</cell><cell>84.7</cell><cell>76.9</cell><cell>88.6</cell><cell>40.3</cell><cell>83.0</cell><cell>25.8</cell><cell>71.9</cell></row><row><cell cols="2">HAFN 92.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>1 which is indicated by Eq. (9) as follows:C2(θg, θ f , θy) = 1 ns(x i ,y i )∈Ds Ly(xi, yi)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Accuracy (%) on ImageCLEF-DA in vanilla setting Method I→P P→I I→C C→I C→P P→C Avg ResNet-50 [16] 74.8 83.9 91.5 78.0 65.5 91.2 80.7 DAN [23] 74.5 82.2 92.8 86.3 69.2 89.8 82.5</figDesc><table><row><cell>DANN [10]</cell><cell>75.0 86.0 96.2 87.0 74.3 91.5 85.0</cell></row><row><cell>JAN [26]</cell><cell>76.8 88.0 94.7 89.5 74.2 91.7 85.8</cell></row><row><cell cols="2">CDAN* [24] 76.7 90.6 97.0 90.5 74.5 93.5 87.1</cell></row><row><cell>HAFN</cell><cell>76.9 89.0 94.4 89.6 74.9 92.9 86.3</cell></row><row><cell></cell><cell>±0.4 ±0.4 ±0.1 ±0.6 ±0.2 ±0.1</cell></row><row><cell>SAFN</cell><cell>78.0 91.7 96.2 91.1 77.0 94.7 88.1</cell></row><row><cell></cell><cell>±0.4 ±0.5 ±0.1 ±0.3 ±0.5 ±0.3</cell></row><row><cell cols="2">SAFN+ENT 79.3 93.3 96.3 91.7 77.6 95.3 88.9</cell></row><row><cell></cell><cell>±0.1 ±0.4 ±0.4 ±0.0 ±0.1 ±0.1</cell></row><row><cell cols="2">SAFN+ENT* 80.2 93.8 96.7 92.8 78.4 95.7 89.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Accuracy (%) on Office-31 under vanilla setting SAFN+ENT 90.1 98.6 99.8 90.7 73.0 70.2 87.1 ±0.8 ±0.2 ±0.0 ±0.5 ±0.2 ±0.3 SAFN+ENT* 90.3 98.7 100.0 92.1 73.4 71.2 87.6</figDesc><table><row><cell>Method</cell><cell>A→W D→W W→D A→D D→A W→A Avg</cell></row><row><cell cols="2">ResNet-50 [16] 68.4 96.7 99.3 68.9 62.5 60.7 76.1</cell></row><row><cell>DAN [23]</cell><cell>80.5 97.1 99.6 78.6 63.6 62.8 80.4</cell></row><row><cell cols="2">DANN [10] 82.0 96.9 99.1 79.7 68.2 67.4 82.2</cell></row><row><cell cols="2">ADDA [43] 86.2 96.2 98.4 77.8 69.5 68.9 82.9</cell></row><row><cell>JAN [26]</cell><cell>85.4 97.4 99.8 84.7 68.6 70.0 84.3</cell></row><row><cell>GTA [36]</cell><cell>89.5 97.9 99.8 87.7 72.8 71.4 86.5</cell></row><row><cell cols="2">CDAN* [24] 93.1 98.2 100.0 89.8 70.1 68.0 86.6</cell></row><row><cell>HAFN</cell><cell>83.4 98.3 99.7 84.4 69.4 68.5 83.9</cell></row><row><cell></cell><cell>±0.7 ±0.1 ±0.1 ±0.7 ±0.5 ±0.3</cell></row><row><cell>SAFN</cell><cell>88.8 98.4 99.8 87.7 69.8 69.7 85.7</cell></row><row><cell></cell><cell>±0.4 ±0.0 ±0.0 ±1.3 ±0.4 ±0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Accuracy (%) on Office-Home under partial setting (ResNet-50) Method Ar→Cl Ar→Pr Ar→Rw Cl→Ar Cl→Pr Cl→Rw Pr→Ar Pr→Cl Pr→Rw Rw→Ar Rw→Cl Rw→Pr Avg ResNet [16] 38.57 60.78 75.21 39.94 48.12 52.90 49.68 30.91 70.79 65.38 41.79 70.42 53.71 DAN [23] 44.36 61.79 74.49 41.78 45.21 54.11 46.92 38.14 68.42 64.37 45.37 68.85 54.48 DANN [10] 44.89 54.06 68.97 36.27 34.34 45.22 44.08 38.03 68.69 ±0.44 ±0.53 ±0.50 ±0.48 ±0.30 ±1.04 ±0.68 ±0.42 ±0.51 ±0.13 ±0.37 ±0.19 ±0.50 ±0.33 ±0.27 ±0.46 ±1.39 ±0.52 ±0.31 ±0.46 ±0.78 ±0.37 ±0.83 ±0.20</figDesc><table><row><cell>52.98</cell><cell>34.68</cell><cell>46.50 47.39</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Evaluation on the Robustness</figDesc><table><row><cell>Method</cell><cell cols="12">Ar → Rw (5%) CNG ONG PNG CNG ONG PNG CNG ONG PNG CNG ONG PNG Cl → Rw (5%) Pr → Rw (5%) VisDA2017 (1%)</cell></row><row><cell>DAN [23]</cell><cell>-14.6</cell><cell>13.8</cell><cell>-0.8</cell><cell>-4.9</cell><cell>24.5</cell><cell cols="2">19.6 -12.0</cell><cell>17.3</cell><cell>5.3</cell><cell>18.7</cell><cell>25.0</cell><cell>43.7</cell></row><row><cell cols="2">DANN [10] -17.2</cell><cell>21.9</cell><cell>4.7</cell><cell>-10.9</cell><cell>39.4</cell><cell cols="2">28.5 -14.5</cell><cell>19.5</cell><cell>5.0</cell><cell>13.6</cell><cell>26.7</cell><cell>40.3</cell></row><row><cell>JAN [26]</cell><cell>-15.3</cell><cell>13.1</cell><cell>-2.2</cell><cell>-7.1</cell><cell>19.1</cell><cell cols="2">12.0 -13.4</cell><cell>12.2</cell><cell>-1.2</cell><cell>20.4</cell><cell>24.5</cell><cell>44.9</cell></row><row><cell>PADA [7]</cell><cell>-17.2</cell><cell>12.2</cell><cell>-5.0</cell><cell>-10.9</cell><cell>25.6</cell><cell cols="2">14.7 -14.5</cell><cell>9.4</cell><cell>-5.1</cell><cell>13.6</cell><cell>24.2</cell><cell>37.8</cell></row><row><cell>SAFN</cell><cell>-18.1</cell><cell>8.5</cell><cell>-9.6</cell><cell>-13.6</cell><cell>8.2</cell><cell>-5.4</cell><cell>-16.1</cell><cell>7.7</cell><cell>-8.4</cell><cell>5.0</cell><cell>15.6</cell><cell>20.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Accuracy (%) on VisDA2017 under partial setting</figDesc><table><row><cell>Method</cell><cell>Synthetic-12→Real-6</cell></row><row><cell>ResNet-50 [16]</cell><cell>45.26</cell></row><row><cell>DAN [23]</cell><cell>47.60</cell></row><row><cell>DANN [10]</cell><cell>51.01</cell></row><row><cell>PADA* [7]</cell><cell>53.53</cell></row><row><cell>HAFN</cell><cell>65.06±0.90</cell></row><row><cell>SAFN</cell><cell>67.65±0.51</cell></row><row><cell>SAFN*</cell><cell>70.67</cell></row><row><cell cols="2">e.g., D → A, A → D, Cl → Pr, Cl → Rw and etc, where the</cell></row><row><cell cols="2">source and target domains are substantially different.</cell></row><row><cell>As illustrated in</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>https://interpretablevision.github.io/ Analysis of (a) varying unlabeled target sample size; (b)(c) parameter sensitivity of R and ∆r; (d) varying embedding size.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell><cell>1.0 Office-31 r 1.5</cell><cell>2.0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Accuracy</cell><cell>20% 30% 40% 50% 60% 70% 80% 90% 100% Sample size 0.69 0.70 0.71 0.72 0.73 0.74 0.75 0.76 SAFN on VisDA2017</cell><cell>Accuracy</cell><cell>55 60 65 70 80 85 75</cell><cell>5</cell><cell>10 15 20 25 30 35 Value of R VisDA2017 Office31(A-&gt;W)</cell><cell>Accuracy</cell><cell>72 76 88 80 84</cell><cell>0.2</cell><cell cols="2">0.3 VisDA2017 r 0.4 VisDA2017 Office31(A-&gt;W) 0.5</cell><cell>Accuracy</cell><cell>0.72 0.76 0.92 0.88 0.80 0.84</cell><cell>500</cell><cell>1000 Embedding Size 1500 VisDA2017 Office31(A-&gt;W) 2000</cell></row><row><cell></cell><cell>(a) Sample Size</cell><cell></cell><cell></cell><cell></cell><cell>(b) Sensitivity of R</cell><cell></cell><cell></cell><cell cols="2">(c) Sensitivity of ∆r</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(d) Embedding Size</cell></row><row><cell cols="2">Figure 3: VisDA2017_Source_Only</cell><cell></cell><cell></cell><cell></cell><cell>VisDA2017_SAFN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>plane bcycl bus car horse knife mcycl person plant sktbrd train truck</cell><cell cols="2">plane bcycl bus car horse knife mcycl person plant sktbrd train truck</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Source Target</cell><cell cols="2">Source Target</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(a) Source Only</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>3</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://pytorch.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Impossibility theorems for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pál</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Integrating structured biological data by kernel maximum mean discrepancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="49" to="57" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised pixel-level domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Partial transfer learning with selective adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Partial adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domainadversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep reconstruction-classification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning kernels for unsupervised domain adaptation with applications to visual object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="3" to="27" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Understanding the disharmony between dropout and batch normalization by variance shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.05134</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised image-toimage translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transferable representation learning with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fewshot adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6670" to="6680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Usman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06924</idno>
		<title level="m">Visda: The visual domain adaptation challenge</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">From source to target and back: symmetric bi-directional adaptive gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2988" to="2997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generate to adapt: Aligning domains using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="8503" to="8512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A dirt-t approach to unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Narui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th International Conference on Learning Representations</title>
		<meeting>6th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Return of frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2011 IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<title level="m">Deep domain confusion: Maximizing for domain invariance</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.09751</idno>
		<title level="m">Characterizing and avoiding negative transfer</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.00124</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Collaborative and adversarial network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3801" to="3809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Ring loss: Convex feature normalization for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5089" to="5097" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
