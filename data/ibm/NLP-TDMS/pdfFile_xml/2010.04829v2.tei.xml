<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Supervised Relation Classification as Two-way Span-Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Amir</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bar Ilan University amirdnc@gmail</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bar Ilan University amirdnc@gmail</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachar</forename><surname>Rosenman</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Bar Ilan University shacharosn@gmail</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
							<email>yoav.goldberg@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<addrLine>&amp; AI2</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Supervised Relation Classification as Two-way Span-Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The current supervised relation classification (RC) task uses a single embedding to represent the relation between a pair of entities. We argue that a better approach is to treat the RC task as span-prediction (SP) problem, similar to Question answering (QA). We present a span-prediction based system for RC and evaluate its performance compared to the embedding based system. We demonstrate that the supervised SP objective works significantly better then the standard classification based objective. We achieve state-of-the-art results on the TACRED and SemEval task 8 datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The relation classification (RC) task revolves around binary relations (such as "[e 1 ] founded [e 2 ]") that hold between two entities. The task is to read a corpus and return entity pairs e 1 , e 2 for which the relation holds (according to the text). This is often posed as a Relation Classification task (RC), in which we are given a sentence and two entities (where each entity is a span over the sentence), and need to classify the relation into one of |R| possible relations, or to a null "no-relation" class if none of the |R| relations hold between the given entities. Relation Extraction datasets, including the popular and large TACRED dataset <ref type="bibr" target="#b20">(Zhang et al., 2017)</ref>, all take the relation classification view, by providing tuples of the form (s, e 1 , e 2 , r), where s is a sentence, e 1 , e 2 are entities in s and r is a semantic relation between e 1 and e 2 . Consequently, all state-of-the-art models follow the classification view: the sentence and entities are encoded into a vector representation, which is then being classified into one of the R relations. The training objective then aims to embed the sentence + entities into a space in which the different relations are well separated. We argue that this is a sub-optimal training architecture and training objective for the task, and propose to use span-predictions models, as used in question-answering models, as an alternative. Our method converts RC datasets to the SP form, using this reduction we evaluate the RC using SP models in a supervised setting. We show a high level flow of our method in <ref type="figure">Figure 1</ref>. <ref type="bibr" target="#b0">Alt et al. (2020)</ref> analyzed the errors of current RC systems and showed that 10% of the errors are the result of predicting a relation that is based on other arguments in the sentence. This was further explored by <ref type="bibr" target="#b15">(Rosenman et al., 2020)</ref>, where the authors showed that the current embedding based methods often classify a sentence without considering the marked entities. Our span-prediction method forces the model to identify the exact entities which compose each relation, which helps the model to overcome the challenges presented in these two works. We demonstrate this on the TACRED and SemEval datasets. Our method surpasses the current state-of-the-art on these datasets by 2.3F 1 points on TACRED and 0.9F 1 points on SemEval. Additionally, we experiment with the newly "released challenge relation extraction" (CRE) dataset, which was made specifically to test the existence of shallow heuristics in RE models. On all three datasets, our span-prediction models outperform existing RC. We also experiment with several different templates and show that our method can benefit from templates that add some prior semantic knowledge that is related to the classified relation type. All the method we present and our experiments will are publicly available online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Using QA for zero-shot RE/RC has been explored by <ref type="bibr" target="#b9">Levy et al. (2017)</ref>, who demonstrated that by posing each relation as a question, one can train a system that transfers well to new and unseen relations in a "zero-shot" setting. We show that by improving their reduction by making it twodirectional and switching to a fully supervised setup we can improve the accuracy of state-of-the- <ref type="figure">Figure 1</ref>: Traditional RC (top) VS our span-prediction approach (bottom). for each relation type that is compatible with the marked entity type, we create two questions. If the model answers one of them correctly, we assert the relation over the two entities.</p><p>art RC system. Following <ref type="bibr" target="#b9">Levy et al. (2017)</ref>, several works proposed the use of SP like architectures to solve a variety of tasks like coreference resolution <ref type="bibr" target="#b19">(Wu et al., 2019)</ref>, event extractions <ref type="bibr" target="#b3">(Du and Cardie, 2020)</ref>, nested named entities <ref type="bibr" target="#b11">(Li et al., 2019a)</ref> and multi turn entity extraction <ref type="bibr" target="#b12">(Li et al., 2019b)</ref>. While the mentioned works used SP models to improve performance on a specific task, It's worth mentioning that other works have used QA for different reasons, like <ref type="bibr" target="#b4">(He et al., 2015)</ref> that used QA as an easier way to annotate data for the SRL task.</p><p>Recently, <ref type="bibr" target="#b6">Jiang et al. (2019)</ref> presented a unified model for many NLP tasks, using a unified spanbased classification method. Such predictors may also benefit from adopting a QA-like span modeling, as we present here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Embedding Classification vs Span-Prediction</head><p>Embedding-Based Relation Classification A RC sample takes the form (c, e 1 , e 2 , r) where c = [c 0 , . . . , c n ] is a context (usually a sentence), e 1 and e 2 are spans that correspond to head and tail entities and are given as spans over the sentence, and r ∈ R ∪ {∅} is a relation from a predefined set of relations R, or ∅ indicating that no relation from R holds. RC classifier takes the form of a multi-class classifier:</p><formula xml:id="formula_0">f rc (c, e 1 , e 2 ) → r ∈ R ∪ {∅}</formula><p>The training objective is to score the correct r ∈ R ∪ {∅} overall incorrect answers, usually using a cross-entropy loss. State-of-the-art methods (Baldini Soares et al., 2019) achieve this by learning an embedding function embed(c, e 1 , e 2 ) that maps instances with the same relation to be close to the embedding of the corresponding relation in an embedding space. The embedding function is used on pre-trained masked LMs such as SpanBERT <ref type="bibr" target="#b7">(Joshi et al., 2020)</ref>, RoBERTa  and ALBERT <ref type="bibr" target="#b8">(Lan et al., 2019)</ref>.</p><p>Span Prediction A SP sample takes the from of (c, q, e a ) where c = [c 0 , . . . , c m ] is a context (a sentence or a paragraph), q = [q 0 , . . . , q l ] is a query, and e a is the answer to the query represented as a span over the c, or a special out-of-sequencespan indicating that the answer does not exist. 1 SP model takes the form of a span predictor from a c, q pair to a span over c:</p><formula xml:id="formula_1">f qa (c, q) → e a ∈ [1..m] × [1..m]</formula><p>This predictor takes the form:</p><formula xml:id="formula_2">arg max ea score c,q (e a )</formula><p>where score c,q (e a ) is a learned span scoring function, and e a ranges over all possible spans. The training objective is to maximize the score the correct spans above all other candidate spans. The scoring function in state-of-the-art models <ref type="bibr">(Mc-Cann et al., 2018;</ref><ref type="bibr" target="#b4">He et al., 2015;</ref><ref type="bibr" target="#b19">Wu et al., 2019)</ref> also make use of pre-trained LMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Method Comparison</head><p>The question q ("where was Sam born?") in QA can be thought of as involving a span e q ("Sam") and a predicate r q ("where was born"). Under this view, the SP classifier can be written as:</p><p>f qa (c, e q , r q ) → e compared to the relation classifier:</p><p>f rc (c, e 1 , e 2 ) → r</p><p>Note that both methods include a context, two spans, and a relation/predicate, but the RC models classify from two spans to a relation (from a fixed set), while the SP model classify from a span and a relation (from a potentially open set) into another span. Let's review the implications of this difference:</p><p>Embedding While the two methods embeds the input prior to classification, the items that are being embedded change. In RC the embedding h re is based on the context and entities:</p><p>h re = embed(c, e 1 , e 2 ) while for span-prediction the embedding h qa encodes both the context and the question (the relation of interest and one of the entities): 2 h qa = embed(q, c) = embed(r, e 1 , c)</p><p>Note that the span-predictor embedding includes the relation name, as well as template word that surround the (r, e 1 ) pair. This makes the embedding strictly more informative, and has several benefits, as we explain below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implications</head><p>Relation type indication for the pretrained model. The inclusion of the relation r in the input to the contextualized embedder allows the embedder to specialize on a specific relation. For example, consider the sentence "Martha gave birth to John last February". The entity John participates in two relations: "date of birth" and "parents of". The RC embedding will have to either infer the relation based on the entities, or else preserve information regarding both relations, while in the spanprediction case the embedding takes the relation r into account, and can focus on the existence (or nonexistence) of one of the entities as the argument for this relation. Focusing on a specific relation in the embedding stage (which involves most of the computation of the model) allows using all of the model computation for a specific relation.</p><p>Sharing of semantic information. The spanprediction model is based on templates encoding r and e, and these templates may pass valuable information to the model: (1) by containing semantic information that is correlated to the target relation (e.g. questions that represent the relation); and (2) by containing information that can help generalize over different relations.</p><p>For example, consider the relation "born in" with the template question "Who was born in X?" and the relation "parent of" with the question "Who is the parent of X?". While the relations are different from each other, they both contain an entity of type "person", a similarity which is communicated to the model by the use of the shared word "Who". This can help the model generalize commonalities across relation types, when needed.</p><p>More demanding loss function. During training, relation-classification models classify sentences with marked entities to one of |R| + 1 relation types. Span prediction models are also required to decide whether the sentence contains a given relation (they should predict if the sentence contains the answer or not), but they are also required to predict the span of the missing argument. This means that the span-prediction models are required to predict the relation between the input entities in addition to the relation itself.</p><p>Limitations. It is important to note, however, that the span-prediction method is more computationally expensive: instead of performing a single contextualized embedding operation followed by k + 1-way classification, we need to perform k contextualized embedding operations (and in our case, 2k such operations), each of them followed by scoring of all spans. We leave ways of improving the computational efficiency of the model to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reducing RC to span-prediction</head><p>Given the uncovered similarity between RC and span-predicting showed in Section 3.1, we now describe how to reduce RC to SP.</p><p>Given an RC instance (c, e 1 , e 2 ) → rel we can create an SP instance (q = (e q , rel q ), c) → e a as follows. Let T rel (e) be a template function associated with relation rel. The function takes an entity e and returns a question. For example, a template for date-of-birth relation might be T dob ="When was born", and T dob (Sam) ="When was Sam born?". Given an RC instance (c, e 1 , e 2 ) → rel we can now create a span-prediction instance (T rel (e 1 ), c) → e 2 , and return that the relation rel holds if the span returned from f qa (T rel (e 1 ), c) is compatible with e 2 . This is essentially the construction used by <ref type="bibr" target="#b9">(Levy et al., 2017)</ref>.</p><p>Bidirectional questions. We note that the decision to predict e 2 based on e 1 is arbitrary, and that we could have just as well change the template to e.g. "Who was born on ?", and predict e 1 from e 2 .</p><p>We propose to use both options, by associating a relation rel with two templates, T e 1 →e 2 rel and T e 2 →e 1 rel , creating the two corresponding SP instances, and combining the two answers. Con-cretely, given the RC instance: We show in Section 5 that using two questions indeed results in substantial improvements.</p><formula xml:id="formula_3">RC:(c, Sam, 1991) → date-of-birth</formula><p>Template formulation. Note that while in this example we formulate the questions in English, simpler template might also be used. We also experiment with a template that replaces the question by the relation name and another template that used an unused token for each relation. We elaborate on the template variations in detail in Section 5.</p><p>Answer combination. There are various possible strategies to combining the two answers. An approach which we found to be effective is to combine using an OR operation: if either of the returned spans is compatible with the expected span, 3 the relation rel is returned, and if neither of them is compatible, the answer is no-relation.</p><p>A natural alternative is to combine using an AND operation, requiring the answers of the two questions to be compatible in order to return rel. In our experiments (Section 7), this yielded lower Fscores on the relation classification task, as we classified more cases as no-relation when we shouldn't have. The span predictor network had easier time answering one formulation on some instances, and the other formulation on others. As span-prediction models quality improve, future applications may reconsider the combination method.</p><p>Binary vs. Multiclass. This reduction targets a binary version of RC, where the relation is given and the classifier needs to decide if it holds or not. We extended it to the multi-class version by creating a version for each of the relevant 4 relations. 5</p><p>Supervised dataset construction. The reduction allows to train a SP model to classify RC instances. For each RC training instance (c, e 1 , e 2 , r), where r ∈ R∪{∅}, we consider all relations r ∈ R which are compatible with (e 1 , e 2 ). <ref type="bibr">6</ref> We then generate two SP instances for each of the compatible relations. Instances that are generated with the templates of the gold-relation r are marked as positive instances (their answer is either e 1 or e 2 , as appropriate), while instances that are generated from r = r are negative examples (their answer is the no-answer span). <ref type="figure" target="#fig_0">Figure 2</ref> provides an example.</p><p>Per-template thresholds. General purpose SP models use a global threshold τ to distinguish between answerable and non-answerable questions given a context. In the supervised relation classification case, the set of questions is fixed in advance to 2|R|. We observe that the optimal threshold value for each question is different. We thus set a different threshold value τ i rel for each template. The threshold is set using the model's threshold setting procedure, but considering the set of questions generated from each template separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Main Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We compare ourselves on three RC datasets.</p><p>TACRED <ref type="bibr" target="#b20">(Zhang et al., 2017)</ref> is the currently most popular and largest RC dataset. It spans 41 "classic" RC relations, which hold between persons, locations, organizations, dates, and so on (e.g, "siblings", "dates of birth", "subsidiaries", etc). TA-CRED contains 106,264 labeled sentences (train + dev + test), where 20% of the data is composed 4 A relation is relevant for a given pair of entities if the entities types match that of the relation. <ref type="bibr">5</ref> In the rare case (less than 4%) that our model predicts more than one relation, we return one of them arbitrarily. 6 A relation is compatible with a pair of entities if it is between entities with the same named-entity types. from the 41 relations and the rest 80% are "no relation" instances. Challenge relation extraction (CRE) Rosenman et al. <ref type="bibr">(2020)</ref> showed that current RC models have a strong bias towards shallow heuristic that does not capture the deep semantically relation between entities. For example, classifying an entity pair by the entities type + an unrelated event in the sentence. To show this bias empirically, they created a Wikipedia based dataset intended to be used only for testing, which contains 3000 manually tagged sentences from the TACRED relations. Each sentence in the dataset contains two entity pairs that are compatible with the same relation. The evaluation of the CRE is binary -the model goal is to indicate if a given relation is found or not found in the dataset. The model was evaluated with both SP and RC models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Template variations.</head><p>We convert the TACRED and SemEval training sets to span-prediction form in three ways, representing various amounts of semantic information. From most informative to least, the variations are:</p><p>Natural language questions (question) For each RC sample we create two samples, as described in Section 4. The complete template list is available in the supplementary materials. Each of the datasets used the same train/validation/test splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparisons</head><p>We compare our results to several leading models, reporting the results from the corresponding papers. LiTian <ref type="bibr" target="#b10">(Li and Tian, 2020)</ref> is the current topscoring model on the SemEval dataset. It uses a dedicated RC architecture and uses the BERT pretrained LM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Models</head><p>We train span-predicting models using the architecture described in <ref type="bibr" target="#b2">(Devlin et al., 2018)</ref>, starting from either the BERT-Large <ref type="bibr" target="#b2">(Devlin et al., 2018)</ref> or ALBERT <ref type="bibr" target="#b8">(Lan et al., 2019)</ref> pre-trained LMs. <ref type="bibr">8</ref> BERT-large is used to compare the SOTA model reported in (Baldini Soares et al., 2019) on equal grounds, while ALBERT is a stronger pre-trained LM which is used to show the full capabilities of our approach. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Main Results</head><p>The results of the CRE evaluation are presented in <ref type="table">Table 1</ref>. We report the results in the same format <ref type="bibr">7</ref> The same paper reports additional results based on external training data, which is not comparable. However, these results have since been superseded by the KEPLER model. <ref type="bibr">8</ref> We used the implementations provided by Huggingface <ref type="bibr">(Wolf et al., 2019)</ref>. Following previous work, used the Adam optimizer, an initial learning rate of 3e −5 , and up to 20,000 steps with early stopping on a dev-set. <ref type="bibr">9</ref> We also ran preliminary tests using  and <ref type="bibr" target="#b7">(Joshi et al., 2020)</ref> that showed inferior results compared to ALBERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Acc + Acc − Acc   used in the original paper: the percentage of positive samples that were identified correctly (Acc + ), the percentage of negative samples that were identified correctly (Acc − ), and the overall weighted accuracy (Acc). Except for the token-BERT reduction, all of the reduction we used surpassed their RC and SQuAD trained models, where the SP model (BERT and ALBERT) improve by more then 5% compared to the squad models. We also observed a correlation between the amount of semantic information in the templates and the model performance.</p><p>The results for TACRED are presented in <ref type="table" target="#tab_1">Table  2</ref>, both our BERT based SP and relation datasets outperform MTB model. like in CRE, there is a clear correlation between the amount of semantic data in the template and the model accuracy. This is somewhat surprising considering the fact that the amount of semantic data given to each relation template in the QA reduction is negligible compared to the amount of data the model see during training.</p><p>The results for SemEval are presented in <ref type="table" target="#tab_2">Table  3</ref>. The best performing model is the QA model, which also suppress LiTian's model. Surprisingly, the token model perform better than the relation token, which somewhat undermine our hypothesis that the semantic information in the templates correlates to the model overall accuracy. We explain this anomaly by looking at the relation names in SemEval. In contract to TACRED (and CRE) the relation names in SemEval are somewhat abstract, and have lower semantic similarity to the relation instances. For example, the TACRED relation "per:parents" gives a lot more information than the SemEval relation "instrument-agency".</p><p>Another difference between the datasets is the difference in accuracy gain from each of our models CRE has the most benefit, then TACRED and then SemEval. We assume that this difference originates from the dataset nature -The "shallow huristics" shown by (Rosenman et al., 2020) that CRE was made to highlight are more prominent in TA-CRED then SemEval. . Our span-prediction based loss is specially tailored to deal with such situations. In contrast, SemEval does not contain the "no relation" type, and the chance of any two relations to appear in the same sentence is low, resulting in this challenge to be a lot less prominent on SemEval then TACRED.</p><p>Since we didn't have access to KEPLLER (the current SOTA), we used the best pretrained model available to us -ALBERT model. all of our ALBERT-based relation reduction methods outperforms the current best TACRED model (KEPLER) by 2.3% F 1 , despite KEPLER using external data.   <ref type="table">Table 5</ref>: Answer combination method. TACRED performance when using the AND combination (in brackets, the corresponding OR combination). Using AND substantially increase precision, while dropping recall, resulting in a lower F 1 score on all models.</p><p>Another anomaly is that on ALBERT, the QA reduction performed worse by the relation reduction and even the token reduction. This somewhat undermines our assumption that QA reduction is superior to relation reduction because the former contains more information about the relation type. We currently have no convincing explanation to this result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ablations</head><p>The importance of bidirectional questions. To assess the impact of using questions in both directions, we also report the ALBERT-based QAreduction on TACRED in which we present two questions per relation, but where both questions use e 1 as the template argument and e 2 as the answer ("Single Question" in <ref type="table" target="#tab_4">Table 4</ref>). This model has significantly less success than the two-way model, resulting in a drop of 2.4%F 1 .</p><p>Combination using OR vs. AND. We combine the answers of the two generated questions by an "OR" operator, but the same can be done with the "AND" operator. To check this we ran our models but report the relation as "present" iff the two questions return a correct answer. In <ref type="table">Table 5</ref>   drop in F 1 of about 10%. The reason for this degradation is that the AND operator is more focused on precision, while the OR operator is more focused on recall. Over the years a major challenge of RC system was to increase recall (She et al., 2018) -It's easier for RC system to filter unrelated samples then to generalize to new patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Relation to SQuAD Training</head><p>We advocated a fully-supervised training of RC models as span-prediction. How well does this compare to using existing QA models, like SQuAD, in a zero-shot setting? And can we leverage the existing knowledge in QA datasets, via pre-training?</p><p>We explore these two options, and conclude that while the zero shot accuracy is impressively high, the unification of SQuAD and TACRED harm the overall accuracy.</p><p>Zero-shot SQuAD In light of the success of SQuAD trained model on CRE (as demonstrated by Rosenman et al. <ref type="formula">(2020)</ref>), we evaluate the SQuAD 2.0 trained model performance on TACRED, using our bidirectional reduction. In this zero shot setup we take a SQuAD trained model (without any modifications) and apply our reduction to evaluate the test set of TACRED.</p><p>Joined training with SQuAD We now attempt to leverage the SQuAD 2.0 data to improve our RC model. We train our SP question,BERT model by combining the data original SQuAD questions and the TACRED-generated questions. We do this in two ways: in the unified version we combine the two datasets simply by shuffling together the TA-CRED and SQuAD questions into a single dataset.</p><p>In the serial version we first train on the SQuAD data, and then continue training the model on TA-CRED data.</p><p>Results <ref type="table" target="#tab_6">Table 6</ref> lists the results. Unsurprisingly, the zero shots F 1 score on TACRED is are substantially lower than all the supervised variants. However, the recall of the zero shot setup is substantially higher: the SQuAD 2.0 model is very permissive. Interestingly, the additional SQuAD questions did not improve-and even substantially hurt-the SP method compared to train on only the TACREDgenerated questions. This goes to highlight that the main benefits of the SP method comes from the combination of the supervised training and the span-prediction objective, and not merely from the QA form, or from the additional semantic information that is potentially embedded in the QA models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this work, we argue for the use of spanprediction methods, typically used for QA, to replace the standard RC architectures. Our approach reduce each RC sample to a series of binary spanprediction tasks. We Show that This approach achieves state-of-the-art performance in supervised settings, with the moderate cost of supplying question templates that describe the relation. <ref type="table" target="#tab_8">Tables 7 and 8 on the next page show the question  templates we used on the TACRED dataset for</ref>  org:parents Q1: What organization is the parent organization of e 1 ? Q2 What organization is the child organization of e 2 ? org:subsidiaries Q1: What organization is the child organization of e 1 ? Q2 What organization is the parent organization of e 2 ?  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Templates For TACRED</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Supervised dataset construction. Example of span-prediction samples that are generated from RC samples. The RC sample contains sentence, entities (highlighted) and relation, while the span-prediction sample has a context (same as the sentence the RC sentence), a query, and an answer. A set of relation questions are created based on the RC entities types; underlined relations are the correct ones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>we create the two SP instances: QA1:(c, When was Sam born?) → 1991 QA2:(c, Who was born in 1991?) → Sam</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>SemEval 2010 Task 8(SemEval, Hendrickx  et al. (2010)), is a smaller dataset, containing 10,717 annotated examples covering 9 relations, without no-relation examples. SemEval relations are substantially different from those in TACRED, covering more abstract relations such as part-whole, cause-effect, content-container, and so on.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Relation name (relation) Same as the question dataset, but we replace each of the questions with the relation name, entity, and a marker that indicate if it's a head or tail entity. E.g., the relation RC:(c, John, CEO) → per:title will be represented as the questions: QA1:(c, per:title t John) → CEO QA2:(c, per:title h CEO) → John Unique tokens (token) Same as the relation dataset, but we replace the relation name with a new reserved token. E.g., the above per:title relation will be represented as the questions: QA1:(c, r2 t John) → CEO QA2:(c, r2 h CEO) → John</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>MTB</head><label></label><figDesc><ref type="bibr" target="#b1">(Baldini Soares et al., 2019)</ref> is a state of the art RC model which is based on BERT-large, and which does not involve any additional training material except for the pre-trained LM. MTB way of creating sentence embedding is the current SOTA, and thus our most direct comparison. 7 KEPLER This model holds the current highest reported RC results over TA-CRED. It is a RoBERTa based RC model which incorporates additional knowledge in the form of a knowledge-graph derived from Wikipedia and Wikidata and uses MTB for sentence embedding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>TACRED. Supervised results on the TACRED datasets. Top: Using BERT. This is a direct comparison to the MTB span-prediction model. MTB F 1 is taken from the original paper. SP models (except token) suppress MTB. Bottom: Using ALBERT. Here the reference point is KEPLLER, the current best performing model on this dataset. All the supervised SP-ALBERT models outperform KEPPLER.</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F 1</cell></row><row><cell>RC M T B,BERT</cell><cell>-</cell><cell>-</cell><cell>89.2</cell></row><row><cell cols="4">LiTian (current best) 94.2 88.0 91.0</cell></row><row><cell>SP token,BERT</cell><cell cols="3">92.8 88.8 90.7</cell></row><row><cell>SP relation,BERT</cell><cell cols="3">91.9 83.1 87.1</cell></row><row><cell>SP question,BERT</cell><cell cols="3">90.7 93.2 91.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>SemEval. Supervised results on the SemEval datasets. LiTian is the current state of the art.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Importance of bidirectional questions. The SP question,ALBERT model with two questions combined via OR (full setup), vs. a single question. Asking two questions instead of one significantly increase the model performance.</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F 1</cell></row><row><cell>SP token,BERT</cell><cell cols="3">80.1 (63.3) 54.7 (78.4) 65.0 (70.0)</cell></row><row><cell>SP relation,BERT</cell><cell cols="3">84.4 (67.0) 44.8 (76.0) 58.5 (71.2)</cell></row><row><cell>SP question,BERT</cell><cell cols="3">83.15 (71.1) 50.0 (72.6) 62.4 (71.8)</cell></row><row><cell>SP token,ALBERT</cell><cell cols="3">80.1 (72.2) 54.7 (74.6) 65.0 (73.4)</cell></row><row><cell>SP relation,ALBERT</cell><cell cols="3">81.9 (74.6) 56.1 (75.2) 66.6 (74.8)</cell></row><row><cell cols="4">SP question,ALBERT 81.2 (73.3) 55.9 (71.8) 66.3 (72.6)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Using</figDesc><table><row><cell>SQuAD 2.0 Top: Evaluating SQuAD</cell></row><row><cell>2.0 QA model on TACRED in a zero-shot setup, using</cell></row><row><cell>our bidirectional SP reduction. Mid: "Fine-tuning" the</cell></row><row><cell>SP question,BERT models on TACRED after SQuAD</cell></row><row><cell>2.0 per-training. Bottom: The SP model trained with</cell></row><row><cell>out pre-training, significantly outperforming the pre-</cell></row><row><cell>trained variants.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>the QA reduction.</figDesc><table><row><cell>Relation Name</cell><cell>Question</cell></row><row><cell>per:date_of_birth</cell><cell>Q1: When was e 1 born? Q2 Who was born in e 2 ?</cell></row><row><cell>per:title</cell><cell>Q1: What is e 1 's title? Q2 Who has the title e 2</cell></row><row><cell>org:top_members/employees</cell><cell>Q1: Who are the top members of the organization e 1 ? Q2 What organization is e 2 a top member of?</cell></row><row><cell>org:country_of_headquarters</cell><cell>Q1: In what country the headquarters of e 1 is? Q2 What organization have it's headquarters in e 2 ?</cell></row><row><cell>per:parents</cell><cell>Q1: Who are the parents of e 1 ? Q2 Who are the children of e 2 ?</cell></row><row><cell>per:age</cell><cell>Q1: What is e 1 's age? Q2 Whose age is e 2 ?</cell></row><row><cell>per:countries_of_residence</cell><cell>Q1: What country does e 1 resides in? Q2 Who resides in country e 2 ?</cell></row><row><cell>per:children</cell><cell>Q1: Who are the children of e 1 ? Q2 Who are the parents of e 2 ?</cell></row><row><cell>org:alternate_names</cell><cell>Q1: What is the alternative name of the organization e 1 ? Q2 What is the alternative name of the organization e 2 ?</cell></row><row><cell>per:charges</cell><cell>Q1: What are the charges of e 1 ? Q2 Who was charged in e 2 ?</cell></row><row><cell>per:cities_of_residence</cell><cell>Q1: What city does e 1 resides in? Q2 Who resides in city e 2 ?</cell></row><row><cell>per:origin</cell><cell>Q1: What is e 1 origin? Q2 Who originates from e 2 ?</cell></row><row><cell>org:founded_by</cell><cell>Q1: Who founded e 1 ? Q2 What did e 2 found?</cell></row><row><cell>per:employee_of</cell><cell>Q1: Where does e 1 work? Q2 Who is an employee of e 2 ?</cell></row><row><cell>per:siblings</cell><cell>Q1: Who is the sibling of e 1 ? Q2 Who is the sibling of e 2 ?</cell></row><row><cell>per:alternate_names</cell><cell>Q1: What is the alternative name of e 1 ? Q2 What is the alternative name of e 2 ?</cell></row><row><cell>org:website</cell><cell>Q1: What is the URL of e 1 ? Q2 What organization have the URL e 2 ?</cell></row><row><cell>per:religion</cell><cell>Q1: What is the religion of e 1 Q2 Who believe in e 2</cell></row><row><cell>per:stateorprovince_of_death</cell><cell>Q1: Where did e 1 died? Q2 Who died in e 2 ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>TACRED question templates part 1 What is the state or province of the headquarters of e 1 ? Q2 What organization's headquarters are in the state or province e 2 ?</figDesc><table><row><cell>Relation Name</cell><cell>Question</cell></row><row><cell>per:other_family</cell><cell>Q1: Who are family of e 1 ? Q2 Who are family of e 2 ?</cell></row><row><cell>per:stateorprovinces_of_residence</cell><cell>Q1: What is the state of residence of e 1 ? Q2 Who lives in the state of e 2 ?</cell></row><row><cell>org:members</cell><cell>Q1: Who is a member of the organization e 1 ? Q2 What organization e 2 is member of?</cell></row><row><cell>per:cause_of_death</cell><cell>Q1: How did e 1 died? Q2 How died by e 2 ?</cell></row><row><cell>org:member_of</cell><cell>Q1: What is the group the organization e 1 is member of? Q2 What organization is a member of e 2 ?</cell></row><row><cell>org:number_of_employees/members</cell><cell>Q1: How many members does e 1 have? Q2 What organization have e 2 members?</cell></row><row><cell>per:country_of_birth</cell><cell>Q1: In what country was e 1 born Q2 Who was born in the country e 2 ?</cell></row><row><cell>org:shareholders</cell><cell>Q1: Who hold shares of e 1 ? Q2 What organization does e 2 have shares of?</cell></row><row><cell cols="2">org:stateorprovince_of_headquarters Q1: per:city_of_death Q1: In what city did e 1 died? Q2 Who died in the city e 2 ?</cell></row><row><cell>per:city_of_birth</cell><cell>Q1: In what city was e 1 born? Q2 Who was born in the city e 2 ?</cell></row><row><cell>per:spouse</cell><cell>Q1: Who is the spouse of e 1 ? Q2 Who is the spouse of e 2 ?</cell></row><row><cell>org:city_of_headquarters</cell><cell>Q1: Where are the headquarters of e 1 ? Q2 Which organization has its headquarters in e 2 ?</cell></row><row><cell>per:date_of_death</cell><cell>Q1: When did e 1 die? Q2 Who died on e 2</cell></row><row><cell>per:schools_attended</cell><cell>Q1: Which schools did e 1 attend? Q2 Who attended e 2 ?</cell></row><row><cell>org:political/religious_affiliation</cell><cell>Q1: What is e 1 political or religious affiliation? Q2 Which organization has is political or religious affiliation with e 2 ?</cell></row><row><cell>per:country_of_death</cell><cell>Q1: Where did e 1 die? Q2 Who dies in e 2 ?</cell></row><row><cell>org:founded</cell><cell>Q1: When was e 1 founded? Q2 What organization was founded on e 2 ?</cell></row><row><cell>per:stateorprovince_of_birth</cell><cell>Q1: In what state was e 1 born? Q2 Who was born in state e 2 ?</cell></row><row><cell>org:dissolved</cell><cell>Q1: When was e 1 dissolved? Q2 Which organization was dissolved in e 2 ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>TACRED question templates part 2</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In practice, this span is the out-of-sentence CLS token.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In practice, the embedding is obtained via a pre-trained LM such as BERT, and as per-usual is prefixed with a CLS token, while the different components are separated with a SEP token.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Two non-empty spans are said to be compatible if either of them contain the other.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Matching the Blanks: Distributional Similarity for Relation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Livio Baldini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1279</idno>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2895" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Event Extraction by Answering (Almost) Natural Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Question-answer driven semantic role labeling: Using natural language to annotate natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings -EMNLP 2015: Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SemEval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iris</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><forename type="middle">Nam</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Diarmuid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenza</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2010 -SemEval 2010 -5th International Workshop on Semantic Evaluation, Proceedings</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Generalizing Natural Language Analysis through Span-relation Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00300</idno>
		<title level="m">SpanBERT: Improving Pre-training by Representing and Predicting Spans. Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="64" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/k17-1034</idno>
	</analytic>
	<monogr>
		<title level="m">CoNLL 2017 -21st Conference on Computational Natural Language Learning, Proceedings</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Downstream Model Design of Pre-trained Language Model for Relation Extraction Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A Unified MRC Framework for Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingrong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Entity-Relation Extraction as Multi-Turn Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiayu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1129</idno>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1340" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<title level="m">The Natural Language Decathlon: Multitask Learning as Question Answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Exposing Shallow Heuristics of Relation Extraction Models with Challenge Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Shachar Rosenman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Jacovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distant Supervision for Relation Extraction with Hierarchical Attention and Entity Descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Heng She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chi</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2018.8489631</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Neural Networks</title>
		<meeting>the International Joint Conference on Neural Networks</meeting>
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">KEPLER: A Unified Model for Knowledge Embedding and Pretrained Language Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaocheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<title level="m">Morgan Funtowicz, and Jamie Brew. 2019. HuggingFace&apos;s Transformers: State-of-the-art Natural Language Processing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Coreference Resolution as Query-based Span Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Positionaware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d17-1004</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP 2017 -Conference on Empirical Methods in Natural Language Processing, Proceedings</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
