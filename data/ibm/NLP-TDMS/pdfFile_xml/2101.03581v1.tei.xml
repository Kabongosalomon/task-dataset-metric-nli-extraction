<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Curvature-based Feature Selection with Application in Classifying Electronic Health Records</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheming</forename><surname>Zuo</surname></persName>
							<email>zheming.zuo@durham.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
							<email>jie.li@tees.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Al Moubayed</surname></persName>
							<email>noura.al-moubayed@durham.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computing, Engineering &amp; Digital Technologies</orgName>
								<orgName type="institution">Teesside University</orgName>
								<address>
									<postCode>TS3 6DR</postCode>
									<settlement>Middlesbrough</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Curvature-based Feature Selection with Application in Classifying Electronic Health Records</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>feature selection · precision medicine · healthcare · electronic health records · classification</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Electronic Health Records (EHRs) are widely applied in healthcare facilities nowadays. Due to the inherent heterogeneity, unbalanced, incompleteness, and high-dimensional nature of EHRs, it is a challenging task to employ machine learning algorithms to analyse such EHRs for prediction and diagnostics within the scope of precision medicine. Dimensionality reduction is an efficient data preprocessing technique for the analysis of high dimensional data that reduces the number of features while improving the performance of the data analysis, e.g. classification. In this paper, we propose an efficient curvature-based feature selection method for supporting more precise diagnosis. The proposed method is a filter-based feature selection method, which directly utilises the Menger Curvature for ranking all the attributes in the given data set. We evaluate the performance of our method against conventional PCA and recent ones including BPCM, GSAM, WCNN, BLS II, VIBES, 2L-MJFA, RFGA, and VAF. Our method achieves state-of-the-art performance on four benchmark healthcare data sets including CCRFDS, BCCDS, BTDS, and DRDDS with impressive 24.73% and 13.93% improvements respectively on BTDS and CCRFDS, 7.97% improvement on BCCDS, and 3.63% improvement on DRDDS. Our CFS source code is publicly available at https://github.com/zhemingzuo/CFS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. we propose a simple yet efficient feature selection method, namely Curvature-based Feature Selection (CFS), to select discriminative attributes in line with the ranked and averaged curvature values for each dimension in the given EHR data set; 2. we further embed the CFS approach into the TSK+ <ref type="bibr" target="#b18">[19]</ref> fuzzy inference system, termed as CFS-TSK+, for supporting better decision-making of clinical diagnosis, i.e. improving the performance of classifying digital healthcare data.</p><p>The rest of the paper is organised as follows. Section 2 revisits the related work. Section 3 presents our CFS approach and CFS-TSK+ classifier. Section 4 details the experimental results for comparison and validation. Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, the most recent developments of machine learning techniques in classifying medical data will be showcased first. This is followed by revisiting dimensionality reductions techniques for EHR data from the perspectives of feature extraction and feature selection, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Machine Learning for Digital Healthcare</head><p>In the past few decades, machine learning and deep learning algorithms have been widely proposed for solving healthcare problems, such as diagnose prediction of various diseases including cervical cancer <ref type="bibr" target="#b19">[20]</ref>, breast cancer <ref type="bibr" target="#b20">[21]</ref>, and thoracic disease <ref type="bibr" target="#b21">[22]</ref>, which usually taken in the form of classification.</p><p>Due to privacy considerations, there is a large number of healthcare data sets contain missing values. For coping with this common issue, the Bayesian Possibilistic C-means (BPCM) <ref type="bibr" target="#b9">[10]</ref> was devised for interpolating the missing values by extending the Fuzzy C-Means clustering algorithm (to model the noise and uncertainty) with the support of Bayesian theory (to calculate cluster centroids). The Gene Sequence-based Auxiliary Model (GSAM) <ref type="bibr" target="#b10">[11]</ref>, as an ensemble learner, was proposed for predicting the missing values via data correction and classifying testing data samples via a combination of multiple weak learners within a gene auxiliary module.</p><p>For enhancing the classification performance in terms of accuracy, the Weight Constrained Neural Network (WCNN) <ref type="bibr" target="#b11">[12]</ref> was proposed. WCNN utilises network training to solve a constraint optimisation problem. The work of <ref type="bibr" target="#b12">[13]</ref> devised the extension of the Broad Learning System (BLS) by adding label-based autoencoder (BLS II), for learning robust feature representations in an ensemble way, and also to for tuning the hyper-parameters in Support Vector Machine (SVM), namely BLS II-SVM. Another ensemble learner VIBES was presented in <ref type="bibr" target="#b13">[14]</ref> for detecting the dependency between attributes in the given data set and speeding the forward search for base learners.</p><p>In addition, the Genetic Algorithm is adopted for optimising the performance of Random Forest (RFGA) <ref type="bibr" target="#b15">[16]</ref>. Work towards the enhancement of activation functions in the neural networks was also proposed, such as Variable Activation Function (VAF) <ref type="bibr" target="#b16">[17]</ref> and Adaptive Takagi-Sugeno-Kang (AdaTSK) <ref type="bibr" target="#b22">[23]</ref>. Apart from those adaptive action functions, <ref type="bibr" target="#b14">[15]</ref> presented a proposition of two-layer mixture of factor analysers with joint factor loading (2L-MJFA) for conducting the dimensionality reduction and classification together. This is done by utilising two mixtures nested with each other, and each of which contains a number of components, where each class of the data set is represented in a specific mixture of factor analysers (MFA). Such an approach has been proven to be suitable for small-scale data set, particularly, for the data set that contains a smaller number of data instances but includes a larger number of data attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dimensionality Reduction for EHRs</head><p>The EHR data is usually with high dimensions, thereby contains a large number of input features. It is noteworthy that some of input features may not relevant with the problem to be resolved. To effectively deal with such high-dimensional data, a typical solution is to apply specific techniques to reduce the dimensions of the original data set. Fundamentally, the dimensionality reduction techniques are typically divided into two aspects: 1) feature extraction, which combines the original features and creating a set of new feature representation, 2) feature selection that selects a subset of the original features <ref type="bibr" target="#b23">[24]</ref>. <ref type="figure" target="#fig_0">Fig. 1</ref> depicts the major difference between those two types of techniques, and both technologies are described below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Feature Extraction</head><p>Feature extraction (FE), also termed as Feature Construction, is a substitute of feature selection that transforms the original data from a high-dimensional space into a low-dimensional one, as illustrated in the upper pathway of <ref type="figure" target="#fig_0">Fig 1.</ref> By adopting this type of techniques, the problem is represented in a more discriminating (i.e. informative) space, thus, lead to more efficient analysis process. Such techniques have typically applied in the fields of medical image analysis, such as Magnetic Resonance Imaging (MRI), Computed Tomography (CT) Scan, Ultrasound and X-Rays <ref type="bibr" target="#b23">[24]</ref>. The common feature extraction techniques can be grouped into two main types: linear and non-linear. Linear feature extraction approaches, such as PCA, adopt the matrix factorisation method to transform the original data into a lower dimensional subspace. For instance, PCA looks for "principal components" in the given data that are uncorrelated eigenvectors by considering the covariance matrix and its eigenvalues and eigenvectors <ref type="bibr" target="#b24">[25]</ref>. Although unsupervised PCA is highly effective in identifying important features of the data, it cannot easily determine the nonlinear relationship among the features, which commonly exists in the complex EHRs, especially, the electrocardiogram (ECG), electroencephalography (EEG) <ref type="bibr" target="#b25">[26]</ref>, and biological data <ref type="bibr" target="#b23">[24]</ref>.</p><p>Compared with linear feature extraction methods, which linearly maps the original data into a low-dimensional subspace, non-linear feature extraction approaches works in different ways to represent the non-linear distribution, such as Kernel PCA <ref type="bibr" target="#b26">[27]</ref>, Locally Linear Embedding (LLE) <ref type="bibr" target="#b26">[27]</ref>, and Self-Organising Maps (SOM) <ref type="bibr" target="#b27">[28]</ref>. Such approaches worked based on the hypothesis which the data lies on an embedded non-linear manifold that has a lower dimension than the raw data space and lies within it <ref type="bibr" target="#b26">[27]</ref>.</p><p>Although the extracted features have the higher discriminating power that not only reduces the computational cost but also increases the classification accuracy, the combinations of the newly created set of features may have no physical meaning, therefore, feature extraction may not be a good approach with respect to readability, explainabibility and transparency <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Feature Selection</head><p>Feature selection (FS), a.k.a. Variable Selection or Attribute Selection, is a process of selecting a subset of the most relevant attributes in the given data set for use of model construction (i.e. data modelling). Similar to FE, the aim of FS is also to aid in the task of generating accurate predictive models, however, is achieved by identifying and removing unneeded, irrelevant and redundant attributes from data that do not contribute to the accuracy of a predictive model or may, in fact, decrease the accuracy of the model <ref type="bibr" target="#b28">[29]</ref>, as depicted in the lower pathway of <ref type="figure" target="#fig_0">Fig. 1</ref>. Thereby, it is perfect when interpretability and knowledge extraction are crucial, e.g. in medicine. Essentially, FS methods assess and evaluate the individual feature in the original data set to determine the relevance of each feature for the given problem, so as to select the most relevant features. In general, based on the relationship with the different learning methods, the process of feature selection can be categorised into three types, filter method, wrapper method, and embedded method.</p><p>• Filter: Filter method focuses on the general characteristics of the each feature itself, which ranks features based on a certain evaluation criteria. This is followed by a threshold value selection process in order to eliminate the features that less than the selected crisp value. This method is computationally efficient and learning invariant, as it independent of any learning algorithm. The limitation of such approaches is that there is no interaction between the classifiers, class labels (outputs), and dependency of one feature over others.</p><p>Consequently, those approaches may fail to determine the most "useful" features.</p><p>• Wrapper: Unlike the filter method, the wrapper method depends on the performance of learning algorithm to select features. In this method, candidate subsets of features are evaluated by an induction algorithm. The learning algorithms are employed to analyse the relationship between input features and the outputs (i.e. class labels), thus, to identify the most useful/relevant features. Compared with filter methods, which are not computationally intensive, the wrapper approaches usually have a complex progress and more computationally costly than filter methods. In addition, this method is more prone to over-fitting on small training data sets.</p><p>• Embedded: Though embedded method-based approaches still interact with the learning algorithms for selection relevant features, it conducts a different procedure from the filter and wrapper methods. In general, the embedded approaches can be described as a combination of the filter method and the wrapper method. It not only measures the relations between one input feature and its output feature (i.e. class labels) but also considers the each feature's general characteristic itself locally for better local discrimination <ref type="bibr" target="#b29">[30]</ref>. In particular, the embedded approaches firstly use the independent criteria to determine the optimal feature subsets from the given data set, and then, the learning algorithm is applied to finalise the final optimal feature subsets from the previous results. Compared with the wrapper method, the embedded approaches are computationally inexpensive and less prone to over-fitting <ref type="bibr" target="#b29">[30]</ref>.</p><p>Recently, a hybrid method is also widely employed to preprocess the EHRs, in order to increase the model prediction capability. This method aggregates one or more feature selection methods together, e.g. filter and wrapper methods, to take the advantages of different methods, hence, to generate optimal results. The hybrid method usually can achieve a better performance, e.g. higher prediction accuracy, however, it also requires a higher computational cost <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed System</head><p>In this section, a novel filter method feature selection approach, called Curvature-based Feature Selection (CFS), is proposed and detailed. The system pipeline is outlined in <ref type="figure">Fig. 2</ref>, which comprises of three main components:</p><p>two-dimensional (2-D) data re-construction, feature weight calculation by Menger Curvature (depicted in <ref type="figure" target="#fig_1">Fig. 3</ref>), and feature ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Cleaning</head><p>Feature Selection</p><p>Feature Normalisation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Fuzzy Interpolation</head><p>Predicted class label ≡ High-dimensional Data Set <ref type="figure">Figure 2</ref>: Curvature-based Feature Selection method.</p><formula xml:id="formula_0">ℝ "×$ ℝ "×$ % ℝ "×$ % 2-D Re-construction … 1 2 3 * Feature Weight Calculation 1 2 … Feature Ranking 1 2 ′ … ′ … … ℝ "×$ 1 2 ′ MC</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Menger Curvature</head><p>The Menger Curvature (MC) <ref type="bibr" target="#b31">[32]</ref> measures the curvature of triple data points within the n-dimensional Euclidean space E n represented by the reciprocal of the radius of the circle that passes through the three points p 1 , p 2 , and p 3 in <ref type="figure" target="#fig_1">Fig. 3</ref>.</p><formula xml:id="formula_1">! ( ! , ! ) " ( " , " ) # ( # , # )</formula><p>Circumcircle of ( ! , " , # ) In this work, only two-dimensional plane curves problems are considered. Given that</p><formula xml:id="formula_2">p 1 (x 1 , y 1 ), p 2 (x 2 , y 2 ), p 3 (x 3 , y 3 )</formula><p>are the three points in a 2-D space E 2 and p 1 , p 2 , p 3 are not collinear, as depicted in <ref type="figure" target="#fig_1">Fig. 3</ref>, MC on p 2 is calculated as:</p><formula xml:id="formula_3">MC(p 1 , p 2 , p 3 ) = 1 R = 2sin(ϕ) p 1 , p 3 ,<label>(1)</label></formula><p>where R represents the radius, ||p 1 , p 3 || denotes the Euclidean distance between p 1 and p 3 , and ϕ is the angle of p 2 -corner of the triangle spanned by p 1 , p 2 , p 3 , which can be calculated in line with the Law of Cosines:</p><formula xml:id="formula_4">cos(ϕ) = p 1 , p 2 2 + p 2 , p 3 2 − p 1 , p 3 2 2 · p 1 , p 2 2 · p 2 , p 3 2 .<label>(2)</label></formula><p>MC on points p 1 and p 3 is not calculable, as these points are boundary points. The efficacy of MC is confirmed in constructing Mamdani fuzzy rule base <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Curvature-based Feature Selection</head><p>Assume that a high-dimensional raw data set, denoted as X ∈ R m×n , contains m data instances, n inputs attributes, and a single output feature y. In real-world problem domain, a data cleaning process (e.g. removing attributes with missing values) and data normalisation phase (e.g. bounding all the values within the interval of [0, 1]) may be applied on X to obtain X ∈ R m×n s.t. n &lt; n. In this work, we adopt the Min-Max (MM) normalisation technique:</p><formula xml:id="formula_5">X = X − min(X ) max(X ) − min(X ) .<label>(3)</label></formula><p>This operation helps to cancel out the influence of possible large variations in the raw data set and guarantees that our CFS is able to compare the curvatures for each attribute in an equitable manner. In other words, all the attribute values are normalised to the same frame of reference to ensure the correct rankings generated by CFS. The proposed curvature-based feature selection method is described as follows:</p><p>Step 1 -2-D Data Re-construction: The first step of the proposed CFS is to break down the cleaned high-dimensional data set X into n 2-D planes, which is implemented by combining all input attributes F i (1 i n ) and the output y. Thus, X can be decomposed to n 2-D planes, represented as P (F i ,y) .</p><p>Step 2 -Feature Weighting: For each decomposed 2-D plane P (F i ,y) , the Menger Curvature method, introduced in Section 3.1, is adopted to obtain the averaged curvature value of the feature F i . Given that a decomposed 2-D panel (P (F i ,y) ) contains m data instances, the Menger Curvature value (MC i mj ) of data point m j (2 j m − 1) can be determined by Eq. (1). To this end, the mean of MC for F i , denoted as MC F i , is computed as in:</p><formula xml:id="formula_6">MC F i = 1 m − 2 m−1 j=2 MC i mj ,<label>(4)</label></formula><p>where MC i mj represents the curvature value of the m th j data point in feature F i . MC F i indicates the corresponding weight of the feature F i , the greater value of MC F i signifies a higher degree of importance of the corresponding feature F i for the data set X , and vice versa.</p><p>Step 3 -Feature Ranking and Feature Selection: A conventional ordinal ranking method is used to rank the features, based on the obtained MC F i . Thereby, the features of X are ranked. This is followed by selecting the corresponding features from the raw data set X . Given a threshold ∂, the features with MC F i greater than the given threshold ∂ will be selected. Equivalently, TopK method can be employed:</p><formula xml:id="formula_7">X := X Rank TopK MC F i ,<label>(5)</label></formula><p>such that X ∈ R m×n . To this end, we have reduced the dimensionality of X to X while preserving the statistical nature of the original data set. Then, in line with the rest parts shown in <ref type="figure">Fig. 2</ref>, obtained X will be further normalised and classified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Normalisation</head><p>For improving the performance of classification and ensuring the degree of membership in the TSK+ calculable, the selected features in X are further normalised using a total number of eight normalisation techniques <ref type="bibr" target="#b22">[23]</ref> in this work including the Min-Max (MM) normalisation, 1-normalisation, 2-normalisation, Power Normalisation (PN), and its variants (i.e. 1PN, 2PN, PN 1, and PN 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Classification</head><p>For classifying the selected and normalised features, nine classifiers <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b22">23]</ref> are used, namely Gaussian Naïve Bayes (GNB), Random Forest (RF), AdaBoost (AB), Logistic Regression (LR), Linear Support Vector Machine (Linear SVM), Quadratic Discriminant Analysis (QDA), Decision Tree (DT), k Nearest Neighbours (kNN), Back-Propagation Neural Network (BPNN). Additionally, we also combine the proposed CFS method with TSK+ (CFS-TSK+) and evaluate its performance for the classification of four benchmark medical data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate CFS performance and compare the results against PCA, one of the most popular dimensionality-reduction techniques, on four benchmark clinical data sets. Following we describe the data sets and the experimental setup we used to examine both techniques.  <ref type="figure" target="#fig_2">Fig. 4(a)</ref>. In addition, there are 799 out of 858 data instances, with 26 populated out of 35 attributes, due to missing values '?'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>Breast Cancer Coimbra Data Set <ref type="bibr" target="#b33">[34]</ref> (BCCDS) is composed of 116 data instances (each of which contains 9 attributes) that can be grouped into 2 categories, i.e. healthy controls, and patients.</p><p>Breast Tissue Data Set <ref type="bibr" target="#b34">[35]</ref> (BTDS) contains 106 data instances and each of which is with 9 feature dimensions that can be classified into 6 categories including carcinoma, fibro-adenoma, mastopathy, glandular, connective, and adipose.</p><p>Diabetic Retinopathy Debrecen Data Set <ref type="bibr" target="#b35">[36]</ref> (DRDDS) includes 1,151 data instances that categorised into 2 classes which respectively indicating having Diabetic Retinopathy (DR) and not having DR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dealing with Missing Data</head><p>Missing data, a.k.a. missing values, is a common issue in the digital healthcare domain. As introduced above, missing data could reduce the statistical power of the predictive model, as well as lead to incorrect or invalid results. Thereby, an extra stage may be required for handling the issue of missing data. There are two major methods that could be adopted to cope with the missing values, i.e. data imputation and case deletion <ref type="bibr" target="#b36">[37]</ref>. Concretely, the imputation is the process of inserting the missed values with substituting components. Several approaches have been well-discussed in the literature, such as mean, Multiple Imputation with Chained Equations-Full (MICE-full), and missForset <ref type="bibr" target="#b37">[38]</ref>. Among those methods, mean imputation approach imputes missing values as the mean of the available values for each variable, MICE-full and missForset are then use machine learning algorithms, e.g. random forest, to predict the missing values based on the observed values of a data matrix. For the latter, entire data instances with the missing data are simply omitted/removed, and then only the remaining data is to be used for the analysis. In this work, we merely apply the case deletion method on CCRFDS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment Setup</head><p>All the experiments were implemented in Python ™ 3.6.9 in conjunction with MATLAB ® 2019b, and conducted using a workstation equipped with INTEL ® Core ™ i9-9900K (8-core) CPU @ 3.60 GHz and 64GB RAM.</p><p>Among all the four selected data sets, we perform data cleaning on CCRFDS, i.e. the attributes, which contain missing value, are eliminated. Thereby, the CCRFDS used in this work contains 858 data instances and each of which has 9 attributes (not including the class label). For all the rest three data sets, we use the originally published data.  For selecting features, we compare the proposed CFS using the TopK method defined in Eq. (5), with the well-known PCA by varying the number of the selected features. That is, we select 7 out of 9 attributes (in CCRFDS, BCCDS, and BTDS) and 15 out of 19 attributes (in DRDDS). For normalising the selected features, 8 normalisation methods introduced in Section 3.3 are employed, in which the power coefficient in PN and its variants were set to 0.1. For classification, 10 classifiers (introduced in Section 3.4) are employed with the configuration information: the maximum number of estimators is 100 at which the boosting is terminated in AB; the 1 regularisation is adopted as the penalty function in LR; the Gini index is employed as the criterion in DT and the maximum depth of the tree is valued as 5; the number of neurons in a single hidden layer of BPNN is set to 20; the k is valued as 3 in kNN. The mean accuracy is reported for the ten employed classifiers for performance comparisons via the 10-Fold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">The Efficacy of CFS</head><p>We verify the efficacy of the proposed CFS method by comparing it with PCA on 4 clinical data sets using 8 feature normalisation techniques and 10 classifiers.</p><p>Based on the summary visualised in the second row of <ref type="figure" target="#fig_4">Fig. 5</ref>, CFS outperforms PCA for the following data sets: CCRFDS, BCCDS, and DRDDS, and slightly less competitive for DRDDS. For the first three data sets, CFS yields an average mean accuracy of 95.00%, 61.30%, and 69.79%, versus 94.73%, 60.17%, and 53.73% resulted from PCA, respectively. For the last data set DRDDS, CFS achieved average mean accuracy of 65.02% in contrast to 65.20% generated by PCA. This observation indicates that the CFS is generally more competitive than PCA.</p><p>For the CCRFDS, the best performance yielded by PCA-based and CFS-based are 96.27% and 97.09%, using the MM and PN 1 normalisation approaches, respectively. Concretely, in <ref type="figure" target="#fig_4">Fig. 5(a)</ref>, the PCA-based classifiers tend to generate better performance using conventional data normalisation methods (i.e. MM, 1, and 2) where the CFS-based ones yield more competitive acccuracies when using PN and its variants (i. <ref type="figure" target="#fig_0">e. 1PN, 2PN, PN 1, and PN 2)</ref>.</p><p>For the BCCDS, the best performance obtained by PCA-based and CFS-based are 76.67% and 79.17%, all using the MM normalisation approach. Concretely, in <ref type="figure" target="#fig_4">Fig. 5(b)</ref>, the PCA-based classifiers tend to generate better performance using conventional data normalisation methods (i.e. MM, 1, and 2) where the CFS-based classifiers (except the CFS-TSK+) yield more competitive acccuracies when using PN and its variants. Mean Acc.</p><p>(%) 74.72%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>76.98%</head><p>(a) CCRFDS @ 7 dim.</p><p>(b) BCCDS @ 7 dim.</p><p>(c) BTDS @ 7 dim.</p><p>(d) DRDDS @ 15 dim.  For the DRDDS, the peak performance of CFS and PCA are 76.98% and 74.72%. In constrast to BTDS, PCA-based classifiers showed to be more accurate than CFS-based ones via all the data normalisation techniques, though averagely close with each other.</p><p>For better explain the reason that CFS is a more competitive candidate of feature selection in comparison to PCA, we visualised the ranking of all the attributes generated by CFS in the two bottom rows of <ref type="figure" target="#fig_4">Fig. 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">The Efficiency of CFS-TSK+</head><p>We detail here the peak performances of PCA-TSK+ and CFS-TSK+ in <ref type="table">Table 3</ref>. Notably, in conjunction with <ref type="figure" target="#fig_4">Fig. 5</ref>, CFS-TSK+ achieved the best performance in the data sets of CCRFDS and BCCDS. This observation confirmed the practicability and efficiency of combing the CFS with TSK+.</p><p>However, the best performance of CFS-TSK+ and PCA-TSK+ on BTDS help us to identify the possible drawback of the TSK+ in coping with classification task. That is, the TSK+ is not sensitive to formulate the class boundary when the given data samples are sparsely distributed in the feature space. Alternatively, the rule base are not generalised well in the step of clustering where each cluster is corresponding to a fuzzy rule. Based on the time consumption, we did not perform rule base optimisation in this work as this is bit beyond our scope. For the last data set DRDDS, owing greatly to the lack of expert knowledge, it is not explainable to show how reasonable the ranked results of CFS in comparison to the rest data sets, which are more common sensible. The part of designing a self-explainable component could be treated as an active future work. <ref type="table">Table 3</ref>: Performance summary and comparisons. DS denotes data set. Abbreviations of all the experimented data sets are summarised in <ref type="table">Table 3</ref>. · · · represents multiple combinations achieved the same performance (see <ref type="figure" target="#fig_4">Fig. 5</ref>(c). Best performance is marked in bold. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussions</head><p>To summarise the proposed approach, we compare our CFS with PCA and other recent competitive works in <ref type="table">Table 3</ref>. Though CFS achieved three best performance among the total four medical data sets, and CFS-TSK+ yielded two highest mean accuracies on two data sets, we identified that possible drawback of the proposed CFS is the lack of better explainability when the domain (e.g. clinical science) knowledge is not available. This might be mitigated by predicting the missing values on the anonymised data set and training a self-explainable component. Another piece of active future work could be the enhancement of sparsity awareness of the CFS-TSK+ in the scenario of classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work we propose the Curvature-based Feature Selection method for contributing the classification of clinical (EHR) data sets. We achieve state-of-the-art performance on four benchmark clinical data sets. Though lack of expert knowledge of clinical science, we visualise the results of feature ranking of the proposed CFS to support better explainability. It is noteworthy that self-explainability of CFS and sparsity awareness of class boundaries of CFS-TSK+ are observed as possible future directions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of feature extraction and feature selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The Menger Curvature of a triple of data points on a 2-D space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Data instances percentage for each data set. Best viewed in colour.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>0.03 0.05 0.07 0.09 0.11 0.13 0.15 0.17 0.19 0.21 0.23 0.25 0.27 Avg. Curvature on BTDS Attr. Name HFS (high-frequency slope of phase angle) PA500 (phase angle at 500 KHz) DR (dist.[I0, real part of max. freq. pt.]) DA (impedance dist. among spectral ends) P (length of the spectral curve) I0 (impedivity at zero frequency) A/DA (area under spectrum) Max IP (maximum of the spectrum) Area (spectrum) 0 0.04 0.08 0.12 0.16 0.2 0.24 0.28 0.32 0.36 0.4 0.44 0.48 0.52 0.56 Avg. Curvature on DRDDS Attr. Name Binary result of the AM/FM-based classification # of MAs found at the confidence level of 0.8 # of MAs found at the confidence level of 0.9 # of MAs found at the confidence level of 0.7 # of MAs found at the confidence level of 0.6 # of MAs found at the confidence level of 1.0 # of MAs found at the confidence level of 0.5 Exudates detected at level of 1 (Exu1) Dist.[centre(marcula), centre(OD)] Exu2 Diameter of the optic disc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Classification accuracies of PCA and CFS feature selection methods on four EHR data sets by varying both feature normalisation methods and classifiers. Leftmost column shows the detailed classification performance, second column further summarises the corresponding statistics, and rightmost columns lists the feature rankings provided by CFS in a descending order over each data set for intuitive explainability. Best viewed in colour.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of the four clinical data sets. † denotes the exclusion of class label. represents the number of dimensions contain the missing values.</figDesc><table><row><cell>Data Set</cell><cell># of instances</cell><cell># of dim.  †</cell><cell># of classes</cell><cell>Missing values?</cell><cell># of instances.  †</cell><cell># of dim.  †</cell><cell>Year published</cell></row><row><cell>CCRFDS [18]</cell><cell>858</cell><cell cols="4">35 2 799</cell><cell>26</cell><cell>2017</cell></row><row><cell>BCCDS [34]</cell><cell>116</cell><cell>9</cell><cell cols="5">2 N/A N/A 2018</cell></row><row><cell>BTDS [35]</cell><cell>106</cell><cell>9</cell><cell cols="5">6 N/A N/A 2010</cell></row><row><cell>DRDDS [36]</cell><cell cols="7">1,151 19 2 N/A N/A 2014</cell></row></table><note>Cervical Cancer (Risk Factors) Data Set [18] (CCRFDS) comprises demographic information, habits, and historic medical records of 858 patients with some missing attribute values due to consents of the participated patients. The data set is categorised by the Boolean value of the biopsy. CCRFDS is also highly class-imbalanced, i.e. only 18 out of 858 participants have cancer, demonstrated in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Optimal performance comparisons of PCA-TSK+ and CFS-TSK+. Rule base employed in PCA-TSK+ and CFS-TSK+ were not optimised. (· · · ) denotes multiple combinations achieved the same performance. Best performance is marked in bold.For the BTDS, we show that CFS is capable of help differentiating between certain categories of healthy or pathological breast tissue. In general, CFS-based classifiers outperforms their PCA counterparts over all the data normalisation approaches used. Concretely, CFS-based classifiers achieved several times of 100% accuracy , while the peak performance of PCA-based ones is 69.73%.</figDesc><table><row><cell>Data Set</cell><cell cols="2">PCA-TSK+ (%)↑ CFS-TSK+ (%)↑</cell></row><row><cell>CCRFDS</cell><cell>95.81 (MM)</cell><cell>97.09 (PN 1)</cell></row><row><cell>BCCDS</cell><cell>76.67 (MM)</cell><cell>79.17 (MM)</cell></row><row><cell>BTDS</cell><cell>46.36 ( 1PN)</cell><cell>33.65 (· · · )</cell></row><row><cell>DRDDS</cell><cell>61.03 (PN 1)</cell><cell>60.95 (PN 1)%</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deepigeos: A deep interactive geodesic framework for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Zuluaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aertsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Doel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deprest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vercauteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1559" to="1572" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Feature selection: A data perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Trevino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Prediction of pathological complete response to neoadjuvant chemotherapy in breast cancer using deep learning with integrative imaging, molecular and demographic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Duanmu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brahmavar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Duong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Med. Image Comput. Comput.-Assisted Intervention</title>
		<meeting>Int. Conf. Med. Image Comput. Comput.-Assisted Intervention</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="242" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Feature selection for survival analysis with competing risks using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rietschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V D</forename><surname>Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS Work</title>
		<meeting>NeurIPS Work</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Application of clinical concept embeddings for heart failure prediction in uk ehr data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pikoula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hemingway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS Work</title>
		<meeting>NeurIPS Work</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local adaptive projection framework for feature selection of labeled and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6362" to="6373" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unified simultaneous clustering and feature selection for unlabeled and labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6083" to="6098" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Feature selection based on dependency margin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1209" to="1221" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards scalable fuzzy-rough feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Parthaláin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A bayesian possibilistic c-means clustering approach for cervical cancer screening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">501</biblScope>
			<biblScope unit="page" from="495" to="510" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine learning for assisting cervical cancer diagnosis: An ensemble approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghoneim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alrashoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving the classification efficiency of an ann utilizing a new training methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">E</forename><surname>Livieris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A construction of robust representations for small data sets using broad learning system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Man, Cybern. Syst</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>IEEE Trans. Syst.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The construction of a majority-voting ensemble based on the interrelation and amount of information of features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Aydın</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Aslan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Comput. J</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new two-layer mixture of factor analyzers with joint factor loading model for the classification of small dataset problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Goulermas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="page" from="352" to="363" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A genetic algorithm approach to optimising random forests applied to class engineered data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Gaber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="page" from="220" to="234" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A simple and efficient architecture for trainable activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Apicella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Isgrò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prevete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">370</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transfer learning with partial observability applied to cervical cancer screening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fernandes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Iberian Conf. Pattern Recognit Image Anal</title>
		<meeting>Iberian Conf. Pattern Recognit Image Anal</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tsk inference with sparse rule bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P H</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Comput. Intell. Syst</title>
		<imprint>
			<biblScope unit="page" from="107" to="123" />
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cervical cancer classification using convolutional neural networks and extreme learning machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghoneim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Hossain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="643" to="649" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unbalanced breast cancer data classification using novel fitness functions in genetic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Devarriya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mansharamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sakalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhardwaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page">112866</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Thoracic disease identification and localization with limited supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8290" to="8299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adaptive activation function generation for artificial neural networks through fuzzy inference with application in grooming text categorisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Fuzzy Syst</title>
		<meeting>IEEE Int. Conf. Fuzzy Syst</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A review of feature selection methods in medical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Remeseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bolon-Canedo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in biology and medicine</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page">103375</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gaze-informed egocentric action recognition for memory aid systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="12894" to="12904" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Enhanced detection of movement onset in eeg through deep oversampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Moubayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Mcgough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Jt. Conf. Neural Networks</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dimension reduction methods for microarray data: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIMS Bioengineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="197" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Machine learning algorithms for network intrusion detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P H</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S L</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AI in Cybersecurity</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="151" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Grooming detection using fuzzy-rough feature selection and text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Fuzzy Syst</title>
		<meeting>IEEE Int. Conf. Fuzzy Syst</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Supervised, unsupervised, and semi-supervised feature selection: a review on gene selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mirzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Haron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">N A</forename><surname>Hamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinf</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="971" to="989" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Feature selection and classification systems for chronic disease prediction: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Egyptian Info. J</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="189" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Menger curvature and rectifiability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Léger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. of Math</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="831" to="869" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Curvature-based sparse rule base generation for fuzzy interpolation using menger curvature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Comput. Intell. Syst</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Using resistin, glucose, age and bmi to predict the presence of breast cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Patrício</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Crisóstomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Matafome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Seiça</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Caramelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC cancer</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Classification of breast tissue by electrical impedance spectroscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P M</forename><surname>De Sá</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jossinet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Biol. Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="30" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">An ensemble-based system for automatic screening of diabetic retinopathy. Knowledgebased Syst</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Antal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hajdu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="20" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The prevention and handling of the missing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Korean J. Anesthesiology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">402</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Using machine learning to predict laboratory test results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Dighe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Baron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Clin. Pathol</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="778" to="788" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
