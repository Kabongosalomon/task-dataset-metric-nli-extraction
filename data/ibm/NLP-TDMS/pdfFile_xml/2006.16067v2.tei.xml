<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
							<email>sryoon@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we address the problem of image anomaly detection and segmentation. Anomaly detection involves making a binary decision as to whether an input image contains an anomaly, and anomaly segmentation aims to locate the anomaly on the pixel level. Support vector data description (SVDD) is a long-standing algorithm used for an anomaly detection, and we extend its deep learning variant to the patch-based method using self-supervised learning. This extension enables anomaly segmentation and improves detection performance. As a result, anomaly detection and segmentation performances measured in AUROC on MVTec AD dataset increased by 9.8% and 7.0%, respectively, compared to the previous state-of-the-art methods. Our results indicate the efficacy of the proposed method and its potential for industrial application. Detailed analysis of the proposed method offers insights regarding its behavior, and the code is available online 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Anomaly detection is a binary classification problem to determine whether an input contains an anomaly. Detecting anomalies is a critical and long-standing problem faced by the manufacturing and financial industries. Anomaly detection is usually formulated as a one-class classification because abnormal examples are either inaccessible or insufficient to model distribution during the training. When concentrating on image data, detected anomalies can also be localized, and anomaly segmentation problem is to localize the anomalies at the pixel level. In this study, we tackle the problems of image anomaly detection and segmentation.</p><p>One-class support vector machine (OC-SVM) <ref type="bibr" target="#b0">[1]</ref> and support vector data description (SVDD) <ref type="bibr" target="#b1">[2]</ref> are classic algorithms used for one-class classification. Given a kernel function, OC-SVM seeks a max-margin hyperplane from the origin in the kernel space. Likewise, SVDD searches for a data-enclosing hypersphere in the kernel space. These approaches are closely related, and Vert et al. <ref type="bibr" target="#b2">[3]</ref> showed their equivalence in the case of a Gaussian kernel. Ruff et al. <ref type="bibr" target="#b3">[4]</ref> proposed a deep learning variant of SVDD, Deep SVDD, by deploying a deep neural network in the place of the kernel function. The neural network was trained to extract</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head><p>Anomaly map K=64</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly map K=32</head><p>Anomaly map aggregated <ref type="figure">Fig. 1</ref>: Proposed method localizes defects in an MVTec AD <ref type="bibr" target="#b7">[8]</ref> image.</p><p>Patch SVDD performs multi-scale inspection and combines the results. As a result, the anomaly map pinpoints the defects (contoured with a red line).</p><p>a data-dependent representation, removing the need to choose an appropriate kernel function by hand. Furthermore, Ruff et al. <ref type="bibr" target="#b4">[5]</ref> re-interpreted Deep SVDD in an information-theoretic perspective and applied to semi-supervised scenarios.</p><p>In this paper, we extend Deep SVDD to a patch-wise detection method, thereby proposing Patch SVDD. This extension is rendered nontrivial by the relatively high level of intra-class variation of the patches and is facilitated by self-supervised learning. The proposed method enables anomaly segmentation and improves anomaly detection performance. <ref type="figure">Fig. 1</ref> shows an example of the localized anomalies using the proposed method. In addition, the results in previous studies <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> show that the features of a randomly initialized encoder might be used to distinguish anomalies. We detail the more in-depth behavior of random encoders and investigate the source of separability in the random features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Anomaly detection and segmentation</head><p>Problem formulation Anomaly detection is a problem to make a binary decision whether an input is an anomaly or not. The definition of anomaly ranges from a tiny defect to an out-of-distribution image. We focus here on detecting a defect in an image. A typical detection method involves training a scoring function, A θ , which measures the abnormality of an input. At test time, inputs with high A θ (x) values are deemed to be an anomaly. A de facto standard metric for the scoring function is the area under the receiver operating characteristic curve (AUROC), as expressed in Eq. 1 <ref type="bibr" target="#b8">[9]</ref>.</p><formula xml:id="formula_0">AUROC [A θ ] = P [A θ (X normal ) &lt; A θ (X abnormal )] .<label>(1)</label></formula><p>A good scoring function is, thus, one that assigns a low anomaly score to normal data and a high anomaly score to abnormal data. Anomaly segmentation problem is similarly formulated, with the generation of an anomaly score for every pixel (i.e., an anomaly map) and the measurement of AUROC with the pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep SVDD Patch SVDD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2:</head><p>Comparison of Deep SVDD <ref type="bibr" target="#b3">[4]</ref> and the proposed method. Patch SVDD performs inspection on every patch to localize a defect. In addition, the self-supervised learning allows the features to form multi-modal clusters, thereby enhancing anomaly detection capability. The image is from MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset.</p><p>Auto encoder-based methods Early deep learning approaches to anomaly detection used auto encoders <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. These auto encoders were trained with the normal training data and did not provide accurate reconstruction of abnormal images. Therefore, the difference between the reconstruction and the input indicated abnormality. Further variants have been proposed to utilize structural similarity indices <ref type="bibr" target="#b12">[13]</ref>, adversarial training <ref type="bibr" target="#b10">[11]</ref>, negative mining <ref type="bibr" target="#b11">[12]</ref>, and iterative projection <ref type="bibr" target="#b13">[14]</ref>. Certain previous works utilized the learned latent feature of the auto encoder for anomaly detection. Akcay et al. <ref type="bibr" target="#b14">[15]</ref> defined the reconstruction loss of the latent feature as an anomaly score, and Yarlagadda et al. <ref type="bibr" target="#b15">[16]</ref> trained OC-SVM <ref type="bibr" target="#b0">[1]</ref> using the latent features. More recently, several methods have made use of factors other than reconstruction loss, such as restoration loss <ref type="bibr" target="#b16">[17]</ref> and an attention map <ref type="bibr" target="#b17">[18]</ref>.</p><p>Classifier-based methods After the work of Golan et al. <ref type="bibr" target="#b18">[19]</ref>, discriminative approaches have been proposed for anomaly detection. These methods exploit an observation that classifiers lose their confidence <ref type="bibr" target="#b19">[20]</ref> for the abnormal input images. Given an unlabeled dataset, a classifier is trained to predict synthetic labels. For example, Golan et al. <ref type="bibr" target="#b18">[19]</ref> randomly flip, rotate, and translate an image, and the classifier is trained to predict the particular type of transformation performed. If the classifier does not provide a confident and correct prediction, the input image is deemed to be abnormal. Wang et al. <ref type="bibr" target="#b20">[21]</ref> proved that such an approach could be extended to an unsupervised scenario, where the training data also contains a few anomalies. Bergman et al. <ref type="bibr" target="#b21">[22]</ref> adopted an open-set classification method and generalized the method to include non-image data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVDD-based methods SVDD [2] is a classic one-class classification algorithm.</head><p>It maps all the normal training data into a predefined kernel space and seeks the smallest hypersphere that encloses the data in the kernel space. The anomalies are expected to be located outside the learned hypersphere. As a kernel function determines the kernel space, the training procedure is merely deciding the radius and center of the hypersphere. Ruff et al. <ref type="bibr" target="#b3">[4]</ref> improved this approach using a deep neural network. They adopted the neural network in place of the kernel function and trained it along</p><formula xml:id="formula_1">Image (cable)</formula><p>Anomaly map using SVDD</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly map using Patch SVDD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image (leather)</head><p>Anomaly map using SVDD Anomaly map using Patch SVDD <ref type="figure">Fig. 3</ref>: Comparison of anomaly maps generated using two different losses. For a relatively simple image (leather), the encoders trained with either L SVDD or L Patch SVDD both localize the defect (contoured with a red line) well. By contrast, when the image has high complexity (cable), L SVDD fails to localize the defect. The image is from MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset.</p><p>with the radius of the hypersphere. This modification allows the encoder to learn a data-dependent transformation, thus enhancing detection performance on high-dimensional and structured data. To avoid a trivial solution (i.e., the encoder outputs a constant), they removed the bias terms in the network. Ruff et al. <ref type="bibr" target="#b4">[5]</ref> further applied this method to a semi-supervised scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Self-supervised representation learning</head><p>Learning a representation of an image is a core problem of computer vision. A series of methods have been proposed to learn a representation of an image without annotation. One branch of research suggests training the encoder by learning with a pretext task, which is a self-labeled task to provide synthetic learning signals. When a network is trained to solve the pretext task well, the network is expected to be able to extract useful features. The pretext tasks include predicting relative patch location <ref type="bibr" target="#b5">[6]</ref>, solving a jigsaw puzzle <ref type="bibr" target="#b22">[23]</ref>, colorizing images <ref type="bibr" target="#b23">[24]</ref>, counting objects <ref type="bibr" target="#b24">[25]</ref>, and predicting rotations <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Patch-wise Deep SVDD</head><p>Deep SVDD <ref type="bibr" target="#b3">[4]</ref> trains an encoder that maps the entire training data to features lying within a small hypersphere in the feature space. The encoder, f θ , is trained to minimize the Euclidean distances between the features and the center of the hypersphere using the following loss function:</p><formula xml:id="formula_2">L SVDD = i f θ (x i ) − c 2 ,<label>(2)</label></formula><p>where x is an input image. At test time, the distance between the representation of the input and the center is used as an anomaly score. The center c is calculated in advance of the training, as shown in Eq. 3, where N denotes the number of the training data. Therefore, the training pushes the features around a single center.</p><formula xml:id="formula_3">y = 0 0 1 2 3 4 5 6 7</formula><p>Classifier Encoder <ref type="figure">Fig. 4</ref>: Self-supervised learning <ref type="bibr" target="#b5">[6]</ref>. The encoder is trained to extract informative features so that the following classifier can correctly predict the relative positions of the patches. Once the training is complete, the classifier is discarded. Note that the two encoders share their weights, as in Siamese Network <ref type="bibr" target="#b26">[27]</ref>. The image is from MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset.</p><formula xml:id="formula_4">c . = 1 N N i f θ (x i ).<label>(3)</label></formula><p>In this study, we extend this approach to patches; the encoder encodes each patch, not the entire image, as illustrated in <ref type="figure">Fig. 2</ref>. Accordingly, inspection is performed for each patch. Patch-wise inspection has several advantages. First, the inspection result is available at each position, and hence we can localize the positions of defects. Second, such fine-grained examination improves overall detection performance.</p><p>A direct extension of Deep SVDD <ref type="bibr" target="#b3">[4]</ref> to a patch-wise inspection is straightforward. A patch encoder, f θ , is trained using L SVDD with x replaced with a patch, p. The anomaly score is defined accordingly, and the examples of the resulting anomaly maps are provided in <ref type="figure">Fig. 3</ref>. Unfortunately, the detection performance is poor for the images with high complexity. This is because patches have high intra-class variation; some patches correspond to the background, while the others contain the object. As a result, mapping all the features of dissimilar patches to a single center and imposing a uni-modal cluster weaken the connection between the representation and the content. Therefore, using a single center c is inappropriate, yet deciding on the appropriate number of multiple centers and the allocation of patches to each center are cumbersome.</p><p>To bypass the above issues, we do not explicitly define the center and allocate the patches. Instead, we train the encoder to gather semantically similar patches by itself. The semantically similar patches are obtained by sampling spatially adjacent patches, and the encoder is trained to minimize the distances between their features using the following loss function: where p i is a patch near p i . Furthermore, to enforce the representation to capture the semantics of the patch, we append the following self-supervised learning.</p><formula xml:id="formula_5">L SVDD' = i,i f θ (p i ) − f θ (p i ) 2 ,<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-supervised learning</head><p>Doersch et al. <ref type="bibr" target="#b5">[6]</ref> trained an encoder and classifier pair to predict the relative positions of two patches, as depicted in <ref type="figure">Fig. 4</ref>. A well-performing pair implies that the trained encoder extracts useful features for location prediction. Aside from this particular task, previous research <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28]</ref> reported that the self-supervised encoder functions as a powerful feature extractor for downstream tasks. For a randomly sampled patch p 1 , Doersch et al. <ref type="bibr" target="#b5">[6]</ref> sampled another patch p 2 from one of its eight neighborhoods in a 3 × 3 grid. If we let the true relative position be y ∈ {0, ..., 7}, the classifier C φ is trained to predict y = C φ (f θ (p 1 ), f θ (p 2 )) correctly. The size of the patch is the same as the receptive field of the encoder. To prevent the classifier from exploiting shortcuts <ref type="bibr" target="#b6">[7]</ref> (e.g., color aberration), we randomly perturb the RGB channels of the patches. Following the approach by Doersch et al. <ref type="bibr" target="#b5">[6]</ref>, we add a self-supervised learning signal by adding the following loss term:</p><formula xml:id="formula_6">L SSL = Cross-entropy (y, C φ (f θ (p 1 ), f θ (p 2 ))) .<label>(5)</label></formula><p>As a result, the encoder is trained using a combination of two losses with the scaling hyperparameter λ, as presented in Eq. 6. This optimization is performed using stochastic gradient descent and Adam optimizer <ref type="bibr" target="#b28">[29]</ref>.</p><formula xml:id="formula_7">L Patch SVDD = λL SVDD' + L SSL .<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Hierarchical encoding</head><p>As anomalies vary in size, deploying multiple encoders with various receptive fields helps in dealing with variation in size.  detection performance as well. For this reason, we employ a hierarchical encoder that embodies a smaller encoder; the hierarchical encoder is defined as</p><formula xml:id="formula_8">f big (p) = g big (f small (p)).<label>(7)</label></formula><p>An input patch p is divided into a 2 × 2 grid, and their features are aggregated to constitute the feature of p, as shown in <ref type="figure" target="#fig_0">Fig. 5</ref>. Each encoder with receptive field size K is trained with the self-supervised task of patch size K. Throughout the experiment, the receptive field sizes of the large and small encoders are 64 and 32, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Generating anomaly maps</head><p>After training the encoders, the representations from the encoder are used to detect the anomalies. First, the representation of every normal train patch, {f θ (p normal )|p normal }, is calculated and stored. Given a query image x, for every patch p with a stride S within x, the L2 distance to the nearest normal patch in the feature space is then defined to be its anomaly score using Eq. 8. To mitigate the computational cost of the nearest neighbor search, we adopt its approximate algorithm 2 . As a result, the inspection of a single image from MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset for example, requires approximately 0.48 second.</p><formula xml:id="formula_9">A patch θ (p) . = min p normal f θ (p) − f θ (p normal ) 2 .<label>(8)</label></formula><p>Patch-wise calculated anomaly scores are then distributed to the pixels. As a consequence, pixels receive the average anomaly scores of every patch to which they belong, and we denote the resulting anomaly map as M.</p><p>The multiple encoders discussed in Section 3.3 constitute multiple feature spaces, thereby yielding multiple anomaly maps. We aggregate the multiple</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly map</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly map</head><p>Image Anomaly map <ref type="figure">Fig. 7</ref>: Anomaly maps generated by the proposed method. Patch SVDD generates anomaly maps of each image in fifteen classes of MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset. The ground truth defect annotations are depicted as red contours in the image, and the darker heatmap indicates higher anomaly scores. maps using element-wise multiplication, and the resulting anomaly map, M multi , provides the answer to the problem of anomaly segmentation:</p><formula xml:id="formula_10">M multi . = M small M big ,<label>(9)</label></formula><p>where M small and M big are the generated anomaly maps using f small and f big , respectively. The pixels with high anomaly scores in the map M multi are deemed to contain defects. It is straightforward to address the problem of anomaly detection. The maximum anomaly score of the pixels in an image is its anomaly score, as expressed in Eq. 10. <ref type="figure" target="#fig_1">Fig. 6</ref> illustrates the overall flow of the proposed method, and its pseudo-code is provided in Appendix A1.  <ref type="bibr" target="#b17">[18]</ref> 0.861 VAE Proj ICLR' 20 <ref type="bibr" target="#b13">[14]</ref> 0.893 Patch SVDD (Ours) 0.957</p><formula xml:id="formula_11">A image θ (x) . = max i,j M multi (x) ij .<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>To verify the validity of the proposed method, we applied it to MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset. The dataset consists of 15-class industrial images, each class categorized as either an object or texture. Ten object classes contain regularly positioned objects, whereas the texture classes contain repetitive patterns. The implementation details used throughout the study are provided in Appendix A3, and please refer to <ref type="bibr" target="#b7">[8]</ref> for more details on the dataset. <ref type="figure">Fig. 7</ref> shows anomaly maps generated using the proposed method, indicating that the defects are properly localized, regardless of their size. <ref type="table" target="#tab_1">Table 1</ref> shows the detection and segmentation performances for MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset compared with state-of-the-art baselines in AUROC. Patch SVDD provides state-of-theart performance over the powerful baselines including auto encoder-based and classifier-based methods and outperforms Deep SVDD <ref type="bibr" target="#b3">[4]</ref> by 55.6% improvement. More numerical results are provided in Appendix A2.1. <ref type="figure">Fig. 8</ref> shows t-SNE visualizations <ref type="bibr" target="#b29">[30]</ref> of the learned features of multiple train images. Patches located at the points shown in <ref type="figure">Fig. 8(b)</ref> are mapped to the points with the same color and size in <ref type="figure">Fig. 8(a)</ref> and <ref type="figure">Fig. 8(c)</ref>. In <ref type="figure">Fig. 8(a)</ref>, the points with similar color and size form clusters in the feature space. Since the images in the cable class are regularly positioned, the patches from the same position have similar content, even if they are from different images. Likewise, for the regularly positioned object classes, the points with similar color and size in t-SNE visualization (i.e., the patches with similar positions) can be regarded to be semantically similar. By contrast, features of the leather class in <ref type="figure">Fig. 8(c)</ref> show the opposite tendency. This is because the patches in texture classes are analogous, regardless of their position in the image; the positions of the patches are not quite related to their semantics for the texture images.   <ref type="figure">Fig. 9</ref>: The effects of the losses vary among classes. L SSL is particularly beneficiary to the object classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Anomaly detection and segmentation results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Detailed analysis t-SNE visualization</head><p>Effect of self-supervised learning Patch SVDD trains an encoder using two losses: L SVDD' and L SSL , where L SVDD' is a variant of L SVDD . To compare the roles of the proposed loss terms, we conduct an ablation study. <ref type="table" target="#tab_2">Table 2</ref> suggests that the modification of L SVDD to L SVDD' and the adoption of L SSL improve the anomaly detection and segmentation performances. <ref type="figure">Fig. 9</ref> shows that the effects of the proposed loss terms vary among classes. Specifically, the texture classes (e.g. tile and wood) are less sensitive to the choice of loss, whereas the object classes, including cable and transistor, benefit significantly from L SSL . To investigate the reason behind these observations, we provide (in <ref type="figure">Fig. 10</ref>) t-SNE visualizations of the features of an object class (the transistor) for the encoders trained with L SVDD , L SVDD' , and L SVDD' + L SSL . When training is performed with L SVDD <ref type="figure">(Fig. 10(a)</ref>) or L SVDD' <ref type="figure">(Fig. 10(b)</ref>), the features form a uni-modal cluster. In contrast, L SSL results in multi-modal feature clusters on the basis of their semantics (i.e., color and size), as shown in <ref type="figure">Fig. 10(c)</ref>. The  <ref type="figure">Fig. 12</ref>: The effect of hierarchical encoding.</p><p>Aggregating the results from multi-scale inspection boosts the performance, and adopting hierarchical structure to the encoder is helpful as well.</p><p>multi-modal property of the features is particularly beneficial to the object classes, which have high intra-class variation among the patches. Features of the patches with dissimilar semantics are separated, and hence anomaly inspection using those features becomes more deliberate and accurate. The intrinsic dimensions (ID) <ref type="bibr" target="#b30">[31]</ref> of the features also indicate the effectiveness of L SSL . The ID is the minimal number of coordinates required to describe the points without significant information loss <ref type="bibr" target="#b31">[32]</ref>. A larger ID denotes that the points are spreaded in every direction, while a smaller ID indicates that the points lie on low-dimensional manifolds with high separability. In <ref type="figure" target="#fig_5">Fig. 11</ref>, we show the average IDs of features in each class trained with three different losses. If the encoder is trained with the proposed L Patch SVDD , features with the lowest ID are yielded, implying that these features are neatly distributed.</p><p>Hierarchical encoding In Section 3.3, we proposed the use of hierarchical encoders. <ref type="figure">Fig. 12</ref> shows that aggregating multi-scale results from multiple encoders improves the inspection performances. In addition, an ablation study</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head><p>Anomaly map K=64</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly map K=32</head><p>Anomaly map aggregated <ref type="figure">Fig. 13</ref>: Multi-scale inspection. Patch SVDD performs multi-scale inspection and aggregates the results. The image is from MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset.</p><p>with a non-hierarchical encoder shows that the hierarchical structure itself also boosts performance. We postulate that the hierarchical architecture provides regularization for the feature extraction. Note that the non-hierarchical encoder has a number of parameters similar to that of the hierarchical counterpart.</p><p>We provide an example of multi-scale inspection results, together with an aggregated anomaly map, in <ref type="figure">Fig. 13</ref>. The anomaly maps from various scales provide complementary inspection results; the encoder with a large receptive field coarsely locates the defect, whereas the one with a smaller receptive field refines the result. Therefore, an element-wise multiplication of the two maps localizes the accurate position of the defect.</p><p>Hyperparameters As shown in Eq. 6, the hyperparameter λ balances L SVDD' and L SSL . A large λ emphasizes gathering of the features, while a small λ promotes their informativeness. Interestingly, the most favorable value of λ varies among the classes. Anomalies in the object classes are well detected under a smaller λ, while the texture classes are well detected with a larger λ. <ref type="figure">Fig. 14</ref> shows an example of this difference; the anomaly detection performance for the cable class (object) improves as λ decreases, while the wood class (texture) shows the opposite trend. As discussed in the previous sections, this occurs because the self-supervised learning is more helpful when the patches show high intra-class variation, which is the case for the object classes. The result coincides with that shown in <ref type="figure">Fig. 9</ref> because using L SVDD' as a loss is equivalent to using L Patch SVDD with λ &gt;&gt; 1.</p><p>The number of feature dimensions, D, is another hyperparameter of the encoder. The anomaly inspection performance for varying D is depicted in <ref type="figure" target="#fig_0">Fig. 15(a)</ref>. A larger D signifies improved performance-a trend that has been discussed in a self-supervised learning venue <ref type="bibr" target="#b27">[28]</ref>. <ref type="figure" target="#fig_0">Fig. 15(b)</ref> indicates that the ID of the resulting features increases with increasing D. The black dashed line represents the y = x graph, and it is the upper bound of ID. The average ID of features among the classes saturates as D = 64; therefore, we used a value of D = 64 throughout our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly detection performance (AUROC)</head><p>λ <ref type="figure">Fig. 14:</ref> The effect of λ. The anomaly detection performances for the two classes show the opposite trends as λ varies. Random encoder Doersch et al. <ref type="bibr" target="#b5">[6]</ref> showed that randomly initialized encoders perform reasonably well in image retrieval; given an image, the nearest images in the random feature space look similar to humans as well. Inspired by this observation, we examined the anomaly detection performance of the random encoders and provided the results in <ref type="table">Table 3</ref>. As in Eq. 8, the anomaly score is defined to be the distance to the nearest normal patch, but in the random feature space. In the case of certain classes, the features of the random encoder are effective in distinguishing between normal and abnormal images. Some results even outperform the trained deep neural network model (L2-AE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intrinsic dimension Anomaly inspection performances (AUROC)</head><formula xml:id="formula_12">D D (a) (b)</formula><p>Here, we investigate the reason for the high separability of the random features. For simplicity, let us assume the encoder to be a one-layered convolutional layer parametrized by a weight W = 0 and a bias b followed by a nonlinearity, σ. Given two patches p 1 and p 2 , their features h 1 and h 2 are provided by Eq. 11, where * denotes a convolution operation.</p><formula xml:id="formula_13">h 1 = σ(W * p 1 + b) h 2 = σ(W * p 2 + b).<label>(11)</label></formula><p>As suggested by Eq. 12, when the features are close, so are the patches, and vice versa. Therefore, retrieving the nearest patch in the feature space is analogous to doing so in the image space.</p><formula xml:id="formula_14">h 1 − h 2 2 ≈ 0 ⇔ (W * p 1 + b) − (W * p 2 + b) ≈ 0 ⇔ W * (p 1 − p 2 ) ≈ 0 ⇔ p 1 − p 2 2 ≈ 0.<label>(12)</label></formula><p>In <ref type="table">Table 3</ref>, we also provide the results for anomaly detection task using the nearest neighbor algorithm using the raw patches (i.e., f θ (p) = p in Eq. 8). For certain classes, the raw patch nearest neighbor algorithm works surprisingly well. <ref type="table">Table 3</ref>: Nearest neighbor algorithm using the random encoders and raw patches for MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset. For certain classes, the nearest neighbor algorithm using the random features shows good anomaly detection performance. For those classes, using the raw patches also yields high performance. The effectiveness of the raw patches for anomaly detection can be attributed to the high similarity among the normal images. Furthermore, the well-separated classes provided by the random encoder are well-separated by the raw patch nearest neighbor algorithm, and vice versa. Together with the conclusion of Eq. 12, this observation implies the strong relationship between the raw image patch and its random feature. To summarize, the random features of anomalies are easily separable because they are alike the raw patches, and the raw patches are easily separable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed Patch SVDD, a method for image anomaly detection and segmentation. Unlike Deep SVDD <ref type="bibr" target="#b3">[4]</ref>, we inspect the image at the patch level, and hence we can also localize defects. Moreover, additional self-supervised learning improves detection performance. As a result, the proposed method achieved state-of-the-art performance on MVTec AD <ref type="bibr" target="#b7">[8]</ref> industrial anomaly detection dataset.</p><p>In previous studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, images were featurized prior to the subsequent downstream tasks because of their high-dimensional and structured nature. However, the results in our analysis suggest that a nearest neighbor algorithm with a raw patch often discriminates anomalies surprisingly well. Moreover, since the distances in random feature space are closely related to those in the raw image space, random features can provide distinguishable signals. p1 ← RandomJitter(p) 4:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1 Pseudo code</head><formula xml:id="formula_15">L SVDD' ← f θ (p) − f θ (p1) 2 5:</formula><p>p2, y ← RandomNeighborhood(p) A neighborhood in the 3 × 3 grid 6:</p><p>LSSL ← Cross-entropy (y, C φ (f θ (p), f θ (p2))) 7:</p><p>Backprop L Patch SVDD ← λL SVDD'   <ref type="table" target="#tab_2">Table A2</ref>: The effect of hierarchical encoding. Aggregating the results from multi-scale inspection boosts the performance, and adopting hierarchical structure to the encoder is helpful as well. The plot of the data is provided in <ref type="figure">Fig. 12</ref> of the main paper.    <ref type="figure">Fig. A2</ref>: Anomaly maps generated by the proposed method. Patch SVDD generates anomaly maps of the images in each class of MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset. The ground truth defect annotations are depicted as red contours in the image, and the darker heatmap indicates higher anomaly scores. The name of the class is provided at the left of the image, and the type of the defect is indicated below the image.  <ref type="figure">Fig. A3</ref>: Anomaly maps generated by the proposed method. Patch SVDD generates anomaly maps of the images in each class of MVTec AD <ref type="bibr" target="#b7">[8]</ref> dataset. The ground truth defect annotations are depicted as red contours in the image, and the darker heatmap indicates higher anomaly scores. The name of the class is provided at the left of the image, and the type of the defect is indicated below the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2 Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.1 Numerical results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3 Implementation details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.1 Dataset</head><p>The dataset in the study, MVTec AD <ref type="bibr" target="#b7">[8]</ref>, consists of 15-class industrial images. Each class is categorized as either an object 3 or texture 4 . Each class contains 60 to 390 normal train images and 40 to 167 test images. Test images include both normal and abnormal examples, and the defects of the abnormal images are annotated at the pixel level in the form of binary masks. We downsampled every image to a resolution of 256 × 256. Gray-scale images are converted to RGB images by replicating the single channel to three. No data augmentation method (e.g., horizontal flip, rotation) was used for the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.2 Networks</head><p>Two neural networks are used throughout the study: an encoder and a classifier. The encoder is composed of convolutional layers only. The classifier is a twolayered MLP model having 128 hidden units per layer, and the input to the classifier is a subtraction of the features of the two patches. The activation function for both networks is a LeakyReLU <ref type="bibr" target="#b32">[33]</ref> with a α = 0.1. Please refer to the code 5 for the detailed architecture of the networks.</p><p>As proposed in Section 3.3 of the main paper, the encoder has a hierarchical structure. The receptive field of the encoder is K = 64, and that of the embedded smaller encoder is K = 32. Patch SVDD divides the images into patches with a size K and a stride S. The values for the strides are S = 16 and S = 4 for the encoders with K = 64 and K = 32, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3.3 Environments</head><p>The experiments throughout the study were conducted on a machine equipped with an Intel i7-5930K CPU and an NVIDIA GeForce RTX 2080 Ti GPU. The code is implemented in python 3.7 and PyTorch <ref type="bibr" target="#b33">[34]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 5 :</head><label>5</label><figDesc>Hierarchical encoding. An input patch is divided into a 2 × 2 grid of sub-patches, and the sub-patches are independently encoded using the smaller encoder (f small ). The output features are aggregated to produce a single feature. The image is from MVTec AD<ref type="bibr" target="#b7">[8]</ref> dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 6 :</head><label>6</label><figDesc>Overall flow of the proposed method. For a given test image, Patch SVDD divides the image into patches of size K with strides S and extracts their features using the trained encoder. The L2 distance to the nearest normal patch in the feature space becomes the anomaly score of each patch. The resulting anomaly map localizes the defects (contoured with a red line). The image is from MVTec AD<ref type="bibr" target="#b7">[8]</ref> dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) t-SNE for cable (b) Points at each position (c) t-SNE for leatherFig. 8: t-SNE visualizations [30] of the learned features. The color and size of each point represent the position (θ and r of the polar coordinates) within an image (b). From its color and size, we can infer the positions of the corresponding patches of the features in (a, c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 10 :Fig. 11 :</head><label>1011</label><figDesc>(a) t-SNE usingSVDD   (b) t-SNE using SVDD' (c) t-SNE using SVDD' + SSL Features of the multiple train images in the transistor class by the encoders trained with different losses. Adopting L SSL (c) enables the representations to form clusters on the basis of their semantics. Intrinsic dimensions of the features under different losses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 15 :</head><label>15</label><figDesc>The effect of the embedding dimension, D. Larger D yields better inspection results (a) and larger intrinsic dimensions (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1 1 :</head><label>11</label><figDesc>Patch SVDD (train) Input normal images {x}, hyperparameter λ, encoder f θ , and classifier C φ 2: for patch p in {x} do Train the encoder 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. A1 :</head><label>A1</label><figDesc>Anomaly maps generated by the proposed method. Patch SVDD generates anomaly maps of the images in each class of MVTec AD<ref type="bibr" target="#b7">[8]</ref> dataset. The ground truth defect annotations are depicted as red contours in the image, and the darker heatmap indicates higher anomaly scores. The name of the class is provided at the left of the image, and the type of the defect is indicated below the image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The experimental results in Section 4.2 show that enforcing a hierarchical structure on the encoder boosts anomaly</figDesc><table><row><cell></cell><cell></cell><cell>learned</cell></row><row><cell></cell><cell></cell><cell>feature space</cell></row><row><cell>Image</cell><cell>Patches</cell><cell>Nearest normal patches Anomaly Map</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Anomaly detection (left) and segmentation (right) performances on MVTec AD<ref type="bibr" target="#b7">[8]</ref> dataset. The proposed method, Patch SVDD, achieves the state-of-the-art performances on both tasks.</figDesc><table><row><cell>Method</cell><cell>AUROC</cell><cell>Method</cell><cell>AUROC</cell></row><row><cell>Task: Anomaly Detection</cell><cell></cell><cell cols="2">Task: Anomaly Segmentation</cell></row><row><cell>Deep SVDD [4] ICML' 18</cell><cell>0.592</cell><cell>L2-AE</cell><cell>0.804</cell></row><row><cell>GEOM [19] NeurIPS' 18</cell><cell>0.672</cell><cell>SSIM-AE</cell><cell>0.818</cell></row><row><cell cols="2">GANomaly [15] ACCV' 18 0.762</cell><cell>VE VAE CVPR' 20</cell><cell></cell></row><row><cell>ITAE [17] arXiv' 19</cell><cell>0.839</cell><cell></cell><cell></cell></row><row><cell>Patch SVDD (Ours)</cell><cell>0.921</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The effect of the losses.</figDesc><table><row><cell>Anomaly detection</cell><cell>performance (AUROC)</cell><cell>cable</cell><cell>transistor</cell><cell>tile</cell><cell>wood</cell></row><row><cell></cell><cell></cell><cell></cell><cell>object</cell><cell>texture</cell><cell></cell></row><row><cell>0.703 0.832</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.739 0.880</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.921 0.957</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Modifying L SVDD to L SVDD' and adopting L SSL both improve the anomaly detection (Det.) and seg- mentation (Seg.) performances.LSVDD L SVDD' LSSL Det. Seg.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>for patch p in {x} do Patch size K with stride S 15: S small ← S small ∪ {f small (p)} 16: end for 17: return (S big , S small ), (f big , f small ) Normal features and trained encoders Algorithm 2 Patch SVDD (test) Input query image x, normal feature sets (S big , S small ), and encoders (f big , f small ) 2: Initialize M big and M small 3: for patch p in x do Patch size K with stride S 4: d ← min h∈S big f big (p) − h 2 to M small of each pixel in p 10: end for 11: M multi ← M small M big Element-wise multiplication 12: a ← max M multi Anomaly score 13: return M multi , a Anomaly map and anomaly scoreAlgorithm 1 trains a hierarchical encoder using L Patch SVDD . After the training, sets of features of normal patches are extracted using the trained multi-scale encoders. The outputs of Algorithm 1 are the sets of normal features and trained encoders. Algorithm 2 performs inspection on a query image and outputs the anomaly map and anomaly score.</figDesc><table><row><cell></cell><cell>LSSL</cell><cell></cell></row><row><cell cols="2">8: end for</cell><cell></cell></row><row><cell cols="2">9: f big , f small ← f θ</cell><cell>Split encoders</cell></row><row><cell cols="2">10: S big , S small ← ∅</cell><cell>Sets of normal features</cell></row><row><cell cols="2">11: for patch p in {x} do</cell><cell>Patch size K with stride S</cell></row><row><cell>12:</cell><cell>S big ← S big ∪ {f big (p)}</cell><cell></cell></row><row><cell cols="2">13: end for</cell><cell></cell></row><row><cell cols="3">14: Anomaly score of a patch</cell></row><row><cell>5:</cell><cell>Distribute d to M big of each pixel in p</cell><cell></cell></row><row><cell cols="2">6: end for</cell><cell></cell></row><row><cell cols="2">7: for patch p in x do</cell><cell>Patch size K with stride S</cell></row><row><cell>8:</cell><cell>d ← min h∈S small f small (p) − h 2</cell><cell>Anomaly score of a patch</cell></row><row><cell>9:</cell><cell>Distribute d</cell><cell></cell></row></table><note>1:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table A1 :</head><label>A1</label><figDesc>Anomaly detection (Det.) and segmentation performances (Seg.) of proposed Patch SVDD on MVTec AD<ref type="bibr" target="#b7">[8]</ref> dataset. The inspection performances for each class are given in AUROC, and the average values are also reported inTable 1of the main paper.</figDesc><table><row><cell></cell><cell cols="2">Patch SVDD</cell></row><row><cell>Classes</cell><cell>Det.</cell><cell>Seg.</cell></row><row><cell>bottle</cell><cell>0.986</cell><cell>0.981</cell></row><row><cell>cable</cell><cell>0.903</cell><cell>0.968</cell></row><row><cell>capsule</cell><cell>0.767</cell><cell>0.958</cell></row><row><cell>carpet</cell><cell>0.929</cell><cell>0.926</cell></row><row><cell>grid</cell><cell>0.946</cell><cell>0.962</cell></row><row><cell>hazelnut</cell><cell>0.920</cell><cell>0.975</cell></row><row><cell>leather</cell><cell>0.909</cell><cell>0.974</cell></row><row><cell>metal nut</cell><cell>0.940</cell><cell>0.980</cell></row><row><cell>pill</cell><cell>0.861</cell><cell>0.951</cell></row><row><cell>screw</cell><cell>0.813</cell><cell>0.957</cell></row><row><cell>tile</cell><cell>0.978</cell><cell>0.914</cell></row><row><cell>toothbrush</cell><cell>1.000</cell><cell>0.981</cell></row><row><cell>transistor</cell><cell>0.915</cell><cell>0.970</cell></row><row><cell>wood</cell><cell>0.965</cell><cell>0.908</cell></row><row><cell>zipper</cell><cell>0.979</cell><cell>0.951</cell></row><row><cell>Average</cell><cell>0.921</cell><cell>0.957</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/nuclearboy95/Anomaly-Detection-PatchSVDD-PyTorch arXiv:2006.16067v2 [cs.CV] 13 Jul 2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/yahoojapan/NGT</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">bottle, cable, capsule, hazelnut, metal nut, pill, screw, toothbrush, transistor, and zipper 4 carpet, grid, leather, tile, and wood 5 https://github.com/nuclearboy95/Anomaly-Detection-PatchSVDD-PyTorch</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Estimating the support of a high-dimensional distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1443" to="1471" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Support vector data description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Consistency and convergence rates of one-class svms and related algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Vert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="817" to="854" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Deep semi-supervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Görnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<editor>ICLR.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<editor>ICCV.</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Automatic shortcut removal for self-supervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tschannen</surname></persName>
		</author>
		<editor>ICML.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Mvtec ad-a comprehensive real-world dataset for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
		<editor>CVPR.</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient auc optimization for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jaroszewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Principles of Data Mining and Knowledge Discovery</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="42" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Anomaly detection for skin disease images using variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.01349</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adversarially learned one-class classifier for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khalooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Ocgan: One-class novelty detection using gans with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<editor>CVPR.</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Improving unsupervised defect segmentation by applying structural similarity to autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Löwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02011</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Iterative energy-based projection on a normal data manifold for anomaly localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Combrexelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eline</surname></persName>
		</author>
		<editor>ICLR.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ganomaly: Semi-supervised anomaly detection via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Satellite image forgery detection and localization using gan and one-class classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Yarlagadda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Güera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bestagini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Maggie Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tubaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Imaging</title>
		<imprint>
			<biblScope unit="page" from="214" to="215" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Inverse-transform autoencoder for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10676</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Towards visually explaining variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Camps</surname></persName>
		</author>
		<editor>CVPR.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep anomaly detection using geometric transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-ofdistribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Effective end-to-end unsupervised outlier detection via inlier priority of discriminative network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Classification-based anomaly detection for general data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hoshen</surname></persName>
		</author>
		<editor>ICLR.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Representation learning by learning to count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML deep learning workshop</title>
		<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Revisiting self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1920" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<editor>ICLR.</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimating the intrinsic dimension of datasets by a minimal neighborhood information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Facco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Errico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intrinsic dimension of data representations in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ansuini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Macke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoccolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<editor>ICML.</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
