<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Coreference Resolution in Research Papers from Multiple Domains</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-01-04">4 Jan 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Brack</surname></persName>
							<email>arthur.brack|anett.hoppe|ralph.ewerth@tib.eu</email>
							<affiliation key="aff0">
								<orgName type="department">TIB -Leibniz Information Centre for Science and Technology</orgName>
								<address>
									<settlement>Hannover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">L3S Research Center</orgName>
								<orgName type="institution">Leibniz University</orgName>
								<address>
									<settlement>Hannover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Coreference Resolution in Research Papers from Multiple Domains</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Daniel Uwe Müller</title>
						<imprint>
							<date type="published" when="2021-01-04">4 Jan 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>coreference resolution · information extraction · knowledge graph population · scholarly communication</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Coreference resolution is essential for automatic text understanding to facilitate high-level information retrieval tasks such as text summarisation or question answering. Previous work indicates that the performance of state-ofthe-art approaches (e.g. based on BERT) noticeably declines when applied to scientific papers. In this paper, we investigate the task of coreference resolution in research papers and subsequent knowledge graph population. We present the following contributions: (1) We annotate a corpus for coreference resolution that comprises 10 different scientific disciplines from Science, Technology, and Medicine (STM); (2) We propose transfer learning for automatic coreference resolution in research papers; (3) We analyse the impact of coreference resolution on knowledge graph (KG) population; (4) We release a research KG that is automatically populated from 55,485 papers in 10 STM domains. Comprehensive experiments show the usefulness of the proposed approach. Our transfer learning approach considerably outperforms state-of-the-art baselines on our corpus with an F1 score of 61.4 (+11.0), while the evaluation against a gold standard KG shows that coreference resolution improves the quality of the populated KG significantly with an F1 score of 63.5 (+21.8).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Current research is generally published in form of PDF files and, sometimes, research artefacts of other modalities (data sets, source code, etc.). This makes them hard to handle for retrieval systems, since their content is hidden in human-but not machineinterpretable text. In consequence, current academic search engines are not able to adequately support researchers in their day-to-day tasks. This is further aggravated by the exploding number of published articles <ref type="bibr" target="#b3">[4]</ref>.</p><p>Approaches to automatically structure research papers are thus an active area of research. Coreference resolution is the task to identify mentions in a text which refer to the same entity or concept. It is an essential step for automatic text understanding and facilitates down-stream tasks such as text summarisation or question answering. For instance, the text 'Coreference resolution is... It is used for question answering...', has two coreferent mentions 'Coreference resolution' and 'It'. This allows us to extract the fact &lt;coreference resolution, used for, question answering&gt;.</p><p>Current methods for coreference resolution based on deep learning achieve quite impressive results (e.g. an F1 score of 79.6 for the OntoNotes 5.0 dataset <ref type="bibr" target="#b18">[19]</ref>) in the general domain, that is data from phone conversations, news, magazines, etc. But results of previous work indicate <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b44">44]</ref> that general coreference resolution systems perform poorly on scientific text. This is presumably caused by the specific terminology and phrasing used in a scientific domain. Some other studies state that annotating scientific text is costly since it demands certain expertise in the article's domain <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b17">18]</ref>. Most corpora for research papers cover only a single domain (e.g. biomedicine <ref type="bibr" target="#b9">[10]</ref>, artificial intelligence <ref type="bibr" target="#b26">[26]</ref>) and are thus limited to these domains. As a result, the annotated corpora are relatively small and overall only a few domains are covered. Datasets for the general domain are usually much larger, but they have not been exploited yet by approaches for coreference resolution in research papers.</p><p>Coreference resolution is also one of the main steps in the KG population pipeline <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b39">39]</ref>. However, to date it is not clear, to which extent (a) coreference resolution can help to reduce the number of scientific concepts in the populated KG, and (b) how coreference resolution influences the quality of the populated KG. Besides, a KG comprising multiple scientific domains has not been populated yet.</p><p>In this paper, we address the task of coreference resolution in research papers and subsequent knowledge graph population. Our contributions can be summarised as follows: (1) First, we annotate a corpus for coreference resolution that consists of 110 abstracts from 10 domains from Science, Technology, and Medicine. The systematic annotation resulted in a substantial inter-coder agreement (0.68 κ). We provide and compare baseline results for this dataset by evaluating five different state-of-the-art approaches: (i) coreference resolution systems for the general <ref type="bibr" target="#b19">[20]</ref> and (ii) for the artificial intelligence domain <ref type="bibr" target="#b26">[26]</ref>; (iii) supervised learning with training data from our corpus with a SpanBERT <ref type="bibr" target="#b18">[19]</ref> and (iv) a SciBERT-based system <ref type="bibr" target="#b2">[3]</ref>, and (v) the Scientific Information Extractor <ref type="bibr" target="#b26">[26]</ref>. Our experimental results confirm that state-of-the-art coreference approaches do not perform well on research papers. <ref type="bibr" target="#b1">(2)</ref> Consequently, we propose sequential transfer learning for coreference resolution in research papers. This approach utilises our corpus by fine-tuning a model that is pre-trained on a large corpus from the general domain <ref type="bibr" target="#b37">[37]</ref>. Experimental results show that our approach significantly outperforms the best state-of-the-art baseline (F1 score of 61.4, i.e. +11.0). (3) We investigate the impact of coreference resolution on automatic KG population. To evaluate the quality of various KG population strategies, we (i) compile a gold standard KG from our annotated corpus that contains scientific concepts referenced by mentions from text, and (ii) present a procedure to evaluate the clustering results of mentions. (4) We release (i) an automatically populated KG from 55,485 abstracts of the 10 STM domains and (ii) a gold KG (Test-STM-KG) from the annotated STM-corpus. Experimental results show that coreference resolution has only a small impact on the number of concepts in a populated KG, but it helps to improve the quality of the KG significantly: the population with coreference resolution yields an F1 score of 63.5 evaluated against the gold KG (+21.8 F1). We release all our corpora and source code to facilitate further research.</p><p>The remainder of the paper is organised as follows: Section 2 summarises related work on coreference resolution. Section 3 describes the annotation procedure and the characteristics of the corpus, and our proposed approaches for coreference resolution, KG population and KG evaluation. The experimental setup and results are reported in Section 4 and 5, while Section 6 concludes the paper and outlines future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Approaches for Coreference Resolution</head><p>For a given document d, the task of coreference resolution is (a) to extract mentions of scientific concepts M (d) = {m 1 , ..., m h }, and (b) to cluster mentions that refer to the same concept, i.e. c d (m) ⊆ M (d) is the cluster for mention m. Recent approaches mostly rely on supervised learning and can be categorised into three groups <ref type="bibr" target="#b32">[32]</ref>: (1) Mention-pair models <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b45">45]</ref> are binary classifiers that determine whether two mentions are coreferent or not. (2) Entity-mention models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b41">41]</ref> determine whether a mention is coreferent to a preceding cluster. A cluster has more expressive features compared to a mention in mention-pair models. (3) Ranking-based models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b30">30]</ref> simultaneously rank all candidate antecedents (i.e. preceding mention candidates). This enables the model to identify the most probable antecedent.</p><p>Lee et al. <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25]</ref> propose an end-to-end neural coreference resolution model. It is a ranking-based model that jointly recognises mentions and clusters. Therefore Furthermore, several approaches proposed multi-task learning, such that related tasks may benefit from knowledge in other tasks to achieve better prediction accuracy: Luan et al. <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b49">49]</ref> train a model on three tasks (coreference resolution, entity and relation extraction) using one dataset of research papers. Sanh et al. <ref type="bibr" target="#b43">[43]</ref> introduce a multi-task model that is trained on four tasks (mention detection, coreference resolution, entity and relation extraction) using two different datasets in the general domain.</p><p>Results of some previous studies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b44">44]</ref> revealed that general coreference systems do not work well in the biomedical domain due to the lack of domain knowledge. For instance, on Colorado Richly Annotated Full Text (CRAFT) corpus [10] a coreference resolution system for the news domain achieves only 14.0 F1 (-32.0).</p><p>To the best of our knowledge, a transfer learning approach from the general to the scientific domain has not been proposed for coreference resolution yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Corpora for Coreference Resolution in Research Papers</head><p>For the general domain, multiple datasets exist for coreference resolution, e.g. Message Understanding Conference (MUC-7) <ref type="bibr" target="#b31">[31]</ref>, Automatic Content Extraction (ACE05) <ref type="bibr" target="#b13">[14]</ref>, or OntoNotes 5.0 <ref type="bibr" target="#b37">[37]</ref>. The OntoNotes 5.0 dataset <ref type="bibr" target="#b37">[37]</ref> is the largest one and is used in many benchmark experiments for coreference resolution systems <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">29]</ref>.</p><p>Various annotated datasets for coreference resolution exist also for research papers: CRAFT corpus <ref type="bibr" target="#b9">[10]</ref> covers 97 papers from biomedicine. The corpus of Schäfer et al. <ref type="bibr" target="#b44">[44]</ref> contains 266 papers from computational linguistics and language technology. Chaimongkol et al. <ref type="bibr" target="#b5">[6]</ref> annotated a corpus of 284 papers from four subdisciplines in computer science. The SciERC corpus <ref type="bibr" target="#b26">[26]</ref> comprises 500 abstracts from the artificial intelligence domain and features annotations for scientific concepts and relations. It was used to generate an artificial intelligence (AI) knowledge graph <ref type="bibr" target="#b11">[12]</ref>. Furthermore, several datasets exist for scientific concept extraction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b40">40]</ref> and relation extraction <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b0">1]</ref> that cover various scientific domains.</p><p>To the best of our knowledge, a corpus for coreference resolution that comprises a broad range of scientific domains is not available yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Coreference Resolution in Research Papers</head><p>As the discussion of related work reveals, existing corpora for coreference resolution in scientific papers normally cover only a single domain, and coreference resolution approaches do not perform well on scholarly texts. To address these issues, we systematically annotate a corpus with coreferences in abstracts from 10 different science domains. Current approaches for coreference resolution in research papers do not exploit existing annotated datasets from the general domain, which are usually much larger than in the scientific domain. We propose a sequential transfer learning approach that takes advantage from large, annotated datasets. Finally, to the best of our knowledge, the impact of (a) coreference resolution and (b) cross-domain collapsing of mentions to scientific concepts on KG population with multiple science domains has not been investigated yet. Consequently, we present an evaluation procedure for the clustering aspect in the KG population pipeline.</p><p>In the sequel, we describe our annotated corpus, our transfer learning approach for coreference resolution, and an evaluation procedure for clustering in KG population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus for Coreference Resolution in 10 STM Domains</head><p>In this section, we describe the STM corpus <ref type="bibr" target="#b4">[5]</ref>, which we used as the basis for the annotation, our annotation process, and the characteristics of the resulting corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STM Corpus:</head><p>The STM corpus <ref type="bibr" target="#b4">[5]</ref> comprises 110 articles from 10 domains in Science, Technology and Medicine, namely Agriculture (Agr), Astronomy (Ast), Biology (Bio), Chemistry (Che), Computer Science (CS), Earth Science (ES), Engineering (Eng), Materials Science (MS), Mathematics (Mat), and Medicine (Med). It contains annotated mentions of scientific concepts in abstracts with four domain-independent concept types, namely Process, Method, Material, and Data. These concept mentions were later linked to entities in Wikipedia and Wikidata <ref type="bibr" target="#b14">[15]</ref>. The 110 articles (11 per domain) were taken from the OA-STM corpus <ref type="bibr" target="#b23">[23]</ref> of Elsevier Labs.</p><p>We build upon related work and extend the STM corpus with coreference annotations. In particular, we (1) annotate coreference links between existing scientific concept mentions in abstracts using the BRAT annotation tool <ref type="bibr" target="#b46">[46]</ref>, and (2) annotate further mentions, i.e. pronouns and noun phrases consisting of multiple consecutive mentions.  Annotation Process: Other studies have shown that non-expert annotations are viable for the scientific domain <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b47">47]</ref>, and they are less costly than domain-expert annotations. Therefore, we also annotate the corpus with non-domain experts, i.e. by two students in computer science. Furthermore, we follow mostly the annotation procedure of the STM corpus <ref type="bibr" target="#b4">[5]</ref>, which consists of the following three phases: 1. Pre-Annotation: This phase aims at developing annotation guidelines through trial annotations. We adapted the comprehensive annotation guidelines of the OntoNotes 5.0 dataset <ref type="bibr" target="#b38">[38]</ref>, which were developed for the general domain, to research papers.</p><p>In particular, we provide briefer and simpler descriptions with examples from the scientific domain. Within three iterations both annotators labelled independently 10, 9 and 7 abstracts (i.e. 26 abstracts), respectively. After each iteration the annotators discussed the outcome and refined the annotation guidelines. 2. Independent Annotation: After the annotation guidelines were finalised, both annotators independently re-annotated the previously annotated abstracts and 24 additional abstracts. The final inter-coder agreement was measured on the 50 abstracts (5 per domain) using Cohen's κ <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b21">22]</ref> and MUC <ref type="bibr" target="#b48">[48]</ref>. As shown in <ref type="table" target="#tab_0">Table 1</ref>, we achieve a substantial agreement with 0.68 κ and 0.69 MUC. 3. Consolidation: Finally, the remaining 60 abstracts were annotated by one annotator and the annotation results of this author were used as the gold standard corpus.</p><p>Corpus Characterstics: <ref type="table" target="#tab_1">Table 2</ref> shows the characteristics of the resulting corpus broken down per concept type, while they are listed per domain in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Transfer Learning for Coreference Resolution</head><p>We suggest sequential transfer learning <ref type="bibr" target="#b42">[42]</ref> for coreference resolution in research papers. Therefore, we fine-tune a model pre-trained on a large (source) dataset to our (target) dataset. As the source dataset, we use the English portion of the OntoNotes 5.0 dataset <ref type="bibr" target="#b37">[37]</ref>, since it is a broad corpus that consists of 3,493 documents with telephone conversations, magazine and news articles, web data, broadcast conversations, and the New Testament. Besides, our annotation guidelines were adapted from OntoNotes 5.0. For the model, we utilise BERT for Coreference Resolution (BFCR) <ref type="bibr" target="#b19">[20]</ref> with Span-BERT <ref type="bibr" target="#b18">[19]</ref> word embeddings. This model achieves state-of-the-art results on the Onto-Notes dataset <ref type="bibr" target="#b18">[19]</ref>. Another advantage is the availability of the pre-trained model and the source code. The BFCR model improves Lee et al.'s approach <ref type="bibr" target="#b25">[25]</ref> by replacing the LSTM encoder with the SpanBERT transformer-encoder. SpanBERT <ref type="bibr" target="#b18">[19]</ref> has different training objectives than BERT <ref type="bibr" target="#b12">[13]</ref> to better represent spans of text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cross-Domain Research Knowledge Graph Population</head><formula xml:id="formula_0">C := {c d (m)|d ∈ D, m ∈ M (d)} (1) [c] := {x ∈ C|collapsable(c, x)} (2) E := {[c]|c ∈ C}<label>(3)</label></formula><p>Now, we can construct the KG: for each paper d ∈ D and for each scientific concept e ∈ E we create a node in the KG. The scientific concept type of e is the most frequent concept type of all mentions in e. Then, for each mention m ∈ M (d) we create a 'mentions' link between the paper and the corresponding scientific concept [m] ∈ E.</p><p>Cross-Domain vs. In-Domain Collapsing: One commonly used approach to define the collapsable relation is to treat two clusters as equivalent, if and only if the 'label' of the clusters is the same. The label of a cluster is the longest mention in the cluster normalised by (a) lower-casing, (b) removing articles, possessives and demonstratives, (c) resolving acronyms, and (d) lemmatisation using WordNet <ref type="bibr" target="#b15">[16]</ref> to transform plural forms to singular. Other studies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">26]</ref> used a similar label function for KG population. However, a research KG that comprises multiple scientific disciplines has not been populated yet. Thus, it is not clear whether it is feasible to collapse clusters across domains. Usually, terms within a scientific domain are unambiguous. However, some terms have different meanings across scientific disciplines (e.g. "neural network" in CS and Med). Thus, we investigate both cross-domain and in-domain collapsing strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Graph Population Approach:</head><p>We populate a research KG with research papers from multiple scientific domains, i.e. 55,485 abstracts of Elsevier with CC-BY licence from the 10 investigated domains. First, we extract (a) concept mentions from the abstracts using the scientific concept extractor of the STM-corpus <ref type="bibr" target="#b4">[5]</ref>, and (b) clusters within the abstracts with our transfer learning coreference model. Then, those mention clusters, which contain solely mentions recognised by the coreference resolution model and not by the scientific concept extraction model, are dropped, since the coreference resolution model does not recognise the concept type of the mentions. Finally, the remaining clusters serve for the population of the KG as described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation Procedure of Clustering in KG Population</head><p>One common approach to evaluate the quality of a populated KG is to annotate a (random) subset of statements by humans as true or false and to calculate precision and recall <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b50">50]</ref>. To evaluate recall, small collections of ground-truth capturing all knowledge is necessary, that are usually difficult to obtain <ref type="bibr" target="#b50">[50]</ref>. To the best of our knowledge, a common approach to evaluate the clustering aspect of the KG population pipeline does not exist yet. Thus, in the following, we present (1) an annotated test KG, and (2) metrics to evaluate clustering of mentions to concepts in KG population.</p><p>Test KG: To enable evaluation of KG population strategies, we compile a test KG, referred to as Test-STM-KG. For this purpose, we reuse the STEM-ECR corpus <ref type="bibr" target="#b14">[15]</ref>, in which 1,221 mentions of the STM corpus are linked to Wikipedia entities. First, we extract all annotated clusters of the STM corpus in which all mentions of the cluster uniquely refer to the same Wikipedia entity. Then, we collapse all clusters which refer to the same Wikipedia entity to concepts. Formally, the Test-STM-KG is a partition of mentions, where each part denotes a concept, i.e. a disjoint set of mentions. A mention is uniquely represented by the tuple (start offset, end offset, concept type, doc id).  <ref type="table" target="#tab_4">Table 4</ref> shows the characteristics of the compiled Test-STM-KG. It consists of 920 clusters, of which 711 are singleton clusters. These clusters were collapsed to 762 concepts, of which 31 concepts are used across multiple domains (referred to as MIX).</p><p>Evaluation Procedure: To evaluate the clustering result of a KG population strategy, we use the metrics of coreference resolution. The three popular metrics for coreference resolution are M U C <ref type="bibr" target="#b48">[48]</ref>, B 3 <ref type="bibr" target="#b1">[2]</ref> and CEAF e φ4 <ref type="bibr" target="#b28">[28]</ref>. Each of them represents different evaluation aspects (see <ref type="bibr" target="#b36">[36]</ref> for more details). To calculate these metrics, we treat the gold concepts (i.e. a partition of mentions) of the Test-STM-KG as the 'key' and the predicted concepts as the 'response'. We report also the CoNLL P/R/F1 scores, that is the averages of M U C's, B 3 's and CEAF e φ4 's respective precision (P), recall (R) and F1 scores. The CoNLL metrics were proposed for the conference on Computational Natural Language Learning (CoNLL) shared tasks on coreference resolution <ref type="bibr" target="#b36">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>Here we describe our experimental setup for coreference resolution and KG population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Automatic Coreference Resolution</head><p>We evaluate three different state-of-the-art architectures on the STM dataset: (I) BERT for Coreference Resolution (BFCR) <ref type="bibr" target="#b19">[20]</ref> with SpanBERT <ref type="bibr" target="#b18">[19]</ref> word embeddings (referred to as BFCR Span), (II) BFCR with SciBERT <ref type="bibr" target="#b2">[3]</ref> word embeddings (referred to as BFCR Sci), and (III) Scientific Information Extractor (SCIIE) <ref type="bibr" target="#b26">[26]</ref> with ELMo <ref type="bibr" target="#b35">[35]</ref> word embeddings (referred to as SCIIE). The three architectures are evaluated in the following six approaches (#1 -#6):</p><p>-Pre-   Evaluation: We use the metrics M U C <ref type="bibr" target="#b48">[48]</ref>, B 3 <ref type="bibr" target="#b1">[2]</ref>, CEAF e φ4 <ref type="bibr" target="#b28">[28]</ref> and CoN LL <ref type="bibr" target="#b36">[36]</ref> in compliance with other studies on coreference resolution <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b24">24]</ref>. To obtain robust results, we apply five-fold cross-validation, according to the data splits given by Brack et al. <ref type="bibr" target="#b4">[5]</ref>, and report averaged results. For each fold, the dataset is split into train/validation/test sets with 8/1/2 abstracts per domain, respectively, i.e. 80/10/20 abstracts. We reuse the original implementations and default hyperparameters of the above architectures. Hyperparameter-tuning of the best baseline approach #3 according to <ref type="bibr" target="#b19">[20]</ref> confirmed that the default hyperparameters of BFCR Span perform best on our corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation of KG Population Strategies</head><p>We compare four KG population strategies: (1) cross-domain and (2) in-domain collapsing, as well as <ref type="formula" target="#formula_0">(3)</ref> cross-domain and (4) in-domain collapsing without coreference resolution. To evaluate cross-domain and in-domain collapsing, we take the gold clusters (i.e. mention clusters within the abstracts) of the Test-STM-KG and collapse them to concepts according to the respective strategy. When leaving out the coreference resolution step, we treat all mentions in the Test-STM-KG as singleton clusters and collapse them to concepts according to the respective strategy. Finally, we calculate the metrics as described in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>In this section, we discuss the experimental results for automatic coreference resolution and KG population. <ref type="table" target="#tab_6">Table 5</ref> shows the overall results of the six evaluated approaches and <ref type="table" target="#tab_7">Table 6</ref> the results per domain of the best baseline #3 and our approach #6. Our transfer learning approach #6 BFCR Span from OntoNotes (Onto) <ref type="bibr" target="#b37">[37]</ref> to STM significantly outperforms the best baseline approach #3 with an overall CoNLL F1 of 61.4 (+10.0) and a low standard deviation ±1.5 across the five folds. The approaches #1 BFCR Span pre-trained on OntoNotes <ref type="bibr" target="#b37">[37]</ref>, and #2 SCIIE pretrained on SciERC <ref type="bibr" target="#b26">[26]</ref> achieve a CoNLL F1 score of 37.1 and 7.4, respectively. These scores are quite low compared to the approaches #3 -#6 that use training data of the STM corpus. This indicates that models pre-trained on existing datasets do not generalise sufficiently well for coreference resolution in research papers. Models trained only on the STM corpus (i.e. #3 -#5) achieve better results. However, they have quite low recall scores indicating that the size of the training data might not be sufficient to enable the model to generalise well. SciBERT #4, although pre-trained on scientific texts, performs worse than SpanBERT #3. Presumably the reason is that SpanBERT has approximately 3 times more parameters than SciBERT. Our transfer learning approach #6 achieves the best results with quite balanced precision and recall scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic Coreference Resolution</head><p>Furthermore, to evaluate the effectiveness of our transfer learning approach, we compare the best baseline #3 and our transfer learning approach #6 also with the Sci-ERC corpus <ref type="bibr" target="#b26">[26]</ref>. The SciERC corpus comprises 500 abstracts from the AI domain. Since SciERC has around 5 times more training data than STM, we compare the approaches #3 and #6 also using only <ref type="bibr">1 5</ref> th of the training data in SciERC while keeping the original validation and test sets. It can be seen in <ref type="table" target="#tab_8">Table 7</ref> that our transfer learning approach #6 improves slightly the baseline result using the whole training data with 60.1 F1 (+0.8). When using only <ref type="bibr">1 5</ref> th of the training data, our transfer learning approach noticeably outperforms the baseline with 54.2 F1 (+7.1). Thus, our transfer learning approach can help significantly to improve the performance of coreference resolution in research papers with few labelled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cross-Domain Research KG</head><p>In this subsection, we describe the characteristics of our populated KG and discuss the evaluation results of various KG population strategies. <ref type="table">Table 8</ref> shows the characteristics of the populated KGs per domain. The resulting KGs with cross-domain and in-domain collapsing have more than 994,000 and 1.1 Mio. scientific concepts, respectively, obtained from <ref type="table">Table 8</ref>: Characteristics of the populated research KGs per domain: (1) number of abstracts, number of extracted scientific concept mentions and coreferent mentions, (2) the number of scientific concepts for the KG with cross-domain collapsing, (3) in-domain collapsing, (4) cross-domain collapsing but without coreference resolution, and (5) indomain collapsing but without coreference resolution. Reduction denotes the percentual reduction of mentions to scientific concepts and MIX the cross-domain concepts. Evaluation of KG Population Strategies: Next, we discuss the different KG population strategies. For each strategy, <ref type="table">Table 8</ref> reports the number of concepts in the populated KG and the percentage reduction of mentions to concepts, and in <ref type="table" target="#tab_10">Table 9</ref> the evaluation results of KGs against the Test-STM-KG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Characteristics of the Research KG:</head><p>Cross-Domain vs. In-Domain Collapsing: Cross-domain collapsing achieves a higher CoNLL F1 score of 64.8 than in-domain collapsing with a score of 63.5 (see <ref type="table" target="#tab_10">Table 9</ref>). However, in-domain collapsing yields (as expected) a higher precision (CoNLL P 85.5), since some terms have different meanings across domains (e.g. Measure (mathematics) vs. Measurement in https://en.wikipedia.org). Furthermore, the Test-STM-KG has only 31 cross-domain concepts due to its small size. Thus, we expect that cross-domain collapsing would yield worse results on a larger test set. Furthermore, as shown in <ref type="table">Table 8</ref>, cross-domain collapsing yields less concepts than in-domain collapsing (more than 994,000 versus 1.1 Mio. concepts). We can also observe that only 70,044 (7%) of the concepts are used across multiple domains. This indicates, that each scientific domain mostly uses its own terminology. However, the concepts used across domains can have different meanings. Thus, when precision is more important than recall in downstream tasks, in-domain collapsing should be the preferred choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Coreference Resolution:</head><p>Coreference resolution has only a small impact on the number of resulting concepts in a populated KG (see <ref type="table">Table 8</ref>). However, as shown in <ref type="table" target="#tab_10">Table 9</ref>, leaving out the coreference resolution step during KG population yields only low CoNLL F1 scores, i.e. 41.7 (-21.8) F1 and 43.5 (-21.3) F1. Thus, coreference resolution significantly improves the quality of a populated KG .</p><p>Qualitative Analysis: We also inspected the top five frequent domain-specific concepts in the populated KG (a list of these concepts can be found in our public repository). As far as we can judge with our computer science background, we consider the extracted top frequent concepts to be reasonable and useful for the domains. For instance, in Ast, the method 'standard model' is frequently mentioned, while in CS the process 'cyber attack' appears most often. The frequency of the top concepts differs significantly between the domains: In Med, Ast, Eng, ES and Agr, a top frequent concept is referenced 10.8, 10.2, 4.9, 3.8, and 3.1 times per 1000 abstracts, respectively. In Che, MS, Mat, Bio, and CS, a top frequent concept is referenced only by few abstracts (0.3, 0.4, 1.0, 1.4, and 2.3, respectively, per 1000 abstracts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we have investigated the task of coreference resolution in research papers across 10 different scientific disciplines. We have annotated a corpus that comprises 110 abstracts with coreferences with a substantial inter-coder agreement. Our baseline results with current state-of-the-art approaches for coreference resolution demonstrate that current approaches perform poorly on our corpus. The proposed approach, which uses sequential transfer learning and exploits annotated datasets from the general domain, outperforms noticeably the state-of-the-art baselines. Thus, our transfer learning approach can help to reduce annotation costs for scientific papers, while obtaining highquality results at the same time. Furthermore, we have investigated the impact of coreference resolution on KG population. For this purpose, we have compiled a gold KG from our annotated corpus and propose an evaluation procedure for KG population strategies. We have demonstrated that coreference resolution has a small impact on the number of resulting concepts in the KG, but improved significantly the quality of the KG. Finally, we have generated a research KG from 55,485 abstracts of the 10 investigated domains. We show that each domain mostly uses its own terminology and that the populated KG contains useful concepts. To facilitate further research, we make our corpora and source code publicly available: https://github.com/arthurbra/stm-coref</p><p>In future work, we plan to evaluate multi-task learning approaches, and to populate and evaluate a much larger research KG to get more insights in scientific language use.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, the model considers all spans in the text as possible mentions and learns distributions over possible antecedents for each mention. For computational efficiency, candidate spans and antecedents are pruned during training and inference. Joshi et al. [20] enhance Lee et al.'s model with BERT-based word embeddings [13], while Ma et al. [29] improve the model with better attention mechanisms and loss functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Let d ∈ D be an abstract, M (d) = {m 1 , ..., m h } the mentions of scientific concepts in d, and c d (m i ) ⊆ M (d) the corresponding coreference cluster for mention m i in d. If mention m s is not coreferent with other mentions in d, then c d (m s ) = {m s } is a singleton cluster. The set of all clusters is denoted by C. An equivalence relation collapsable ⊆ C × C defines if two clusters can be collapsed, i.e. if the clusters refer to the same scientific concept. To create the set of all concepts E, we build the quotient set for the set of clusters C with respect to the relation collapsable:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Per-domain and overall inter-annotator agreement (Cohen's κ and MUC) for coreference resolution annotation in our STM corpus.</figDesc><table><row><cell></cell><cell cols="2">Mat Med Ast CS Bio Agr ES Eng Che MS Overall</cell></row><row><cell>κ</cell><cell>0.84 0.80 0.78 0.72 0.70 0.66 0.61 0.58 0.56 0.52</cell><cell>0.68</cell></row><row><cell cols="2">MUC 0.83 0.69 0.78 0.73 0.70 0.72 0.61 0.66 0.56 0.63</cell><cell>0.69</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Characteristics of the annotated STM corpus with 110 abstracts per concept type in terms of number of scientific concept mentions, number of coreferent mentions, number of coreference clusters and singleton clusters, and the number of overall clusters. MIXED denotes clusters consisting of mentions with different concept types, NONE denotes coreference mentions and clusters without a scientific concept mention.</figDesc><table><row><cell></cell><cell cols="6">Data Material Method Process MIXED NONE Total</cell></row><row><cell># mentions</cell><cell cols="2">1,658 2,099</cell><cell cols="2">258 2,112</cell><cell>0</cell><cell>0 6,127</cell></row><row><cell cols="2"># coreferent mentions 351</cell><cell>910</cell><cell>101</cell><cell>510</cell><cell>0</cell><cell>705 2,577</cell></row><row><cell cols="2"># coreference clusters 153</cell><cell>339</cell><cell>30</cell><cell>198</cell><cell>50</cell><cell>138 908</cell></row><row><cell cols="3"># singleton clusters 1,307 1,189</cell><cell cols="2">157 1,602</cell><cell>0</cell><cell>0 4,255</cell></row><row><cell># overall clusters</cell><cell cols="2">1,460 1,528</cell><cell cols="2">187 1,800</cell><cell>50</cell><cell>138 5,163</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>The original corpus has in total 6,127 mentions. 2,577 mentions were annotated as coreferent resulting in 908 coreference clusters. Thus, each coreference cluster contains on average 2.84 mentions, while Method clusters contain the most (3.4 mentions) and Data clusters the least (2.3 mentions). Furthermore, 705 mentions were annotated additionally (referred to as NONE) since they represent pronouns (422 mentions) or noun phrases consisting</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Characteristics of the STM corpus per domain (11 abstracts per domain). These treatments]...'. Fifty clusters (5%) contain mentions with different concept types (referred to as MIXED) due to disagreements between the annotators of the original concept mentions, and the annotators of coreferences. For instance, non-</figDesc><table><row><cell></cell><cell>Agr Ast Bio Che CS ES Eng MS Mat Med Total</cell></row><row><cell># mentions</cell><cell>741 791 649 553 483 698 741 574 297 600 6,127</cell></row><row><cell cols="2"># coreferent mentions 276 365 275 282 181 241 318 256 124 259 2,577</cell></row><row><cell cols="2"># coreference clusters 106 120 98 90 67 93 117 87 48 82 908</cell></row><row><cell cols="2"># singleton clusters 520 549 443 384 339 525 503 371 210 411 4,255</cell></row><row><cell># clusters</cell><cell>626 669 541 474 406 618 620 458 258 493 5,163</cell></row><row><cell cols="2">of multiple consecutive original mentions (283 mentions) such as '... [[A], [B], and [C]</cell></row><row><cell>[treatments]]... [</cell><cell></cell></row></table><note>coreferent mentions were annotated as coreferent, or coreferent mentions have different concept types. Finally, 138 clusters (15%) do not have a concept type (NONE) since they form clusters which are not coreferent with the original concept mentions.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Characteristics of the Test-STM-KG: number of concepts per concept type and per domain. MIX denotes the number of cross-domain concepts.</figDesc><table><row><cell></cell><cell cols="3">Agr Ast Bio CS Che ES Eng MS Mat Med MIX Total</cell></row><row><cell>Data</cell><cell>5 18 3 20 4 9 28 13 37</cell><cell>8</cell><cell>9 154</cell></row><row><cell cols="3">Material 27 35 30 20 26 52 32 30 9 40</cell><cell>7 308</cell></row><row><cell>Method</cell><cell>1 1 1 21 6 2 4 10 3</cell><cell>8</cell><cell>7 64</cell></row><row><cell cols="3">Process 17 12 21 34 13 33 20 25 15 38</cell><cell>8 236</cell></row><row><cell>Total</cell><cell cols="3">50 66 55 95 49 96 84 78 64 94 31 762</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Trained Models: We evaluate already pre-trained models on the test sets of the STM corpus, i.e. #1 BFCR Span trained on the English portion of the OntoNotes dataset [38], and #2 SCIIE trained on SciERC [26] from the AI domain. -Supervised Learning: We train a model from scratch with the three architectures using the training data of the STM corpus and evaluate their performance with the test sets of STM: #3 BFCR Span, #4 BFCR Sci, and #5 SCIIE. -Transfer Learning: This is our proposed approach #6. We fine-tune all parameters of a pre-trained model on the English portion of the OntoNotes dataset [19] with the training data of our STM corpus. For that, we use the BFCR Span architecture.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Performance of the baseline approaches #1 -#5 and our proposed transfer learning approach #6 on the test sets of the STM corpus across five-fold cross validation.</figDesc><table><row><cell></cell><cell></cell><cell>M U C</cell><cell>B 3</cell><cell>CEAF e φ4</cell><cell>CoN LL</cell></row><row><cell></cell><cell>Training data</cell><cell>P R F1</cell><cell>P R F1</cell><cell>P R F1</cell><cell>P R F1</cell></row><row><cell cols="6">#1 BFCR Span OntoNotes 57.1 31.1 40.2 55.9 25.7 35.2 50.2 28.1 36.0 54.4 28.3 37.1</cell></row><row><cell>#2 SCIIE</cell><cell>SciERC</cell><cell cols="4">13.4 4.5 6.8 13.1 4.3 6.5 18.1 6.0 9.0 14.9 4.9 7.4</cell></row><row><cell cols="2">#3 BFCR Span STM</cell><cell cols="4">61.6 45.6 52.3 59.8 41.5 48.8 57.9 44.4 50.0 59.8 43.8 50.4</cell></row><row><cell cols="2">#4 BFCR Sci STM</cell><cell cols="4">61.9 40.2 48.6 59.7 36.1 44.9 61.7 36.9 46.0 61.1 37.7 46.5</cell></row><row><cell>#5 SCIIE</cell><cell>STM</cell><cell cols="4">60.3 45.2 51.6 57.6 41.7 48.3 56.6 43.6 49.1 58.1 43.5 49.7</cell></row><row><cell cols="6">#6 BFCR Span Onto→STM 64.5 63.5 63.9 61.0 60.0 60.4 60.5 59.6 60.0 62.0 61.0 61.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Per domain and overall CoNLL F1 results of the best baseline #3 and our transfer learning approach #6 on the STM corpus across five-fold cross validation.</figDesc><table><row><cell cols="3">Training data Agr Ast Bio Che CS ES Eng MS Mat Med Overall</cell></row><row><cell>#3 BFCR Span STM</cell><cell>48.0 50.5 52.2 49.0 59.1 39.6 52.8 47.6 42.5 51.0</cell><cell>50.4</cell></row><row><cell cols="2">#6 BFCR Span Onto→STM 62.8 61.1 57.5 56.3 74.9 57.5 59.8 52.1 55.7 62.1</cell><cell>61.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>CoNLL scores on the tests sets of the SciERC corpus<ref type="bibr" target="#b26">[26]</ref> across 3 random restarts of the approaches: current state of the art of Luan et al., the best baseline approach (#3), and our transfer learning approach (#6). We report results using the whole and using only1  5  th of the training data of SciERC (referred to as 1 5 SciERC).</figDesc><table><row><cell>Training data</cell><cell>P R F1</cell></row><row><cell>Luan et al. [26] SciERC</cell><cell>52.0 44.9 48.2</cell></row><row><cell>#3 BFCR Span SciERC</cell><cell>63.3 55.7 59.3</cell></row><row><cell cols="2">#6 BFCR Span OntoNotes→SciERC 63.9 57.1 60.1</cell></row><row><cell>#3 BFCR Span 1 5 SciERC</cell><cell>63.1 39.1 47.1</cell></row><row><cell cols="2">#6 BFCR Span OntoNotes→ 1 5 SciERC 52.8 56.7 54.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Mio. concept mentions and 726,000 coreferent mentions. Ast and Bio are the most represented domains, while CS and Mat are the most underrepresented.</figDesc><table><row><cell></cell><cell>Agr</cell><cell>Ast</cell><cell>Bio</cell><cell>CS Che</cell><cell>ES</cell><cell>Eng</cell><cell cols="2">MS Mat</cell><cell>Med MIX</cell><cell>Total</cell></row><row><cell># abstracts</cell><cell cols="7">7,731 15,053 11,109 1,216 1,234 2,352 3,049 2,258</cell><cell cols="2">665 10,818</cell><cell>-</cell><cell>55,485</cell></row><row><cell cols="10"># mentions 332,983 370,311 423,315 45,388 46,203 129,288 127,985 86,490 20,466 586,019</cell><cell>-2,168,448</cell></row><row><cell cols="10"># coref. men. 108,579 120,942 143,292 17,674 14,059 40,974 42,654 25,820 8,510 203,884</cell><cell>-726,388</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">cross-domain collapsing</cell><cell></cell><cell></cell></row><row><cell cols="10">KG concepts 138,342 173,027 177,043 20,474 21,298 62,674 55,494 39,211 9,275 227,690 70,044 994,572</cell></row><row><cell>-Data</cell><cell cols="9">27,132 64,537 32,946 5,380 5,124 19,542 17,053 10,629 2,982 66,473 19,715 271,513</cell></row><row><cell>-Material</cell><cell cols="9">69,534 45,296 83,627 6,242 10,154 24,322 19,689 17,276 2,406 68,141 20,812 367,499</cell></row><row><cell>-Method</cell><cell cols="7">2,992 8,819 6,135 2,001 1,055 1,776 2,953 1,605</cell><cell cols="2">685 9,363 1,627</cell><cell>39,011</cell></row><row><cell>-Process</cell><cell cols="9">38,684 54,375 54,335 6,851 4,965 17,034 15,799 9,701 3,202 83,713 27,890 316,549</cell></row><row><cell>reduction</cell><cell>58%</cell><cell>53%</cell><cell cols="2">58% 55% 54%</cell><cell>52%</cell><cell cols="3">57% 55% 55%</cell><cell>61%</cell><cell>-</cell><cell>54%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">in-domain collapsing</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">KG concepts 180,135 197,605 229,201 30,736 32,191 81,584 78,417 55,358 14,567 278,686</cell><cell>-1,178,480</cell></row><row><cell>reduction</cell><cell>46%</cell><cell>47%</cell><cell cols="2">46% 32% 30%</cell><cell>37%</cell><cell cols="3">39% 36% 29%</cell><cell>52%</cell><cell>-</cell><cell>46%</cell></row><row><cell></cell><cell></cell><cell cols="7">cross-domain collapsing without coreference resolution</cell></row><row><cell cols="10">KG concepts 146,894 182,479 187,557 21,950 22,555 66,600 59,689 41,776 9,939 242,797 77,493 1,059,729</cell></row><row><cell>reduction</cell><cell>56%</cell><cell>51%</cell><cell cols="2">56% 52% 51%</cell><cell>48%</cell><cell cols="3">53% 52% 51%</cell><cell>59%</cell><cell>-</cell><cell>51%</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">in-domain collapsing without coreference resolution</cell><cell></cell></row><row><cell cols="10">KG concepts 184,218 199,894 234,399 31,525 32,937 83,445 80,476 56,690 14,911 284,547</cell><cell>-1,203,042</cell></row><row><cell>reduction</cell><cell>45%</cell><cell>46%</cell><cell cols="2">45% 31% 29%</cell><cell>35%</cell><cell cols="3">37% 34% 27%</cell><cell>51%</cell><cell>-</cell><cell>45%</cell></row><row><cell cols="5">55,485 abstracts with more than 2,1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Performance of the collapsing strategies evaluated against the Test-STM-KG: in-domain and cross-domain collapsing with and without coreference resolution.</figDesc><table><row><cell></cell><cell>#concepts</cell><cell>M U C</cell><cell>B 3</cell><cell></cell><cell>CEAF e φ4</cell><cell>CoN LL</cell></row><row><cell></cell><cell>in KG</cell><cell>P R F1</cell><cell>P R</cell><cell>F</cell><cell>P R F1</cell><cell>P R F1</cell></row><row><cell>in-domain collapsing</cell><cell cols="6">859 86.3 70.6 77.7 86.0 69.0 76.6 84.1 23.1 36.2 85.5 54.2 63.5</cell></row><row><cell>-without coreferences</cell><cell cols="6">900 75.5 38.8 51.2 75.2 37.9 50.4 71.1 14.0 23.4 73.9 30.2 41.7</cell></row><row><cell>cross-domain collapsing</cell><cell cols="6">837 85.0 73.0 78.5 84.5 72.1 77.8 84.7 24.6 38.1 84.7 56.6 64.8</cell></row><row><cell>-without coreferences</cell><cell cols="6">876 73.5 41.0 52.6 72.2 15.5 25.5 72.2 15.5 25.5 73.0 32.4 43.5</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vikraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<title level="m">Semeval 2017 task 10: Scienceie -extracting keyphrases and relations from scientific publications</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="546" to="555" />
		</imprint>
	</monogr>
	<note>SemEval@ACL</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="563" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scibert: A pretrained language model for scientific text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3613" to="3618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bornmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2215" to="2222" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain-independent extraction of scientific concepts from research articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ewerth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">12035</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="251" to="266" />
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Corpus for coreference resolution on scientific papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaimongkol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aizawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3187" to="3190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Statistical Models for Text Classification and Clustering: Applications and Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>UNIVERSITY OF CALIFORNIA, IRVINE</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Entity-centric coreference resolution with model stacking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1405" to="1415" />
		</imprint>
	</monogr>
	<note>ACL (1)</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coreference annotation and resolution in the colorado richly annotated full text (CRAFT) corpus of biomedical journal articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lanfranchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A B</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Panteleyeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Specialized models and ranking for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP. pp</title>
		<imprint>
			<biblScope unit="page" from="660" to="669" />
			<date type="published" when="2008" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ai-kg: an automatically generated knowledge graph of artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dessi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Recupero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC 2020</title>
		<meeting>ISWC 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>accepted for publication</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ACE) program -tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC. European Language Resources Association</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The STEM-ECR dataset: Grounding scientific entity references in STEM scholarly content to authoritative encyclopedic and lexicographic sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>D&amp;apos;souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Jaradeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ewerth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2192" to="2203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<title level="m">WordNet: An Electronic Lexical Database. Language, Speech, and Communication</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the discoursive structure of computer graphics research papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ronzano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="42" to="51" />
		</imprint>
	</monogr>
	<note>LAW@NAACL-HLT</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2018 task 7: Semantic relation extraction and classification in scientific papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gábor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qasemizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zargayouna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Charnois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval@NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="679" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Spanbert: Improving pretraining by representing and predicting spans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BERT for coreference resolution: Baselines and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5802" to="5807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The genia event and protein coreference tasks of the bionlp shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yonezawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Inter-annotator Agreement in Coreference Annotation of Polish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kopec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ogrodniczuk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="149" to="158" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/978-3-319-05503-9_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-05503-915" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Elsevier oa stm corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Labs</surname></persName>
		</author>
		<ptr target="https://github.com/elsevierlabs/OA-STM-Corpus" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP. pp</title>
		<imprint>
			<biblScope unit="page" from="188" to="197" />
			<date type="published" when="2017" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Higher-order coreference resolution with coarse-to-fine inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="687" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP. pp</title>
		<imprint>
			<biblScope unit="page" from="3219" to="3232" />
			<date type="published" when="2018" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ontology population: Approaches and design aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lubani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A M</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahmud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT/EMNLP</title>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Jointly optimized neural coreference resolution with mutual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ACM</publisher>
			<biblScope unit="page" from="402" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A mention-ranking model for abstract anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marasovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="221" to="232" />
			<date type="published" when="2017" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mikheev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moens</surname></persName>
		</author>
		<title level="m">The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>Seventh message understanding conference</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Machine learning for entity coreference resolution: A retrospective look at two decades of research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI Press</publisher>
			<biblScope unit="page" from="4877" to="4884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>COLING</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving protein coreference resolution by simple semantic classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">304</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Deep contextualized word representations. In: NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scoring coreference partitions of predicted mentions: A reference implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Association for Computer Linguistics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="30" to="35" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Towards robust linguistic analysis using ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL Shared Task</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Mining knowledge graphs from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ACM</publisher>
			<biblScope unit="page" from="789" to="790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The ACL RD-TEC: A dataset for benchmarking terminology extraction and classification in computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Handschuh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<idno type="DOI">10.3115/v1/W14-4807</idno>
		<ptr target="https://www.aclweb.org/anthology/W14-4807" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Computational Terminology (Computerm). pp. 52-63. Association for Computational Linguistics and Dublin City University</title>
		<meeting>the 4th International Workshop on Computational Terminology (Computerm). pp. 52-63. Association for Computational Linguistics and Dublin City University<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Supervised models for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ur Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP. pp</title>
		<imprint>
			<biblScope unit="page" from="968" to="977" />
			<date type="published" when="2009" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Neural Transfer Learning for Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>Galway</pubPlace>
		</imprint>
		<respStmt>
			<orgName>National University of Ireland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">A hierarchical multi-task approach for learning embeddings from semantic tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI Press</publisher>
			<biblScope unit="page" from="6949" to="6956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A fully coreference-annotated corpus of scholarly papers from the ACL anthology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Spurk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steffen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING (Posters)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1059" to="1070" />
		</imprint>
		<respStmt>
			<orgName>Indian Institute of Technology Bombay</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A machine learning approach to coreference resolution of noun phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Soon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="521" to="544" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">brat: a web-based tool for nlp-assisted text annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Topic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Towards discipline-independent argumentative zoning: Evidence from chemistry and computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Batchelor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1493" to="1502" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;09</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A model-theoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Aberdeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Connolly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hirschman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>ACL</publisher>
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Entity, relation, and event extraction with contextualized span representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Wennberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5783" to="5788" />
		</imprint>
	</monogr>
	<note>EMNLP/IJCNLP (1)</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Machine knowledge: Creation and curation of comprehensive knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Razniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<idno>abs/2009.11564</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
