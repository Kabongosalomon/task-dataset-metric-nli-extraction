<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Progressive Augmentation of GANs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Zhang</surname></persName>
							<email>dan.zhang2@bosch.com</email>
							<affiliation key="aff0">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Khoreva</surname></persName>
							<email>anna.khoreva@bosch.com</email>
							<affiliation key="aff1">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Progressive Augmentation of GANs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Training of Generative Adversarial Networks (GANs) is notoriously fragile, requiring to maintain a careful balance between the generator and the discriminator in order to perform well. To mitigate this issue we introduce a new regularization technique -progressive augmentation of GANs (PA-GAN). The key idea is to gradually increase the task difficulty of the discriminator by progressively augmenting its input or feature space, thus enabling continuous learning of the generator. We show that the proposed progressive augmentation preserves the original GAN objective, does not compromise the discriminator's optimality and encourages a healthy competition between the generator and discriminator, leading to the better-performing generator. We experimentally demonstrate the effectiveness of PA-GAN across different architectures and on multiple benchmarks for the image synthesis task, on average achieving ∼ 3 point improvement of the FID score.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Generative Adversarial Networks (GANs) <ref type="bibr" target="#b11">[12]</ref> are a recent development in the field of deep learning, that have attracted a lot of attention in the research community <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16]</ref>. The GAN framework can be formulated as a competing game between the generator and the discriminator. Since both the generator and the discriminator are typically parameterized as deep convolutional neural networks with millions of parameters, optimization is notoriously difficult in practice <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>The difficulty lies in maintaining a healthy competition between the generator and discriminator. A commonly occurring problem arises when the discriminator overshoots, leading to escalated gradients and oscillatory GAN behaviour <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b3">4]</ref>. Moreover, the supports of the data and model distributions typically lie on low dimensional manifolds and are often disjoint <ref type="bibr" target="#b0">[1]</ref>. Consequently, there exists a nearly trivial discriminator that can perfectly distinguish real data samples from synthetic ones. Once such a discriminator is produced, its loss quickly converges to zero and the gradients used for updating parameters of the generator become useless. For improving the training stability of GANs regularization techniques <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b12">13]</ref> can be used to constrain the learning of the discriminator. But as shown in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19]</ref> they also impair the generator and lead to the performance degradation.</p><p>In this work we introduce a new regularization technique to alleviate this problem -progressive augmentation of GANs (PA-GAN) -that helps to control the behaviour of the discriminator and thus improve the overall training. <ref type="bibr" target="#b0">1</ref> The key idea is to progressively augment the input of the discriminator network or its intermediate feature layers with auxiliary random bits in order to gradually increase the discrimination task difficulty (see <ref type="figure" target="#fig_1">Fig. 1</ref>). In doing so, the discriminator can be prevented from becoming over-confident, enabling continuous learning of the generator. As opposed to standard augmentation techniques (e.g. rotation, cropping, resizing), the proposed progressive augmentation does not directly modify the data samples or their features, but rather structurally appends to them. Moreover, it can also alter the input class. For instance, in the single-level augmentation the data sample or its features x are combined with a random bit s and both are provided to the discriminator.  At level l = 0 (no augmentation) the discriminator D aims at classifying the samples x d and x g , respectively drawn from the data P d and generative model P g distributions, into true (green) and fake (blue). At single-level augmentation (l = 1) the class of the augmented sample is set based on the combination x d and x g with s, resulting in real and synthetic samples contained in both classes and leading to a harder task for D. With each extra augmentation level (l → l + 1) the decision boundary between two classes becomes more complex and the discrimination task difficulty gradually increases. This prevents the discriminator from easily solving the task and thus leads to meaningful gradients for the generator updates.</p><p>The class of the augmented sample (x, s) is then set based on the combination x with s, resulting in real and synthetic samples contained in both classes, see <ref type="figure" target="#fig_1">Fig. 1-(a)</ref>. This presents a more challenging task for the discriminator, as it needs to tell the real and synthetic samples apart plus additionally learn how to separate (x, s) back into x and s and understand the association rule. We can further increase the task difficulty of the discriminator by progressively augmenting its input or feature space, gradually increasing the number of random bits during the course of training as depicted in <ref type="figure" target="#fig_1">Fig. 1-(b)</ref>.</p><p>We prove that PA-GAN preserves the original GAN objective and, in contrast to prior work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b30">31]</ref>, does not bias the optimality of the discriminator (see Sec. 3.1). Aiming at minimum changes we further propose an integration of PA-GAN into existing GAN architectures (see Sec. <ref type="bibr" target="#b2">3</ref>.2) and experimentally showcase its benefits (see Sec. 4.1). Structurally augmenting the input or its features and mapping them to higher dimensions not only challenges the discrimination task, but, in addition, with each realization of the random bits alters the loss function landscape, potentially providing a different path for the generator to approach the data distribution.</p><p>Our technique is orthogonal to existing work, it can be successfully employed with other regularization strategies <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b5">6]</ref> and different network architectures <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37]</ref>, which we demonstrate in Sec. 4.2. We experimentally show the effectiveness of PA-GAN for unsupervised image generation tasks on multiple benchmarks (Fashion-MNIST <ref type="bibr" target="#b35">[36]</ref>, CIFAR10 <ref type="bibr" target="#b17">[18]</ref>, CELEBA-HQ <ref type="bibr" target="#b15">[16]</ref>, and Tiny-ImageNet <ref type="bibr" target="#b6">[7]</ref>), on average improving the FID score around 3 points. For PA combination with SS-GAN <ref type="bibr" target="#b5">[6]</ref> we achieve the best FID of 14.7 for the unsupervised setting on CIFAR10, which is on par with the results achieved by large scale BigGAN training <ref type="bibr" target="#b3">[4]</ref> using label supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Many recent works have focused on improving the stability of GAN training and the overall visual quality of generated samples <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b3">4]</ref>. The unstable behaviour of GANs is partly attributed to a dimensional mismatch or non-overlapping support between the real data and the generative model distributions <ref type="bibr" target="#b0">[1]</ref>, resulting in an almost trivial task for the discriminator. Once the performance of the discriminator is maxed out, it provides a non-informative signal to train the generator. To avoid vanishing gradients, the original GAN paper <ref type="bibr" target="#b11">[12]</ref> proposed to modify the min-max based GAN objective to a non-saturating loss. However, even with such a re-formulation the generator updates tend to get worse over the course of training and optimization becomes massively unstable <ref type="bibr" target="#b0">[1]</ref>.</p><p>Prior approaches tried to mitigate this issue by using heuristics to weaken the discriminator, e.g. decreasing its learning rate, adding label noise or directly modifying the data samples. <ref type="bibr" target="#b30">[31]</ref> proposed a one-sided label smoothing to smoothen the classification boundary of the discriminator, thereby preventing it from being overly confident, but at the same time biasing its optimality. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b31">32]</ref> tried to ensure a joint support of the data and model distributions to make the job of the discriminator harder by adding Gaussian noise to both generated and real samples. However, adding high-dimensional noise introduces significant variance in the parameter estimation, slowing down the training and requiring multiple samples for counteraction <ref type="bibr" target="#b28">[29]</ref>. Similarly, <ref type="bibr" target="#b29">[30]</ref> proposed to blur the input samples and gradually remove the blurring effect during the course of training. These techniques perform direct modifications on the data samples.</p><p>Alternatively, several works focused on regularizing the discriminator. <ref type="bibr" target="#b12">[13]</ref> proposed to add a soft penalty on the gradient norm which ensures a 1-Lipschitz discriminator. Similarly, <ref type="bibr" target="#b28">[29]</ref> added a zero-centered penalty on the weighted gradient-norm of the discriminator, showing its equivalence to adding input noise. On the downside, regularizing the discriminator with the gradient penalty depends on the model distribution, which changes during training, and results in increased runtime due to additional gradient norm computation <ref type="bibr" target="#b18">[19]</ref>. Most recently, <ref type="bibr" target="#b3">[4]</ref> also experimentally showed that the gradient penalty may lead to the performance degradation, which corresponds to our observations as well (see Sec. 4.2) In addition to the gradient penalty, <ref type="bibr" target="#b3">[4]</ref> also exploited the dropout regularization <ref type="bibr" target="#b32">[33]</ref> on the final layer of the discriminator and reported its similar stabilizing effect. <ref type="bibr" target="#b24">[25]</ref> proposed another way to stabilize the discriminator by normalizing its weights and limiting the spectral norm of each layer to constrain the Lipschitz constant. This normalization technique does not require intensive tuning of hyper-parameters and is computationally light. Moreover, <ref type="bibr" target="#b36">[37]</ref> showed that spectral normalization is also beneficial for the generator, preventing the escalation of parameter magnitudes and avoiding unusual gradients.</p><p>Several methods have proposed to modify the GAN training methodology in order to further improve stability, e.g. by considering multiple discriminators <ref type="bibr" target="#b8">[9]</ref>, growing both the generator and discriminator networks progressively <ref type="bibr" target="#b15">[16]</ref> or exploiting different learning rates for the discriminator and generator <ref type="bibr" target="#b13">[14]</ref>. Another line of work resorts to objective function reformulation, e.g. by using the Pearson χ 2 divergence <ref type="bibr" target="#b22">[23]</ref>, the Wasserstein distance <ref type="bibr" target="#b1">[2]</ref>, or f-divergence <ref type="bibr" target="#b25">[26]</ref>.</p><p>In this work we introduce a novel and orthogonal way of regularizing GANs by progressively increasing the discriminator task difficulty. In contrast to other techniques, our method does not bias the optimality of the discriminator or alter the training samples. Furthermore, the proposed augmentation is complementary to prior work. It can be employed with different GAN architectures and combined with other regularization techniques (see Sec. 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Progressive Augmentation of GANs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Theoretical Framework of PA-GAN</head><p>The core idea behind the GAN training <ref type="bibr" target="#b11">[12]</ref> is to set up a competing game between two players, commonly termed discriminator and generator. The discriminator aims at distinguishing the samples x ∈ X respectively drawn from the data distribution P d and generative model distribution P g , i.e. performing binary classification D : X → [0, 1]. <ref type="bibr" target="#b1">2</ref> The aim of the generator, on the other hand, is to make synthetic samples into data samples, challenging the discriminator. In this work, X represents a compact metric space such as the image space [−1, 1] N of dimension N . Both P d and P g are defined on X . The model distribution P g is induced by a function G that maps a random vector z ∼ P z to a synthetic data sample, i.e. x g = G(z) ∈ X . Mathematically, the two-player game is formulated as</p><formula xml:id="formula_0">min G max D E P d {log [D(x)]} + E Pg {log [1 − D(x)]} .<label>(1)</label></formula><p>As being proved by <ref type="bibr" target="#b11">[12]</ref>, the inner maximum equals the Jensen-Shannon (JS) divergence between P d and P g , i.e., D JS (P d P g ). Therefore, the GAN training attempts to minimize the JS divergence between the model and data distributions.  </p><formula xml:id="formula_1">∆ = P d (x)δ[s] + P g (x)δ[s − 1] 2 , Q x,s (x, s) ∆ = P g (x)δ[s] + P d (x)δ[s − 1] 2 . (2)</formula><p>Their JS divergence is equal to  <ref type="figure">Figure 2</ref>: PA-GAN overview. With each level of progressive augmentation l the dimensionality of s is enlarged from 1 to L, s = {s 1 , s 2 , . . . , s L }. The task difficulty of the discriminator gradually increases as the length of s grows.</p><formula xml:id="formula_2">D JS (P x,s Q x,s ) = D JS (P d P g ) .<label>(3)</label></formula><p>Taking <ref type="formula">(2)</ref> as the starting point and with s l being a sequence of i.i.d. random bits of length l, the recursion of constructing the paired joint distributions of (x, s l )</p><formula xml:id="formula_3">P x,s l (x, s l ) ∆ = P x,s l−1 (x, s l−1 )δ[s l ]/2 + Q x,s l−1 (x, s l−1 )δ[s l − 1]/2 Q x,s l (x, s l ) ∆ = Q x,s l−1 (x, s l−1 )δ[s l ]/2 + P x,s l−1 (x, s l−1 )δ[s l − 1]/2 (4)</formula><p>results into a series of JS divergence equalities for l = 1, 2, . . . , L, i.e.,</p><formula xml:id="formula_4">D JS (P d P g ) = D JS (P x,s1 Q x,s1 ) = · · · = D JS (P x,s L Q x,s L ) .<label>(5)</label></formula><p>Theorem 1. The min-max optimization problem of GANs <ref type="bibr" target="#b11">[12]</ref> as given in <ref type="formula" target="#formula_0">(1)</ref> is equivalent to</p><formula xml:id="formula_5">min G max D E Px,s l {log [D(x, s l )]} + E Qx,s l {log [1 − D(x, s l )]} ∀l ∈ {1, 2, . . . , L},<label>(6)</label></formula><p>where the two joint distributions, i.e., P x,s l and Q x,s l , are defined in (4) and the function D maps</p><formula xml:id="formula_6">(x, s l ) ∈ X × {0, 1} l onto [0, 1]. For a fixed G, the optimal D is D * (x, s l ) = P x,s l (x, s l ) P x,s l (x, s l ) + Q x,s l (x, s l ) = P d (x) P d (x) + Q d (x) ,<label>(7)</label></formula><p>whereas the attained inner maximum equals D JS (P x,s l Q x,s l ) = D JS (P d P g ) for l = 1, 2, . . . , L.</p><p>According to Theorem 1, solving (1) is interchangeable with solving (6). In fact, the former can be regarded as a corner case of the latter by taking l = 0 as the absence of the auxiliary bit vector s. As the length l of s increases, the input dimension of the discriminator grows accordingly. Furthermore, two classes to be classified consist of both the data and synthetic samples as illustrated in <ref type="figure" target="#fig_1">Fig. 1</ref>-(a). Note that, the mixture strategy of the distributions of two independent random variables in Lemma 1 can be extended for any generic random variables (see Sec. S2.4 in the supp. material).</p><p>When solving (1), G and D are parameterized as deep neural networks and SGD (or its variants) is typically used for the optimization, updating their weights in an alternating or simultaneous manner, with no guarantees on global convergence. Theorem 1 provides a series of JS divergence estimation proxies by means of the auxiliary bit vector s that in practice can be exploited as a regularizer to improve the GAN training (see Sec. 4.1 for empirical evaluation). First, the number of possible combinations of the data samples with s l grows exponentially with l, thus helping to prevent the discriminator from overfitting to the training set. Second, the task of the discriminator gradually becomes harder with the length l. The input dimensionality of D becomes larger and as the label of (x, s l−1 ) is altered based on the new random bit s l the decision boundary becomes more complicated ( <ref type="figure" target="#fig_1">Fig. 1-b</ref>). Given that, progressively increasing l can be exploited during training to balance the game between the discriminator and generator whenever the former becomes too strong. Third, when the GAN training performance saturates at the current augmentation level, adding one random bit changes the landscape of the loss function and may further boost the learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation of PA-GAN</head><p>The min-max problem in (6) shares the same structure as the original one in (1), thus we can exploit the standard GAN training for PA-GAN, see <ref type="figure">Fig. 2</ref>. The necessary change only concerns the discriminator. It involves 1) using checksum principle as a new classification criterion, 2) incorporating s in addition to x as the network input and 3) enabling the progression of s during training.</p><p>Checksum principle. The conventional GAN discriminator assigns TRUE (0) / FAKE (1) class label based on x being either data or synthetic samples. In contrast, the discriminator D in <ref type="bibr" target="#b5">(6)</ref> requires s l along with x to make the decision about the class label. Starting from l = 1, the two class distributions in (2) imply the label-0 for (x d , s = 0), (x g , s = 1) and label-1 for (x d , s = 1), (x g , s = 0). The real samples are no longer always in the TRUE class, and the synthetic samples are no longer always in the FAKE class, see <ref type="figure" target="#fig_1">Fig. 1</ref>-(a). To detect the correct class we can use a simple checksum principle. Namely, let the data and synthetic samples respectively encode bit 0 and 1 followed by associating the checksum 0(1) of the pair (x, s) with TRUE(FAKE). <ref type="bibr" target="#b2">3</ref> For more than one bit, P x,s l and Q x,s l are recursively constructed according to <ref type="bibr" target="#b3">(4)</ref>. Based on the checksum principle for the single bit case, we can recursively show its consistency for any bit sequence length s l , l &gt; 1. This is a desirable property for progression. With the identified checksum principle, we further discuss a way to integrate a sequence of random bits s l into the discriminator network in a progressive manner.</p><p>Progressive augmentation. With the aim of maximally reusing existing GAN architectures we propose two augmentation options. The first one is input space augmentation, where s is directly concatenated with the sample x and both are fed as input to the discriminator network. The second option is feature space augmentation, where s is concatenated with the learned feature representations of x attained at intermediate hidden layers. For both cases, the way to concatenate s with x or its feature maps is identical. Each entry s l creates one augmentation channel, which is replicated to match the spatial dimension of x or its feature maps. Depending on the augmentation space, either the input layer or the hidden layer that further processes the feature maps will additionally take care of the augmentation channels along with the original input. In both cases, the original layer configuration (kernel size, stride and padding type) remains the same except for its channel size being increased by l. All the other layers of the discriminator remain unchanged. When a new augmentation level is reached, one extra input channel of the filter is instantiated to process the bit l + 1.</p><p>These two ways of augmentation are beneficial as they make the checksum computation more challenging for the discriminator, i.e., making the discriminator unaware about the need of separating x and s from the concatenated input. We note that in order to take full advantage of the regularization effect of progressive augmentation, s needs to be involved in the decision making process of the discriminator either through input or feature space augmentation. Augmenting s with the output D(x) makes the task trivial, thereby disabling the regularization effect of the progressive augmentation.</p><p>In this work we only exploit s by concatenating it with either the input or the hidden layers of the network. However, it is also possible to combine it with other image augmentation strategies, e.g. using s as an indicator for the rotation angle, as in <ref type="bibr" target="#b5">[6]</ref>, or the type of color augmentation that is imposed on the input x and encouraging D to learn the type through the checksum principle.</p><p>Progression scheduling. To schedule the progression we rely on the kernel inception distance (KID) introduced by <ref type="bibr" target="#b2">[3]</ref> to decide if the performance of G at the current augmentation level saturates or even starts degrading (typically happens when D starts overfitting or becomes too powerful). Specifically, after t discriminator iterations, we evaluate KID between synthetic samples and data samples drawn from the training set. If the current KID score is less than 5% of the average of the two previous evaluations attained at the same augmentation level, the augmentation is leveled up, i.e. l → l + 1. To validate the effectiveness of this scheduling mechanism we exploit it for the learning rate adaptation as in <ref type="bibr" target="#b2">[3]</ref> and compare it with progressive augmentation in the next section. Sec. S7. All measures are computed based on the same number of the test data samples and synthetic samples, following the evaluation framework of <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19]</ref>. By default all reported numbers correspond to the median of five independent runs with 300k, 500k, 400k and 500k training iterations for Fashion-MNIST, CIFAR10, CELEBA-HQ, and Tiny-ImageNet, respectively.</p><p>Training details: We use uniformly distributed noise vector z ∈ [−1, 1] 128 , the mini-batch size of 64, and Adam optimizer <ref type="bibr" target="#b16">[17]</ref>. The two time-scale update rule (TTUR) <ref type="bibr" target="#b13">[14]</ref> is considered when choosing the learning rates for D and G. For progression scheduling KID 4 is evaluated using samples from the training set every t = 10k iterations, except for Tiny-ImageNet with t = 20k given its approximately 2× larger training set. More details are provided in Sec. S8. <ref type="table" target="#tab_2">Table 1</ref> gives an overview of the FID performance achieved with and without applying the proposed progressive augmentation (PA) across different datasets and networks. We observe consistent improvement of the FID score achieved by PA with both the input PA (input) and feature PA (feat) space augmentation (see Sec. S4.1 for augmentation details and ablation study on the augmentation space). From SN DCGAN to the ResNet-based SA GAN the FID reduction preserves approximately around 3 points, showing that the gain achieved by PA is complementary to the improvement on the architecture side. In comparison to input space augmentation, augmenting intermediate level features does not overly simplify the discriminator task, paralysing PA. In the case of SN DCGAN on CELEBA-HQ, it actually outperforms the input space augmentation. Overall, a stable performance gain of PA, independent of the augmentation space choice, showcases high generalization quality of PA and its easy adaptation into different network designs. <ref type="bibr" target="#b4">5</ref> Lower FID values achieved by PA can be attributed mostly to the improved sample diversity. By looking at generated images in <ref type="figure">Fig. 3</ref> (and <ref type="figure" target="#fig_4">Fig. S4</ref> in the supp. material), we observe that PA increases the variation of samples while maintaining the same image fidelity. This is expected as PA being a regularizer does not modify the GAN architecture, as in PG-GAN <ref type="bibr" target="#b15">[16]</ref> or BigGAN <ref type="bibr" target="#b3">[4]</ref>, to directly improve the visual quality. Specifically, <ref type="figure">Fig. 3</ref> shows synthetic images produced by SN DCGAN and SA GAN with and without PA, on Fashion-MNIST and CELEBA-HQ. By polar interpolation between two samples z 1 and z 2 , from left to right we observe the clothes/gender change. PA improves sample variation, maintaining representative clothes/gender attributes and achieving smooth transition between samples (e.g. hair styles and facial expressions). For further evaluation, we also measure the diversity of generated samples with the MS-SSIM score <ref type="bibr" target="#b26">[27]</ref>. We use 10k synthetic images generated with SA GAN on CELEBA-HQ. Employing PA reduces MS-SSIM from 0.283 to 0.266, while PG-GAN <ref type="bibr" target="#b15">[16]</ref>    <ref type="figure">Figure 3</ref>: Synthetic images generated through latent space interpolation with and without using PA. PA helps to improve variation across interpolated samples, i.e., no close-by images looks alike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">PA Across Different Architectures and Datasets</head><p>Ablation Study. In <ref type="figure" target="#fig_4">Fig. 4</ref> and <ref type="table" target="#tab_4">Table 2</ref> we present an ablation study on PA, comparing singlelevel augmentation (without progression) with progressive multi-level PA, showing the benefit of progression. From no augmentation to the first level augmentation, the required number of iterations varies over the datasets and architectures (30k∼ 70k). Generally the number of reached augmentation levels is less than 15. <ref type="figure" target="#fig_4">Fig. 4</ref> also shows that single-level augmentation already improves the performance over the baseline SN DCGAN. However, the standard deviation of its FIDs across five independent runs starts increasing at later iterations. By means of progression, we can counteract this instability, while reaching a better FID result. <ref type="table" target="#tab_4">Table 2</ref> further compares augmentation at different levels with and without continuing with progression. Both augmentation and progression are beneficial, while progression alleviates the need of case dependent tuning of the augmentation level.</p><p>As a generic mechanism to monitor the GAN training, progression scheduling is usable not only for augmentation level-up, but also for other hyperparameter adaptations over iterations. Analogous to <ref type="bibr" target="#b2">[3]</ref> here we test it for the learning rate adaptation. From <ref type="figure" target="#fig_4">Fig. 4</ref>, progression scheduling shows its effectiveness in assisting both the learning rate adaptation and PA for an improved FID performance. PA outperforms learning rate adaptation, i.e. median FID 22.2 vs. 24.0 across five independent runs. Regularization Effect of PA. <ref type="figure" target="#fig_6">Fig. 5</ref> depicts the discriminator loss (D loss) and the generator loss (G loss) behaviour as well as the FID curves over iterations. It shows that the discriminator of SN DCGAN very quickly becomes over-confident, providing a non-informative backpropagation signal to train the generator and thus leading to the increase of the G loss. PA has a long lasting regularization effect on SN DCGAN by means of progression and helps to maintain a healthy competition between its discriminator and generator. Each rise of the D loss and drop of the G loss coincides with an iteration at which the augmentation level increases, and then gradually reduces after the discriminator timely adapts to the new bit. Observing the behaviour of the D and G losses, we conclude that both PA (input) and PA (feat) can effectively prevent the SN DCGAN discriminator from overfitting, alleviating the vanishing gradient issue and thus enabling continuous learning of the generator. At the level one augmentation, both PA (feat) and PA (input) start from the similar overfitting stage, i.e., (a) and (b) respectively at the iteration 60k and 70k. Combining the bit s directly with high-level features eases the checksum computation. As a result, the D loss of PA (feat N/8 ) reduces faster, but making its future task more difficult due to overfitting to the previous augmentation level. On the other hand, PA (input) let the bits pass through all layers, and thus its adaptation to augmentation  Iterations D Loss  progression improves over iterations. In the end, both PA (feat) and PA (input) lead to similar regularization effect and result in the improved FID scores.</p><formula xml:id="formula_7">SN DCGAN -Reinit. -Dropout(feat) -PA (input) -PA (feat) 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5</formula><p>In <ref type="figure" target="#fig_6">Fig. 5</ref> we also evaluate the Dropout <ref type="bibr" target="#b32">[33]</ref> regularization applied on the fourth convolutional layer with the keep rate 0.7 (the best performing setting in our experiments). Both Dropout and PA resort to random variables for regularization. The former randomly removes features, while the latter augments them with additional random bits and adjusts accordingly the class label. In contrast to Dropout, PA has a stronger regularization effect and leads to faster convergence (more rapid reduction of FID scores). In addition, we compare PA with the Reinit. baseline, where at each scheduled progression all weights are reinitialized with Xavier initialization <ref type="bibr" target="#b10">[11]</ref>. Compared to PA, using Reinit. strategy leads to longer adaptation time (the D loss decay is much slower) and oscillatory GAN behaviour, thus resulting in dramatic fluctuations of FID scores over iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison and Combination with Other Regularizers</head><p>We further compare and combine PA with other regularization techniques, i.e., one-sided label smoothing <ref type="bibr" target="#b30">[31]</ref>, GP from <ref type="bibr" target="#b12">[13]</ref>, its zero-centered alternative GP zero-cent from <ref type="bibr" target="#b28">[29]</ref>, Dropout <ref type="bibr" target="#b32">[33]</ref>, and self-supervised GAN training via auxiliary rotation loss (SS) <ref type="bibr" target="#b5">[6]</ref>.</p><p>One-sided label smoothing (Label smooth.) weakens the discriminator by smoothing its decision boundary, i.e., changing the positive labels from one to a smaller value. This is analogous to introducing label noise for the data samples, whereas PA alters the target labels based on the deterministic checksum principle. Both GP and GP zero-cent regularize the norms of gradients to stabilize the GAN training. The former aims at a 1-Lipschitz discriminator, and the latter is a closed-form approximation of adding input noise. <ref type="table" target="#tab_6">Table 3</ref> shows that both of them are compatible with PA but degrade the performance of SN DCGAN alone and its combination with PA. This effect has been also observed in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b3">4]</ref>, constraining the learning of the discriminator improves the GAN training stability but at the cost of performance degradation. Note that, however, with PA performance degradation is smaller.</p><p>Dropout shares a common stochastic nature with PA as illustrated in <ref type="figure" target="#fig_6">Fig. 5</ref> and in the supp. material. We observe from <ref type="table" target="#tab_6">Table 3</ref> that Dropout and PA can be both exploited as effective regularizers.</p><p>Dropout acts locally on the layer. The layer outputs are randomly and independently subsampled, thinning the network. In contrast, PA augments the input or the layer with extra channels containing random bits, these bits also change the class label of the input and thus alter the network decision process. Dropout helps to break-up situations where the layer co-adapts to correct errors from prior layers and enables the network to timely re-learn features of constantly changing synthetic samples. PA regularizes the decision process of D, forcing D to comprehend the input together with the random bits for correct classification and has stronger regularization effect than Dropout, see <ref type="figure" target="#fig_6">Fig. 5</ref> and the supp. material. Hence, they have different roles. Their combination further improves FID by ∼ 0.8 point on average, showing the complementarity of both approaches. It is worth noting that Dropout is sensitive to the selection of the layer at which it is applied. In our experiments (see the supp. material) it performs best when applied at the fourth convolutional layer.</p><p>Self-supervised training (SS-GAN) in <ref type="bibr" target="#b5">[6]</ref> regularizes the discriminator by encouraging it to solve an auxiliary image rotation prediction task. From the perspective of self-supervision, PA presents the discriminator a checksum computation task, whereas telling apart the data and synthetic samples becomes a sub-task. Rotation prediction task was initially proposed and found useful in <ref type="bibr" target="#b9">[10]</ref> to improve feature learning of convolutional networks. The checksum principle is derived from Theorem 2. Their combination is beneficial and achieves the best FID of 14.7 for the unsupervised setting on CIFAR10, which is the same score as in the supervised case with large scale BigGAN training <ref type="bibr" target="#b3">[4]</ref>.</p><p>Overall, we observe that PA is consistently beneficial when combining with other regularization techniques, independent of input or feature space augmentation. Additional improvement of the FID score can come along with fine selection of the augmentation space type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work we have proposed progressive augmentation (PA) -a novel regularization method for GANs. Different to standard data augmentation our approach does not modify the training samples, instead it progressively augments them or their feature maps with auxiliary random bits and casts the discrimination task into the checksum computation. PA helps to entangle the discriminator and thus to avoid its early performance saturation. We experimentally have shown consistent performance improvements of employing PA-GAN across multiple benchmarks and demonstrated that PA generalizes well across different network architectures and is complementary to other regularization techniques. Apart from generative modelling, as a future work we are interested in exploiting PA for semi-supervised learning, generative latent modelling and transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Materials: Progressive Augmentation of GANs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1 Content</head><p>This document completes the presentation of PA-GAN in the main paper with the following:</p><p>• Theoretical proofs for Lemma 1 and Theorem 1 in Sec. S2;</p><p>• Implementation details of PA-GAN in Sec. S3;</p><p>• Additional ablation studies in Sec. S4;</p><p>• Analysis of PA effectiveness as regularizer on the toy example in Sec. S5;</p><p>• Exemplar synthetic images in Sec. S6;</p><p>• Results for the IS <ref type="bibr" target="#b33">[34]</ref> and KID <ref type="bibr" target="#b2">[3]</ref> metrics in Sec. S7;</p><p>• Network architectures and hyperparameter settings in Sec. S8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2 Theoretical Framework of PA-GAN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2.1 Information Theory Viewpoint on the JS Divergence</head><p>Apart from quantifying distributions' similarity, the JS divergence has an information theory interpretation that inspires our approach. In accordance with the binary classification task of the discriminator, we introduce a binary random variable s with a uniform distribution P s . Associating s = 0 and s = 1 respectively with x ∼ P d and x ∼ P g , we obtain a joint distribution function</p><formula xml:id="formula_8">P x,s (x, s) ∆ = P d (x)δ[s] + P g (x)δ[s − 1] 2 ,<label>(S1)</label></formula><p>where δ[·] stands for the Kronecker delta function. The marginal distribution of P x,s with respect to x (a.k.a. the mixture distribution) is equal to</p><formula xml:id="formula_9">P m ∆ = P s (s = 0)P d + P s (s = 1)P g = P d + P g 2 .<label>(S2)</label></formula><p>Computing the mutual information of the two random variables s and x based on P x,s is identical to computing the JS divergence between P d and P g , i.e.,</p><formula xml:id="formula_10">I(x; s) = E Pm [p d (x) log p d (x)] + E Pm [p g (x) log p g (x)] 2 = D JS (P d P g ) ,<label>(S3)</label></formula><p>where p d (x) and p g (x) are density functions of P d and P g with respect to P m . <ref type="bibr" target="#b5">6</ref> The minimum of the JS divergence D JS (P d P g ) equal to zero is attainable iff P d = P g , while zero mutual information indicates the independence between x and s, yielding P x,s (x, s) = P m (x)P s (s).</p><p>Exploiting the equality presented in (S3), we proceed with proving Lemma 1, i.e., a series of JS divergence equalities. (S4) <ref type="bibr" target="#b5">6</ref> Both P d and Pg are absolutely continuous with respect to Pm. Therefore, their densities exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1</head><p>Their JS divergence is equal to</p><formula xml:id="formula_11">D JS (P x,s Q x,s ) = D JS (P d P g ) .</formula><p>(S5) Taking (S4) as the starting point and with s l being a sequence of i.i.d. random bits of length l, the recursion of constructing the paired joint distributions of (x, s l )</p><formula xml:id="formula_12">P x,s l (x, s l ) ∆ = P x,s l−1 (x, s l−1 )δ[s l ]/2 + Q x,s l−1 (x, s l−1 )δ[s l − 1]/2 Q x,s l (x, s l ) ∆ = Q x,s l−1 (x, s l−1 )δ[s l ]/2 + P x,s l−1 (x, s l−1 )δ[s l − 1]/2 (S6)</formula><p>results into a series of JS divergence equalities for l = 1, 2, . . . , L, i.e.,</p><formula xml:id="formula_13">D JS (P d P g ) = D JS (P x,s1 Q x,s1 ) = · · · = D JS (P x,s L Q x,s L ) .<label>(S7)</label></formula><p>Proof. Starting from the single bit s, the two joint distributions P x,s and Q x,s differ from each other by their opposite way of associating the bit s ∈ {0, 1} with the data and synthetic samples. Their marginals with respect to x are identical and equal the mixture distribution P m , being neither the data nor the model distribution, in contrast to the framework of <ref type="bibr" target="#b7">[8]</ref>.</p><p>The joint distribution P x,s has yielded the mutual information I(x; s) with the equality in (S3). By analogy, we compute the mutual informationĨ(x; s) between x and s which follow Q x,s with the equality:Ĩ</p><formula xml:id="formula_14">(x; s) = D JS (P d P g ) .<label>(S8)</label></formula><p>The combination of (S3) and (S8) leads to</p><formula xml:id="formula_15">D JS (P d P g ) = I(x; s) +Ĩ(x; s) 2 .<label>(S9)</label></formula><p>Rewriting mutual information as KL divergence yields:</p><formula xml:id="formula_16">D JS (P d P g ) = D KL (P x,s P m P s ) + D KL (Q x,s P m P s ) 2 ,<label>(S10)</label></formula><p>where P m and P s are the common marginals of P x,s and Q x,s with respect to x and s. By further identifying P m (x)P s (s) = P x,s (x, s) + Q x,s (x, s) 2 (S11) and plugging it into (S10), we finally reach to D JS (P d P g ) = D JS (P x,s Q x,s ) (S12) by the definition of JS divergence.</p><p>It is worth noting that the equivalence holds even if the feasible solution set of P g determined by G does not include the data distribution P d . This is of practical interest as it is often difficult to guarantee the fulfillment of such premise when modeling G by means of neural networks.</p><p>Replacing the data and model distributions P d and P g respectively with P x,s and Q x,s , we can systematically add a new bit with the same derivation as above. Repeating this procedure L times eventually yields the recursively constructed {P x,s l , Q x,s l } l=1,...,L followed by a sequence of JS divergence equalities </p><formula xml:id="formula_17">D JS (P d P g ) = · · · = D JS P x,s l−1 Q x,s l−1 = · · · = D JS (P x,s L Q x,s L ) .<label>(S13</label></formula><formula xml:id="formula_18">G max D E Px,s l {log [D(x, s l )]} + E Qx,s l {log [1 − D(x, s l )]} ∀l ∈ {1, 2, . . . , L},<label>(S14)</label></formula><p>where the two joint distributions, i.e., P x,s l and Q x,s l , are defined in (S6) and the function D maps (x, s l ) ∈ X × {0, 1} l onto [0, 1]. For a fixed G, the optimal D is</p><formula xml:id="formula_19">D * (x, s l ) = P x,s l (x, s l ) P x,s l (x, s l ) + Q x,s l (x, s l ) = P d (x) P d (x) + Q d (x) ,<label>(S15)</label></formula><p>whereas the attained inner maximum equals D JS (P x,s l Q x,s l ) = D JS (P d P g ) for l = 1, 2, . . . , L.</p><p>Proof. Analogous to the proofs for GANs <ref type="bibr" target="#b11">[12,</ref><ref type="bibr">Sec.4]</ref>, we can construct a binary classification task for computing JS divergences, i.e.,</p><formula xml:id="formula_20">D JS (P x,s l Q x,s l ) = max D E Px,s l {log [D(x, s l )]} + E Qx,s l {log [1 − D(x, s l )]} ∀l,<label>(S16)</label></formula><p>where the optimal D * equals</p><formula xml:id="formula_21">D * (x, s l ) = P x,s l (x, s l ) P x,s l (x, s l ) + Q x,s l (x, s l ) (a) = P d (x) P d (x) + Q d (x)</formula><p>.</p><p>(S17)</p><p>The equality (a) in above is based on the recursive construction of P x,s l and Q x,s l from P d and P g .</p><p>The equalities in (S5) imply that for any given pair (P d , P g ) the correspondingly constructed joint distribution pair (P x,s l , Q x,s l ) yields the same JS divergence. For this reason, we can use the two JS divergences interchangeably as the objective function while optimizing P g , yielding</p><formula xml:id="formula_22">min G max D E P d {log [D(x)]} + E Pg {log [1 − D(x)]} ≡ min G max D E Px,s l {log [D(x, s l )]} + E Qx,s l {log [1 − D(x, s l )]} ∀l. (S18)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2.4 Generalization of Lemma 1</head><p>In this work, we base the development of PA on Lemma 1 and Theorem 1. From a broader perspective, the random bits s can be any generic random variables applicable for generative modelling. Proposition 1. Let s denote a random variable with two unequal distributions P s,a and P s,b . Together with the two distributions P d and P g of x, two joint distributions are constructed as follows:</p><formula xml:id="formula_23">P x,s (x, s) = P d (x)P s,a (s) + P g (x)P s,b (s) 2 Q x,s (x, s) = P d (x)P s,b (s) + P g (x)P s,a (s) 2 .</formula><p>(S19)</p><p>The </p><p>where the kernel width/height, stride and padding type used for filtering the augmentation bits are the same as that of φ(x). <ref type="bibr" target="#b6">7</ref> Depending on the augmentation space, here φ(x) collectively denotes either the input x or its feature maps. When spectral normalization is in use, the power method is applied to estimate the largest singular value of the filter matrix that processes the augmented input. In case of augmenting the input to a residual block, the augmentation bits are passed along with x or its feature maps into the first convolutional layer in the main branch as well as into the shortcut connection. We bypass the shortcut connection if it is an identity mapping.</p><p>When progression scheduling increases the augmentation level, a new set of filter coefficients are instantiated to process the new augmentation bit according to (S21). They are initialized by random Gaussian variables with the mean and variance computed from the existing filter coefficients for φ(x). Before filtering, each augmentation bit can be additionally modulated by two trainable parameters {λ l , β l }. The scaling parameter λ l is initialized with the mean value of the previous ones, where the first one, i.e., λ 1 , is initialized as one. The offset parameters {β l } are always initialized as zeros.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3.2 Mini-batch Discrimination</head><p>Each mini-batch is constructed with the same number of real data samples, synthetic samples and bit sequences. Each bit sequence is randomly sampled and associated with one real and one synthetic sample. Based on the checksums of the formed pairs, we can decide their correct class and feed it into the discriminator to compute the cross-entropy loss. This way of generating (x, s) guarantees a balanced number of TRUE/FAKE samples, forming the two mini-batches B tr and B fk .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3.3 Warm-up Phase of Progression</head><p>At the beginning of the new augmentation level the discriminator is ignorant about this disruptive change and as the bit s = 1 flips the reference label it will lead to about 50% discriminator errors in one mini-batch. Aiming at a smooth transition from the current augmentation level to the new one, here we introduce two warm-up mechanisms that are usable when the discriminator exhibits deficiency in timely coping with the new augmentation level.</p><p>The first mechanism instantiates an Adam optimizer, independent of the ones for D and G, to solely train the newly introduced weights right after progressing to the new level. It takes the D loss and can use the same learning hyperparameters as those of the D optimizer. After multiple iterations (e.g., 1k), we continue with the original alternation between the D and G optimizer, where the new weights together with the existing ones of the discriminator network are handled by the D optimizer.</p><p>According to Lemma 1, the augmentation bits shall follow a uniform distribution, i.e., P(s = 1) = p and P(s = 0) = 1 − p with p = 0.5. As the new augmentation bit taking on the value one causes discriminator errors, the second mechanism temporally adopts a non-uniform distribution when kicking off a new augmentation level. Namely, we can on purpose create more 0s than 1s by linearly increasing p from 0 and 0.5 within a given number of iterations, e.g., 5k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3.4 Loss Functions</head><p>In this work, we experimented of using PA with the following loss functions of GANs.</p><p>Non-saturating (NS) loss. The cross-entropy loss for D is given as</p><formula xml:id="formula_25">min D −E Px,s l {log D(x, s l )} − E Qx,s l {log [1 − D(x, s l )]} .<label>(S22)</label></formula><p>Since both distribution P x,s l and Q x,s l involve synthetic samples, the non-saturating (NS) loss for G <ref type="bibr" target="#b11">[12]</ref> is reformulated as </p><formula xml:id="formula_26">min G −E Qx,s l {log D(x, s l )} − E Px,s l {log [1 − D(x, s l )]} .<label>(S23</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4</head><p>Hinge loss. Instead of cross-entropy loss, D can also be trained using the hinge loss</p><formula xml:id="formula_27">min D E Px,s l {max [0, 1 − D(x, s l )]} + E Qx,s l {max [0, 1 + D(x, s l )]} . (S24)</formula><p>Accordingly, the G loss is adapted to min</p><formula xml:id="formula_28">G E Px,s l {D(x, s l )} − E Qx,s l {D(x, s l )} . (S25)</formula><p>WGAN-GP. In the main paper, we have focused on generative modeling with JS divergence. It is also possible to interchange the JS divergence with the Wasserstein distance and then cast GAN training into WGAN-GP training <ref type="bibr" target="#b1">[2]</ref>. Wasserstein distance is weaker than JS divergence and D termed critic in WGAN no longer solves the classification task. So, we alternatively exploit the stochastic model averaging role of the augmentation bits rather than their regularization role.</p><p>Briefly, with the Kantorovich-Rubinstein duality, minimizing the Wasserstein distance between P d and P g is transformed into the following two-player game min</p><formula xml:id="formula_29">G max D E Px,s l {D(x, s l )} − E Qx,s l {D(x, s l )} .<label>(S26)</label></formula><p>Ideally, D in the context of WGAN should be 1-Lipschitz continuous. As a pragmatic relaxation on this constraint, a gradient penalty (GP) <ref type="bibr" target="#b12">[13]</ref> is commonly added to the objective function when optimizing D.</p><p>Within the same mini-batch of x ∼ P d and x ∼ P g , we draw M mini-batches s ∼ P s of the same size. Combining each of them with the data and synthetic samples, we create M mini-batches for approximating the expectations in the objective function</p><formula xml:id="formula_30">E Px,s l {D(x, s l )} − E Qx,s l {D(x, s l )} ≈ L m ∆ = 1 |B tr,m | (x, s l ) ∈ B tr,m D(x, s l ) − 1 |B fk,m | (x, s l ) ∈ B fk,m D(x, s l ), m = 1, . . . , M.<label>(S27)</label></formula><p>The critic D of WGAN-GP is trained to maximize the averaged loss L m across the M mini-batches, making use of stochastic model averaging. The generator G is then trained to minimize the maximum of {L m }, m = 1, . . . , M , i.e. picking the best performing case of the critic, as a good quality of the critic D is important to the optimization process of G in the context of WGAN. With single bit augmentation of PA (feat) and two draws per minibatch, we can improve WGAN-GP of SN DCGAN on CIFAR10 from 25.0 to 23.9 FID. Here, we boost the diversity of the two draws by choosing them with opposite checksums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4 Additional Ablation Studies</head><p>In this section, we provide additional ablation studies of PA. Complementary to <ref type="table" target="#tab_2">Table 1</ref> in Sec. 4.1., an ablation study on the choice of augmentation space is conducted in Sec. S4.1, evaluating PA across input, low-and high-level feature space augmentation. One important finding in Sec. 4.2. of the main paper is that dropout and PA are complementary and mutually beneficial. In Sec. S4.2, we report our detailed investigation on the dropout regularization followed by evaluation of its combination with PA across the datasets and architectures. The two time-scale update rule (TTUR) <ref type="bibr" target="#b13">[14]</ref>, updating the discriminator and generator with different learning rates, is notoriously helpful to stabilize GAN training. In Sec. S4.3, we examine the performance of PA under different TTURs and then compare it with the adaptive learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4.1 Ablation Study on Augmentation Space</head><p>In the main paper, in <ref type="table" target="#tab_2">Table 1</ref> of Sec. 4.1. we reported the FID scores achieved by PA, by augmenting either the input -PA (input), or its features with spatial dimension N/8 -PA (feat N/8 ), where N is the input image dimension (see Sec. S8 for the detailed configuration). Here, we further perform the ablation study on the choice of the augmentation space across two datasets (CIFAR10 and CELEBA-HQ) and two architectures (SN DCGAN and SA GAN). From <ref type="table" target="#tab_2">Table S1</ref>, we observe the stable performance improvement across all configurations, inline with <ref type="table" target="#tab_2">Table 1</ref> of the main paper. The performance difference across different feature space augmentations is generally small (less than one FID point).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4.2 Ablation Study on Dropout and its Combination with PA</head><p>In Sec. 4.2. of the main paper, we have shown the effectiveness of using dropout, particularly, in combination with the proposed PA. In this part we report further ablations for both techniques.</p><p>We start from applying dropout at the input layer and different intermediate layers. Note that, in contrast to dropout, we apply PA directly on the input and not on the input layer. In addition, we experiment with different keep rates of the dropout, i.e. {0.1, 0.3, 0, 5, 0.7, 0.9, 0.95}. <ref type="table" target="#tab_4">Table S2</ref> reports the FID scores achieved with different dropout configurations. In contrast to PA (see <ref type="table" target="#tab_2">Table S1</ref> or <ref type="table" target="#tab_2">Table 1</ref> in the main paper), the performance of dropout is very dependent on the applied layer and the selected keep rate. The feature space with the spatial dimension N/4 together with the keep rate 0.7 is the best performing setting on CIFAR10 with SN DCGAN.</p><p>We further note that the binary dropout mask is independently drawn for each entry of the input or intermediate layer outputs (each convolution feature map activation is "dropped-out" independently).</p><p>In addition, we also experiment with the spatial dropout (SpatialDropout) <ref type="bibr" target="#b34">[35]</ref>, which randomly drops the entire feature maps instead of individual elements. The results in Tables S2 show that the entry-wise dropout outperforms the spatial dropout in the context of GAN training, i.e., FID 22.1 vs. 23.4. Therefore we only consider the entry-wise dropout for comparison with PA in the main paper.</p><p>In <ref type="table" target="#tab_6">Table 3</ref> of the main paper, we have successfully combined dropout at its best setting with PA on CIFAR10 with SN DCGAN and SA GAN. <ref type="table" target="#tab_6">Table S3</ref> and S4 additionally report the FID improvements where dropout is applied at different intermediate layers and keep rates. In all configurations, PA provides complementary gains. Note that, for CELEBA-HQ Dropout alone in <ref type="table" target="#tab_6">Table S3</ref> only has a marginal performance improvement over the baseline, whereas its combination with PA leads to larger performance boost. Overall, <ref type="table" target="#tab_6">Table S3</ref>, S4 plus <ref type="table" target="#tab_6">Table 3</ref> in the main paper confirms the effectiveness of exploiting both techniques. Adding PA is beneficial independent of the dropout settings (keep rate and applied layer), it helps to reduce the FID sensitivity to the dropout hyperparameter choice.    faster over iterations (see <ref type="figure" target="#fig_1">Figure S1</ref>) without requiring extra hyperparameter search for the best update rule.  <ref type="figure" target="#fig_1">Figure S1</ref> shows the effectiveness of progression scheduling in assisting both the learning rate adaptation and progressive augmentation for an improved performance. PA outperforms learning rate adaptation as well as the tuned TTUR <ref type="bibr" target="#b13">[14]</ref> , i.e. FID 22.6 vs. 24.0 vs. 25.3. Its combination with Dropout delivers the best performance in this experiment, i.e., 20.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4.3 Ablation Study on Learning Rates</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S5 Effectiveness of PA as a Regularizer</head><p>Here we exploit progressive augmentation on a toy classification task to empirically illustrate its regularization benefits discussed in Sec. 3 of the main paper. Specifically, we focus on binary classification task taking the alike Cat and Dog images from CIFAR10 <ref type="bibr" target="#b17">[18]</ref>, which represent the  <ref type="figure" target="#fig_1">Figure S1</ref>: FID learning curves (mean FIDs with one standard deviation across five random runs) of PA, TTUR, adaptive learning rate and Dropout on CIFAR10 with SN DCGAN.</p><p>TRUE (real) and FAKE (synthetic) data samples, and train the discriminator network of SN DCGAN with the cross-entropy loss to tell them apart. <ref type="figure">Figure S2</ref> depicts the discriminator loss (D loss) behaviour over iterations on the training and test sets. It shows that the discriminator very quickly becomes over-confident on the training set and that overfitting takes place after 1k iterations.</p><p>In order to regularize the discriminator we exploit the proposed progressive augmentation (PA), augmenting either the input -PA (input), or its features with spatial dimension N/8</p><formula xml:id="formula_31">-PA (feat N/8 ),</formula><p>where N is the input image dimension. For a comparison purpose, we also experiment with the Dropout [33] regularization applied on feat N/4 layer with the keep rate 0.7 (the best performing rate in our experiments). Both techniques resort to random variables for regularization. The former randomly removes features, while the latter augments them with additional random bits and adjusts accordingly the class label. In contrast to Dropout, PA exhibits a long lasting regularization effect by means of progression. Each rise of D loss coinciding with an iteration at which the augmentation level increases (every 2k iterations) and then gradually reduces after the discriminator timely adapts to the new bit. At the level one augmentation, both PA (input) and PA (feat N/8 ) start from the similar overfitting stage. Combining the bit s directly with high-level features eases checksum computation. As a result, the D loss of PA (feat N/8 ) reduces faster, but making its future task more difficult due to overfitting to the previous augmentation level. On the other hand, PA (input) let the bits pass through all layers, and thus its adaptation to augmentation progression improves over iterations. In the end, both PA (input) and PA (feat N/8 ) lead to similar regularization effect. In addition, we compare PA with the Reinit. baseline, where every 2k iterations all weights are reinitialized with Xavier initialization <ref type="bibr" target="#b10">[11]</ref>. Compared to PA, using Reinit. strategy leads to longer adaptation time (the D loss decay is much slower), potentially providing non-informative signal to the generator and thus slowing down the training.</p><p>In <ref type="figure" target="#fig_9">Figure S3</ref> we explore the stochastic nature of Dropout and PA. Each realization of the dropout mask or the augmentation bit sequence s changes the loss function landscape, varying its gradient with respect to the synthetic sample (i.e. the Dog class in this case). With the same experimental setup, we now assess the correlation of the gradients based on the first four eigenvalues of their correlation matrix -λ i , i = 0, . . . , 3, i.e. computing the averaged square roots of their ratios γ ∆ = 1 <ref type="figure" target="#fig_9">Figure S3</ref> depicts the histograms ofγ among 10 3 instances. PA has more instances with smallerγ in comparison to Dropout, indicating a more diverse set of gradients, exploitable by the generator to approach the data distribution. In contrast to Dropout, in PA the augmentation random bits determine the target class in binary classification and the discriminator is trained to comprehend s together with x, leading to the richer loss function landscape. Between input and feature space augmentation, the former yields more diverse gradients than the latter as s is passed through all layers. <ref type="figure" target="#fig_4">Figure S4</ref> shows a set of synthetic samples that are outcomes of GAN training with and without PA. PA not only improves sample quality and variation, but also sensibly navigates the image manifold through latent space interpolation.  <ref type="figure">Figure S2</ref>: Behaviour of the discriminator loss (D loss) with and w/o PA and in comparison to Dropout, using the D architecture of SN DCGAN. See Sec. S5 for details.  </p><formula xml:id="formula_32">3 3 i=1 λ 0 /λ i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S6 Exemplar Synthetic Samples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S7 Evaluation with Other Performance Measures</head><p>In addition to FID, here we measure the quality of synthetic samples by means of kernel inception distance (KID) <ref type="bibr" target="#b2">[3]</ref> and inception score (IS) <ref type="bibr" target="#b33">[34]</ref>, see <ref type="table" target="#tab_2">Tables S6 and S7 which correspond to Tables 1  and 3</ref> in the main paper. The evaluation framework setup is the same as that with FID and follows <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19]</ref>. For Fashion-MNIST and CELEBA-HQ, IS computed from the pre-trained Inception network is not meaningful and thus omitted. Overall, the obtained results show consistent observations with those that are made in Sec. 4 of the main paper based on the FID measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S8 Network Architectures and Hyperparameter Settings</head><p>In this work we exploit the implementation provided by <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19]</ref> 8 and [37] 9 . For the experiments, we run on single GPU (Nvidia Titan X).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S8.1 Network Architectures</head><p>SN DCGAN. Following <ref type="bibr" target="#b24">[25]</ref> for spectral normalization (SN), we adopt the same architecture as in <ref type="bibr" target="#b18">[19]</ref> and present its configuration in <ref type="table">Table S8</ref>. The input and feature (i.e., feat N/2 , feat N/4 and feat N/8 ) space augmentations respectively take place at the input of the layers with the index 0, 2, 4 and 6. In case of dropout, it is applied to the same intermediate layers plus the output of the layer   <ref type="table" target="#tab_2">Table 1</ref> in the main paper, we pick the feat N/8 for all evaluated datasets, whereas Sec. S4.1 presents an ablation study on the augmentation space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0.">For</head><p>SA GAN (sBN). The ResNet-based discriminator and generator architectures tailored for CIFAR10, CELEBA-HQ and T-ImageNet are presented in <ref type="table">Table S9</ref> and S11, respectively. Taking the ResNet architecture in <ref type="bibr" target="#b12">[13]</ref> for CIFAR10, in <ref type="bibr" target="#b18">[19]</ref> for CELEBA-HQ and <ref type="bibr" target="#b3">[4]</ref> for IMAGENET as the baseline, we adapt them by adding the SN and self-attention as proposed in <ref type="bibr" target="#b36">[37]</ref>. For the residual and non-local blocks we use the implementation provided by <ref type="bibr" target="#b36">[37]</ref>. As we target unsupervised GAN, the conditional batch normalization (BN) used by the generator's residual blocks only takes the input noise vector z as the conditioning, namely, self-modulation BN (sBN) <ref type="bibr" target="#b4">[5]</ref>.</p><p>For CIFAR10, we have considered the input and feature (i.e., feat N/2 and feat N/4 ) space augmentations which respectively take place at the input of the residual blocks with the index 0, 2 and 4, see <ref type="table">Table S9</ref>-(a). Note that both residual blocks with the index 3 and 4 have their feature maps of dimension N/4. We experiment with the feature space augmentation on both of them. They differ little in performance, thereby we only report the result of the feature space augmentation at the residual block 4 in <ref type="table" target="#tab_2">Table 1</ref> of the main paper.</p><p>For CELEBA-HQ, we empirically observe that it is beneficial to start from a convolutional layer rather than a residual block at the discriminator. Apart from input and feat N/8 space augmentation reported in <ref type="table" target="#tab_2">Table 1</ref> of the main paper, we have also experimented the other feature space augmentations that take place at the input of each residual block, see <ref type="table" target="#tab_2">Table S10</ref>. At the spatial dimension N , we only report the result of input space augmentation, whereas the feature space augmentation at the first residual block delivers a similar performance. Augmenting the input of the last residual block benefits from the first warm-up mechanism presented in Sec. S3.3, otherwise the discriminator can fail after augmentation progression.</p><p>For T-ImageNet, we have experimented with the augmentation space at both the input and feat 16 (at the input of the 3rd residual block) and reported their performance in <ref type="table" target="#tab_2">Table 1</ref> of the main paper. It is beneficial to use the second warm-up mechanism introduced in Sec. S3.3. Comparing with the other datasets, the synthesis quality on T-ImageNet is still poor. Single GPU simulation with 64 samples per batch is not enough in this case. Large-scale simulation as in <ref type="bibr" target="#b3">[4]</ref>, though demanding a large amount of resources, would be of interest. the decay rate of the (s)BNs at the generator is set to 0.9. During the evaluation phase, the generator uses the moving averaged mean and variance to produce synthetic samples, thereby being independent of batch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S8.3 Other Hyperparameter Settings</head><p>Comparison with SotA on Human Face Synthesis. For CELEBA (64 × 64), we used the same network architecture as T-ImageNet. This network is not as tailored as PG-GAN <ref type="bibr" target="#b15">[16]</ref> and COCO-GAN <ref type="bibr" target="#b19">[20]</ref> for human face synthesis. Unlike the other experiments, we followed the FID evaluation of COCO-GAN <ref type="bibr" target="#b19">[20]</ref> for the sake of fair comparison. The augmentation space is at feat 8 (the input of the 4th residual block). The hyperparameter setting for the D and G optimizers is: lr d = 0.0004, lr g = 0.0001, β 1 = 0, β 2 = 0.999, iter d /iter g = 1 and 1m training iterations. <ref type="table" target="#tab_6">Table 3</ref> In Sec. 4 of the main paper, we have experimented with a diverse set of regularization techniques and reported the FIDs in <ref type="table" target="#tab_6">Table 3</ref>. Their settings are as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularization Techniques in</head><p>For Label smooth., we followed the one-side label smoothing presented in <ref type="bibr" target="#b30">[31]</ref> smoothing the positive labels from 1 to 0.9 and leaving the negative ones to 0 in the binary classification task of the discriminator.</p><p>The GP from <ref type="bibr" target="#b12">[13]</ref> and the zero-centered alternative GP zero-cent from <ref type="bibr" target="#b28">[29]</ref> are implemented by exploiting the publicly available code in https://github.com/igul222/improved_wgan_ training and https://github.com/rothk/Stabilizing_GANs. The weighting parameter for GP and GP zero-cent is respectively set to 1 and 0.1 as suggested by <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>When combining GP with PA, we adjust its weighting factor whenever kicking off a new augmentation level, namely, gradually increasing the weighting factor from zero to its original value within 5k iterations. This is mainly because the new bit can flip the reference label. Such relaxation on the 1-Lipschitz constraint allows the discriminator to timely cope with the new augmentation bit. Using β 2 = 0.99 instead of β 2 = 0.9 stabilizes the training on SA GAN.</p><p>For Dropout, we experimented with different keep rates and applied layers. From <ref type="table" target="#tab_4">Table S2</ref>, we selected the best performing setting of the Dropout with the keep rate 0.7 applied on the feature space with the spatial dimension N/4.</p><p>For SS, we used the same mini-batch construction as in <ref type="bibr" target="#b5">[6]</ref> for computing the auxiliary rotation loss. The rotation loss is respectively added to the D and G loss with the weighting factors equal to 1.0 and 0.2 as suggested by <ref type="bibr" target="#b5">[6]</ref>. The augmentation bits does not affect the reference label when constructing the rotation loss.</p><p>WGAN-GP In Sec. S3.4, we additionally trained CIFAR10 on SN DCGAN with WGAN-GP. The learning rates lr d and lr g remain the same as that of NS loss, i.e., 2 × 10 −4 , but with two discriminator steps per generator step. The two momentum parameters for the Adam optimizer change to β 1 = 0 and β 2 = 0.9. The GP is weighted by one.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Visualization of progressive augmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Lemma</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>F</head><label></label><figDesc>-MNIST: SN DCGAN without PA F-MNIST: SN DCGAN with PA CELEBA-HQ: SA GAN without PA CELEBA-HQ: SA GAN with PA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Adpt lrd -Single-level (input) -PA (input) FID learning curves on SN DCGAN CI-FAR10. The curves show the mean FID with one standard deviation across five random runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Discriminator (D) and generator (G) loss over iterations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Behaviour of the discriminator loss (D loss) and the generator loss (G loss) as well as FID changes over iterations, using SN DCGAN on CIFAR10. PA acts as a stochastic regularizer, preventing the discriminator from becoming overconfident.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>S2. 2 Proof for Lemma 1 Lemma 2 .</head><label>212</label><figDesc>Let s ∈ {0, 1} denote a random bit with uniform distribution P s (s) = δ[s]+δ[s−1] 2 , where δ[s] is the Kronecker delta. Associating s with x, two joint distributions of (x, s) are constructed as P x,s (x, s) ∆ = P d (x)δ[s] + P g (x)δ[s − 1] 2 , Q x,s (x, s) ∆ = P g (x)δ[s] + P d (x)δ[s − 1] 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>mutual information I(x; s) andĨ(x; s), with respect to P x,s and Q x,s , are minimized to zero if P d = P g . When P s,a and P s,b have non-overlapped supports, the JS divergence between P x,s and Q x,s equals the JS divergence between P d and P g , i.e., D JS (P d P g ) = D JS (P x,s Q x,s ).Proof. The mutual information between x and s is minimized and equal zero if they are independent. Under the condition P s,a = P s,b , the two joint distributions P x,s and Q x,s become factorizable if P d = P g . Analogous to the proof of Lemma 1, the JS divergence between P x,s and Q x,s equals the mean of I(x; s) andĨ(x; s), i.e.,D JS (P x,s Q x,s ) = I(x; s) +Ĩ(x; s) 2 .(S20)Expressing mutual information as KL divergence plus the condition that P s,a and P s,b have nonoverlapped supports, we reach to (S3) for both I(x; s) andĨ(x; s) and thereby conclude the proof.Lemma 1 is a special case of Proposition 1, namely, P s,a (s) = δ[s] and P s,b (s) = δ[s − 1].S3 Implementation Details of PA-GANS3.1 Input and Feature Space AugmentationAs being presented in Sec. 3.2, we spatially replicate each augmentation bit and perform depth concatenation with the input x or its learned feature maps at the intermediate hidden layers. After concatenation along the channel axis, the input layer or the hidden layer then process such augmented input. For instance, in the case of a convolutional layer, it processes the augmented input as conv(φ(x), s 1 , . . . , s l ) = conv(φ(x)) + l conv(s l )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure S3 :</head><label>S3</label><figDesc>Histograms of averaged square roots of eigenvalue ratios computed from gradient correlation matrices for PA and Dropout. Smaller correlation values indicate a more diverse set of gradients exploitable by the generator to approach the data distribution. See Sec. S5 for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>(a) SN DCGAN (b) SN DCGAN with PA (c) SA GAN (sBN) (d) SA GAN (sBN) with PA Figure S4: Synthetic samples from training SN GAN on Fashion-MNIST (28 × 28) and SA GAN (sBN) on CELEBA-HQ (128 × 128) with and without using PA. In all cases, i.e., (a), (b), (c) and (d), the eight images per row are generated through polar-interpolation between two randomly sampled z 1 and z 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>is the Kronecker delta. Associating s with x, two joint distributions of (x, s) are constructed as</figDesc><table><row><cell>δ[s] P x,s (x, s)</cell><cell>2</cell><cell>, where</cell></row></table><note>1. Let s ∈ {0, 1} denote a random bit with uniform distribution P s (s) = δ[s]+δ[s−1]</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>FID improvement of PA across different datasets and network architectures. We experiment with augmenting the input and feature spaces, see Sec.4.1 for details.</figDesc><table><row><cell>Method</cell><cell cols="6">PA F-MNIST CIFAR10 CELEBA-HQ T-ImageNet ∆PA</cell></row><row><cell></cell><cell></cell><cell>10.6</cell><cell>26.0</cell><cell>24.3</cell><cell>-</cell><cell></cell></row><row><cell>SN DCGAN [25]</cell><cell cols="2">input 6.2</cell><cell>22.2</cell><cell>20.8</cell><cell>-</cell><cell>4.2</cell></row><row><cell></cell><cell>feat</cell><cell>6.2</cell><cell>22.6</cell><cell>18.8</cell><cell>-</cell><cell></cell></row><row><cell></cell><cell></cell><cell>-</cell><cell>18.8</cell><cell>17.8</cell><cell>47.6</cell><cell></cell></row><row><cell>SA GAN (sBN) [37]</cell><cell>input</cell><cell>-</cell><cell>16.1</cell><cell>15.4</cell><cell>44.8</cell><cell>2.6</cell></row><row><cell></cell><cell>feat</cell><cell>-</cell><cell>16.3</cell><cell>15.8</cell><cell>44.7</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>achieves 0.283, and MS-SSIM of 10k real samples is 0.263.Comparison with SotA on Human Face Synthesis. Deviating from from low-to high-resolution human face synthesis, the recent work COCO-GAN<ref type="bibr" target="#b19">[20]</ref> outperformed PG-GAN<ref type="bibr" target="#b15">[16]</ref> on the CELEBA dataset<ref type="bibr" target="#b20">[21]</ref> via conditional coordinating. At the resolution 64 of CELEBA, PA improves the SA GAN FID from 4.11 to 3.35, being better than COCO-GAN, which achieves FID of 4.0 and outperforms PG-GAN at the resolution 128 (FID of 5.74 vs. 7.30). Thus we conclude that the quality of samples generated by PA is comparable to the quality of samples generated by the recent state-of-the-art</figDesc><table /><note>models [20, 16] on human face synthesis.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Median FIDs of input space augmentation starting from the level l with and without progression on CIFAR10 with SN DCGAN.</figDesc><table><row><cell cols="2">Augment. level Progression l</cell><cell>∆PA</cell></row><row><cell>0</cell><cell>26.0 22.2</cell><cell>3.8</cell></row><row><cell>1</cell><cell>23.8 22.3</cell><cell>1.5</cell></row><row><cell>2</cell><cell>23.6 22.9</cell><cell>0.7</cell></row><row><cell>3</cell><cell>23.5 22.9</cell><cell>0.6</cell></row><row><cell>4</cell><cell>23.5 23.2</cell><cell>0.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Benefiting from a smoothed decision boundary, Label smooth. slightly improves the performance of SN DCGAN (26.0 vs. 25.8), but underperforms in comparison to PA (input) (22.2) and PA (feat) (22.6). By applying PA on top of Label smooth. we observe a similar reduction of the FID score (23.1 and 22.3 for input and feature space augmentation, respectively).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>FID performance of PA, different regularization techniques and their combinations on CIFAR10, see Sec. 4.2 for details.</figDesc><table><row><cell>Method</cell><cell>PA GAN</cell><cell>[31]</cell><cell>[13]</cell><cell>[29]</cell><cell>[33]</cell><cell>[6]</cell><cell>∆PA</cell></row><row><cell>SN DCGAN [25]</cell><cell>26.0 input 22.2</cell><cell>25.8 23.1</cell><cell>26.7 21.8</cell><cell>26.5 22.3</cell><cell>22.1 21.9</cell><cell cols="2">− − 3.0</cell></row><row><cell></cell><cell>feat 22.6</cell><cell>22.3</cell><cell>22.7</cell><cell>23.0</cell><cell>20.6</cell><cell cols="2">− 3.1</cell></row><row><cell>SA GAN (sBN) [37]</cell><cell>18.8 input 16.1</cell><cell>− −</cell><cell>17.8 15.8</cell><cell>17.8 16.1</cell><cell>16.2 15.5</cell><cell cols="2">15.7 14.7 1.3</cell></row><row><cell></cell><cell>feat 16.3</cell><cell>−</cell><cell>16.1</cell><cell>15.9</cell><cell>15.6</cell><cell cols="2">14.9 1.3</cell></row><row><cell></cell><cell>∆PA 3.1</cell><cell>3.1</cell><cell>3.2</cell><cell>2.8</cell><cell>0.8</cell><cell cols="2">0.9 2.3</cell></row></table><note>-Label smooth. -GP -GPzero-cent -Dropout -SS</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table S1 :</head><label>S1</label><figDesc>Median FIDs of input and feature space augmentation across five random runs. We experiment with augmenting input and features at different intermediate layers, e.g. feat N/4 denotes layer with the spatial dimension N/4, where N is the input image dimension.</figDesc><table><row><cell>Method</cell><cell>Dataset</cell><cell cols="4">PA input (N) feat N/2 feat N/4 feat N/8</cell></row><row><cell>SN DCGAN -NS Loss</cell><cell>CIFAR10 CELEBA-HQ 24.3 26.0</cell><cell>22.2 20.8</cell><cell>22.8 19.6</cell><cell>22.7 18.8</cell><cell>22.6 18.8</cell></row><row><cell cols="2">CIFAR10 SA GAN (sBN) -Hinge Loss CELEBA-HQ 17.8 18.8</cell><cell>16.1 15.4</cell><cell>16.3 15.4</cell><cell>16.3 16.4</cell><cell>-15.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table S2 :</head><label>S2</label><figDesc>Median FIDs (across five random runs) of Dropout and SpatialDropout applied on the input layer or intermediate layers with different keep rates on CIFAR10 using SN DCGAN.</figDesc><table><row><cell>Keep rate</cell><cell cols="8">Dropout input (N) feat N/2 feat N/4 feat N/8 input (N) feat N/2 feat N/4 feat N/8 SpatialDropout</cell></row><row><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell>26.0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.95</cell><cell>25.5</cell><cell>25.6</cell><cell>24.1</cell><cell>25.3</cell><cell>26.0</cell><cell>25.3</cell><cell>24.9</cell><cell>26.0</cell></row><row><cell>0.9</cell><cell>26.4</cell><cell>25.1</cell><cell>23.4</cell><cell>24.6</cell><cell>26.2</cell><cell>25.3</cell><cell>24.0</cell><cell>25.8</cell></row><row><cell>0.7</cell><cell>28.0</cell><cell>25.6</cell><cell>22.1</cell><cell>24.4</cell><cell>27.6</cell><cell>26.1</cell><cell>23.4</cell><cell>25.3</cell></row><row><cell>0.5</cell><cell>27.1</cell><cell>25.9</cell><cell>23.1</cell><cell>24.0</cell><cell>29.7</cell><cell>26.9</cell><cell>24.1</cell><cell>25.4</cell></row><row><cell>0.3</cell><cell>27.7</cell><cell>25.6</cell><cell>22.4</cell><cell>24.6</cell><cell>31.3</cell><cell>28.8</cell><cell>24.6</cell><cell>25.8</cell></row><row><cell>0.1</cell><cell>32.3</cell><cell>28.6</cell><cell>24.3</cell><cell>23.9</cell><cell>45.7</cell><cell>37.7</cell><cell>28.8</cell><cell>25.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table S5</head><label>S5</label><figDesc></figDesc><table /><note>compares the performance achieved by using different learning rate configurations. The improvement achieved by PA is consistent across different settings (∼ 3 FID points), showing its robustness to different update rules. Compared to the best performing TTUR, PA reduces the FID</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table S3 :</head><label>S3</label><figDesc>Median FIDs (across five random runs) of PA together with dropout applied on different intermediate layers with the keep rate 0.7 and on CIFAR10 and CELEBA-HQ.</figDesc><table><row><cell>Method</cell><cell>Dataset</cell><cell>PA</cell><cell>GAN</cell><cell cols="3">-Dropout [33] feat N/8 feat N/4 feat N/2</cell><cell>∆PA</cell></row><row><cell>SN DCGAN -NS Loss SA GAN (sBN) -Hinge Loss</cell><cell>CIFAR10</cell><cell cols="3">26.0 24.4 feat N/8 22.6 21.3 18.8 − feat N/4 16.3 −</cell><cell>22.1 20.6 16.2 15.6</cell><cell>25.6 22.5 17.1 15.7</cell><cell>2.0 1.1 2.2 0.7</cell></row><row><cell>SN DCGAN -NS Loss</cell><cell>CELEBA-HQ</cell><cell cols="2">24.3 feat N/8 18.8</cell><cell>− −</cell><cell>24.0 18.1</cell><cell>− −</cell><cell>0.3 0.7</cell></row><row><cell></cell><cell></cell><cell cols="2">∆PA 3.8</cell><cell>3.1</cell><cell>2.7</cell><cell>2.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table S4 :</head><label>S4</label><figDesc>Median FIDs (across five random runs) of PA together with dropout applied on different intermediate layers and keep rates on CIFAR10 with SN DCGAN.</figDesc><table><row><cell></cell><cell>Dropout</cell><cell>input(N)</cell><cell>feat N/2</cell><cell>feat N/4</cell><cell>feat N/8</cell></row><row><cell cols="2">PA(feat N/8 )</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.9</cell><cell cols="4">26.4 22.6 25.1 21.9 23.4 21.2 24.6 21.6</cell></row><row><cell>Keep Rate</cell><cell>0.7</cell><cell cols="4">28.0 22.9 25.6 21.3 22.1 20.6 24.4 22.5</cell></row><row><cell></cell><cell>0.5</cell><cell cols="4">27.1 23.1 25.9 22.3 23.1 21.2 24.0 22.1</cell></row><row><cell>∆PA</cell><cell></cell><cell>4.5</cell><cell>3.7</cell><cell>1.9</cell><cell>2.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table S5 :</head><label>S5</label><figDesc>Median FIDs (across five random runs) of different learning rates (TTURs) on CIFAR10 with SN DCGAN. Italic and bold denotes the best FIDs w/o and with PA respectively, underline denotes the default learning rate setting of SN DCGAN. PA (feat N/8 ) 10 −4 2 × 10 −4 4 × 10 −4 10 −3 ∆PA</figDesc><table><row><cell>H lr g H H lr d 10 −4 H H</cell><cell>27.0 23.3</cell><cell>25.8 22.2</cell><cell>25 .3 22.6</cell><cell>27.0 3.5 22.9</cell></row><row><cell>2 × 10 −4</cell><cell>26.7 24.8</cell><cell>26.0 22.6</cell><cell>26.2 22.3</cell><cell>27.2 3.1 24.0</cell></row><row><cell>4 × 10 −4</cell><cell>28.7 24.7</cell><cell>26.1 23.3</cell><cell>26.3 22.9</cell><cell>28.2 3.6 24.2</cell></row><row><cell>10 −3</cell><cell>28.5 25.7</cell><cell>27.0 23.6</cell><cell>26.4 23.4</cell><cell>27.4 2.9 25.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table S5</head><label>S5</label><figDesc>has also shown a stable FID performance of SN DCGAN with the generator learning rate lr g = 2 × 10 −4 and the discriminator learning rate lr d ∈ {10 −4 , 2 × 10 −4 , 4 × 10 −4 }. With this identification, we fix lr g = 2 × 10 −4 and reuse the progression scheduling to adaptively reduce lr d from 4 × 10 −4 to 10 −4 with the learning rate decay of 0.8 (in our experiments the best performing learning rate decay among {0.99, 0.95, 0.9, 0.8, 0.7}).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table S6 :</head><label>S6</label><figDesc>KID/IS improvements with PA across different datasets and network architectures, in accordance withTable 1in the main paper.</figDesc><table><row><cell></cell><cell></cell><cell>KID</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>IS</cell></row><row><cell>Method</cell><cell cols="6">PA F-MNIST CIFAR10 CELEBA-HQ T-ImageNet ∆PA</cell><cell cols="3">CIFAR10 T-ImageNet ∆PA</cell></row><row><cell>SN DCGAN</cell><cell></cell><cell>0.004</cell><cell>0.016</cell><cell>0.011</cell><cell>-</cell><cell></cell><cell>7.6</cell><cell>-</cell></row><row><cell>NS Loss</cell><cell cols="3">input 0.002 0.013</cell><cell>0.007</cell><cell>-</cell><cell>0.003</cell><cell>7.8</cell><cell>-</cell><cell>0.2</cell></row><row><cell>[25]</cell><cell cols="3">feat 0.002 0.013</cell><cell>0.005</cell><cell>-</cell><cell></cell><cell>7.8</cell><cell>-</cell></row><row><cell>SA GAN (sBN)</cell><cell></cell><cell>-</cell><cell>0.011</cell><cell>0.006</cell><cell>0.035</cell><cell></cell><cell>8.4</cell><cell>8.8</cell></row><row><cell cols="2">Hinge Loss input</cell><cell>-</cell><cell>0.008</cell><cell>0.004</cell><cell>0.033</cell><cell>0.002</cell><cell>8.7</cell><cell>9.1</cell><cell>0.3</cell></row><row><cell>[37]</cell><cell>feat</cell><cell>-</cell><cell>0.009</cell><cell>0.004</cell><cell>0.033</cell><cell></cell><cell>8.6</cell><cell>9.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table S7 :</head><label>S7</label><figDesc>KIDs/ISs of PA, different regularization techniques and their combinations on CIFAR10, in according withTable 3in the main paper.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>KID</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>PA GAN</cell><cell cols="6">-Label smooth. -GP -GPzero-cent -Dropout -SS [31] [13] [29] [33] [6]</cell><cell>∆PA</cell></row><row><cell>SN DCGAN NS Loss</cell><cell>0.016 feat 0.013</cell><cell></cell><cell>0.016 0.014</cell><cell>0.018 0.014</cell><cell>0.017 0.014</cell><cell>0.013 0.012</cell><cell>− −</cell><cell>0.003</cell></row><row><cell cols="2">SA GAN (sBN) 0.011 Hinge Loss feat 0.009</cell><cell></cell><cell>− −</cell><cell>0.010 0.008</cell><cell>0.010 0.008</cell><cell cols="3">0.008 0.008 0.008 0.007</cell><cell>0.001</cell></row><row><cell></cell><cell>∆PA 0.003</cell><cell></cell><cell>0.002</cell><cell>0.003</cell><cell>0.003</cell><cell cols="3">0.001 0.001</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>IS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="2">PA GAN</cell><cell cols="5">-Label smooth. -GP -GPzero-cent -Dropout -SS [31] [13] [29] [33] [6]</cell><cell>∆PA</cell></row><row><cell>SN DCGAN NS Loss</cell><cell cols="2">7.6 feat 7.8</cell><cell>7.5 7.7</cell><cell>7.5 7.7</cell><cell>7.5 7.7</cell><cell>7.9 7.9</cell><cell>− −</cell><cell>0.2</cell></row><row><cell cols="3">SA GAN (sBN) 8.4 Hinge Loss feat 8.6</cell><cell>− −</cell><cell>8.5 8.6</cell><cell>8.5 8.7</cell><cell>8.7 8.7</cell><cell>8.6 8.8</cell><cell>0.1</cell></row><row><cell></cell><cell cols="2">∆PA 0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.0</cell><cell>0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table S12 :</head><label>S12</label><figDesc>Training details for the experiments in this work. × 10 −4 2 × 10 −4 3 × 10 −4 3 × 10 −4 3 × 10 −4 lr g 4 × 10 −4 2 × 10 −4 2 × 10 −4</figDesc><table><row><cell>Hyper-parameters</cell><cell cols="6">SN DCGAN NS Loss F-MNIST CIFAR10 CELEBA-HQ CIFAR10 CELEBA-HQ T-IMAGENET SA GAN (sBN) Hinge Loss</cell></row><row><cell>β 1</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>β 2</cell><cell>0.999</cell><cell>0.999</cell><cell>0.999</cell><cell>0.9</cell><cell>0.9</cell><cell>0.9</cell></row><row><cell>lr d</cell><cell>10 −4</cell><cell cols="3">2 10 −4</cell><cell>10 −4</cell><cell>10 −4</cell></row><row><cell>iter d /iter g</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/boschresearch/PA-GAN 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">D(x) aims to learn the probability of x being true or fake, however, it can also be regarded as the sigmoid response of classification with cross entropy loss.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">By checksum we mean the XOR operation over a bit sequence.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">FID is used as the primary metric, KID is chosen for scheduling to avoid over-optimizing towards FID.<ref type="bibr" target="#b4">5</ref> We also experiment with using PA for WGAN-GP<ref type="bibr" target="#b1">[2]</ref>, improving FID from 25.0 to 23.9 on CIFAR10, see Sec. S4.2 in the supp. material.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://github.com/google/compare_gan 9 https://github.com/brain-research/self-attention-gan S9</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets: We consider four datasets: Fashion-MNIST <ref type="bibr" target="#b35">[36]</ref>, CIFAR10 <ref type="bibr" target="#b17">[18]</ref>, CELEBA-HQ (128 × 128) <ref type="bibr" target="#b15">[16]</ref> and Tiny-ImageNet (a simplified version of ImageNet <ref type="bibr" target="#b6">[7]</ref>), with the training set sizes equal to 60k, 50k, 27k and 100k plus the test set sizes equal to 10k, 10k, 3k, and 10k, respectively. Note that we focus on unsupervised image generation and do not use class label information.</p><p>Networks: We employ SN DCGAN <ref type="bibr" target="#b24">[25]</ref> and SA GAN <ref type="bibr" target="#b36">[37]</ref>, both using spectral normalization (SN) <ref type="bibr" target="#b24">[25]</ref> in the discriminator for regularization. SA GAN exploits the ResNet architecture with a self-attention (SA) layer <ref type="bibr" target="#b36">[37]</ref>. Its generator additionally adopts self-modulation BN (sBN) <ref type="bibr" target="#b4">[5]</ref> together with SN. We exploit the implementations provided by <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b36">37]</ref>. Following <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37]</ref>, we train SN DCGAN and SA GAN <ref type="bibr" target="#b36">[37]</ref> with the non-saturation (NS) and hinge loss, respectively. Evaluation metrics: We use Fréchet inception distance (FID) <ref type="bibr" target="#b14">[15]</ref> as the main evaluation metric. Additionally, we also report inception score (IS) <ref type="bibr" target="#b33">[34]</ref> and kernel inception distance (KID) <ref type="bibr" target="#b2">[3]</ref> in</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S8.2 Network Training Details</head><p>The training details across the datasets (i.e., F-MNIST, CIFAR10, CELEBA-HQ and T-ImageNet) and architectures (i.e., SN DCGAN, and SA GAN) are summarized in <ref type="table">Table S12</ref>. For both architectures,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikołaj</forename><surname>Bińkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">N</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Athur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Demystifying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gans</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On self modulation for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self-supervised gans via auxiliary rotation loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative multi-adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ishan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sridhar</forename><surname>Gemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010)</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">GANs trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">How (not) to train your generative model: Scheduled sampling, likelihood, adversary?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05101</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.04720</idno>
		<title level="m">The GAN landscape: Losses, architectures, regularization, and normalization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">COCO-GAN: generation by parts via conditional coordinating</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh</forename><surname>Hubert Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Che</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Sheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwann-Tzong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Are GANs created equal? A large-scale study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04076</idno>
		<title level="m">Multi-class generative adversarial networks with the L2 loss function</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Which training methods for GANs do actually converge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka. F-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stabilizing training of generative adversarial networks through regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tempered adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giambattista</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard Schölkopf Arash</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehrjou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Amortised map inference for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Casper Kaae Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huszár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient object localization using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<title level="m">Self-attention generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
