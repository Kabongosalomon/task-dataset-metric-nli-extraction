<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Generalization via Model-Agnostic Learning of Semantic Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
							<email>qi.dou@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Image Analysis Group</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Image Analysis Group</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Image Analysis Group</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
							<email>b.glocker@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Image Analysis Group</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Domain Generalization via Model-Agnostic Learning of Semantic Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generalization capability to unseen domains is crucial for machine learning models when deploying to real-world conditions. We investigate the challenging problem of domain generalization, i.e., training a model on multi-domain source data such that it can directly generalize to target domains with unknown statistics. We adopt a model-agnostic learning paradigm with gradient-based meta-train and meta-test procedures to expose the optimization to domain shift. Further, we introduce two complementary losses which explicitly regularize the semantic structure of the feature space. Globally, we align a derived soft confusion matrix to preserve general knowledge about inter-class relationships. Locally, we promote domainindependent class-specific cohesion and separation of sample features with a metric-learning component. The effectiveness of our method is demonstrated with new state-of-the-art results on two common object recognition benchmarks. Our method also shows consistent improvement on a medical image segmentation task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning methods have achieved remarkable success, under the assumption that training and test data are sampled from the same distribution. In real-world applications, this assumption is often violated as conditions for data acquisition may change, and a trained system may fail to produce accurate predictions for unseen data with domain shift. To tackle this issue, domain adaptation algorithms normally learn to align source and target data in a domain-invariant discriminative feature space <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. These methods rely on access to a few labelled <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b49">50]</ref> or unlabelled <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b50">51]</ref> data samples from the target distribution during training.</p><p>An arguably harder problem is domain generalization, which aims to train a model using multi-domain source data, such that it can directly generalize to new domains without need of retraining. This setting is very different to domain adaptation as no information about the new domains is available, a scenario that is encountered in real-world applications. In the field of healthcare, for example, medical images acquired at different sites can differ significantly in their data distribution, due to varying scanners, imaging protocols or patient cohorts. At deployment, each new hospital can be regarded as a new domain but it is impractical to collect data each time to adapt a trained system. Learning a model which directly generalizes to new clinical sites would be of great practical value.</p><p>Domain generalization is an active research area with a number of approaches being proposed. As no a priori knowledge of the target distribution is available, the key question is how to guide the model learning to capture information which is discriminative for the specific task but insensitive to changes of domain-specific statistics. For computer vision applications, the aim is to capture general semantic features for object recognition. Previous work has demonstrated that this can be investigated through regularization of the feature space, e.g., by minimizing divergence between marginal distributions of data sources <ref type="bibr" target="#b34">[35]</ref>, or joint consideration of the class conditional distributions <ref type="bibr" target="#b29">[30]</ref>. Li et al. <ref type="bibr" target="#b27">[28]</ref> use adversarial feature alignment via maximum mean discrepancy. Leveraging distance metrics of feature vectors is another method <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b33">34]</ref>. Model-agnostic meta-learning <ref type="bibr" target="#b9">[10]</ref> is a recent gradient-based method for fast adaptation of models to new conditions, e.g., a new task at few-shot learning. Metalearning has been introduced to address domain generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31]</ref>, by adopting an episodic training paradigm, i.e., splitting the available source domains into meta-train and meta-test at each iteration, to simulate domain shift. Promising performance has been demonstrated by deriving the loss from a task error <ref type="bibr" target="#b25">[26]</ref>, a classifier regularizer <ref type="bibr" target="#b0">[1]</ref>, or a predictive feature-critic module <ref type="bibr" target="#b30">[31]</ref>.</p><p>We introduce two complementary losses which explicitly regularize the semantic structure of the feature space via a model-agnostic episodic learning procedure. Our optimization objective encourages the model to learn semantically consistent features across training domains that may generalize better to unseen domains. Globally, we align a derived soft confusion matrix to preserve inter-class relationships. Locally, we use a metric-learning component to encourage domain-independent while class-specific cohesion and separation of sample features. The effectiveness of our approach is demonstrated with new state-of-the-art performance on two common object recognition benchmarks. Our method also shows consistent improvement on a medical image segmentation task. Code for our proposed method is available at: https://github.com/biomedia-mira/masf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Domain adaptation is based on the central theme of bounding the target error by the source error plus a discrepancy metric between the target and the source <ref type="bibr" target="#b1">[2]</ref>. This is practically performed by narrowing the domain shift between the target and source either in input space <ref type="bibr" target="#b18">[19]</ref>, feature space <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b50">51]</ref>, or output space <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b48">49]</ref>, generally using maximum mean discrepancy <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b45">46]</ref> or adversarial learning <ref type="bibr" target="#b13">[14]</ref>. The success of methods operating on feature representations motivates us to optimize the semantic feature space for domain generalization in this paper.</p><p>Domain generalization aims to generalize models to unseen domains without knowledge about the target distribution during training. Different methods have been proposed for learning generalizable and transferable representations. A promising direction is to extract task-specific but domain-invariant features <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>. Muandet et al. <ref type="bibr" target="#b34">[35]</ref> propose a domain-invariant component analysis method with a kernel-based optimization algorithm to minimize the dissimilarity across domains. Ghifary et al. <ref type="bibr" target="#b11">[12]</ref> learn multi-task auto-encoders to extract invariant features which are robust to domain variations. Li et al. <ref type="bibr" target="#b29">[30]</ref> consider the conditional distribution of label space over input space, and minimize discrepancy of a joint distribution. Motiian et al. <ref type="bibr" target="#b33">[34]</ref> use contrastive loss to guide samples from the same class being embedded nearby in latent space across data sources. Li et al. <ref type="bibr" target="#b27">[28]</ref> extend adversarial autoencoders by imposing maximum mean discrepancy measure to align multidomain distributions. Instead of harmonizing the feature space, others use low-rank parameterized CNNs <ref type="bibr" target="#b24">[25]</ref> or decompose network parameters to domain-specific/-invariant components <ref type="bibr" target="#b21">[22]</ref>. Data augmentation strategies, such as gradient-based domain perturbation <ref type="bibr" target="#b46">[47]</ref> or adversarially perturbed samples <ref type="bibr" target="#b52">[53]</ref> demonstrate effectiveness for model generalization. A recent method with state-of-theart performance is JiGen <ref type="bibr" target="#b2">[3]</ref>, which leverages self-supervised signals by solving jigsaw puzzles.</p><p>Meta-learning (a.k.a. learning to learn <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b47">48]</ref>) is a long standing topic exploring the training of a meta-learner that learns how to train particular models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>. Recently, gradient-based meta-learning methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b35">36]</ref> have been successfully applied to few-shot learning, with a procedure purely leveraging gradient descent. The episodic training paradigm, originated from model-agnostic meta-learning (MAML) <ref type="bibr" target="#b9">[10]</ref>, has been introduced to address domain generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31]</ref>. Epi-FCR <ref type="bibr" target="#b26">[27]</ref> alternates domain-specific feature extractors and classifiers across domains via episodic training, but without using inner gradient descent update. The method of MLDG <ref type="bibr" target="#b25">[26]</ref> closely follows the update rule of MAML, back-propagating the gradients from an ordinary task loss on meta-test data. A limitation is that using the task objective might be sub-optimal, as it is highly abstracted from the feature representations (only using class probabilities). Moreover, it may not well fit the scenario where target data are unavailable (as pointed out by Balaji et al. <ref type="bibr" target="#b0">[1]</ref>). A recent method, MetaReg <ref type="bibr" target="#b0">[1]</ref>, learns a regularization function (e.g., weighted L 1 loss) particularly for the network's classification layer, excluding the feature extractor. Instead, Li et al. <ref type="bibr" target="#b30">[31]</ref> propose a feature-critic network which learns an auxiliary meta loss (producing a non-negative scalar) depending on output of the feature extractor. Both <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b30">[31]</ref> lack notable guidance from semantics of feature space, which may contain crucial domain-independent 'general knowledge' for model generalization. Our method is orthogonal to previous work, proposing to enforce semantic features via global class alignment and local sample clustering, with losses explicitly derived in an episodic learning procedure. are the feature extractor and the task net, F ψ and T θ are their updated versions by inner gradient descent on the task loss L task , the M φ is a metric embedding net, and D k denotes different source domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In the following, we denote input and label spaces by X and Y, the domains D = {D 1 , D 2 , . . . , D K } are different distributions on the joint space X × Y. Since domain generalization involves a common predictive task, the label space is shared by all domains. In each domain, samples are drawn from a dataset</p><formula xml:id="formula_0">D k = {(x (k) n , y (k) n )} N k n=1</formula><p>where N k is the number of labeled data points in the k-th domain. The domain generalization (DG) setting further assumes the existence of domain-invariant patterns in the inputs (e.g. semantic features), which can be extracted to learn a label predictor that performs well across seen and unseen domains. Unlike domain adaptation, DG assumes no access to observations from or explicit knowledge about the target distribution.</p><p>In this work, we consider a classification model composed of a feature extractor, F ψ : X → Z, where Z is a feature space (typically much lower-dimensional than X ), and a task network, T θ : Z → R C , where C is the number of classes in Y. The final class predictions are given by p(y | x; ψ, θ) =ŷ = softmax(T θ (F ψ (x))), where softmax(a) = e a / r e ar . <ref type="bibr" target="#b0">1</ref> The parameters (ψ, θ) are optimized with respect to a task-specific loss L task , e.g. cross-entropy:</p><formula xml:id="formula_1">task (y,ŷ) = − c 1[y = c] logŷ c .</formula><p>Although the minimization of L task may produce highly discriminative features z = F ψ (x), and hence an excellent predictor for data from the training domains, nothing in this process prevents the model from overfitting to the source domains and suffering from degradation on unseen test domains. We therefore propose to optimize the feature space such that its semantic structure is insensitive to different training domains, and generalize better to new unseen domains. <ref type="figure" target="#fig_0">Figure 1</ref> gives an overview of our model-agnostic learning of semantic features (MASF), which we will detail in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model-Agnostic Learning with Episodic Training</head><p>The key of our learning procedure is an episodic training scheme, originated from model-agnostic meta-learning <ref type="bibr" target="#b9">[10]</ref>, to expose the model optimization to distribution mismatch. In line with our goal of domain generalization, the model is trained on a sequence of simulated episodes with domain shift. Specifically, at each iteration, the available domains D are randomly split into sets of meta-train D tr and meta-test D te domains. The model is trained to semantically perform well on held-out D te after being optimized with one or more steps of gradient descent with D tr domains. In our case, the feature extractor's and task network's parameters, ψ and θ, are first updated from the task-specific supervised loss L task (e.g. cross-entropy for classification), computed on meta-train:</p><formula xml:id="formula_2">(ψ , θ ) = (ψ, θ) − α∇ ψ,θ L task (D tr ; ψ, θ) ,<label>(1)</label></formula><p>where α is a learning-rate hyperparameter. This results in a predictive model T θ • F ψ with improved task accuracy on the meta-train source domains, D tr .</p><p>Once this optimized set of parameters has been obtained, we can apply a meta-learning step, aiming to enforce certain properties that we desire the model to exhibit on held-out domain D te . Crucially, the objective function quantifying these properties, L meta , is computed based on the updated parameters,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Model-agnostic learning of semantic features for domain generalization</head><formula xml:id="formula_3">Input: Source training domains D = {D k } K k=1 ; hyperparameters α, η, γ, β 1 , β 2 &gt; 0 Output: Feature extractor F ψ , task network T θ , embedding network M φ 1: repeat 2:</formula><p>Randomly split source domains D into disjoint meta-train D tr and meta-test D te 3:</p><formula xml:id="formula_4">(ψ , θ ) ← (ψ, θ) − α∇ ψ,θ L task (D tr ; ψ, θ) 4:</formula><p>Compute global class alignment loss:</p><formula xml:id="formula_5">L global ← 1 |Dtr| Di∈Dtr 1 |Dte| Dj ∈Dte global (D i , D j ; ψ , θ ) // Section 3.2 5:</formula><p>Compute local sample clustering loss:</p><formula xml:id="formula_6">L local (D; ψ , φ) ← E D [ n,m con ] or E D [ a,p,n tri ] // Section 3.3 6: L meta ← β 1 L global + β 2 L local 7: (ψ, θ) ← (ψ, θ) − η∇ ψ,θ (L task + L meta ) 8: φ ← φ − γ∇ φ L local 9: until convergence (ψ , θ )</formula><p>, and the gradients are computed towards the original parameters, (ψ, θ). Intuitively, besides the task itself, the training procedure is learning how to generalize under domain shift. In other words, parameters are updated such that future updates with given source domains also improve the model regarding some generalizable aspects on unseen target domains.</p><p>In particular, we desire the feature space to encode semantically relevant properties: features from different domains should respect inter-class relationships, and they should be compactly clustered by class labels regardless of domains (cf. Alg. 1). In the remainder of this section we describe the design of our semantic meta-objective, L meta = β 1 L global + β 2 L local , composed of a global class alignment term and a local sample clustering term, with weighting coefficients β 1 , β 2 &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Global Class Alignment Objective</head><p>Relationships between class concepts exist in purely semantic space, independent of changes in the observation domain. In light of this, compared with individual hard label prediction, aligning class relationships can promote more transferable knowledge towards model generalization. This is also noted by Tzeng et al. <ref type="bibr" target="#b49">[50]</ref> in the context of domain adaptation, by aggregating the output probability distribution when fine-tuning the model on a few labelled target data. In contrast to their work, our goal is to structure the feature space itself to preserve learned class relationships on unseen data, by means of explicit regularization.</p><p>Specifically, we formulate this objective in a manner that imposes a global layout of extracted features, such that the relative locations of features from different classes embody the inherent similarity in semantic structures. Inspired by knowledge distillation from neural networks <ref type="bibr" target="#b17">[18]</ref>, we exploit what the model has learned about class ambiguities-in the form of per-class soft labels-and enforce them to be consistent between D tr and D te domains. For each domain k, we summarize the model's current 'concept' of each class c by computing the class-specific mean feature vectorsz</p><formula xml:id="formula_7">(k) c : z (k) c = 1 N (c) k n:y (k) n =c F ψ (x (k) n ) ≈ E D k [F ψ (x) | y = c] ,<label>(2)</label></formula><p>where N </p><formula xml:id="formula_8">s (k) c = softmax(T θ (z (k) c )/τ ) .<label>(3)</label></formula><p>The collection of soft labels [s (k) c ] C c=1 represents a kind of 'soft confusion matrix' associated with a particular domain, encoding the inter-class relationships learned by the model. Such relationships should be preserved as general semantics on meta-test after updating the classification model on meta-train (e.g., cartoon dogs are more easily misclassified as horses than as houses, which likely holds in unseen domains). Standard supervised training with L task focuses only on the dominant hard label prediction, there is no reason a priori for consistency of such inter-class alignment. We therefore propose to align the soft class confusion matrix between two domains D i ∈ D tr and D j ∈ D te , by minimising their symmetrized Kullback-Leibler (KL) divergence, averaged over all C classes:</p><formula xml:id="formula_9">global (D i , D j ; ψ , θ ) = 1 C C c=1 1 2 [D KL (s (i) c s (j) c ) + D KL (s (j) c s (i) c )] ,<label>(4)</label></formula><p>where D KL (p q) = r p r log pr qr . Other symmetric divergences such as Jensen-Shannon (JS) could also be considered, although our preliminary experiments showed no significant difference with JS over symm. KL. Finally, the global class alignment loss, L global (D tr , D te ; ψ , θ ), is calculated as the average of global (D i , D j ; ψ , θ ) over all pairs of available meta-train and meta-test domains, (D i , D j ) ∈ D tr × D te (cf. Alg. 1). The complexity of this computation is not problematic in practice, since the number of domains selected in a training mini-batch is limited (as with the form in MAML <ref type="bibr" target="#b9">[10]</ref>), and in our experiments we took |D tr | = 2 and |D te | = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Local Sample Clustering Objective</head><p>In addition to promoting the alignment of class relationships across domains with L global as defined above, we further encourage robust semantic features that locally cluster according to class regardless of the domain. This is crucial, as neither of the class-prediction-based losses (L task or L global ) ensure that features of samples in the same class will lie close to each other and away from those of different classes, a.k.a. feature compactness <ref type="bibr" target="#b20">[21]</ref>. If the model cannot project the inputs to the semantic feature clusters with domain-independent class-specific cohesion and separation, the predictions may suffer from ambiguous decision boundaries, and still be sensitive to unseen kinds of domain shift. We therefore propose a local regularization objective L local to boost robustness, by increasing the compactness of class-specific clusters while reducing their overlap. Note how this is complementary to the global class alignment of semantically structuring the relative locations among class clusters.</p><p>Our preliminary experiments revealed that applying such regularization explicitly onto the features may constrain the optimization for L task and L global too heavily, hurting generalization performance on unseen domain. We thus take a metric-learning approach, introducing an embedding network M φ that operates on the extracted features, z = F ψ (x). This component represents a learnable distance function <ref type="bibr" target="#b4">[5]</ref> between feature vectors (rather than between raw inputs):</p><formula xml:id="formula_10">d φ (z n , z m ) = e n − e m 2 = M φ (z n ) − M φ (z m ) 2 .<label>(5)</label></formula><p>The sample pairs (n, m) are randomly drawn from all source domains D, because we expect the updated F ψ will harmonize the semantic feature space of D te with that of D tr , in terms of classspecific clustering regardless of domains. The computed embeddings, e = M φ (z), can then be optimized with any suitable metric-learning loss L local (D; ψ , φ) to regularize the local sample clustering. Under mild domain shift, the contrastive loss <ref type="bibr" target="#b15">[16]</ref> is a sensible choice, as it attempts to separately collapse each group of same-class exemplars to a distinct single point. It might however be over-restrictive for more extreme situations, wherein domains are related rather semantically, but with wildly distinct low-level statistics. For such cases, we propose instead to employ the triplet loss <ref type="bibr" target="#b44">[45]</ref>.</p><p>Contrastive loss is computed for pairs of samples, attracting samples of the same class and repelling samples of different classes <ref type="bibr" target="#b15">[16]</ref>. Instead of pushing clusters apart to infinity, the repulsion range is bounded by a distance margin ξ.</p><p>Our contrastive loss for a pair of samples (n, m) is defined as:</p><formula xml:id="formula_11">n,m con = d φ (z n , z m ) 2 , if y n = y m (max{0, ξ − d φ (z n , z m )}) 2 , if y n = y m .<label>(6)</label></formula><p>The total loss for a training mini-batch, L local , is normally averaged over all pairs of samples. In cases where full O(N 2 ) enumeration is intractable-e.g. image segmentation, which would involve all pairs of pixels in all images-we can obtain an unbiased O(N ) estimator of the loss by e.g. shuffling the samples and iterating over (2i − 1, 2i) pairs with i = 1, . . . , N/2 .</p><p>Triplet loss aims to make pairs of samples from the same class closer than pairs from different classes, by a certain margin ξ <ref type="bibr" target="#b44">[45]</ref>. Given one 'anchor' sample a, one 'positive' sample p (with y a = y p ), and one 'negative' sample n (with y a = y n ), we compute their triplet loss as follows:</p><formula xml:id="formula_12">a,p,n tri = max{0, d φ (z a , z p ) 2 − d φ (z a , z n ) 2 + ξ} .<label>(7)</label></formula><p>Schroff et al. <ref type="bibr" target="#b44">[45]</ref> argue that judicious triplet selection is essential for good convergence, as many triplets may already satisfy this constraint and others may be too hard to contribute meaningfully to the learning process. Here we adopt their proposed online 'semi-hard' triplet mining strategy, and L local is the average over all selected triplet pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate and compare our method on three datasets: 1) the classic VLCS domain generalization benchmark for image classification, 2) the recently introduced PACS benchmark for object recognition with challenging domain shift, 3) a real-world medical imaging task of tissue segmentation in brain MRI. Results with an in-depth analysis and ablation study are presented in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">VLCS Dataset</head><p>VLCS <ref type="bibr" target="#b7">[8]</ref> is a classic benchmark for domain generalization, which includes images from four datasets: PASCAL VOC2007 (V) <ref type="bibr" target="#b6">[7]</ref>, LabelMe (L) <ref type="bibr" target="#b40">[41]</ref>, Caltech (C) <ref type="bibr" target="#b8">[9]</ref>, and SUN09 (S) <ref type="bibr" target="#b3">[4]</ref>. The multi-class object recognition task includes five classes: bird, car, chair, dog and person. We follow previous work <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34]</ref> of using the publicly available pre-extracted DeCAF 6 features (4096-dimensional vector) for leave-one-domain-out validation with randomly dividing each domain into 70% training and 30% test, inputting to two fully connected layers with output size of 1024 and 128 with ReLU activation. For our metric embedding M φ (inputting the 128-dimensional vector), we use two fully connected layers with output size of 128 and 64. The triplet loss is adopted for computing L local , with coefficient β 2 = 0.005, such that it is in a similar scale to L task and L global (β 1 = 1). We use the Adam optimizer <ref type="bibr" target="#b22">[23]</ref> with η initialized to 10 −3 and exponentially decayed by 2% every 1k iterations. For the inner optimization to obtain (ψ , θ ), we clip the gradients by norm (threshold by 2.0) to prevent them from exploding, since this step uses plain, non-adaptive gradient descent (with learning rate α = 10 −5 ). Note that, although performing gradient descent on L meta involves second-order gradients on (ψ, θ), their computation does not incur a substantial overhead in training time <ref type="bibr" target="#b9">[10]</ref>. We also employ an Adam optimizer for the meta-updates of φ with learning rate γ = 10 −5 without decay. The batch size is 128 for each source domain, with an Nvidia TITAN Xp 12 GB GPU. The metric-learning margin hyperparameter ξ was chosen heuristically based on observing the distances within and between the clusters of class features. For our results, we report the average and standard deviation over three independent runs.</p><p>Results. <ref type="table" target="#tab_0">Table 1</ref> shows the object recognition accuracies on different target domains. Our DeepAll baseline-i.e., merging all source domains and training F ψ •T θ by standard supervised learning on L task with the same hyperparameters-achieves an average accuracy of 72.19% over four domains. Using our episodic training paradigm with regularizations on semantic feature space, we improve the performance to 74.11%, setting the state-of-the-art accuracy on VLCS. We compare with eight different methods (cf. Section 2) which report previous best results on this benchmark. CCSA <ref type="bibr" target="#b33">[34]</ref> combines contrastive loss together with ordinary cross-entropy without using episodic meta-update paradigm. Notably, our approach outperforms MLDG <ref type="bibr" target="#b25">[26]</ref>, indicating that explicitly encouraging semantic properties in the feature space is superior to using a highly-abstracted task loss on meta-test. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PACS Dataset</head><p>The PACS dataset <ref type="bibr" target="#b24">[25]</ref> is a recent benchmark with more severe distribution shift between domains, making it more challenging than VLCS. It consists of four domains: art painting, cartoon, photo, sketch, with objects from seven classes: dog, elephant, giraffe, guitar, house, horse, person. Following practice in the literature <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>, we also use leave-one-domain-out cross-validation, i.e., training  on three domains and testing on the remaining unseen one, and adopt an AlexNet <ref type="bibr" target="#b23">[24]</ref> pre-trained on ImageNet <ref type="bibr" target="#b39">[40]</ref>. The metric embedding M φ is connected to the last fully connected layer (i.e., fc7 layer with a 4096-dimesional vector), by stacking two fully connected layers with output size of 1024 and 256. For the L local , we also use the triplet loss with β 2 = 0.005, β 1 = 1.0, particularly considering the severe domain shift. We initialize learning rates α = η = γ = 10 −5 and clip inner gradients by norm. The batch size is 128 for each source domain.</p><p>Results. <ref type="table" target="#tab_1">Table 2</ref> summarizes the results of object recognition on PACS dataset with a comparison to previous work (noting that not all compared methods reported results on both VLCS and PACS). MLDG <ref type="bibr" target="#b25">[26]</ref> and MetaReg <ref type="bibr" target="#b0">[1]</ref> employ episodic training with meta-learning, but from different angles in terms of the meta learner's objective (Li et al. <ref type="bibr" target="#b25">[26]</ref> minimize task error, Balaji et al. <ref type="bibr" target="#b0">[1]</ref> learn a classifier regularizer). The promising results for <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref> indicate that exposing the training procedure to domain shift benefits model generalization to unseen domains. Our method further explicitly considers the semantic structure, regarding both global class alignment and local sample clustering, yielding improved accuracy. Across all domains, our method increases average accuracy by 3.51% over the baseline. Note that current state-of-the-art JiGen [3] improves 1.86% over its own baseline. In addition, we observe an improvement of 6.20% when the unseen domain is sketch, which has a distinct style and requires more general knowledge about semantic concepts.</p><p>Ablation analysis. We conduct an extensive study using PACS benchmark to investigate two key points: 1) the contribution of each component to our method's performance, 2) how the semantic feature space is influenced by our proposed meta losses. First, we test all possible combinations of including the key components: episodic meta-learning simulating domain shift, global class alignment loss and local sample clustering loss. Accuracies averaged over three runs when using different combinations are given in <ref type="table" target="#tab_2">Table 3</ref>. For example, first row corresponds to the DeepAll baseline with standard training by aggregating all source data. The fifth row is directly adding the L global , L local losses on top of L task with standard optimization scheme, i.e., without splitting D to meta-train and meta-test domains. From the ablation study, we observe that each component plays its own role in a complementary way. Specifically, the proposed losses that encourage semantic structure in feature space yield improvement over DeepAll, as well as over pure episodic training (the second row) that corresponds to our implementation of MLDG thus enabling straightforward comparison. By further leveraging the gradient-based update paradigm, performance is further improved across all settings.   We utilize t-SNE <ref type="bibr" target="#b51">[52]</ref> to analzye the feature space learned with our proposed model and the DeepAll baseline (cf. <ref type="figure" target="#fig_2">Fig. 2</ref>). It appears that our MASF model yields a better separation of classes. We also note that the sketch domain is further apart from art painting and cartoon, although all three are source domains in this experiment, possibly explained by the unique characteristics of sketches. In <ref type="figure" target="#fig_3">Figure 3</ref> (a), we plot the difference of feature distances between samples of negative pairs and positive pairs, i.e., E[ z a − z n 2 − z a − z p 2 ]. For the two magenta lines, respectively for MASF and DeepAll, sample pairs are drawn from different training source domains. We see that both distance margins naturally increase as training progresses. The shaded area highlights that MASF yeilds a higher distance margin between classes compared to DeepAll, indicating that sample clusters are better separated with MASF. Similarly, for the two blue lines, sample pairs are from the unseen target domain and a source domain (randomly selected at each iteration). As expected, the margin is not as large as between training domains, yet our method still presents a notably bigger margin than the baseline. In <ref type="figure" target="#fig_3">Figure 3</ref> (b), we plot global quantifying differences of average class posteriors between unseen target domain and a source domain during training. We observe that the semantic inter-class relationships, conveying general knowledge about a recognition task, would not naturally converge and generalize to the unseen domain without explicit guidance.</p><p>Deeper architectures. In the interest of providing stronger baseline results, we perform additional preliminary experiments using more up-to-date deep residual architectures <ref type="bibr" target="#b16">[17]</ref> with ResNet-18 and ResNet-50. <ref type="table" target="#tab_3">Table 4</ref> shows strong and consistent improvements of MASF over the DeepAll baseline in all PACS splits for both network architectures. This suggests our proposed algorithm is also beneficial for domain generalization with deeper feature extractors. <ref type="figure">Figure 4</ref>: Different brain MRI datasets with example images and intensity histograms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Set-A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Set-B Set-C Set-D</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Tissue Segmentation in Multi-site Brain MRI</head><p>We evaluate our method on a real-world medical imaging task of brain tissue segmentation in T1weighted MRI. Data was acquired from four clinical centers (denoted as Set-A/B/C/D). Domain shift occurs due to differences in scanners, acquisition protocols and many other factors, posing severe limitations for translating learning-based methods to clinical practice <ref type="bibr" target="#b12">[13]</ref>. <ref type="figure">Figure 4</ref> shows example images and intensity histograms. We adapt MASF for the segmentation of four classes: background, grey matter (GM), white matter (WM), cerebrospinal fluid (CSF). We employ a U-Net <ref type="bibr" target="#b37">[38]</ref>, commonly used for this task. For L global , thez (k) c is computed by averaging over all pixels of a class. Our metric-embedding has two layers of 1×1 convolutions, with contrastive loss for L local . We randomly split each domain to 80% for training and 20% for testing in experimental settings.</p><p>Results. For easier comparison, we average the evaluated Dice scores achieved for the three foreground classes (GM/WM/CSF) and report it in <ref type="table" target="#tab_4">Table 5</ref>. Although hard to notice visually from the gray-scale images, the domain shift from data distribution degrades segmentation significantly by up to 10%. DeepAll is a strong baseline, yet our model-agnostic learning scheme provides consistent improvement over naively aggregating data from multiple sources, especially when generalizing to a new clinical site with relatively poorer imaging quality (i.e., Set-D). <ref type="figure" target="#fig_3">Figure 3 (c)</ref> is the Silhouette plot <ref type="bibr" target="#b38">[39]</ref> of the embeddings from M φ , demonstrating that the samples within the same class cluster are tightly grouped, as well as clearly separated from those of other classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have presented promising results for a new approach to domain generalization of predictive models by incorporating global and local constraints for learning semantic feature spaces. The better generalization capability is demonstrated by new state-of-the-art results on popular benchmarks and a dense classification task (i.e., semantic segmentation) for medical images. The proposed loss functions are generally orthogonal to other algorithms, and evaluating the benefit of their integration is an appealing future direction. Our learning procedure could also be interesting to explore in the context of generative models, which may greatly benefit from semantic guidance when learning low-dimensional data representations from multiple sources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An overview of the proposed model-agnostic learning of semantic features (MASF): (a) episodic training under simulated domain shift, with gradient flows indicated; (b) global alignment of class relationships; (c) local sample clustering, towards cohesion and separation. F ψ and T θ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>k</head><label></label><figDesc>is the number of samples in domain D k labelled as class c. The obtainedz (k) c conveys how samples from a particular class are generally represented. It is then forwarded to the task network T θ , for computing soft label distributions s (k) c with a 'softened' softmax at temperature τ &gt; 1 [18]:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The t-SNE visualization of extracted features from F ψ , using our proposed (a-b) MASF and the (c-d) DeepAll model on PACS dataset. In (a) and (c), the different colors indicate different classes; correspondingly in (b) and (d), the different colors indicate different domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Analysis of the learning procedure: (a) margin of feature distance between sample negative pairs (with different classes) and positive pairs (with the same class), (b) class relationships alignment loss between unseen target domain and source domain, (c) Silhouette plot of the embeddings from meta metric-learning. Detailed analysis is in Section 4.2 for (a-b) and Section 4.3 for (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Domain generalization results on VLCS dataset with object recognition accuracy (%).</figDesc><table><row><cell cols="2">Source Target</cell><cell cols="7">D-MTAE CIDDG CCSA DBADG MMD-AAE MLDG Epi-FCR JiGen DeepAll [12] [30] [34] [25] [28] [26] [27] [3] (Baseline)</cell><cell>MASF (Ours)</cell></row><row><cell>L,C,S</cell><cell>V</cell><cell>63.90</cell><cell>64.38 67.10 69.99</cell><cell>67.70</cell><cell>67.7</cell><cell>67.1</cell><cell cols="3">70.62 68.67±0.09 69.14±0.19</cell></row><row><cell>V,C,S</cell><cell>L</cell><cell>60.13</cell><cell>63.06 62.10 63.49</cell><cell>62.60</cell><cell>61.3</cell><cell>64.3</cell><cell cols="3">60.90 63.10±0.11 64.90±0.08</cell></row><row><cell>V,L,S</cell><cell>C</cell><cell>89.05</cell><cell>88.83 92.30 93.63</cell><cell>94.40</cell><cell>94.4</cell><cell>94.1</cell><cell cols="3">96.93 92.86±0.13 94.78±0.16</cell></row><row><cell>V,L,C</cell><cell>S</cell><cell>61.33</cell><cell>62.10 59.10 61.32</cell><cell>64.40</cell><cell>65.9</cell><cell>65.9</cell><cell cols="3">64.30 64.11±0.17 67.64±0.12</cell></row><row><cell cols="2">Average</cell><cell>68.60</cell><cell>69.59 70.15 72.11</cell><cell>72.28</cell><cell>72.3</cell><cell>72.9</cell><cell>73.19</cell><cell>72.19</cell><cell>74.11</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Domain generalization results on PACS dataset with recognition accuracy (%) using AlexNet.</figDesc><table><row><cell cols="2">Source Target</cell><cell cols="7">D-MTAE CIDDG DBADG MLDG Epi-FCR MetaReg JiGen DeepAll [12] [30] [25] [26] [27] [1] [3] (Baseline)</cell><cell>MASF (Ours)</cell></row><row><cell cols="3">C,P,S Art painting 60.27</cell><cell>62.70</cell><cell>62.86</cell><cell>66.23</cell><cell>64.7</cell><cell cols="3">69.82 67.63 67.60±0.21 70.35±0.33</cell></row><row><cell cols="2">A,P,S Cartoon</cell><cell>58.65</cell><cell>69.73</cell><cell>66.97</cell><cell>66.88</cell><cell>72.3</cell><cell cols="3">70.35 71.71 68.87±0.22 72.46±0.19</cell></row><row><cell cols="2">A,C,S Photo</cell><cell>91.12</cell><cell>78.65</cell><cell>89.50</cell><cell>88.00</cell><cell>86.1</cell><cell cols="3">91.07 89.00 89.20±0.24 90.68±0.12</cell></row><row><cell cols="2">A,C,P Sketch</cell><cell>47.68</cell><cell>64.45</cell><cell>57.51</cell><cell>58.96</cell><cell>65.0</cell><cell cols="3">59.26 65.18 61.13±0.30 67.33±0.12</cell></row><row><cell cols="2">Average</cell><cell>64.48</cell><cell>68.88</cell><cell>69.21</cell><cell>70.01</cell><cell>72.0</cell><cell>72.62 73.38</cell><cell>71.70</cell><cell>75.21</cell></row><row><cell></cell><cell>elephant</cell><cell>house</cell><cell></cell><cell></cell><cell>source domains target domain</cell><cell></cell><cell></cell><cell>(c)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>horse</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>person</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(d)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>dog</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(a)</cell><cell>giraffe</cell><cell>guitar</cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation study on key components of our method with the PACS dataset (accuracy, %).</figDesc><table><row><cell cols="3">Episodic L global L local</cell><cell>Art</cell><cell>Cartoon</cell><cell>Photo</cell><cell>Sketch</cell><cell>Average</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="4">67.60±0.21 68.87±0.22 89.20±0.24 61.13±0.30</cell><cell>71.70</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell cols="4">69.19±0.10 70.66±0.37 90.36±0.18 59.89±0.26</cell><cell>72.52</cell></row><row><cell>-</cell><cell></cell><cell>-</cell><cell cols="4">69.43±0.29 70.22±0.21 90.64±0.15 60.11±0.17</cell><cell>72.60</cell></row><row><cell>-</cell><cell>-</cell><cell></cell><cell cols="4">69.50±0.15 70.25±0.13 90.12±0.12 63.02±0.12</cell><cell>73.22</cell></row><row><cell>-</cell><cell></cell><cell></cell><cell cols="4">69.48±0.20 71.15±0.16 90.16±0.15 64.73±0.34</cell><cell>73.88</cell></row><row><cell></cell><cell></cell><cell>-</cell><cell cols="4">69.94±0.15 72.16±0.28 90.10±0.12 63.54±0.13</cell><cell>73.93</cell></row><row><cell></cell><cell>-</cell><cell></cell><cell cols="4">69.50±0.20 71.44±0.34 90.16±0.15 64.97±0.28</cell><cell>74.02</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">70.35±0.33 72.46±0.19 90.68±0.12 67.33±0.12</cell><cell>75.21</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>PACS results with deep residual network architectures (accuracy, %). ± 0.25 71.69 ± 0.22 69.69 ± 0.11 72.29 ± 0.15</figDesc><table><row><cell cols="2">Source Target</cell><cell cols="2">ResNet-18</cell><cell>ResNet-50</cell></row><row><cell></cell><cell></cell><cell>DeepAll</cell><cell>MASF (ours)</cell><cell>DeepAll</cell><cell>MASF (ours)</cell></row><row><cell>C,P,S</cell><cell cols="4">Art-painting 77.38 ± 0.15 80.29 ± 0.18 81.41 ± 0.16 82.89 ± 0.16</cell></row><row><cell>A,P,S</cell><cell>Cartoon</cell><cell cols="3">75.65 ± 0.11 77.17 ± 0.08 78.61 ± 0.17 80.49 ± 0.21</cell></row><row><cell>A,C,S</cell><cell>Photo</cell><cell cols="3">94.25 ± 0.09 94.99 ± 0.09 94.83 ± 0.06 95.01 ± 0.10</cell></row><row><cell>A,C,P</cell><cell>Sketch</cell><cell>69.64</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Evaluation of brain tissue segmentation (Dice coefficient, %) in different settings: columns 1-4: train model on single source domain, test on all domains; columns 5-6: train on three source domains, test on remaining domain. 88.91 88.81 85.03 89.09 89.82 Set-B 85.03 94.22 81.38 88.31 90.41 91.71 Set-C 93.14 92.80 95.40 88.68 94.30 94.50 Set-D 76.32 88.39 73.50 94.29 88.62 89.51</figDesc><table><row><cell cols="2">Test Train Set-A Set-B Set-C Set-D DeepAll MASF</cell></row><row><cell>Set-A</cell><cell>90.62</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For image segmentation, F ψ extracts feature maps and the task network T θ is applied pixel-wise.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant No 757173, project MIRA, ERC-2017-STG) and is supported by an EPSRC Impact Acceleration Award (EP/R511547/1). DCC is also partly supported by CAPES, Ministry of Education, Brazil (BEX 1500/2015-05).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MetaReg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting hierarchical context on a large database of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myung</forename><forename type="middle">Jin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Co-regularization based semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="478" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Pascal Visual Object Classes (VOC) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1657" to="1664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="70" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Machine learning with multi-site imaging data: An empirical study on the impact of scanner effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ender</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging Meets NeurIPS Workshop</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimal kernel choice for large-scale two-sample tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Sejdinovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Strathmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivaraman</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1205" to="1213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2014 Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CyCADA: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning (ICML)</title>
		<meeting>the 35th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1989" to="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to cluster in order to transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chang</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyang</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised learning via compact latent space clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><forename type="middle">Le</forename><surname>Folgoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryutaro</forename><surname>Tanno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Nori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning (ICML)</title>
		<meeting>the 35th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2459" to="2468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">L</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5542" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3490" to="3497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00113</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to optimize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="624" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Feature-critic networks for heterogeneous domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11448</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5716" to="5726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ImageNet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">LabelMe: a database and web-based tool for image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohei</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3723" to="3732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook. PhD thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Technische Universität München</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">FaceNet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Equivalence of distance-based and RKHS-based statistics in hypothesis testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Sejdinovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2263" to="2291" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<title level="m">Learning to Learn</title>
		<editor>Sebastian Thrun and Lorien Pratt</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5334" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
