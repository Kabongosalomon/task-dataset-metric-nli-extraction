<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi-Supervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragav</forename><surname>Sachdeva</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><forename type="middle">R</forename><surname>Cordeiro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
						</author>
						<title level="a" type="main">ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi-Supervised Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we address the problem of training deep neural networks in the presence of severe label noise. Our proposed training algorithm ScanMix, combines semantic clustering with semi-supervised learning (SSL) to improve the feature representations and enable an accurate identification of noisy samples, even in severe label noise scenarios. To be specific, ScanMix is designed based on the expectation maximisation (EM) framework, where the E-step estimates the value of a latent variable to cluster the training images based on their appearance representations and classification results, and the M-step optimises the SSL classification and learns effective feature representations via semantic clustering. In our evaluations, we show state-of-the-art results on standard benchmarks for symmetric, asymmetric and semantic label noise on CIFAR-10 and CIFAR-100, as well as large scale real label noise on WebVision. Most notably, for the benchmarks contaminated with large noise rates (80% and above), our results are up to 27% better than the related work. The code is available at https:// github.com/ragavsachdeva/ScanMix.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Much of the recent success of deep learning models is attributable to the availability of well-curated large-scale data sets that enables a reliable supervised learning process <ref type="bibr" target="#b27">(Litjens et al., 2017)</ref>. However, the vast majority of data sets available in the real-world have incorrect (i.e., noisy) labels due to human failure, poor quality of data or inadequacy of the automatic labelling process <ref type="bibr" target="#b9">(Frénay &amp; Verleysen, 2013)</ref>. Using such noisy data sets for training not only hurts the accuracy of the models but also biases the model to make the same mistakes present in the labels. Therefore, one of <ref type="figure">Figure 1</ref>. ScanMix combines semantic clustering (a) that pulls together points that have similar appearances and classification results, with semi-supervised learning (SSL) (c) that trains the classifier by treating the samples classified to have noisy labels, as unlabelled samples. In the figure, circles represent true cat label, and squares, true dog class, where samples 3 and 6 have noisy labels, but the classifier produces the right classification (see yellow and pink bars). In frames (a),(c) the arrows denote how samples are moved in the feature space at each stage, with samples 3 and 6 showing white background in (b),(c) because they are classified as noisy in (b) and have their labels removed for SSL. the important challenges in the field is the formulation of robust training algorithms that work effectively with data sets corrupted with noisy labels. For classification tasks, deep neural networks (DNNs) have some natural robustness to noisy labels <ref type="bibr" target="#b34">(Rolnick et al., 2017)</ref>. However, this robustness is limited and DNNs are known to be able to easily overfit a training data contaminated with label noise .</p><p>The most successful approaches to address the learning from label noise (LNL) problem are based on semi-supervised learning (SSL) methods <ref type="bibr" target="#b8">(Ding et al., 2018;</ref><ref type="bibr" target="#b24">Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref>. SSL methods run the following steps iteratively: a) automatically split the training set into clean and noisy sets, b) discard the labels of the samples in the noisy set and, c) minimise the classification loss with the labelled (clean) and unlabelled (noisy) data. Thus, the process of automatically splitting the training set into clean and noisy sets is the cornerstone of this pipeline. For low noise rates, such automatic identification is fairly successful <ref type="bibr">(Ding arXiv:2103</ref><ref type="bibr">.11395v1 [cs.CV] 21 Mar 2021</ref><ref type="bibr" target="#b24">Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref> because of the strong support in the training set that associates image representations and their true labels. However, for severe label noise, this support weakens, resulting in the inevitable over-fitting of label noise <ref type="bibr" target="#b8">(Ding et al., 2018;</ref><ref type="bibr" target="#b24">Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref>.</p><p>To mitigate the issues caused by severe label noise, one can consider self-supervised learning strategies <ref type="bibr" target="#b4">(Chen et al., 2020a;</ref><ref type="bibr" target="#b10">Gansbeke et al., 2020;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref> to build feature representations from the images without using any labels. These self-supervised learning strategies <ref type="bibr" target="#b4">(Chen et al., 2020a;</ref><ref type="bibr" target="#b10">Gansbeke et al., 2020;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref> show better classification accuracy than recently proposed LNL methods <ref type="bibr" target="#b24">(Li et al., 2020;</ref><ref type="bibr" target="#b36">Tam Nguyen et al., 2019)</ref> when the noise rate is large (above 80% symmetric and 40% asymmetric). However, for low noise rates, LNL methods tend to outperform their self-supervised counterparts. This can be explained by the fact that self-supervised methods typically tend to cluster images that have similar appearances, but such similarity does not imply that the images belong to same class. Our hypothesis is that in a noisy label context, the use of self-supervised learning (without using the training set labels) can create an initial feature representation that is more related to the real hidden representation in comparison to supervised training with noisy labels. However, the use of self-supervised learning alone is not enough to bridge the gap to its supervised training counterpart when the data set is largely well-structured and clean. To this end, we propose a joint training mechanism that performs semantic clustering and SSL in tandem. We hypothesise that the joint approach enables: 1) the model to not get heavily biased by noisy labels (as it is guided by semantic clustering), and 2) still use the efficient SSL strategy to produce accurate classification results. We summarise these points in <ref type="figure">Fig. 1</ref>.</p><p>In this paper, we propose ScanMix, a new training algorithm robust to label noise that aims to cluster images with similar appearance and classification results, enabling a more effective identification of noisy label images to subsequently be "unlabelled" and then used in SSL. To this end, we formalise our algorithm based on the expectation maximisation (EM) framework <ref type="bibr" target="#b6">(Dempster et al., 1977)</ref>, where the E-step estimates the value of a latent variable that defines the cluster of the training images based on their appearance representations and classification results, and the M-step optimises the SSL classification and learns effective feature representations via semantic clustering. The main objective of Scan-Mix is that these learned feature representations can enable a more accurate identification of noisy label samples and a better training of the classifier using SSL methods <ref type="bibr" target="#b8">(Ding et al., 2018;</ref><ref type="bibr" target="#b24">Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref>.</p><p>To the best of our knowledge, this paper is the first to jointly explore SSL and semantic clustering for the problem of severe noisy-label deep learning. Experiments on CIFAR-10 <ref type="bibr" target="#b20">(Krizhevsky et al., 2009)</ref>, CIFAR-100 <ref type="bibr" target="#b20">(Krizhevsky et al., 2009</ref>) under symmetric, asymmetric and semantic noise, show that our method significantly outperforms the previous approaches. For 90% symmetric noise rate, we push the SOTA by 15% on CIFAR-10 and 27% on CIFAR-100. For asymmetric and semantic noise, our method improves the previous results by roughly 5%. While ScanMix is also competitive on lower noise rates, our main contribution is a significant improvement on severe label noise regimes. Furthermore, our experiments on WebVision  show that our proposed method can be successfully applied to a large-scale real-world data set that contains a challenging semantic label noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Prior work</head><p>The last few years have witnessed a large number of publications in the field of noisy label learning. The main techniques explored are: label cleansing <ref type="bibr" target="#b16">(Jaehwan et al., 2019;</ref><ref type="bibr" target="#b44">Yuan et al., 2018)</ref>, robust loss functions <ref type="bibr" target="#b38">(Wang et al., 2019a;</ref>, meta-learning <ref type="bibr" target="#b11">(Han et al., 2018a)</ref>, sample weighting <ref type="bibr" target="#b33">(Ren et al., 2018)</ref>, ensemble learning <ref type="bibr" target="#b30">(Miao et al., 2015)</ref>, student-teacher model <ref type="bibr" target="#b37">(Tarvainen &amp; Valpola, 2017)</ref>, coteaching <ref type="bibr" target="#b12">(Han et al., 2018b;</ref><ref type="bibr" target="#b17">Jiang et al., 2018;</ref><ref type="bibr" target="#b24">Li et al., 2020;</ref><ref type="bibr" target="#b29">Malach &amp; Shalev-Shwartz, 2017;</ref><ref type="bibr" target="#b43">Yu et al., 2019)</ref>, dimensionality reduction of the image representation <ref type="bibr" target="#b28">(Ma et al., 2018)</ref>, and a combination of the techniques above <ref type="bibr" target="#b19">(Kim et al., 2019;</ref><ref type="bibr" target="#b36">Tam Nguyen et al., 2019;</ref><ref type="bibr" target="#b42">Yu et al., 2018;</ref><ref type="bibr" target="#b47">Zhang et al., 2019)</ref>. Recent advances in the field showed that the most promising and efficient strategy is the combination of various such methods, e.g., co-training, noise filtering, data augmentation and SSL <ref type="bibr" target="#b24">(Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref>. Below, we do not review approaches that require a clean validation set, such as <ref type="bibr" target="#b48">(Zhang et al., 2020)</ref>, since that setup imposes a strong limitation to the kinds of noisy-label learning problems that can be solved.</p><p>As mentioned in Sec. 1, methods based on SSL for noisylabel training <ref type="bibr" target="#b8">(Ding et al., 2018;</ref><ref type="bibr" target="#b24">Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref> show SOTA results on several benchmarks, so we use them as baseline. In general, these methods rely on: 1) the identification of training samples containing noisy labels and the subsequent removal of their labels; and 2) performing SSL  using this set of unlabelled samples and the remaining set of labelled samples. <ref type="bibr" target="#b8">Ding et al. (2018)</ref> propose to identify a small portion of clean samples from the noisy training set by associating them with a high confidence. Following this, they use the filtered samples as labelled and the remaining ones as unlabelled in an SSL approach. However, relying on highly confident samples to compose the labelled set may not work well for severe noise rate scenarios because even the labelled set can be contaminated with a relatively high noise rate. The methods described in <ref type="bibr" target="#b24">(Li et al., 2020;</ref><ref type="bibr" target="#b31">Ortego et al., 2019)</ref> split the noisy and clean samples as unlabelled and labelled, respectively, by fitting a two-component Gaussian Mixture Model (GMM) on the normalised loss values for each epoch of the training. Next, they use MixMatch  to generate a combined new labelled and unlabelled sets through the use of MixUp <ref type="bibr" target="#b46">(Zhang et al., 2017)</ref> data augmentation. An underlying issue with this approach is that the robustness of MixUp depends on the noise rate of the training set, which means that these strategies do not perform well for high noise rates. A potential way to make SSL methods more robust to severe label noise is with the use of a feature clustering scheme that pulls together samples that are semantically similar, without considering the noisy labels from the training set, and one way to enable such semantic clustering is provided by the recently proposed self-supervised learning approaches <ref type="bibr" target="#b4">(Chen et al., 2020a;</ref><ref type="bibr" target="#b10">Gansbeke et al., 2020;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref>.</p><p>Self-supervised learning has generally been used as a feature learning strategy for unlabelled data sets. For instance, SimCLR <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref> generates data augmentations of the input images and trains the model to have similar representation of an image and its data augmented samples, while increasing the dissimilarity to the other images. By the same token, MoCo <ref type="bibr" target="#b5">(Chen et al., 2020b;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref> tackles the problem of self-supervised representation learning by conflating contrastive learning with a dictionary look-up. The proposed framework builds a dynamic dictionary with a queue and a moving-averaged encoder to enable building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. Another example is the SCAN approach <ref type="bibr" target="#b10">(Gansbeke et al., 2020</ref>) that has several stages of self-supervised training: one based on SimCLR <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref>, followed by another based on a nearest neighbor clustering scheme, and another based on self-labelling. Self-supervised learning approaches usually show results better than the noisy label SOTA methods for severe label noise problems (above 80% noise), but for relatively low label noise rates (below 50% noise), self-supervised learning tends to be worse. Therefore, the main question we address in this paper is how to use the semantic clustering capability of self-supervised learning approaches, combined with an SSL method, to improve the current SOTA results in severe label noise problems, and maintain the SOTA results in low noise label scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we first provide the description of the data set and the label noise processes. Then, we describe our proposed method ScanMix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data set and Label Noise Types</head><p>Let the training set be denoted by</p><formula xml:id="formula_0">D = {(x i , y i )} |D| i=1</formula><p>, with x i ∈ S ⊆ R H×W being the i th image of size H × W , and y i ∈ {0, 1} |Y| a one-hot vector of the noisy label, where Y = {1, ..., |Y|} represents the set of labels, and c∈Y y i (c) = 1. The latent true label of the i th training instance is denoted byŷ i ∈ Y, where c∈Yŷ i (c) = 1. This latent true label is used by a noise process to produce</p><formula xml:id="formula_1">y i ∼ p(y|x i , Y,ŷ i ), with p(y(j)|x i , Y,ŷ i (c)) = η jc (x i ), where η jc (x i ) ∈ [0, 1] and j∈Y η jc (x i ) = 1.</formula><p>The types of noises considered in this paper are: symmetric <ref type="bibr" target="#b19">(Kim et al., 2019)</ref>, asymmetric <ref type="bibr" target="#b32">(Patrini et al., 2017)</ref> and semantic <ref type="bibr" target="#b22">(Lee et al., 2019b)</ref>. The symmetric (or uniform) noise flips the latent true labelŷ i ∈ Y to any of the labels in Y (including the true label) with a fixed probability η, so η jc (</p><formula xml:id="formula_2">x i ) = η |Y|−1 , ∀j, c ∈ Y, such that j = c, and η cc (x i ) = 1 − η.</formula><p>The asymmetric noise flips the labels between semantically similar classes <ref type="bibr" target="#b32">(Patrini et al., 2017)</ref>, so η jc (x i ) is based on a transition matrix between classes j, c ∈ Y, but not on x i . The semantic noise <ref type="bibr" target="#b22">(Lee et al., 2019b)</ref> also uses an estimated transition probability between classes j, c ∈ Y, but takes into account the image x i (i.e., it is an image conditional transition probability).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">ScanMix</head><p>The gist of our proposed ScanMix <ref type="figure">(Fig. 2</ref>) method is the learning of image representations that: 1) warrant an effective clustering of images with appearance and classification similarities, 2) enable the identification of samples containing noisy labels in the training set, and 3) allow the training of accurate classifiers that are robust to the severe noisy labels in the training set. To achieve these goals, Scan-Mix training is formulated with an EM algorithm that uses a latent random variable z ji ∈ {0, 1} which indicates if a sample x j belongs to the set of K nearest neighbours (KNN) of x i , estimated with the Euclidean distance. The classifier trained by ScanMix is parameterised by θ = {ψ, φ}, and represented by</p><formula xml:id="formula_3">p θ (y|x) = p ψ (y|f φ (x)),<label>(1)</label></formula><p>where p ψ (.) ∈ [0, 1] |Y| produces a probability distribution over the classes in the classification space Y using the fea-</p><formula xml:id="formula_4">ture representation f φ (x) ∈ R d of the input image x.</formula><p>The optimal parameters for the classifier are estimated with maximum likelihood estimation (MLE):  <ref type="figure">Figure 2</ref>. Our proposed ScanMix has a pre-training stage consisting of a self-supervised training <ref type="bibr" target="#b4">(Chen et al., 2020a;</ref><ref type="bibr" target="#b10">Gansbeke et al., 2020;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref>, where we use contrastive loss to approximate features to its data augmented variants, in the feature space, while repelling representations from negative examples. In the training stage we first warm-up the classifier using a simple classification loss. Then, using the classification loss, we train the GMM to separate the samples into a clean set X and a noisy set U that are "MixMatched"  for SSL training. In parallel to this SSL training, we use the classification results and feature representations to train the semantic clustering. More details in Algorithm 1.</p><formula xml:id="formula_5">θ * = arg max θ 1 |D| (xi,yi)∈D log p θ (y i |x i ),<label>(2)</label></formula><p>where</p><formula xml:id="formula_6">log(p θ (y i |x i )) = E q(z) log p θ (y i |x i ) q(z) q(z) = ELBO (q, θ) + KL[q(z)||p θ (z|y i , x i )].<label>(3)</label></formula><p>In (3) above, we have:</p><formula xml:id="formula_7">ELBO (q, θ) = E q(z) [log(p θ (y, z|x))] − E q(z) [log(q(z))],<label>(4)</label></formula><p>with KL[·] denoting the Kullback-Leibler divergence, and q(z) representing the variational distribution that approximates p θ (z|y, x), defined as</p><formula xml:id="formula_8">p θ (z ji |x i , y i ) = (1 − y j y i )(1 − z ji )+ (y j y i )(p θ (.|x j ) p θ (.|x i )) zji (1 − p θ (.|x j ) p θ (.|x i )) (1−zji)<label>(5)</label></formula><p>where p θ (.|x) ∈ [0, 1] |Y| represents the probability classification for all classes defined in (1).</p><p>The maximisation of the log likelihood in (2) follows the EM algorithm <ref type="bibr" target="#b6">(Dempster et al., 1977)</ref> consisting of two steps. The E-step maximizes the lower bound of (3) by zeroing the KL divergence, which is achieved by setting q(z ji ) = p θ old (z ji |y i , x i ), where θ old denotes the parameter from the previous EM iteration. Then the M-step is based on the maximisation of the ELBO in <ref type="formula" target="#formula_7">(4)</ref>, which re-writes (2) as:</p><formula xml:id="formula_9">θ * = arg max θ 1 |D| (xi,yi)∈D log p θ (y i |x i )+ |D| j=1 zij ∈{0,1} q(z ji ) log p θ (z ji |y i , x i ) ,<label>(6)</label></formula><p>where the term E q(z) [log(q(z))] is removed from ELBO since it does not depend on θ (i.e., it only depends on the parameter from the previous iteration, denoted by θ old ). Hence, (6) comprises two terms: 1) the classification term that maximises the likelihood of the label y i for sample x i ; and 2) the semantic clustering term that maximises the association between samples that are close in the feature and label spaces, according to q(z ji ) estimated from the E-step.</p><p>According to the Equations 5 and 6, the run-time complexities of the terms associated with the semantic clustering in the E and M-steps are quadratic in |D|, which would make this algorithm impractical for large-scale noisy label problems. Therefore, we approximate both steps by running a self-supervised pre-training process <ref type="bibr" target="#b4">(Chen et al., 2020a;</ref><ref type="bibr" target="#b10">Gansbeke et al., 2020;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref> that forms an initial set of K nearest neighbours in the feature space f φ (x) for each training sample. The set of KNN samples for each sample</p><formula xml:id="formula_10">x i ∈ D is denoted by N xi = {x j } K j=1</formula><p>(for x j ∈ D). Then, q(z ji ) is approximated to be equal to 1, when x j ∈ N xi and y j = y i , and 0 otherwise. Such an approximation makes the run-time complexity of the E and M steps linear in D. In our formulation, the original labels of all training samples will change to the classification output produced by the model p θ (.|x) during the training for the semantic clustering term. The original labels will also change to the classification output when training the classification term for the training samples estimated to be noisy (we provide more details below).</p><p>To optimise the classification term in <ref type="formula" target="#formula_9">(6)</ref>, we rely on a semi-supervised learning approach <ref type="bibr" target="#b24">(Li et al., 2020</ref>) that minimises the following loss:</p><formula xml:id="formula_11">M LE = X + λ u U + λ r r ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_12">X = − 1 |X | (xi,ỹi)∈X ỹ i log p θ (.|x i ), U = 1 |U | (xi,ỹi)∈U ỹ i − p θ (.|x i ) 2 2 , r = KL   π |Y| 1 |X | + |U | x∈(X U ) p θ (.|x)   ,<label>(8)</label></formula><p>where λ u weights the noisy set loss, λ r weights the regularisation loss, and π |Y| denotes a vector of |Y| dimensions with values equal to 1/|Y|. Note that the loss in <ref type="formula" target="#formula_11">(7)</ref> is divided into three parts: 1) the loss X for the set X that contains the training samples estimated to have correct labels, 2) the loss U for the set U that contains the training samples estimated to have wrong labels, and 3) a regularisation to balance the classification output. The sets of augmented clean samples X and augmented noisy samples U are derived from the following stages. First, we identify label noise similarly to <ref type="bibr">Jiang et al., 2020;</ref><ref type="bibr" target="#b22">Lee et al., 2019b;</ref><ref type="bibr" target="#b24">Li et al., 2020)</ref>, where two mutually exclusive sub-sets X , U ⊆ D are formed with:</p><formula xml:id="formula_13">X = {(x i , y i ) : p (clean| i , γ) ≥ τ } , U = {(x i , y * i ) : p (clean| i , γ) &lt; τ } ,<label>(9)</label></formula><p>with τ denoting a threshold to classify a clean sample, y * i = p θ (.|x i ), i = −y i log p θ (.|x i ), and p (clean| i , γ) being a function that estimates the probability that (x i , y i ) is a clean label training sample. The function p (clean| i , γ) above is represented by a bi-modal Gaussian mixture model (GMM)s <ref type="bibr" target="#b24">(Li et al., 2020</ref>) (with γ denoting the parameters of the GMM), where the component with the larger mean denotes the noisy component and the component with smaller mean represents the clean component. Next, we run SSL <ref type="bibr" target="#b24">(Li et al., 2020)</ref>, consisting of a simple data augmentation, based on geometrical and visual transformations, to increase the number of samples in X and U. This is followed by Mix-Match ) that combines samples from both sets to form the sets X and U , which are used in (8).</p><p>To maximise the semantic clustering term in (6) we use the SCAN loss proposed in <ref type="bibr" target="#b10">(Gansbeke et al., 2020)</ref>, which is defined by</p><formula xml:id="formula_14">CLU = N + λ e e ,<label>(10)</label></formula><p>with</p><formula xml:id="formula_15">N = − 1 |D| |D| i=1 xj ∈Nx i q(z ji ) log p θ (.|x i ) p θ (.|x j ) ,<label>(11)</label></formula><p>and</p><formula xml:id="formula_16">e = c∈Y E x∼D [p(c|x, θ)] log E x∼D [p(c|x, θ)]<label>(12)</label></formula><p>that maximises the entropy of the average classification and is weighted by λ e . In (11), q(z ji ) = 1 if x i and x j have the same classification result i.e., arg max c∈Y p θ (c|x i ) = arg max c∈Y p θ (c|x j ), and x j ∈ N xi .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training and Inference</head><p>Algorithm 1 shows a detailed description of the training process that starts with a self-supervised pre-training <ref type="formula">(</ref> . Then, we warm-up the classifier by training it for a few epochs on the (noisy) training data set using cross-entropy loss. Next, we run the EM optimisation defined above using the losses in <ref type="formula" target="#formula_11">(7)</ref> and <ref type="formula" target="#formula_3">(10)</ref>. The inference uses the classifier in (1) to analyse x .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first present the data sets used in the experiments, then we provide details of the implementation of ScanMix, followed by a comparison with the SOTA methods in the field, and an ablation study of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>We evaluate our method on CIFAR-10 ( <ref type="bibr" target="#b20">Krizhevsky et al., 2009)</ref>, CIFAR-100 <ref type="bibr" target="#b20">(Krizhevsky et al., 2009)</ref>, and WebVision . The CIFAR-10 and CIFAR-100 data sets contain 50,000 training images and 10,000 test images of size 32 × 32 pixels with 10 and 100 classes respectively. Since both these data sets have been annotated with clean labels, we use synthetic noise to evaluate the models. For these data sets, we evaluate three types of noise: symmetric, asymmetric and semantic. For symmetric noise we used η ∈ {0.2, 0.5, 0.8, 0.9}, where η was defined in Sec. 3.1 as the symmetric noise probability <ref type="bibr" target="#b24">(Li et al., 2020;</ref><ref type="bibr" target="#b32">Patrini et al., 2017)</ref>. The asymmetric noise was applied to the data set, similarly to <ref type="bibr" target="#b24">(Li et al., 2020;</ref><ref type="bibr" target="#b32">Patrini et al., 2017)</ref>, which replaces the labels truck → automobile, bird → airplane, deer → horse, and cat → dog. For asymmetric noise, we use the noise rates of 40% and 49%. For the semantic noise,  <ref type="table">Table 1</ref>. Results for all competing methods on CIFAR-10 and CIFAR-100 under symmetric and asymmetric noises. Results from related approaches are as presented in <ref type="bibr" target="#b24">(Li et al., 2020)</ref>. The results with (*) were produced by locally running the published code provided by the authors. Top methods (±1%) are in bold.  <ref type="table">Table 2</ref>. Results for Semantic Noise. Results from baseline methods are as presented in <ref type="bibr" target="#b21">(Lee et al., 2019a)</ref>. The results with (*) were produced by locally running the published code provided by the authors. Top methods (±1%) are in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Test Accuracy F-correction <ref type="bibr" target="#b32">(Patrini et al., 2017)</ref> 61.12 Decoupling <ref type="bibr" target="#b29">(Malach &amp; Shalev-Shwartz, 2017)</ref> 62.54 D2L <ref type="bibr" target="#b28">(Ma et al., 2018)</ref> 62.68 MentorNet <ref type="bibr" target="#b17">(Jiang et al., 2018)</ref> 63.00 Co-teaching <ref type="bibr" target="#b12">(Han et al., 2018b)</ref> 63.58 Iterative-CV <ref type="bibr" target="#b3">(Chen et al., 2019)</ref> 65.24 DivideMix <ref type="bibr" target="#b24">(Li et al., 2020)</ref> 77.32 ScanMix (Ours) 77.72 <ref type="table">Table 3</ref>. Results for WebVision . Results from baseline methods are as presented in <ref type="bibr" target="#b24">(Li et al., 2020)</ref>.</p><p>we use the same setup from <ref type="bibr" target="#b22">(Lee et al., 2019b)</ref>, which generates semantically noisy labels based on a trained VGG (Simonyan &amp; Zisserman, 2015), DenseNet (DN) <ref type="bibr" target="#b15">(Huang et al., 2017)</ref>, and ResNet (RN) <ref type="bibr" target="#b13">(He et al., 2016)</ref> on CIFAR-10 and CIFAR-100.</p><p>We also test our method on WebVision , which is a real-world large scale data set containing 2.4 million images collected from the internet, with the same 1000 classes from ImageNet <ref type="bibr" target="#b7">(Deng et al., 2009)</ref>. As the images vary in size, we resized them to 227 × 227 pixels. WebVision provides a clean test set of 50k images, with 50 images per class. We compare our model using the first 50 classes of the Google image subset, as in <ref type="bibr" target="#b3">(Chen et al., 2019;</ref><ref type="bibr" target="#b24">Li et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation</head><p>CIFAR-10/-100 We use ResNet-18 as our backbone model following previous works <ref type="bibr" target="#b24">(Li et al., 2020)</ref>. For the self-supervised pre-training learning task, we adopt the stan-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 ScanMix (SM)</head><p>Inputs: D, number of epochs E, clean sample threshold τ // Self-supervised pre-training</p><formula xml:id="formula_17">1 f φ (x),{Nx i } |D| i=1 = PreTrain(D) // Warm Up 2 p θ (y|x) = WarmUp(D,f φ (x))</formula><p>while e &lt; E do // Estimate sets of clean and noisy samples dard SimCLR <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref> implementation with a batch size of 512, SGD optimiser with a learning rate of 0.4, decay rate of 0.1, momentum of 0.9 and weight decay of 0.0001, and run it for 500 epochs. This pre-trained model produces feature representations of 128 dimensions. Using these representations we mine K = 20 nearest neighbours (as in <ref type="bibr" target="#b10">(Gansbeke et al., 2020)</ref>) for each sample to form the sets {N xi } |D| i=1 , defined in Sec. 3.2. For the semantic clustering task, we use a batch size of 128, λ e = 2 as in <ref type="bibr" target="#b10">(Gansbeke et al., 2020)</ref>, SGD optimiser with momentum of 0.9, weight decay of 0.0005 and learning rate ∈ {0.001, 0.00001} based on the predicted noise rate. More specifically, we predict this noise rate with |U|/|D|, defined in (9) -if this ratio is larger than 0.6, then the learning rate is 0.001, otherwise, the learning rate is 0.00001. This accounts for the fact that when the estimated label noise is high, then we want to increase the influence of semantic clustering in the training; but when the label noise is low, then the signal from the labels in the SSL method should carry more weighting. For the SSL, we adopt the implementation of <ref type="bibr" target="#b24">(Li et al., 2020)</ref> and use the same hyperparameters, where we rely on SGD with learning rate of 0.02 (which is reduced to 0.002 halfway through the training), momentum of 0.9 and weight decay of 0.0005. Number of epochs E = 300.</p><formula xml:id="formula_18">3 for i = {1, ..., |D|} do 4 Estimate p(clean| i, γ), with i = −y i log p θ (.|xi) 5 end 6 X , U=FormCleanNoisySets({p(clean| i, γ)} |D| i=1 , τ ) 7 X , U =MixMatch(X , U) // E-step 8 for (xi, yi) ∈ D do 9ỹi = arg maxc∈Y p θ (c|xi)</formula><p>WebVision We use InceptionResNet-V2 as our backbone model following previous works <ref type="bibr" target="#b24">(Li et al., 2020)</ref>. For the self-supervised pre-training task we adopt the standard MoCo-v2 method for a 4-GPU training <ref type="bibr" target="#b5">(Chen et al., 2020b)</ref> with a batch size of 128, SGD optimiser with a learning rate of 0.015, momentum of 0.9 and weight decay of 0.0001, and run it for 500 epochs. The feature representations learned from this process have 128 dimensions. All the other parameters were the same as described above for CIFAR, except the batch size of semantic clustering task was 64, and number of epochs E = 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with State-of-the-Art</head><p>We compare ScanMix with several existing methods using the data sets described in Sec. 4.1. For CIFAR-10 and CIFAR-100, we evaluate the models using different levels of symmetric label noise, ranging from 20% to 90% and asymmetric noise rates of 40% and 49%. We report both the best test accuracy across all epochs and the averaged test accuracy over the last 10 epochs of training. <ref type="table">Table 1</ref> summarizes the results for CIFAR-10 and CIFAR-100 data sets. Results show that our method significantly outperforms the previous methods under severe label noise. Specifically, we observe an increase of roughly +15% for CIFAR-10 with 90% symmetric noise, +5% for CIFAR-10 with 49% asymmetric noise, +27% for CIFAR-100 with 90% symmetric noise and +6% for CIFAR-100 with 80% symmetric noise. These results demonstrate that our proposal of simultaneously performing semantic clustering and SSL does make the model more robust to noisy labels than previous methods, particularly for severe label noise. <ref type="table">Table 2</ref> shows the ability of our method to handle semantic noise, which can be regarded as a much harder type of label noise. For CIFAR-10, our method shows a consistent improvement of around 4% to 5% with respect to the result of our evaluation of DivideMix. For CIFAR-100, Scan-Mix is slightly better. Given the smaller noise rates in this benchmark, these results are expected, or even surprising for CIFAR-10. It is important to note that the previous SOTA of the field was RoG <ref type="bibr" target="#b22">(Lee et al., 2019b)</ref> and ScanMix is better by a large margin of 12% to 20%.</p><p>We also evaluate ScanMix on the noisy large-scale data set WebVision. <ref type="table">Table 3</ref> shows the Top-1 test accuracy of all methods. Results show that ScanMix is only slightly better than the SOTA, which we believe is due to the relatively low rate of label noise in this data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>We show the results of the ablation study of ScanMix in <ref type="table">Table 4</ref>. Using classification accuracy in the testing set of CIFAR-10 and CIFAR-100 under symmetric and asymmetric noises at several rates, we aim to show the influence  <ref type="bibr" target="#b10">(Gansbeke et al., 2020)</ref> 77.5 77.5 77.5 77.5 77.5 77.5 37.1 37.1 37.1 37.1 SSL (DivideMix) <ref type="bibr" target="#b24">(Li et al., 2020)</ref> 96.  <ref type="table">Table 4</ref>. In this ablation study we show the classification accuracy in the testing set of CIFAR-10 and CIFAR-100 under symmetric and asymmetric noises at several rates. First, we show the results of self-supervised pre-training using the current SOTA SCAN <ref type="bibr" target="#b10">(Gansbeke et al., 2020)</ref> (first two rows, with the results with (*) produced by locally running the published code provided by the authors). Then we show the current SOTA SSL learning for noisy label DivideMix <ref type="bibr" target="#b24">(Li et al., 2020)</ref>. Next, we show the results of DivideMix pre-trained with SCAN. The last row shows our ScanMix that combines SSL and semantic clustering. The top results (±1%) are in bold. of self-supervised training by itself or in combination with SSL. For self-supervised learning, we use the current SOTA method, SCAN <ref type="bibr" target="#b10">(Gansbeke et al., 2020)</ref>, displayed in the first two rows, with the first row containing the published results, and the second, our replicated results using the authors' code. The result is the same across different noise rates because it never uses the noisy labels for training. Using the pure SSL method, DivideMix <ref type="bibr" target="#b24">(Li et al., 2020)</ref>, which is the current SOTA in noisy label learning, we see that it has much better results for low noise levels, but SCAN is better for severe label noise. When using SCAN for pretraining DivideMix, we note that results become quite good for all types and levels of noise. Neverthless, our ScanMix improves the results of SCAN + DivideMix, showing the efficacy of ScanMix, which combines SSL with semantic clustering.</p><p>We also show the distribution of losses produced by Scan-Mix and DivideMix at one of the early epochs of training for CIFAR-10 and CIFAR-100 affected by 90% label noise in <ref type="figure" target="#fig_2">Figure 3</ref>. Note that the regime of semantic clustering combined with SSL in ScanMix enables a much clearer separation between the clean (green bars) and noisy (blue bars) samples, when compared with the distribution produced by DivideMix. Such clearer separation will help the classification of clean samples in <ref type="formula" target="#formula_13">(9)</ref>, which in turn will improve the performance of the SSL in <ref type="formula" target="#formula_11">(7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this work we presented ScanMix, a novel training strategy to address severe label noise via semantic clustering and semi-supervised learning. We compared our model to SOTA methods on severe noise rate scenarios for CIFAR-10 and CIFAR-100 and also on the large-scale data set WebVision. Results showed that our proposed ScanMix outperformed SOTA methods, with 27% improvement for 90% symmetric noise on CIFAR-100 and 15% on CIFAR-10. Our approach also produced superior results for asymmetric and semantic noise, which are regarded to be much more challenging noise types. The results showed that the semantic clustering is crucial to deal with severe noise rate and semantic noise.</p><p>We also attempted to test ScanMix on the Clothing1M <ref type="bibr" target="#b40">(Xiao et al., 2015)</ref> data set. The preliminary results we observed were competitive but slightly worse than the SOTA. Ultimately, the comparison between ScanMix and other methods in the field for Clothing1M is unfair to us given the experimental setup used by previous approaches. Due to the large size of the data set, the previous methods train by random selecting a subset of the full training set at each epoch. This means that they effectively can access the whole training set after a number of epochs. However, ScanMix needs a fixed training set given the need to form the nearest neighbors sets {N xi } |D| i=1 after pre-training. Due to memory limitations we had to restrict the training to use only about 10% of the training set of Clothing1M <ref type="bibr" target="#b40">(Xiao et al., 2015)</ref>, unlike previous methods which had unrestricted access to the entire data set. This discrepancy in the experimental setup makes it difficult for us to meaningfully compare our method with existing works. We plan to investigate ways to mitigate this issue, so we can have a fair comparison between ScanMix and the SOTA in the field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc><ref type="bibr" target="#b4">Chen et al., 2020a;</ref><ref type="bibr" target="#b10">Gansbeke et al., 2020;</ref><ref type="bibr" target="#b14">He et al., 2019)</ref> which optimises the parameters of the feature extractor f φ (x) using only the images of D and defines the set of KNNs for each training sample{N xi } |D| i=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>16</head><label></label><figDesc>10 q(zji) = 0, ∀j ∈ {1, ..., |D|} for xj ∈ Nx i do 11ỹj = arg maxc∈Y p θ (c|xj) if (ỹi ==ỹj)Estimate θ = {ψ, φ} by minimising:M LE in (7) using X , U , and CLU in (10) using {Nx i }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Per-sample normalised loss distributions of the training set produced in the early stages of the training by our ScanMix (left) and DivideMix (Li et al., 2020) (right) for CIFAR-10 (top) and CIFAR-100 (bottom) affected by 90% label noise, where green bars represent the clean samples and blue bars the noisy samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>1 94.6 93.2 76.0 93.4 83.7* 77.3 74.6 60.2 31.5</figDesc><table><row><cell>Self-superv. pre-train + SSL (DivideMix)*</cell><cell>95.3 94.4 93.7 91.0 93.3 85.9</cell><cell>75.2 74.4 64.4 52.8</cell></row><row><cell>ScanMix (Ours)</cell><cell>96.0 94.5 93.5 91.0 93.7 88.6</cell><cell>77.0 75.7 66.0 58.5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">University of Adelaide, Adelaide, Australia 2 Universidade Federal Rural de Pernambuco, Recife, Brazil 3 Universitat Ulm, Ulm, Germany.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>MIR Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixmatch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<title level="m">A Holistic Approach to Semi-Supervised Learning. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixmatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5049" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05040</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simple</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<title level="m">Framework for Contrastive Learning of Visual Representations. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2020-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Baselines with Momentum Contrastive Learning. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2020-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A semisupervised two-stage approach to learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frénay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="845" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">V</forename><surname>Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scan</surname></persName>
		</author>
		<title level="m">Learning to classify images without labels</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Pumpout: A meta approach for robustly training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<title level="m">Momentum Contrast for Unsupervised Visual Representation Learning. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2019-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Photometric transformer networks and label adjustment for breast density prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jaehwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Donggeun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hyo-Eun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Beyond synthetic noise: Deep learning on controlled noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nlnl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Robust inference via generative classifiers for handling noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11300</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Robust inference via generative classifiers for handling noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11300</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dividemix</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07394</idno>
		<title level="m">Learning with Noisy Labels as Semi-supervised Learning. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2020-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Webvision database: Visual learning and understanding from web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">WebVision Database: Visual Learning and Understanding from Web Data. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2017-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A A</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dimensionality-driven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3355" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Decoupling&quot; when to update&quot; from&quot; how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="960" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Label noise-robust boosting algorithm based on a nonconvex loss function and the numerically stable base learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rboost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2216" to="2228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.08741</idno>
		<title level="m">Towards robust learning with different label noise distributions</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09050</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4334" to="4343" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shavit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10694</idno>
		<title level="m">Deep Learning is Robust to Massive Label Noise. arXiv eprints, art</title>
		<imprint>
			<date type="published" when="2017-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tam</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mummadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Phuong Nhung Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hoai Phuong Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Beggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Self</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01842</idno>
		<title level="m">Learning to Filter Noisy Labels with Self-Ensembling. arXiv e-prints, art</title>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Imae for noise-robust learning: Mean absolute error does not treat examples equally and gradient magnitude&apos;s variance matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12141</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">1903</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning with biased complementary labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="68" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">How does disagreement help generalization against label corruption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04215</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Iterative cross learning on noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcmains</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="757" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning to hallucinate clean representations for noisy-labeled visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metacleaner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7373" to="7382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Distilling effective supervision from severe label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9294" to="9303" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
