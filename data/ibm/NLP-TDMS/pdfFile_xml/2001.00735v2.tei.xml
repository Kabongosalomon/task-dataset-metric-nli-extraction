<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Trajectory Forecasts in Unknown Environments Conditioned on Grid-Based Plans</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Mohan</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
						</author>
						<title level="a" type="main">Trajectory Forecasts in Unknown Environments Conditioned on Grid-Based Plans</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We address the problem of forecasting pedestrian and vehicle trajectories in unknown environments, conditioned on their past motion and scene structure. Trajectory forecasting is a challenging problem due to the large variation in scene structure and the multimodal distribution of future trajectories. Unlike prior approaches that directly learn one-to-many mappings from observed context to multiple future trajectories, we propose to condition trajectory forecasts on plans sampled from a grid based policy learned using maximum entropy inverse reinforcement learning (MaxEnt IRL). We reformulate MaxEnt IRL to allow the policy to jointly infer plausible agent goals, and paths to those goals on a coarse 2-D grid defined over the scene. We propose an attention based trajectory generator that generates continuous valued future trajectories conditioned on state sequences sampled from the MaxEnt policy. Quantitative and qualitative evaluation on the publicly available Stanford drone and NuScenes datasets shows that our model generates trajectories that are diverse, representing the multimodal predictive distribution, and precise, conforming to the underlying scene structure over long prediction horizons.</p><p>Index Terms-multimodal trajectory forecasting, maximum entropy inverse reinforcement learning</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trajectory Forecasts in Unknown Environments</head><p>Conditioned on Grid-Based Plans Nachiket Deo, and Mohan M. Trivedi, Fellow, IEEE Abstract-We address the problem of forecasting pedestrian and vehicle trajectories in unknown environments, conditioned on their past motion and scene structure. Trajectory forecasting is a challenging problem due to the large variation in scene structure and the multimodal distribution of future trajectories. Unlike prior approaches that directly learn one-to-many mappings from observed context to multiple future trajectories, we propose to condition trajectory forecasts on plans sampled from a grid based policy learned using maximum entropy inverse reinforcement learning (MaxEnt IRL). We reformulate MaxEnt IRL to allow the policy to jointly infer plausible agent goals, and paths to those goals on a coarse 2-D grid defined over the scene. We propose an attention based trajectory generator that generates continuous valued future trajectories conditioned on state sequences sampled from the MaxEnt policy. Quantitative and qualitative evaluation on the publicly available Stanford drone and NuScenes datasets shows that our model generates trajectories that are diverse, representing the multimodal predictive distribution, and precise, conforming to the underlying scene structure over long prediction horizons.</p><p>Index Terms-multimodal trajectory forecasting, maximum entropy inverse reinforcement learning I. INTRODUCTION Autonomous vehicles need to operate in a space shared with humans and human driven vehicles. In order to plan safe and efficient paths through complex traffic, autonomous vehicles need the ability to reason about the intent and future motion of surrounding agents. We address the problem of predicting the future locations of pedestrians and vehicles, conditioned on their track history and a bird's eye view representation of the static scene around them. In particular, we wish to forecast trajectories in unknown environments, where prior observations of trajectories are unavailable. This is a challenging task due to a number of factors:</p><p>• Unknown goals and path preferences: Without prior observations of agent trajectories in a scene, goals and path preferences of agents need to be inferred purely from the scene layout. • Scene-compliance: Additionally, the predicted trajectories need to conform to the inferred goals and paths in the scene layout. • Variability in scene structure: Scene elements such as roads, sidewalks, crosswalks and buildings can be found in a variety of configurations. Thus there's high variability in the inputs to the trajectory forecasting model. horizons, leading to highly non-linear trajectories. Thus, there's high variability in the outputs of the trajectory forecasting model. • Multimodality: Finally, the distribution of future trajectories is multimodal. In any given scene, an agent can have one of multiple potential goals, with multiple paths to each goal. Regression based approaches have been shown to average the modes of the predictive distribution <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. This would lead to trajectory forecasts that may not conform to the underlying scene.</p><p>Recent work has addressed multimodality of the distribution of future trajectories by learning one-to-many mappings from input context to multiple trajectories. Mixture models <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b10">[10]</ref> assign a mixture component to each mode of the trajectory distribution. They output mean trajectories and probabilities for each mixture component, along with prediction uncertainty. Alternatively, conditional generative models <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[11]</ref>- <ref type="bibr" target="#b16">[16]</ref> map input context and a sample from a simple latent distribution to a trajectory output. They can be sampled from indefinitely, to output multiple trajectories. Both, conditional generative models and mixture models need to learn a mapping from a high dimensional input space (variable scene and agent configuration) to a high dimensional output space (continuous valued trajectories). Several recent works thus incorporate inductive bias into the predicted modes by conditioning on agent goals <ref type="bibr" target="#b17">[17]</ref>- <ref type="bibr" target="#b19">[19]</ref>, lane center-lines <ref type="bibr" target="#b20">[20]</ref>- <ref type="bibr" target="#b22">[22]</ref> or anchor trajectories <ref type="bibr" target="#b23">[23]</ref>, <ref type="bibr" target="#b24">[24]</ref>.</p><p>Another set of approaches <ref type="bibr" target="#b25">[25]</ref>- <ref type="bibr" target="#b29">[28]</ref> pioneered by Ziebart et al. <ref type="bibr" target="#b25">[25]</ref>, model agents as Markov decision processes (MDPs) exploring a 2-D grid defined over the scene. A reward map for the MDP is learned via maximum-entropy inverse reinforcement learning (MaxEnt IRL) <ref type="bibr" target="#b30">[29]</ref>. MDPs are naturally suited to model the agent's sequential decision making. Additionally, since the reward is learned from local scene cues at each grid location, it can be transferred to unknown scenes with a different configuration of scene elements. However, MaxEnt IRL approaches suffer from two limitations: First, they require a pre-defined absorbing goal state, limiting them to applications where goals of agents are known beforehand. As opposed to this, we need to infer goals of agents. Second, they only provide future locations of the agent in the grid, without mapping them to specific times 1 . This does not take into account the agent's dynamics.</p><p>In this work, we seek to leverage the transferability of grid based MaxEnt IRL approaches, while allowing for sampling of continuous valued trajectories similar to conditional generative <ref type="figure">Fig. 1</ref>: Forecasts generated by P2T: We address the problem of forecasting agent trajectories in unknown environments. The inputs to our model (left) are snippets of the agents' past trajectories, and a bird's eye view representation of the scene around them. Our model infers potential goals of the agents (left-middle) and paths to these goals (middle) over a coarse 2-D grid defined over the scene by modeling the agent as a MaxEnt policy exploring the grid. It generates continuous valued trajectories conditioned on the grid-based plans sampled from the policy (middle-right). Finally it outputs K predicted trajectories by clustering the sampled trajectories (right). models. We present P2T (Plans-to-Trajectories), a planning based approach to generate long-term trajectory forecasts in unknown environments. In particular, our approach relies on two key ideas. 1) Joint inference of goals and paths by learning rewards: We reformulate the maximum entropy inverse reinforcement learning framework to learn transient path state rewards and terminal goal state rewards. Our reformulation allows for joint inference of goals, and paths to goals. This alleviates the need for a pre-defined absorbing goal state in the original formulation <ref type="bibr" target="#b30">[29]</ref>. 2) Trajectories conditioned on plans: We refer to state sequences sampled from the MaxEnt policy as plans.</p><p>We propose an attention based trajectory generator that outputs continuous valued trajectories conditioned on sampled plans, rather than a latent variable. Compared to conditional generative models, our model outputs trajectories that better conform to the underlying scene over longer prediction horizons. Additionally, the state sequences of the MaxEnt policy allow for better interpretability compared to the latent space of a conditional generative model <ref type="figure">Figure 1</ref> shows forecasts generated by P2T for two example scenarios from the NuScenes <ref type="bibr" target="#b31">[30]</ref> (top row) and Standord drone <ref type="bibr" target="#b32">[31]</ref> (bottom row) datasets. Our model infers potential goals of the agent and paths to these goals over a coarse 2-D grid defined over the scene. We visualize these goals and paths using state visitation frequencies of our MaxEnt policy. We note that the goals and paths conform to the underlying scene, and past motion of the agent, and that the state distribution of the MaxEnt policy is multimodal. We observe that the continuous valued trajectories generated by our model conform to the grid-based plans sampled from the policy. Finally, we cluster the sampled trajectories from the model to give K trajectories to be used by a downstream planner. We evaluate our model on two publicly available trajectory datasets: the Stanford drone dataset <ref type="bibr" target="#b32">[31]</ref> (SDD) consisting of pedestrians, bicyclists, skateboarders and slow moving vehicles at various locations on a university campus, and the NuScenes dataset <ref type="bibr" target="#b33">[32]</ref> consisting of vehicles navigating complex urban traffic. We report results in terms of minimum over K average displacement error (MinADE K ), final displacement error (MinFDE K ) and miss rate (MR K ) metrics reported in prior work <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b21">[21]</ref>, as well as sample quality metrics such as off-road rate <ref type="bibr" target="#b34">[33]</ref> and offyaw rate <ref type="bibr" target="#b35">[34]</ref>. Our model achieves state of the art results on several metrics, while being competitive on others. In particular, it significantly outperforms existing approaches in terms of sample quality metrics, forecasting trajectories that are both diverse as well as precise. We make our code publicly available at https://github.com/nachiket92/P2T.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRELIMINARIES</head><p>In this section, we briefly review maximum entropy inverse reinforcement learning (MaxEnt IRL) for path forecasting, conditioned on pre-defined goal states <ref type="bibr" target="#b25">[25]</ref>- <ref type="bibr" target="#b27">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MDP formulation:</head><p>We consider a Markov decision process M = {S, A, T , r}, for a finite horizon setting with N steps. S is the state space consisting of cells in a 2-D grid defined over the scene. A is the action space consisting of 4 discrete actions, {up, down, left, right}, to move to adjacent cells. We assume deterministic dynamics, where T : S × A → S is the state transition function. Finally, r : S → R − 0 is the reward function mapping each state to a real value less than or equal to 0. We assume that the initial state s init and the goal state s goal of the MDP are known.</p><p>MaxEnt IRL objective: Under the maximum entropy distribution, the probability of observing a state action sequence τ = {(s 1 , a 1 ), (s 2 , a 2 ), . . . (s N , a N )} is proportional to the exponential of its reward.</p><formula xml:id="formula_0">P (τ ) = 1 Z exp (r(τ )) = 1 Z exp N i=1 r(s i ) ,<label>(1)</label></formula><p>where Z the normalizing constant. MaxEnt IRL involves learning a reward function r θ (s) parametrized by a set of parameters θ, operating on a set of features extracted for each state s. The objective is to learn a reward function that maximizes the log likelihood of observing a training set of</p><formula xml:id="formula_1">demonstrations T = {τ 1 , τ 2 , . . . τ K } arg max θ L θ = arg max θ τ ∈T log 1 Z θ exp(r θ (τ )) .<label>(2)</label></formula><p>This can be solved using stochastic gradient descent, with the gradient of the log likelihood L θ simplifying to</p><formula xml:id="formula_2">dL θ dθ = τ ∈T (D τ − D θ ) dr θ dθ ,<label>(3)</label></formula><p>where, D τ are the state visitation frequencies (SVFs) for the training demonstration τ and D θ are the expected SVFs for the MaxEnt policy given the current set of reward parameters θ. If a deep neural network is used to model the reward function r θ (s), dr θ dθ can be obtained using backpropagation as described in <ref type="bibr" target="#b36">[35]</ref>. D θ is obtained using Algorithm 1 and Algorithm 2.</p><p>Approximate value iteration: Algorithm 1 involves solving for the MaxEnt policy π θ , given the current reward function r θ , and the goal state s goal . π θ represents the probability of taking action a, given state s. The policy can be stationary, ie., independent of the time step π θ (a|s), or non-stationary π (n) θ (a|s). We use a non-stationary policy as used in <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b38">[37]</ref>. Algorithm 1 involves iterative updates of the state and action log partition functions V (s) and Q(s, a). These can be interpreted as soft estimates of the expected future reward given state s and the expected future reward given state-action pair (s, a) respectively. V (s) is initialized to 0 for s goal and −∞ for all other states. V (s) and Q(s, a) are then iteratively updated over N steps, while holding V (s goal ) fixed at 0. For each step, π θ is given by</p><formula xml:id="formula_3">π (n) θ (a|s) = exp Q (n) (s, a) − V (n) (s) .<label>(4)</label></formula><p>Holding V (s goal ) fixed to 0, while initializing all other V (s) values to −∞ ensures that the MDP ends at s goal .</p><p>Policy propagation: Algorithm 2 involves calculating the SVFs. It involves repeatedly applying π θ for N steps, starting with the initial state distribution, to give SVF at each step. The SVF corresponding to the goal state is set to 0 at each step, since the goal state absorbs any probability mass that reaches it. The expected SVF D θ is obtained by summing the SVFs over the N steps.</p><formula xml:id="formula_4">Algorithm 1 Approx. value iteration (goal conditioned) Inputs: r θ , s goal 1: V (N ) (s) ← −∞, ∀s ∈ S 2: for n = N, ..., 2, 1 do 3: V (n) (s goal ) ← 0 4: Q (n) (s, a) = r θ (s) + V (n) (s ), s = T (s, a) 5: V (n−1) (s) = logsumexp a Q (n) (s, a) 6: π (n) θ (a|s) = exp Q (n) (s, a) − V (n) (s) 7: end for Algorithm 2 Policy propagation (goal conditioned) Inputs: π θ , s init , s goal 1: D (1) (s) ← 0, ∀s ∈ S 2: D (1) (s init ) ← 1 3: for n = 1, 2..., N do 4: D (n) (s goal ) ← 0 5: D (n+1) (s) = s ,a π (n) θ (a|s )D (n) (s ), T (s , a) = s 6: end for 7: D(s) = n D (n) (s)</formula><p>Path forecasting conditioned on goals: The MaxEnt policy π * θ , for the converged reward model r θ , can be sampled from, to give path forecasts on the 2-D grid from the s init to s goal . Since π * θ is stochastic, the policy can explore multiple paths within the scene to the goal state. However, for most cases of pedestrian or vehicle trajectory forecasting, s goal is unknown, and needs to be inferred. Additionally, sampling π * θ only provides future paths, without mapping them to specific times. A step for the MDP need not correspond to a fixed time interval. Different agents can have different speeds. Agents can also accelerate or decelerate over the course of the 10s prediction horizon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED APPROACH</head><p>We leverage the transferability of grid based MaxEnt IRL, while not requiring knowledge of s goal , and generate continuous valued trajectories, mapped to specific times in the future. <ref type="figure" target="#fig_1">Figure 2</ref> provides an overview of P2T, our proposed approach. P2T consists of three components.</p><p>The first component is a reward model, comprised by convolutional and pooling layers. At each cell on a coarse 2-D grid, the reward model maps local scene context and motion features capturing the agent's track history, to a transient path state reward and a terminal goal state reward. We describe the reward model in greater detail in section III-B.</p><p>The next component is a MaxEnt policy independent of pre-defined goal states. We reformulate MaxEnt IRL to allow for inference of goal and path states, given the path and goal rewards learned by the reward model (see section III-A). We obtain a single policy that can be sampled to generate paths to different plausible goals on the 2-D grid. We refer to each state sequence sampled from the policy as a plan. The final component of P2T is an attention based trajectory generator, that outputs continuous valued trajectories conditioned on the sampled plans. The trajectory generator encodes the track history of the agent using a gated recurrent unit (GRU), and the sampled plans using a bidirectional GRU (BiGRU). Finally, a GRU decoder equipped with soft-attention <ref type="bibr" target="#b39">[38]</ref>, attends to the plan encoding to output trajectories over the prediction horizon. Section III-C describes the trajectory generator in greater detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Inferring goals and paths by learning rewards</head><p>We wish to relax the requirement of prior knowledge of s goal in MaxEnt IRL. Certain locations in a scene are likelier to be goals of agents. For pedestrians, these can be points where paths and sidewalks exit the scene, entrances to buildings, or parked cars. For vehicles, these can be points where lanes exit the scene, stop signs or parking lots. Goals are also likelier to be along the direction of the agent's motion. Rather than always terminating at a predefined goal, we would like our policy to induce a distribution over possible goal states. This would allow us to sample paths from the policy terminating at different goals in the scene. We propose to do this by learning path and goal state rewards, conditioned on the scene and past motion of the agent, and learning a policy unconstrained by s goal . We reformulate the MDP and modify the approximate value iteration algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MDP formulation:</head><p>• State space: Potentially any cell location on the 2-D grid could be the goal of the agent, or a point on their future path. We define the state space S = {S p , S g }. S p is the set of path states and S g is the set of goal states. Each cell location on the 2-D grid has an associated path state belonging to S p and a goal state belonging to S g . The policy terminates on reaching any goal state.</p><p>• Action space: A = {up, down, left, right, end}. The up, down, left and right actions allow transitions from path states to adjacent path states. Additionally, we define an end action that transitions the MDP from a path state to the goal state at the same cell location.</p><p>• Transition function: T : S p × A → S maps path state and action pairs to other path states and goal states. Since goal states are terminal, the MDP has no transitions out of a goal state.</p><p>• Rewards: We learn two functions, r p θ corresponding to path rewards, and r g θ corresponding to goal rewards.</p><p>Approximate value iteration with inferred goals: Algorithm 3 depicts our modified approximate value iteration, unconstrained on s goal . Unlike algorithm 1, we do not hold the V (s goal ) fixed at 0 to enforce goal directed behavior. Instead, we use r g θ to learn a policy that induces a multimodal distribution over potential goal states. The inputs to algorithm 3 are the learned rewards r g θ and r p θ . We initialize V (s) to −∞ for all path states S p . This is because we want the MDP to end up at some goal state within the N step finite horizon.</p><p>Since the goal states are terminal, the MDP receives the goal rewards only once. We thus hold V (s) fixed to r g θ (s) for all goal states S g . We then iteratively update the state-action log partition function Q (n) (s, a) and the state log partition function V (n) (s) for the path states S p over N steps. At the end of each step, the MaxEnt policy is obtained by taking the ratio of the exponent of Q (n) (s, a) and V (n) (s).</p><p>Policy propagation with inferred goals: Algorithm 4 depicts policy propagation independent of s goal . This is almost identical to algorithm 2. The only difference is, we do not set the goal state SVFs to 0, as in line 4 of algorithm 2. This is because we use the goal SVFs to train the reward model for r g θ , using equation <ref type="formula" target="#formula_2">(3)</ref>. We use a frame of reference centered at the agent's location at the time of prediction. Thus, s init is always the path state at the center of the grid.</p><p>Algorithm 3 Approx. value iteration (inferred goals)</p><formula xml:id="formula_5">Inputs: r g θ , r p θ 1: V (N ) (s) ← −∞, ∀s ∈ S p 2: for n = N, ..., 2, 1 do 3: V (n) (s) ← r g θ (s), ∀s ∈ S g 4: Q (n) (s, a) = r p θ (s) + V (n) (s ), ∀s ∈ S p , s = T (s, a) 5: V (n−1) (s) = logsumexp a Q (n) (s, a), ∀s ∈ S p 6: π (n) θ (a|s) = exp Q (n) (s, a) − V (n) (s) 7: end for</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4 Policy propagation (inferred goals)</head><p>Inputs: π θ , s init</p><formula xml:id="formula_6">1: D (1) (s) ← 0, ∀s ∈ S 2: D (1) (s init ) ← 1 3: for n = 1, 2..., N do 4: D (n+1) (s) = s ,a π (n) θ (a|s )D (n) (s ), T (s , a) = s 5: end for 6: D(s) = n D (n) (s)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Reward model</head><p>We define a reward model consisting purely of convolutional and pooling layers. This allows us to learn a mapping from local patches of the scene to path and goal rewards. The equivariance of the convolutional layers allows the reward model to be transferred to novel scenes with a different configuration of scene elements. <ref type="figure" target="#fig_2">Figure 3</ref> shows our reward model. It consists of three sets of convolutional layers.</p><p>CNN f eat serves as a scene feature extractor, operating on the birds eye view representation I of the static scene around the agent:</p><p>φ I = CNN f eat (I) .</p><p>The spatial dimensions of the scene features φ I equal the size of the 2-D grid corresponding to our state space S. In addition to scene features, we want our goal and path rewards to depend on the past motion of the agent. Thus, similar to Zhang et al. <ref type="bibr" target="#b29">[28]</ref>, we concatenate the scene features with feature maps encoding the agent's motion, and the locations of the grid cells:</p><formula xml:id="formula_8">φ M = [|v|, x, y] .<label>(6)</label></formula><p>Here, |v| is the speed of the agent. This value is replicated over the entire feature map. x and y are the locations of each grid cell in the agent-centric frame of reference, with the origin at the agent's current location and the x-axis aligned along the agent's current direction of motion. CNN p and CNN g map the scene and motion features to path and goal rewards respectively:  This downsamples the spatial dimension of the feature maps to 50 × 50. This is followed by a 2 × 2 convolutional layer with depth 32 and stride 2, to aggregate context at each cell location. This gives 32 scene feature maps over a 25 × 25 grid. CNN p and CNN g have identical architectures consisting of two 1 × 1 convolutional layers. The first layer has depth 32, and the second layer has depth 1 to give a single path or goal reward value at each cell. We apply the log-sigmoid activation at the outputs of CNN p and CNN g to restrict reward values between −∞ and 0. The reward model is trained to maximize the log-likelihood L θ of agent paths in the train set shown in equation <ref type="formula" target="#formula_1">(2)</ref>, with gradients given by equation <ref type="formula" target="#formula_2">(3)</ref>. The state visitation frequencies D θ for both path and goal states are obtained using algorithms 3 and 4. We use Adam <ref type="bibr" target="#b41">[40]</ref> with learning rate 0.0001 to train the reward model.</p><formula xml:id="formula_9">r p θ = CNN p (φ I , φ M ) .<label>(7)</label></formula><formula xml:id="formula_10">r g θ = CNN g (φ I , φ M ) .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Trajectories conditioned on plans</head><p>Consider the optimal MaxEnt policy π * θ obtained using algorithm 3 for the converged reward model. Consider state sequences or plans sampled from π * θ , with the i th plan given by</p><formula xml:id="formula_11">s (i) = s (i) 1 , s (i) 2 , . . . , s (i) N .<label>(9)</label></formula><p>We expect the sampled plans to end at a diverse set of goal states, and explore various paths to these goals. Additionally, each plan S (i) can be expected to conform to the underlying scene and model the agent's sequential decision making. However, the plans by themselves do not capture the dynamics of the agent's motion. A fast moving agent can make more progress along a plan compared to a slow moving agent over a fixed prediction horizon T f . The dynamics of the agent's motion can be estimated using a snippet of their most recent track history, over time T h ,</p><formula xml:id="formula_12">x = [x −T h , . . . , x 1 , x 0 ] ,<label>(10)</label></formula><p>where the x t 's correspond to past location, velocity, acceleration and yaw-rate of the agent, with the subscript t representing time and t = 0 the prediction instant.</p><p>We thus seek a model that, for each sampled plan s (i) , and track history x, generates a continuous valued trajectory y (i) over a prediction horizon T f ,</p><formula xml:id="formula_13">y (i) = y (i) 1 , y (i) 2 , . . . , y (i) T f ,<label>(11)</label></formula><p>where y t is the future location of the agent at time t. We propose a trajectory generator modeled as a recurrent neural network encoder-decoder, equipped with soft attention <ref type="bibr" target="#b39">[38]</ref>.</p><p>The trajectory generator has the following components.</p><p>• Motion encoder: We encode the track history x using a GRU encoder, where the state of the GRU at time t is given by</p><formula xml:id="formula_14">h mt = GRU m h mt−1 , e x (x t ) .<label>(12)</label></formula><p>Here e x (·) is a fully connected embedding layer. The GRU state at the prediction instant, h m0 , can be expected to encode the motion of the agent.</p><p>• Plan encoder: The plan encoder ( <ref type="figure">Fig. 4)</ref>  n in a sampled plan s (i) , we embed the scene features, agent states and location co-ordinates at the grid cell corresponding to s (i) n , using fully connected layers and concatenate the outputs to give the state encoding φ s s (i) n . We use a bidirectional GRU (BiGRU) encoder to aggregate the state encodings over the entire plan. The state of the BiGRU at step n is given by</p><formula xml:id="formula_15">h (i) sn = BiGRU s h (i) sn−1 , h (i) sn+1 , φ s s (i) n .<label>(13)</label></formula><p>• Attention based decoder: We use a GRU decoder equipped with a soft attention module to generate the output trajectories y (i) . Our core idea is to allow the decoder to attend to specific states of the sampled plan s (i) as it generates trajectories along the plan. Thus, the decoder can attend to just the first few states of sampled plans, as it generates the future trajectories for a slow moving agent. On the other hand, it can attend to later states while generating a fast moving agent's trajectories. We initialize the state of the decoder using the final state of the motion encoder,</p><formula xml:id="formula_16">h dec1 = h m0 .<label>(14)</label></formula><p>This provides the decoder a representation of the agent's motion. The decoder state is then updated over the prediction horizon, with the outputs at each time-step giving the predicted locations.</p><formula xml:id="formula_17">h (i) dect = GRU dec h (i) dect−1 , Att h (i) dect−1 , h (i) s 1:N ,<label>(15)</label></formula><formula xml:id="formula_18">y (i) t = o y (h (i) dect ),<label>(16)</label></formula><p>where Att(·) is the attention module and o y (·) is a fully connected layer operating on the decoder states. <ref type="figure">Fig. 4</ref>: Plan encoder: For each state in a sampled plan, we encode the scene features, surrounding agent states and the location co-ordinates of the grid cell and term it φ S (s). This is then fed into bidirectional GRU to encode the the entire sampled plan. Our GRU decoder generates output trajectories by attending to the plan encoding.</p><p>Sampling and clustering: The trajectory generator outputs a trajectory conditioned on each sampled plan. This allows us to indefinitely sample trajectories from our model. Since the MaxEnt policy induces a multimodal distribution over path and goal states, the sampled trajectories also represent a multimodal predictive distribution. However, sampling by itself can be inefficient, with several sampled state sequences and trajectories being identical or very similar. In order to provide downstream path planners with a succinct representation of the trajectory distribution, we cluster the sampled trajectories using the K-means algorithm to output a set of K predicted trajectories. The number of clusters K can be varied as required by the downstream path planner, without having to re-train the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation details:</head><p>As per the standard benchmarks for both datasets, we use track history of 3.2 seconds and a prediction horizon of 4.8 seconds SDD <ref type="bibr" target="#b32">[31]</ref>, while a track history of 2 seconds and a prediction horizon of 6 seconds for NuScenes <ref type="bibr" target="#b33">[32]</ref>. We assume an agent centric frame of reference with the x-axis aligned along the agent's direction of motion at t = 0. We use a 32 sized state vector for each of the GRUs. The motion encoder uses an embedding layer of size 16, while the plan encoder uses embedding layers of size 16, 32 and 16 for grid locations, scene features and surrounding agent states respectively. Our attention module is a multi-layer perceptron (MLP) with one hidden layer of size 32. To train the model, we sample 200 plans and corresponding trajectories from the trajectory generator and cluster them to give K output trajectories y <ref type="bibr" target="#b0">(1)</ref> , y <ref type="bibr" target="#b1">(2)</ref> , . . . , y (K) . We use K = 10 for NuScenes and K = 20 for SDD. We minimize the minimum over K average displacement error (MinADE K ) over the training set.</p><formula xml:id="formula_19">MinADE K = min i∈{1,...,K} 1 T f T f t=1 y GT t − y (i) t 2 ,<label>(17)</label></formula><p>where y GT is the ground truth future trajectory of the agent. The MinADE K loss has been used in prior work for training models for multimodal trajectory forecasting <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b11">[11]</ref>. For a model generating multiple trajectories, it avoids penalizing plausible future trajectories that do not correspond to the ground truth. To speed up convergence, we pre-train the model to minimize the average displacement error between y GT and the trajectory predicted by the model conditioned on the ground truth plan of the agent y S GT . We use Adam, with learning rate 0.0001 for training the trajectory generator</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>Stanford drone dataset: The Stanford drone dataset (SDD) <ref type="bibr" target="#b32">[31]</ref> consists of trajectories of pedestrians, bicyclists, skateboarders and vehicles captured using drones at 60 different scenes on the Stanford university campus. The dataset provides bird's eye view images of the scenes, and locations of tracked agents in the scene's pixel co-ordinates. The dataset contains a diverse set of scene elements like roads, sidewalks, walkways, buildings, parking lots, terrain and foliage. The roads and walkways have different configurations, including roundabouts and four-way intersections. We use the dataset split defined in the TrajNet benchmark <ref type="bibr" target="#b42">[41]</ref> and used in prior work <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b14">[14]</ref>, for defining our train, validation and test sets. The dataset is split based on scenes. Thus, the train, validation and test sets all have different scenes from the 60 total scenes. This allows us to evaluate our model on unknown scenes where it hasn't seen prior trajectory data. Note that we consider all trajectories in the train, validation and test scenes of SDD as per <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b43">[42]</ref>. Subsequent work <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b19">[19]</ref> has reported results on a subset of trajectories primarily consisting of pedestrians. We report results on this split separately.</p><p>NuScenes: The NuScenes dataset <ref type="bibr" target="#b33">[32]</ref> comprises 1000 scenes, each of which is a 20 second record, capturing complex urban traffic over a wide variety of road layouts and lane structures. The dataset was captured using vehicle mounted camera and lidar sensors while driving through Boston and Singapore, and contains hand annotated vehicle detection boxes and tracks at a 2 Hz. In particular, we train and evaluate our model using the official benchmark split for the NuScenes prediction challenge consisting of vehicle trajectories. In addition to trajectories, NuScenes provides high definition bird's eye view maps of the scene, including drivable area masks, cross-walks, sidewalks and lane center-lines along with their connectivity and directions. We use a 50m × 50m crop of the HD map around the vehicle of interest as the scene representation for our model. It extends 40m along the agent's direction of motion, 10m behind and ± 25m laterally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Metrics</head><p>Deviation from ground-truth: For evaluating a trajectory forecasting model, we need a metric for how much the forecasts deviate from the ground truth future trajectory. However, since our model generates forecasts from a multimodal distribution, we need a metric that does not penalize plausible trajectories generated by the model that don't correspond to the ground truth. Thus, we use the minimum of K average displacement error (MinADE K ), final displacement error <ref type="figure">Fig. 5</ref>: Sample quality metrics. MinADE K , MinFDE K and miss rate fail to penalize a diverse set of trajectories that don't conform to the scene (left). The off-road rate (middle) and offyaw (right) metrics address this by penalizing predicted points that fall off the drivable area or onto oncoming traffic. Warm colors indicate higher errors.</p><p>(MinFDE K ) and miss rate within 2 meters (MR K,2 ) as metrics, as utilized in prior work on multimodal trajectory forecasting <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b21">[21]</ref>. MinADE K (eq. 18) computes the average prediction error in terms of L2 norm between the ground truth future trajectory, and the forecast trajectory closest to it. MinFDE K is similar to MinADE K , but only considers the prediction error for the final predicted location. Finally, a set of K predictions is considered a missed prediction if none of the K trajectories are within 2 meters of the ground truth over the entire prediction horizon. MR K,2 computes the fraction of missed predictions in the test set.</p><p>Sample quality metrics: While MinADE K , MinFDE K and MR K,2 avoid penalizing plausible future trajectories that don't conform to the ground truth, they also do not penalize implausible future trajectories as long as one of the K trajectories is close to the ground truth. Thus a model that generates a very diverse set of K trajectories by random guessing can achieve low MinADE K , MinFDE K and MR K,2 values, even if the trajectories do not conform to the underlying scene. Thus, while these metrics serve as good measures of the 'recall' of the model for the multimodal predictive distribution, they serve as poor measures for the model's 'precision'. We refer readers to Rhinehart et al. <ref type="bibr" target="#b13">[13]</ref> for a detailed discussion on the diversity-precision trade-off. To evaluate the precision of trajectories generated by our model, we additionally report results on two recently proposed sample quality metrics.</p><p>• Off-road rate: The off-road rate metric proposed by Niedoba et al. <ref type="bibr" target="#b34">[33]</ref> computes the fraction of all predicted points that fall outside the road. For the NuScenes dataset, we use the drivable area mask to compute off-road rate. For SDD, we hand label the bird's eye view images in the test set, assigning each pixel as a path or an obstacle. Paths include roads, sidewalks, walkways etc., while obstacles include buildings, terrain, parked cars and road dividers.</p><p>• Off-yaw metric: For vehicles moving through city streets, the off-road rate metric fails to penalize predictions that fall onto oncoming traffic or illegal lanes. We thus additionally report the off-yaw metric proposed by Greer et al. <ref type="bibr" target="#b35">[34]</ref>, for the NuScenes dataset. The offyaw metric computes the deviation between the direction    <ref type="figure">Figure 5</ref> illustrates how the off-road rate and off-yaw rate can penalize a set of diverse but imprecise forecasts that MinADE K , MinFDE K and MR K,2 metrics fail to penalize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison with the state of the art</head><p>We compare our model with prior and concurrently developed models that represent the state of the art for the Stanford drone and NuScenes. <ref type="table" target="#tab_2">Table I</ref> reports results on SDD based on the dataset split used in <ref type="bibr" target="#b11">[11]</ref>. While most prior works have reported MinADE K and MinFDE K for K=20, Desire <ref type="bibr" target="#b0">[1]</ref> has results reported for K=5. We report metrics for both values of K here for our models. Note that the error values are in pixels in the bird's eye view image co-ordinates. We also report off-road rate values on SDD for our models based on per pixel path/obstacle labels for the SDD test set. Our model achieves the lowest MinFDE K values, while only being closely outperformed by the HBA-Flow model on MinADE K . <ref type="table" target="#tab_2">Table II</ref> reports results on the dataset split used by Mangalam et al. <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b19">[19]</ref>. This uses a subset of trajectories in SDD, primarily consisting of pedestrians. Our model outperforms PECNet <ref type="bibr" target="#b18">[18]</ref>. However, the recently proposed Y-Net <ref type="bibr" target="#b19">[19]</ref> achieves lower MinADE K and MinFDE K values. Similar to our models, Y-Net also conditions trajectories on goals and intermediate waypoints of agents in the scene, suggesting the importance of modeling the static scene for trajectory forecasts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SDD:</head><p>NuScenes: <ref type="table" target="#tab_2">Table III</ref> reports results on the NuScenes prediction benchmark. We compare our models with the physics oracle and CoverNet <ref type="bibr" target="#b24">[24]</ref> baselines released with the benchmark, and the winning entries of the NuScenes prediction challenge, cxx <ref type="bibr" target="#b22">[22]</ref>, MHA-JAM <ref type="bibr" target="#b9">[9]</ref> and Trajectron++ <ref type="bibr" target="#b44">[43]</ref>. Additionally, we also consider the simple yet effective MTP <ref type="bibr" target="#b4">[5]</ref> and Multipath <ref type="bibr" target="#b23">[23]</ref> models as implemented and reported on NuScenes by Greer et al. <ref type="bibr" target="#b35">[34]</ref>. Since NuScenes requires a single set of trajectories to evaluate metrics for K=5 and K=10, we merge the clustered trajectories for K=5 and K=10. To remove duplicates, we discard trajectories from the set of 10 closest to each trajectory in the set of 5 in terms of displacement error. The set of 5 trajectories is nominally assigned a higher score than the set of 10 trajectories. The benchmark does not include results for the off-yaw metric. However, we report the metric for our models as well as those from Greer et al. <ref type="bibr" target="#b35">[34]</ref>.</p><p>Our model achieves state of the art results on almost metrics on the NuScenes benchmark 2 . In particular, it achieves  The low off-road and off-yaw metrics suggest that conditioning trajectories on plans sampled from the MaxEnt policy lead to more scene compliant trajectories. We investigate this further in section IV-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablations</head><p>We additionally report results for ablations of our model with respect to the following components.</p><p>• Grid-based plans: To analyze the effect of conditioning trajectories on the grid based plans, we consider an ablation of our model without the MaxEnt policy and plan encoder ( <ref type="figure">Figure 6</ref>). In this case, the trajectory decoder attends to all features in the grid, rather than just those along the sampled state sequence. To keep memory usage tractable, we maxpool the features using a 2×2 kernel before attention layers. In order to sample a diverse set of trajectories, we additionally condition the trajectory decoder with a latent variable z sampled from a univariate Gaussian distribution. We refer to this ablation as the latent variable model (LVM).</p><p>• Trajectory generator: Next, we consider a model without the trajectory generator. To output continuous valued trajectories along sampled plans, we fit a smoothing spline along the sampled grid locations and propagate a constant speed trajectory along the spline using the target agent's velocity at the prediction instant. We refer to this model as P2T CS .</p><p>• Reward Layers: Finally, we consider an ablation without the reward layers to analyze the usefulness of using IRL. Instead of learning the reward, we learn a behavior cloning policy that directly maps the scene and motion features to action probabilities at each grid cell. We refer to this model as P2T BC .</p><p>Tables IV and V report results for ablation studies on SDD and NuScenes respectively. We note that for both datasets, our complete proposed model (P2T IRL ) outperforms the LVM across all metrics. In particular, the high off-road and offyaw metrics for the LVM compared to the other three models suggest that the LVM generates more trajectories that veer off the road or violate lane direction. This shows that the inductive bias due to grid based plans leads to trajectories that are more scene compliant. Conversely, P2T CS achieves comparable offroad and off-yaw metrics as P2T IRL . However it does poorly in terms of the MinADE, MinFDE and miss rate metrics. Thus, although its trajectories are scene compliant, they deviate significantly from the ground truth, suggesting the limitation of the constant speed model compared to the attention based GRU decoder for modeling agent dynamics. Finally, P2T IRL slightly outperforms the behavior cloning model P2T BC on most metrics, with the difference being more prominent for SDD than for NuScenes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Runtime</head><p>In table VI we provide inference times for each component of the model. Inference is performed using an NVIDIA GeForce GTX 1080 Ti GPU. We also implement algorithms 1 and 2 using vectorized operations on the GPU. For each prediction instance, we sample 1000 state sequences from MaxEnt policy, generating 1000 trajectories, which are finally clustered to output K trajectories. The runtimes reported here are for K=10. We note inference can be performed in 79 ms (or 12Hz) for the complete proposed model which will allow for real-time deployment, given access to rasterized birds eye view scene representations and past tracks of agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Qualitative examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figures 7 and 8 show qualitative examples from the</head><p>NuScenes and Stanford drone datasets. We show the input scene and past tracks of agents, heat maps for goal and path state visitation frequencies for the MaxEnt policy and the final set of 10 clustered trajectories from the trajectory generator. We note that the MaxEnt policy explores plausible path and goal states in the 2-D grid for a variety of scene configurations. For the Nuscenes dataset, this corresponds to reachable lanes for the target agent. Note that the policy accurately infers which lanes correspond to the direction of motion rather than oncoming traffic. For SDD, the policy shows a preference for paths and roads while avoiding terrain or obstacles. We also note that the path and goal SVFs are multimodal. Finally, the predicted trajectories closely map to the states explored by the policy, leading to a diverse set of scene compliant predictions over a variety of scene configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUDING REMARKS</head><p>We introduced an approach to forecast trajectories of pedestrians and vehicles in unknown environments conditioned on plans sampled from a grid based MaxEnt IRL policy. We reformulated MaxEnt IRL to learn a policy that can jointly infer goals and paths of agents on a coarse 2-D grid defined over the scene. We showed that our policy infers plausible goals of agents in unknown environments and paths to these goals that conform to the underlying scene. Additionally, we showed that our policy induces a multi-modal distribution over path and goal states. Next, we introduced an attention based trajectory generator that outputs continuous valued trajectories conditioned on state sequences sampled from our MaxEnt policy. Trajectories sampled from our trajectory generator are diverse and conform to the scene, outperforming prior approaches on the TrajNet benchmark split of the Stanford drone dataset and the NuScenes prediction benchmark. With an inference time of 79 ms, the proposed model can readily be deployed in conjunction with on board detectors <ref type="bibr" target="#b45">[44]</ref>, trackers <ref type="bibr" target="#b46">[45]</ref>, <ref type="bibr" target="#b47">[46]</ref> and HD Maps for autonomous driving. Mohan Manubhai Trivedi is a Distinguished Professor at University of California, San Diego (UCSD) and the founding director of the UCSD LISA: Laboratory for Intelligent and Safe Automobiles, winner of the IEEE ITSS Lead Institution Award (2015). Currently, Trivedi and his team are pursuing research in intelligent vehicles, autonomous driving, machine perception, machine learning, human-robot interactivity, driver assistance. Three of his students have received "best dissertation" recognitions and over twenty best papers/finalist recognitions. Trivedi is a Fellow of IEEE, ICPR and SPIE. He received the IEEE ITS Society's highest accolade "Outstanding Research Award" in 2013. Trivedi serves frequently as a consultant to industry and government agencies in the USA and abroad.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>• Non-linearity of agent trajectories: Drivers and pedestrians can make several decisions over long prediction The authors are with the Laboratory for Intelligent and Safe Automobiles (LISA), University of California at San Diego, La Jolla, CA 92093 USA (email:ndeo@ucsd.edu, mtrivedi@ucsd.edu)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Overview: P2T consists of three modules: (1) a fully convolutional reward model, that outputs transient path state rewards and terminal goal state rewards on a coarse 2-D grid, (2) a MaxEnt RL policy for the learned path and state rewards, that can be sampled to generate multimodal plans on the 2-D grid, and (3) an attention based trajectory generator, that outputs continuous valued trajectories conditioned on the sampled plans.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Reward model: CNN f eat extracts features from the static scene. We concatenate these with feature maps capturing the agent's motion. CNN p and CNN g learn path and goal rewards from the features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 :</head><label>7</label><figDesc>Qualitative examples from NuScenes. From top to bottom: Inputs, goal SVFs, path SVFs and predictions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 :</head><label>8</label><figDesc>Qualitative examples from SDD. From top to bottom: Inputs, goal SVFs, path SVFs and predictions Nachiket Deo is currently working towards his PhD in electrical engineering from the University of California at San Diego (UCSD), with a focus on intelligent systems, robotics, and control. His research interests span computer vision and machine learning, with a focus on motion prediction for vehicles and pedestrians.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>Results on SDD test set for split used in<ref type="bibr" target="#b11">[11]</ref> </figDesc><table><row><cell>Model</cell><cell>MinADE 5</cell><cell>MinADE 20</cell><cell>MinFDE 5</cell><cell>MinFDE 20</cell><cell>Off-road rate</cell></row><row><cell>S-GAN [2]</cell><cell>-</cell><cell>27.25</cell><cell>-</cell><cell>41.44</cell><cell>-</cell></row><row><cell>Desire [1]</cell><cell>19.25</cell><cell>-</cell><cell>34.05</cell><cell>-</cell><cell>-</cell></row><row><cell>MATF [12]</cell><cell>-</cell><cell>22.59</cell><cell>-</cell><cell>33.53</cell><cell>-</cell></row><row><cell>SoPhie [11]</cell><cell>-</cell><cell>16.27</cell><cell>-</cell><cell>29.38</cell><cell>-</cell></row><row><cell>CF-VAE [14]</cell><cell>-</cell><cell>12.60</cell><cell>-</cell><cell>22.30</cell><cell>-</cell></row><row><cell>HBA-flow [42]</cell><cell>-</cell><cell>10.80</cell><cell>-</cell><cell>19.80</cell><cell>-</cell></row><row><cell>P2T (ours)</cell><cell>15.90</cell><cell>10.97</cell><cell>30.48</cell><cell>18.40</cell><cell>0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc>Results on SDD test set for split used in<ref type="bibr" target="#b18">[18]</ref> </figDesc><table><row><cell>Model</cell><cell>MinADE 5</cell><cell>MinADE 20</cell><cell>MinFDE 5</cell><cell>MinFDE 20</cell><cell>Off-road rate</cell></row><row><cell>PECNet [18]</cell><cell>12.79</cell><cell>9.96</cell><cell>29.58</cell><cell>15.88</cell><cell>-</cell></row><row><cell>Y-Net [19]</cell><cell>11.49</cell><cell>7.85</cell><cell>20.23</cell><cell>11.85</cell><cell>-</cell></row><row><cell>P2T (ours)</cell><cell>12.81</cell><cell>8.76</cell><cell>23.95</cell><cell>14.08</cell><cell>0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III :</head><label>III</label><figDesc>Results on NuScenes test set for the prediction benchmark split Similar to Greer et al., we only penalize deviations above 45 • to avoid penalizing lane changes.</figDesc><table><row><cell>Model</cell><cell>MinADE 5</cell><cell>MinADE 10</cell><cell>MR 5,2</cell><cell>MR 10,2</cell><cell>Off-road rate</cell><cell>Off-yaw metric</cell></row><row><cell>Physics oracle [24]</cell><cell>3.70</cell><cell>3.70</cell><cell>0.88</cell><cell>0.88</cell><cell>0.12</cell><cell>-</cell></row><row><cell>CoverNet [24]</cell><cell>2.62</cell><cell>1.92</cell><cell>0.76</cell><cell>0.64</cell><cell>0.13</cell><cell>-</cell></row><row><cell>MTP [5]</cell><cell>2.44</cell><cell>1.57</cell><cell>0.70</cell><cell>0.55</cell><cell>0.11</cell><cell>0.11</cell></row><row><cell>Trajectron ++ (3rd place) [43]</cell><cell>1.88</cell><cell>1.51</cell><cell>0.70</cell><cell>0.57</cell><cell>0.25</cell><cell>-</cell></row><row><cell>MHA-JAM (2nd place) [9]</cell><cell>1.81</cell><cell>1.24</cell><cell>0.59</cell><cell>0.46</cell><cell>0.07</cell><cell>-</cell></row><row><cell>cxx (winning entry) [22]</cell><cell>1.63</cell><cell>1.29</cell><cell>0.69</cell><cell>0.60</cell><cell>0.08</cell><cell>-</cell></row><row><cell>Multipath [23]</cell><cell>1.63</cell><cell>1.50</cell><cell>0.75</cell><cell>0.74</cell><cell>0.38</cell><cell>0.37</cell></row><row><cell>Noah (current best entry)</cell><cell>1.59</cell><cell>1.37</cell><cell>0.69</cell><cell>0.62</cell><cell>0.08</cell><cell>0.37</cell></row><row><cell>P2T (Ours)</cell><cell>1.45</cell><cell>1.16</cell><cell>0.64</cell><cell>0.46</cell><cell>0.03</cell><cell>0.04</cell></row><row><cell cols="3">of motion of the nearest lane and the yaw of predicted</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>points.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV :</head><label>IV</label><figDesc>Ablations on SDD</figDesc><table><row><cell>Model</cell><cell>CNN f eat</cell><cell>Reward layers</cell><cell>Grid-based plans</cell><cell>Trajectory generator</cell><cell>MinADE 5</cell><cell cols="2">MinADE 20 MinFDE 5</cell><cell>MinFDE 20</cell><cell>Offroad rate</cell></row><row><cell>LVM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>18.28</cell><cell>12.17</cell><cell>36.71</cell><cell>20.98</cell><cell>0.11</cell></row><row><cell>P2T CS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>21.70</cell><cell>16.10</cell><cell>38.25</cell><cell>25.22</cell><cell>0.09</cell></row><row><cell>P2T BC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>15.93</cell><cell>11.56</cell><cell>30.29</cell><cell>19.51</cell><cell>0.06</cell></row><row><cell>P2T IRL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>15.90</cell><cell>10.97</cell><cell>30.48</cell><cell>18.40</cell><cell>0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V :</head><label>V</label><figDesc>Ablations on NuScenes Ablation of grid based plans: Models with (left) and without (right) the plan encoder and grid based policy. Without the grid based plan, the trajectory decoder attends to all features within the grid significantly lower off-road rate and off-yaw metrics compared to previous methods, while still maintaining low MinADE K and miss rate values. The low MinADE K and miss rates suggest that our model generates a diverse set of trajectories.</figDesc><table><row><cell>Model</cell><cell>CNN f eat</cell><cell>Reward layers</cell><cell>Grid-based plans</cell><cell>Trajectory generator</cell><cell>MinADE 5</cell><cell>MinADE 10</cell><cell>MR 5,2</cell><cell>MR 10,2</cell><cell>Offroad rate</cell><cell>Off-yaw metric</cell></row><row><cell>LVM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.77</cell><cell>1.27</cell><cell>0.80</cell><cell>0.63</cell><cell>0.10</cell><cell>0.12</cell></row><row><cell>P2T CS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4.18</cell><cell>4.05</cell><cell>0.93</cell><cell>0.92</cell><cell>0.02</cell><cell>0.07</cell></row><row><cell>P2T BC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.47</cell><cell>1.15</cell><cell>0.67</cell><cell>0.49</cell><cell>0.04</cell><cell>0.07</cell></row><row><cell>P2T IRL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.45</cell><cell>1.16</cell><cell>0.64</cell><cell>0.46</cell><cell>0.03</cell><cell>0.04</cell></row><row><cell>Fig. 6:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI :</head><label>VI</label><figDesc>Inference time</figDesc><table><row><cell>Component</cell><cell>Time</cell></row><row><cell>Reward model</cell><cell>2 ms</cell></row><row><cell>Solve for MaxEnt policy (Algorithm 3)</cell><cell>28 ms</cell></row><row><cell>Sample MaxEnt Policy</cell><cell>28 ms</cell></row><row><cell>Trajectory Generator</cell><cell>12 ms</cell></row><row><cell>Clustering</cell><cell>9 ms</cell></row><row><cell>Total</cell><cell>79 ms</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We refer to agent locations without assigned times as paths, and agent locations with assigned times as trajectories</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">URL: https://eval.ai/web/challenges/challenge-page/591/leaderboard/1659, results as of April 27, 2021</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional social pooling for vehicle trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1468" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-modal trajectory prediction of surrounding vehicles with maneuver based lstms</title>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1179" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Djuric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2090" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Naturalistic driver intention and path prediction using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nebot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Intentnet: Learning to predict intention from raw sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="947" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Scene compliant trajectory forecast with agent-centric spatio-temporal grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ridel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.07507</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Trajectory prediction for autonomous driving based on multi-head attention with joint agent-map representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Messaoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nashashibi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02545</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rules of the road: Predicting driving behavior with a convolutional model of semantic interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8454" to="8462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01482</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="772" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Conditional flow variational autoencoders for structured sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hanselmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-N</forename><surname>Straehle</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09008</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accurate and diverse sampling of sequences based on a &quot;best of many&quot; sample objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8485" to="8493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01296</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.08294</idno>
		<title level="m">Tnt: Target-driven trajectory prediction</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">It is not the journey but the destination: Endpoint conditioned trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="759" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">From goals, waypoints &amp; paths to long term human trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.01526</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchetti-Bowick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.04450</idno>
		<title level="m">Map-adaptive goal-based trajectory prediction</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8748" to="8757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Probabilistic multi-modal trajectory prediction with lane attention for autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dabiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02574</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning. PMLR, 2020</title>
		<imprint>
			<biblScope unit="page" from="86" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Covernet: Multimodal behavior prediction using trajectory sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phan-Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Grigore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Boulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">83</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Planning-based prediction for pedestrians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ratliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Srinivasa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="3931" to="3936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Activity forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="201" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Watch this: Scalable costfunction learning for path planning in urban environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wulfmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2089" to="2095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Integrating kinematics and environment context into deep inverse reinforcement learning for predicting off-road vehicle trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bonatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="894" to="905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Maximum entropy inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aaai</title>
		<meeting><address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1433" to="1438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bankiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">E</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Baldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.11027</idno>
		<title level="m">nuscenes: A multimodal dataset for autonomous driving</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">nuscenes: A multimodal dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bankiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">E</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Baldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Improving movement prediction of traffic actors using off-road loss and bias mitigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niedoba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Trajectory prediction in autonomous driving with a lane heading auxiliary loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>RA-L</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Maximum entropy deep inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wulfmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.04888</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Modeling interaction via the principle of maximum causal entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Reinforcement learning and control as probabilistic inference: Tutorial and review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00909</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Trajnet: Towards a benchmark for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-N</forename><surname>Straehle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09878</idno>
		<title level="m">Haar wavelet based block autoregressive flows for trajectories</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.03093</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ground plane polling for 6dof pose estimation of objects on the road</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Vehicles</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="449" to="460" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">No blind spots: Full-surround multi-object tracking for autonomous vehicles using cameras and lidars</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Vehicles</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="588" to="599" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Trackmpnn: A message passing graph neural architecture for multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gebre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mhatre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramezani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04206</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
