<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">11 A Data Set and a Convolutional Model for Iconography Classification in Paintings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Milani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piero</forename><surname>Fraternali</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Politecnico</forename><surname>Di Milano</surname></persName>
						</author>
						<title level="a" type="main">11 A Data Set and a Convolutional Model for Iconography Classification in Paintings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/1122445.1122456</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts: • Computing methodologies → Artificial intelligence</term>
					<term>Computer vision</term>
					<term>Computer vision tasks</term>
					<term>Computer vision problems</term>
					<term>• Applied computing → Arts and humanities</term>
					<term>Additional Key Words and Phrases: Iconography, Art, Paintings, Data set, Deep learning, Classification, Transfer learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Iconography in art is the discipline that studies the visual content of artworks to determine their motifs and themes and to characterize the way these are represented. It is a subject of active research for a variety of purposes, including the interpretation of meaning, the investigation of the origin and diffusion in time and space of representations, and the study of influences across artists and art works. With the proliferation of digital archives of art images, the possibility arises of applying Computer Vision techniques to the analysis of art images at an unprecedented scale, which may support iconography research and education. In this paper we introduce a novel paintings data set for iconography classification and present the quantitative and qualitative results of applying a Convolutional Neural Network (CNN) classifier to the recognition of the iconography of artworks. The proposed classifier achieves good performances (71.17% Precision, 70.89% Recall, 70.25% F1-Score and 72.73% Average Precision) in the task of identifying saints in Christian religious paintings, a task made difficult by the presence of classes with very similar visual features. Qualitative analysis of the results shows that the CNN focuses on the traditional iconic motifs that characterize the representation of each saint and exploits such hints to attain correct identification. The ultimate goal of our work is to enable the automatic extraction, decomposition, and comparison of iconography elements to support iconographic studies and automatic art work annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACM Reference Format:</head><p>Federico Milani and Piero Fraternali. 2020. A Data Set and a Convolutional Model for Iconography Classification in Paintings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Iconography is that branch of the history of art which concerns itself with the subject matter or meaning of works of art, as opposed to their form <ref type="bibr" target="#b60">[68]</ref>. Iconography focuses on the subject of an artwork and on the way it is represented. The iconographic analysis of an artwork determines the subject portrayed in the image (e.g., the crucifixion or the visitation of the magi) and characterizes the way in which such a theme is represented, e.g, the number of subjects or objects that constitute the representation, their disposition and mutual relations, and ultimately their possible symbolic meaning. Iconographic studies have a fundamental role in art history, because iconography is a cultural marker, which can be used to support the identification of the production period and to delimit the region of provenance of an artwork, and to understand the intention of the commissioner or of the author. The popularization of digital art images, which are now available in massive numbers in open data sets <ref type="bibr" target="#b56">[64,</ref><ref type="bibr" target="#b72">80]</ref>, offers new possibilities to art history and iconography studies. Researchers have now at their disposition a wealth of images, usable to investigate the evolution of iconography motifs and themes in time and space, to assess the influences across artworks and authors, and even to conduct cross-media studies, which e.g., may reconnect a specific iconography to its literary source. A revealing signal of the increasing importance of IT-supported iconography studies is the effort of standardizing the identification of the content of images by means of a single agreed-upon iconography taxonomy. The most prominent effort in this direction is the Iconclass system <ref type="bibr" target="#b25">[33]</ref>, which provides over 28k classification types for ten top-level categories of images and is increasingly used by art historians and collection curators to label art images in a way that facilitates search and comparison. However, both the manual creation and the analysis of labelled art images data sets is a non-trivial and time consuming task. Iconographic classes are numerous, may denote complex content made of multiple interrelated motifs, can present themselves in multiple variants, and can be sub-structured into elements whose identification and characterization may be important too.</p><p>Computer Vision (CV) methods may be of great help in supporting the production and the exploitation of iconography-oriented art images data sets: 1) given an image, the set of iconography classes potentially denoting its content could be retrieved and ranked by likelihood, to support the semi-automatic labeling of the data set; 2) the regions of the image where the core elements of the iconography class are present could be detected, supporting the morphological analysis of the iconography and the detection of specific variants or of important sub-elements; 3) a data set of art images could be clustered based on the iconography class of artworks, the specific variant they express, and the presence or position of specific sub-elements. Machine Learning (ML) and CV techniques are the natural candidates to support the iconography analysis of art images. In its "simplest" form, this task can be formulated as a classification problem. Classification of natural images by their content is now considered a solved CV task. Conversely, classifying artwork iconography is much less investigated and still presents non trivial challenges: iconographic classes are numerous and structurally complex, high-quality annotated data sets are not commonly available, and the art images themselves are visually more homogeneous than natural images which makes their discrimination difficult. Training a CV component for the classification of art iconography requires creating a data set annotated at the image level with the iconography class(es) portrayed in the artwork. Such labelling could be semi-automated, e.g., by exploiting keywords and metadata associated with each image, but expert judgement is still fundamental to provide missing labels or correct wrong annotations.</p><p>The more interesting problem of characterizing the image regions where the constituents of an iconography class are found requires addressing the much harder problem of multi-instance object detection <ref type="bibr" target="#b53">[61]</ref>. The definition of a high quality data set, supporting the training of a component for the detection of the constituents of an iconography class is far from trivial, because it would require an expert to manually annotate at the pixel level a sufficient number of examples for a very high number of classes (28k); if the analysis of specific objects or parts of an iconography (e.g., the number of nails in a crucifixion scene 1 , the position and number of angels in a annunciation scene, etc.) should be supported, the effort would be even greater.</p><p>In this paper, we address the problem of iconography analysis by tackling the initial task of iconography class identification in images of paintings. As a case study, we consider iconography classes associated with saints in christian religious art. The contributions of the paper can be summarized as follows:</p><p>• We introduce a novel data set, called ArtDL, for iconography classification, which consists of 42k annotated images pertaining to 19 classes (10 of which are "long tail" having less than 1000 annotated samples). Each class denotes the presence of a specific character (e.g., Virgin Mary, Saint Sebastian, Saint Anthony of Padua, Saint Mary Magdalene, Saint Francis of Assisi, Saint Jerome, Saint Peter, Saint Paul, Saint Dominic, Saint John the Baptist).</p><p>• We develop a CNN classifier for the task of iconography class recognition. We address the problem of the limited amount of labeled data in the art iconography domain by applying transfer learning <ref type="bibr" target="#b59">[67]</ref>, to re-use common knowledge extracted from a model pre-trained on ImageNet <ref type="bibr" target="#b30">[38]</ref>. In the best experiment, with the 10 most discriminative classes, the classifier achieves 72% average precision and 70% F1 score, with 71% precision at 70% recall. • We analyze the output of the classifiers qualitatively by exploiting visual understanding and interpretability techniques (specifically Class Attention Maps -CAMs <ref type="bibr" target="#b81">[89]</ref>) to identify the representative image regions where the classifier focuses its attention. We also illustrate examples of confusion among classes, mostly in cases of strong visual similarity, to better highlight the hardness of the task. • We publish both the data set and the trained CNN model at the address: http://www.artdl.org</p><p>The rest of the paper is organized as follows: Section 2 overviews the related work on the IT-supported tasks and methods for artwork image analysis and on the main data sets that enable research in such a field; it also briefly reviews the essential results about model interpretability, a key technique to support the qualitative analysis of our results. Section 3 introduces the ArtDL data set for saint iconography in artworks and the proposed architecture for addressing the saint iconography classification task; Section 4 presents the results of applying the defined architecture to the ArtDL data set from both a quantitative and a qualitative point of view; Section 5 concludes and provides an outlook on the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Computer Vision and Deep Learning for Artwork Image Analysis</head><p>The increased availability of visual art content in digital format has spawned the research interest in methods for supporting digital humanities studies and cultural heritage asset management. In this section we report the most relevant research results addressing the different tasks of artwork image analysis and describe the main data sets created to support such efforts.</p><p>2.1.1 Artwork analysis tasks. The artwork classification by style is one of the first areas of study. The early work <ref type="bibr" target="#b82">[90]</ref> explored the automatic categorization of paintings by genre (Impressionism, Cubism, Impressionism, Pop Art and Realism) using a data set of ∼350 images from different sources (Google, Artlex, CARLI Digital Collections). The proposed method extracted multiple image features and used them to train different classifiers: Naive Bayes, K-Nearest-Neighbours, Support Vector Machines, Decision Trees and Artificial Neural Networks. The results demonstrated the feasibility of the task, even with such a small data set. The work <ref type="bibr" target="#b36">[44]</ref> proposed a method for style recognition based on Adaptive Sparse Analysis that exploits Discrete Cosine Transform to learn a dictionary of distinctive painting characteristics. The experiments spanned authentication, stylometry and classification tasks and showcased promising results. More recent approaches adopt CNNs for feature extraction, replacing the design of hand crafted features. In <ref type="bibr" target="#b46">[54]</ref> the authors compare linear classifiers based on hand-crafted features and on features obtained using AlexNet <ref type="bibr" target="#b49">[57]</ref> pre-trained with ImageNet <ref type="bibr" target="#b30">[38]</ref>; the assessment exploits a data set of around 85,000 images labeled with 25 different art styles. The same approach is used in <ref type="bibr" target="#b76">[84]</ref>, where the features obtained by a variation of the AlexNet CNN are used to train an SVM, showing that automatically extracted features can outperform classical image descriptors. Other examples of style image classification can be found in <ref type="bibr" target="#b9">[17,</ref><ref type="bibr" target="#b22">30,</ref><ref type="bibr" target="#b34">42,</ref><ref type="bibr" target="#b51">59]</ref>.</p><p>Artists have their own imprint that makes experts recognize their work among others with the same style. The author identification task has been investigated in several studies <ref type="bibr" target="#b47">[55,</ref><ref type="bibr" target="#b56">64]</ref>, with motivations that range from the automatic cataloguing of unlabeled works to the identification of forgery. The authors of <ref type="bibr" target="#b69">[77]</ref> proposed an automatic method to analyze paintings of several artists and schools and to group them by artistic movement. The generated phylogenies highlight similarities and influential links in agreement with art historians. Johnson et al. <ref type="bibr" target="#b44">[52]</ref> proposed an approach to classify paintings by author, which relies among the other features on the segmentation of brushstrokes (using K-means clustering and edge extraction). A similar approach was employed in <ref type="bibr" target="#b31">[39]</ref>, where stroke segmentation was used for artist identification and forgery detection. Artists were asked to imitate different artworks (e.g., by Picasso) to generate a test data set. The work <ref type="bibr" target="#b10">[18]</ref> proposed a hierarchical multitask classification framework to automatically detect the characteristics of an artwork and produce multiple metadata, such as author, year, genre and medium of paintings.</p><p>The artwork content analysis task focuses on automatically recognizing the subject of artworks, by detecting the objects that appear in the image or by localizing their position <ref type="bibr" target="#b16">[24,</ref><ref type="bibr" target="#b28">36,</ref><ref type="bibr" target="#b39">47,</ref><ref type="bibr" target="#b70">78]</ref>. Applications include image retrieval and iconography labeling for asset management. In <ref type="bibr" target="#b26">[34]</ref> the authors introduce the Paintings Dataset of 200,000+ British paintings annotated with ten classes (e.g., bird, boat, chair). The objective is to predict the object classes that appear in an input image. The adopted approach consists of training a model on the PASCAL VOC <ref type="bibr" target="#b32">[40]</ref> data set and then evaluating how well the trained model performs when moved from natural images to art paintings. This technique is known as Transfer Learning (TL) <ref type="bibr" target="#b59">[67]</ref> and is frequently applied to art image analysis due to the absence of art-specific models trained on large data sets. Several studies evaluate the transferability of previous knowledge to the art domain. The work of <ref type="bibr" target="#b65">[73]</ref> investigates the behavior of CNNs pre-trained on a different domain and fine-tuned with art images. The results show that fine-tuned models outperform models trained from scratch on art images. The same conclusions are obtained in <ref type="bibr" target="#b19">[27]</ref> which studies transferability on different classification tasks: genre, artist, style recognition. Another example of fine tuning is <ref type="bibr" target="#b77">[85]</ref>, where the goal is to detect people in artworks. The authors employ the Fast R-CNN <ref type="bibr" target="#b38">[46]</ref> model pre-trained on ImageNet, fine-tune it in the People-Art data set, and assess performances on their own data set and on the Picasso data set, previously used for detecting people in cubist artworks <ref type="bibr" target="#b37">[45]</ref>.</p><p>More specific artwork analysis tasks, such as sentiment detection or visual aesthetic analysis have also been investigated <ref type="bibr" target="#b4">[12,</ref><ref type="bibr" target="#b5">13,</ref><ref type="bibr" target="#b14">22,</ref><ref type="bibr" target="#b15">23,</ref><ref type="bibr" target="#b20">28,</ref><ref type="bibr" target="#b45">53,</ref><ref type="bibr" target="#b52">60]</ref>. For example, <ref type="bibr" target="#b20">[28]</ref> exploits CNNs to predict subjective aspects of human perception: aesthetic evaluation, evoked sentiment and memorability. The authors also analyze which features of the images contribute the most to a given aspect and explore such findings in the context of art history. <ref type="table">Table 1</ref> surveys the principal results in the field of artwork image analysis. The table lists recent works in order of appearance, specifies the task they address, the reported performance results, and the data set(s) used in the evaluation. We can observe a high variance of results depending on the data set and on the task, e.g. artist identification has an accuracy between 30.2% and 92.9% while style classification has an accuracy that ranges between 39.1% and 84.4%.</p><p>2.1.2 Artwork analysis data sets. Machine learning methods are data-driven and thus the progress of research is conditioned by the availability of data sets for training algorithms. In the field of art work image analysis great efforts have been devoted to the creation of data sets and baselines <ref type="bibr" target="#b13">[21,</ref><ref type="bibr" target="#b39">47,</ref><ref type="bibr" target="#b54">62,</ref><ref type="bibr" target="#b72">[80]</ref><ref type="bibr" target="#b73">[81]</ref><ref type="bibr" target="#b74">[82]</ref><ref type="bibr" target="#b78">86]</ref>. <ref type="table">Table 2</ref> surveys the data sets mentioned in the art work image analysis literature. We can observe that the number of images varies between ∼ 4k and ∼ 2M, and the proposed annotations almost always include artist, style, genre, type, medium, and material. Some notable data sets are Iconart, which focuses on Christian art, OmniArt, which includes also IconClass categories, and Painting-91, which contains 10 classes belonging to the Pascal VOC data set. At present, most art data sets offer whole-image labeling, and only a few data sets provide the location of objects within the image, but only in small numbers and for a limited set of rather generic objects. The overview of <ref type="table">Table  2</ref> highlights the opportunity of producing more data sets with finer-grain annotations at the object and pixel level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interpretability and attention maps</head><p>Deep Learning architectures are black-boxes with extremely good performance but hard to analyze in their internal mechanics. The opaqueness of their behavior makes the diagnosis of errors and the optimization of  <ref type="table">Table 2</ref>. State-of-the-art data sets for classification on the artworks field with their corresponding number of images, classes and type of annotation. inference problematic. Various efforts have been made to design intuitive techniques for the visualization of CNN behavior supporting the interpretation of their performance. A prominent result in this direction is the concept of Class Activation Map (CAM). CAMs, first introduced in <ref type="bibr" target="#b81">[89]</ref>, aim at highlighting for a specific object class the most discriminative areas of the input image that contribute to the assignment to that class. The idea is to map the class weights at the output of the CNN back to features maps of the last convolutional layer from which they are computed using global average pooling. By up-sampling such a projection to the size of the input image, one can visualize the importance of each image location for the prediction of the class. The original formulation of the CAM has been subsequently extended. The work in <ref type="bibr" target="#b68">[76]</ref> introduces Gradient-weighted Class Activation Mapping (Grad-CAM) and exploits the gradients of any target object through the final convolution layer to produce a map of the areas most contributing to the activation. Such an approach can be applied to other tasks beyond classification and does not require changing or re-training of the architecture. The Guided Grad-CAM method further combines low-resolution class-discriminative heat maps from Grad-CAM and fine-grained details extracted with guided back-propagation <ref type="bibr" target="#b71">[79]</ref>. <ref type="bibr" target="#b21">[29]</ref> proposes Grad-CAM++, a method that differentiates the importance of each pixel in a feature map yielding to an improvement with respect to Grad-CAM in the localization of single and multiple instances. The authors of <ref type="bibr" target="#b58">[66]</ref> modify the approach of <ref type="bibr" target="#b21">[29]</ref> to obtain Smooth Grad-Cam++. As the name suggests, a smoothing of the gradients is introduced by adding small perturbations to the image of interest and making an 7,646 Wikidata <ref type="bibr" target="#b2">[10]</ref> 3,648 Total 47,551 <ref type="table">Table 3</ref>. Amount of images retrieved from each source average of all gradient matrices generated from the noisy images. Their method can also create visualizations for specific layers, feature maps or neurons. In Section 4.2 we exploit the CAMs to investigate how the proposed classifier identifies the designated iconography classes in the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A DEEP LEARNING METHOD FOR ICONOGRAPHY CLASSIFICATION</head><p>In this paper, we present a CNN model for the task of identifying saint iconography in Christian art paintings.</p><p>The model is trained and tested on the ArtDL data set, which we have created on purpose for the task and made public at the address https://www.artdl.org.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data set</head><p>The ArtDL data set contains 42,479 images of artworks portraying Christian saints, divided in 10 classes: Saint Dominic (iconclass 11HH(DOMINIC)), Saint Francis of Assisi (iconclass 11H(FRANCIS)), Saint Jerome (iconclass 11H(JEROME)), Saint John the Baptist (iconclass 11H(JOHN THE BAPTIST)), Saint Anthony of Padua (iconclass 11H(ANTONY OF PADUA), Saint Mary Magdalene (iconclass 11HH(MARY MAGDALENE)), Saint Paul (iconclass 11H(PAUL)), Saint Peter (iconclass 11H(PETER)), Saint Sebastian (iconclass 11H(SEBASTIAN)) and Virgin Mary (iconclass 11F). All images are associated with high-level annotations specifying which iconography classes appear in them (from a minimum of 1 class to a maximum of 7 classes).</p><p>3.1.1 Image acquisition. The total number of collected images before any filtering is 47,551, gathered from the data sources listed in <ref type="table">Table 3</ref>. Images were retrieved by using public APIs, CSV databases or web scraping. The data set comprises both RGB (60%) and BW (40%) images. Most sources contained only RGB images while some sources, e.g., Catalogo Generale dei Beni Culturali [2], published almost only BW images. All images were acquired together with the information about them available in the data source, including artwork title, description, tags and other metadata. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates some examples of the collected images.</p><p>3.1.2 Image filtering. After automatic image acquisition, three main data quality issues had to be addressed:</p><p>Duplicate images. Some sources are themselves a collection of multiple open data sets and thus exact and near-duplicates may occur. The detection and removal of such images were performed in two steps: first by automatically removing all the files with the same MD5 hash and then by calculating the hash similarity of image pairs and submitting to the user those pairs with a similarity above a certain threshold.   Damaged, empty, and non-painting images. Several images portray ruined or incomplete artworks or were wrongly annotated with classes not present in the artwork. To quickly filter as many irrelevant images as possible we exploited a state-of-the-art model for face and pose detection (OpenPose <ref type="bibr" target="#b17">[25]</ref>) and removed all the images with at least one annotation but no detected pose. Furthermore, we manually inspected and possibly included by manually annotating the correct classes those images with one detected pose but no annotations.</p><p>Fragment images. Several images do not represent an entire artwork but only some part of it, e.g. a single panel of a polyptych or a specific part of a scene. All the images with metadata including keywords such as "detail", "fragment", or "portion", were manually processed. Some of them were kept in the data set because they contained specific iconography hints (e.g., an image containing only the ointment jar of Mary Magdalene).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Annotation creation and revision.</head><p>The data set was initially labelled with iconography class keywords found in the artwork title, description, tags and other metadata. The automatically assigned labels have been validated by manually inspecting a random sample of ∼ 30% of the items. In 5% of the cases we found that keywords were misleading or too broad (e.g. John or Mary without further specification) and referred to unrelated paintings.</p><p>3.1.4 Data set split. The data set is split into training (33,983 images), validation (4,248 images) and test (4,248 images) by keeping the distribution of each class in the 3 splits balanced, e.g. 80% of Virgin Mary in the training, 10% in the validation and 10% in the test set. <ref type="table" target="#tab_3">Table 4</ref> shows the total number of images for each class and the number of images with no annotated class. There is a sensible imbalance among the classes, with Virgin Mary being depicted in 19,365 images while Anthony of Padua in 214 images. <ref type="figure" target="#fig_1">Figure 2</ref> shows the distribution and the co-occurrence of classes in the training set. Co-occurrence gives the percentage of images of class X that contain also an annotation for class Y, e.g. 58.68% of images annotated with Mary Magdalene are annotated also with Virgin Mary. The validation and test set have a similar distribution. Some classes have a high co-occurrence (e.g., Peter and Paul or Mary Magdalene and Virgin Mary).</p><p>High co-occurrence values are due to the presence in the data set of polyptychs and of complex scenes depicting multiple characters. Such frequently co-occurring classes may create confusion in the model and be more difficult to distinguish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Architecture</head><p>The developed classifier exploits a backbone based on ResNet50 <ref type="bibr" target="#b41">[49]</ref> trained on the ImageNet data set <ref type="bibr" target="#b30">[38]</ref>. Such architecture is made fully convolutional by replacing the last two layers (average pooling and fully connected layers) with a 1x1 convolution layer, which outputs one channel for each class of the data set and acts as a classifier. We decided to use a pre-trained model instead of performing the training from scratch, due to the limited number of training images available, their high complexity and variability (many of them contain difficult scenes with numerous subjects) and the complexity of the network.</p><p>During the training phase, images are transformed and augmented. First of all, they are padded to a square, based on their largest dimension, then they are resized to a fixed square size and normalized by the mean and standard deviation of the data set. The padding step is useful to avoid distortions and keep the aspect ratio unmodified after the resizing, while the resizing is useful to train on batches of multiple samples and to fit more images in the GPU memory. The augmentation performed is an horizontal flip with a probability of 50%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fine-tuning</head><p>Transfer Learning (TL) is an effective technique that exploits the feature extraction capability of a model trained in a given domain to support a task in a different one. TL works by fine tuning, i.e., by retraining only selected layers of the original model, normally the deepest ones that work at an abstraction level that is more domain-dependent. TL has been recently shown to improve performance in art-related classification and detection tasks <ref type="bibr" target="#b19">[27,</ref><ref type="bibr" target="#b77">85]</ref>. We apply TL to the original ResNet50 architecture and fine-tune all the layers except the initial 7x7 convolution, the 3x3 max pooling layers, and the first two residual blocks. This allows the model to exploit both low-level features, which are more general purpose (e.g. edges, corners, shapes, etc.), learned from a great amount of natural images, and mid and high-level features learned from artworks during fine-tuning. The fine-tuned layers were trained with a lower learning rate with respect to the 1x1 convolution layer, to gradually adapt the previously learned features to the artwork domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Output</head><p>The outputs of the network are:</p><p>• A value for each class denoting the confidence of the classification.</p><p>• Class-aware cues, represented by the Class Activation Maps (CAMs) <ref type="bibr" target="#b81">[89]</ref>, which highlight the areas of the image contributing most to its assignment to a class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>In this section we present a quantitative and qualitative analysis of the iconography classification performances on the ArtDL data set. Experiments were performed on a subset composed of single-label images of the 10 selected classes. Note that being single-label does not imply that the image contains only one character. A complex scene can be annotated with only one class and is still considered single-label, as can be seen in <ref type="figure" target="#fig_6">Figure 6</ref>. Exploiting images without annotations and with multiple labels is part of our future work. The image subset used in the experiments contains 18,637 images: 14,912 for training, 1,861 for validation and 1,864 for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quantitative results</head><p>The evaluation metrics used for the quantitative analysis are: Precision, Recall, Average Precision (AP) and Confusion Matrix. Due to the high imbalance of the data set, Accuracy is not appropriate to assess the performances of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Fine-tuning.</head><p>As explained in Section 3.3, the architecture used in this work is a Fully Convolutional ResNet50 network pre-trained on ImageNet. A comparison of alternative configurations has been performed to determine the most effective freezing strategy to apply during fine tuning. <ref type="figure" target="#fig_2">Figure 3</ref> shows the performances obtained when freezing the architecture at different layers. The best results are obtained by freezing the first few layers, which learn low-level features, and by fine-tuning all the deeper layers; training only the classifier while freezing all the pre-trained layers yielded the worst results. These findings are consistent with the literature <ref type="bibr" target="#b79">[87]</ref>: fine-tuning almost all the layers of the architecture is required due to the different domain and nature of ImageNet (the data set used to pre-train the architecture) and the targeted iconography data set. 4.1.2 Data set resampling. As mentioned in Section 3.1 the ArtDL data set is characterized by a rather high class imbalance. Several techniques can be exploited to address class imbalance during training. We compared the techniques of weighted loss, undersampling of the majority classes, and oversampling of the minority classes. Oversampling of the minority classes to the majority class Virgin Mary, applied before training. proved the best option and yielded a sensible improvement to both quantitative and qualitative results.   <ref type="table" target="#tab_4">Table 5</ref> shows the evaluation results on the test set for each iconography class. Almost all the classes have more than 68% of precision with some reaching ∼ 85% while having ∼ 60% of recall. Virgin Mary is the class with the best performances, as expected due to the high number of images belonging to this class. Paul is the one with the worst performances: this result can be attributed to its rather generic iconography: the saint is most often represented as a common bearded man and only in very few images has the sword in his hand, which is the distinctive attribute of the class. Other classes, such as Saint Sebastian, have a number of images similar to Paul but their distinctive iconography attributes are much more frequently displayed in the artworks. The obtained results are consistent and even better with respect to those found in the previous research for artwork content analysis (reported also in <ref type="table">Table 1</ref>). In <ref type="bibr" target="#b39">[47]</ref> and <ref type="bibr" target="#b40">[48]</ref>, which are the works most closely related to ours, the authors respectively report a mean AP of 62.7% and 69.2% for the classification task; <ref type="bibr" target="#b29">[37]</ref> reaches a mean AP of 68.5% on the classification of generic objects in artworks. These figures are obtained with different tasks and data sets and therefore do not constitute a head-to-head comparison. <ref type="figure" target="#fig_3">Figure 4</ref> shows the percentage of confusion between classes. Such an analysis allows one to better understand which class Y is predicted instead of the real class X and how frequent is such a wrong prediction, easing the diagnosis of classification errors. For completeness, the table includes also the None label, to address the images with a ground truth class but no predicted classes. The table highlights the quite strong discriminative power of the model which distinguishes well most classes. Some cases deserve attention: Saint Dominic is wrongly predicted ∼ 42% of the times as Virgin Mary. This is due to the fact that the respective images are the least present in the data set and the model falls back to the most represented class. Adding more and diverse examples of the class would eliminate the confusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Classification evaluation.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Qualitative results</head><p>The iconography of Christian saints relies on the presence of specific symbolic attributes <ref type="bibr" target="#b50">[58]</ref>. This makes the classification task particularly interesting, because one can use the interpretation tools described in Section 2 to understand how the model mimics the human behavior in recognizing a saint, either by looking at the distinctive attributes or at the global context in which the character is embedded. For this purpose, we examined the CAMs produced by our architecture for a number of sample images. <ref type="figure" target="#fig_4">Figure 5</ref> contains six test images, depicting different scenes, in which at least an example for each class is visible. For each original test image (left), we also show the CAM (center) of the most prominent class for each example and the original image overlaid with the CAM (right).  It is noticeable that the area that activates the network the most is the ointment jar in the bottom center of the painting, one of the identifying symbols of Mary Magdalene. We can also note a less strong activation induced by the presence of her hairs, which are a well-known characterizing attribute of the saint. In other paintings this symbol yields a very high activation. <ref type="figure" target="#fig_4">Figure 5</ref>.B 3 depicts St. Jerome in the desert. From the CAM, we can see that the model learns to recognize the saint by his face and beard. As for St. Magdalene, the model is also able to capture a specific symbol used for identifying St. Jerome, the lion; which has a very high activation. In other paintings, the area with the highest activation is his red flat-top cardinal's hat.</p><p>If we look at <ref type="figure" target="#fig_4">Figure 5</ref>.C 4 , we can see St. Sebastian who is recognizable by his body tied to a tree and shot with arrows. The CAM shows that the arrows correspond to the areas that contribute most to the classification and are extracted as the salient features of the recognized subject following the iconography very precisely. We can observe that the naked torso of St. Sebastian is not useful to recognize the class because there are a lot of scenes with other naked men, e.g., "The Crucifixion of Jesus" or "The Baptism of Jesus".  Here, we can see that the main characteristic that the model uses to classify Mary is her veiled head. But the activation area covering the Child Jesus shows the utility of the context for the recognition; the model has learned that also Child Jesus is important to recognize Mary. In the iconography and in the training images, these two subjects are in most cases very close to each other and sometimes even overlapping. <ref type="figure" target="#fig_4">Figure 5</ref>.E 6 shows an example where the model correctly classifies St. John the Baptist. The most activating region is the head of the saint; another area useful for the classification task is the saint's ragged clothing. Saint John the Baptist usually appears in complex scenes with other male characters: by looking at the CAMs in other paintings, e.g., representations of "The baptism of Christ", one can note that the saint is often confused with Jesus Christ or the naked body of other men.</p><p>Figure 5.F 7 shows Francis of Assisi. As we can see, the saint is mainly recognized by his face and by the white cord of his clothing, which is a specific iconography symbol for this class. Even if the training classes include Anthony of Padua, who is represented very similarly to Francis of Assisi, the classifier differentiates the two classes well <ref type="figure" target="#fig_3">(Figure 4)</ref>.</p><p>From the presented examples and from many other similar cases, we can observe that the proposed architecture, even if based on a quite simple architecture exploiting a model pre-trained on natural images and fine-tuned with rather noisy artwork images, learns to discriminate well the iconography classes using the same clues that we, as humans, consider important when describing the themes of a painting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">False Positive analysis.</head><p>Mistaken FP predictions can happen because the model correctly predicts the classes portrayed in the image but the ground truth annotations are wrong or missing. This motivation is especially relevant in our case in which annotations were obtained semi-automatically and are both scarce and noisy. <ref type="figure" target="#fig_6">Figure 6</ref> shows two cases of false false positives, i.e., images for which the model correctly predicts the classes, but the noisy ground truth misses the annotations and thus the predictions are mistakenly counted as a false positive. <ref type="figure" target="#fig_6">Figure 6</ref>.A 8 shows Virgin Mary holding Child Jesus between Jerome and Peter. The model classifies with over 90% probability the presence of Jerome and Virgin Mary even if only Peter is included in the annotations of the image. The reported CAMs show the attention area. These results are consistent with the test images presented in <ref type="figure" target="#fig_4">Figure 5</ref>: Jerome is recognized by the lion at his feet and Virgin Mary is localized by her face and the contextual presence of the Child. <ref type="figure" target="#fig_6">Figure 6</ref>.B 9 shows Virgin Mary holding Child Jesus and surrounded by saints. In this case, Virgin Mary is the only annotated class but the model can also correctly recognize Peter and Paul. From the CAMs, we can see that there is no confusion between the three classes.</p><p>These results suggest that we could use the output of the model, especially when there is a strong classification score, to iteratively refine the data set labels and thus increase the data set completeness and the model performance. The same approach could be used to support the extension of the data set, by automatically proposing candidate annotations for the new images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS AND FUTURE WORK</head><p>In this work, we have presented a novel artworks iconography data set (ArtDL) and a simple architecture for the classification of iconographic entities in Christian art paintings. Evaluation results show good performance even in presence of the label noise produced by the semi-automatic procedure employed for data collection.</p><p>Future work will concentrate on the following objectives;</p><p>• Data set improvement and extension: we plan to use the current classifier to reduce the label noise and to incorporate more iconography classes. • Architecture improvement: we aim at improving the classifier by applying techniques for learning with scarce labels (e.g., label refinery <ref type="bibr" target="#b7">[15]</ref>) and semi-supervised learning methods (e.g., classifier improvement with Generative Adversarial Networks <ref type="bibr" target="#b67">[75]</ref>). The resulting model will be also applied to multi-object classification. • Object detection and instance segmentation support: iconography studies require not only the detection of classes but also of their position and mutual spatial relations. To this end, we are building an object detection and instance segmentation architecture, exploiting the CAMs of the classifier to enable the semi-automatic creation of the bounding boxes and pixel-level annotations required for training object detectors, along the lines of <ref type="bibr" target="#b39">[47]</ref> and <ref type="bibr" target="#b3">[11]</ref>. Our ultimate goal is to cover the entire IconClass dictionary, which features 28k classes. This long term goal requires effective IT-enabled tools for the annotation process, which can be supported by the automatic classification of single characters and by the inference of more complex classes comprising multiple individuals in specific spatial relations (e.g., by predicting the class "Ann seldbritt" (IconClass 73A221) when Saint Ann appears holding the Virgin Mary and the baby Jesus in her lap). The envisioned iconography classifier and localization detector could support the study of the evolution of iconography across space and time, enabling advanced queries over art images collections that mix visual content and metadata (e.g., "Find all annunciations where the angel appears to the right of Mary" or "Find the earliest three-nails crucifixion in the collection").</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Examples of images in the data set and their annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Co-occurrence matrix of the 10 classes present in the training split of ArtDL. Each value is the percentage of images of class X that are belonging also to class Y, e.g. 21.03% images labelled with Anthony of Padua are annotated with Virgin Mary too.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Performances of the model when freezing at a specified layer and fine-tuning the following deeper layers. For each metrics, a single value is obtained by averaging across all the classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Confusion between classes. Rows are the ground truth classes and columns are the predicted classes. Values on the main diagonal are the precision of each class and values on the columns add up to 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Examples of Class Activation Maps on different test images and for different classes. (A) St. Mary Magdalene, (B) St. Jerome, (C) St. Sebastian, (D) Virgin Mary, (E) St. John the Baptist, (F) St. Francis of Assisi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>A 2 represents St. Mary Magdalene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Examples of images with missing ground truth annotations that the model is able to correctly extract. For each image here we present: the original painting and the original painting overlaid with the CAMs of the depicted classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>D 5 shows the Virgin Mary holding the Child Jesus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table /><note>Total number of images for each class. None represents the images with no annotated class. The number of images used for training, validation and test is also reported.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Evaluation metrics computed on the test set. For each class we report the number of test images and the values of the metrics used to evaluate the performances of the model. The last row contains the mean value over all the classes.</figDesc><table><row><cell>Class name</cell><cell cols="5"># Test Images Precision Recall F1-Score Average Precision</cell></row><row><cell>Anthony of Padua</cell><cell>14</cell><cell>72.73%</cell><cell>57.14%</cell><cell>64.00%</cell><cell>64.14%</cell></row><row><cell>Francis of Assisi</cell><cell>98</cell><cell>69.23%</cell><cell>82.65%</cell><cell>75.35%</cell><cell>76.06%</cell></row><row><cell>Jerome</cell><cell>118</cell><cell>70.77%</cell><cell>77.97%</cell><cell>74.19%</cell><cell>78.88%</cell></row><row><cell>John the Baptist</cell><cell>99</cell><cell>58.09%</cell><cell>79.80%</cell><cell>67.23%</cell><cell>75.69%</cell></row><row><cell>Mary Magdalene</cell><cell>90</cell><cell>79.27%</cell><cell>72.22%</cell><cell>75.58%</cell><cell>82.23%</cell></row><row><cell>Paul</cell><cell>52</cell><cell>54.55%</cell><cell>34.62%</cell><cell>42.35%</cell><cell>38.47%</cell></row><row><cell>Peter</cell><cell>119</cell><cell>72.95%</cell><cell>74.79%</cell><cell>73.86%</cell><cell>77.93%</cell></row><row><cell>Saint Dominic</cell><cell>29</cell><cell>50.00%</cell><cell>65.52%</cell><cell>56.72%</cell><cell>54.35%</cell></row><row><cell>Saint Sebastian</cell><cell>56</cell><cell>91.11%</cell><cell>73.21%</cell><cell>81.19%</cell><cell>82.46%</cell></row><row><cell>Virgin Mary</cell><cell>1189</cell><cell>93.04%</cell><cell>91.00%</cell><cell>92.01%</cell><cell>97.03%</cell></row><row><cell>Mean</cell><cell></cell><cell>71.17%</cell><cell>70.89%</cell><cell>70.25%</cell><cell>72.73%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Three nails crucifixions started replacing four nails ones in the middle of the XIII century; the number of nails helps researchers delimit the production period of an artwork<ref type="bibr" target="#b42">[50]</ref> </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">"Maddalena penitente", Turchi Alessandro detto Orbetto, 1635-1640 3 "I mercanti che avevano rubato l'asino chiedono perdono al santo", Maestro dei Gesuati, 1450-1459 4 "St. Sebastian", El Greco, 1600</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">"Apparizione della Madonna a San Filippo", Ricci Ubaldo, 1700-1749 6 "Saint John the Baptist", Lippo Memmi, 1330 -1340 7 "San Francesco", Domenico di Michelino, 1460 ACM J. Comput. Cult. Herit., Vol. 37, No. 4, Article 111. Publication date: August 2020. A Data Set and a Convolutional Model for Iconography Classification in Paintings • 111:15</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">"La vergine in trono con il Bambino e tra san Girolamo e san Pietro", Andrea d'Assisi, 1490 9 "Madonna della Cintola", Bernardo di Stefano Rosselli, 1480</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ICCD -Istituto Centrale per il Catalogo e la Documentazione</title>
		<ptr target="https://www.metmuseum.org" />
	</analytic>
	<monogr>
		<title level="m">The Metropolitan Museum of Art</title>
		<imprint/>
	</monogr>
	<note>Gallerix online museum. n.d.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">PHAROS: The International Consortium of Photo Archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Museo Nacional Del</forename><surname>Prado</surname></persName>
		</author>
		<ptr target="https://www.wikiart.org" />
	</analytic>
	<monogr>
		<title level="m">Web Gallery of Art, searchable fine arts database</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>Wikiart.org -Visual Art Encyclopedia</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wikidata</surname></persName>
		</author>
		<ptr target="https://www.wikidata.org/wiki/Wikidata:Main_Page" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2209" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recognizing Emotions From Abstract Paintings Using Non-Linear Matrix Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Jenaesthetics subjective dataset: analyzing paintings by subjective scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Seyed Ali Amirshahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Uwe Hayn-Leichsenring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Denzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Redies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining holistic and part-based deep representations for computational painting categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Rao Muhammad Anwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorma</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laaksonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval</title>
		<meeting>the 2016 ACM on International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="339" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Label Refinery: Improving ImageNet Classification through Label Progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hessam</forename><surname>Bagherinezhad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02641</idno>
		<ptr target="http://arxiv.org/abs/1805.02641" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Painting classification using a pre-trained convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sugata</forename><surname>Banerji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atreyee</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision, Graphics, and Image processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Classification of artistic styles using binarized features derived from a deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noga</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="71" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards a hierarchical multitask classification framework for cultural heritage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelhak</forename><surname>Belhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Bouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebti</forename><surname>Foufou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large age-gap face verification by feature injection in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Bianco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="36" to="42" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multitask Painting Categorization by Deep Multibranch Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Mazzini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Napoletano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raimondo</forename><surname>Schettini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="90" to="101" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multitask Painting Categorization by Deep Multibranch Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Mazzini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Napoletano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raimondo</forename><surname>Schettini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using CNN features to better understand what makes visual artworks special</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhardt</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Redies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">830</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computational and experimental approaches to visual aesthetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Brachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Redies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in computational neuroscience</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The cross-depiction problem: Computer vision algorithms for recognising objects in artwork and in photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongping</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadeo</forename><surname>Corradi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00110</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Artistic image classification: An analysis on the printart database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno Pinho Da</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessio</forename><surname>Del Bue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João Paulo</forename><surname>Costeira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="143" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fine-tuning convolutional neural networks for fine art classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Cetinic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomislav</forename><surname>Lipic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonja</forename><surname>Grgic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="107" to="118" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Deep Learning Perspective on Beauty, Sentiment, and Remembrance of Art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Cetinic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomislav</forename><surname>Lipic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonja</forename><surname>Grgic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="73694" to="73710" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Grad-cam++: Generalized gradientbased visual explanations for deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Chattopadhay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prantik</forename><surname>Howlader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vineeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="839" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-view feature combination for ancient paintings chronological classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingquan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Computing and Cultural Heritage</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>JOCCH)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep correlation features for image style classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ta</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ling</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM international conference on Multimedia</title>
		<meeting>the 24th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="402" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image style classification based on learnt deep correlation features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ta</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ling</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2491" to="2502" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Iconclass: an iconographic classification system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leendert D Couprie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Art Libraries Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="32" to="49" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The State of the Art: Object Retrieval in Paintings using Discriminative Regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The State of the Art: Object Retrieval in Paintings using Discriminative Regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference</meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Of gods and goats: Weakly supervised learning of figurative art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elliot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The art of detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elliot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="721" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Picasso, matisse, or a fake? Automated analysis of drawings at the stroke level for attribution and authentication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Elgammal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milko Den</forename><surname>Leeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Categorizing paintings in art styles based on qualitative color descriptors, quantitative global features and machine learning (QArt-Learn)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoe</forename><surname>Falomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lledó</forename><surname>Museros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismael</forename><surname>Sanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Gonzalez-Abril</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Domain transfer for delving into deep networks capacity to de-abstract art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corneliu</forename><surname>Florea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Badea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Florea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Vertan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scandinavian Conference on Image Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="337" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pandora: Description of a painting database for art movement recognition with baselines and perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corneliu</forename><surname>Florea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Răzvan</forename><surname>Condorovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Vertan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raluca</forename><surname>Butnaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Florea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruxandra</forename><surname>Vrânceanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th European Signal Processing Conference (EUSIPCO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="918" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adaptive sparse representation for analyzing artistic style of paintings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingquan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Computing and Cultural Heritage (JOCCH)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Detecting people in cubist art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiry</forename><surname>Ginosar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="101" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weakly Supervised Object Detection in Artworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Gonthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Gousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Said</forename><surname>Ladjal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bonfait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Multiple instance learning on deep features for weakly supervised object detection with extreme domain shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Gonthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saïd</forename><surname>Ladjal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Gousseau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01178</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Dictionary of Symbols, Images and Signs of Christian Art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerd</forename><surname>Heinz-Mohr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="volume">320</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fine-art painting classification via two-channel deep residual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingsheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Hua</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijiao</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Rim Conference on Multimedia</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Image processing for artist identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ella</forename><surname>C Richard Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hendriks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Igor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Berezhnoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James Z</forename><surname>Postma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="37" to="48" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A method for extracting emotion using colors comprise the painting image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwann</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyounoh</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="4985" to="5002" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Trentacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aseem</forename><surname>Agarwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Winnemoeller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1311.3715</idno>
		<title level="m">Recognizing image style</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Painter identification using local features and naive bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Object recognition supported by user interaction for service robots</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="474" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Painting-91: A large scale database for computational painting categorization. Machine Vision and Applications 25</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shida</forename><surname>Beigpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00138-014-0621-6</idno>
		<ptr target="https://doi.org/10.1007/s00138-014-0621-6" />
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="1385" to="1397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Saints and their Symbols: Recognizing Saints in Art and in Popular Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gioia</forename><surname>Lanzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">237</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Recognizing art style automatically in painting with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Lecoutre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Negrevergne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Yger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian conference on machine learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="327" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Aesthetic visual quality assessment of paintings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsuhan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of selected topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="236" to="252" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deepart: Learning joint representations of visual arts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>She</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM international conference on Multimedia</title>
		<meeting>the 25th ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1183" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cheung</surname></persName>
		</author>
		<title level="m">Visual Arts Search on Mobile Devices. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The rijksmuseum challenge: Museum-centered visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Van Gemert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Multimedia Retrieval</title>
		<meeting>International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">451</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The Rijksmuseum Challenge: Museum-Centered Visual Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E J</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Van Gemert</surname></persName>
		</author>
		<ptr target="https://ivi.fnwi.uva.nl/isis/publications/2014/MensinkICMIR2014" />
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia Retrieval</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Smooth grad-cam++: An enhanced inference level visualization technique for deep convolutional neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Omeiza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skyler</forename><surname>Speakman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Celia</forename><surname>Cintas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Komminist</forename><surname>Weldermariam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.01224</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Studies in Iconology: Humanistic Themes in the Art of the Renaissance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Panofsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1939" />
			<biblScope unit="volume">262</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Cross-layer features in convolutional neural networks for generic classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsuhan</forename><surname>Kuan-Chuan Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3057" to="3061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Toward correlating and solving abstract tasks using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsuhan</forename><surname>Kuan-Chuan Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Color multi-fusion fisher vector feature for fine art painting categorization and influence analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajit</forename><surname>Puthenputhussery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingfeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Sparse representation based complete kernel marginal fisher analysis framework for computational art painting categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajit</forename><surname>Puthenputhussery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingfeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="612" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Deep transfer learning for art classification problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthia</forename><surname>Sabatelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Geurts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Large-scale classification of fine-art paintings: Learning the right metric on the right feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Elgammal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00855</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Improved Techniques for Training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasaath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Computer analysis of art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">A</forename><surname>Tarakhovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Computing and Cultural Heritage (JOCCH)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aubry</forename><surname>Mathieu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02678</idno>
		<title level="m">Discovering Visual Patterns in Art Collections with Spatially-consistent Feature Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6806</idno>
		<title level="m">Striving for simplicity: The all convolutional net</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Artpedia: A New Visual-Semantic Dataset with Visual and Contextual Sentences in the Artistic Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Stefanini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Cornia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Baraldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Corsini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International Conference on Image Analysis and Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">OmniEyes: Analysis and Synthesis of Artistically Painted Eyes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjorgji</forename><surname>Strezoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogier</forename><surname>Knoester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Nanne Van Noord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="628" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Omniart: multi-task deep learning for artistic data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjorgji</forename><surname>Strezoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Worring</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.00684</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Omniart: A large-scale artistic benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjorgji</forename><surname>Strezoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Multimedia Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">88</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Communications, and Applications (TOMM)</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Ceci n&apos;est pas une pipe: A deep convolutional network for fine-art paintings classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chee</forename><surname>Wei Ren Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hernán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoshi</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE international conference on image processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3703" to="3707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Detecting people in artwork with CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Westlake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongping</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="825" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Bam! the behance artistic media dataset for recognition beyond photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wilber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Collomosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1202" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Fine-art painting classification via two-channel dual path networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingsheng</forename><surname>Sheng-Hua Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Machine Learning and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="137" to="152" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Classifying paintings by artistic genre: An analysis of features &amp; classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Zujovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Gandy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thrasyvoulos N</forename><surname>Pappas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Workshop on Multimedia Signal Processing. IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
