<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CLOUD-NET: AN END-TO-END CLOUD DETECTION ALGORITHM FOR LANDSAT 8 IMAGERY</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-01-29">29 Jan 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sorour</forename><surname>Mohajerani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering Science</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<settlement>Burnaby</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parvaneh</forename><surname>Saeedi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering Science</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<settlement>Burnaby</settlement>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CLOUD-NET: AN END-TO-END CLOUD DETECTION ALGORITHM FOR LANDSAT 8 IMAGERY</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-01-29">29 Jan 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cloud detection in satellite images is an important first-step in many remote sensing applications. This problem is more challenging when only a limited number of spectral bands are available. To address this problem, a deep learning-based algorithm is proposed in this paper. This algorithm consists of a Fully Convolutional Network (FCN) that is trained by multiple patches of Landsat 8 images. This network, which is called Cloud-Net, is capable of capturing global and local cloud features in an image using its convolutional blocks. Since the proposed method is an end-to-end solution no complicated pre-processing step is required. Our experimental results prove that the proposed method outperforms the state-ofthe-art method over a benchmark dataset by 8.7% in Jaccard Index.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Precise identification/measurement of cloud coverage is a crucial step in the analysis of satellite imagery. For instance, clouds could occlude objects on the land and cause difficulty for many remote sensing applications including change detection, geophysical parameter retrieving, and object tracking <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b3">3]</ref>. In addition, transmission of images with high cloud coverage from satellites to the ground stations would be unnecessary and useless. Cloud coverage by itself might provide useful information about the climate parameters and natural disasters such as hurricanes and volcanic eruptions <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5]</ref>. As a result, identification of the cloud regions in images is an important pre-processing step for many applications.</p><p>In recent years, researchers have developed many cloud detection methods. These methods can be divided into three main categories: threshold-based <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b9">9]</ref>, handcrafted <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b11">11]</ref>, and deep learning-based <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13]</ref> approaches. Zhu et al. in <ref type="bibr" target="#b7">[7]</ref> introduced the Function of mask (Fmask) algorithm. Fmask basically consisted of a decision tree in which the potential cloud pixels were separated from non-cloud pixels based on multiple threshold functions. An improved version of Fmask was proposed in <ref type="bibr" target="#b8">[8]</ref>. This method benefited Our thanks goes to the Government of Canada for providing financial support for this project through the Technology Development Program. from Cirrus band of Landsat 8 to increase the accuracy of the detected clouds and is currently utilized to produce cloud masks of the Landsat Level-1 data products <ref type="bibr" target="#b14">[14]</ref>. Qui et al. in <ref type="bibr" target="#b9">[9]</ref> integrated Digital Elevation Map (DEM) information into Fmask and improved its performance in mountainous areas.</p><p>Haze Optimized Transformation (HOT) <ref type="bibr" target="#b10">[10]</ref> is among the most famous handcrafted algorithms for identification of clouds <ref type="bibr" target="#b11">[11]</ref>. In this algorithm, Zhang et al. utilized the correlation between two spectral bands of Landsat images to distinguish thin clouds from clear regions.</p><p>In recent years, deep learning-based methods have been proved to deliver good performance in many image processing applications. Researchers, in the remote sensing field, have also proposed such algorithms to address the problem of cloud detection. For instance, Xie et al. <ref type="bibr" target="#b12">[12]</ref> utilized two Convolutional Neural Networks (CNNs) for classification of sub-regions in an image into thick cloud, thin cloud, or noncloud classes. Many Fully Convolutional Neural Networks (FCNs) have been introduced for semantic segmentation of images. Most of these networks have an encoder-decoder architecture, which is inspired by U-Net <ref type="bibr" target="#b15">[15]</ref>. The effectiveness of U-Net has been proven in many other computer vision applications <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17]</ref>. Authors in <ref type="bibr" target="#b13">[13]</ref> used a FCN to segment the cloud regions of Landsat 8 images. This network was a very deep version of U-Net and was trained by images and their automatically generated Ground Truths (GTs).</p><p>In this paper, we introduce a new Cloud detection Network (Cloud-Net) for end-to-end pixel-level labeling of the satellite images. We specifically designed convolution blocks of Cloud-Net to capture complicated semantic features of clouds in remote sensing images. Unlike Fmask and the method in <ref type="bibr" target="#b12">[12]</ref>, Cloud-Net is capable of learning both local and global features from the entire scene in an end-to-end manner. It does not require any complicated pre-processing step such as super-pixel segmentation. In addition, unlike <ref type="bibr" target="#b13">[13]</ref>, Cloud-Net effectively utilizes the extracted features from its sophisticated convolution blocks to recover more accurate cloud masks. As a result, it delivers superior performance for cloud detection. Moreover, we have modified the dataset introduced in <ref type="bibr">[</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODOLOGY</head><p>To get a cloud mask at a CNN's output with the same size as the input image, the CNN should have two branches or arms. One of these arms-contracting arm-is responsible for extracting features and producing deep low-level features of the input image. The other arm-expanding arm-is to utilize those features and retrieve cloud attributes, recover them, and finally generate an output cloud mask. This output is, in fact, a probability map in which every pixel location correspond to the probability of that pixel belonging to the cloud class. Our cloud segmentation CNN, Cloud-Net, shares the same contracting and expanding arms as mentioned above. Indeed, it is inspired by the network used in <ref type="bibr" target="#b18">[18]</ref>. The architecture of the proposed Cloud-Net is displayed in <ref type="figure" target="#fig_0">Fig. 1</ref>. The blue bars and blocks form the contracting arm, while the green arrows and blocks build the expanding arm.</p><p>We have used Landsat 8 spectral images to train Cloud-Net. Landsat 8 contains two optical sensors to acquire eleven spectral bands. In this paper, we have utilized four of these bands-Band 2 to Band 5-since they are among the more common bands provided by most remote sensing satellites such as Sentinel-2, HJ-1, GF-2, etc. Since the spatial dimensions of the Landsat 8 images are very large, multiple non-overlapping 384 × 384 patches are extracted from each of those images. Before being utilized by Cloud-Net, these patches are downsized to 192 × 192. Therefore input size of the network is 192 × 192 × 4 and the size of the output cloud mask is 192 × 192 × 1.</p><p>The shortcut connections in each block (consisting of Concat, Copy, and Addition layers shown in <ref type="figure" target="#fig_0">Fig. 1</ref>) help the network to preserve and utilize the learned contexts from the earlier layers. As a result, the network is capable of capturing more cloud features. Another effect of these connections is speeding up the training process by preventing the network from experiencing the vanishing gradient phenomenon during backpropagation. In addition, the connections between two arms of the Cloud-Net help the expanding arm to generate a more accurate cloud mask.</p><p>Before each training epoch, commonly used geometric data augmentation techniques such as horizontal flipping, rotation, and zooming are applied. The activation function of the convolution layers of Cloud-Net is ReLU <ref type="bibr" target="#b19">[19]</ref>. A sigmoid layer is used in the last convolution layer of the network. For optimization of our model, the Adam gradient descent method <ref type="bibr" target="#b20">[20]</ref> is used. The following soft Jaccard loss function <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b21">21]</ref> is implemented to be minimized:</p><formula xml:id="formula_0">F L (t, y) = − N i=1 t i y i + N i=1 t i + N i=1 y i − N i=1 t i y i + .</formula><p>(1)</p><p>Here, t denotes the GT and y is the output array of Cloud-Net. y i and t i represent the ith pixel value of y and t, respectively. N is the total number of pixels in the GT. To avoid division by zero, = 10 −7 is added to the numerator and denominator of the loss function. The weights of the network are initialized with a uniform random distribution between [−1, 1]. The initial learning rate for the training of the model is set to 10 −4 . We applied a learning rate decay policy during the training phase with a decay rate of 0.7 and a patience factor of 15. This policy is continued until the learning rate reaches the value of 10 −9 . The proposed network is implemented using Keras framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL SETTING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.0.1.">Dataset</head><p>For training and testing of the proposed method, we have utilized the dataset introduced in [13] with a few modifications. This dataset has 18 Landsat 8 images for training and 20 images for testing. Among these 38 images, we have noticed that five of them (four from the training set and one from the test set) had inaccurate and uncertain GTs. We replaced these images with five new images. Next, the GTs of all images in the training set have been manually annotated. Therefore, instead of using automatically generated GTs of the training set in <ref type="bibr" target="#b13">[13]</ref>, we use more accurate and manually obtained GTs of the modified training set. This obviously affects the performance of the algorithm since the network learns the cloud features from correct images/GTs instead of inconsistent data. It is worth noting that after cropping the images of this dataset into 384 × 384 patches, 8400 patches for training and 9201 patches for testing are obtained. Cloud-Net is trained with 8400 training patches. This dataset, which is called 38-Cloud dataset, is publicly available to the research community by request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.0.2.">Test Phase</head><p>To obtain the cloud mask of an unseen test image, it is first cut into multiple 384 × 384 non-overlapping patches. Then, each patch is resized to 192 (to be fit the input of the network) and fed into the Cloud-Net. The predicted cloud probability map of each patch is obtained using the well-trained weights of our network. Next, it is binarized using a global threshold of 0.047 and then resized to 384×384. Once the predicted masks of all the patches are produced, they are stitched together to create the final cloud mask of the original test image. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.0.3.">Evaluation Metrics</head><p>Once the cloud mask of a complete Landsat 8 scene is generated, it is compared with the corresponding GTs. The predicted mask has two classes of "cloud" and "clear" for each pixel. The performance of our algorithm is quantitatively measured by evaluating the Overall Accuracy, Recall, Precision, Specificity, and Jaccard Index. These metrics are defined as follows:</p><p>Jaccard Index = T P T P + F N + F P Here TP, TN, FP, and FN are the total number of true positive, true negative, false positive, and false negative pixels, respectively. The Jaccard Index or intersection over union is a widely accepted metric for measuring the performance of many image segmentation algorithms <ref type="bibr" target="#b13">[13]</ref>. <ref type="table" target="#tab_1">Table 1</ref> represents the quantitative results of the proposed method over 20 test images of the 38-Cloud dataset. As shown in this table, Cloud-Net improves FCN's Jaccard Index by 8.7%. This indicates the superiority of our proposed network to FCN given that both are trained with the same training set. Indeed, to get the numerical results in the first row of <ref type="table" target="#tab_1">Table 1</ref>, we have trained FCN with the exact setting as <ref type="bibr" target="#b13">[13]</ref> using 38-Cloud training set and their more accurate GTs. Therefore, the numerical results of this experiment are fair to be compared with that of Cloud-Net. Please note that according to <ref type="bibr" target="#b13">[13]</ref>, FCN's overall accuracy is 88.30%. Also, the proposed method exceeds Fmask's performance, which is a widely used algorithm for cloud detection. Some qualitative results of the proposed method are displayed in <ref type="figure" target="#fig_1">Fig. 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Cloud-Net architecture. Conv T , Concat, and Maxpool refer to convolution transposed, concatenation, and maxpooling, respectively. The bars with gradient shading represent the feature maps. The numbers on the top and the bottom of the bars are the corresponding depth of each feature map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Cloud-Net visual results: (a),(e) natural color images from 38-Cloud test set, (b),(f) corresponding GTs (c),(g) results of FCN [13] (d),(h) results of Cloud-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>T P + T N T P + T N + F P + F N .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Cloud-Net performance over 38-Cloud test set (in %).</figDesc><table><row><cell cols="2">Method</cell><cell cols="4">Jaccard Precision Recall Specificity</cell><cell>Overall Accuracy</cell></row><row><cell>FCN</cell><cell>[13]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">trained with 38-Cloud</cell><cell>72.17</cell><cell>84.59</cell><cell>81.37</cell><cell>98.45</cell><cell>95.23</cell></row><row><cell cols="2">training set</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Fmask [8]</cell><cell>75.16</cell><cell>77.71</cell><cell>97.22</cell><cell>93.96</cell><cell>94.89</cell></row><row><cell cols="2">Proposed Cloud-Net</cell><cell>78.50</cell><cell>91.23</cell><cell>84.85</cell><cell>98.67</cell><cell>96.48</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">based algorithm for segmentation of clouds in remote sensing images was developed. The proposed FCN, Cloud-Net, benefits from sophisticated convolution blocks. Using a specialized architecture, Cloud-Net performance is superior to the competing state-of-the-art algorithms</title>
		<imprint/>
	</monogr>
	<note>In this paper, a deep learning-. In addition, we modified the dataset introduced in [13], giving researchers access to a more reliable and more accurate dataset for future analysis. 6. REFERENCES</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Comparison of elevation change detection methods from ICESat altimetry over the greenland ice sheet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Felikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Pritchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harpold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Schutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Geo. and Remote Sens</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="5494" to="5505" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Retrieving clear-sky atmospheric parameters from seviri and abi infrared radiances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Schmit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geoph. Research: Atmospheres</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">D15</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A simple modal approach to the problem of meteorological object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dell&amp;apos;acqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gamba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Geo. and Remote Sens. Symp. (IGARSS)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2152" to="2154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Remote sensing of global volcanic eruptions using fengyun series satellites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Geo. and Remote Sens. Symp. (IGARSS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4797" to="4800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simulation and prediction of hurricane lili during landfall over the central gulf states using mm5 modeling system and satellite data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fadavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Geo. and Remote Sens. Symp. (IGARSS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="36" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Characterization of the landsat-7 etm+ automated cloud-cover assessment (ACCA) algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Irish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arvidson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1179" to="1188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Object-based cloud and cloud shadow detection in landsat imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Woodcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. of Env</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">8394</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improvement and expansion of the fmask algorithm: cloud, cloud shadow, and snow detection for landsats 47, 8, and sentinel 2 images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Woodcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. of Env</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="269" to="277" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving fmask cloud and cloud shadow detection in mountainous area for landsats 4-8 images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. of Env</title>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="page" from="107" to="119" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An image transform to characterize and compensate for spatial variations in thin cloud contamination of landsat images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Guindon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cihlar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. of Env</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="173" to="187" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bag-of-words and object-based classification for cloud extraction from satellite imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. of Selected Topics in Applied Earth Obs. and Remote Sens</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="4197" to="4205" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multilevel cloud detection in remote sensing images based on deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. of Selected Topics in Applied Earth Obs. and Remote Sens</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="3631" to="3640" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A cloud detection algorithm for remote sensing images using fully convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohajerani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Krammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saeedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Workshop on Multimedia Sign. Proc. (MMSP)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Geological Survey (USGS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
		<ptr target="https://earthexplorer.usgs.gov/" />
		<imprint>
			<pubPlace>Online</pubPlace>
		</imprint>
	</monogr>
	<note>EarthExplorer</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">U-Net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">3D U-Net: Learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Içek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">S</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiresolutional ensemble of stacked dilated U-Net for inner cell mass segmentation in human embryonic images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saeedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Havelock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Image Proc. (ICIP)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3518" to="3522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CPNet: A context preserver convolutional neural network for detecting shadows in single rgb images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohajerani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saeedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Workshop on Multimedia Sign. Proc. (MMSP)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Int. Conf. on Mach. Learning (ICML)</title>
		<meeting>the Int. Conf. on Mach. Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the bayes-optimality of f-measure maximizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Willem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krzysztof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Arkadiusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weiwei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyke</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3513" to="3568" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
