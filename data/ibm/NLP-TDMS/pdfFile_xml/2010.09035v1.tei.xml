<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Structured Prediction for Facial Landmark Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisha</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Structured Prediction for Facial Landmark Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T15:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing deep learning based facial landmark detection methods have achieved excellent performance. These methods, however, do not explicitly embed the structural dependencies among landmark points. They hence cannot preserve the geometric relationships between landmark points or generalize well to challenging conditions or unseen data. This paper proposes a method for deep structured facial landmark detection based on combining a deep Convolutional Network with a Conditional Random Field. We demonstrate its superior performance to existing state-of-the-art techniques in facial landmark detection, especially a better generalization ability on challenging datasets that include large pose and occlusion. loss function, without any assumption. 4) Experiments on benchmark face alignment datasets demonstrate the advantages of the proposed method in achieving better prediction accuracy and generalization to challenging or unseen data than current state-of-the-art (SoA) models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Facial Landmark Detection</head><p>Classic facial landmark detection methods including Active Shape Model (ASM) (14; 28), Active Appearance Model (AAM) (13; 24; 27; 36), Constrained Local Model (CLM) (25; 37), and Cascade Regression (8; 6; 53; 7; 46) rely on hand-crafted shallow image features and are usually sensitive to initializations. They are outperformed by modern deep learning based methods.</p><p>Using deep learning for face alignment was first proposed in (39) and achieved better performance than classic methods. This purely deep appearance based approach uses a deep cascade convolutional network and coordinate regression in each cascade level. Later on, more work using purely deep appearance based framework for coordinate regression has been explored. Tasks-constrained deep convolutional network (TCDCN) (50) was proposed to jointly optimize facial landmark detection with correlated tasks such as head pose estimation and facial attribute inference. Mnemonic Descent Method (MDM) (42), an end-to-end trainable deep convolutional Recurrent Neural Network (RNN), was proposed where the cascade regression was implemented by RNN. Recently, heatmap learning based methods established new state-of-the-art for face alignment and body pose estimation (41;  30; 43). And most of these face alignment methods (5; 44) follow the architecture of Stacked Hourglass (30). The stacked modules refine the network predictions after each stack. Different from direct coordinate regression, it predicts a heatmap with the same size as the input image. Hybrid deep methods combine deep models with face shape models. One strategy is to directly predict 3D deformable parameters instead of landmark locations in a cascaded deep regression framework, e.g. 3D Dense Face Alignment (3DDFA) (54) and Pose-Invariant Face Alignment (PIFA) (23). Another strategy is to use the deformable model as a constraint to limit the face shape search space thus to refine the predictions from the appearance features, e.g. Convolutional Experts Constrained Local Model (CE-CLM) (48).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Facial landmark detection is to automatically localize the fiducial facial landmark points around facial components and facial contour. It is essential for various facial analysis tasks such as facial expression analysis, headpose estimation and face recognition. With the development of deep learning techniques, traditional facial landmark detection approaches that rely on hand-crafted low-level features have been outperformed by deep feature based approaches. The purely deep learning based methods, however, cannot effectively capture the structural dependencies among landmark points. They hence cannot perform well under challenging conditions, such as large head pose, occlusion, and large expression variation. Probabilistic graphical models such as Conditional Random Fields (CRFs), have been widely applied to various computer vision tasks. They can systematically capture the structural relationships among random variables and perform structured prediction. Recently, there have been works that combine deep models with CRF to simultaneously leverage convolutional neural networks' (CNNs) representation power and CRF's structure modeling power <ref type="bibr">(10; 9; 51)</ref>. Their combination has yielded significant performance improvement over methods that use either CNN or CRF alone. These works so far are mainly applied to classification tasks such as semantic image segmentation. Besides classification, some works apply the CNN and CRF model to human pose <ref type="bibr">(41; 12; 11)</ref> and facial landmark detection <ref type="bibr">(2; 44)</ref> . To simplify computational complexity, the CRF models are typically of special structure (e.g. tree structure), moreover, they employ approximate learning and inference criteria. In this work, we propose to combine CNN with a fully-connected CRF to jointly perform facial landmark detection in regression framework.</p><p>Compared to the existing works, the contributions of our work are summarized as follows: 1) We introduce the fully-connected CNN-CRF that produces structured probabilistic prediction of facial landmark locations. 2) Our model explicitly captures the structure relationship variations caused by pose and deformation, unlike some previous works that combine CNN with CRF using a fixed pairwise relationship. 3) We use an alternating method and derive closed-form solutions in the alternating steps for learning and inference, unlike previous works that use approximate methods such as energy minimization which ignores the partition function for learning and mean-field for inference. And instead of using discriminative criterion or other approximate loss functions, we employ negative log likelihood (NLL)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Structured Deep Models</head><p>To produce structured predictions, some works combine deep models with graphical models. Early works like <ref type="bibr" target="#b30">(31)</ref>   <ref type="bibr" target="#b9">(10)</ref> use CNN to output image dependent part presence as the unary term and spatial relationship as the pairwise potential in a tree-structured CRF and uses Dynamic Programming for inference. <ref type="bibr">Tompson et al. (41;</ref><ref type="bibr" target="#b39">40)</ref> jointly trained a CNN and a fully-connected MRF by using the convolution kernel to capture pairwise relationships among different body joints and an iterative convolution process to implement the belief propagation. The idea of using convolution to implement message passing has also been explored in <ref type="bibr" target="#b11">(12)</ref>, where structure relationships at the body joint feature level rather than the output level are captured in a bi-directional tree structured model. And the work of Chu et al. <ref type="bibr" target="#b11">(12)</ref> is applied to face alignment <ref type="bibr" target="#b43">(44)</ref> to pass messages between facial part boundary feature maps. As an extension to (12), (11) models structures in both output and hidden feature layers in CNN. Similarly, for image segmentation, DeepLab (9) uses fully connected CRF with binary cliques and mean-field inference, and (26) uses efficient piecewise training to avoid repeated inference during training. In <ref type="bibr" target="#b50">(51)</ref>, the CRF mean-field inference is implemented by RNN and the network is end-to-end trainable by directly optimizing the performance of the mean-field inference. Using RNN to implement message passing has also been applied to facial action unit recognition <ref type="bibr" target="#b14">(15)</ref>. In <ref type="bibr" target="#b19">(20)</ref>, the MRF deformable part model is implemented as a layer in a CNN.</p><p>Comparison. Compared to previous models serving similar purposes such as <ref type="bibr">(12; 11; 44)</ref> that assume a tree structured model with belief propagation as inference method, we use a fully-connected model. With a fully connected model, we don't need to specify a certain tree structured model, letting the model learn the strong or weak relationships from data, thus this method is more generalizable to different tasks. And the works <ref type="bibr">(41; 12; 11; 44; 51)</ref> use convolution to implement the pairwise term and the message passing process. The pairwise term, once trained, is independent of the input image, thus cannot capture the pairwise constraint variations across different conditions like target object rotation and object shape. However, we explicitly capture the object pose, deformation variations. Moreover, they employ approximate methods such as energy minimization ignoring the partition function for learning and mean-field for inference. In this paper we do exact learning and inference, capturing the full covariance of the joint distribution of facial landmarks given deformable parameters. Lastly, compared to the traditional CRF models (33; 34), the weights for each unary terms in our model are also outputs of the neural network whose inverse quantifies heteroscedastic aleatoric uncertainty of the unary prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>This section presents the proposed structured deep probabilistic facial landmark detection model. In this model, the joint probability distribution of facial landmark locations and deformable parameters are captured by a conditional random field model. Denote the face image as x, the 2D facial landmark locations as y, each landmark is y i , i = 1, . . . , N . The deformable model parameters that capture pose, identity and expression variation are denoted as ζ. The model parameter we want to learn is denoted as Θ. Assuming ζ is marginally dependent on x but conditionally independent of x given y, the graphical model is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model definition</head><p>Based on this definition and assumption, the joint distribution of landmarks y and deformable parameters ζ conditioned on the face image x can be formulated in a CRF framework and written as</p><formula xml:id="formula_0">p Θ (y, ζ | x) = 1 Z Θ (x) exp{− N i=1 φ θ1 (y i , x) − N i=1 N j=i+1 ψ Cij (y i , y j , ζ)}<label>(1)</label></formula><p>where Θ = [θ 1 , C ij ], θ 1 is neural network parameter, C ij is a 2 × 2 symmetric positive definite matrix that captures the spatial relationships between a pair of landmark points, y i and y j .</p><formula xml:id="formula_1">Z Θ (x) is the partition function. φ θ1 (y i , x)</formula><p>is the unary energy function with parameter θ 1 and ψ Cij (y i , y j , ζ) is the triple-wise energy function with parameter C ij .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Energy functions</head><p>We define the unary and triple-wise energy in Eq.(2) and Eq.(3) respectively.</p><formula xml:id="formula_2">φ θ1 (y i , x) = 1 2 [y i − µ i (x, θ 1 )] T Σ −1 i (x, θ 1 )[y i − µ i (x, θ 1 )] (2) ψ Cij (y i , y j , ζ) = [y i − y j − µ ij (ζ)] T C ij [y i − y j − µ ij (ζ)]<label>(3)</label></formula><p>where µ i (x, θ 1 ) and Σ i (x, θ 1 ) are the outputs of the CNN that represent mean and covariance matrix of each landmark given the image x. µ ij (ζ) represents the expected difference between two landmark locations. It is fully determined by the 3D deformable face shape parameters ζ, which contains rigid parameters: rotation R and scale S, and non-rigid parameters q.</p><formula xml:id="formula_3">µ ij (ζ) 1 = 1 λ SR(ȳ 3d i + Φ i q −ȳ 3d j − Φ j q)</formula><p>, whereȳ 3d is the 3D mean face shape, Φ is the bases of deformable model, they are learned from data. The deformable parameters ζ = [S, R, q] are jointly estimated with 2D landmark locations during inference. In this work, we assume weak perspective projection model. S is a 3 × 3 diagonal matrix that contains 2 independent parameters s x , s y as scaling factor (encode the camera intrinsic parameters) for column and row respectively. While R is a 3 × 3 orthonormal matrix with 3 independent parameters γ 1 , γ 2 , γ 3 as the pitch, yaw, roll rotation angle. Note that the translation vector is canceled by taking the difference of two landmark points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learning and Inference</head><p>We propose to implement the conditional probability distribution in Eq. (1) with a CNN-CRF model. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the CNN with parameter θ 1 outputs mean µ i (x, θ 1 ) and covariance matrix Σ i (x, θ 1 ) for each facial landmark y i , which together forms the unary energy function φ θ1 (y i | x). A fully-connected (FC) graph with parameter C ij 0 gives the triple-wise energy ψ Cij (y i , y j , ζ), if given ζ as well as the output from the unary, the FC can output E(x, ζ, Θ) and Λ p (x, ζ, Θ), the mean and precision matrix for the conditional distribution p Θ (y | ζ, x). The FC can be implemented as another layer following the CNN. Combining the unary and the triple-wise energy, we obtain the joint distribution p Θ (y, ζ | x). However, direct inference of y * , ζ * from p Θ (y, ζ | x) is difficult, therefore we iteratively infer from conditional distributions p Θ (y | ζ, x) and p Θ (ζ | y). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean and Precision matrix</head><p>During learning and inference, we need to compute conditional probability p Θ (y | ζ, x). By using the quadratic unary and triple-wise energy function, the distribution p Θ (y | ζ, x) is a multivariate Gaussian distribution that can be written as</p><formula xml:id="formula_4">p Θ (y | ζ, x) = 1 Z Θ (x, ζ) exp{− N i=1 φ θ1 (y i , x) − N i=1 N j=i+1 ψ Cij (y i , y j , ζ)} = exp{ 1 2 ln |Λ p (x, Θ, ζ)| − 1 2 [y − E(x, Θ, ζ)] T Λ p (x, Θ, ζ)[y − E(x, Θ, ζ)]}<label>(4)</label></formula><p>where Z Θ (x) is the partition function. E(x, Θ, ζ) and Λ p (x, Θ, ζ) is the mean and precision matrix of the multivariate Gaussian distribution. They are computed exactly during learning and inference.</p><p>The mean E can be computed by solving the linear system of equations Λ p E = b where Λ p , the precision matrix, is a symmetric positive definite matrix that can be directly computed from the coefficient in the unary and pairwise term as shown in Eq. (5), and b can be computed from Eq. <ref type="bibr" target="#b4">(5)</ref>.</p><formula xml:id="formula_5">Λp =    Λp11 . . . Λp1N . . . . . . . . . ΛpN1 . . . ΛpNN    , Λpii = Σ −1 i + j =i Cij Λpij = −Cij b =     b1 b2 . . . bN     , bi = Σ −1 i µi + j =i Cijµij<label>(5)</label></formula><p>From Eq.(5) we can see that the final inference result E i is a combination of µ i and µ j + µ ij , j ∈ {1, . . . , N }, j = i. To solve this linear system of equations, we use direct method for exact solution with a fast implementation by Cholesky factorization that requires O(N 3 ) FLOPs. For a practical implementation of the determinant to avoid numerical issues, we again use the Cholesky factorization of Λ p to get LL T = Λ p , then we compute the log determinant by ln |Λ p | = 2 ln diag(L) where diag(·) takes the diagonal element of a matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning</head><p>During learning, our goal is to optimize Θ given training data D = {x m , y m , m = 1, . . . , M }. We directly optimize the inference performance. Note that we don't have ground truth label for ζ, where ζ = {ζ 1 , . . . , ζ m }. We use an alternating method, based on the current Θ t ,ŷ t = E(x, Θ t , ζ t ), optimize ζ by</p><formula xml:id="formula_6">ζ t+1 m = arg min ζm − ln p Θ t (ŷ t m , ζ m | x m ) = arg min ζm ψ C t ij (ŷ t mi ,ŷ t mj , ζ m )<label>(6)</label></formula><p>Then based on current ζ t , optimize Θ by</p><formula xml:id="formula_7">Θ t+1 = arg min Θ Loss = arg min Θ − M m=1 ln pΘ(ym, ζ t m | xm) = arg min Θ − M m=1 ln pΘ(ym | ζ t m , xm) = arg min Θ M m=1 − 1 2 ln |Λp(xm, Θ, ζ t m )| + 1 2 [ym − E(xm, Θ, ζ t m )] T Λp(xm, Θ, ζ t m )[ym − E(xm, Θ, ζ t m )]<label>(7)</label></formula><p>The algorithm for this problem is designed to first set C ij = 0 and optimize θ 1 , the CNN parameter. Then set C ij = 0.01I and optimize ζ, then fix a subset of parameters from Θ and optimize the others alternately, whose pseudo code is shown in Algorithm 1.</p><formula xml:id="formula_8">Algorithm 1: Learning CNN-CRF Input: training data {x m , y m , m = 1, . . . , M }; Initialization: parameters Θ 0 = {θ 0 1 = randn, C 0 ij = 0}, t = 0 ; while not converge do θ t+1 1 = θ t 1 − η t 1 ∂Loss ∂θ1 ; t = t + 1; end y t m = E(x m , Θ t , ζ t ), C t ij = 0.01I; while not converge do</formula><p>Stage 1: Fix parameters Θ = Θ t , optimize ζ by Eq. <ref type="formula" target="#formula_6">(6)</ref>; Optimize deformable parameters while not converge do ζ t+1 m = arg min ζm ψ C t ij (ŷ t mi ,ŷ t mj , ζ m ),ŷ t+1 = E(x, Θ, ζ t+1 ), t = t + 1; end Θ t = Θ Stage 2: Fix ζ = ζ t , C ij = C t ij , update θ 1 using Eq. <ref type="formula" target="#formula_7">(7)</ref>; Update CNN parameters while not converge do θ t+1</p><formula xml:id="formula_9">1 = θ t 1 − η t 1 ∂Loss ∂θ1 ; t = t + 1; end [ζ t , C t ij ] = [ζ, C ij ] Stage 3: Fix ζ = ζ t , θ 1 = θ t 1 , update C ij using Eq. (7); Update CRF parameters while not converge do C t+1 ij = C t ij − η t 2 ∂Loss ∂Cij ; t = t + 1; end [ζ t , θ t 1 ] = [ζ, θ 1 ] end Inference</formula><p>The inference problem is a joint inference of ζ, y for each input face image x, defined in Eq. </p><p>We use an alternating method. Based on current y t , optimize ζ t by (see supplementary):</p><formula xml:id="formula_11">ζ t = arg max ζ ln p Θ (y t , ζ | x) = arg min ζ N i=1 N j=i+1 ψ Cij (y t i , y t j , ζ)<label>(9)</label></formula><p>Then based on current ζ t , optimize y t+1 by:</p><formula xml:id="formula_12">y t+1 = arg max y ln p Θ (y, ζ t | x) = arg max y ln p Θ (y | ζ t , x) = E(x, Θ, ζ t )<label>(10)</label></formula><p>The inference algorithm is shown in Algorithm 2.</p><p>Algorithm 2: Inference for CNN-CRF Input: face image x Initialization: y 0 i = µ i , i = 1, . . . , N , t = 0; while not converge do Update ζ by Eq. <ref type="bibr" target="#b8">(9)</ref>. ζ t = arg min ζ N i=1 N j=i+1 ψ Cij (y t i , y t j , ζ); Update y by Eq. (10). y t+1 = E(x, Θ, ζ t ); t = t + 1 ; end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets. We evaluate our methods on popular benchmark facial landmark detection datasets, including 300W (35), Menpo (49), COFW (6), 300VW (1). 300W has 68 landmark annotation. It contains 3837 faces for training and 300 indoor and 300 outdoor faces for testing. Menpo contains images from AFLW and FDDB with landmark re-annotation following the 68 landmark annotation scheme. It has two subsets, Menpo-frontal which has 68 landmark annotations for near frontal faces (6679 samples) and Menpo-profile which has 39 landmark annotations for profile faces (2300 samples). We use it as a test set for cross dataset evaluation. COFW has 1345 training samples and 507 testing samples, whose facial images are all partially occluded. The original dataset is annotated with 29 landmarks. We use the COFW-68 test set <ref type="bibr" target="#b18">(19)</ref> which has 68 landmarks re-annotation for cross dataset evaluation. 300VW is a facial video dataset with 68 landmarks annotation. It contains 3 scenarios: 1) constrained laboratory and naturalistic well-lit conditions; 2) unconstrained real-world conditions with different illuminations, dark rooms, overexposed shots, etc.; 3) completely unconstrained arbitrary conditions including various illumination, occlusions, make-up, expression, head pose, etc. We use the test set for cross dataset evaluation. Evaluation metrics. We evaluate our algorithm using the standard normalized mean error (NME) and the Cumulative Errors Distribution (CED) curve. Besides, the area-under-the-curve (AUC) and the failure rate (FR) for a maximum error of 0.07 are reported. Same as in <ref type="bibr" target="#b4">(5)</ref>, the NME is defined as the average point-to-point Euclidean distance between the ground truth (y gt ) and predicted (y pred ) landmark locations normalized by the ground truth bounding box size d = √ w bbox * h bbox ,</p><formula xml:id="formula_13">NME = 1 N N i=1 ||y (i) pred −y (i) gt ||2 d</formula><p>. Based on the NME in the test dataset, we can draw a CED Curve with NME as the horizontal axis and percentage of test images as the vertical axis. Then the AUC is computed as the area under that curve for each test dataset. Implementation details. To make a fair comparison with the SoA purely deep learning based methods (5), we use the same training and testing procedure for 2D landmark detection. The 3D deformable model was trained on the 300W-train dataset or 300W-LP dataset by structure from motion <ref type="bibr" target="#b3">(4)</ref>. For CNN, we use 4 stacks of Hourglass with the same structure as (5), each stack followed by a softmax layer to output a probability map for each facial landmark. From the probability map, we compute mean µ i and covariance Σ i . And we use additional softmax cross entropy loss and L1 loss on the mean <ref type="bibr" target="#b37">(38)</ref> to assist training which shows better performance empirically. Training procedure: The initial learning rate η 1 is 10 −4 for 15 epochs using a minibatch of 10, then dropped to 10 −5 and 10 −6 after every 15 epochs and keep training until convergence. The learning rate η 2 is set to 10 −3 . We applied random augmentations such as random cropping, rotation, etc. We first train the method on 300W-LP (54) dataset which is augmented from the original 300W dataset for large yaw pose. And then we fine-tune on the original 300W train dataset. Testing procedure: We follow the same testing procedure as <ref type="bibr" target="#b4">(5)</ref>. The face is cropped using the ground truth bounding box defined in 300W. The cropped face is rescaled to 256 × 256 before passed to the network. For the Menpo-profile dataset, the annotation scheme is different, we use the overlapping 26 points for evaluation, i.e., removing points other than the 2 endpoints on the face contour and the eyebrow respectively and removing the 5th point on the nose contour. In <ref type="table" target="#tab_1">Table 1</ref>, we compare with some most recent best results reported, in the 300W protocol that trains on LFPW-train, HELEN-train, AFW and tests on LFPW-test, HELEN-test, ibug and use NME normalized with inter-ocular/pupil distance as the metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparison with existing approaches</head><p>In <ref type="table" target="#tab_2">Table 2</ref>, we compare with other baseline facial landmark detection algorithms, including purely deep learning based methods such as TCDCN <ref type="bibr" target="#b49">(50)</ref> and FAN (5) as well as hybrid methods such as CLNF (2) and CE-CLM <ref type="bibr" target="#b47">(48)</ref>. The results for these methods are evaluated using the code provided by the authors in the same experiment protocol, i.e., same bounding box and same evaluation metrics. The CED curves on the 300W testset are shown in <ref type="figure">Fig. 3a</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-dataset Evaluation</head><p>Besides 300W testset, we evaluate the proposed method on Menpo dataset, COFW-68 testset, 300VW testset for cross dataset evaluation. The results are shown in <ref type="table" target="#tab_2">Table 2</ref> for Menpo and COFW-68 dataset and <ref type="table" target="#tab_3">Table 3</ref> for 300VW dataset. And the CED curves are shown in <ref type="figure">Fig. 3b, 3c</ref>, 3d respectively. The method is trained on 300W-LP and fine-tuned on 300W Challenge train set for 68 landmarks. We can see that compared to the results on 300W testset and Menpo-frontal dataset, where the SoA methods attaining saturating performance as mentioned in <ref type="formula" target="#formula_5">(5)</ref>, for cross-dataset evaluation in more challenging conditions such as COFW with heavy occlusion and Menpo-profile with large pose, the proposed method shows better generalization ability with a significant performance improvement. On the other hand, the proposed method shows smallest failure rate (FR) on all evaluated datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis</head><p>In this section, we report the results of sensitivity analysis and ablation study. If not specified, analysis is performed on test datasets with models trained on 300W-LP and fine-tuned on 300W train set. Sensitivity to challenging conditions. We evaluate different methods on challenging conditions caused by either high noise, low resolution, or different initializations in <ref type="figure" target="#fig_4">Fig. 5</ref>. Generally, the proposed CNN-CRF model is more robust under challenging conditions compared to a pure CNN model with the same structure, i.e. the CNN-CRF model with C ij = 0.  <ref type="table" target="#tab_4">Table 4</ref>, we evaluate the performance of a plain CNN prediction, the 3D deformable model fitting to the ground truth, and the joint CNN-CRF prediction accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a method combining CNN with a fully-connected CRF model for facial landmark detection. Compared to the state-of-the-art purely deep learning based methods, our method explicitly captures the structured relationships between different facial landmark locations. Compared to previous methods that combine CNN with CRF for human body pose estimation that learn a fixed pairwise relationship representation for different test samples implemented by convolution, our methods capture the structure relationship variations caused by pose and deformation. Moreover, we use a fully-connected model instead of a tree-structured model, obtaining a better representation ability. Lastly, compared to previous methods that do approximate learning such as omitting the partition function and inference such as mean-field method, we perform exact learning and inference, thus able to provide a better structured uncertainty. Experiments on benchmark datasets demonstrate that the proposed method outperforms the existing state-of-the-art methods, in particular under challenging conditions, for both within dataset and cross dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The graphical model. Dashed, dotted, solid lines represent dependencies between pairs of landmarks, landmark and deformable parameters, landmarks and face image, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Overall flowchart of the proposed CNN-CRF model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(8) y * , ζ * = arg max y,ζ ln p Θ (y, ζ | x)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>CED curves on different datasets (better viewed in color and magnified) CED curves on 300VW testset (better viewed in color and magnified)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Prediction error sensitivity to challenging conditions Ablation Study. The improvement of the proposed method lies in two aspects. On the one hand, the proposed softmax + L1 mean loss + Gaussian negative log likelihood (NLL) loss gives better results empirically. On the other hand, the joint training of the CNN-CRF model with the assistance of the deformable model captures structured relationships with pose and deformation awareness. To analyze the effect of the proposed method, in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>jointly train a CNN and a graphical model for image segmentation. Do et al.(16) introduced NeuralCRF for sequence labeling. And various works are explored for other tasks. For instance, Jain et al. (22) and Eigen et al. (18)'s work for image restoration, Yao et al. and Morin et al.'s work (47; 29) for language understanding, Yoshua et al., Peng et al. and Jaderberg et al.'s work (3; 32; 21) for handwriting or text recognition. Recently, for human body pose estimation, Chen et al.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison with SoA methods on 300W dataset using 300W protocol (NME normalized with interocular/pupil distance %)</figDesc><table><row><cell>Method</cell><cell>Subset</cell><cell>Com.</cell><cell>Chal.</cell><cell>Full</cell></row><row><cell></cell><cell cols="2">Inter-ocular distance</cell><cell></cell><cell></cell></row><row><cell>MDM (42)</cell><cell></cell><cell>-</cell><cell>-</cell><cell>4.05</cell></row><row><cell>RDR (45)</cell><cell></cell><cell>5.03</cell><cell>8.95</cell><cell>5.80</cell></row><row><cell>SAN (17)</cell><cell></cell><cell>3.34</cell><cell>6.60</cell><cell>3.98</cell></row><row><cell cols="2">LAB (4-stack) (44)</cell><cell>2.98</cell><cell>5.19</cell><cell>3.49</cell></row><row><cell cols="2">Our method (4-stack)</cell><cell>2.93</cell><cell>4.84</cell><cell>3.30</cell></row><row><cell></cell><cell cols="2">Inter-pupil distance</cell><cell></cell><cell></cell></row><row><cell>MDM (42)</cell><cell></cell><cell>4.83</cell><cell>10.14</cell><cell>5.88</cell></row><row><cell cols="2">LAB (4-stack) (44)</cell><cell>4.20</cell><cell>7.41</cell><cell>4.92</cell></row><row><cell cols="2">Our method (4-stack)</cell><cell>4.06</cell><cell>6.98</cell><cell>4.63</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Within and cross dataset prediction results (%)</figDesc><table><row><cell>Dataset</cell><cell></cell><cell></cell><cell>300W-test</cell><cell></cell><cell cols="3">Menpo-frontal</cell><cell cols="3">Menpo-profile</cell><cell cols="3">COFW-68 test</cell></row><row><cell>Method</cell><cell>Metric</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell></row><row><cell cols="2">TCDCN (50)</cell><cell>4.15</cell><cell>42.1</cell><cell>4.83</cell><cell>4.04</cell><cell>46.2</cell><cell>5.84</cell><cell>13.96</cell><cell>5.9</cell><cell>75.61</cell><cell>4.71</cell><cell>35.8</cell><cell>8.68</cell></row><row><cell>CFSS (52)</cell><cell></cell><cell>3.09</cell><cell>56.7</cell><cell>1.83</cell><cell>3.91</cell><cell>57.4</cell><cell>9.75</cell><cell>15.04</cell><cell>15.2</cell><cell>58.87</cell><cell>3.79</cell><cell>49.0</cell><cell>4.34</cell></row><row><cell>3DDFA (54)</cell><cell></cell><cell>6.90</cell><cell>20.6</cell><cell>30.00</cell><cell>6.57</cell><cell>28.7</cell><cell>24.57</cell><cell>8.37</cell><cell>20.5</cell><cell>41.43</cell><cell>8.13</cell><cell>18.2</cell><cell>43.79</cell></row><row><cell>CLNF (2)</cell><cell></cell><cell>4.22</cell><cell>47.6</cell><cell>6.67</cell><cell>3.74</cell><cell>55.4</cell><cell>5.82</cell><cell>8.32</cell><cell>27.8</cell><cell>27.65</cell><cell>4.75</cell><cell>42.9</cell><cell>10.65</cell></row><row><cell cols="2">CE-CLM (48)</cell><cell>3.05</cell><cell>56.9</cell><cell>2.33</cell><cell>2.78</cell><cell>63.3</cell><cell>1.66</cell><cell>4.63</cell><cell>45.2</cell><cell>7.17</cell><cell>3.36</cell><cell>52.4</cell><cell>2.37</cell></row><row><cell cols="2">FAN (reported in (5))</cell><cell>-</cell><cell>66.9</cell><cell>-</cell><cell>-</cell><cell>67.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SAN (17)</cell><cell></cell><cell>2.86</cell><cell>59.7</cell><cell>1.00</cell><cell>2.95</cell><cell>61.9</cell><cell>3.11</cell><cell>8.80</cell><cell>29.0</cell><cell>28.65</cell><cell>3.50</cell><cell>51.9</cell><cell>3.94</cell></row><row><cell>our method</cell><cell></cell><cell>2.21</cell><cell>68.1</cell><cell>0.17</cell><cell>2.01</cell><cell>71.0</cell><cell>0.16</cell><cell>3.03</cell><cell>60.0</cell><cell>1.96</cell><cell>2.55</cell><cell>63.2</cell><cell>0.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>300VW testset prediction results for cross-dataset evaluation (%)</figDesc><table><row><cell>Dataset</cell><cell></cell><cell cols="3">300VW-category1</cell><cell cols="3">300VW-category2</cell><cell cols="3">300VW-category3</cell></row><row><cell>Method</cell><cell>Metric</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell><cell>NME</cell><cell>AUC</cell><cell>FR</cell></row><row><cell cols="2">TCDCN (50)</cell><cell>3.49</cell><cell>51.2</cell><cell>1.74</cell><cell>3.80</cell><cell>45.8</cell><cell>1.76</cell><cell>4.45</cell><cell>43.8</cell><cell>8.85</cell></row><row><cell>CFSS (52)</cell><cell></cell><cell>2.44</cell><cell>67.0</cell><cell>1.66</cell><cell>2.49</cell><cell>64.3</cell><cell>0.77</cell><cell>3.26</cell><cell>60.5</cell><cell>5.18</cell></row><row><cell>3DDFA (54)</cell><cell></cell><cell>5.80</cell><cell>32.4</cell><cell>24.50</cell><cell>4.44</cell><cell>39.2</cell><cell>8.82</cell><cell>5.48</cell><cell>31.6</cell><cell>18.26</cell></row><row><cell>CLNF (2)</cell><cell></cell><cell>3.34</cell><cell>60.4</cell><cell>4.31</cell><cell>2.98</cell><cell>60.0</cell><cell>3.02</cell><cell>4.73</cell><cell>47.1</cell><cell>7.74</cell></row><row><cell cols="2">CE-CLM (48)</cell><cell>2.54</cell><cell>65.7</cell><cell>1.58</cell><cell>2.39</cell><cell>66.0</cell><cell>0.61</cell><cell>3.61</cell><cell>56.4</cell><cell>5.69</cell></row><row><cell cols="2">FAN (reported in (5))</cell><cell>-</cell><cell>72.1</cell><cell>-</cell><cell>-</cell><cell>71.2</cell><cell>-</cell><cell>-</cell><cell>64.1</cell><cell>-</cell></row><row><cell>SAN (17)</cell><cell></cell><cell>2.58</cell><cell>64.5</cell><cell>1.10</cell><cell>2.57</cell><cell>63.2</cell><cell>0.42</cell><cell>4.06</cell><cell>52.9</cell><cell>7.19</cell></row><row><cell>our method</cell><cell></cell><cell>1.91</cell><cell>73.3</cell><cell>0.36</cell><cell>1.97</cell><cell>71.6</cell><cell>0.04</cell><cell>2.50</cell><cell>67.4</cell><cell>1.68</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ablation study on 300W testset (%)</figDesc><table><row><cell>Method</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment The work described in this paper is supported in part by NSF award IIS #1539012 and by RPI-IBM Cognitive Immersive Systems Laboratory (CISL), a center in IBM's AI Horizon Network.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="http://ibug.doc.ic.ac.uk/resources/300-VW/" />
		<title level="m">300VW dataset</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Continuous conditional neural fields for structured regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadas</forename><surname>Baltrušaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="593" to="608" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2014</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Globally trained handwritten word recognizer using spatial representation, convolutional neural networks, and hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donnie</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. D. Cowan, G. Tesauro, and J. Alspector</editor>
		<imprint>
			<publisher>Morgan-Kaufmann</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="937" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">05</biblScope>
			<biblScope unit="page" from="878" to="892" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">How far are we from solving the 2d &amp; 3d face alignment problem? (and a dataset of 230,000 3d facial landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Tzimiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust face landmark estimation under occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Burgos-Artizzu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 IEEE International Conference on Computer Vision, ICCV &apos;13</title>
		<meeting>the 2013 IEEE International Conference on Computer Vision, ICCV &apos;13<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1513" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Face alignment by explicit shape regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="190" />
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint cascade face detection and alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="109" to="122" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2014</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Articulated pose estimation by a graphical model with image dependent pairwise relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1736" to="1744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Crf-cnn: Modeling structured information in human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Hongsheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="316" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Structured feature learning for pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV&apos;98</title>
		<editor>Hans Burkhardt and Bernd Neumann</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="484" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Active shape models-their training and application. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="38" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep structure inference network for facial action unit recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ciprian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meysam</forename><surname>Corneanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Madadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Escalera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trinh-Minh-Tri</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Artieres</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<editor>Yee Whye Teh and Mike Titterington</editor>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="13" to="15" />
		</imprint>
		<respStmt>
			<orgName>Chia Laguna Resort</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Style aggregated network for facial landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="379" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Restoring an image taken through a window covered with dirt or rain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings -2013 IEEE International Conference on Computer Vision, ICCV 2013</title>
		<meeting>-2013 IEEE International Conference on Computer Vision, ICCV 2013</meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="633" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Occlusion coherence: Detecting and localizing occluded faces. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<idno>abs/1506.08347</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deformable part models are convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="437" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Deep Structured Output Learning for Unconstrained Text Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supervised learning of image restoration with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhigulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Briggman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Helmstaedter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007-10" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pose-invariant face alignment via cnn-based dense 3d model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Jourabloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="203" />
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An active illumination and appearance model for face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kahraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Muhitin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Turkish Journal of Electrical Engineering and Computer Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="677" to="692" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Facetracer: A search engine for large collections of images with faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neeraj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shree</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 10th European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2008-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient piecewise training of deep structured models for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="3194" to="3203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Active appearance models revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="164" />
			<date type="published" when="2004-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Locating facial features with an extended active shape model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Milborrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Nicolls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th European Conference on Computer Vision: Part IV, ECCV &apos;08</title>
		<meeting>the 10th European Conference on Computer Vision: Part IV, ECCV &apos;08<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hierarchical probabilistic neural network language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics</title>
		<editor>Robert G. Cowell and Zoubin Ghahramani</editor>
		<meeting>the Tenth International Workshop on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="246" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016 -14th European Conference</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VIII</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Toward automatic phenotyping of developing embryos from videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Delhomme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Piano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Barbano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Img. Proc</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1360" to="1371" />
			<date type="published" when="2005-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Conditional neural fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liefeng</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, and A. Culotta</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1419" to="1427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Continuous conditional random fields for regression in remote sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladan</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Vucetic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoran</forename><surname>Obradovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on ECAI 2010: 19th European Conference on Artificial Intelligence</title>
		<meeting>the 2010 Conference on ECAI 2010: 19th European Conference on Artificial Intelligence<address><addrLine>Amsterdam, The Netherlands, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="809" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Continuous conditional random fields for efficient regression in large fully connected graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kosta</forename><surname>Ristovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladan</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Vucetic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoran</forename><surname>Obradovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Georgios Tzimiropoulos, Stefanos Zafeiriou, and Maja Pantic. 300 faces in-the-wild challenge. Image Vision Comput</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Epameinondas</forename><surname>Antonakos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A nonlinear discriminative approach to aam fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goecke</surname></persName>
		</author>
		<ptr target="https://app.dimensions.aion2018/11/15" />
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deformable model fitting by regularized landmark mean-shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="215" />
			<date type="published" when="2011-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.08229</idno>
		<title level="m">Integral human pose regression</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep convolutional network cascade for facial point detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2013.446</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3476" to="3483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Efficient object localization using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Joint training of a convolutional network and a graphical model for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1799" to="1807" />
		</imprint>
	</monogr>
	<note>NIPS&apos;14</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mnemonic descent method: A recurrent process applied for end-to-end face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mihalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nicolaou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Epameinondas Antonakos, and Stefanos Zafeiriou</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4177" to="4187" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Convolutional pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shih-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4724" to="4732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Look at boundary: A boundary-aware face alignment algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yici</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Recurrent 3d-2d dual learning for large-pose facial landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengtao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luoqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuecheng</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashraf</forename><surname>Kassim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Global supervised descent method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuehan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>De La Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2664" to="2673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recurrent conditional random field for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2014-05" />
			<biblScope unit="page" from="4077" to="4081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Convolutional experts constrained local model for 3d facial landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadas</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Baltrusaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV) Workshops</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The menpo facial landmark localisation challenge: A step towards the solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="2116" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Facial landmark detection by deep multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanpeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="94" to="108" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2014</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Conditional random fields as recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV &apos;15</title>
		<meeting>the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV &apos;15<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1529" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Face alignment by coarse-to-fine shape searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4998" to="5006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unconstrained face alignment via cascaded compositional learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3409" to="3417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Face alignment in full pose range: A 3d total solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
