<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Type-Driven Incremental Semantic Parsing with Polymorphism</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate Center City</orgName>
								<orgName type="institution">University of New York</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
							<email>liang.huang.sh@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Queens College City</orgName>
								<orgName type="institution">University of New York</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Type-Driven Incremental Semantic Parsing with Polymorphism</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semantic parsing has made significant progress, but most current semantic parsers are extremely slow (CKY-based) and rather primitive in representation. We introduce three new techniques to tackle these problems. First, we design the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers. Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction, which eliminates the need for a syntactic grammar such as CCG. Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing. Our system learns very accurate parses in GEOQUERY, JOBS and ATIS domains.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most existing semantic parsing efforts employ a CKY-style bottom-up parsing strategy to generate a meaning representation in simply typed lambda calculus <ref type="bibr" target="#b15">Zettlemoyer and Collins (2005)</ref>; <ref type="bibr" target="#b9">Lu and Ng (2011)</ref> or its variants <ref type="bibr" target="#b13">Wong and Mooney (2007)</ref>; <ref type="bibr" target="#b8">Liang et al. (2011)</ref>. Although these works led to fairly accurate semantic parsers, there are two major drawbacks: efficiency and expressiveness.</p><p>First, as many researches in syntactic parsing <ref type="bibr" target="#b10">Nivre (2008)</ref>; <ref type="bibr" target="#b17">Zhang and Clark (2011)</ref> have shown, compared to cubic-time CKY-style parsing, incremental parsing can achieve comparable accuracies while being linear-time, which means orders of magnitude faster in practice. We therefore introduce the first incremental parsing algorithm for semantic parsing. More interestingly, unlike syntactic parsing, our incremental semantic parsing algorithm, being strictly type-driven, directly employs type checking to automatically determine the direction of function application on-the-fly, thus reducing the search space and eliminating the need for a syntactic grammar such as CCG which explicitly encodes the direction of function application.</p><p>However, to fully exploit the power of type-driven incremental parsing, we need a more sophisticated type system than simply typed lambda calculus. We argue that it is beneficial to incorporate an explicit subtype hierarchy, such that ambiguous terms can be grounded based on context in a more explicit and declarative fashion. Compare the following two phrases:</p><p>(1) the mayor of New York?</p><p>(2) the capital of New York?</p><p>If we know that mayor is a function from city to person, then the first New York can only be of type city; similarly knowing capital maps states to cities disambiguates the second New York to be of type state. This can not be done using a simple type system with just entities and booleans. Now let us consider a more complex question which will be our running example in this paper:</p><p>(3) What is the capital of the largest state by area?</p><p>Since we know capital takes a state as input, we expect the largest state by area to return a state. But does largest always return a state type? Notice that it is polymorphic, for example, largest city by population, or largest lake by perimeter. So there is no unique type for largest: its return type should depend on the type of its first argument (city, state, or lake). This observation motivates us to introduce the powerful mechanism of parametric polymorphism from programming languages into the type system for natural language. For example, we can define the type of largest to be a template</p><formula xml:id="formula_0">largest : ('a→t)→('a→i)→'a</formula><p>where 'a is a type variable that can match any type (for formal details see Section 3). Just like in functional programming languages such as ML or Haskell, type variables can be bound to a real type (or a range of types) during function application, using the technique of type inference. In the above example, when largest is applied to city, we know that type variable 'a is bound to type city (or its subtype), so that largest would eventually return a city.</p><p>We make the following contributions:</p><p>• We design a linear-time incremental semantic parsing algorithm (Section 2), which is much more efficient than the majority of existing semantic parsers that are cubic-time CKY-based.</p><p>• In line with classical Montague theory <ref type="bibr" target="#b3">Heim and Kratzer (1998)</ref>, our parser is type-driven parsing instead of syntax-driven as in CCG-based efforts <ref type="bibr" target="#b15">Zettlemoyer and Collins (2005)</ref>; <ref type="bibr" target="#b7">Kwiatkowski et al. (2011)</ref>; <ref type="bibr" target="#b5">Krishnamurthy and Mitchell (2014)</ref> (Section 2.3).</p><p>• We introduce parametric polymorphism into natural language semantics (Section 3), along with proper treatment of subtype polymorphism, and implement Hindley-Milner style type inference <ref type="bibr">(Pierce, 2005, Chap.</ref> 10) during parsing (Section 3.2). 1</p><p>• We adapt the latent-variable max-violation perceptron training from machine translation <ref type="bibr" target="#b14">Yu et al. (2013)</ref>, which is a perfect fit for semantic parsing due to its huge search space (Section 4).</p><p>Experiments on GEOQUERY, JOBS and ATIS domains show close to state-of-the-art performances, and demonstrate the advantage of a powerful type system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Type-Driven Incremental Parsing</head><p>We start with the simplest meaning representation (MR), untyped lambda calculus, and then introduce typing and the incremental parsing algorithm for it. Later in Section 3, we add subtyping and type polymorphism to enrich the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Meaning Representation with Types</head><p>The untyped MR for the running example is: Q: What is the capital of the largest state by area? MR: (capital (argmax state size)) Note the binary function argmax(·, ·) is a higher-order function that takes two other functions as input: the first argument is a "domain" function that defines the set to search for, and second argument is an "evaluation" function that returns a integer for an element in that domain. In other words argmax(f, g) = argmax</p><p>x:f (x) g(x). (b) type-driven incremental parsing with subtyping (&lt;:) and type polymorphism (e.g., type variable 'a); see Section 3.2. The simply typed lambda calculus <ref type="bibr" target="#b3">Heim and Kratzer (1998)</ref>; <ref type="bibr" target="#b9">Lu and Ng (2011)</ref> augments the system with types, including base types (entities e, truth values t, or numbers i), and function types (e.g., e→t). So function capital is of type e→e, state is of type e→t, and size is of type e→i. The argmax function is of type (e→t)→(e→i)→e. 2 The simply typed MR is now written as (capital : e→e (argmax :(e→t)→(e→i)→e state : e→t size : e→i))).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Incremental Semantic Parsing: An Example</head><p>We use the above running example to explain our type-driven incremental semantic parsing algorithm. <ref type="figure" target="#fig_0">Figure 1</ref> (a) illustrates the full derivation.</p><p>Similar to a standard shift-reduce parser, we maintain a stack and a queue. The queue contains words to be parsed, while the stack contains subexpressions of the final MR, where each subexpression is a valid typed lambda expression. At each step, the parser choose to shift or reduce, but unlike standard shift-reduce parser, there is also a third possible action, skip, which skips a semantically vacuous word (e.g., "the", "of", "is", etc.). For example, the first three words of the example question "What is the ..." are all skipped (steps 1-3 in <ref type="figure" target="#fig_0">Figure 1 (a)</ref>).</p><p>The parser then shifts the next word, "capital", from the queue to the stack. But unlike incremental syntactic parsing where the word itself is moved onto the stack, here we need to find a grounded predicate in the GeoQuery domain for the current word. In this example we find the predicate:</p><p>capital : e→e and put it on the stack (step 4).</p><p>Next, words "of the" are skipped (steps 5-6). Then for word "largest", we shift the predicate argmax : (e→t)→(e→i)→e onto the stack (step 7), which becomes capital : e→e argmax : (e→t)→(e→i)→e.</p><p>At this step we have two expressions on the stack and we could attempt to reduce. But type checking fails because for left reduce, argmax expects an argument (its "domain" function) of type (e→t) which is different from capital's type (e→e), so is the case for right reduce.</p><p>So we have to shift again. This time for word "state" we shift the predicate state : e→t onto the stack, which becomes:</p><p>capital : e→e argmax : (e→t)→(e→i)→e state : e→t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type-Driven Reduce</head><p>At this step we can finally perform a reduce action, since the top two expressions on the stack pass the type-checking for rightward function application (a partial application): argmax expects an (e→t) argument, which is exactly the type of state. So we conduct a right-reduce, applying argmax on state, and the resulting expression is: (capital (argmax state size)) : e.</p><formula xml:id="formula_1">(</formula><p>Here we can see the novelty of our shift-reduce parser: its decisions are largely driven by the type system. When we attempt a reduce, at most one of the two reduce actions (left, right) is possible thanks to type checking, and when neither is allowed, we have to shift (or skip). This observation suggests that our incremental parser is more deterministic than those syntactic incremental parsers whose each step always faces a three-way decision (shift, left-reduce, right-reduce). We also note that this typechecking mechanism, inspired by the classical type-driven theory in linguistics <ref type="bibr" target="#b3">Heim and Kratzer (1998)</ref>, eliminates the need for an explicit encoding of direction as in CCG, which makes our formalism much simpler than the synchronous syntactic-semantic ones in most other semantic parsing efforts <ref type="bibr">Collins (2005, 2007)</ref>; <ref type="bibr" target="#b13">Wong and Mooney (2007)</ref>.</p><p>As a side note, besides function application, reduce also occurs when the top two expressions on the stack can be combined to represent a more specific meaning, which we call union.</p><p>For example, when parsing the phrase "major city", we have the top two expressions on the stack major : e→t city : e→t</p><p>We can combine the two expressions using predicate and since their types match, and get λx : e . (and : t→t→t (major : e→t x) (city : e→t x)),</p><p>where type t→t→t takes two booleans and return one (again, using currying notation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Subtype and Type Polymorphisms</head><p>As mentioned in Section 1, simply typed lambda calculus representation can not distinguish between Mississippi the river and Mississippi the state since they both have the same type e. Furthermore, currently function capital can apply to any entity type, for example capital(boston), which should have been disallowed by the type checker. So we need a more sophisticated type system that helps ground terms to real-world entities, and this refined type system will in turn help type-driven parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Augmenting MR with Subtyping</head><p>We first augment the meaning representation with a type hierarchy which is domain specific. For example <ref type="figure" target="#fig_1">Figure 2</ref> shows a (slightly simplified) version of the type hierarchy for GEOQUERY domain. Here the root type top has a subtype of locations, lo, which consists of two different kinds of locations, administrative units (au) including states (st) and cities (ct), and nature units (nu) including rivers (rv) and lakes (lk). We use &lt;: to denote the (transitive, reflexive, and antisymmetric) subtyping relation between types; for example in GEOQUERY we have st &lt;: lo, rv &lt;: nu, and T &lt;: top for any type T.</p><p>In addition we have an integer type i derived from the root type top. The boolean type t does not belong to the type hierarchy, because it does not represent the semantics from the task domain.</p><p>Each constant in the GEOQUERY domain is well typed. For example, there are states (mississippi:st), cities (boston:ct), rivers (mississippi:rv), and lakes (tahoe:lk). Note that the names like mississippi appears twice for two different entities. The fact that we can distinguish them by type is a crucial advantage of a typed semantic formalism.</p><p>Similarly each predicate is also typed. For example, we can query the length of a river, len:rv→i, or the population of some administrative unit, population:au→i. Notice that population(·) can be applied to both states and cities, since they are subtypes of administrative unit, i.e., st &lt;: au and ct &lt;: au. This is because, as in Java and C++, a function that expects a type T argument can always take an argument of another type S which is a subtype of T. More formally:</p><formula xml:id="formula_2">e 2 : S S &lt;: T (λx : T . e 1 ) e 2 → [x → e 2 ]e 1 ,<label>(4)</label></formula><p>where [x → e 2 ]e 1 means substituting all occurrences of variable x in expression e 1 with expression e 2 . For example, we can query whether two locations are adjacent, using next_to:lo→(lo→t), and similarly the next_to(·, ·) function can be applied to two states, or to a river and a city, etc. The above type system works smoothly for first-order functions (i.e., predicates taking atomic type arguments), but the situation with higher-order functions (i.e., predicates that take functions as input) is more involved. What is the type of argmax? One possibility is to define it to be as general as possible, as in the simply typed version (and many conventional semantic parsers):</p><p>argmax : (top→t)→(top→i)→top.</p><p>But this actually no longer works for our sophisticated type system for the following reason.</p><p>Intuitively, remember that capital:st→ct is now a function that takes a state as input, so the return type of argmax must be a state or its subtype, rather than top which is a supertype of st. But we can not simply replace top by st, since argmax can also be applied in other scenarios such as "the largest city" or "the longest river". In other words, argmax is a polymorphic function, and to assign a correct type for it we have to introduce type variables (widely used in functional programming languages such as Haskell and ML, and also in C++ templates). We define argmax : ('a→t)→('a→i)→'a where the type variable 'a is a place-holder for "any type".</p><p>Before we move on, there is an important consequence of polymorphism worth mentioning here. For the types of unary predicates such as city(·) and state(·) that characterize its argument, we define theirs argument types to be the required type, i.e., city : ct→t, and state : st→t. This might look a little weird since everything in the domain of those functions are always mapped to true; i.e., f (x) is either undefined or true, and never false for such f 's. This is different from classical simply-typed Montague semantics <ref type="bibr" target="#b3">Heim and Kratzer (1998)</ref> which defines such predicates as type top→t so that city(mississippi : st) returns false. The reason for our design is, again, due to subtyping and polymorphism: capital takes a state type as input, so argmax must returns a state, and therefore its first argument, the state function, must have type st→t so that the matched type variable 'a will be bound to st. This more refined design will also help prune unnecessary argument matching using type checking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parsing with Subtype Polymorphism and Parametric Polymorphism</head><p>We modify the previous incremental parsing algorithm with simple types (Section 2) to accommodate subtyping and polymorphic types. <ref type="figure" target="#fig_0">Figure 1 (b)</ref> shows the derivation of the running example using the new parsing algorithm. Below we focus on the differences brought by the new algorithm.</p><p>In step 4, unlike capital : e→e, we shift the predicate capital : st→ct and in step 7, we shift the polymorphic expression for "largest"</p><p>argmax : ('a→t)→('a→i)→'a which states the input side is reversed (contravariant). This might look counterintuitive at the first glance, but the intuition is that, it is safe to allow the function size of type lo→i to be used in the context where another type st→i is expected, since in that context the argument passed to size will be state type (st), which is a subtype of location type (lo) that size expects, which in turn will not surprise size. See the classical type theory textbook <ref type="bibr">(Pierce, 2002, Chap. 15</ref>.2) for details. See <ref type="figure" target="#fig_0">Figure 1 (b)</ref> for the full derivation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Training: Latent Variable Perceptron</head><p>We follow the Latent Variable Violation-Fixing Perceptron framework <ref type="bibr" target="#b4">Huang et al. (2012)</ref>; <ref type="bibr" target="#b14">Yu et al. (2013)</ref> for the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Framework</head><p>The key challenge in the training is that, for each question, there might be many different unknown derivations that lead to its annotated MR, which is known as the spurious ambiguity. In our type-driven incremental semantic parsing task, the spurious ambiguity is caused by how the expression templates are chosen and grounded during the shift step, and the different reduce orders that lead to the same result. We treat this unknown information as latent variable. More formally, we denote D(x) to be the set of all partial and full parsing derivations for an input sentence x, and mr (d) to be the MR yielded by a full derivation d. Then we define the sets of (partial and full) reference derivations as:</p><formula xml:id="formula_3">good i (x, y) ∆ = {d ∈ D(x) | |d| = i, ∃full derivation d s.t.</formula><p>d is a prefix of d , mr (d ) = y}, Those "bad" partial and full derivations that do not lead to the annotated MR can be defined as:</p><formula xml:id="formula_4">bad i (x, y) ∆ = {d ∈ D(x) | d ∈ good i (x, y), |d| = i}.</formula><p>At step i, the best reference partial derivation is</p><formula xml:id="formula_5">d + i (x, y) ∆ = argmax d∈good i (x,y) w · Φ(x, d),<label>(6)</label></formula><p>while the Viterbi partial derivation is</p><formula xml:id="formula_6">d − i (x, y) ∆ = argmax d∈bad i (x,y) w · Φ(x, d),<label>(7)</label></formula><p>where Φ(x, d) is the defined feature set for derivation d.</p><p>In practice, to compute Eq. 7 exactly is intractable, and we resort to beam search. Following <ref type="bibr" target="#b14">Yu et al. (2013)</ref>, we then find the step i * with the maximal score difference between the best reference partial derivation and the Viterbi partial derivation: <ref type="figure">y)</ref>), and do update:</p><formula xml:id="formula_7">i * ∆ = argmax i w · ∆Φ(x, d + i (x, y), d − i (x,</formula><formula xml:id="formula_8">w ← w + ∆Φ(x, d + i * (x, y), d − i * (x, y)) where ∆Φ(x, d, d ) ∆ = Φ(x, d) − Φ(x, d ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Forced Decoding</head><p>We use forced decoding to retrieve the reference derivations good i (x, y) for each question/MR pair (x, y) in Eq. 6. Unlike syntactic incremental parsing, where the forced decoding can be done in polynomial time <ref type="bibr" target="#b1">Goldberg et al. (2014)</ref>, we do not have an algorithm designed for efficient forced decoding. We apply exponential-time brute-force search to calculate good (x, y), during which we do pruning based on the predicate application orders.</p><p>However, this requires heavy computation we can not afford. In practice we choose multi-pass forced decoding. First we use brute-force search to decode, but with a time limit. Then we train a Perceptron using successfully decoded reference derivations, and use the trained Perceptron to decode the unfinished questions with a large beam. We then add the reference derivations newly discovered into the next step training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We implement our type-driven incremental semantic parser (TISP) using Python, and evaluate its performance of both speed and accuracy on GEOQUERY and JOBS datasets.</p><p>Our feature design is inspired by the very effective Word-Edge features in syntactic parsing <ref type="bibr" target="#b0">Charniak and Johnson (2005)</ref> and <ref type="bibr">MT He et al. (2008)</ref>. From each parsing state, we collect atomic features including the types and the leftmost and rightmost words of the span of the top 3 MR expressions on the stack, the top 3 words on the queue, the grounded predicate names and the ID of the expression template used in the shift action.</p><p>To ease the overfitting problem caused by the feature sparsity, we assign different budgets to different kinds of features and only generate feature combinations within a budget limit. We get 84 combined feature templates in total.</p><p>For evaluation, we follow <ref type="bibr" target="#b15">Zettlemoyer and Collins (2005)</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation on GEOQUERY Dataset</head><p>We first evaluate TISP on GEOQUERY dataset.</p><p>Following the scheme of <ref type="bibr" target="#b16">Zettlemoyer and Collins (2007)</ref>, we use the first 600 sentences of Geo880 as the training set and the rest 280 sentences as the testing set.</p><p>Note that we do not have a separate development set, due to the relatively small size of Geo880. So to find the best number of iterations to stop the training, we do a 10-fold cross-validation training over the training set, and choose to train 20 iterations and then evaluate.</p><p>We use two-pass forced decoding. In the initial brute-force pass we set the time limit to 1,200 seconds, and find the reference derivations for 530 of the total 600 training sentences, a coverage of ∼ 88%. In the second pass we set beam size to 16,384 and get 581 sentences covered (∼ 97%).</p><p>In the training and evaluating time, we use a very small beam size of 16, which gives us very fast decoding. In serial mode, our parser takes ∼ 83s to decode the 280 sentences (2,147 words) in the testing set, which means ∼ 0.3s per sentence, or ∼ 0.04s per word.</p><p>We compare the our accuracy performance with existing methods in <ref type="table">Table 1</ref>. Given that all other methods use CKY-style parsing, our method is well balanced between accuracy and speed.</p><p>In addition, to unveil the helpfulness of our type system, we train a parser with only simple types. <ref type="table">(Table 1)</ref> In this setting, the predicates only have primitive types of location lo, integer i, and boolean t, while the constants still keep their types. It still has the type system, but it is weaker than the polymorphic one. Its accuracy is lower than the standard one, mostly caused by that the type system can not help pruning the wrong applications like (population:au→i mississippi:rv).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluations on JOBS and ATIS Datasets</head><p>The JOBS domain contains descriptions about required and desired qualifications of a job. The qualifications include programming language (la), years of experience (ye), diplomat degree (de), area of fields (ar), platform (pa), title of the job (ti), etc. We show a simplified version of the type hierarchy for JOBS in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>Following the splitting scheme of <ref type="bibr" target="#b15">Zettlemoyer and Collins (2005)</ref>, we use 500 sentences as training set and 140 sentences as testing set. <ref type="table">Table 1</ref> shows that our algorithm achieves significantly higher recall than existing method of Zettlemoyer and Collins <ref type="formula">(2005)</ref>, although our precision is not as high as theirs. This is actually because our method parses a lot more questions in the dataset, as the column of the percentage of successfully parsed sentences suggests.</p><p>We also evaluate the performance of TISP on ATIS dataset as in <ref type="table">Table 1</ref>. ATIS dataset contains more than 5,000 examples and is a lot larger than GEOQUERY and JOBS. Our method achieves comparable performance on this dataset. Due to space constraints, we do not show its type hierarchy here.</p><p>6 Related Work <ref type="bibr" target="#b15">Zettlemoyer and Collins (2005)</ref> introduce a type hierarchy to semantic parsing and parse with typed lambda calculus combined with CCG. However, simply introducing subtyped predicates without polymorphism will cause type checking failures in handling high-order functions, as shown in Section 3. Furthermore, our system, being type-driven, almost completely rely on the types of MR expressions to guide parsing (except for some simple POS tag triggers) while their system is heavily CCG-based and syntax-driven. <ref type="bibr" target="#b6">Kwiatkowski et al. (2013)</ref> use "on-the-fly" matching to fetch the most possible predicate in the dataset for some MR subexpression. The matching happens at the end of parsing, and is constrained by the type of the subexpression. We do matching and parsing jointly, both of which are constrained by the typing, and affect the typing, which is more similar to how human do semantic parsing, i.e., we parse part of the sentence and bind that part to some specific meaning, and continue parsing using grounded meaning. <ref type="bibr" target="#b13">Wong and Mooney (2007)</ref> also use type information to help reduce unnecessary tree joining in decoding. However, their types are static, while our type system is stronger so that we can infer type from polymorphism, which gives use better search quality in decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have presented an incremental semantic parser that is guided by a powerful type system of subtyping and parametric polymorphism. This polymorphism greatly reduced the number of templates and effectively pruned search space during the parsing. Our parser is competitive with state-of-the-art accuracies, but, being linear-time, is orders of magnitude faster than CKY-based parsers in theory and in practice.</p><p>For future work, we would like to work on weakly supervised learning that learn from questionanswer pairs instead of question-MR pairs, where the datasets are larger, and TISP should benefit more on such problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Type-driven Incremental Semantic Parsing (TISP) with (a) simple types and (b) subtyp-ing+polymorphism on the example question: "what is the capital of the largest state by area?". Steps 5-6 and 10 are skip actions and thus omitted. The stack and queue in each row are the results after each action.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Type hierarchy for GEOQUERY domain (slightly simplified for presentation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Type hierarchy for JOBS domain (slightly simplified for presentation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Now if we want to continue reduction, it does not type check for either left or right reduction, so we have to shift again.So we move on to shift the final word "area" with the grounded predicate in GeoQuery database:size : e→i and the stack becomes (step 11):capital : e→e (argmax state) : (e→i)→e size : e→i.</figDesc><table><row><cell>while the stack becomes (step 9)</cell><cell></cell></row><row><cell>capital : e→e</cell><cell>(argmax state) : (e→i)→e</cell></row><row><cell cols="2">Now apparently we can do a right reduce supported by type checking (step 12):</cell></row><row><cell>capital : e→e</cell><cell>(argmax state size) : e</cell></row><row><cell cols="2">followed by another, final, right reduce (step 13):</cell></row></table><note>argmax state) : (e→i)→e</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>And after the shift in step 8, the stack becomes capital : st→ct argmax : ('a→t)→('a→i)→'a state : st→t At step 9, in order to apply argmax onto state : st→t, we simply bind type variable 'a to type st, i.e., argmax : (st→t)→(st→i)→st state : st→tAfter the shift in step 11, the stack becomes:capital : st→ct (argmax state) : (st→i)→st size : lo→i.</figDesc><table><row><cell>results in</cell><cell></cell></row><row><cell>(argmax state) : (st→i)→st</cell><cell></cell></row><row><cell>Can we still apply right reduce here? According to the subtyping rule (Eq. 4), we want</cell><cell></cell></row><row><cell>lo→i &lt;: st→i</cell><cell></cell></row><row><cell cols="2">to hold, knowing that st &lt;: lo. Luckily, there is a rule about function types in type theory that exactly fits</cell></row><row><cell>here:</cell><cell></cell></row><row><cell>A &lt;: B B→C &lt;: A→C</cell><cell>(5)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">There are three kinds of polymorphisms in programming languages: parametric (e.g., C++ templates), subtyping, and ad-hoc (e.g., operator overloading). See(Pierce, 2002, Chap. 15) for details.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that the type notation is always curried, i.e., we represent a binary function as a unary function that returns another unary function. Also the type notation is always right-associative, so (e→t)→((e→i)→e) is also written as (e→t)→(e→i)→e.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Coarse-to-fine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A tabular method for dynamic oracles in transition-based parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sartorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Satta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving statistical machine translation using lexicalized rule selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-08" />
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Semantics in Generative Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Heim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kratzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Blackwell Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structured perceptron with inexact search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fayong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Joint syntactic and semantic parsing with combinatory categorial grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Lexical generalization in ccg grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP, EMNLP &apos;11</title>
		<meeting>EMNLP, EMNLP &apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="590" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A probabilistic forest-to-string model for language generation from typed lambda calculus expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Algorithms for deterministic incremental dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="553" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Advanced Topics in Types and Programming Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pierce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Types and Programming Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Pierce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting-Association for computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">960</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Max-violation perceptron and forced decoding for scalable mt training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of UAI</title>
		<meeting>UAI</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online learning of relaxed ccg grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL-2007</title>
		<meeting>EMNLP-CoNLL-2007</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Shift-reduce ccg parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
