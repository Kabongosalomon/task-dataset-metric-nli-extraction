<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
							<email>sunkai@buaa.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richong</forename><surname>Zhang</surname></persName>
							<email>zhangrc@act.buaa.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Mensah</surname></persName>
							<email>samensah@buaa.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongyi</forename><surname>Mao</surname></persName>
							<email>ymao@uottawa.ca</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">BDBC</orgName>
								<orgName type="institution" key="instit2">SKLSDE Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">BDBC and SKLSDE</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">BDBC and SKLSDE</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">University of Ottawa</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">BDBC and SKLSDE</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T15:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The idea of using multi-task learning approaches to address the joint extraction of entity and relation is motivated by the relatedness between the entity recognition task and the relation classification task. Existing methods using multi-task learning techniques to address the problem learn interactions among the two tasks through a shared network, where the shared information is passed into the taskspecific networks for prediction. However, such an approach hinders the model from learning explicit interactions between the two tasks to improve the performance on the individual tasks. As a solution, we design a multitask learning model which we refer to as recurrent interaction network which allows the learning of interactions dynamically, to effectively model task-specific features for classification. Empirical studies on two real-world datasets confirm the superiority of the proposed model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The extraction of entities and relations from textual data comprises of two sub-tasks: entity recognition (ER) and relation classification (RC). The ER task aims at extracting all entities in a given text. The RC task aims at classifying the relation between any pair of entities in the text. In practice, both tasks are required to be solved jointly, and have been observed to contribute significantly in extracting structured knowledge from unstructured text for several applications, including knowledge base construction <ref type="bibr" target="#b13">(Komninos and Manandhar, 2017;</ref><ref type="bibr" target="#b4">Deng et al., 2019;</ref><ref type="bibr" target="#b20">Nathani et al., 2019)</ref>. For instance, consider the sentence John was born in Sheffield, a city in the north of England. The goal of a joint entity and relation extraction task is to identify all the factual relational triples (or relational facts) (Sheffield, * Corresponding author birth place of, John) and (England, contains, Sheffield). The simplest approach to solve this joint task is to utilize a pipeline-based approach by firstly extracting all entities in the sentence and then classifying the relation between all entity pairs <ref type="bibr" target="#b27">(Zelenko et al., 2003;</ref><ref type="bibr" target="#b35">Zhou et al., 2005;</ref><ref type="bibr" target="#b0">Chan and Roth, 2011)</ref>. However, pipeline-based approaches disregard the correlation between ER and RC tasks, leading to error propagation in these methods.</p><p>Recently, researchers have exploited multi-task learning (MTL) <ref type="bibr" target="#b1">(Collobert and Weston, 2008)</ref> techniques to capture the correlation between the ER and RC tasks, and have successfully improved the performance of the individual tasks <ref type="bibr" target="#b19">(Miwa and Bansal, 2016;</ref><ref type="bibr" target="#b28">Zeng et al., 2019a)</ref>. These methods have a flat structure . <ref type="figure" target="#fig_0">Figure 1(a)</ref> shows a flat structure for multitask learning. Methods using a flat structure learn interactions between tasks through a shared network, and extract a shared common representation which is exploited by task-specific networks independently. We refer to MTL methods utilizing a flat structure as conventional MTL methods. A conventional MTL method is effective to an extent because they help to improve generalization performance on all the tasks. However, it is based on the strong assumption that the shared network is sufficient to capture the correlations between the tasks.</p><p>Even so, identifying the relational facts in sentences is a difficult problem. Reason being that several relational facts may overlap in a sentence <ref type="bibr" target="#b32">(Zhang et al., 2018)</ref>. Although a conventional MTL method may learn task-specific features and has been successfully applied in a wide variety of scenarios <ref type="bibr" target="#b31">(Zhang and Wang, 2016;</ref><ref type="bibr" target="#b25">Wu et al., 2016;</ref><ref type="bibr" target="#b7">Goo et al., 2018;</ref><ref type="bibr" target="#b8">Han et al., 2019;</ref><ref type="bibr" target="#b21">Nishino et al., 2019;</ref><ref type="bibr" target="#b11">Hu et al., 2019)</ref>, its flat structure restricts the model to effectively learn the correlations between tasks. For example in <ref type="figure" target="#fig_0">Figure 1</ref>(a), the model cannot explicitly learn correlations between the two tasks. Without modeling explicit interactions, as shown in a sequence learning task , the existing MTL-based methods <ref type="bibr" target="#b19">(Miwa and Bansal, 2016;</ref><ref type="bibr" target="#b28">Zeng et al., 2019a)</ref> cannot effectively capture the correlation between the ER and the RC tasks.</p><p>In this paper, we overcome the aforementioned limitation of previous MTL-based methods by proposing a recurrent interaction network (RIN) to effectively capture the correlations between the ER and RC tasks. RIN has a multi-task learning architecture which allows interactions between the ER and RC tasks to be learned explicitly, with the aim to improve the performance on the individual tasks. More specifically, RIN has a recurrent structure comprising of multiple interaction layers, allowing the model to progressively learn complex interactions while refining predictions for ER and RC. The RIN structure is an example of a multitask learning network with a graph structure . We show the graph structure in <ref type="figure" target="#fig_0">Figure 1</ref> <ref type="bibr">(b)</ref>. As shown by our experiment, the proposed model progressively provides discriminating features which is an essential requirement for the individual task for classification. Empirical studies on NYT and WebNLG datasets achieve new state-of-the-art performances and confirm the effectiveness of the proposed RIN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous neural methods proposed for jointly extracting entities and relations can generally be categorized into three classes. The first class models the joint extraction task as a sequence labeling problem <ref type="bibr" target="#b2">Dai et al., 2019;</ref><ref type="bibr" target="#b24">Takanobu et al., 2019;</ref><ref type="bibr" target="#b26">Yu et al., 2019)</ref>. Among the proposed works,  was the first to introduce a tagging strategy to address the problem, transferring the joint extraction task to a sequence labelling problem. However, this method has the fundamental weakness of addressing the overlapping problem of relational facts in the text. To meet it, <ref type="bibr" target="#b2">(Dai et al., 2019)</ref> proposed a position-attentive tagging scheme to solve the overlapping problem. Meanwhile, <ref type="bibr" target="#b24">(Takanobu et al., 2019;</ref><ref type="bibr" target="#b26">Yu et al., 2019)</ref> approach the problem by decomposing the joint extraction task into two sequence labeling sub-tasks, to address the joint entity and relation extraction problem.</p><p>The second class of works use a sequence-tosequence (seq2seq) approach to address the problem <ref type="bibr" target="#b30">(Zeng et al., 2018</ref><ref type="bibr" target="#b29">(Zeng et al., , 2019b</ref>. <ref type="bibr" target="#b30">(Zeng et al., 2018</ref>) employs a seq2seq model to directly extract relational facts from the sentence by decoding the first entity, second entity, and relation in that order. But, their approach is limited to extracting a predefined number of relational facts from the text. In extracting relational triples, the order of extraction is key to identify the relational facts. As such, <ref type="bibr" target="#b29">(Zeng et al., 2019b)</ref> proposed a seq2seq approach which utilizes a reinforcement learning model to learn the order of extracting the relational triples. Although effective, the proposed seq2seq models <ref type="bibr" target="#b30">(Zeng et al., 2018</ref><ref type="bibr" target="#b29">(Zeng et al., , 2019b</ref> only decode a single word for an entity.</p><p>The third class design a multi-task learning model to extract relational facts. Only few works using this approach have been proposed <ref type="bibr" target="#b19">(Miwa and Bansal, 2016;</ref><ref type="bibr" target="#b28">Zeng et al., 2019a)</ref>. <ref type="bibr" target="#b19">(Miwa and Bansal, 2016)</ref> is one of the first works to extract relational facts using an MTL framework. <ref type="bibr" target="#b28">(Zeng et al., 2019a)</ref> proposed an MTL model which comprises of an ER model to extract entities with multi-tokens, and a seq2seq model to extract relational facts. Their approach solves the entity extraction problem faced by models which are solely seq2seq based. ) exploited a bidirectional recurrent neural network and graph convolutional network to extract common features of the ER and RC tasks, which are further fed into two independent classifiers for ER and RC predictions. Despite the substantial efforts and great successes in the design of these MTL-based methods, these methods follow the conventional MTL approach <ref type="bibr" target="#b1">(Collobert and Weston, 2008)</ref>. Thus, they only capture implicit interactions by means of the shared network of the ER and RC tasks.</p><p>Modelling explicit interactions between multiple tasks in an MTL architecture has been explored to improve predictions in several domains <ref type="bibr" target="#b33">Zhao et al., 2019;</ref><ref type="bibr" target="#b3">Dankers et al., 2019;</ref><ref type="bibr" target="#b14">Lan et al., 2017;</ref><ref type="bibr" target="#b17">Liu et al., , 2016</ref>. As mentioned in Section 1, it is difficult to effectively learn the correlations between the ER and the RC tasks. To this end, we follow some of the ideas from other domains to dynamically learn the interactions between the two tasks, refining the classifiers of the tasks. To the best of our knowledge, this is the first work to model explicit interactions in a multitask learning architecture for the joint extraction of entities and relations in text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Statement</head><p>In this section, we formally describe the joint entity and relation extraction problem. For a set T = {t 1 , · · · , t l } of pre-defined l relation types, and a given sentence s = {w 1 , w 2 , · · · , w n } of n words, the problem is to extract all relational facts for the given sentence. In this paper, a single relational triple is of the form w i , t, w j , where w i , w j ∈ s are entity words or heads of multi-token entities, and w i = w j , and the relation t ∈ T . The goal is to predict the probability y t (i,j) that the relational triple w i , t, w j is factual given the word pair (w i , w j ). Besides, the entity recognition task can identify the head and tail words of multi-token entities for the extracted relational triple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>In this section, we describe the recurrent interaction network (RIN) for extracting relational facts in text. The RIN model is composed of an entity recognition (ER) module and a relation classification (RC) module. We start by presenting an overview of the RIN model, showing the interaction between the ER and RC tasks. Next, we elaborate the ER and RC modules and define the training objective. The framework of RIN is shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Recurrent Interaction Network</head><p>The RIN model we propose uses a bidirectional LSTM network to learn correlations between the ER and the RC tasks, and derives shared features for the two tasks. We denote H as the output of shared features, where H = {h 1 , h 2 , . . . , h n } corresponds to the representations of words in sentence s. A straightforward strategy for the joint ER and RC task is to pass H into independent ER or RC modules for predictions. Denote C e as the ER module to identify and extract entities in the text, and C r as the RC module to classify relational triples in the text. Formally, Y e and Y r , the set of predictions of the entities and relational triples are formulated as:</p><formula xml:id="formula_0">Y r = C r (H) Y e = C e (H)<label>(1)</label></formula><p>where Y e =: {y i |h i ∈ H}, Y r =: {y (i,j) |h i , h j ∈ H}, y i is a probability distribution over BIOES labels , and y (i,j) is a probability distribution over the relation types t ∈ T . This structure is basically a conventional MTL method, where interactions are learned implicitly, impeding dynamic learning of intrinsic correlations between the two tasks.</p><p>To enhance the interaction between the two tasks, we dynamically learn the explicit interactions between the ER and RC tasks. Each layer of the RIN model is an interaction layer comprising of two separate gated recurrent units (GRUs), accounting for the ER task and the RC task. The GRU networks are designed to model task-specific features at the k-th layer, taking into account the previous shared features H (k−1) and the previous predictions Y k−1 e and Y k−1 r . Meanwhile, the shared features H (k) generated at the k-th layer is a sum of the previous task-specific features and the previous shared features H (k−1) . Such a mechanism ensures that we retain the learned correlations as learning progresses along the network.</p><p>Let GRU r and GRU e denote the GRU networks for the relation classification and entity recognition modules in the interaction layer. Denote H k r and H k e the task-specific features modeled by the respective GRU r and GRU e networks at the k-th layer. Formally, the outputs H k r and H k e and shared features H k at the k-th interaction layer is computed as follows:</p><formula xml:id="formula_1">H k r = GRU r Y k−1 r , H k−1 |θ GRUr H k e = GRU e Y k−1 e , H k−1 |θ GRUe H k = H k r + H k e + H k−1<label>(2)</label></formula><p>where θ GRUr and θ GRUe are parameters for the GRU r and GRU e networks respectively. To take advantage of the previous learned explicit interactions in this network, we allow the network to have a minimum of two layers, i.e, k = 2, 3 . . . K.</p><p>Hence, for the ER task and RC tasks, the outputs at the k-th layer is formulated as:</p><formula xml:id="formula_2">Y k r = C r (H k r ) Y k e = C e (H k e )<label>(3)</label></formula><formula xml:id="formula_3">H (0) Cr Ce GRUr GRUe Cr Ce GRUr GRUe ... ... ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GRUr GRUe</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cr</head><p>Ce</p><formula xml:id="formula_4">H (0) H (1) H (k−1) Y (0) r Y (1) r Y (k−1) r Y (k) r Y (0) e Y (1) e Y (k−1) e Y (k) e + + H (1) r H (2) r H (k) r H (1) e H (2) e H (k) e h1 h2 h3</formula><p>We <ref type="formula" target="#formula_0">y1</ref>   In <ref type="formula">(b)</ref> and (c), we use a toy example of shared features H = {h 1 , h 2 , h 3 } to demonstrate the entity prediction for word w i and relation prediction for all pairs (w 1 , w 1 ), (w 1 , w 2 ), (w 1 , w 3 ). +, ⊕, * , φ, and σ denote a summation operator, a concatenation operator, a matrix multiplication, relu activation function and sigmoid function respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">The GRU network</head><p>In the RIN model, we proposed the GRU r and GRU e networks for the relation classification and entity recognition modules. Formally, for a single word w, the GRU e network takes the output y ∈ Y e and the shared word representation h ∈ H as inputs and computes the ER task feature vector h e ∈ H e . Formally, this can be formulated as:</p><formula xml:id="formula_5">z = σ (W z (h ⊕ y)) u = σ (W u (h ⊕ y)) h = tanh (W o ((u * h) ⊕ y)) h e = (1 − z) * h + z * ȟ (4)</formula><p>where ⊕ is a concatenation operator, W z , W u , W o are learnable parameters of the GRU network. GRU r follows the same architecture as GRU e to compute the RC task feature vector h r ∈ H r for word w. However, for a given word w i , it considers h i ∈ H and the vector y i , where y i is modeled from the set of relation predictions for all word pairs containing w i . We can define this set as Y r (w i ) =: {y (i,j) ∈ Y r |w j ∈ s}.</p><formula xml:id="formula_6">y i = maxpool ( Y r (w i )) ,<label>(5)</label></formula><p>where the function maxpool(·) is a maxpool operation along the dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Entity Recognition (ER)</head><p>The ER module C e attempts to recognize all entities in the text based on the features H e . As an entity may consist of multiple words, we formalize the ER task as tagging each word with an entity label, taking values from (Begin, Inside, End, Single, Out) using the BIOES tagging scheme . Specifically, the ER module classifies each word to one of the five label clusters. The probability distribution y of word w over these five clusters is calculated based on the ER task feature vector h e as follows:</p><formula xml:id="formula_7">y = softmax(W e h e + b e ),<label>(6)</label></formula><p>where θ ER = {W e , b e } are learnable model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Relation Classification (RC)</head><p>The RC module C r makes an attempt to identify and extract relational facts from the sentence. Following , we classify all relations between pairs of words in the sentence based on the features H r . Thus, the relation classification task is interpreted as a binary classification problem, where we identify the truth value of a relational triple w i , t, w j by classifying the word pair (w i , w j ). The task can be regarded as learning the probability distribution y (i,j) for each word pair (w i , w j ). The value y (i,j) is a probability distribution over the relation types t ∈ T . Thus, y (i,j) is a vector with size l, where each dimension is a probability y t (i,j) of the relational triple w i , t, w j to be factual. We compute y (i,j) for each word pair (w i , w j ) by performing the following steps:</p><formula xml:id="formula_8">m = φ (W m (h i ⊕ h j )) y (i,j) = σ (W r m + b r )<label>(7)</label></formula><p>where h i , h j ∈ H r are the RC task feature vectors for w i , w j ∈ s, ⊕ is a concatenation operation, φ(·) is the ReLU activation function, σ(·) is the sigmoid activation function. θ RC = {W m , W r , b r } are learnable model parameters. Instead of using a softmax function for classification, as used in , we find that the sigmoid function offers a natural way of identifying multiple relations that may exist between word pairs, solving the overlapping problem more efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training Objective</head><p>The RIN model ultimately outputs task-specific representations, which are fed into their corresponding ER module and the RC module for predictions. As such, the training objective of RIN is comprised of two parts: the loss function for RC L r and the loss function for ER L e . The losses L e and L r are defined as L e (w) = CrossEntropy (ȳ, y)</p><formula xml:id="formula_9">L r ( w i , t, w j ) = CrossEntropy ȳ t (i,j) , y t (i,j) (8) whereȳ andȳ t (i,j)</formula><p>are the respective ground truth values of word w and relational triple w i , t, w j , and y and y t (i,j) are the predictions from the ER module (C e ) and the RC module (C r ) at the K-th layer (i.e. the last layer) of RIN.</p><p>The total loss L over all words and relational triples for all sentences is then calculated as follows.</p><formula xml:id="formula_10">L = s   w∈s L e (w) + w i ,w j ∈s,t∈T L r ( w i , t, w j )   (9)</formula><p>With gradient based algorithm, we seek to minimize the total loss L over all model parameters Θ = {θ GRUr , θ GRUe , θ RC , θ ER , θ H } (θ H is the parameters for the BiLSTM network) to achieve good performance for both the ER and RC tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>We conduct experiments to evaluate RIN on two public datasets NYT <ref type="bibr" target="#b23">(Riedel et al., 2010)</ref> and WebNLG <ref type="bibr" target="#b6">(Gardent et al., 2017)</ref>. The NYT dataset consists of 1.18M sentences with 24 predefined relation types. The WebNLG dataset was created by Natural Language Generation (NLG) tasks, and adapted by <ref type="bibr" target="#b30">(Zeng et al., 2018)</ref> for a relational triple extraction task. We directly use the preprocessed datasets released by <ref type="bibr" target="#b30">(Zeng et al., 2018)</ref> 1 . It is worth mentioning that only the tail word of an entity is marked in the preprocessed dataset released by <ref type="bibr" target="#b30">(Zeng et al., 2018)</ref>. To properly distinguish entities, we take a further step of tagging entities with the conventional BIOES tagging scheme as the one used in . We report Precision (Prec), Recall (Rec) and micro-F1 (F1) scores on our model and other recent models <ref type="bibr" target="#b30">(Zeng et al., 2018</ref><ref type="bibr" target="#b29">(Zeng et al., , 2019b</ref><ref type="bibr"></ref> 1 https://github.com/xiangrongzeng/copy re <ref type="bibr" target="#b28">Zeng et al., 2019a</ref>) for the Partial Match task and the Exact Match task. For our proposed method, we report the mean results over five runs using different random seeds, along with its standard deviation to show the stability of our results. The statistics of datasets are summarized in <ref type="table" target="#tab_1">Table 2</ref>. Additional experiments on older datasets NYT10 <ref type="bibr" target="#b23">(Riedel et al., 2010)</ref> and NYT11 <ref type="bibr" target="#b10">(Hoffmann et al., 2011)</ref> are also performed, and the results are available in the supplementary file. Our results on these datasets show satisfactory performance, generally outperforming previous models on the NYT10 and NYT11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Partial Match and Exact Match</head><p>Both NYT and WebLG datasets support evaluation for the Partial Match task and the Exact Match task. The Partial Match task only requires the relation and the heads of both subject and object entities of the extracted relational triple to be correct. For the Exact Match as recently adopted by <ref type="bibr" target="#b28">Zeng et al., 2019a)</ref>, the extracted relational triple is considered to be correct if the relation and the heads and tails of the subject and object entities are all correct. Thus, the extracted relational triple completely matches the gold relational triple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Details</head><p>For a fair comparison with previous recent works <ref type="bibr" target="#b30">(Zeng et al., 2018)</ref>, we use the 100dimensional Glove embedding <ref type="bibr" target="#b22">(Pennington et al., 2014)</ref> to represent the word embeddings 2 . Partof-speech (POS) tags are assigned to words using Stanford POS tagger 3 . We map each POS tag to a randomly initialized 10-dimensional POS embedding. We concatenate both word and POS embeddings as the input embeddings. For any given sentence, the input embeddings for words are fed to a BiLSTM network to learn a 100-dimensional embedding for each word. We improve learning by using dropout regularization in the input embeddings. The BiLSTM embeddings represent the shared features H in the RIN model. Our model is trained using an Adam optimizer <ref type="bibr" target="#b12">(Kingma and Ba, 2014)</ref>. The hyper-parameters are set empirically and manually tuned on the development set to select the best model. We implement our model using PyTorch on a Linux machine with a GPU device NVIDIA V100 NVLINK 32GB.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Performance Comparison</head><p>We compare our model with several recent models based on the Partial Match and the Exact Match evaluation tasks. We also include a baseline model RIN w/o interaction which excludes the interaction network used in RIN. In RIN w/o interaction , the shared features H modeled by BiLSTM network is directly passed into C e and C r for task-specific predictions. We also compare with several recent models, including the NovelTagging , sequence-to-sequence (seq2seq) models such as OneDecoder <ref type="bibr" target="#b30">(Zeng et al., 2018)</ref>, Multi-Decoder <ref type="bibr" target="#b30">(Zeng et al., 2018)</ref>, and OrderRL <ref type="bibr" target="#b29">(Zeng et al., 2019b)</ref>, and MTL-based methods Copy-MLT <ref type="bibr" target="#b28">(Zeng et al., 2019a)</ref>, and GraphRel . Partial Match <ref type="table">Table 1</ref> shows the performance of different models on the datasets. For the Partial Match evaluation task, it can first be noted that the small standard deviation for our model RIN and its ablated model RIN w/o interaction shows that our results are stable to an extent on the datasets. Even with the simple structure of RIN w/o interaction , its results outperform the compared methods. In extracting relational facts, our model treats the Partial Match task as a relation classification problem. Whereas the compared methods take a seq2seq based approach to directly extract relational facts in the sentence. The results suggest that our approach may be more effective in identifying the relational facts for this task. It is more interesting to see the performance achieved by RIN. First of all, it can be noted that the model shows a level of stability due to its small standard deviation. Moreover, RIN shows a significant performance boost to the RIN w/o interaction model, suggesting the importance of dynamically learning the explicit interactions between the ER task and the RC task. Exact Match For the Exact Match task, we do not consider the methods <ref type="bibr" target="#b30">(Zeng et al., 2018</ref><ref type="bibr" target="#b29">(Zeng et al., , 2019b</ref>, since these methods consider a seq2seq approach in extracting relational triples. Seq2seq methods are able to only decode a single word for an entity. Hence, they will inevitably fail to identify entities with multiple words.</p><p>In <ref type="table">Table 1</ref>, we find that our ablated model RIN w/o interaction consistently outperforms previous models on the two datasets. In a more detailed analysis, we can note that the variants of the GraphRel model ) consider the Exact Match task as a relation classification problem which classifies all word pairs in the sentence. In its relation classification module, it exploits a softmax function for the final classification. Hence, the model is not able to address cases where multiple relations exist between a pair of entities. We believe this explains why its results underperforms when compared to RIN w/o interaction . Although CopyMLT and its variants <ref type="bibr" target="#b28">(Zeng et al., 2019a</ref>) consider a seq2seq based approach to directly extract relational triples, its ER model can identify entities with multiple words and hence can address the Exact Match task. Nonetheless, it fails to outperform our model due to the fact that it uses a seq2seq based approach which we believe to be a more complex method for identifying relational triples. Besides, our main model RIN significantly outperforms RIN w/o interaction on the two datasets, further proving the importance of the explicit interactions learned between the ER and RC tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Impact of K on the results</head><p>The hyper-parameter K is the number of interaction layers of the RIN model. Thus, K controls the number of times the RIN model attempts to learn explicit interactions between the ER and RC task. We conduct experiments to study the impact of K on the performance of RIN. We expect that the performance of the model increases as we learn more explicit interactions between the ER task and the RC task. <ref type="figure" target="#fig_3">Figure 3</ref> shows the F1 curves of RIN on the datasets for increasing values of K. Here, at K = 0 the RIN model is reduced to RIN w/o interaction .</p><p>We observe that as K increases the performance of RIN increases to an extent up to a point where it overfits. Taking a closer look at the performance on the Partial Match task, we find that RIN w/o interaction poorly models the interaction between the ER and RC task. By learning explicit interactions using the RIN model, we observe a sharp rise in performance at K = 1. On the Exact Match task we observe an interesting behaviour of RIN on the NYT and WebNLG dataset. Note that the 60% of entities on the WebNLG are multi-tokens, while 30% of the entities in the NYT dataset are multi-tokens. This means that the Exact Match task is more difficult on the WebNLG dataset, compared to the NYT dataset. As a consequence, RIN finds it difficult to learn explicit interactions on the WebNLG, while it learns much more easily on the NYT as K rises. We observe a sharp rise in performance from the first layer to the second layer on the NYT dataset. The second layer of RIN takes advantage of the original shared features H and the task-specific features of the first interaction layer. Thus, effective learning of the interaction between the two tasks takes place from the second layer. This explains the sharp rise in performance on the NYT dataset for the Exact Match task.</p><p>The results suggests that, to an extent, the proposed RIN model can dynamically filter additional interaction information between the two tasks along the multiple interaction layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Experiment</head><p>To examine the contributions of our main model components, we conduct ablation experiments on the NYT and WebNLG datasets. We use the default hyper-parameter settings for the ablated models (see <ref type="table" target="#tab_0">Table 3</ref>  <ref type="table" target="#tab_6">Table 5</ref> shows the results for the experiment.</p><p>We find that the performance of RIN deteriorates as we remove critical components. Among the ablated models designed, RIN w/o interaction performs very poorly on the two datasets, suggesting the importance of learning explicit interactions dy-   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Case Study</head><p>We present two case examples from NYT dataset as illustrations to observe the behaviour of the RIN and RIN w/o interaction models. <ref type="table" target="#tab_5">Table 4</ref> shows the results of the study. In the first case example, both RIN and RIN w/o interaction correctly extracts all the gold entities in the sentence. But, RIN w/o interaction captures only the gold relational triple (Europe, /location/location/contains, Denmark), and misses the gold triple (Europe, /location/location/contains, Norway). Given the fact that (Europe, /location/location/contains, Norway) overlaps a relational fat, it is important to dynamically learn to capture the complex interaction between the ER and RC tasks. The RIN model takes advantage of its interaction network to identify both gold triples.</p><p>In the second case, we observe that both RIN and RIN w/o interaction correctly extract the relational triple (York, /location/location/contains, Scott).</p><p>However, RIN w/o interaction identifies Texas as an entity by error while RIN correctly extracts the entity Scott and New York. The results suggest that RIN is able to leverage information from the RC module to correctly identify entities in the ER module. It is worth noting that we can easily complete the entity York in the extracted relational triple by aligning it to the extracted entity New York.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we tackle the weakness of existing MTL-based methods proposed for the joint extraction of entities and relation in unstructured text. Specifically, these methods assume that a shared network is sufficient to capture the correlations between the entity recognition task and the relation classification task, and that the shared features derived from this network can be passed into models for the task-specific tasks to make predictions independently. Instead, we show that dynamically learning the interactions between the tasks may capture complex correlations which improves the taskspecific feature for classification. We proposed multi-task learning model which allows explicit interactions to be dynamically learned among the subtasks. Our experiments on benchmark datasets validates clear advantage over the existing proposed methods. We note that our model can be adapted for other NLP tasks, including aspect level sentiment classification and slot filling. As future work, we intend to explore its application in those fields.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Two topological structures for multi-task learning. Here, A and B are related tasks, and S is the shared information of the two tasks. The directed edges define the information flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Framework of RIN. (b) The ER module (C e ). (c) The RC module (C r ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>(a) The framework of RIN. (b) The entitiy recognition module. (c) The relation classification module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Curves of F1 performance on different number of interaction layers K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc>9±0.6 83.1±0.6 83.5±0.2 84.9±0.6 86.3±0.8 85.6±0.3 RIN 87.2±0.2 87.3±0.3 87.3±0.1 87.6±0.1 87.0±0.9 87.3±0.4Table 1: Precision, Recall and F1 performance of different models on the datasets. Results for the compared models are retrieved from their original papers. We report the mean results over five runs and the standard deviation. The best performance is bold-typed.</figDesc><table><row><cell>NYT</cell><cell>WebNLG</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of NYT and WebNLGlists the hyper-parameters of RIN on the datasets. For the relation classification task, we threshold the probabilities of the prediction and return only the relations with probability values ≥ 0.5. The code for our model will be made available upon acceptance.</figDesc><table><row><cell></cell><cell cols="3">Hyper-parameter NYT WebNLG</cell></row><row><cell></cell><cell>K</cell><cell>4</cell><cell>2</cell></row><row><cell></cell><cell>d</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>Partial Match</cell><cell>η</cell><cell>1e −3</cell><cell>5e −4</cell></row><row><cell></cell><cell>bs</cell><cell>50</cell><cell>50</cell></row><row><cell></cell><cell>epochs</cell><cell>100</cell><cell>150</cell></row><row><cell></cell><cell>K</cell><cell>7</cell><cell>3</cell></row><row><cell></cell><cell>d</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>Exact Match</cell><cell>η</cell><cell>1e −3</cell><cell>5e −4</cell></row><row><cell></cell><cell>bs</cell><cell>50</cell><cell>50</cell></row><row><cell></cell><cell>epochs</cell><cell>100</cell><cell>150</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Hyper-parameter settings of RIN on the datasets (K: number of interaction layers, d: dropout rate for input embeddings, η: learning rate, bs: batch size.)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>). The ablated models are: (1) RIN w/o ER : A RIN model which excludes the taskspecific features H e in the update of the shared features H, restricting the RC module from learning from the ER module. (2) RIN w/o RC : A RIN model which excludes the task-specific features H r in the update of the shared features H, restricting the ER module from learning from the RC module. (3) RIN w/o POS : A RIN which only uses the Glove word embeddings as the input embeddings. We also include the ablated model RIN w/o interaction .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Case1: A cult of victimology arose and was happily exploited by clever radicals among Europes Muslims, especially certain religious leaders like Imam Ahmad Abu Laban in Denmark and Mullah Krekar in Norway.</figDesc><table><row><cell></cell><cell>Golden:Europe, Denmark, Norway</cell></row><row><cell></cell><cell>(Europe, /location/location/contains, Denmark)</cell></row><row><cell></cell><cell>(Europe, /location/location/contains, Norway)</cell></row><row><cell></cell><cell>RIN w/o interaction : Europe, Denmark, Norway</cell></row><row><cell></cell><cell>(Europe, /location/location/contains, Denmark)</cell></row><row><cell></cell><cell>RIN: Europe, Denmark, Norway</cell></row><row><cell></cell><cell>(Europe, /location/location/contains, Denmark)</cell></row><row><cell></cell><cell>(Europe, /location/location/contains, Norway)</cell></row><row><cell>Case2: Scott (No rating , 75 minutes)</cell><cell>Golden: Scott, New York</cell></row><row><cell>Engulfed by nightmares, blackouts and the</cell><cell>(York, /location/location/contains, Scott)</cell></row><row><cell>anxieties of the age, a Texas woman flees</cell><cell>RIN w/o interaction : Texas, New York</cell></row><row><cell>homeland insecurity for a New York vision</cell><cell>(York, /location/location/contains, Scott)</cell></row><row><cell>quest in this acute, resourceful and</cell><cell>RIN: Scott, New York</cell></row><row><cell>bracingly ambitious debut film.</cell><cell>(York, /location/location/contains, Scott)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Case study for RIN and RIN w/o interaction . Entities and relational triples are in blue and orange texts respectively. We mark a wrong prediction with a red text.</figDesc><table><row><cell>Model</cell><cell cols="2">NYT WebNLG</cell></row><row><cell>RIN</cell><cell>84.7</cell><cell>77.0</cell></row><row><cell>RINw/o ER</cell><cell>83.9</cell><cell>76.4</cell></row><row><cell>RINw/o RC</cell><cell>77.3</cell><cell>76.0</cell></row><row><cell>RINw/o interaction</cell><cell>76.9</cell><cell>74.2</cell></row><row><cell>RINw/o POS</cell><cell>84.1</cell><cell>76.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>F1 performance of different ablation models on the datasets. The Exact Match evaluation is used. namically between the ER and RC tasks. We also find that RIN w/o ER marginally underperforms the RIN model, and also showing a better performance when compared to RIN w/o RC . The results suggest that the performance of RIN is heavily dependent on the ER module exploiting information from the RC module. Lastly, the results for RIN w/o POS suggest that the POS tags does not significantly boost the performance of RIN.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://nlp.stanford.edu/projects/glove/ 3 https://stanfordnlp.github.io/CoreNLP/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exploiting syntactico-semantic structures for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.1145/1390156.1390177</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008)</title>
		<meeting><address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06-05" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and overlapping relations using position-attentive sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoqiao</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33016300</idno>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Honolulu</title>
		<meeting><address><addrLine>Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-01-27" />
			<biblScope unit="page" from="6300" to="6308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modelling the interplay of metaphor and emotion through multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verna</forename><surname>Dankers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1227</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="2218" to="2229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multitask learning with multi-view attention for answer selection and knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexiang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33016318</idno>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-01-27" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="6318" to="6325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graphrel: Modeling text as relational graphs for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsu-Jui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Hsuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1409" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Creating training corpora for NLG micro-planners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1017</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
	<note type="report_type">Vancouver</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Slot-gated modeling for joint slot filling and intent prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Chih-Wen Goo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Kai</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Li</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Chieh</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keng-Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-2118</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-01" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="753" to="757" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Joint event and temporal relation extraction with shared representations and structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rujun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1041</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="434" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An interactive multi-task learning network for end-to-end aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Wee Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="504" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference</title>
		<meeting><address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06-24" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Open-domain targeted sentiment analysis via span-based extraction and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Lv</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1051</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Feature-rich networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Komninos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-2051</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="324" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-task attention-based neural networks for implicit discourse relationship representation and identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d17-1134</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="1299" to="1308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploiting BERT for end-to-end aspectbased sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-5505</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Noisy User-generated Text, W-NUT@EMNLP 2019</title>
		<meeting>the 5th Workshop on Noisy User-generated Text, W-NUT@EMNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-04" />
			<biblScope unit="page" from="34" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning multi-task communication with message passing for sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie Chi Kit</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33014360</idno>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-01-27" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="4360" to="4367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recurrent neural network for text classification with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016<address><addrLine>New York, NY, USA, 9</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07-15" />
			<biblScope unit="page" from="2873" to="2879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-task deep neural networks for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1441</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4487" to="4496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using lstms on sequences and tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016-08-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning attention-based embeddings for relation prediction in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Nathani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jatin</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Kaul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4710" to="4723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Keeping consistency of sentence generation and document classification with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toru</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shotaro</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuji</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Taniguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuhide</forename><surname>Miura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohkuma</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1315</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="3193" to="3203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-15939-8_10</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases, European Conference, ECML PKDD 2010</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09-20" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A hierarchical framework for relation extraction with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33017072</idno>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-01-27" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="7072" to="7079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bilinguallyconstrained synthetic data for implicit discourse relation recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yidong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Su</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1253</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2306" to="2312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Joint extraction of entities and relations based on a novel decomposition strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1909.04273</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kernel methods for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Zelenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinatsu</forename><surname>Aone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Richardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1083" to="1106" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Copymtl: Copy mechanism for joint extraction of entities and relations with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianying</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning the extraction order of multiple relational facts in a sentence with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1035</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="367" to="377" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extracting relational facts by an end-to-end neural model with copy mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1047</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="506" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A joint model of intent determination and slot filling for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence<address><addrLine>New York, NY, USA, 9</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07-15" />
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="page" from="2993" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-31" />
			<biblScope unit="page" from="2205" to="2215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A neural multi-task learning framework to jointly model medical named entity recognition and normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sendong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.3301817</idno>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-01-27" />
			<biblScope unit="page" from="817" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and relations based on a novel tagging scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexing</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1113</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1227" to="1236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Exploring various knowledge in relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06-30" />
			<biblScope unit="page" from="427" to="434" />
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
