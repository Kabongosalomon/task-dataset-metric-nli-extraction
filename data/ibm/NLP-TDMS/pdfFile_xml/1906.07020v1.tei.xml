<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attention-based Modeling for Emotion Detection and Classification in Textual Conversations *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ragheb</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">IUT de Béziers</orgName>
								<orgName type="institution">University of Montpellier</orgName>
								<address>
									<settlement>Béziers</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Azé</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">IUT de Béziers</orgName>
								<orgName type="institution">University of Montpellier</orgName>
								<address>
									<settlement>Béziers</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Bringay</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">AMIS</orgName>
								<orgName type="institution">Paul Valery University -Montpellier 3</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">LIRMM UMR 5506</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">AMIS</orgName>
								<orgName type="institution">Paul Valery University -Montpellier 3</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Attention-based Modeling for Emotion Detection and Classification in Textual Conversations *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper addresses the problem of modeling textual conversations and detecting emotions. Our proposed model makes use of 1) deep transfer learning rather than the classical shallow methods of word embedding; 2) self-attention mechanisms to focus on the most important parts of the texts and 3) turn-based conversational modeling for classifying the emotions. The approach does not rely on any hand-crafted features or lexicons. Our model was evaluated on the data provided by the SemEval-2019 shared task on contextual emotion detection in text. The model shows very competitive results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Emotional intelligence has played a significant role in many application in recent years <ref type="bibr" target="#b6">[Krakovsky, 2018]</ref>. It is one of the essential abilities to move from narrow to general human-like intelligence. Being able to recognize expressions of human emotion such as interest, distress, and pleasure in communication is vital for helping machines choose more helpful and less aggravating behavior. Human emotions are a mental state that can be sensed and hence recognized in many sources such as visual features in images or videos <ref type="bibr" target="#b1">[Boubenna and Lee, 2018]</ref>, as textual semantics and sentiments in texts <ref type="bibr" target="#b1">[Calefato et al., 2017]</ref> or even patterns in EEG brain signals <ref type="bibr" target="#b5">[Jenke et al., 2014]</ref>. With the increasing number of messaging platforms and with the growing demand of customer chat bot applications, detecting the emotional state in conversations becomes highly important for more personalized and human-like conversations <ref type="bibr" target="#b9">[Zhou et al., 2018]</ref>. This paper addresses the problem of modeling a conversation that comes with multiple turns for detecting and classifying emotions. The proposed model makes use of transfer learning through the universal language modeling that is composed of consecutive layers of Bi-directional Long Term Short Term Memory (Bi-LSTM) units. These layers are learned first in sequence-to-sequence fashion on a general text and then fine-tuned to a specific target task. The model also makes use of an attention mechanism in order to focus on the most important parts of each text turn. Finally, the proposed classifier models the changing of the emotional state of a specific user across turns.</p><p>This article is an extension of the work done for the Semeval-2019 Task-3 <ref type="bibr" target="#b2">[Chatterjee et al., 2019b]</ref> including a discussion on the identification of vocabulary related to feeling by the attention layer. The paper is organized as follows. In Section 2, the related work is introduced. Then, we present a quick overview of the task and the datasets in Section 3. Section 4 describes the proposed model architecture, some variants and hyperparameters settings. The experiments and results are presented in Section 5. Section 6 concludes the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Transfer learning or domain adaptation has been widely used in machine learning especially in the era of deep neural networks <ref type="bibr" target="#b4">[Goodfellow et al., 2016]</ref>. In natural language processing (NLP), this is done through Language Modeling (LM). Through this step, the model aims to predict a word given some context. This is considered as a vital and important basics in most of NLP applications. Not only because it tries to understand the long-term dependencies and hierarchical structure of the text but also for its open and free resources. LM is considered as unsupervised learning process which needs only corpus of unlabeled text. The problem is that LMs get overfitted to small datasets and suffer catastrophic forgetting when fine-tuned with a classifier. Compared to Computer Vision (CV), NLP models are typically more shallow and thus require different fine-tuning methods. The developing of the Universal Language Model Fine-tuning (ULM-FiT) <ref type="bibr" target="#b4">[Howard and Ruder, 2018]</ref> is considered like moving from shallow to deep pre-training word representation. This idea has been proved to achieve CV-like transfer learning for many NLP tasks. ULMFiT makes use of the state-ofthe-art AWD-LSTM (Average stochastic gradient descent -Weighted Dropout) language model <ref type="bibr" target="#b7">[Merity et al., 2018]</ref>. Weight-dropped LSTM is a strategy that uses a DropConnect <ref type="bibr" target="#b8">[Wan et al., 2013]</ref> mask on the hidden-to-hidden weight matrices, as a means to prevent overfitting across the recurrent connections.</p><p>On the other hand, one of the recent trend in deep learning models is the attention Mechanism <ref type="bibr" target="#b8">[Young et al., 2018]</ref>.</p><p>Attention in neural networks are inspired from the visual attention mechanism found in humans. The main principle is being able to focus on a certain region of an image with "high resolution" while perceiving the surrounding image in "low resolution", and then adjusting the focal point over time. This is why the early applications for attention were in the field of image recognition and computer vision <ref type="bibr" target="#b6">[Larochelle and Hinton, 2010]</ref>. In NLP, most competitive neural sequence transduction models have an encoder-decoder structure <ref type="bibr" target="#b8">[Vaswani et al., 2017]</ref>. A limitation of these architectures is that it encodes the input sequence to a fixed length internal representation. This cause the results going worse performance for very long input sequences. Simply, attention tries to overcome this limitation by guiding the network to learn where to pay close attention in the input sequence. Neural Machine Translation (NMT) is one of the early birds that make use of attention mechanism <ref type="bibr" target="#b0">[Bahdanau et al., 2014]</ref>. It has recently been applied to other problems like sentiment analysis <ref type="bibr" target="#b6">[Ma et al., 2018]</ref> and emotional classification <ref type="bibr" target="#b6">[Majumder et al., 2018]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>The datasets provided by the task organizers of Semeval-2019 Task-3 are collections of labeled conversations <ref type="bibr" target="#b2">[Chatterjee et al., 2019b]</ref>. Each conversation is a three turn talk between two persons. The conversation labels correspond to the emotional state of the last turn. Conversations are manually classified into three emotional states for happy, sad, angry and one additional class for others. In general, released datasets are highly imbalanced and contains about 4% for each emotion in the validation (development) set and final test set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Models</head><p>In this section, we present the proposed model architecture for modeling a conversation through language models encoding and classification stages. Also, we explain the the training procedures used and the external resources for training the language model. In addition to the basic architecture, We will describe the used variants of the model for evaluation. Finally, we will list the hyperparameters used for building and training these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Architecture</head><p>In figure 1, we present our proposed model architecture. The model consists of two main steps: encoder and classifier. We used a linear decoder to learn the language model encoder as we will discuss later. This decoder is replaced by the classifier layers. The input conversations come in turns of three. After tokenization, we concatenate the conversation text but keep track of each turn boundaries. The overall conversation is inputted to the encoder. The encoder is a normal embedding layer followed by AWD-LSTM block. This uses three stacked different size Bi-LSTM units trained by ASGD (Average Stochastic Gradient Descent) and managed dropout between LSTM units to prevent overfitting. The conversation encoded output has the form of</p><formula xml:id="formula_0">C Enc = [T 1 Enc ⊕T 2 Enc ⊕T 3 Enc ]</formula><p>where T i is the i th turn in the conversation and ⊕ denotes a concatenation operation and</p><formula xml:id="formula_1">T i Enc = {T i 1 , T i 2 , . . . , T i Ni }. The sequence length of turn i is denoted by N i . The size of T i j is the final encoding of the j's sequence item of turn i.</formula><p>For classification, the proposed model pays close attention to the first and last turns. The reasons behind this are that the problem is to classify the emotion of the last turn. Also, the effect of the middle turn appear implicitly on the encoding of the last turn as we used Bi-LSTM encoding on the concatenated conversation. In addition to these, tracking the difference between the first and the last turn of the same person may be beneficial in modeling the semantic and emotional changes. So, we apply self-attention mechanism followed by an average pooling to get turn-based representation of the conversation. The attention scores for the i th turn S i is given by:</p><formula xml:id="formula_2">S i = Sof tmax{W i .T i Enc }<label>(1)</label></formula><p>Where W i is the weight of the attention layer of the i th turn and S i has the form of S i = {S i 1 , S i 2 , ..., S i Ni }. The output of the attention layer is the scoring of the encoded turn sequence O i = {o i 1 , o i 2 , . . . , o i Ni } which has the same length as the turn sequence and is given by</p><formula xml:id="formula_3">O i = S i T i</formula><p>Enc where is the element-wise multiplication. The difference of the pooled scored output of O 1 and O 3 is computed as O diff . The Input of the linear block is X in is formed by:</p><formula xml:id="formula_4">X in = [O diff ⊕ O 3 pool ]<label>(2)</label></formula><p>The fully connected linear block consist of two different sized dense layers followed by a Softmax to determine the target emotion of the conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Procedures</head><p>Training the overall models comes into three main steps:</p><p>1. The LM is randomly initialized and then trained by stacking a linear decoder in top of the encoder. The LM is trained on a general-domain corpus. This helps the model to get the general features of the language.</p><p>2. The same full LM after training is used as an initialization to be fine-tuned using the data of the target task (conversation text). In this step we limit the vocabulary of the LM to the frequent words (repeated more tan twice) of target task.</p><p>3. We keep the encoder and replace the decoder with the classifier and both are fine-tuned on the target task. For training the language model, we used the Wikitext-103 dataset <ref type="bibr" target="#b7">[Merity et al., 2016]</ref>. We train the model on the forward and backward LMs for both the general-domain and task specific datasets. Both LMs -backward and forward-are used to build two versions of the same proposed architecture. The final decision is the ensemble of both. Our code is released at https://github.com/WaleedRagheb/Attentive-Emocontext. However we tried the uni-directional models, experimental studies shows that the ensemble models give a better performance. Training the self-attention layer uses the same learning rates used in the classification layers group.</p><p>We used Pytorch 1 to build the whole model and make use of Fastai 2 libraries for applying the training strategies and fine-tuning the language models. For text preprocessing, the text is first normalized and tokenized. Special tokens were added for capitalized and repeated words. we keep the punctuation and the emotions symbols in text. We used Spacy 3 and the wrapper of FastText 4 . The models are trained and tested on Nvidia GEFORCE GTX 1080 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Variations</head><p>In addition to the model -Model-Adescribed by <ref type="figure" target="#fig_0">Figure 1</ref>, we tried five different variants. Each variant modify the classifier layer groups. Studying the effect of these variants will provide a good model ablation analysis.</p><p>The first variant -(Model-B)-is formed by bypassing the self attention layer. This will pass the output of the encoder directly to the average pooling layer such that</p><formula xml:id="formula_5">X B in = [T diff ⊕ T 3 pool ]</formula><p>where T diff is the difference between the first and third pooled encoded turns of the conversations.</p><p>-(Model-C)-is to input a pooled condensed representation to the whole conversation C pool rather than the last turn to the linear layer block. In this case:</p><formula xml:id="formula_6">X C in = [O diff ⊕C pool ].</formula><p>We also studied two versions of the basic model where only one input is used</p><formula xml:id="formula_7">X D in = O diff -(Model-D)-and X E in = O 3 pool -(Model- E).</formula><p>In these two variants, we just change the size of the first linear layer.</p><p>Also, we apply the forward direction LM and classifier only without ensemble them with the backward direction and keep the same basic architecture -(Model-F).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Hyperparameters</head><p>We use the same set of hyperparameters across all model variants. For training and fine-tuning the LM, we use the same set of hyperparameter of AWD-LSTM proposed by <ref type="bibr" target="#b7">[Merity et al., 2018]</ref> replacing the LSTM with Bi-LSTM and keep the same embedding size of 400 and 1150 hidden activations. We used weighted dropout of 0.2 and 0.25 as the input embedding dropout and the learning rate is 0.004. We fine-tuned the LM by all provided datasets in table 1. We train the LM for 14 epochs using batch size of 128 and limit the number of vocabulary to all token that appear more than twice. For classifier, we used masked self-attention layers and average pooling. For the linear block, we used hidden linear layer of size 100 and apply dropout of 0.4. We used Adam optimizer <ref type="bibr">[Dozat and Manning, 2017]</ref> with β 1 = 0.8 and β 2 = 0.99. The base learning rate is 0.01. We used the same batch size used in training LMs but we create each batch using weight random sampling. We used the same weights provided by the organizers (0.4 for each emotion). We train the classifier on training set for 30 epochs and select the best model on validation set to get the final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results &amp; Discussions</head><p>The results of the test set for different variants of the model for each emotion is shown in table 2. The table shows the value of precision (P), recall (R) and F1 measure for each emotion and the micro-F1 for all three emotional classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Happy  The micro-F1 scores are the official metrics used in this task.</p><p>Model-A gives the best performance F1 for each emotion and the overall micro-F1 score. However some variants of this model give better recall or precision values for different emotions, Model-A compromise between these values to give the best F1 for each emotion. Removing the self-attention layer in the classifier -Model-B-degraded the results. Also, inputting a condensed representation of the all conversation rather than the last turn -Model-C-did not improve the results. Even modeling the turns difference only -Model-D-gives better results over Model-C. These proves empirically the importance of the last turn in the classification performance. This is clear for Model-E where the classifier is learned only by inputting the last turn of the conversation. Ensemble the forward and backward models was more useful than using the forward model only -Model-F.</p><p>Comparing the results for different emotions and different models, we notice the low performance in detecting happy emotion. This validate the same conclusion <ref type="bibr">of Chatterjee et.al in [2019a]</ref>. They justify this by the difficulties even for human level annotation to discriminate between happy and many other emotions. The model shows a significant improvement over the EmoContext organizer baseline (F1: 0.5868). Also, comparing to other participants in the same task with the same datasets, the proposed model gives competitive performance and ranked 11 th out of more than 150 participants. The proposed model can be used to model multiturn and multi-parties conversations. It can be used also to track the emotional changes in long conversations.</p><p>One of the most attractive outcomes of applying the attention mechanism is its ability to process all the input sequences with different weights of attentions. It usually pays closer attention to the most important parts that influence the network decision. To validate these findings, we compared the most important tokens in terms of attention scores with sentiment and emotional lexicons. We found EmoLex proposed by S. <ref type="bibr" target="#b8">Mohammad et al. in [2018]</ref> [2013] a good example. EmoLex is created with a high-quality, moderate-sized, emotion and polarity lexicon. It has entries for more than 10,000 word-sense pairs. We extracted the words related Emocontext emotions for happy (Joy) and sad (sadness) and angry (anger). <ref type="table" target="#tab_3">Table 3</ref> shows the results of matching the top 20% attention scored tokens with EmoLex in both validation (Dev) and testing testsets. The self-attention layers proposed in the first T 1 and last turn T 3 in the conversation seems to pay close attention to the corresponding emotional words. This is clear with the diagonal in table 2. However the mentioned difficulties in Happy emotion detection, the self-attention focuses in parts of text related to joy with a significant difference between the sadness and anger lexicon words. This significance is decreased between the sadness and anger words. However, the attention model is well focused to the correct emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexicon-based Datasets</head><p>Joy Sadness Anger  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we present a new model used for Semeval-2019 Task-3 <ref type="bibr" target="#b2">[Chatterjee et al., 2019b</ref>]. The proposed model makes use of deep transfer learning rather than the shallow models for language modeling. The model pays close attention to the first and the last turns written by the same person in 3-turn conversations. The classifier uses self-attention layers and the overall model does not use any special emotional lexicons or feature engineering steps. The results of the model and its variants show a competitive results compared to the organizers baseline and other participants. Our best model gives micro-F1 score of 0.7582. The model can be applied to other emotional and sentiment classification problems and can be modified to accept external attention signals and emotional specific word embedding.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Proposed model architecture (Model-A).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>shows the number of conversations examples and emotions provided in the official released datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Data size Happy</cell><cell cols="2">Sad Angry</cell></row><row><cell>Training</cell><cell>30160</cell><cell cols="2">5191 6357</cell><cell>6027</cell></row><row><cell>Validation (Dev)</cell><cell>2755</cell><cell>180</cell><cell>151</cell><cell>182</cell></row><row><cell>Testing</cell><cell>5509</cell><cell>369</cell><cell>308</cell><cell>324</cell></row></table><note>Table 1: Used datasets.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Test set results of the basic proposed model and its variants.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Matching Percentages of emotion related words in the top 20% attention scored parts of the text in T 1 and T 2 in Validation (V) and Testing (T) datasets .</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://pytorch.org/ 2 http://www.fast.ai/ 3 https://spacy.io/ 4 https://fasttext.cc/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to acknowledge La Région Occitanie and Communauté d'Agglomération Béziers Méditerranée which finance the thesis of Waleed Ragheb as well as INSERM and CNRS for their financial support of CONTROV project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bahdanau</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding emotions in text using deep learning and big data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee ; Hadjer</forename><surname>Boubenna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dohoon</forename><surname>Boubenna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Calefato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019a] Ankush Chatterjee, Umang Gupta, Manoj Kumar Chinnakotla, Radhakrishnan Srikanth, Michel Galley, and Puneet Agrawal</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="309" to="317" />
		</imprint>
	</monogr>
	<note>Computers in Human Behavior</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 3: Emocontext: Contextual emotion detection in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation (SemEval-2019)</title>
		<meeting>The 13th International Workshop on Semantic Evaluation (SemEval-2019)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Timothy Dozat and Christopher D. Manning. Deep biaffine attention for neural dependency parsing</title>
		<idno>abs/1611.01734</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Dozat and Manning</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
	<note>Deep Learning</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feature extraction and selection for emotion recognition from eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Jenke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="339" />
			<date type="published" when="2014-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Yukun Ma, Haiyun Peng, and Erik Cambria. Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Krakovsky ; Marina Krakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI 2018)</title>
		<editor>Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihalcea, Alexander F. Gelbukh, and Erik Cambria</editor>
		<imprint>
			<publisher>CoRR</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1243" to="1251" />
		</imprint>
	</monogr>
	<note>Dialoguernn: An attentive rnn for emotion detection in conversations. Association for the Advancement of Artificial Intelligence (AAAI 2019)</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pointer sentinel mixture models. CoRR, abs/1609.07843</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Merity</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<editor>Mohammad and Turney, 2013] Saif M. Mohammad and Peter D. Turney</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="436" to="465" />
		</imprint>
	</monogr>
	<note>Computational Intelligence</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohammad ; Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vaswani</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Edition of the Language Resources and Evaluation Conference (LREC-2018)</title>
		<editor>Sanjoy Dasgupta and David McAllester</editor>
		<meeting>the 11th Edition of the Language Resources and Evaluation Conference (LREC-2018)<address><addrLine>Miyazaki, Japan; Atlanta, Georgia, USA; Tom Young, Devamanyu Hazarika, Soujanya Poria, and Erik Cambria</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="17" to="19" />
		</imprint>
	</monogr>
	<note>Proceedings of the 30th International Conference on Machine Learning. Recent trends in deep learning based natural language processing. review article</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="730" to="739" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
