<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning for Classification of Hyperspectral Data: A Comparative Review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Audebert</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Bertrand</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Lefèvre</surname></persName>
						</author>
						<title level="a" type="main">Deep Learning for Classification of Hyperspectral Data: A Comparative Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, deep learning techniques revolutionized the way remote sensing data are processed. Classification of hyperspectral data is no exception to the rule, but has intrinsic specificities which make application of deep learning less straightforward than with other optical data. This article presents a state of the art of previous machine learning approaches, reviews the various deep learning approaches currently proposed for hyperspectral classification, and identifies the problems and difficulties which arise to implement deep neural networks for this task. In particular, the issues of spatial and spectral resolution, data volume, and transfer of models from multimedia images to hyperspectral data are addressed. Additionally, a comparative study of various families of network architectures is provided and a software toolbox is publicly released to allow experimenting with these methods. 1 This article is intended for both data scientists with interest in hyperspectral data and remote sensing experts eager to apply deep learning techniques to their own dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Thanks to recent advances in deep learning for image processing and pattern recognition, remote sensing data classification progressed tremendously in the last few years. In particular, standard optical imagery (Red-Green-Blue -RGBand Infra-Red -IR-) benefited from using deep convolutional neural networks (CNN) for tasks such as classification, object detection or semantic segmentation <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. This was made possible by the transfer of models developed in computer vision, which focuses mostly on images encoded on three channels. However, remote sensing relies often on multispectral imagery (coming from satellites such as Sentinel-2 or Landsat, or from airborne sensors) which allows to capture simultaneously the radiance at several wavelength bands. Hyperspectral imaging (HSI) data are a subset of multispectral data for which the wavelength resolution is fine, wavelength bands are contiguous and their range is particularly high. It makes possible a precise analysis of soils and materials <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>.</p><p>Indeed, the high spectral resolution allows to characterize precisely the electromagnetic spectrum of an object. However, most hyperspectral sensors have a low spatial resolution so deep learning techniques designed for computer vision are not easily transferable to hyperspectral data cubes since the spectral dimension prevails over the spatial neighborhood in most cases. If compared with today's optical images, the N. <ref type="bibr">Audebert</ref>  volume of data is similar but the structure is completely different. Moreover, the low spatial resolution actually limits the number of samples available for training statistical models. This also makes more difficult the annotation process which is required in supervised learning, since objects smaller than the spatial resolution are mixed with their neighborhood. These two points are the main challenges to take up in order to use deep learning for hyperspectral image processing. This article aims at bridging the gap between data scientists and hyperspectral remote sensing experts. Thus, it is more focused than previous reviews on deep learning <ref type="bibr" target="#b5">[6]</ref> while presenting hyperspectral peculiarities from a deep learning point of view, different from <ref type="bibr" target="#b6">[7]</ref>. We first summarize some principles of hyperspectral imaging and list some reference datasets available for public use. We then review some standard machine learning techniques used for classification before focusing on recent works with deep learning, where the comparison of existing networks is supported by experimental analysis. We finally conclude with an emphasis on the emerging research axes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. HYPERSPECTRAL IMAGING: PRINCIPLES AND RESOURCES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Hyperspectral imaging principles in a nutshell</head><p>Hyperspectral sensors measure the intensity of the radiant flux for a given surface and a given wavelength, i.e. a physical quantity in watts per squared meter steradian (W/(sr.m 2 )). Precisely, per each surface unit (which corresponds to a pixel of the image) the sensor captures light emitted and reflected by the object as a spectrum of several hundreds of channels, which defines a spectral response curve.</p><p>In the context of Earth Observation, signals coming from the Earth surface are changed by atmospheric perturbations such as clouds, water vapor atmospheric aerosols, etc. So, for remote sensing of surfaces and land cover, the reflectance is preferably used, defined as the ratio between the emitted flux of the surface and the incidental flux. This ratio gives the reflecting effectiveness of a given object for each light wavelength band. Reflectance is an intrinsic property of the materials, independently of the environment, and thus is highly discriminative for classification purposes.</p><p>To compensate for the atmospheric perturbations, several atmospheric correction methods have been developed <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> in order to obtain measures able to characterize the land cover <ref type="bibr" target="#b10">[11]</ref>. They take the intensity images as input and produce reflectance images, by getting rid of the light diffusion effects and radiative phenomena of the atmosphere. They are based on elaborate physics models and take into account acquisition arXiv:1904.10674v1 [cs.LG] 24 Apr 2019 parameters such as the sunlight levels or the local digital surface model to deal with multiple-reflection phenomena.</p><p>In practice, hyperspectral images are (w, h, B) tensors, i.e. three-dimensional cubes with two spatial dimensions (width w and height h) and a spectral one (with B bands). Compared to volumetric data, e.g. seismic data cubes, this so-called hypercube is anisotropic: the three dimensions do not represent the same physical displacement. However, all values in the hypercube are expressed in the same unit, either light intensities or reflectances, which makes linear operations on a 3D subset of the cube mathematically and physically valid. This property will come in handy when dealing with convolutions and filtering operations on the hypercube.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Reference datasets</head><p>Several public datasets captured using an hyperspectral sensor have been made available to the scientific community. They usually come along with annotations to evaluate the classification performances. Pavia, Indian Pines and Data Fusion Contest 2018 are presented in details in the following. Other standard ones include Salinas (captured with the AVIRIS sensor over the Salinas Valley, Cal., USA and composed of classes such as vegetable cultures, vineyeard and bare soils), Kennedy Space Center (also with AVIRIS over the Kennedy Space Center, with classes such as wetlands and various types of wild vegetation) and Botswana (captured with the Hyperion sensor from the EO'1 satellite, with 14 classes of vegetation and swamps over the Okavango delta). While characteristics of all are listed and compared in <ref type="table" target="#tab_1">Table I</ref>, a few ones are now presented in details. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Pavia:</head><p>Pavia is a dataset captured using the ROSIS sensor with a ground sample distance (GSD) of 1.3 m over the city of Pavia, Italy (cf. <ref type="figure" target="#fig_0">Fig. 1</ref>). It is divided in two parts: Pavia University (103 bands, 610 × 340px) and Pavia Center (102 bands, 1096 × 715px). 9 classes of interest are annotated covering 50% of the whole surface. They comprise various urban materials (such as bricks, asphalt, metals), water and vegetation.</p><p>This has been for long one of the main reference datasets because it is one of the largest labeled HSI data and because it allows to evaluate the use of HSI for potential applications. However, some preprocessing might be necessary in order to remove some pixels with no spectral information and a few errors occur in the ground-truth. 2) Data Fusion Contest 2018 (DFC2018): The DFC2018 hyperspectral data (cf. <ref type="figure" target="#fig_1">Fig. 2</ref>) was acquired over Central Houston, Texas, USA, using an airborne sensor. It covers a [380-1,050] nm spectral range over 48 contiguous bands at 1 m GSD. 20 classes of interest are defined and include not only urban categories (buildings and roads of various types, railways, cars, trains, etc.) but also various vegetation types (stressed, healthy, deciduous or evergreen trees) and specific materials. This dataset is part of the 2018 Data Fusion Contest release, along with very-high-resolution imagery and multispectral LiDAR <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[13]</ref>. 3) Indian Pines: Indian Pines is a dataset captured using the AVIRIS sensor. The scene covers agricultural areas in North-Western Indiana, USA, with a ground sampling distance (GSD) of 20 m/px, resulting in a 145 × 145px image with 224 spectral bands. Most parts of the image represent fields with various crops while the rest denotes forests and dense vegetation. 16 classes (cf. <ref type="figure" target="#fig_2">Fig. 3</ref> and 4) are labeled (e.g. corn, grass, soybean, woods, etc.), some of them being very rare (less than 100 samples for alfalfa or oats). Water absorption bands (104→108, 150→163 and 220) are usually removed before processing. In spite of its limited size, it is one of the main reference datasets of the community. Though, rare classes are usually not taken into account when evaluating classification algorithms.</p><p>4) Dataset summary: The various dataset statistics and informations are compiled in <ref type="table" target="#tab_1">Table I</ref>. This highlights that the main issue with applying machine learning approaches to hyperspectral data lies in the small number of available samples. Existing datasets are small with respect to standard optical imagery. Moreover, due to sensor diversity and postprocessing methods, it is not possible to train algorithms simultaneously on different datasets.</p><p>Nevertheless these datasets are available and have been shared among researchers for years thanks to the good will  III. HYPERSPECTRAL IMAGE ANALYSIS ISSUES AND STANDARD APPROACHES This section briefly recalls standard issues and current approaches for hyperspectral data processing. Especially, supervised statistical learning approaches for classification are detailed since they are obvious reference baselines and inspiration for deep learning-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pre-processing and normalization</head><p>Working with hyperspectral images often implies preprocessing the data. Besides the aforementioned atmospheric <ref type="bibr" target="#b1">2</ref> For example from http://www.ehu.eus/ccwintco/index.php?title= Hyperspectral Remote Sensing Scenes 3 IEEE GRSS DASE website: http://dase.grss-ieee.org/ and geometric corrections, band selection and normalization are often also applied. Those normalizations will impact how classifiers are able to separate spectral features in the ways described below. 1) Band selection: Depending on the sensor, some spectral bands might be difficult to process or contain outliers which modify the spectrum dynamics. For example, we often remove bands related to water absorption, bands with a low signal-tonoise ratio and saturated values. Not only this improves the robustness of the classifiers by alleviating the noise present in the data, this also helps fight against the well-known curse of dimensionality that provokes decreasing performances of statistical classification models when the dimensions of the data increases. Band selection can also be used by dropping uninformative bands, e.g. using Principal Component Analysis (PCA) <ref type="bibr" target="#b14">[14]</ref> or mutual information <ref type="bibr" target="#b15">[15]</ref>. However, band selection should be done carefully.Unsupervised dimension reduction can sometimes lead to worse performance than using the raw data since it might remove information that is not useful for compression but was discriminant for classification <ref type="bibr" target="#b16">[16]</ref> 2) Statistical normalization: It is a common practice in the machine learning community to normalize the data beforehand to rely on common assumptions for which classifiers are known to behave well, such as zero-mean and unit-variance. Standard strategies often allow to significantly improve processing with statistical approaches. We denote by X i individual spectra and by I the whole image. These strategies then are:</p><p>• Using the spectral angle, the normalized variant of the spectrum with a unit Euclidean norm: X = X/ X ; The angle between two spectra is a common similarity measure used for classification, notably in the popular Spectral Angle Mapper (SAM) classifier <ref type="bibr" target="#b17">[17]</ref>. • Normalizing first and second-order moments (so that to obtain a zero mean and unit variance). This can be done for each band independently, which works especially well with classifiers that expect all features to have similar amplitudes, such as Support Vector Machines. However, this squashes the dynamics in the spectral dimension. Alternatively, the normalization can be done globally on the whole image:</p><formula xml:id="formula_0">I = I−m I √ σ I ; • Converting the dynamics to [0, 1] using I = I−min(I) max(I)−min(I)</formula><p>. This is helpful mostly for numerical optimization that rarely behave well with very large values and relates more to the implementation than the theoretical standpoint. Once again, this can be applied for each band, at the risk of making relative amplitudes disappear and squashing dynamics, or globally on the whole image. Finally, in order to minimize the influence of outliers and obtain balanced image dynamics, it is also popular to clip on image values over a given threshold: either values over the last decile or outside the range m I ± 2 × √ σ I .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spectral classification</head><p>The most straightforward approach for classifying hyperspectral data is to consider it as a set of 1D spectra. This makes sense given its fine spectral resolution but low spatial resolution. Each pixel corresponds to a spectral signature, that is a discrete signal to which a statistical model can be fit. In the sequel, we restrict our considerations to machine learning approaches with little or not expert processing, but those previously cited. 1) Unmixing: In an ideal case, a pixel in an hyperspectral image corresponds to the reflectance of a material observed over a surface unit. However, the actual spatial resolution of HSI implies that often a pixel corresponds to a surface made of several various materials which produce a spectra mixture. Formally, if we denote by S 1 , . . . , S n the pure spectra (endmembers) of the set of materials in the scene, then for a pixel of coordinates (i, j), the locally observed spectrum is a function F of S i :</p><formula xml:id="formula_1">φ i,j = F (S 1 , . . . , S n ) n k=1 λ k S k .</formula><p>Under the hypothesis of a plane surface, we may assume F is a mere linear combination where weight coefficients λ k correspond to the proportion of material k in the observed area.</p><p>One way to perform hyperspectral data classification is unmixing <ref type="bibr" target="#b18">[18]</ref>, that is finding the individual materials in the observed area by computing their abundance maps. Reference spectra of pure materials are called end-members 4 and constitute a decomposition basis of mixed spectra. Abundance maps correspond to the proportional contributions of the endmembers to each pixel, that are the decomposition coefficients of the mixture. Usually, given the pure spectra S k and image Φ, it is possible to invert the linear system to obtain the coefficients λ k for each point, and thus abundance maps. Such approaches rely on linear algebra and numerical methods for solving inverse problems. However, learning-based approaches are also used, for instance clustering methods to find unknown end-members.</p><p>2) Dimensionality reduction: Much works are dedicated to reducing the dimension of spectra. Indeed, given the spatial resolution, neighbor intensities are highly correlated so a spectral signature contains a lot of redundant information. The main issue consists in extracting the discriminative information to reduce the set of relevant bands <ref type="bibr" target="#b19">[19]</ref>.Among the various preprocessing methods for feature generation which have been used, we can cite feature extraction algorithms such as the well-known principal component analysis (PCA) <ref type="bibr" target="#b20">[20]</ref> or more recently random feature selection <ref type="bibr" target="#b21">[21]</ref>. An other approach consists in computing some indices which integrate physical priors about the band response, such as the Normalized Difference Vegetation Index (NDVI) or the Normalized Difference Water Index (NDWI). This differs from band selection since the resulting features are not reflectances or intensities anymore. Instead, they are a new representation of the data in a space that will be suitable for classification.</p><p>Classification is then processed in a standard way, by using common statistical models: decision trees and random forests <ref type="bibr" target="#b22">[22]</ref>, support vector machines (SVM) <ref type="bibr" target="#b23">[23]</ref>, <ref type="bibr" target="#b24">[24]</ref>, etc. Approaches such as manifold learning also fit this framework <ref type="bibr" target="#b25">[25]</ref>. The goal of dimension reduction is to tackle the curse of dimensionality and to simplify the representation space to make the learning stage easier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Spatial-spectral classification</head><p>If a spectral-only approach might work, it is not satisfying since it does not benefit from the spatial structure of hyperspectral images. Indeed, it is likely that neighboring pixels may share some structural relationships (e.g. buildings usually have polygon shapes while vegetation has a fractal-like appearance). Taking the spatial aspect into account during the analysis improves the model robustness and efficiency thanks to these structural dependencies. Three main approaches can be distinguished based on when the spatial aspect is considered in the classification process.</p><p>1) Spatial regularization: A popular technique consists to classify individual spectra first, then to regularize the resulting classification with a spatially-structured model such as Markov Random Fields (MRF) or Conditional Random Fields (CRF) <ref type="bibr" target="#b26">[26]</ref>. Spatial regularization is then a supervised postprocessing.</p><p>2) Pre-segmentation: An alternate approach consists in performing spatial regularization as an unsupervised preprocessing. Various methods <ref type="bibr" target="#b27">[27]</ref>, <ref type="bibr" target="#b28">[28]</ref>, <ref type="bibr" target="#b29">[29]</ref> propose to first segment the hyperspectral image, then to aggregate spectrumwise features for each segmented region in order to enforce local consistence. Hierarchical segmentations, e.g. tree-like segmentations, are often used to derive local morphological features, such as in the popular morphological attribute profile approach <ref type="bibr" target="#b30">[30]</ref>.</p><p>3) Joint learning: The last approach learns simultaneously spatial and spectral features by using specific kernels. It takes roots in the inspiring works of <ref type="bibr" target="#b31">[31]</ref> to compute endmembers by benefiting from the correlation between spatially close pixels and <ref type="bibr" target="#b32">[32]</ref> by exploiting a mixture of spatial and spectral classifiers. More recent approaches focus on statistical models able to learn directly over local neighborhoods (fixed or adaptive) how to extract combined spectral and spatial features. In particular, <ref type="bibr" target="#b33">[33]</ref> introduced the possibility to design spatial-spectral kernels for SVMs able to handle hyperspectral data. This technique will then be largely adopted in later works <ref type="bibr" target="#b34">[34]</ref>, <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b36">[36]</ref>. With a similar objective, <ref type="bibr" target="#b37">[37]</ref> proposes a methood to choose automatically the filters which lead to the most efficient features for hyperspectral data classification from a random-filter bank.</p><p>The main limitation of traditional shallow learning methods stems from the feature engineering required to improve the classifier's performances. Indeed, spectra from different classes have to be separated in the feature space which can be challenging to achieve. In comparison, deep learning is focused on representation learning, i.e. automatically designing a feature space that is tailored to the objective task. This reduces significantly the need for feature engineering and hopefully should improve performances since both representation and classification will be jointly optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DEEP LEARNING FOR HYPERSPECTRAL DATA</head><p>Recent works use deep learning techniques for classifying hyperspectral images. The review which follows is organized so as to identify the main families of methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pre-processing and normalization</head><p>Pre-processing and normalization processes used for deep learning are similar to the ones used for standard machine learning. However, it is worth noting that most works do not use band selection or saturated spectrum removal but on the contrary rely on the robustness of neural networks.</p><p>For unmixing, a now standard, unsupervised approach <ref type="bibr" target="#b38">[38]</ref>, <ref type="bibr" target="#b39">[39]</ref> consists in a network with two stacked auto-encoders: the first one is used for denoising while the second one does the actual unmixing by enforcing a sparsity constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spectral classification</head><p>1) Supervised learning: The most straightforward evolution from shallow machine learning to deep learning is using a deep fully-connected network instead of a standard classifier (SVM or Random Forest). The principle remains the same, but the network may thematically model the task in a finer way and with a better discrimination capacity. This has been implemented since the 2000s <ref type="bibr" target="#b40">[40]</ref>, <ref type="bibr" target="#b41">[41]</ref> with small networks, and brought up to date recently by <ref type="bibr" target="#b42">[42]</ref> with unidimensional CNN which learn a filter collection to be applied on individual spectra. However, processing sequential data can also be done using Recurrent Neural Networks (RNN). RNN use memory to retrieve past information and are often used to process time series. <ref type="bibr" target="#b43">[43]</ref> suggests to use these RNN to classify hyperspectral data by assuming that these models can efficiently model both long-range and short-range dependencies in the spectral domain. A similar approach using RNN treating hyperspectral pixels as a sequence of reflectances was introduced in <ref type="bibr" target="#b44">[44]</ref>, including a pseudo-labeling scheme for semi-supervised learning. Finally, an approach using both the recurrent and convolutional aspects has been proposed by <ref type="bibr" target="#b45">[45]</ref>, in which the filtered features are finally processed by recurrent layers.</p><p>2) Unsupervised learning: One of the most important benefits of deep learning for processing hyperspectral data is the introduction of auto-encoders. Indeed, the band selection problem and more generally dimensionality reduction can be considered as a data compression issue. Within this perspective, auto-encoders allow to learn a smart compression with minimal information loss, for example more efficient than a standard PCA. Thus <ref type="bibr" target="#b46">[46]</ref> and later <ref type="bibr" target="#b47">[47]</ref> proposed dimension reduction through cascade of auto-encoders for denoising followed by classification with a simple perceptron.</p><p>C. Spatial-spectral approaches 1) 1D or 2D Convolutional Neural Networks: A more recent approach grounds in convolutional networks so popular in multimedia vision: Convolutional Neural Networks (CNN). In computer vision, most CNN are designed using a first part which is convolutional and performs the feature extraction and representation learning, and a second part which is fully connected and performs the classification. However, the number of filters is proportional to the number of input channels, e.g. for a first convolutional layer with a kernel 5 × 5 and n output channels, there will be 5 × 5 × n × 3 for an RGB image (3 channels) but 5×5×n×100 for common hyperspectral images (with 100 bands). Therefore, a popular approach to transpose deep convolutional networks to hyperspectral imaging consists in reducing the spectral dimension in order to close the gap between hyperspectral and RGB images. a) Supervised learning: Thus, several works proposed a CNN for hyperspectral data classification. <ref type="bibr" target="#b48">[48]</ref> uses a PCA to project the hyperspectral data into a 3-channel tensor to then perform the classification using a standard 2D CNN architecture, as shown in <ref type="figure" target="#fig_4">Figure 5</ref>. The architecture alternates convolutions and dimension reduction (either by PCA or by sampling) followed by a multi-layer perceptron for the final classification step, as shown in <ref type="figure" target="#fig_4">Figure 5</ref>, with 2D convolutions in red and 1D fully connected layers in blue. As an alternative, <ref type="bibr" target="#b50">[50]</ref> flattens the spatial dimensions to produce a 2D image with a different shape, instead of an hypercube, and then applies a traditional 2D CNN on the resulting image. One drawback of these methods is that they try to make hyperspectral images similar to RGB ones, i.e. to force hyperspectral data into the multimedia computer vision framework. However, the specific properties of hyperspectral imaging might be wasted when doing so, especially when using unsupervised and uncontrolled dimension reduction.</p><p>Trying to go around this problem, <ref type="bibr" target="#b51">[51]</ref>, <ref type="bibr" target="#b52">[52]</ref> propose another approach. Instead of dealing with the hypercube as a whole, they introduce two CNN: a 1D CNN that extracts a spectral feature along the radiometric dimension, and a 2D CNN that learns spatial features as previously described. The features from the two models are then concatenated and fed to a classifier to perform a spatial-spectral classification as usual.</p><p>b) Unsupervised learning: It is worth noting that this kind of models has also been extended for the semi-supervised and unsupervised setups. <ref type="bibr" target="#b53">[53]</ref> introduced 2D multi-scale convolutional auto-encoders for simultaneous embedding learning of hyperspectral data including both spatial and spectral information and classification, while <ref type="bibr" target="#b54">[54]</ref> proposed the use of CNN for unsupervised feature extraction: it performs reduction dimension of spectra by using also the spatial information using a regularizing sparse constraint.</p><p>Similarly to standard approaches, a first approach to spatialspectral classification consists in representing a pixel by a  <ref type="figure">Fig. 6</ref>: 2D+1D CNN for classification of hyperspectral data with a residual learning mechanism as proposed in <ref type="bibr" target="#b49">[49]</ref>.</p><p>descriptor with two parts :</p><p>• a spectral feature computed on the radiometric spectrum;</p><p>• a spatial feature computed on the local neighborhood of the considered pixel.</p><p>A standard descriptor is a vector obtained from the concatenation of the complete spectrum and the spatial feature obtained by PCA on a w × h-sized neighborhood around the pixel in all bands, from which the K principal components are kept (usually w = h 8 and K = 3). This descriptor is then processed by a deep classifier, often unsupervised such as Deep Belief Networks in <ref type="bibr" target="#b55">[55]</ref>, <ref type="bibr" target="#b56">[56]</ref>, Restricted Boltzmann Machines in <ref type="bibr" target="#b57">[57]</ref>, <ref type="bibr" target="#b58">[58]</ref>, or cascades of auto-encoders in <ref type="bibr" target="#b59">[59]</ref>, <ref type="bibr" target="#b60">[60]</ref>, <ref type="bibr" target="#b61">[61]</ref>, <ref type="bibr" target="#b62">[62]</ref>.</p><p>Overall, while the previous approaches introduced deep learning into the hyperspectral imaging framework, they did not fully leveraged the representation learning ability of endto-end deep networks. Indeed, ad hoc processing of the hypercube, either by splitting the dimensions or by unsupervised dimension reduction, could be replaced by learned counterparts.</p><p>2) 2D+1D CNN: a) Supervised learning: Indeed, the importance of spectral information leads to new approaches dealing globally with the hyperspectral cube. The idea is to process directly the hypercube using an end-to-end deep learning process. To answer the problem of the spectral dimension reduction, several works tried to design CNN alternating spatial convolutions with spectral ones to regularly reduce the size of the feature maps.</p><p>In particular <ref type="bibr" target="#b63">[63]</ref> introduces a CNN which consider both the spatial and spectral neighborhoods of a given pixel, i.e. that takes a 3D patch as an input. The first layers reduce the spectral dimension using a 1 × 1 × n kernel, then the spatial ones with a k × k × 1 kernel, and so on. Eventually, two fully-connected layers perform the final classification step. This allows them to compute feature maps where both spectral and spatial representations are learned in an alternate way.</p><p>In a similar idea, <ref type="bibr" target="#b64">[64]</ref> suggests an alternative approach that performs spatial-spectral convolutions in the first layer to perform spectral dimension reduction, similarly to what could be expected from PCA, albeit supervised and including spatial knowledge. Deeper layers form a traditional 2D CNN that performs as usual.</p><p>b) Unsupervised learning.: On the unsupervised side, <ref type="bibr" target="#b65">[65]</ref> introduce a 2D CNN with a residual learning paradigm <ref type="bibr" target="#b67">[66]</ref> that is able to learn an efficient low-dimension representation of the hyperspectral pixels and their neighborhood.</p><p>Finally, <ref type="bibr" target="#b49">[49]</ref> proposes a Fully Convolutional Network (FCN) which handles N bands. The first layer extracts a multiscale spatial-spectral feature using a module inspired by the Inception architecture <ref type="bibr" target="#b68">[67]</ref>. The model applies in the raw data several convolutions with an increasing kernel size in the spatial dimensions, i.e <ref type="figure" target="#fig_0">. 1×1×N , 3×3×N and 3×3×N</ref> where N is the number of bands. This reduces the spectral dimension and also performs a multi-scale filtering of the data. These resulting activation maps are then fed to a succession of nonlinearities and 1D convolutions that project the feature maps in the final classification space. This architecture is illustrated in <ref type="figure">Figure 6</ref>, with 1D convolution in pink, 2D convolutions in blue and pooling in orange. It is worth noting that thanks to its Fully Convolutional architecture, this network generates predictions for all pixels in the input patch, and not only the central one. This means that it is more efficient at inference time when sliding over the whole image.</p><p>3) 3D CNN: If spatial-spectral methods already reach particularly satisfying results, especially with respect to the spatial regularity, they require a high level of engineering in their design which is not fully compatible with the "datato-output" motto that defines deep learning. A promising approach <ref type="bibr" target="#b69">[68]</ref> handles directly the hyperspectral cube with 3D CNN which work simultaneously on the three dimensions using 3D convolutions. This conceptually simpler approach slightly improves the classification performances with respect to 2D+1D models. Many architectures have been proposed to handle 3D convolutional neural networks for hyperspectral data, mostly to investigate well-known techniques from deep learning for computer vision, such as multi-scale feature extraction <ref type="bibr" target="#b70">[69]</ref> and semi-supervision <ref type="bibr" target="#b71">[70]</ref>. Instead of producing 2D feature maps, these 3D CNN produce 3D feature cubes that are well-suited for pattern recognition in a volume and seem at least theoretically more relevant for hyperspectral image classification. <ref type="bibr" target="#b72">[71]</ref> especially showed that 3D CNN for classification of hyperspectral images obtained higher performances than their 2D counterparts.</p><p>Indeed, with respect to spectral or 2D+1D CNN, 3D CNN combine those two pattern recognition strategies into one filter, requiring less parameters and layers. They can learn to recognize more complex 3D patterns of reflectances: colocated spectral signatures, various differences of absorption between bands, etc. However, all directions are not equivalent in the hyperspectral data cube, so these patterns cannot be processed as mere volumetric data. As for 2D+1D CNN, it implies extra care when designing the network like using anisotropic filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparative Study of Deep Learning Architectures for</head><p>Hyperspectral Data 1) Deep Learning for Hyperspectral Toolbox: Despite the abundant literature on data driven hyperspectral image processing, there are only few available tools that can be used to compare the state of the art methods in a common framework. To this end, we provide DeepHyperX 5 , a deep learning toolbox based on the PyTorch framework that can be used to benchmark neural networks on various public hyperspectral datasets. It includes many supervised approaches, ranging from linear SVM to state of the art 3D CNN. Indeed, many models from the literature are implemented in the toolbox, including 1D CNN for spectral classification (cf. <ref type="figure">Fig. 8</ref>, with 1D convolutions in pink, pooling in orange and fully connected layers in blue) and the most recent 2D and 3D CNN as suggested in <ref type="bibr" target="#b63">[63]</ref>, <ref type="bibr" target="#b72">[71]</ref>, <ref type="bibr" target="#b49">[49]</ref>, <ref type="bibr" target="#b69">[68]</ref> (cf. <ref type="figure">Fig. 7</ref> for a 3D convolutional network architecture example, with 3D convolutions in green, 3D pooling in orange and 1D fully connected layers in blue). The models can be trained and evaluated on several datasets from the literature, e.g. Pavia Center/University, Indian Pines, Kennedy Space Center or DFC2018, described in Sec. II-B. Many hyper-parameters can be tuned to assess the impact of spatial features, the size of the training set or the optimization strategy. This toolbox allows us to evaluate how the methods from the state of the art compare in different use cases.</p><p>Technically, this toolbox is written in Python and consists in an interface around the PyTorch and scikit-learn libraries. Deep networks are implemented using PyTorch that can leverage both CPU and GPU based on the user needs, while we rely on scikit-learn for the SVM implementations. Several public classification datasets are pre-configured for easy investigation of deep models. The modular architecture of the toolbox allow users to easily add new remote sensing datasets and new deep architectures.</p><p>2) Best practices: Designing and optimizing deep networks can seem arcane, especially considering the abundant literature on this topic that has been published since 2010. However, a principled approach can drastically ease the process of experimenting deep learning on novel applications. A deep learning 5 https://github.com/nshaud/DeepHyperX experiment can be divided in three broad stages: building a model, optimizing the model and running inferences. We are assuming here that the model will be used for classification using a classification loss function such as the cross-entropy.</p><p>Building a model can often be summed up as choosing a model from the literature. Most of the time, it is better to rely on a well-validated architecture from the state of the art than spending time designing one from scratch. Based on the dataset and the application, choosing a model can be done on the following criterion:</p><p>• If the dataset is an image that presents spatial correlations, a 2D approach will outperform pixel-wise classifiers in most cases. For hyperspectral images, 3D CNN will be able to leverage correlations in all three dimensions of the data. • Bigger models mean more parameters to optimize requiring in turn more training samples. • Large convolutional kernels tend to be slower, especially in 3D. Most implementations are optimized for small 2D kernels. • Fully Convolutional Networks are more efficient since they can predict several pixels at a time. Moreover, the absence of fully connected layers means that they will have a lot less parameters, therefore being easier to train. • Non-saturating activation functions such as ReLU alleviate vanishing gradients and help build deeper networks while being faster to compute than sigmoid or tanh alternatives.</p><p>During training, the algorithm of choice for optimizing the network's weights is the backpropagation algorithm <ref type="bibr" target="#b73">[72]</ref>. This technique relies on the stochastic gradient descent (SGD) or one of its variants. Many versions have been proposed in the literature, using more or less hyperparameters. The fundamental hyperparameter is the learning rate α which controls the magnitude of the weight update after each iteration. A too high α will cause the loss to diverge or to oscillate around the local minimum without reaching it, while a too small α will be very slow to converge. In practice, it is recommended to train with the highest α that makes not the loss diverge at first, and then slowly decreasing it during the training. For example, our toolbox uses an adaptive policy that divides α by one order of magnitude when the validation error plateaus. An alternative is to use an SGD variant with an adaptive learning rate, such as the popular <ref type="bibr" target="#b74">[73]</ref>.</p><p>Dealing with the backpropagation with a large number of weights can be complex. Optimizing deep networks involves working with many parameters. One fundamental best practice that is often overlooked is the virtue of initialization. Weights are randomly initialized at the start of the training, but various strategies have been developed so that the SGD starting point has better convergence properties. The initialization policy from <ref type="bibr" target="#b76">[74]</ref> is especially suited for CNN including ReLU activation. Also, due to their large number of weights, the fully connected layers are often prone to overfitting. Dropout <ref type="bibr" target="#b77">[75]</ref> significantly alleviates this phenomenon. Moreover, deeper networks often benefit from a larger batch size and the use of Batch Normalization <ref type="bibr" target="#b78">[76]</ref>, which smooths the loss landscape.</p><p>Training sample preparation also includes a few practices that can be applied for better performances. First, shuffling the dataset after each epoch helps avoiding recurring patterns in the SGD and overall makes the optimization smoother. Data augmentation is especially useful to introduce equivariances. For example, in image data, horizontal and vertical symmetries can be applied by flipping the training patches randomly during the training. This increases the diversity of the examples and the robustness of the model. Moreover, many datasets present large class imbalance, where one or a few classes dominate the labels. One simple solution is to weight according to the loss function in order to penalize more the less-occurring classes. The inverse-median frequency class weighting is commonly used to do so, e.g. in semantic segmentation. This is equivalent to showing more examples from the rarer classes to the model.</p><p>It is fundamental to be careful when tuning the optimization hyperparameters. Their choice should be based on a validation set that is not the same as the test set, or the test results will be optimistic. If this is not possible, a cross-validation over several train/test splits helps to assess how robust the hyperparameters are in order to avoid overfitting.</p><p>Finally, during inference it is recommended to use the network that reached the best validation score and not necessarily the last epoch weights. This implies saving regular checkpoints during the training.</p><p>We tried our best in our toolbox to apply these best practices while letting advanced users use their own parameters where needed.</p><p>3) Experiments: In this section, we compare several deep architectures from the literature for hyperspectral image classification in a remote sensing context. To the best of our knowledge, there have been none principled analysis of the various deep convolutional networks introduced in the past. Indeed, works from the literature perform experiments using slightly different setups:</p><p>• Most papers divide the datasets in a train and test splits by randomly sampling over the whole image. A few papers (e.g. <ref type="bibr" target="#b43">[43]</ref>, <ref type="bibr" target="#b79">[77]</ref>) use the standard train/test split from the IEEE GRSS DASE initiative. • Some authors consider only a subset of the classes. This is especially prominent for Indian Pines, where the classes with less than 100 samples are often excluded, e.g. in <ref type="bibr" target="#b42">[42]</ref>, <ref type="bibr" target="#b49">[49]</ref>. • Even when the train/test splits are done the same way, the number of samples in the train set might vary. Some authors use 20% of all the training set, while others use a fixed amount of samples for each (e.g. 200 samples for each class). • Some authors further divide the training set into a proper training set and a validation set for hyperparameters tuning, while others perform the tuning directly on the test set. In this work, we argue that randomly sampling the training samples over the whole image is not a realistic use case. Moreover, we affirm that it is a poor indication of generalization power. Indeed, neighboring pixels will be highly correlated, which means that the test set will be very close to the train set.</p><p>To demonstrate this, we consider a nearest-neighbor baseline using randomly sampled training pixels, and another using colocated training pixels well-separated from the test set.</p><p>Also, in the case of 2D and 3D approaches, especially Convolutional Neural Networks, the receptive field of the network might involuntarily includes test samples in the training set. Indeed, the first convolutional layer also sees the neighbors of the central pixel which might be in the test set if the sampling has not been carefully checked. An example of this is illustrated in <ref type="figure">Figure 9</ref>.</p><p>Following the standards from the machine learning for remote sensing community, we perform our experiments by using well-defined train/test splits where the samples are extracted from significantly disjoint parts of the image. In the case of 3D CNN, it ensures that no pixel from the test set will be surreptitiously introduced in the train set. To do so, we use the train/test splits for Indian Pines, Pavia University and the DFC2018 as defined by the IEEE GRSS on the DASE benchmarking website. The ground truth is divided based on the connected components instead of the pixels, which allows the evaluation to actually measure how the model generalizes to new geo-entities. Hyperparameters are tuned using 5% of the train set as a separated validation set.</p><p>We use our toolbox to compare various reimplementations of the state of the art. Models have been implemented as close as possible to the original papers <ref type="bibr" target="#b5">6</ref> We list below the models compared and the changes we performed, if any:</p><p>• 1D CNN from <ref type="bibr" target="#b42">[42]</ref>. As the optimizer is not specified in the original paper, we use the standard SGD with momentum. • 1D RNN <ref type="bibr" target="#b43">[43]</ref>. The authors experiment both with the standard tanh non-linearity and a parameterized variant. We use the former. • 2D+1D CNN <ref type="bibr" target="#b63">[63]</ref>. No modification. • 3D CNN <ref type="bibr" target="#b69">[68]</ref>. No modification. The 2D+1D and 3D CNN are trained using patches of 5 × 5 pixels. The models are compared with two baselines: an SVM -obtained by grid search-and a fully-connected 1D neural network with three layers interlaced with Dropout <ref type="bibr" target="#b77">[75]</ref> using the ReLU non-linearity <ref type="bibr" target="#b80">[78]</ref>. To compensate the class unbalance in the three datasets, we use inverse median frequency for all models. We also use vertical and horizontal symmetries as data augmentation for the 2D and 3D CNN. We report in <ref type="table" target="#tab_1">Table II</ref> the overall accuracy and Cohen's kappa on the three datasets. Experiments are repeated 5 times on Pavia University and Indian Pines, though only once on the DFC2018 given its much larger size.</p><p>As could be expected, we obtain results significantly lower than those reported in the literature since we use strongly disjoint training and testing sets. <ref type="table" target="#tab_1">Table III</ref> reports the results of our implementation, the original score reported by the authors    <ref type="bibr" target="#b43">[43]</ref> for which our reimplementation underperforms, all of our reimplementations closely approach the results reported in the original papers. However, experimenting on a disjoint test set, which is the realistic use case, shows that the accuracies are actually much lower than expected, as reported in <ref type="table" target="#tab_1">Table II</ref>. It is interesting to see that Indian Pines exhibit a very different behavior compared to Pavia University and DFC2018. Indeed, including spatial information using 2D+1D and 3D CNN in Indian Pines actually decreases our classification accuracies. Our hypothesis stems from the fact that Indian Pines has a very low spatial resolution (20 m/px) compared to the two other datasets. This leads to each pixel being actually a mixture of the ground materials. As this dataset is focused on crop classification, this means that each pixel will be an average of the crop reflectance over 400m 2 , and bringing information from neighboring pixels does not really improve the discriminative power of the model. On the higher resolution Pavia University and DFC2018, 3D spatial-spectral CNN significantly boosts the model's accuracy, respectively by 3% and 2% compared to the 1D CNN, which shows the capacity of 3D CNN to efficiently combine spatial and spectral patterns with 3D filters. The DFC2018 is a very challenging dataset because of its large number of classes with high inter-class similarity. In our experiments, the 1D NN suffered from grave overfitting and performs worse than a linear SVM trained by SGD. This is because the test set from the DFC2018 has a large spatial extent and pixels have very different statistical properties compared to the train set. This overfitting is not a problem in Indian Pines and Pavia University, where the train and test sets are very similar and on the same scene, but will become much more important on real large scenes such as Houston from the DFC2018. Interestingly, the 2D+1D CNN seems to fail to catch the spatial information, maybe because of the low dimensions of the spatial kernels. Higher resolution datasets such as the DFC2018 would probably benefit from larger receptive fields to model long-distance spatial relationships between pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Perspectives</head><p>Several potential research axes appear for the future. A first one, which follows the works described previously, is the implementation of fully-3D, end-to-end networks for hyperspectral data. Indeed, they are theoretically able to perform the reduction dimension in both the spatial domain and the spectral domain. However, due to the small spatial resolution, a direct transfer of 2D CNN which mainly rely on the spatial context   of a full spectrum is not the most promising alternative. On the contrary, the transfer of 3D fully-convolutional networks could extract meaningful local features and tackle this issue. However, there is also a need for new, larger and more complex (e.g., with more classes) reference hyperspectral datasets for the classification task. Indeed, the community has developed standard approaches which already reach satisfying results on most of them, so it is not anymore possible to distinguish between the new proposed approaches.</p><p>A second promising research field is the study of unsupervised and semi-supervised models to overcome the sparsely available annotations of hyperspectral data. For example, 3D spatial-spectral auto-encoders might learn representations of hyperspectral scenes independently of the acquisition context, which can be used for subsequent tasks such as clustering or classification.</p><p>Finally, a last coming research field is data synthesis, which would allow to simulate realistic hyperspectral scenes. In the recent years, generative models such as Gaussian Mixture Models or Generative Adversarial Networks (GAN) have been applied to generate new training samples. Initially, the idea was that generative models could approximate the distribution of the deep features in the embedded space. Then, the models infers new samples that could be used to train larger classifiers. <ref type="bibr" target="#b81">[79]</ref> (using GMM) and <ref type="bibr" target="#b82">[80]</ref> (using GAN) are two examples of such works. However, thanks to the theoretical improvements to the GAN framework, deep generative models are now able to synthesize from scratch hyperspectral pixels <ref type="bibr" target="#b83">[81]</ref> and even small hyperspectral cubes using 3D CNN <ref type="bibr" target="#b84">[82]</ref>. This can of course be used for data augmentation, although the benefit of adding new data estimated from a generative model does not seem huge at this point. Nonetheless, generative models will likely be a great asset to estimate image transformations that usually are costly to implement or require specific expert knowledge, such as atmospheric correction, transfer function estimation between sensors or image denoising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>Deep learning already proved to be efficient for hyperspectral data. 2D or 3D convolutional networks allow to combine spatial and spectral information intuitively and the first published works show state of the art performances, often without expert knowledge about the physics or the sensor.</p><p>Today, the main challenge is the scarce availability of massively annotated datasets. Yet, data volume is the key of the success of statistical approaches. A promising path is the development of unsupervised approaches and data augmentation by synthesis in order to overcome this issue and unlock the full potential of deep learning in hyperspectral imaging.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Pavia University (natural composite image).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Data Fusion Contest 2018 [12] over Houston: composite image with bands 48, 32 and 16 (top) and ground-truth (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Indian Pines (natural composite image).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Examples of train/test splits on the Indian Pines dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>2D CNN for classification of hyperspectral data proposed in<ref type="bibr" target="#b48">[48]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :Fig. 8 :</head><label>78</label><figDesc>3D CNN for classification of hyperspectral data available in the toolbox. It reproduces the architecture proposed in<ref type="bibr" target="#b72">[71]</ref> and alternates 3D convolutions and 3D max-pooling layers.-S p e c t r u m 1D CNN for spectral classification of hyperspectral data available in the toolbox.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and B. Le Saux are with DTIS, ONERA, University Paris Saclay, F-91123 Palaiseau -France. E-mails: nicolas.audebert@onera.fr, bertrand.le saux@onera.fr.</figDesc><table /><note>S. Lefèvre is with Univ. Bretagne Sud, UMR 6074, IRISA, F-56000 Vannes, France. E-mail: sebastien.lefevre@irisa.fr Manuscript received April 30, 2018.1 https://github.com/nshaud/DeepHyperX</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Main public labeled datasets in hyperspectral imaging.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Pixels Bands</cell><cell>Range</cell><cell>GSD Labels Classes Mode</cell></row><row><cell cols="5">Pavia (U &amp; C) 991,040 103 0.43-0.85 µm 1.3 m 50,232 9</cell><cell>Aerial</cell></row><row><cell>Indian Pines</cell><cell cols="4">21,025 224 0.4-2.5 µm 20 m 10,249 16</cell><cell>Aerial</cell></row><row><cell>Salinas</cell><cell cols="4">111,104 227 0.4-2.5 µm 3.7 m 54,129 16</cell><cell>Aerial</cell></row><row><cell>KSC</cell><cell cols="4">314,368 176 0.4-2.5 µm 18 m 5,211 13</cell><cell>Aerial</cell></row><row><cell>Botswana</cell><cell cols="4">377,856 145 0.4-2.5 µm 30 m 3,248 14 Satellite</cell></row><row><cell cols="2">DFC 2018 5,014,744</cell><cell cols="3">48 0.38-1.05 µm 1 m 547,807 20</cell><cell>Aerial</cell></row><row><cell cols="5">of some research groups over the World 2 . Moreover, IEEE</cell></row><row><cell cols="5">GRSS is providing the community with the GRSS Data and</cell></row><row><cell cols="5">Algorithm Standard Evaluation (DASE) website 3 . On DASE,</cell></row><row><cell cols="5">researchers can access the data for Indian Pines, Pavia and</cell></row><row><cell cols="5">DFC2018, and submit classification maps which are evaluated</cell></row><row><cell cols="5">on-line. For each dataset, a leader-board allows to compare</cell></row><row><cell cols="5">the state-of-the-art methods as soon as they are tested.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Test pixel in receptive field , •: center pixel. The 2D receptive field of a CNN can involuntarily include samples from the test set, making the network overfit and biasing the evaluation.of each model and the gap between evaluating either on a uniform random or a disjoint separated test set. Except for the RNN from</figDesc><table><row><cell></cell><cell cols="2">Random train/test</cell><cell></cell><cell>Disjoint train/test</cell></row><row><cell>Fig.</cell><cell>9:</cell><cell>Train ,</cell><cell>Test ,</cell><cell>Receptive field ,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE II :</head><label>II</label><figDesc>Experimental results of various models from our toolbox on the Indian Pines, Pavia University and DFC 2018 datasets using the DASE train/test split. Best results are in bold and second are in italics.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Indian Pines</cell><cell cols="2">Pavia University</cell></row><row><cell>Model</cell><cell cols="4">Random Disjoint Random Disjoint</cell></row><row><cell>Nearest-neighbor</cell><cell>75.63</cell><cell>67.27</cell><cell>89.99</cell><cell>57.77</cell></row><row><cell>1D CNN [42] (original)</cell><cell>90.16</cell><cell>-</cell><cell>92.56</cell><cell>-</cell></row><row><cell>1D CNN (ours)</cell><cell>89.34</cell><cell>82.99</cell><cell>90.59</cell><cell>81.18</cell></row><row><cell>RNN [43] (original)</cell><cell>85.7</cell><cell>-</cell><cell>-</cell><cell>80.70</cell></row><row><cell>RNN (ours)</cell><cell>79.70</cell><cell>62.23</cell><cell>-</cell><cell>67.71</cell></row><row><cell cols="2">2D+1D CNN [63] (original) -</cell><cell>-</cell><cell>94.6</cell><cell>-</cell></row><row><cell>2D+1D CNN (ours)</cell><cell>-</cell><cell>-</cell><cell>92.39</cell><cell>83.80</cell></row><row><cell>3D CNN [68] (original)</cell><cell>99.07</cell><cell>-</cell><cell>99.39</cell><cell>-</cell></row><row><cell>3D CNN (ours)</cell><cell>96.87</cell><cell>75.47</cell><cell>96.71</cell><cell>84.32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III :</head><label>III</label><figDesc>Experimental results with respect to methodological discrepancies between various implementations and evaluation strategies on the Indian Pines and Pavia University datasets.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">A mineralogy term form pure minerals, by opposition to most minerals which exist as solid solutions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">It is worth noting that despite the authors' best efforts, reproducing exactly the results using only the papers and without the original implementations is very difficult. Many hyperparameters and implementation tricks are omitted in the manuscripts, and can only be guessed when trying to reproduce the results. Although this is not specific to hyperspectral data, providing code along with papers has been critical to the success of deep learning in many other areas such as computer vision and natural language processing.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Xavier Ceamanos and Naoto Yokoya for their helpful and valuable insights on various issues examined in this article. The authors would also like to thank the National Center for Airborne Laser Mapping and the Hyperspectral Image Analysis Laboratory at the University of Houston for acquiring and providing the DFC2018 data used in this study, and the IEEE GRSS Image Analysis and Data Fusion Technical Committee. The authors thank Prof. Paolo Gamba from the Telecommunications and Remote Sensing Laboratory, Pavia university (Italy) for providing the Pavia dataset. The authors thank Prof. David Landgrebe and Larry Biehl from Purdue University, West Lafayette (IN., USA) for providing the Indian Pines dataset.</p><p>Nicolas Audebert's work is funded by the joint Total-ONERA research project NAOMI.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic Segmentation of Earth Observation Data Using Multimodal and Multi-scale Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Audebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ACCV 2016</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-11" />
			<biblScope unit="page" from="180" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dense Semantic Labeling of Subdecimeter Resolution Images With Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="881" to="893" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic Segmentation of Aerial Images with an Ensemble of CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marmanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Galliani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Stilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="473" to="480" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hyperspectral remote sensing data analysis and future challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Scheunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="6" to="36" />
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Physics-Based Unmixing Method to Estimate Subpixel Temperatures on Mixed Pixels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cubero-Castan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Achard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Briottet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shimoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1894" to="1906" />
			<date type="published" when="2015-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep learning in remote sensing: A comprehensive review and list of resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fraundorfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="8" to="36" />
			<date type="published" when="2017-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Advances in hyperspectral image and signal processing: A comprehensive overview of the state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rasti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="37" to="78" />
			<date type="published" when="2017-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Atmospheric correction of infrared measurements of sea surface temperature using channels at 3.7, 11 and 12 mm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Deschamps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phulpin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Boundary-Layer Meteorology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="143" />
			<date type="published" when="1980-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SMAC: a simplified method for the atmospheric correction of satellite measurements in the solar spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dedieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="143" />
			<date type="published" when="1994-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image-based atmospheric corrections: Revisited and improved</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chavez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogrammetric engineering and remote sensing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1025" to="1036" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Atmospheric correction algorithms for hyperspectral remote sensing data of land and ocean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">O</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Goetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing of Environment</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="17" to="24" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">IEEE GRSS Data Fusion Contest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee Grss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<ptr target="http://www.grss-ieee.org/community/technical-committees/data-fusion" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">2018 IEEE GRSS Data Fusion Contest: Multimodal land use classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="54" />
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
	<note>technical committees</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the impact of PCA dimension reduction for hyperspectral detection of difficult targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Mersereau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="192" to="195" />
			<date type="published" when="2005-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Band Selection for Hyperspectral Image Classification Using Mutual Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Damper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D B</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="522" to="526" />
			<date type="published" when="2006-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Band selection and its impact on target detection and classification in hyperspectral image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Advances in Techniques for Analysis of Remotely Sensed Data</title>
		<imprint>
			<date type="published" when="2003-10" />
			<biblScope unit="page" from="374" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discrimination among semiarid landscape endmembers using the Spectral Angle Mapper (SAM) algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yuhas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boardman</surname></persName>
		</author>
		<ptr target="https://ntrs.nasa.gov/search.jsp?R=19940012238" />
	</analytic>
	<monogr>
		<title level="m">Summaries of the Third Annual JPL Airborne Geoscience Workshop</title>
		<imprint>
			<publisher>AVIRIS Workshop</publisher>
			<date type="published" when="1992-06" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unmixing hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ziehe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Neural Information Processing Systems</title>
		<meeting>the 12th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="942" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Extraction of optimal spectral bands using hierarchical band merging out of hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Le</forename><surname>Bris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chehata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Briottet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paparoditis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing and Spatial Information Sciences</title>
		<imprint>
			<biblScope unit="page" from="459" to="465" />
			<date type="published" when="2015-08" />
		</imprint>
	</monogr>
	<note>ISPRS -International Archives of the Photogrammetry</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Principal component analysis for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rodarmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Surveying and Land Information Science</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sparse Hilbert Schmidt Independence Criterion and Surrogate-Kernel-Based Feature Selection for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Damodaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2385" to="2398" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Investigation of the random forest framework for classification of hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="492" to="501" />
			<date type="published" when="2005-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral remote sensing images with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1778" to="1790" />
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Support vector machines for hyperspectral remote sensing classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Gualtieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Cromp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE 27th AIPR Workshop: Advances in Computer-Assisted Recognition</title>
		<meeting>SPIE 27th AIPR Workshop: Advances in Computer-Assisted Recognition</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">3584</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PerTurbo Manifold Learning Algorithm for Weakly Labeled Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chapel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1070" to="1078" />
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised Conditional Random Field for hyperspectral remote sensing image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</title>
		<imprint>
			<date type="published" when="2016-07" />
			<biblScope unit="page" from="2614" to="2617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Segmentation and classification of hyperspectral images using watershed transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2367" to="2379" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Advances in Spectral-Spatial Classification of Hyperspectral Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Tilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="652" to="675" />
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Vector Attribute Profiles for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Mura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3208" to="3220" />
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extended profiles with morphological attribute filters for the analysis of hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Mura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Waske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<idno type="DOI">10.1080/01431161.2010.512425</idno>
		<ptr target="https://doi.org/10.1080/01431161.2010.512425" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="5975" to="5991" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spatial/spectral endmember extraction by multidimensional morphological operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2025" to="2041" />
			<date type="published" when="2002-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploiting spectral and spatial information in hyperspectral urban data with high resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dell&amp;apos;acqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gamba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arnason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="322" to="326" />
			<date type="published" when="2004-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Composite kernels for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gomez-Chova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Muñoz-Marí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vila-Francés</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Calpe-Maravilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="97" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2973" to="2987" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Spatial-spectral Kernel-based Approach for the Classification of Remote-sensing Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="381" to="392" />
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scalable Bag of Subpaths Kernel for Learning on Hierarchical Image Representations and Multi-Source Remote Sensing Data Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chapel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">196</biblScope>
			<date type="published" when="2017-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multiclass feature learning for hyperspectral image classification: Sparse and hierarchical solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="272" to="285" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hyperspectral image unmixing using autoencoder cascade</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Endnet: Sparse autoencoder network for endmember extraction and hyperspectral unmixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Esen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Akar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.01894</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral data by decision trees and artificial neural networks to identify weed stress and nitrogen status of corn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Prasher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Landry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Bonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Viau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Electronics in Agriculture</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="67" to="93" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Semisupervised Neural Networks for Efficient Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2271" to="2282" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep Convolutional Neural Networks for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sensors</title>
		<imprint>
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page">258619</biblScope>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep Recurrent Neural Networks for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3639" to="3655" />
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Semi-Supervised Deep Learning Using Pseudo Labels for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1259" to="1270" />
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Convolutional Recurrent Neural Networks forHyperspectral Data Classification</title>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">298</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Stacked Denoise Autoencoder Based Feature Extraction and Classification for Hyperspectral Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sensors</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="page">3632943</biblScope>
			<date type="published" when="2015-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Semi-supervised classification of hyperspectral imagery based on stacked autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE 10033, Eighth International Conference on Digital Image Processing (ICDIP)</title>
		<meeting>SPIE 10033, Eighth International Conference on Digital Image essing (ICDIP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">10033</biblScope>
			<biblScope unit="page" from="100" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep supervised learning for hyperspectral data classification through convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Makantasis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karantzalos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doulamis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Doulamis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</title>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="4959" to="4962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Going deeper with contextual cnn for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4843" to="4855" />
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hyperspectral Image Classification with Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Slavkovikj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verstockt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>De Neve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Hoecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van De Walle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM International Conference on Multimedia, ser. MM &apos;15</title>
		<meeting>the 23rd ACM International Conference on Multimedia, ser. MM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1159" to="1162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Spectral-Spatial Feature Extraction for Hyperspectral Image Classification: A Dimension Reduction and Deep Learning Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4544" to="4554" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral images using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="468" to="477" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">On combining multiscale deep learning features for the classification of hyperspectral remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3368" to="3379" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unsupervised Deep Feature Extraction for Remote Sensing Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1349" to="1362" />
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral image based on deep belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="5132" to="5136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Spectral-Spatial Classification of Hyperspectral Data Based on Deep Belief Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2381" to="2392" />
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral image using autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 9th International Conference on Information</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deep Model for Classification of Hyperspectral Image Using Restricted Boltzmann Machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Midhun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">T N</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 International Conference on Interdisciplinary Advances in Applied Computing, ser. ICONIAAC &apos;14</title>
		<meeting>the 2014 International Conference on Interdisciplinary Advances in Applied Computing, ser. ICONIAAC &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deep Learning-Based Classification of Hyperspectral Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2094" to="2107" />
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Spectral-Spatial Classification of Hyperspectral Image Based on Deep Auto-Encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4073" to="4085" />
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Unsupervised Spectral-Spatial Feature Learning With Stacked Sparse Autoencoder for Hyperspectral Imagery Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2438" to="2442" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Spectral-spatial multi-feature-based deep learning for hyperspectral remote sensing image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-K</forename><forename type="middle">R</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="213" to="221" />
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deep Learning Approach for Remote Sensing Image Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ben Hamida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A. Chokri</forename><surname>Ben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data from Space (BiDS&apos;16)</title>
		<meeting><address><addrLine>Santa Cruz de Tenerife, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="page">133</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10478</idno>
		<title level="m">HSI-CNN: A Novel Convolution Neural Network for Hyperspectral Image</title>
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Unsupervised Spectral-Spatial Feature Learning via Deep Residual Conv-Deconv Network for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="391" to="406" />
			<date type="published" when="2018-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<ptr target="http://ieeexplore.ieee.org/document/8082108/" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<address><addrLine>Las Vegas, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<ptr target="http://www.cv-foundation.org/openaccess/contentcvpr2015/html/SzegedyGoingDeeperWith2015CVPRpaper.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Spectral-Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multi-scale 3d deep convolutional neural network for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>the IEEE International Conference on Image Processing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="3904" to="3908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A semi-supervised convolutional neural network for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="839" to="848" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Deep Feature Extraction and Classification of Hyperspectral Images Based on Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6232" to="6251" />
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Backpropagation Applied to Handwritten Zip Code Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
				<ptr target="http://arxiv.org/abs/1412.6980" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<ptr target="http://jmlr.org/proceedings/papers/v37/ioffe15.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Low-Shot Learning for the Semantic Segmentation of Remote Sensing Imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6214" to="6223" />
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">GMM-Based Synthetic Samples for Classification of Hyperspectral Images With Limited Training Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Riess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="942" to="946" />
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Generative Adversarial Networks-Based Semi-Supervised Learning for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<ptr target="https://www.mdpi.com/2072-4292/9/10/1042" />
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1042</biblScope>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Generative adversarial networks for realistic synthesis of hyperspectral samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Audebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</title>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="page" from="5091" to="5094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Generative Adversarial Networks for Hyperspectral Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5046" to="5063" />
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
				<title level="m">Dr. Nicolas Audebert (M.Eng 2015 Supélec, M</title>
		<meeting><address><addrLine>Sc</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">University of Tours, French HDR degree 2009 at University of Strasbourg) is Full Professor in Computer Science in University Bretagne Sud since 2010, where he conducts his researches within the Institute for Research in Computer Science and Random Systems (IRISA). He is leading the OBELIX team dedicated to image analysis and machine learning for remote sensing and Earth Observation</title>
		<ptr target="http://www.irisa.fr/obelix" />
	</analytic>
	<monogr>
		<title level="m">He currently serves as the chair of the IEEE GRSS Image Analysis and Data Fusion Technical Committee. Prof. Sébastien Lefèvre (M.Sc. 1999 at TU Compiègne</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Université Paris-Sud, PhD 2018 Univ. Bretagne-Sud</orgName>
		</respStmt>
	</monogr>
	<note>He has coauthored more than 140 papers in image analysis and pattern recognition. His current research interests are mainly related to hierarchical image analysis and deep learning applied to remote sensing of environment. He was co-chair of GEOBIA 2016 and is cochair of JURSE 2019</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
