<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Wiedemann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="laboratory">Language Technology Group</orgName>
								<orgName type="institution">Universität Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Remus</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="laboratory">Language Technology Group</orgName>
								<orgName type="institution">Universität Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Chawla</surname></persName>
							<email>avi.chawla.cse16@iitbhu.ac.in</email>
							<affiliation key="aff1">
								<orgName type="department">Indian Institute of Technology (BHU)</orgName>
								<address>
									<settlement>Varanasi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="laboratory">Language Technology Group</orgName>
								<orgName type="institution">Universität Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Contextualized word embeddings (CWE) such as provided by ELMo (Peters et al.,  2018), Flair NLP (Akbik et al., 2018), or  BERT (Devlin et al., 2019 are a major recent innovation in NLP. CWEs provide semantic vector representations of words depending on their respective context. Their advantage over static word embeddings has been shown for a number of tasks, such as text classification, sequence tagging, or machine translation. Since vectors of the same word type can vary depending on the respective context, they implicitly provide a model for word sense disambiguation (WSD). We introduce a simple but effective approach to WSD using a nearest neighbor classification on CWEs. We compare the performance of different CWE models for the task and can report improvements above the current state of the art for two standard WSD benchmark datasets. We further show that the pre-trained BERT model is able to place polysemic words into distinct 'sense' regions of the embedding space, while ELMo and Flair NLP do not seem to possess this ability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Synonymy and Polysemy of Word Representations</head><p>Lexical semantics is characterized by a high degree of polysemy, i.e. the meaning of a word changes depending on the context in which it is currently used <ref type="bibr" target="#b5">(Harris, 1954)</ref>. Word Sense Disambiguation (WSD) is the task to identify the correct sense of the usage of a word from a (usually) fixed inventory of sense identifiers. For the English language, WordNet <ref type="bibr" target="#b4">(Fellbaum, 1998)</ref> is the most commonly used sense inventory providing more than 200K word-sense pairs.</p><p>To train and evaluate WSD systems, a number of shared task datasets have been published in the SemEval workshop series. In the lexical sample task <ref type="bibr" target="#b8">(Kilgarriff, 2001;</ref><ref type="bibr">Mihalcea et al., 2004)</ref>, a training set and a test set is provided. The relatively large data contains one sense-annotated word per training/test instance. The all-words task <ref type="bibr" target="#b3">(Edmonds and Cotton, 2001;</ref><ref type="bibr" target="#b22">Snyder and Palmer, 2004)</ref> only provides a small number of documents as test data where each ambiguous word is annotated with its sense. To facilitate the comparison of WSD systems, some efforts have been made to provide a comprehensive evaluation framework <ref type="bibr" target="#b19">(Raganato et al., 2017)</ref>, and to unify all publicly available datasets for the English language <ref type="bibr" target="#b24">(Vial et al., 2018b)</ref>.</p><p>WSD systems can be distinguished into three types -knowledge-based, supervised, and semisupervised approaches. Knowledge-based systems utilize language resources such as dictionaries, thesauri and knowledge graphs to infer senses. Supervised approaches train a machine classifier to predict a sense given the target word and its context based on an annotated training data set. Semisupervised approaches extend manually created training sets by large corpora of unlabeled data to improve WSD performance. All approaches rely on some way of context representation to predict the correct sense. Context is typically modeled via dictionary resources linked with senses, or as some feature vector obtained from a machine learning model.</p><p>A fundamental assumption in structuralist linguistics is the distinction between signifier and signified as introduced by Ferdinand de Saussure <ref type="bibr" target="#b21">(Saussure, 2001)</ref> in the early 20 th century. Computational linguistic approaches, when using character strings as the only representatives for word meaning, implicitly assume identity between signifier and signified. Different word senses are simply collapsed into the same string representation. In this respect, word counting and dictionary-based approaches to analyze natural language texts have been criticized as pre-Saussurean <ref type="bibr">(Pêcheux et al., 1995)</ref>. In contrast, the distributional hypothesis not only states that meaning is dependent on context. It also states that words occurring in the same contexts tend to have a similar meaning <ref type="bibr" target="#b5">(Harris, 1954)</ref>. Hence, a more elegant way of representing meaning has been introduced by using the contexts of a word as an intermediate semantic representation that mediates between signifier and signified. For this, explicit vector representations, such as TF-IDF, or latent vector representations, with reduced dimensionality, have been widely used. Latent vector representations of words are commonly called word embeddings. They are fixed length vector representations, which are supposed to encode semantic properties. The seminal neural word embedding model Word2Vec <ref type="bibr">(Mikolov et al., 2013)</ref>, for instance, can be trained efficiently on billions of sentence contexts to obtain semantic vectors, one for each word type in the vocabulary. It allows synonymous terms to have similar vector representations that can be used for modeling virtually any downstream NLP task. Still, a polysemic term is represented by one single vector only, which represents all of its different senses in a collapsed fashion.</p><p>To capture polysemy as well, the idea of word embeddings has been extended to encode word sense embeddings. <ref type="bibr" target="#b13">Neelakantan et al. (2014)</ref> first introduced a neural model to learn multiple embeddings for one word depending on different senses. The number of senses can be defined by a given parameter, or derived automatically in a non-paramentric version of the model. However, employing sense embeddings in any downstream NLP task requires a reliable WSD system in an earlier stage to decide how to choose the appropriate embedding from the sense inventory.</p><p>Recent efforts to capture polysemy for word embeddings give up on the idea of a fixed word sense inventory. Contextualized word embeddings (CWE) do not only create one vector representation for each type in the vocabulary, they also they produce distinct vectors for each token in a given context. The contextualized vector representation is supposed to represent word meaning and context information. This enables downstream tasks to actually distinguish the two levels of the signifier and the signified allowing for more realistic modeling of natural language. The advantage of such contextually embedded token representations compared to static word embeddings has been shown for a number of tasks such as text classification <ref type="bibr" target="#b28">(Zampieri et al., 2019)</ref> and sequence tagging <ref type="bibr" target="#b0">(Akbik et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contribution:</head><p>We show that CWEs can be utilized directly to approach the WSD task due to their nature of providing distinct vector representations for the same token depending on its context. To learn the semantic capabilities of CWEs, we employ a simple, yet interpretable approach to WSD using a k-nearest neighbor classification (kNN) approach. We compare the performance of three different CWE models on four standard benchmark datasets. Our evaluation yields that not all contextualization approaches are equally effective in dealing with polysemy, and that the simple kNN approach suffers severely from sparsity in training datasets. Yet, by using kNN, we include provenance into our model, which allows to investigate the training sentences that lead to the classifier's decision. Thus, we are able to study to what extent polysemy is captured by a specific contextualization approach. For two datasets, we are able to report new state-of-the-art (SOTA) results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Word Sense Disambiguation</head><p>Several efforts have been made to induce different vectors for the multiplicity of senses a word can express. <ref type="bibr">Bartunov et al. (2016)</ref>, <ref type="bibr" target="#b13">Neelakantan et al. (2014)</ref>, or <ref type="bibr" target="#b20">Rothe and Schütze (2015)</ref> induce so-called sense embeddings in a pre-training fashion. While <ref type="bibr">Bartunov et al. (2016)</ref> induce sense embeddings in an unsupervised way and only fix the maximum number of senses per word, <ref type="bibr" target="#b20">Rothe and Schütze (2015)</ref> require a pre-labeled sense inventory such as WordNet. Then, the sense embeddings are mapped to their corresponding synsets. Other approaches include the re-use of pre-trained word embeddings in order to induce new sense embeddings <ref type="bibr" target="#b15">(Pelevina et al., 2016;</ref><ref type="bibr">Remus and Biemann, 2018)</ref>. <ref type="bibr" target="#b14">Panchenko et al. (2017)</ref> then also use induced sense embeddings for the downstream task of WSD. Camacho-Collados and Pilehvar (2018) provide an extensive overview of different word sense modeling approaches.</p><p>For WSD, (semi-)supervised approaches with recurrent neural network architectures represent the current state of the art. Two major approaches were followed. <ref type="bibr">First, Melamud et al. (2016)</ref> and <ref type="bibr" target="#b27">Yuan et al. (2016)</ref>, for instance, compute sentence context vectors for ambiguous target words. In the prediction phase, they select nearest neighbors of context vectors to determine the target word sense. <ref type="bibr" target="#b27">Yuan et al. (2016)</ref> also use unlabeled sentences in a semisupervised label propagation approach to overcome the sparse training data problem of the WSD task. Second, Kågebäck and Salomonsson (2016) employ a recurrent neural network to classify sense labels for an ambiguous target word given its surrounding sentence context. In contrast to earlier approaches, which relied on feature engineering <ref type="bibr">(Taghipour and Ng, 2015)</ref>, their architecture only uses pretrained GloVe word embeddings <ref type="bibr" target="#b16">(Pennington et al., 2014)</ref> to achieve SOTA results on two English lexical sample datasets. For the all-words WSD task, <ref type="bibr" target="#b23">Vial et al. (2018a)</ref> also employ a recurrent neural network. But instead of single target words, they sequentially classify sense labels for all tokens in a sentence. They also introduce an approach to collapse the sense vocabulary from WordNet to unambiguous hypersenses, which increases the label to sample ratio for each label, i.e. sense identifier. By training their network on the large sense annotated datasets SemCor <ref type="bibr" target="#b11">(Miller et al., 1993)</ref> and the Princeton Annotated Gloss Corpus based on WordNet synset definitions (Fellbaum, 1998), they achieve the highest performance so far on most all-words WSD benchmarks. A similar architecture with an enhanced sense vocabulary compression was applied in <ref type="bibr" target="#b25">(Vial et al., 2019)</ref>, but instead of GloVe embeddings, BERT wordpiece embeddings <ref type="bibr" target="#b2">(Devlin et al., 2019)</ref> are used as input for training. Especially the BERT embeddings further improved the performance yielding new state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Contextualized Word Embeddings</head><p>The idea of modeling sentence or context-level semantics together with word-level semantics proved to be a powerful innovation. For most downstream NLP tasks, CWEs drastically improved the performance of neural architectures compared to static word embeddings. However, the contextualization methodologies differ widely. We, thus, hypothesize that they are also very different in their ability to capture polysemy.</p><p>Like static word embeddings, CWEs are trained on large amounts of unlabeled data by some vari-ant of language modeling. In our study, we investigate three most prominent and widely applied approaches: Flair <ref type="bibr" target="#b0">(Akbik et al., 2018)</ref>, ELMo (Peters et al., 2018), and BERT <ref type="bibr" target="#b2">(Devlin et al., 2019)</ref>.</p><p>Flair: For the contextualization provided in the Flair NLP framework, <ref type="bibr" target="#b0">Akbik et al. (2018)</ref> take a static pre-trained word embedding vector, e.g. the GloVe word embeddings <ref type="bibr" target="#b16">(Pennington et al., 2014)</ref>, and concatenate two context vectors based on the left and right sentence context of the word to it. Context vectors are computed by two recurrent neural models, one character language model trained from left to right, one another from right to left. Their approach has been applied successfully especially for sequence tagging tasks such as named entity recognition and part-of-speech tagging.</p><p>ELMo: Embeddings from language models (ELMo) <ref type="bibr" target="#b17">(Peters et al., 2018)</ref> approaches contextualization similar to Flair, but instead of two character language models, two stacked recurrent models for words are trained, again one left to right, and another right to left. For CWEs, outputs from the embedding layer, and the two bidirectional recurrent layers are not concatenated, but collapsed into one layer by a weighted, element-wise summation.</p><p>BERT: In contrast to the previous two approaches, Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" target="#b2">(Devlin et al., 2019)</ref> does not rely on the merging of two uni-directional recurrent language models with a (static) word embedding, but provides contextualized token embeddings in an end-to-end language model architecture. For this, a self-attention based transformer architecture is used, which, in combination with a masked language modeling target, allows to train the model seeing all left and right contexts of a target word at the same time. Self-attention and non-directionality of the language modeling task result in extraordinary performance gains compared to previous approaches.</p><p>According to the distributional hypothesis, if the same word regularly occurs in different, distinct contexts, we may assume polysemy of its meaning <ref type="bibr" target="#b10">(Miller and Charles, 1991)</ref>. Contextualized embeddings should be able to capture this property. In the following experiments, we investigate this hypothesis on the example of the introduced models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Nearest Neighbor Classification for WSD</head><p>We employ a rather simple approach to WSD using non-parametric nearest neighbor classification (kNN) to investigate the semantic capabilities of contextualized word embeddings. Compared to parametric classification approaches such as support vector machines or neural models, kNN has the advantage that we can directly investigate the training examples that lead to a certain classifier decision.</p><p>The kNN classification algorithm <ref type="bibr" target="#b1">(Cover and Hart, 1967</ref>) assigns a plurality vote of a sample's nearest labeled neighbors in its vicinity. In the most simple case, one-nearest neighbor, it predicts the label from the nearest training instance by some defined distance metric. Although complex weighting schemes for kNN exist, we stick to the simple non-parametric version of the algorithm to be able to better investigate the semantic properties of different contextualized embedding approaches.</p><p>As distance measure for kNN, we rely on cosine distance of the CWE vectors. Our approach considers only senses for a target word that have been observed during training. We call this approach localized nearest neighbor word sense disambiguation. We use spaCy 1 <ref type="bibr" target="#b6">(Honnibal and Johnson, 2015)</ref> for pre-processing and the lemma of a word as the target word representation, e.g. 'danced', 'dances' and 'dancing' are mapped to the same lemma 'dance'. Since BERT uses wordpieces, i.e. subword units of words instead of entire words or lemmas, we re-tokenize the lemmatized sentence and average all wordpiece CWEs that belong to the target word. Moreover, for the experiments with BERT embeddings 2 , we follow the heuristic by <ref type="bibr" target="#b2">Devlin et al. (2019)</ref> and concatenate the averaged wordpiece vectors of the last four layers. 1 https://spacy.io/ 2 We use the bert-large-uncased model.</p><p>We test different values for our single hyperparameter k ∈ {1, . . . , 10, 50, 100, 500, 1000}. Like words in natural language, word senses follow a power-law distribution. Due to this, simple baseline approaches for WSD like the most frequent sense (MFS) baseline are rather high and hard to beat. Another effect of the skewed distribution are imbalanced training sets. Many senses described in WordNet only have one or two example sentences in the training sets, or are not present at all. This is severely problematic for larger k and the default implementation of kNN because of the majority class dominating the classification result. To deal with sense distribution imbalance, we modify the majority voting of kNN to k = min(k, |V s |) where V s is the set of CWEs with the least frequent training examples for a given word sense s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Datasets</head><p>We conduct our experiments with the help of four standard WSD evaluation sets, two lexical sample tasks and two all-words tasks. As lexical sample tasks, SensEval-2 <ref type="bibr">(Kilgarriff, 2001, SE-2)</ref>   <ref type="bibr" target="#b11">(Miller et al., 1993)</ref>, and b) the Princeton WordNet gloss corpus (WNGT) <ref type="bibr" target="#b4">(Fellbaum, 1998)</ref> separately to investigate the influence of different training sets on our approach. For all experiments, we utilize the suggested datasets as provided by the UFSAC  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>We conduct two experiments to determine whether contextualized word embeddings can solve the WSD task. In our first experiment, we compare different pre-trained embeddings with k = 1. In our second experiment, we test multiple values of k and the BERT pre-trained embeddings 4 in order to estimate an optimal k. Further, we qualitatively examine the results to analyze, which cases can be typically solved by our approach and where it fails.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Contextualized Embeddings</head><p>To compare different CWE approaches, we use k = 1 nearest neighbor classification. <ref type="table" target="#tab_2">Table 2</ref> shows a high variance in performance. Simple kNN with ELMo as well as BERT embeddings beats the state of the art of the lexical sample task SE-2 (cp. Table 3). BERT also outperforms all others on the SE-3 task. However, we observe a major performance drop of our approach for the two all-words WSD tasks in which no training data is provided along with the test set. For S7-T7 and S7-T17, the content and structure of the out-of-domain SemCor and WNGT training datasets differ drastically from those in the test data, which prevents yielding near stateof-the-art results. In fact, similarity of contextualized embeddings largely relies on semantically and structurally similar sentence contexts of polysemic target words. Hence, the more example sentences can be used for a sense, the higher are the chances 3 Unification of Sense Annotated Corpora and Tools. We are using Version 2.1: https://github.com/getalp/ UFSAC 4 BERT performed best in experiment one.  that a nearest neighbor expresses the same sense.</p><p>As can be seen in <ref type="table" target="#tab_0">Table 1</ref>, the SE-2 and SE-3 training datasets provide more CWEs for each word and sense, and our approach performs better with a growing number of CWEs, even with a higher average number of senses per word as is the case in SE-3. Thus, we conclude that the nearest neighbor approach suffers specifically from data sparseness. The chances increase that aspects of similarity other than the sense of the target word in two compared sentence contexts drive the kNN decision. Moreover, CWEs actually do not organize well in spherically shaped form in the embedding space. Although senses might be actually separable, the nonparametric kNN classification is unable to learn a complex decision boundary focusing only on the most informative aspects of the CWE <ref type="bibr">(Yuan et al., 2016, p. 4)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Nearest Neighbors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K-Optimization:</head><p>To attenuate for noise in the training data, we optimize for k to obtain a more robust nearest neighbor classification. <ref type="table" target="#tab_4">Table 3</ref> shows our best results using the BERT embeddings along with results from related works. For SensEval-2 and SensEval-3, we achieve a new state-of-the-art result. We observe convergence with higher k values since our k normalization heuristic is activated. For the S7-T*, we also achieve minor improvements with a higher k, but still drastically lack behind the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Senses in CWE space:</head><p>We investigate how well different CWE models encode information such as distinguishable senses in their vector space. <ref type="figure">Figure 1</ref> shows T-SNE plots (van der Maaten and Hinton, 2008) of six different senses of the word "bank" in the SE-3 training dataset encoded by the three different CWE methods. For visualization purposes, we exclude senses with a frequency of less than two. The Flair embeddings hardly allow to distinguish any clusters as most senses are scattered across the entire plot. In the ELMo embedding space, the major senses are slightly more separated in different regions of the point cloud. Only in the BERT embedding space, some senses form clearly separable clusters. Also within the larger clusters, single senses are spread mostly in separated regions of the cluster. Hence, we conclude that BERT embeddings actually seem to encode some form of sense knowledge, which also explains why kNN can be successfully applied to them. Moreover, we can see why a more powerful parametric classification approach such as employed by <ref type="bibr" target="#b25">Vial et al. (2019)</ref> is able to learn clear decision boundaries. Such clear decision boundaries seem to successfully solve the data sparseness issue of kNN.</p><p>Error analysis: From a qualitative inspection of true positive and false positive predictions, we are able to infer some semantic properties of the BERT embedding space and the used training corpora. <ref type="table" target="#tab_7">Table 4</ref> shows selected examples of polysemic words in different test sets, including their nearest neighbor from the respective training set.</p><p>Not only vocabulary overlap in the context as in 'along the bank of the river' and 'along the bank of the river Greta' (2) allows for correct predictions, but also semantic overlap as in 'little earthy bank' and 'huge bank [of snow]' (3). On the other hand, vocabulary overlap, as well as semantic relatedness as in 'land bank' (5) can lead to false predictions. Another interesting example for the latter is the confusion between 'grass bank' and 'river bank' (6) where the nearest neighbor sentence in the training set shares some military context with the target sentence. The correct sense (bank%1:17:01::Sloping Land) and the predicted sense (bank%1:17:00::A Long Ridge or Pile [of earth]) share high semantic similarity, too. In this example, they might even be used interchangeably. Apparently this context yields higher similarity than any of the other training sentences containing 'grass bank' explicitly.</p><p>In Example (10), the targeted sense is an action, i.e. a verb sense, while the predicted sense is a noun, i.e. a different word class. In general, this could be easily fixed by restricting the classifier decision to the desired POS. However, while example (12) is still a false positive, it nicely shows that the simple kNN approach is able to distinguish senses by word class even though BERT never learned POS classes explicitly. This effect has been investigated in-depth by <ref type="bibr" target="#b7">Jawahar et al. (2019)</ref>, who found that each BERT layer learns different structural aspects of natural language. Example (12) also emphasizes the difficulty of distinguishing verb senses itself, i.e. the correct sense label in this example is watch%2:39:00::look attentively whereas the predicted label and the nearest neighbor is watch%2:41:00::follow with the eyes or the mind; observe. Verb senses in WordNet are very fine grained and thus harder to distinguish automatically and by humans, too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Post-evaluation experiment</head><p>In order to address the issue of mixed POS senses, we run a further experiment, which restricts words to their lemma and their POS tag. <ref type="table" target="#tab_9">Table 5</ref> shows that including the POS restriction increases the F1 scores for S7-T7 and S7-T17. This can be explained by the number of different POS tags that can be found in the different corpora (c.f. <ref type="table">Table 6</ref>). The results are more stable with respect to their relative performance, i.e. SemCor and WNGT reach comparable scores on S7-T17. Also, the results for SE-2 and SE-3 did not change drastically. This can be explained by the average number of POS tags a certain word is labeled with. This variety is much stronger in the S7-T* tasks compared to SE-*.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we tested the semantic properties of contextualized word embeddings (CWEs) to address word sense disambiguation. 5 To test their capabilities to distinguish different senses of a particular word, by placing their contextualized vector They must have been filled in at the bank <ref type="bibr">[A Bank Building]</ref> either by Mr Hatton himself or else by the cashier who was attending to him.</p><p>(2) Soon after setting off we came to a forested valley along the banks [Sloping Land] of the Gwaun.</p><p>In my own garden the twisted hazel, corylus avellana contorta, is underplanted with primroses, bluebells and wood anemones, for that is how I remember them growing, as they still do, along the banks [Sloping Land] of the rive Greta</p><p>(3) In one direction only a little earthy bank <ref type="bibr">[A Long Ridge]</ref> separates me from the edge of the ocean, while in the other the valley goes back for miles and miles.</p><p>The lake has been swept clean of snow by the wind, the sweepings making a huge bank <ref type="bibr">[A Long Ridge]</ref> on our side that we have to negotiate.</p><p>(4) However, it can be possible for the documents to be signed after you have sent a payment by cheque provided that you arrange for us to hold the cheque and not pay it into the bank <ref type="bibr">[A Financial Institution]</ref> until we have received the signed deed of covenant.</p><p>The purpose of these stubs in a paying -in book is for the holder to have a record of the amount of money he had deposited in his bank <ref type="bibr">[A Bank Building]</ref> .</p><p>(5) He continued: assuming current market conditions do not deteriorate further, the group, with conservative borrowings, a prime land bank <ref type="bibr">[A Financial Institution]</ref> and a good forward sales position can look forward to another year of growth.</p><p>Crest Nicholson be the exception, not have much of a land bank <ref type="bibr">[Supply or Stock]</ref> and rely on its skill in land buying.</p><p>(6) The marine said, get down behind that grass bank <ref type="bibr">[A Long Ridge]</ref> , sir, and he immediately lobbed a mills grenade into the river.</p><p>The guns were all along the river bank [Sloping Land] as far as I could see.</p><p>SemCor S7-T17 (7) Some 30 balloon <ref type="bibr">[Large Tough Nonrigid Bag]</ref> shows are held annually in the U.S., including the world's largest convocation of ersatz Phineas Foggs -the nine-day Albuquerque International Balloon Fiesta that attracts some 800, 000 enthusiasts and more than 500 balloons, some of which are fetchingly shaped to resemble Carmen Miranda, Garfield or a 12-story-high condom.</p><p>Homes and factories and schools and a big wide federal highway, instead of peaceful corn to rest your eyes on while you tried to rest your heart, while you tried not to look at the balloon [Large Tough Nonrigid Bag] and the bandstand and the uniforms and the flash of the instruments.      <ref type="table" target="#tab_4">Table 3</ref>.</p><p>representation into different regions of the shared vector space, we used a k-nearest neighbor approach, which allows us to investigate their properties on an example basis. For experimentation, we used pre-trained models from Flair NLP <ref type="bibr" target="#b0">(Akbik et al., 2018)</ref>, ELMo <ref type="bibr" target="#b17">(Peters et al., 2018)</ref>, and BERT <ref type="bibr" target="#b2">(Devlin et al., 2019</ref>). Further, we tested our hypothesis on four standard benchmark datasets for word sense disambiguation. We conclude that WSD can be surprisingly effective using solely CWEs. We are even able to report improvements over state-ofthe-art results for the two lexical sample tasks of SenseEval-2 and SensEval-3.</p><p>Further, experiments showed that CWEs in general are able to capture senses, i.e. words, when used in a different sense, are placed in different regions. This effect appeared strongest using the BERT pre-trained model, where example instances even form clusters. This might give rise to future directions of investigation, e.g. unsupervised word sense-induction using clustering techniques.  <ref type="table">Table 6</ref>: Percentage of senses with a certain POS tag in the corpora.</p><p>Since the publication of the BERT model, a number of extensions based on transformer architectures and language model pre-training have been released. In future work, we plan to evaluate also XLM (Lample and Conneau, 2019), RoBERTa <ref type="bibr" target="#b9">(Liu et al., 2019)</ref> and XLNet (Yang et al., 2019) with our approach. In our qualitative error analysis, we observed many near-misses, i.e. the target sense and the predicted sense are not particularly far away. We will investigate if more powerful classification algorithms for WSD based on contextualized embeddings are able to solve this issue even in cases of extremely sparse training data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and SensEval-3 (Mihalcea et al., 2004, SE-3) provide a training data set and test set each. The all-words tasks of SemEval 2007 Task 7 (Navigli et al., 2007, S7-T7) and Task 17 (Pradhan et al., 2007, S7-T17) solely comprise test data, both with a substantial overlap of their documents. The two sets differ in granularity: While ambiguous terms in Task 17 are annotated with one WordNet sense only, in Task 7 annotations are coarser clusters of highly similar WordNet senses. For training of the allwords tasks, we use a) the SemCor dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>T-SNE plots of different senses of 'bank' and their contextualized embeddings. The legend shows a short description of the respective WordNet sense and the frequency of occurrence in the training data. Here, the SE-3 training dataset is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Properties of our datasets. For the test sets (Te), we do not report k since they are not used as kNN training instances.</figDesc><table><row><cell></cell><cell cols="7">SE-2 (Tr) SE-2 (Te) SE-3 (Tr) SE-3 (Te) S7-T7 (coarse) S7-T17 (fine) SemCor</cell><cell>WNGT</cell></row><row><cell>#sentences</cell><cell>8,611</cell><cell>4,328</cell><cell>7,860</cell><cell>3,944</cell><cell>126</cell><cell>245</cell><cell>37,176</cell><cell>117,659</cell></row><row><cell>#CWEs</cell><cell>8,742</cell><cell>4,385</cell><cell>9,280</cell><cell>4520</cell><cell>455</cell><cell cols="3">6,118 230,558 1,126,459</cell></row><row><cell>#distinct words</cell><cell>313</cell><cell>233</cell><cell>57</cell><cell>57</cell><cell>327</cell><cell>1,177</cell><cell>20,589</cell><cell>147,306</cell></row><row><cell>#senses</cell><cell>783</cell><cell>620</cell><cell>285</cell><cell>260</cell><cell>371</cell><cell>3,054</cell><cell>33,732</cell><cell>206,941</cell></row><row><cell>avg #senses p. word</cell><cell>2.50</cell><cell>2.66</cell><cell>5.00</cell><cell>4.56</cell><cell>1.13</cell><cell>2.59</cell><cell>1.64</cell><cell>1.40</cell></row><row><cell>avg #CWEs p. word &amp; sense</cell><cell>11.16</cell><cell>7.07</cell><cell>32.56</cell><cell>17.38</cell><cell>1.23</cell><cell>2.00</cell><cell>6.83</cell><cell>5.44</cell></row><row><cell>avg k</cell><cell>2.75</cell><cell>-</cell><cell>7.63</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>3.16</cell><cell>2.98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: kNN with k = 1 WSD performance (F1%).</cell></row><row><cell>Best results for each testset are marked bold.</cell></row><row><cell>framework 3 (Vial et al., 2018b), i.e. the respective</cell></row><row><cell>training data. A concise overview of the data can</cell></row><row><cell>be found in Table 1. From this, we can observe</cell></row><row><cell>that the SE-2 and SE-3 training data sets, which</cell></row><row><cell>were published along with the respective test sets,</cell></row><row><cell>provide many more examples per word and sense</cell></row><row><cell>than SemCor or WNGT.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Best kNN models vs. most frequent sense (MFS) and state of the art (F1%). Best results are bold, previous SOTA is in italics and our best results are underlined.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>President Aquino, admitting that the death of Ferdinand Marcos had sparked a wave of sympathy for the late dictator, urged Filipinos to stop weeping for the man who had laughed all the way to the bank[A Bank Building]  .</figDesc><table><row><cell>Example sentence</cell><cell>Nearest neighbor</cell></row><row><cell>SE-3 (train)</cell><cell>SE-3 (test)</cell></row><row><cell>(1)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>In between came lots of coffee drinking while watching[To Look Attentively]  the balloons inflate and lots of standing around deciding who would fly in what balloon and in what order [. . . ].So Captain Jenks returned to his harbor post to watch [To Follow With the Eyes or the Mind; observe] the scouting plane put in five more appearances, and to feel the certainty of this dread rising within him.</figDesc><table><row><cell>(8) The condom balloon [Large Tough Nonrigid Bag] was denied</cell><cell>Just like the balloon [Large Tough Nonrigid Bag] would go</cell></row><row><cell>official entry status this year.</cell><cell>up and you could sit all day and wish it would spring a</cell></row><row><cell></cell><cell>leak or blow to hell up and burn and nothing like that</cell></row><row><cell></cell><cell>would happen.</cell></row><row><cell>(9) Starting with congressman Mario Biaggi (now serving a</cell><cell>When authorities convicted him of practicing medicine</cell></row><row><cell>jail sentence [The Period of Time a Prisoner Is Imprisoned] ), the</cell><cell>without a license (he got off with a suspended</cell></row><row><cell>company began a career of bribing federal, state and</cell><cell>sentence [The Period of Time a Prisoner Is Imprisoned] of three</cell></row><row><cell>local public officials and those close to public officials,</cell><cell>years because of his advanced age of 77), one of his vic-</cell></row><row><cell>right up to and including E. Robert Wallach, close friend</cell><cell>tims was not around to testify: he was dead of cancer."</cell></row><row><cell>and adviser to former attorney general Ed Meese.</cell><cell></cell></row><row><cell>(10) Americans it seems have followed Mal-</cell><cell>Just like the balloon [Large Tough Nonrigid Bag] would go</cell></row><row><cell>colm Forbes's hot-air lead and taken to bal-</cell><cell>up and you could sit all day and wish it would spring a</cell></row><row><cell>loon [To Ride in a Hot-Air Balloon] in a heady way.</cell><cell>leak or blow to hell up and burn and nothing like that</cell></row><row><cell></cell><cell>would happen.</cell></row><row><cell>(11) Any question as to why an author would believe this</cell><cell>But the book [A Written Version of a Play] is written around</cell></row><row><cell>plaintive, high-minded note of assurance is necessary</cell><cell>a somewhat dizzy cartoonist, and it has to be that way.</cell></row><row><cell>is answered by reading this book [A Published Written Work]</cell><cell></cell></row><row><cell>about sticky fingers and sweaty scammers.</cell><cell></cell></row><row><cell>(12)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Example predictions based on nearest neighbor sentences. The word in question is marked in boldface, subset with a short description of its WordNet synset (true positives green, false positives red).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Best POS-sensitive kNN models. Bold numbers are improved results over</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The source code of our experiments is publicly available at: https://github.com/uhh-lt/bert-sense</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was funded by BWFG Hamburg in the Forum 4.0 project, by DFG in the JOIN-T 2 project and by DAAD in form of a WISE stipend.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">From word to sense embeddings: A survey on vector representations of meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Akbik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics (AIS-TATS)</title>
		<editor>Camacho-Collados and Pilehvar2018] Jose Camacho-Collados and Mohammad Taher Pilehvar</editor>
		<meeting>the International Conference on Artificial Intelligence and Statistics (AIS-TATS)<address><addrLine>Santa Fe, NM, USA; Cadiz, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="743" to="788" />
		</imprint>
	</monogr>
	<note>Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin, and Dmitry Vetrov</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nearest neighbor pattern classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SENSEVAL-2: Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Edmonds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cotton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems</title>
		<meeting>SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An improved non-monotonic transition system for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1373" to="1378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What does BERT learn about the structure of language?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex -V)</title>
		<meeting>the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex -V)<address><addrLine>Florence, Italy; Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="51" to="56" />
		</imprint>
	</monogr>
	<note>57th Annual Meeting of the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">English lexical sample task description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems</title>
		<meeting>SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
	<note>Lample and Conneau2019] Guillaume Lample and Alexis Conneau. 2019. Cross-lingual language model pretraining. CoRR, abs/1901.07291</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SENSEVAL-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text</title>
		<editor>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean</editor>
		<meeting>SENSEVAL-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text<address><addrLine>Berlin, Germany; Barcelona, Spain; Scottsdale, AZ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
	<note>1st International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Contextual correlates of semantic similarity. Language and cognitive processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><forename type="middle">G</forename><surname>Charles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A semantic concordance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human Language Technology, HLT &apos;93</title>
		<meeting>the Workshop on Human Language Technology, HLT &apos;93<address><addrLine>Princeton, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semeval-2007 task 07: Coarse-grained english all-words task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval &apos;07</title>
		<meeting>the 4th International Workshop on Semantic Evaluations, SemEval &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient non-parametric estimation of multiple embeddings per word in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neelakantan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting><address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1059" to="1069" />
		</imprint>
	</monogr>
	<note>Alexandre Passos, and Andrew McCallum</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised, knowledge-free, and interpretable word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fide</forename><surname>Marten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Ruppert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ustalov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<editor>Michel Pêcheux, Tony Hak, and Niels Helsloot</editor>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Copenhagen, Denmark; Rodopi, Amsterdam and Atlanta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="91" to="96" />
		</imprint>
	</monogr>
	<note>Automatic discourse analysis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Making sense of word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Pelevina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Representation Learning for NLP</title>
		<meeting>the 1st Workshop on Representation Learning for NLP<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="174" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting><address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pradhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Word sense disambiguation: A unified evaluation framework and empirical comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<editor>Remus and Biemann2018] Steffen Remus and Chris Biemann</editor>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Prague, Czech Republic; Valencia, Spain; Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="99" to="110" />
		</imprint>
	</monogr>
	<note>Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Autoextend: Extending word embeddings to embeddings for synsets and lexemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1793" to="1803" />
		</imprint>
	</monogr>
	<note>Rothe and Schütze2015</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Grundfragen der allgemeinen Sprachwissenschaft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdinand</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saussure</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>de Gruyter</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>3 edition</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semi-supervised word sense disambiguation using word embeddings in general and specific domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer ; Laurens Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Barcelona, Spain; Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
		</imprint>
	</monogr>
	<note>Visualizing data using t-SNE</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Improving the coverage and the generalization ability of neural word sense disambiguation through hypernymy and hyponymy relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vial</surname></persName>
		</author>
		<idno>abs/1811.00960</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">UFSAC: Unification of Sense Annotated Corpora and Tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vial</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Sense vocabulary compression through the semantic knowledge of wordnet for neural word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vial</surname></persName>
		</author>
		<idno>abs/1905.05677</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Loïc Vial, Benjamin Lecouteux, and Didier Schwab</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<title level="m">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised word sense disambiguation with neural models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1374" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SemEval-2019 task 6: Identifying and categorizing offensive language in social media (OffensEval)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
