<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Training Deep Networks without Learning Rates Through Coin Betting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-11-07">November 7, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Orabona</surname></persName>
							<email>francesco@orabona.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
							<email>tommasi@dis.uniroma1.it</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer, Control, and Management Engineering Antonio Ruberti</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Training Deep Networks without Learning Rates Through Coin Betting</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-11-07">November 7, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this paper, we propose a new stochastic gradient descent procedure for deep networks that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a coin and propose a learning-rate-free optimal algorithm for this scenario. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms. * The authors contributed equally.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the last years deep learning has demonstrated a great success in a large number of fields and has attracted the attention of various research communities with the consequent development of multiple coding frameworks (e.g., Caffe <ref type="bibr" target="#b10">[Jia et al., 2014]</ref>, TensorFlow <ref type="bibr" target="#b0">[Abadi et al., 2015]</ref>), the diffusion of blogs, online tutorials, books, and dedicated courses. Besides reaching out scientists with different backgrounds, the need of all these supportive tools originates also from the nature of deep learning: it is a methodology that involves many structural details as well as several hyperparameters whose importance has been growing with the recent trend of designing deeper and multi-branches networks. Some of the hyperparameters define the model itself (e.g., number of hidden layers, regularization coefficients, kernel size for convolutional layers), while others are related to the model training procedure. In both cases, hyperparameter tuning is a critical step to realize deep learning full potential and most of the knowledge in this area comes from living practice, years of experimentation, and, to some extent, mathematical justification <ref type="bibr" target="#b3">[Bengio, 2012]</ref>.</p><p>With respect to the optimization process, stochastic gradient descent (SGD) has proved itself to be a key component of the deep learning success, but its effectiveness strictly depends on the choice of the initial learning rate and learning rate schedule. This has primed a line of research on algorithms to reduce the hyperparameter dependence in SGD-see Section 2 for an overview on the related literature. However, all previous algorithms resort on adapting the learning rates, rather than removing them, or rely on assumptions on the shape of the objective function.</p><p>In this paper we aim at removing at least one of the hyperparameter of deep learning models. We leverage over recent advancements in the stochastic optimization literature to design a backpropagation procedure that does not have a learning rate at all, yet it is as simple as the vanilla SGD. Specifically, we reduce the SGD problem to the game of betting on a coin (Section 4). In Section 5, we present a novel strategy to bet on a coin that extends previous ones in a data-dependent way, proving optimal convergence rate in the convex and quasi-convex setting (defined in Section 3). Furthermore, we propose a variant of our algorithm for deep networks (Section 6). Finally, we show how our algorithm outperforms popular optimization methods in the deep learning literature on a variety of architectures and benchmarks (Section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Stochastic gradient descent offers several challenges in terms of convergence speed. Hence, the topic of learning rate setting has been largely investigated.</p><p>Some of the existing solutions are based on the use of carefully tuned momentum terms <ref type="bibr" target="#b16">[LeCun et al., 1998b</ref><ref type="bibr" target="#b30">, Sutskever et al., 2013</ref><ref type="bibr" target="#b12">, Kingma and Ba, 2015</ref>. It has been demonstrated that these terms can speed-up the convergence for convex smooth functions <ref type="bibr" target="#b19">[Nesterov, 1983]</ref>. Other strategies propose scale-invariant learning rate updates to deal with gradients whose magnitude changes in each layer of the network <ref type="bibr" target="#b6">[Duchi et al., 2011</ref><ref type="bibr" target="#b31">, Tieleman and Hinton, 2012</ref><ref type="bibr" target="#b34">, Zeiler, 2012</ref><ref type="bibr" target="#b12">, Kingma and Ba, 2015</ref>. Indeed, scale-invariance is a well-known important feature that has also received attention outside of the deep learning community <ref type="bibr" target="#b26">[Ross et al., 2013</ref><ref type="bibr" target="#b23">, Orabona and Pal, 2015</ref>]. Yet, both these approaches do not avoid the use of a learning rate.</p><p>A large family of algorithms exploit a second order approximation of the cost function to better capture its local geometry and avoid the manual choice of a learning rate. The step size is automatically adapted to the cost function with larger/shorter steps in case of shallow/steep curvature. Quasi-Newton methods <ref type="bibr" target="#b32">[Wright and Nocedal, 1999]</ref> as well as the natural gradient method <ref type="bibr" target="#b1">[Amari, 1998]</ref> belong to this family. Although effective in general, they have a spatial and computational complexity that is square in the number of parameters with respect to the first order methods, which makes the application of these approaches unfeasible in modern deep learning architectures. Hence, typically the required matrices are approximated with diagonal ones <ref type="bibr" target="#b16">[LeCun et al., 1998b</ref><ref type="bibr" target="#b27">, Schaul et al., 2013</ref>. Nevertheless, even assuming the use of the full information, it is currently unclear if the objective functions in deep learning have enough curvature to guarantee any gain.</p><p>There exists a line of work on unconstrained stochastic gradient descent without learning rates <ref type="bibr" target="#b29">[Streeter and McMahan, 2012</ref><ref type="bibr" target="#b21">, Orabona, 2013</ref><ref type="bibr" target="#b18">, McMahan and Orabona, 2014</ref><ref type="bibr" target="#b22">, Orabona, 2014</ref><ref type="bibr" target="#b5">, Cutkosky and Boahen, 2016</ref><ref type="bibr" target="#b4">, 2017</ref>. The latest advancement in this direction is the strategy of reducing stochastic subgradient descent to coin-betting, proposed by <ref type="bibr" target="#b24">Orabona and Pal [2016]</ref>. However, their proposed betting strategy is worst-case with respect to the gradients received and cannot take advantage, for example, of sparse gradients.</p><formula xml:id="formula_0">B ⊆ R d with respect to the global minimum v * if there is a positive constant τ &gt; 0 such that for all v ∈ B, f (v) − f (v * ) ≤ τ (v − v * ) ∇f (v)</formula><p>. From the definition, it follows that differentiable convex function are also 1-weakly-quasi-convex.</p><p>Betting on a coin. We will reduce the stochastic subgradient descent procedure to betting on a number of coins. Hence, here we introduce the betting scenario and its notation. We consider a gambler making repeated bets on the outcomes of adversarial coin flips. The gambler starts with initial money &gt; 0. In each round t, he bets on the outcome of a coin flip g t ∈ {−1, 1}, where +1 denotes heads and −1 denotes tails. We do not make any assumption on how g t is generated.</p><p>The gambler can bet any amount on either heads or tails. However, he is not allowed to borrow any additional money. If he loses, he loses the betted amount; if he wins, he gets the betted amount back and, in addition to that, he gets the same amount as a reward. We encode the gambler's bet in round t by a single number w t . The sign of w t encodes whether he is betting on heads or tails. The absolute value encodes the betted amount. We define Wealth t as the gambler's wealth at the end of round t and Reward t as the gambler's net reward (the difference of wealth and the initial money), that is</p><formula xml:id="formula_1">Wealth t = + t i=1 w i g i and Reward t = Wealth t − = t i=1 w i g i .<label>(1)</label></formula><p>In the following, we will also refer to a bet with β t , where β t is such that</p><formula xml:id="formula_2">w t = β t Wealth t−1 .<label>(2)</label></formula><p>The absolute value of β t is the fraction of the current wealth to bet and its sign encodes whether he is betting on heads or tails. The constraint that the gambler cannot borrow money implies that β t ∈ [−1, 1]. We also slighlty generalize the problem by allowing the outcome of the coin flip g t to be any real number in [−1, 1], that is a continuous coin; wealth and reward in (1) remain the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Subgradient Descent through Coin Betting</head><p>In this section, following <ref type="bibr" target="#b24">Orabona and Pal [2016]</ref>, we briefly explain how to reduce subgradient descent to the gambling scenario of betting on a coin. Consider as an example the function F (x) := |x − 10| and the optimization problem min x F (x). This function does not have any curvature, in fact it is not even differentiable, thus no second order optimization algorithm could reliably be used on it. We set the outcome of the coin flip g t to be equal to the negative subgradient of F in w t , that is g t ∈ ∂[−F (w t )], where we remind that w t is the amount of money we bet. Given our choice of F (x), its negative subgradients are in {−1, 1}. In the first iteration we do not bet, hence w 1 = 0 and our initial money is $1. Let's also assume that there exists a function H(·) such that our betting strategy will guarantee that the wealth after T rounds will be at least H( T t=1 g t ) for any arbitrary sequence g 1 , · · · , g T .</p><p>We claim that the average of the bets, 1 T T t=1 w t , converges to the solution of our optimization problem and the rate depends on how good our betting strategy is. Let's see how.</p><p>Denoting by x * the minimizer of F (x), we have that the following holds</p><formula xml:id="formula_3">F 1 T T t=1 w t − F (x * ) ≤ 1 T T t=1 F (w t ) − F (x * ) ≤ 1 T T t=1 g t x * − 1 T T t=1 g t w t ≤ 1 T + 1 T T t=1 g t x * − H T t=1 g t ≤ 1 T + 1 T max v vx * − H(v) = H * (x * )+1 T , Algorithm 1 COntinuous COin Betting -COCOB 1: Input: L i &gt; 0, i = 1, · · · , d; w 1 ∈ R d (initial parameters); T (maximum number of iterations); F (function to minimize) 2: Initialize: G 0,i ← L i , Reward 0,i ← 0, θ 0,i ← 0, i = 1, · · · , d 3: for t = 1, 2, . . . , T do 4: Get a (negative) stochastic subgradient g t such that E[g t ] ∈ ∂[−F (w t )] 5: for i = 1, 2, . . . , d do 6:</formula><p>Update the sum of the absolute values of the subgradients:</p><formula xml:id="formula_4">G t,i ← G t−1,i + |g t,i | 7: Update the reward: Reward t,i ← Reward t−1,i +(w t,i − w 1,i )g t,i 8:</formula><p>Update the sum of the gradients: θ t,i ← θ t−1,i + g t,i 9:</p><p>Calculate the fraction to bet:</p><formula xml:id="formula_5">β t,i = 1 Li 2σ 2θt,i Gt,i+Li − 1 , where σ(x) = 1 1+exp(−x)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Calculate the parameters:</p><formula xml:id="formula_6">w t+1,i ← w 1,i + β t,i (L i + Reward t,i ) 11:</formula><p>end for 12: end for 13: Returnw T = 1 T T t=1 w t or w I where I is chosen uniformly between 1 and T where in the first inequality we used Jensen's inequality, in the second the definition of subgradients, in the third our assumption on H, and in the last equality the definition of Fenchel conjugate of H.</p><p>In words, we used a gambling algorithm to find the minimizer of a non-smooth objective function by accessing its subgradients. All we need is a good gambling strategy. Note that this is just a very simple one-dimensional example, but the outlined approach works in any dimension and for any convex objective function, even if we just have access to stochastic subgradients <ref type="bibr" target="#b24">[Orabona and Pal, 2016]</ref>. In particular, if the gradients are bounded in a range, the same reduction works using a continuous coin. <ref type="bibr" target="#b24">Orabona and Pal [2016]</ref> showed that the simple betting strategy of</p><formula xml:id="formula_7">β t = t−1 i=1 gi t</formula><p>gives optimal growth rate of the wealth and optimal worst-case convergence rates. However, it is not data-dependent so it does not adapt to the sparsity of the gradients. In the next section, we will show an actual betting strategy that guarantees optimal convergence rate and adaptivity to the gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The COCOB Algorithm</head><p>We now introduce our novel algorithm for stochastic subgradient descent, COntinuous COin Betting (COCOB), summarized in Algorithm 1. COCOB generalizes the reasoning outlined in the previous section to the optimization of a function F : R d → R with bounded subgradients, reducing the optimization to betting on d coins.</p><p>Similarly to the construction in the previous section, the outcomes of the coins are linked to the stochastic gradients. In particular, each g t,i ∈ [−L i , L i ] for i = 1, · · · , d is equal to the coordinate i of the negative stochastic gradient g t of F in w t . With the notation of the algorithm, COCOB is based on the strategy to bet a signed fraction of the current wealth equal to 1 Li 2σ</p><formula xml:id="formula_8">2θt,i Gt,i+Li − 1 , where σ(x) = 1 1+exp</formula><p>(−x) (lines 9 and 10). Intuitively, if θt,i Gt,i+Li is big in absolute value, it means that we received a sequence of equal outcomes, i.e., gradients, hence we should increase our bets, i.e., the absolute value of w t,i . Note that this strategy assures that |w t,i g t,i | &lt; Wealth t−1,i , so the wealth of the gambler is always positive. Also, it is easy to verify that the algorithm is scale-free because multiplying all the subgradients and L i by any positive constant it would result in the same sequence of iterates w t,i .</p><p>Note that the update in line 10 is carefully defined: The algorithm does not use the previous w t,i in the update. Indeed, this algorithm belongs to the family of the Dual Averaging algorithms, where the iterate is a function of the average of the past gradients <ref type="bibr" target="#b20">[Nesterov, 2009]</ref>.</p><p>Denoting by w * a minimizer of F , COCOB satisfies the following convergence guarantee. Theorem 1. Let F : R d → R be a τ -weakly-quasi-convex function and assume that g t satisfy |g t,i | ≤ L i . Then, running COCOB for T iterations guarantees, with the notation in Algorithm 1,</p><formula xml:id="formula_9">E[F (w I )] − F (w * ) ≤ d i=1 Li+|w * i −w1,i| E Li(G T ,i +Li) ln 1+ (G T ,i +Li) 2 (w * i −w1,i) 2 L 2 i τ T ,</formula><p>where the expectation is with respect to the noise in the subgradients and the choice of I. Moreover, if F is convex, the same guarantee with τ = 1 also holds for w T .</p><p>The proof, in the Appendix, shows through induction that betting a fraction of money equal to β t,i in line 9 on the outcomes g i,t , with an initial money of L i , guarantees that the wealth after T rounds is at</p><formula xml:id="formula_10">least L i exp θ 2 T ,i 2Li(G T ,i +Li) − 1 2 ln G T ,i Li</formula><p>. Then, as sketched in Section 4, it is enough to calculate the Fenchel conjugate of the wealth and use the standard construction for the per-coordinate updates <ref type="bibr" target="#b28">[Streeter and McMahan, 2010]</ref>. We note in passing that the proof technique is also novel because the one introduced in Orabona and Pal <ref type="bibr">[2016]</ref> does not allow data-dependent bounds.</p><p>When |g t,i | = 1, we have β t,i ≈ t−1 i=1 gi t that recovers the betting strategy in <ref type="bibr" target="#b24">Orabona and Pal [2016]</ref>. In other words, we substitute the time variable with the data-dependent quantity G t,i . In fact, our bound depends on the terms G T,i while the similar one in <ref type="bibr" target="#b24">Orabona and Pal [2016]</ref> simply depends on L i T . Hence, as in AdaGrad <ref type="bibr" target="#b6">[Duchi et al., 2011]</ref>, COCOB's bound is tighter because it takes advantage of sparse gradients.</p><p>COCOB converges at a rate ofÕ( w * 1 √ T ) without any learning rate to tune. This has to be compared to the bound of AdaGrad that is</p><formula xml:id="formula_11">1 O( 1 √ T d i=1 ( (w * ) 2 ηi + η i ))</formula><p>, where η i are the initial learning rates for each coordinate. Usually all the η i are set to the same value, but from the bound we see that the optimal setting would require a different value for each of them. This effectively means that the optimal η i for AdaGrad are problem-dependent and typically unknown. Using the optimal η i would give us a convergence rate of O( w * 1 √ T ), that is exactly equal to our bound up to polylogarithmic terms. Indeed, the logarithmic term in the square root of our bound is the price to pay to be adaptive to any w * and not tuning hyperparameters. This logarithmic term is unavoidable for any algorithm that wants to be adaptive to w * , hence our bound is optimal <ref type="bibr">McMahan, 2012, Orabona, 2013]</ref>.</p><p>To gain a better understanding on the differences between COCOB and other subgradient descent algorithms, it is helpful to compare their behaviour on the simple one-dimensional function F (x) = |x − 10| already used in Section 4. In <ref type="figure" target="#fig_0">Figure 1 (left)</ref>, COCOB starts from 0 and over time it increases in an exponential way the iterate w t , until it meets a gradient of opposing sign. From the gambling perspective this is obvious: The wealth will increase exponentially because there is a sequence of identical outcomes, that in turn gives an increasing wealth and a sequence of increasing bets.</p><p>Algorithm 2 COCOB-Backprop 1: Input: α &gt; 0 (default value = 100); w 1 ∈ R d (initial parameters); T (maximum number of iterations); F (function to minimize) 2: Initialize: L 0,i ← 0, G 0,i ← 0, Reward 0,i ← 0, θ 0,i ← 0, i = 1, · · · , number of parameters 3: for t = 1, 2, . . . , T do 4:</p><formula xml:id="formula_12">Get a (negative) stochastic subgradient g t such that E[g t ] ∈ ∂[−F (w t )] 5:</formula><p>for each i-th parameter in the network do 6:</p><p>Update the maximum observed scale:</p><formula xml:id="formula_13">L t,i ← max(L t−1,i , |g t,i |) 7:</formula><p>Update the sum of the absolute values of the subgradients:</p><formula xml:id="formula_14">G t,i ← G t−1,i + |g t,i | 8: Update the reward: Reward t,i ← max(Reward t−1,i +(w t,i − w 1,i )g t,i , 0) 9:</formula><p>Update the sum of the gradients: θ t,i ← θ t−1,i + g t,i 10:</p><p>Calculate the parameters: w t,i ← w 1,i + θt,i Lt,i max(Gt,i+Lt,i,αLt,i) (L t,i + Reward t,i ) 11: end for 12: end for 13: Return w T On the other hand, in <ref type="figure" target="#fig_0">Figure 1</ref> (center), gradient descent shows a different behaviour depending on its learning rate. If the learning rate is constant and too small (black line) it will take a huge number of steps to reach the vicinity of the minimum. If the learning rate is constant and too large (red line), it will keep oscillating around the minimum, unless some form of averaging is used <ref type="bibr">[Zhang, 2004]</ref>. If the learning rate decreases as η √ t , as in AdaGrad <ref type="bibr" target="#b6">[Duchi et al., 2011]</ref>, it will slow down over time, but depending of the choice of the initial learning rate η it might take an arbitrary large number of steps to reach the minimum.</p><p>Also, notice that in this case the time to reach the vicinity of the minimum for gradient descent is not influenced in any way by momentum terms or learning rates that adapt to the norm of the past gradients, because the gradients are all the same. Same holds for second order methods: The function in figure lacks of any curvature, so these methods could not be used. Even approaches based on the reduction of the variance in the gradients, e.g. <ref type="bibr" target="#b11">[Johnson and Zhang, 2013]</ref>, do not give any advantage here because the subgradients are deterministic. <ref type="figure" target="#fig_0">Figure 1 (right)</ref> shows the "effective learning" rate of COCOB that isη t := w t t i=1 g 2 i . This is the learning rate we should use in AdaGrad to obtain the same behaviour of COCOB. We see a very interesting effect: The learning rate is not constant nor is monotonically increasing or decreasing. Rather, it is big when we are far from the optimum and small when close to it. However, we would like to stress that this behaviour has not been coded into the algorithm, rather it is a side-effect of having the optimal convergence rate.</p><p>We will show in Section 7 that this theoretical gain is confirmed in the empirical results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Backprop and Coin Betting</head><p>The algorithm described in the previous section is guaranteed to converge at the optimal convergence rate for non-smooth functions and does not require a learning rate. However, it still needs to know the maximum range of the gradients on each coordinate. Note that for the effect of the vanishing gradients, each layer will have a different range of the gradients <ref type="bibr" target="#b8">[Hochreiter, 1991]</ref>. Also, the weights of the network can grow over time, increasing the value of the gradients too. Hence, it would be impossible to know the range of each gradient beforehand and use any strategy based on betting. By following the previous literature, e.g. <ref type="bibr" target="#b12">[Kingma and Ba, 2015]</ref>, we propose a variant of COCOB better suited to optimizing deep networks. We name it COCOB-Backprop and its pseudocode is in Algorithm 2. Although this version lacks the backing of a theoretical guarantee, it is still effective in practice as we will show experimentally in Section 7.</p><p>There are few differences between COCOB and COCOB-Backprop. First, we want to be adaptive to the maximum component-wise range of the gradients. Hence, in line 6 we constantly update the values L t,i for each variable. Next, since L i,t−1 is not assured anymore to be an upper bound on g t,i , we do not have any guarantee that the wealth Reward t,i is non-negative. Thus, we enforce the positivity of the reward in line 8 of Algorithm 2.</p><p>We also modify the fraction to bet in line 10 by removing the sigmoidal function because 2σ(2x) − 1 ≈ x for x ∈ [−1, 1]. This choice simplifies the code and always improves the results in our experiments. Moreover, we change the denominator of the fraction to bet such that it is at least αL t,i . This has the effect of restricting the value of the parameters in the first iterations of the algorithm. To better understand this change, consider that, for example, in AdaGrad and Adam with learning rate η the first update is w 2,i = w 1,i − ηsgn(g 1,i ). Hence, η should have a value smaller than w 1,i in order to not "forget" the initial point too fast. In fact, the initialization is critical to obtain good results and moving too far away from it destroys the generalization ability of deep networks. Here, the first update becomes w 2,i = w 1,i − 1 α sgn(g 1,i ), so 1 α should also be small compared to w 1,i .</p><p>Finally, as in previous algorithms, we do not return the average or a random iterate, but just the last one (line 13 in Algorithm 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Empirical Results and Future Work</head><p>We run experiments on various datasets and architectures, comparing COCOB with some popular stochastic gradient learning algorithms: AdaGrad <ref type="bibr" target="#b6">[Duchi et al., 2011]</ref>, RMSProp <ref type="bibr" target="#b31">[Tieleman and Hinton, 2012]</ref>, Adadelta <ref type="bibr" target="#b34">[Zeiler, 2012]</ref>, and Adam <ref type="bibr" target="#b12">[Kingma and Ba, 2015]</ref>. For all the algorithms, but COCOB, we select their learning rate as the one that gives the best training cost a posteriori using a very fine grid of values 2 . We implemented 3 COCOB (following Algorithm 2) in Tensorflow <ref type="bibr" target="#b0">[Abadi et al., 2015]</ref> and we used the implementations of the other algorithms provided by this deep learning framework. The best value of the learning rate for each algorithm and experiment is reported in the legend.</p><p>We report both the training cost and the test error, but, as in previous work, e.g., <ref type="bibr" target="#b12">[Kingma and Ba, 2015]</ref>, we focus our empirical evaluation on the former. Indeed, given a large enough neural network it is always possible to overfit the training set, obtaining a very low performance on the test set. Hence, test errors do not only depends on the optimization algorithm.</p><p>Digits Recognition. As a first test, we tackle handwritten digits recognition using the MNIST dataset <ref type="bibr">[Le-Cun et al., 1998a]</ref>. It contains 28 × 28 grayscale images with 60k training data, and 10k test samples. We consider two different architectures, a fully connected 2-layers network and a Convolutional Neural Network (CNN). In both cases we study different optimizers on the standard cross-entropy objective function to classify 10 digits. For the first network we reproduce the structure described in the multi-layer experiment of <ref type="bibr" target="#b12">[Kingma and Ba, 2015]</ref>: it has two fully connected hidden layers with 1000 hidden units each and ReLU activations, with mini-batch size of 100. The weights are initialized with a centered truncated normal distribution and standard deviation 0.1, the same small value 0.1 is also used as initialization for the bias. The CNN architecture follows the Tensorflow tutorial 4 : two alternating stages of 5 × 5 convolutional filters and 2 × 2 max pooling are followed by a fully connected layer of 1024 rectified linear units (ReLU). To reduce overfitting, 50% dropout noise is used during training.</p><p>Training cost and test error rate as functions of the number of training epochs are reported in <ref type="figure" target="#fig_1">Figure 2</ref>. With both architectures, the training cost of COCOB decreases at the same rate of the best tuned competitor algorithms. The training performance of COCOB is also reflected in its associated test error which appears better or on par with the other algorithms.</p><p>Object Classification. We use the popular CIFAR-10 dataset <ref type="bibr" target="#b13">[Krizhevsky, 2009]</ref> to classify 32 × 32 RGB images across 10 object categories. The dataset has 60k images in total, split into a training/test set of 50k/10k samples. For this task we used the network defined in the Tensorflow CNN tutorial 5 . It starts with two convolutional layers with 64 kernels of dimension 5 × 5 × 3, each followed by a 3 × 3 × 3 max pooling with stride of 2 and by local response normalization as in <ref type="bibr" target="#b14">Krizhevsky et al. [2012]</ref>. Two more fully connected layers respectively of 384 and 192 rectified linear units complete the architecture that ends with a standard softmax cross-entropy classifier. We use a batch size of 128 and the input images are simply pre-processed by whitening. Differently from the Tensorflow tutorial, we do not apply image random distortion for data augmentation.</p><p>The obtained results are shown in <ref type="figure">Figure 3</ref>. Here, with respect to the training cost, our learning-rate-free COCOB performs on par with the best competitors. For all the algorithms, there is a good correlation between the test performance and the training cost. COCOB and its best competitor AdaDelta show similar classification results that differ on average ∼ 0.008 in error rate.</p><p>Word-level Prediction with RNN. Here we train a Recurrent Neural Network (RNN) on a language modeling task. Specifically, we conduct word-level prediction experiments on the Penn Tree Bank (PTB) dataset <ref type="bibr" target="#b17">[Marcus et al., 1993]</ref> using the 929k training words and its 73k validation words. We adopted the medium LSTM <ref type="bibr" target="#b9">[Hochreiter and Schmidhuber, 1997]</ref> network architecture described in <ref type="bibr" target="#b33">Zaremba et al. [2014]</ref>: it has 2 layers with 650 units per layer and parameters initialized uniformly in [−0.05, 0.05], a dropout of 50% is applied on the non-recurrent connections, and the norm of the gradients (normalized by mini-batch size = 20) is clipped at 5.</p><p>We show the obtained results in terms of average per-word perplexity in <ref type="figure">Figure 4</ref>. In this task COCOB performs as well as Adagrad and Adam with respect to the training cost and much better than the other algorithms. In terms of test performance, COCOB, Adam, and AdaGrad all show an overfit behaviour indicated by the perplexity which slowly grows after having reached its minimum. Adagrad is the least affected by this issue and presents the best results, followed by COCOB which outperforms all the other methods. We stress again that the test performance does not depend only on the optimization algorithm used in training and that early stopping may mitigate the overfitting effect.</p><p>Summary of the Empirical Evaluation and Future Work. Overall, COCOB has a training performance that is on-par or better than state-of-the-art algorithms with perfectly tuned learning rates. The test error appears to depends on other factors too, with equal training errors corresponding to different test errors. We would also like to stress that in these experiments, contrary to some of the previous reported empirical results on similar datasets and networks, the difference between the competitor algorithms is minimal or not existent when they are tuned on a very fine grid of learning rate values. Indeed, the very similar performance of these methods seems to indicate that all the algorithms are inherently doing the same thing, despite their different internal structures and motivations. Future more detailed empirical results will focus on unveiling what is the common structure of these algorithms that give rise to this behavior.</p><p>In the future, we also plan to extend the theory of COCOB beyond τ -weakly-quasi-convex functions, characterizing the non-convexity present in deep networks. Also, it would be interesting to evaluate a possible integration of the betting framework with second-order methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proof of Theorem 1</head><p>First we state some technical lemmas that will be used in the proof of the convergence rate of COCOB.</p><p>Lemma 1. <ref type="bibr" target="#b24">[Orabona and Pal, 2016</ref>, extended version, Lemma 18] Define f (x) = β exp x 2 2α , for α, β &gt; 0. Then</p><formula xml:id="formula_15">f * (y) ≤ |y| α log αy 2 β 2 + 1 − β .</formula><p>Lemma 2. Let a ≥ 2. Then, with the notation of Algorithm 1, for any t we have</p><formula xml:id="formula_16">(1 + β t,i g t,i ) exp   θ 2 t−1,i aL i (G t−1,i + L i ) − t−1 j=1 |g j,i | a(G j−1,i + L i )   ≥ exp   θ 2 t,i aL i (G t,i + L i ) − t j=1 |g j,i | a(G j−1,i + L i )   .</formula><p>Proof. The statement to prove is equivalent to</p><formula xml:id="formula_17">ln(1 + β t g t ) + θ 2 t−1 aL(L + t−1 j=1 |g j |) ≥ (θ t + g t ) 2 aL(L + t j=1 |g j |) − |g t | a(L + t−1 l=1 |g l |)</formula><p>, where for clarity we dropped the index i. Consider the function</p><formula xml:id="formula_18">φ(x) = − log(1 + β t x) + (θ t−1 + x) 2 aL(G t−1 + |x|)</formula><p>.</p><p>We have that φ(x) is piece-wise convex on [−∞, 0] and [0, ∞]. Hence, we have that</p><formula xml:id="formula_19">φ(x) ≤ φ(0) + x L (φ(L) − φ(0)), ∀0 ≤ x ≤ L φ(x) ≤ φ(0) + x L (φ(0) − φ(−L)), ∀ − L ≤ x ≤ 0 .</formula><p>Also, β t is such that φ(L) = φ(−L). Hence, we have</p><formula xml:id="formula_20">φ(x) ≤ φ(0) + |x| L (φ(L) − φ(0)), ∀ − L ≤ x ≤ L, that is θ 2 t−1 aLG t−1 − (θ t−1 + g t ) 2 aL(G t−1 + |g t |) + log(1 + β t g t ) = φ(0) − φ(g t ) ≥ |g t | L (φ(0) − φ(L)) = |g t | L θ 2</formula><p>t−1 aLG t−1 − (θ t−1 + L) 2 aL(G t−1 + L) + log(1 + β t L) , ∀ − L ≤ g t ≤ L .</p><p>Using this relation we have that</p><formula xml:id="formula_21">θ 2 t−1 aLG t−1 − (θ t−1 + g t ) 2 aL(G t−1 + |g t |) + log(1 + β t g t ) ≥ |g t | L θ 2 t−1 aLG t−1 − (θ t−1 + L) 2 aL i (G t−1 + L) + log(1 + Lβ t ) = |g t | L (G t−1 + L)θ 2 t−1 − (θ 2 t−1 + 2Lθ t−1 )G t−1 aLG t−1 (G t−1 + L) + log(1 + Lβ t ) − |g t | a(G t−1 + L) = |g t | L θ 2 t−1 aG t−1 (G t−1 + L) − 2θ t−1 a(G t−1 + L) + log(1 + Lβ t ) − |g t | a(G t−1 + L)</formula><p>.</p><p>We now use the Taylor expansion, to obtain Hence the expression</p><formula xml:id="formula_22">θ 2 t−1 aG t−1 (G t−1 + L) − 2θ t−1 a(G t−1 + L) + log(1 + Lβ t ) ≥ θ 2 t−1 aG t−1 (G t−1 + L i ) − 2θ 2 t−1 a 2 (G t−1 + L) 2 ≥ aL i θ 2 t−1 + aG t−1 θ 2 t−1 − 2G t−1 θ 2 t−1 a 2 G t−1 (G t−1 + L) 2</formula><p>is greater than zero if a ≥ 2, that is true by definition of a.</p><p>We can now prove Theorem 1.</p><p>by fact that the gradient are unbiased, the definition of w I , and the definition of τ -weakly-quasi-convexity. Hence, the two cases are the same up to the factor τ . We can then proceed in both cases with</p><formula xml:id="formula_23">T t=1 E[(w * − w t ) g t ] = d i=1 T t=1 E[w * i g t,i − g t,i w t,i ] = d i=1 E[L i + w * i θ T,i − Wealth T,i ] .<label>(4)</label></formula><p>Using the definition of Fenchel's conjugate, (4) and the lower bound on the wealth in (3), we have</p><formula xml:id="formula_24">T t=1 E[(w * − w t ) g t ] = E d i=1 (L i + w * i θ T,i − Wealth T,i ) ≤ E d i=1 (L i + w * i θ T,i − H T,i (θ T,i )) ≤ E d i=1 L i + max x (w * i x − H T,i (x)) = E d i=1 L i + H * T,i (w * i ) .</formula><p>Also, the concavity of the logarithm implies that a−b a ≤ ln a − ln b for all a ≥ b &gt; 0. Hence</p><formula xml:id="formula_25">T j=1 |g j | L i + G j−1,i ≤ T j=1 |g j | G j,i ≤ T j=1 (ln G j,i − ln G j−1,i ) = ln G T,i G 0,i = ln G T,i L i .<label>(5)</label></formula><p>Using Lemma 1, the inequality in (5), and overapproximating, we have</p><formula xml:id="formula_26">H * T,i (w * i ) ≤ |w * i | L i (G T,i + L i ) ln 1 + (G T ,i +Li) 2 (w * i ) 2 L 2 i .</formula><p>Putting all together, using Jensen's inequality to bring the expectation under the square root, and dividing by T give us the stated bound, with w 1 = 0. Now, running the algorithm on the functionF (w) = F (w t + w 1 ), for an arbitrary w 1 , would result in the update in Algorithm 1 and would guarantee the same upper bound on E[F (w T )] −F (w * ) that implies the stated bound.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Behaviour of COCOB (left) and gradient descent with various learning rates and same number of steps (center) in minimizing the function y = |x − 10|. (right) The effective learning rates of COCOB. Figures best viewed in colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Training cost (cross-entropy) (left) and testing error rate (0/1 loss) (right) vs. the number epochs with two different architectures on MNIST, as indicated in the figure titles. The y-axis is logarithmic in the left plots. Figures best viewed in colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Training cost (cross-entropy) (left) and testing error rate (0/1 loss) (right) vs. the number epochs on CIFAR-10. The y-axis is logarithmic in the left plots. Figures best viewed in colors. Training cost (left) and test cost (right) measured as average per-word perplexity vs. the number epochs on PTB word-level language modeling task. Figures best viewed in colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>the expression of β t , have log (1 + Lβ t ) = log G t−1 + L) 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>T. Zhang. Solving large scale linear prediction problems using stochastic gradient descent algorithms. In International Conference on Machine Learning (ICML), pages919-926, 2004.    </figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The AdaGrad variant used in deep learning does not have a convergence guarantee, because no projections are used. Hence, we report the oracle bound in the case that projections are used inside the hypercube with dimensions |w * i |.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">[0.00001, 0.000025, 0.00005, 0.000075, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, 0.01, 0.02, 0.05, 0.075, 0.1] 3 https://github.com/bremen79/cocob 4 https://www.tensorflow.org/get_started/mnist/pros</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://www.tensorflow.org/tutorials/deep_cnn</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank the Stony Brook Research Computing and Cyberinfrastructure, and the Institute for Advanced Computational Science at Stony Brook University for access to the high-performance SeaWulf computing system, which was made possible by a $1.4M National Science Foundation grant (#1531492). The authors also thank Akshay Verma for the help with the TensorFlow implementation and Matej Kristan for reporting a bug in the pseudocode in the previous version of the paper. T.T. was supported by the ERC grant 637076 -RoboExNovo. F.O. is partly supported by a Google Research Award.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof of Theorem 1. First, assume that w 1 = 0, then we will show how to remove this assumption.</p><p>|gj | 2(Li+Gj−1,i) . By induction, we first prove that Wealth t,i ≥ H t,i (θ t,i ). For t = 0, it is obvious because Wealth 0,i = L i . We now assume that Wealth t−1 ≥ H t−1,i (θ t−1,i ). Note that |β t,i g t,i | &lt; 1. Hence, using Lemma 2, we have</p><p>that proves the induction. Now, in the convex case, using the fact that the stochastic subgradient are unbiased, the definition of the subgradients, and Jensen's inequality, we have</p><p>While, in the the τ -weakly-quasi-convex case, we have</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="http://tensorflow.org/.Softwareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Natural gradient works efficiently in learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="276" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Convex Analysis and Monotone Operator Theory in Hilbert Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bauschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Practical recommendations for gradient-based training of deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade: Second Edition</title>
		<editor>G. Montavon, G. B. Orr, and K.-R. Müller</editor>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="437" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Online learning without prior information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutkosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Boahen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="643" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Online convex optimization with unconstrained domains and losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutkosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Boahen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="748" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Gradient descent learns linear dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05191</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Untersuchungen zu dynamischen neuronalen Netzen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
		<respStmt>
			<orgName>Institut für Informatik, Lehrstuhl Prof. Brauer, Technische Universität München</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Diploma thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caffe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accelerating stochastic gradient descent using predictive variance reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient backprop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: Tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="9" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unconstrained online linear learning in Hilbert spaces: Minimax algorithms and normal approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1020" to="1039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A method for unconstrained convex minimization problem with the rate of convergence O(1/k 2 )</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Mathematics Doklady</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="372" to="376" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Primal-dual subgradient methods for convex problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical programming</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="221" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dimension-free exponentiated gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1806" to="1814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simultaneous model selection and optimization through parameter-free stochastic learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1116" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scale-free algorithms for online linear optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Algorithmic Learning Theory (ALT)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="287" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Coin betting and parameter-free online learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="577" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A generalized online mirror descent with applications to classification and regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="411" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Normalized online learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mineiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">No more pesky learning rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1002.4862</idno>
		<title level="m">Less regret via online conditioning</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">No-regret algorithms for unconstrained online convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2402" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COURSERA: Neural Networks for Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Numerical optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.2329</idno>
		<title level="m">Recurrent neural network regularization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
