<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FarsTail: A Persian Natural Language Inference Dataset</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-09-18">18 Sep 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Amirkhani</surname></persName>
							<email>amirkhani@qom.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Azari</forename><surname>Jafari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azadeh</forename><surname>Amirak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zohreh</forename><surname>Pourjafari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><forename type="middle">Faridan</forename><surname>Jahromi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeinab</forename><surname>Kouhkan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FarsTail: A Persian Natural Language Inference Dataset</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-09-18">18 Sep 2020</date>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Elsevier September 21, 2020</note>
					<note>(Hossein Amirkhani)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural language processing</term>
					<term>Natural language inference</term>
					<term>Persian language</term>
					<term>Farsi dataset</term>
					<term>Deep learning</term>
					<term>Benchmark * Equal contribution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural language inference (NLI) is known as one of the central tasks in natural language processing (NLP) which encapsulates many fundamental aspects of language understanding. With the considerable achievements of data-hungry deep learning methods in NLP tasks, a great amount of effort has been devoted to develop more diverse datasets for different languages. In this paper, we present a new dataset for the NLI task in the Persian language, also known as Farsi, which is one of the dominant languages in the Middle East. This dataset, named FarsTail, includes 10,367 samples which are provided in both the Persian language as well as the indexed format to be useful for non-Persian researchers. The samples are generated from 3,539 multiple-choice questions with the least amount of annotator interventions in a way similar to the SciTail dataset. A carefully designed multi-step process is adopted to ensure the quality of the dataset. We also present the results of traditional and state-of-the-art methods on FarsTail including different embedding methods such as word2vec, fastText, ELMo, BERT, and LASER, as well as different modeling approaches such as DecompAtt, ESIM, HBMP, ULMFiT, and cross-lingual transfer approach to provide a solid baseline for the future research. The best obtained test accuracy is 78.13% which shows that there is a big room for improving the current methods to be useful for real-world NLP applications in different languages. The dataset is available at https://github.com/dml-qom/FarsTail.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Natural Language Processing (NLP) deals with the development of automatic methods for processing, analyzing, and generating human languages. It consists of a vast number of problems, ranging from low-level to high-level tasks such as named entity recognition <ref type="bibr" target="#b0">[1]</ref>, sentiment analysis <ref type="bibr" target="#b1">[2]</ref>, machine translation <ref type="bibr" target="#b2">[3]</ref>, and machine reading comprehension <ref type="bibr" target="#b3">[4]</ref>. One important task in NLP is Natural Language Inference (NLI) which is believed to be a stringent test for language understanding, since a system with the ability to identify the implications of natural language sentences should have a good level of language understanding <ref type="bibr" target="#b4">[5]</ref>.</p><p>The goal of NLI is to determine the inference relationship between a premise p and a hypothesis h. It is a three-class problem, where each pair (p, h) is assigned to one of these classes: entailment if the hypothesis can be inferred from the premise, contradiction if the hypothesis contradicts with the premise, and neutral if none of the other conditions hold. To determine the hypothesis status, some prior knowledge is considered besides the premise. This includes the knowledge that typical speakers of that language know, such as the commonsense facts and general semantic knowledge. For example, the typical English speakers know that USA refers to the United States of America.</p><p>After substantial success of deep learning (DL) based methods in different artificial intelligence tasks, the NLP researchers also started to develop DL-based models to learn the patterns in available natural language data generated by humans <ref type="bibr" target="#b5">[6]</ref>. The percentage of deep learning papers nearly doubled in a six-year period from 2012 in the major NLP conferences <ref type="bibr" target="#b6">[7]</ref>. Since these methods need a large amount of training data to let the model learn the general pattern for the particular task without overfitting to the available data, different research groups started to gather and publish large datasets. For the NLI task, the development of Stanford NLI dataset (SNLI) caused a considerable progress in developing DL-based models for NLI task <ref type="bibr" target="#b7">[8]</ref>.</p><p>In DL-based NLI literature, there has been a considerable amount of researches on languages with a large amount of training data, such as English, but little attention has been paid to data-poor languages. Despite some efforts in developing NLI datasets for other languages by translation or transferring knowledge obtained from learning on one language to other lan- <ref type="table">Table 1</ref>: Some features of Persian language which make its processing different from other languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Example</head><p>Different forms for some words "Caesar" is written as either ‫"اﻣﭙﺮاﺗﻮر"‬ or ‫"اﻣﭙﺮاﻃﻮر"‬ Different words used for some foreign concepts "computer" is written as either ‫"ﮐﺎﻣﭙﯿﻮﺗﺮ"‬ or ‫"راﯾﺎﻧﻪ"‬ Adding a space may change the meaning ‫"ﻣﺎدر"‬ means "mother", while ‫در"‬ ‫"ﻣﺎ‬ means "we are in" Words with the same spelling but different pronunciation and meaning ‫"ﻣﻠﮏ"‬ can be pronounced as "molk" or "malek" which mean "territory" and "king", respectively Words arbitrarily disjointed to two words separated with a space "nobody" is written as either ‫"ﻫﯿﭽﮑﺲ"‬ or ‫ﮐﺲ"‬ ‫"ﻫﯿﭻ‬ Words with different plural forms "teachers" can be written as ‫,"ﻣﻌﻠﻤﺎن"‬ " ‫ﻣﻌﻠﻢ‬ ‫ﻫﺎ‬ ", or ‫"ﻣﻌﻠﻤﯿﻦ"‬ Words with different formal and conversational forms "listening" is formally written as ‫,"ﺷﻨﯿﺪن"‬ while it is sometimes written in conversational form as ‫"ﺷﻨﻔﺘﻦ"‬ The critical role of punctuation in the meaning of some sentences ‫ﮐﻨﯿﺪ"‬ ‫اﻋﺪاﻣﺶ‬ ‫ﻧﯿﺴﺖ‬ ‫ﻻزم‬ ‫:"ﺑﺨﺸﺶ،‬ Forgive him, it is not necessary to execute him. ‫ﮐﻨﯿﺪ"‬ ‫اﻋﺪاﻣﺶ‬ ‫ﻧﯿﺴﺖ،‬ ‫ﻻزم‬ ‫:"ﺑﺨﺸﺶ‬ It is not necessary to forgive him, execute him.</p><p>Prior knowledge that typical Persian language speakers know "Before revolution" means "Before 1979 revolution" to Iranians guages <ref type="bibr" target="#b8">[9]</ref>, presenting native datasets for other languages help develop models with more comprehensive language understanding capabilities. In addition, these datasets can be used to evaluate the proposed learning architectures and methods for a broader range of languages.</p><p>The focus of this paper is on Persian (Farsi) language which is a pluricentric language spoken and used by around 110 million people in countries such as Iran, Afghanistan, and Tajikistan. It has had a considerable influence on its neighboring languages such as Turkic, Armenian, Georgian, and Indo-Aryan languages. Its alphabet includes 32 characters written right to left. <ref type="table">Table 1</ref> shows some features of Persian language which make its processing different from other languages.</p><p>In this paper, we present, to the best of our knowledge, the first relatively large-scale Persian corpus for NLI task, called FarsTail. We tried to reduce the amount of annotation interventions to provide realistic samples which are naturally occurring in real-world applications instead of task-specific synthesized examples. A protocol similar to the SciTail dataset is followed <ref type="bibr" target="#b9">[10]</ref> where the sentences are either generated from multiple-choice questions with the least amount of intervention or selected from natural sentences that already exist independently in the wild.</p><p>Each person generates three data examples from a multiple-choice question, one for each class, with the same premises but different hypotheses. The entailment hypothesis is formed by substituting the correct answer in the question. Then, a text snippet is extracted from web that the generated hypothesis can be inferred from. The contradiction hypothesis is formed by substituting one wrong answer in the question. Finally, the neutral hypothesis is extracted from web such that it is similar to the question but with an unknown status based on the premise. In the next phase, each sample is relabeled by four other persons and the samples with at least 4 out of 5 agreements are preserved. The rejected samples undergo a new modification and relabeling phase.</p><p>A total of 10,367 samples are generated from a collection of 3,539 multiplechoice questions. The train, validation, and test portions include 7,266, 1,537, and 1,564 instances, respectively. We ensure that the instances with the same premises are in the same set. The developed dataset can also be used in other tasks such as question answering, summarization, semantic search, and machine translation. The developed dataset (as raw texts for Persian researchers and indexed data for non-Persian researchers) has been released for non-commercial usages.</p><p>We evaluate different traditional and state-of-the-art methods on FarsTail, including different embedding methods such as word2vec <ref type="bibr" target="#b10">[11]</ref>, fastText <ref type="bibr" target="#b11">[12]</ref>, ELMo <ref type="bibr" target="#b12">[13]</ref>, BERT <ref type="bibr" target="#b13">[14]</ref>, and LASER <ref type="bibr" target="#b14">[15]</ref>, as well as different modeling methods such as DecompAtt <ref type="bibr" target="#b15">[16]</ref>, ESIM <ref type="bibr" target="#b16">[17]</ref>, HBMP <ref type="bibr" target="#b17">[18]</ref>, and ULMFiT <ref type="bibr" target="#b18">[19]</ref>. We also investigate the cross-lingual transfer learning approach by translating the train/test datasets <ref type="bibr" target="#b8">[9]</ref>. The best obtained accuracy on test set is 78.13% which shows that there are many rooms to improve the models trained on this dataset.</p><p>The merits of the proposed dataset over existing non-English datasets such as XNLI <ref type="bibr" target="#b8">[9]</ref> are: • In FarsTail, task-specific human-generated texts are kept as low as possible to provide texts which are naturally occurring in real-world applications. To this end, FarsTail is collected by a protocol similar to SciTail dataset <ref type="bibr" target="#b9">[10]</ref>; however, in contrast to SciTail which only contains the neutral and entailment classes, we also include contradiction examples in the dataset.</p><p>• FarsTail is not generated by translating from other languages, so it contains first-hand native examples without translation clues. In addition, it does not suffer from the risk of removing some semantic relations by translation because of cultural differences.</p><p>• Since FarsTail is based on real textual contents, where the sentences are constructed from real questions or selected from web, a model trained on this dataset can be used in other NLP tasks such as question answering and machine translation.</p><p>The rest of this paper is organized as follows. In Section 2, the available English and non-English NLI datasets are reviewed. Section 3 presents the FarsTail development process as well as its statistics. The experimental results are presented in Section 4, and the paper concludes in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this section, we review some available English and non-English NLI datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">English NLI datasets</head><p>• SICK <ref type="bibr" target="#b19">[20]</ref>: As one of the first attempts to introduce relatively largescale datasets for NLI task, this dataset was introduced as a task in SemEval-2014. It consists of about 10k English sentence pairs annotated for two different tasks, relatedness in meaning and entailment. The original sentence pairs are randomly selected from 8k ImageFlickr dataset and the SemEval 2012 STS MSR-Video Description dataset. Some rule-based syntactic and lexical transformations are applied to each sentence to obtain sentences with similar, contradictory, and different meanings. Its partly automated construction introduced some spurious patterns into the data <ref type="bibr" target="#b7">[8]</ref>.</p><p>• SNLI <ref type="bibr" target="#b7">[8]</ref>: The Stanford NLI dataset has been developed to alleviate the lack of large-scale annotated data for the NLI problem. It includes 570k labeled instances (550k training, 10k validation, and 10k test examples) gathered using the Amazon Mechanical Turk. An image caption was presented to each turker as the premise and they were asked to generate three sentences as hypothesis, one for each class (entailment, contradiction, and neutral). In the relabeling phase, if at least three out of four new labelers agreed with the main label, this instance was kept in the dataset. This dataset played a considerable role in developing and enhancing deep learning-based NLI systems.</p><p>• MultiNLI <ref type="bibr" target="#b20">[21]</ref>: Compared to SNLI, MultiNLI covers 10 different genres of spoken and written text. With 433k instances, its scale is comparable to SNLI. The test set consists of two parts: matched set which includes the same genres in the training set and mismatched set which includes genres not available in the training set. This allows for cross-genre generalization evaluation.</p><p>• MedNLI <ref type="bibr" target="#b21">[22]</ref>: This dataset was generated by the same approach as SNLI, adjusted for the clinical domain. The MIMIC-III v1.3 <ref type="bibr" target="#b22">[23]</ref>, with de-identified records of 38,597 patients, was used as the premise source. The hypothesis sentences were generated by clinicians. Four clinicians worked on a total of 4,683 premises over a period of six weeks, which resulted in 14,049 unique sentence pairs.</p><p>• SciTail <ref type="bibr" target="#b9">[10]</ref>: This is the first NLI dataset which is collected using the available texts without authoring the sentences. This makes the dataset more realistic, since it consists of natural texts instead of task-specific synthesized sentences. SciTail is the most similar dataset to the dataset presented in this paper. The hypotheses were created from science questions and their corresponding answers, and premises were gathered from the relevant web sentences. It contains 1,834 questions with 10,101 entailment instances and 16,925 neutral ones. This dataset does not contain the contradiction label.</p><p>• QA-NLI <ref type="bibr" target="#b23">[24]</ref>: This dataset is similar to SciTail, except that it was fully automatically constructed. The authors proposed a method to derive NLI datasets from the question answering datasets. This was done by introducing the QA2D task to derive a declarative sentence from a question-answer pair. The generated sentence (D) along with the corresponding passage (P ) forms an NLI example as (P, D). For the correct, incorrect, and unknown answers, the pairs were labeled as entailment, contradiction, and neutral, respectively. Note that incorrect answers are available in QA datasets with multiple answers, and unknowns are also available in some datasets such as SQuAD 2.0 <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Non-English NLI datasets</head><p>• Evalita <ref type="bibr" target="#b25">[26]</ref>: This dataset was constructed to infer the entailment relationship between short Italian sentence pairs. It contains 800 pairs, constructed on the basis of Wikipedia revision histories.</p><p>• ArbTEDS <ref type="bibr" target="#b26">[27]</ref>: This dataset contains 600 Arabic pairs annotated as either inferable or non-inferable. A semi-automatic tool was used to extract the candidate pairs from web, using the Arabic news headlines as the hypothesis and one paragraph returned by the Google-API for this headline as the premise. The pairs were then annotated by eight annotators.</p><p>• German emails <ref type="bibr" target="#b27">[28]</ref>: This dataset was constructed from the customer emails of a multimedia software company to its support center as premises and the categories descriptions as the hypotheses. The matching and non-matching categories were considered as entailment and non-entailment hypotheses, respectively. It contains 638 entailment and 24,143 non-entailment pairs.</p><p>• ASSIN <ref type="bibr" target="#b28">[29]</ref>: This dataset contains 10,000 pairs, half in Brazilian Portuguese and half in European Portuguese. It is a two-class problem with the entailment and not-entailment classes.</p><p>• XNLI <ref type="bibr" target="#b8">[9]</ref>: This dataset was developed for evaluating the cross-lingual understanding capabilities of models. The same crowdsourcing-based procedure used for MultiNLI dataset <ref type="bibr" target="#b20">[21]</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">FarsTail dataset</head><p>In this section, we present the process of developing FarsTail dataset as well as its statistics. FarsTail has been developed with a process similar to the SciTail dataset <ref type="bibr" target="#b9">[10]</ref> with some modifications. A group of five persons (called annotators herein) with a background in NLI worked under the supervision of an NLP expert to develop FarsTail. The taken steps are depicted in <ref type="figure" target="#fig_0">Fig. 1</ref> which include generating NLI instances from multiple-choice questions, relabeling, and data cleaning. The details of these steps are given in Sections 3.1 and 3.2, and the dataset statistics are presented in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Generating NLI instances from questions</head><p>A collection of 3,539 multiple-choice questions was gathered from Iranian university exams in different topics including religion, history, constitution of Iran, history of literature, and Islamic revolution. For each multiple-choice question, an annotator followed the following steps to generate three different pairs, one for each class (entailment, contradiction, and neutral):</p><p>1. The correct answer is inserted into the question to generate a sentence called h 1 . 2. The web is searched to find a text portion p where (p, h 1 ) has entailment relation. We use the available texts on the web instead of generating the premises to provide real-world, naturally occurring texts instead of task-specific synthesized examples.</p><p>Multiple-choice question:  3. An incorrect answer is inserted into the question to generate a sentence called h 2 such that (p, h 2 ) has contradiction relation. The annotator is asked to generate h 2 similar to h 1 in length, but different in structure and words. 4. From the web, a related sentence h 3 is found with a similar length to h 1 and h 2 such that its entailment or contradiction relation cannot be inferred from p. The pair (p, h 3 ) is considered as a neutral instance. <ref type="figure" target="#fig_2">Fig. 2</ref> shows an example of the sample generation process in FarsTail.</p><formula xml:id="formula_0">‫ﺑﻮد؟‬ ‫ﮐﺴﯽ‬ ‫ﭼﻪ‬ ‫ﮔﻮﺗﺮش‬ ‫آﻧﺘﻮﻧﯿﻮ‬ ‫از‬ ‫ﻗﺒﻞ‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫ﮐﻞ‬ ‫دﺑﯿﺮ‬ o ‫ﺳﻮﻻﻧﺎ‬ ‫ﺧﺎوﯾﺮ‬ o ‫ﺻﺤﯿﺢ(‬ ‫)ﺟﻮاب‬ ‫ﻣﻮن‬ ‫ﮐﯽ‬ ‫ﺑﺎن‬ o ‫ﻋﻨﺎن‬ ‫ﮐﻮﻓﯽ‬ o ‫ﯾﻮﺷﯿﺮو‬ ‫ﻣﻮري‬</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Relabeling and data cleaning</head><p>After the sample generation phase, each sample was relabeled by the other four annotators retaining the samples with an agreement of at least 80% among five labelers. The samples were presented to the annotators in a random order to reduce annotation bias caused by presenting the samples with the same premise in succession. To give the rejected samples one more chance, they were revised by their original annotator and relabeled again. The samples which could not obtain a 80% label agreement in any of these two relabeling phases were removed. Among all 10,617 samples (3, 539 × 3), 190 samples were removed in this phase resulting in 10,427 instances.</p><p>The retained samples were investigated one more time for spelling and writing mistakes emphasizing on avoiding probable label change caused by cleaning. Finally, to reduce the unwanted repetition in the data, 60 more samples were removed including the instances generated from different questions which both their premises and hypotheses had a cosine similarity higher than 0.8. The total number of samples in the dataset is therefore 10,367.</p><p>The instances were randomly divided into training, validation, and test sets such that the samples generated from the same question were in the same subset. In addition, to avoid information leak, the samples generated from different questions which either their premises or hypotheses had a cosine similarity higher than 0.9 were included in the same subset. The training, validation, and test sets percentages are nearly 70/15/15 with 7,266, 1,537, and 1,564 samples, respectively.</p><p>The dataset is presented in two formats, raw and indexed. The raw data includes the Persian sentences, while the indexed data is a tokenized version of sentences where each sentence is encoded as a list of word indexes (integers) 1 . The final dataset as well as an API for accessing data and the trained models have been released for non-commercial usages 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">FarsTail statistics</head><p>The statistics of FarsTail dataset is presented in <ref type="table" target="#tab_1">Table 2</ref>. To provide the possibility for comparing different subsets, there is one section for each of train, validation, and test sets. For each of these sets, beside the total statistics, the statistics for different classes are also shown separately where E, C, and N stand for entailment, contradiction, and neutral classes, respectively.</p><p>The column "samples" of <ref type="table" target="#tab_1">Table 2</ref> shows the number of samples in each subset. As mentioned in Section 3.2, 70/15/15% of data go to the train, validation, and test sets, respectively. It can be seen that this is a balanced dataset without any meaningful differences between the number of samples in different classes. The next column (premise tokens) presents the average number of tokens in the premises obtained by the Hazm python library's tokenizer. The next column (hypothesis tokens) shows the same values for hypothesis sentences. To provide a more meaningful length statistic, the next two columns (premise processed tokens and hypothesis processed tokens) report the number of unique tokens ignoring stopwords 3 as well as one-character tokens including punctuations. It is worth mentioning that there are a total of 20,973 tokens in FarsTail dataset where 467 tokens are stopwords or one-character tokens.</p><p>According to these four "tokens" columns, there is not any significant difference between the average number of tokens in train, validation, and test sets. More importantly, the average number of tokens in different classes are almost the same which shows that the length of premises and hypotheses cannot be exploited as a feature to find clues about the class of the given inputs.</p><p>One more point to consider about the "tokens" columns is that the premises in FarsTail are longer than the premises in SciTail dataset <ref type="bibr" target="#b9">[10]</ref>.</p><p>The reported average premise length for entail and neutral samples in Sci-Tail training set are 10.79 and 10.28, respectively, while these numbers are <ref type="bibr">19.35 and 19.31</ref> in FarsTail. Regarding hypotheses, the average length for entail and neutral samples are respectively 6.69 and 7.01 which are almost the same as FarsTail <ref type="bibr">(8.42 and 8.26)</ref>. These longer premises are due to the FarsTail's sample generation process where we insisted on finding exact web text portions which the hypothesis could be inferred from. Anyway, this makes FarsTail a more challenging dataset since it seeks more reasoning to connect the facts presented in longer premises.</p><p>Finally, the last two columns show the average proportion of the hypothesis tokens that overlap with the premise. Both columns treat the sentences as a set of tokens ignoring the word repetition, but the second column also ignore the stopwords and one-character tokens. As expected, the most and the least overlap between premise and hypothesis are in the entailment and neutral samples, respectively. This shows that there are some superficial clues in the samples which can be exploited to estimate the relationship between two sentences without truly understanding them. In the next section, we show that the mere similarity between premise and hypothesis can be used in a simple baseline model which obtains an accuracy higher than random; however, this accuracy is far from that obtained by more advanced deep models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we present the results of different traditional and deep learning-based methods on the FarsTail dataset to provide a baseline for future researches. In Section 4.1, we introduce the evaluated models, and in Section 4.2, the results are presented and discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Models</head><p>We used different methods for representing the input sentences ranging from traditional TF-IDF to more recent word embedding methods such as word2vec 4 <ref type="bibr" target="#b10">[11]</ref>, fastText 5 <ref type="bibr" target="#b11">[12]</ref>, ELMo 6 <ref type="bibr" target="#b12">[13]</ref>, and BERT 7 <ref type="bibr" target="#b13">[14]</ref>. Beside these representations, to investigate the ability of a model to determine the relationship between a given premise and hypothesis just using their word-level similarity, we also considered the simple method of representing a given pair by the cosine similarity between their bag-of-word vectors.</p><p>As the classifier, we exploited different general models including Support Vector Machine (SVM), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) along with three models developed specially for the NLI task including DecompAtt <ref type="bibr" target="#b15">[16]</ref>, ESIM <ref type="bibr" target="#b16">[17]</ref>, and HBMP <ref type="bibr" target="#b17">[18]</ref>.</p><p>One popular approach in learning with small labeled training NLP datasets is to train a language model (LM) on a large unlabeled corpus and fine-tune it on the downstream task. We used ULMFiT <ref type="bibr" target="#b18">[19]</ref> which is one of the popular methods in this line with three steps: LM pre-training, LM fine-tuning, and classifier fine-tuning. In the first step, a language model is trained on a general-domain corpus. We used the Persian Wikipedia for this purpose. Then, the trained LM is fine-tuned on the target task texts without considering their labels. Finally, the pre-trained language model is augmented with additional layers which are trained on the labeled dataset of the target task.</p><p>As another strategy, we evaluated the cross-lingual transfer approach as is investigated for XNLI dataset <ref type="bibr" target="#b8">[9]</ref>. We adopted two simple translationbased baselines, Translate-Source and Translate-Target. In Translate-Source approach, we translated the training data of MultiNLI dataset to Persian language and trained an ESIM model on the union of this translated set and the FarsTail's training set. Then, the FarsTail's training set was used one more time to fine-tune the trained model. The Google Translate service was exploited for translation. In the Translate-Target approach, we trained an ESIM model on the union of original MultiNLI training set and the Englishtranslated version of FarsTail's training set, which was then fine-tuned on the FarsTail's English training set. For estimating the label of a given Persian input, its English translation is fed into the trained model.</p><p>We also tested the LASER embedding 8 <ref type="bibr" target="#b14">[15]</ref> as a space which is shared between multiple languages. Since LASER provides sentence embeddings rather than word embeddings, a simple deep model was trained on the computed representations. <ref type="table" target="#tab_2">Table 3</ref> shows the results obtained from training general classifiers on FarsTail's training set. These classifiers include SVM, LSTM, and BiGRU. For each classifier, different representation methods are investigated. In the cosine representation, we use the simple cosine similarity between the count vectors of the premise and hypothesis. This is a simple baseline to investigate the model which just exploits the similarity between the premise and hypothesis to decide about their inference relationship. The obtained 57.54% test accuracy shows that the mere similarity between premise and hypothesis can be used to obtain an accuracy higher than random, but far better accuracies can be obtained by more advanced techniques as is elaborated in the rest of this section. According to <ref type="figure" target="#fig_3">Fig. 3</ref> (SVM + Cosine), this simple baseline obtains a good performance in distinguishing the neutral from the other two classes which is compatible with the overlap statistics presented in <ref type="table" target="#tab_1">Table 2</ref>, where the overlap between premises and hypotheses in the neutral class is clearly different from that in the other two classes. On the other hand, the worst performance of this simple similarity-based baseline is in the contradiction class where the model is nearly random. This is because contradiction needs a higher level of inference to be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results and discussion</head><p>For each of the other representations in <ref type="table" target="#tab_2">Table 3</ref>, we use two different versions, separate and concat. In the separate approach, the premise and hypothesis are represented separately and the obtained representations are then concatenated; while in the concat method, they are concatenated by a unique character in the middle before representation calculation. Note that the LASER and tf-idf representations are just used with the SVM classifier because they deliver sentence-level representations which cannot be used with the word-level methods like LSTM and BiGRU. On the other hand, to feed the SVM classifier with the word-level representations including word2vec, fastText, ELMo, and BERT, we compute a tf-idf-weighted average of these word representations for each sentence.</p><p>In almost all rows in <ref type="table" target="#tab_2">Table 3</ref>, the separate approach obtains a better performance than the concat one, except the BERT embedding where the concat representation obtains far better results than the separate approach. This is due to the way BERT is pre-trained with a special separator token added between sentence pairs. The best test accuracy in this table is obtained using the concatenated version of BERT representation using the LSTM classifier which shows the power of BERT embedding as is known in the community. The corresponding confusion matrix is presented in <ref type="figure" target="#fig_3">Fig. 3</ref> showing the success of this method in improving the accuracy in all classes specially the contradiction class.</p><p>In <ref type="table" target="#tab_3">Table 4</ref>, the results of DecompAtt <ref type="bibr" target="#b15">[16]</ref>, ESIM <ref type="bibr" target="#b16">[17]</ref>, and HBMP <ref type="bibr" target="#b17">[18]</ref> methods trained on the FarsTail's training set are presented. These methods are specifically published for the NLI task. For each of these methods, the confusion matrix of the best model is also depicted in <ref type="figure" target="#fig_3">Fig. 3</ref>. For the ESIM and HBMP methods, all representations obtain almost similar accuracies; while for the DecompAtt method, word2vec outperforms other embeddings by a large margin.</p><p>Finally, <ref type="table" target="#tab_4">Table 5</ref> shows the results obtained by language modeling and cross-lingual transfer approaches. First, the ULMFiT method <ref type="bibr" target="#b18">[19]</ref> is applied on the FarsTail's training data, which is a language modeling trained on the Persian Wikipedia and fine-tuned on the target task (details are presented in Section 4.1). Then, the ESIM model <ref type="bibr" target="#b16">[17]</ref>, as a NLI-specific method, is trained using the BERT embeddings of not just the FarsTail data but also the MultiNLI samples <ref type="bibr" target="#b20">[21]</ref>. Note that the BERT used in our experiments is a multilingual embedding including a shared space for different languages. The usage of the vast number of samples available in the English MultiNLI dataset makes a clear improvement in the obtained accuracy, where the test accuracy jumps from 0.7136 <ref type="table" target="#tab_3">(Table 4</ref>) to 0.7462 ( <ref type="table" target="#tab_4">Table 5)</ref>.</p><p>We also report the results obtained by two simple translation-based approaches, i.e., Translate-Source and Translate-Target. In Translate-Source, the union of FarsTail's training data and Persian-translated MultiNLI training set is used to train an ESIM model; while in Translate-Target, the FarsTail's training data is translated to English to be used along with the original MultiNLI data (for more details refer to Section 4.1). The results show that the Translate-Source approach, which uses the target language (Persian) as the model's native language, is much more successful than Translate-Target. This is due to the fact that translating the training data from the original Persian language to other languages, as is done in Translate-Target, removes some useful target-specific clues; while in Translate-Target, we use the available data in other languages but preserve our valuable samples in the target language without any manipulation. This is specially true in our experiments where the source and target domains are different; while in XNLI experiments <ref type="bibr" target="#b8">[9]</ref> with similar target and source domains, Translate-Target obtains better results.</p><p>The results in <ref type="table" target="#tab_4">Table 5</ref> demonstrate the usefulness of transfer learning in data-poor languages. Note that our best overall result is obtained using the   Translate-Source approach with fastText embeddings. Anyway, this 78.13% test accuracy shows that there is a big room for improving the current methods to be useful for real-world NLP applications in different languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduced, to the best of our knowledge, the first relatively large-scale NLI dataset for Persian language. We presented the details of the FarsTail development process, which is carefully designed to ensure the data quality. We also presented the dataset statistics as well as the results of some traditional and state-of-the-art methods on it. FarsTail is freely available for non-commercial purposes for both Persian researchers as well as non-Persian ones, since we have presented an indexed version of the dataset along with the raw samples. Due to the usage of multiple-choice questions in developing the FarsTail dataset, these questions along with their corresponding premises can also be exploited in the machine reading comprehension task. In the future, we plan to present this MRC dataset as a byproduct of FarsTail. Finally, since the best obtained result on the FarsTail's test set, even using SOTA methods, was 78.13%, we hope it invokes more research on developing methods which are applicable to real-world NLP tasks in different languages, specially datapoor ones.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The FarsTail dataset development steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Who was the Secretary-General of the United Nations before António Guterres? o Javier Solana o Ban Ki-moon (correct answer) o Kofi Annan o Yoshirō Mori : Entailment hypothesis (question + correct answer) ‫ﺑﻮد.‬ ‫ﻣﻮن‬ ‫ﮐﯽ‬ ‫ﺑﺎن‬ ‫ﮔﻮﺗﺮش،‬ ‫آﻧﺘﻮﻧﯿﻮ‬ ‫از‬ ‫ﻗﺒﻞ‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫ﮐﻞ‬ ‫دﺑﯿﺮ‬ Ban Ki-moon was the Secretary-General of the United Nations before António Guterres. : Premise (from web) ‫ﮐﺮد.‬ ‫اﻧﺘﺨﺎب‬ ‫ﻣﻮن‬ ‫ﮐﯽ‬ ‫ﺑﺎن‬ ‫ﺟﺎﻧﺸﯿﻦ‬ ‫و‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫ﺑﻌﺪي‬ ‫دﺑﯿﺮﮐﻞ‬ ‫ﺑﻌﻨﻮان‬ ‫را‬ ‫ﮔﻮﺗﺮش‬ ‫آﻧﺘﻮﻧﯿﻮ‬ ً ‫رﺳﻤﺎ‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫ﻋﻤﻮﻣﯽ‬ ‫ﻣﺠﻤﻊ‬ The United Nations General Assembly formally elected António Guterres as the next UN Secretary-General and Ban Kimoon's successor.Contradiction hypothesis (question + incorrect answer):‫ﺑﻮد.‬ ‫ﺷﺪه‬ ‫اﻧﺘﺨﺎب‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫ﮐﻞ‬ ‫دﺑﯿﺮ‬ ‫ﺑﻌﻨﻮان‬ ‫ﮔﻮﺗﺮش‬ ‫آﻧﺘﻮﻧﯿﻮ‬ ‫از‬ ‫ﭘﯿﺶ‬ ‫ﻋﻨﺎن‬ ‫ﮐﻮﻓﯽ‬ Before António Guterres, Kofi Annan had been selected as the United Nations Secretary-General.Neutral hypothesis (from web):‫ﮐﺮدﻧﺪ.‬ ‫ﻣﻌﺮﻓﯽ‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫ﮐﻠﯽ‬ ‫دﺑﯿﺮ‬ ‫ﻧﺎﻣﺰد‬ ‫ﺑﻌﻨﻮان‬ ‫را‬ ‫ﮔﻮﺗﺮش‬ ‫آﻧﺘﻮﻧﯿﻮ‬ ‫آرا‬ ‫اﺗﻔﺎق‬ ‫ﺑﻪ‬ ‫ﻣﺘﺤﺪ‬ ‫ﻣﻠﻞ‬ ‫ﺳﺎزﻣﺎن‬ ‫اﻋﻀﺎي‬ The United Nations members unanimously nominated António Guterres as UN Secretary-General.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>An example of generating NLI instances from questions in FarsTail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Confusion matrices of different models for FarsTail test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>was followed to collect and validate 750 examples from each of ten text sources resulted in a total of 7,500 examples. These examples were then translated into 14 different languages by professional translators. The total 112,500 annotated pairs are in English, French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi, Swahili, and Urdu languages. For a discussion of the advantages of our proposed FarsTail dataset over XNLI refer to Section 1.</figDesc><table><row><cell>Build entailment hypothesis</cell><cell></cell><cell></cell></row><row><cell>(question + correct answer)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Revise and relabel again</cell><cell></cell></row><row><cell>Find premise from web for</cell><cell>the removed samples</cell><cell></cell></row><row><cell>entailment hypothesis</cell><cell></cell><cell></cell></row><row><cell>Multiple-choice</cell><cell></cell><cell></cell></row><row><cell>questions</cell><cell>Data cleaning</cell><cell>FarsTail dataset</cell></row><row><cell>Build contradict hypothesis</cell><cell>Retain samples with at</cell><cell></cell></row><row><cell>(question + incorrect answer)</cell><cell>least 80% agreement</cell><cell></cell></row><row><cell>Find neutral hypothesis from</cell><cell>Relabel each sample by</cell><cell></cell></row><row><cell>web</cell><cell>4 other annotators</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the FarsTail dataset.</figDesc><table><row><cell cols="3">subset class samples</cell><cell>prem. tokens</cell><cell>hyp. tokens</cell><cell>prem. proc. tokens</cell><cell>hyp. proc. tokens</cell><cell>overlap</cell><cell>proc. overlap</cell></row><row><cell></cell><cell>E</cell><cell>2,429</cell><cell>40.50</cell><cell>15.53</cell><cell>19.35</cell><cell>8.42</cell><cell>0.67</cell><cell>0.68</cell></row><row><cell>Train</cell><cell>C N</cell><cell>2,389 2,448</cell><cell>40.23 40.52</cell><cell>15.61 15.62</cell><cell>19.20 19.31</cell><cell>8.30 8.26</cell><cell>0.57 0.40</cell><cell>0.54 0.30</cell></row><row><cell></cell><cell cols="2">Total 7,266</cell><cell>40.42</cell><cell>15.59</cell><cell>19.29</cell><cell>8.33</cell><cell>0.55</cell><cell>0.51</cell></row><row><cell></cell><cell>E</cell><cell>515</cell><cell>39.70</cell><cell>14.85</cell><cell>19.13</cell><cell>8.27</cell><cell>0.67</cell><cell>0.66</cell></row><row><cell>Val</cell><cell>C N</cell><cell>499 523</cell><cell>39.58 39.71</cell><cell>15.09 14.95</cell><cell>19.17 19.16</cell><cell>8.11 8.06</cell><cell>0.58 0.39</cell><cell>0.54 0.29</cell></row><row><cell></cell><cell cols="2">Total 1,537</cell><cell>39.67</cell><cell>14.96</cell><cell>19.15</cell><cell>8.14</cell><cell>0.54</cell><cell>0.50</cell></row><row><cell></cell><cell>E</cell><cell>519</cell><cell>39.57</cell><cell>15.48</cell><cell>18.84</cell><cell>8.39</cell><cell>0.68</cell><cell>0.68</cell></row><row><cell>Test</cell><cell>C N</cell><cell>510 535</cell><cell>39.44 39.23</cell><cell>15.81 16.02</cell><cell>18.86 18.73</cell><cell>8.38 8.36</cell><cell>0.57 0.38</cell><cell>0.52 0.27</cell></row><row><cell></cell><cell cols="2">Total 1,564</cell><cell>39.41</cell><cell>15.78</cell><cell>18.81</cell><cell>8.38</cell><cell>0.54</cell><cell>0.49</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Validation and test set accuracy of general classifiers trained on FarsTail's training set using different sentence representations.</figDesc><table><row><cell>Classifier</cell><cell>Representation</cell><cell cols="2">Val Accuracy Test Accuracy</cell></row><row><cell></cell><cell>cosine</cell><cell>0.5485</cell><cell>0.5754</cell></row><row><cell></cell><cell>LASER (separate)</cell><cell>0.5459</cell><cell>0.5198</cell></row><row><cell></cell><cell>LASER (concat)</cell><cell>0.4938</cell><cell>0.4808</cell></row><row><cell></cell><cell>tf-idf (separate)</cell><cell>0.5303</cell><cell>0.5301</cell></row><row><cell></cell><cell>tf-idf (concat)</cell><cell>0.4502</cell><cell>0.4495</cell></row><row><cell></cell><cell>word2vec (separate)</cell><cell>0.5120</cell><cell>0.5448</cell></row><row><cell>SVM</cell><cell>word2vec (concat)</cell><cell>0.3975</cell><cell>0.4201</cell></row><row><cell></cell><cell>fastText (separate)</cell><cell>0.5296</cell><cell>0.5371</cell></row><row><cell></cell><cell>fastText (concat)</cell><cell>0.4112</cell><cell>0.4175</cell></row><row><cell></cell><cell>ELMo (separate)</cell><cell>0.5621</cell><cell>0.5710</cell></row><row><cell></cell><cell>ELMo (concat)</cell><cell>0.4457</cell><cell>0.4604</cell></row><row><cell></cell><cell>BERT (separate)</cell><cell>0.5745</cell><cell>0.5575</cell></row><row><cell></cell><cell>BERT (concat)</cell><cell>0.6532</cell><cell>0.6752</cell></row><row><cell></cell><cell>word2vec (separate)</cell><cell>0.5172</cell><cell>0.5243</cell></row><row><cell></cell><cell>word2vec (concat)</cell><cell>0.4932</cell><cell>0.5006</cell></row><row><cell></cell><cell>fastText (separate)</cell><cell>0.5205</cell><cell>0.5192</cell></row><row><cell>LSTM</cell><cell>fastText (concat) ELMo (separate)</cell><cell>0.5068 0.5478</cell><cell>0.5147 0.5505</cell></row><row><cell></cell><cell>ELMo (concat)</cell><cell>0.5407</cell><cell>0.5428</cell></row><row><cell></cell><cell>BERT (separate)</cell><cell>0.5394</cell><cell>0.5249</cell></row><row><cell></cell><cell>BERT (concat)</cell><cell>0.7534</cell><cell>0.7583</cell></row><row><cell></cell><cell>word2vec (separate)</cell><cell>0.5192</cell><cell>0.5224</cell></row><row><cell></cell><cell>word2vec (concat)</cell><cell>0.4951</cell><cell>0.4942</cell></row><row><cell></cell><cell>fastText (separate)</cell><cell>0.5211</cell><cell>0.5243</cell></row><row><cell>BiGRU</cell><cell>fastText (concat) ELMo (separate)</cell><cell>0.5062 0.5582</cell><cell>0.5166 0.5428</cell></row><row><cell></cell><cell>ELMo (concat)</cell><cell>0.5368</cell><cell>0.5454</cell></row><row><cell></cell><cell>BERT (separate)</cell><cell>0.5348</cell><cell>0.5301</cell></row><row><cell></cell><cell>BERT (concat)</cell><cell>0.7625</cell><cell>0.7558</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Validation and test set accuracy of NLI-specific models trained on FarsTail's training set using different sentence representations.</figDesc><table><row><cell>Model</cell><cell cols="3">Representation Val Accuracy Test Accuracy</cell></row><row><cell></cell><cell>word2vec</cell><cell>0.6597</cell><cell>0.6566</cell></row><row><cell>DecompAtt</cell><cell>fastText ELMo</cell><cell>0.6051 0.5719</cell><cell>0.5831 0.5505</cell></row><row><cell></cell><cell>BERT</cell><cell>0.5999</cell><cell>0.5722</cell></row><row><cell></cell><cell>word2vec</cell><cell>0.7028</cell><cell>0.7110</cell></row><row><cell>ESIM</cell><cell>fastText ELMo</cell><cell>0.7033 0.6903</cell><cell>0.7136 0.6873</cell></row><row><cell></cell><cell>BERT</cell><cell>0.7189</cell><cell>0.7136</cell></row><row><cell></cell><cell>word2vec</cell><cell>0.6617</cell><cell>0.6604</cell></row><row><cell>HBMP</cell><cell>fastText ELMo</cell><cell>0.6584 0.6467</cell><cell>0.6521 0.6349</cell></row><row><cell></cell><cell>BERT</cell><cell>0.6526</cell><cell>0.6432</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Validation and test set accuracy obtained by language modeling and cross-lingual transfer approaches applied to FarsTail's training set.</figDesc><table><row><cell>Method</cell><cell>Representation</cell><cell cols="2">Val Accuracy Test Accuracy</cell></row><row><cell>ULMFiT</cell><cell>Learned</cell><cell>0.7281</cell><cell>0.7244</cell></row><row><cell>ESIM</cell><cell>BERT (FarsTail +</cell><cell>0.7419</cell><cell>0.7462</cell></row><row><cell></cell><cell>MultiNLI)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>word2vec</cell><cell>0.7534</cell><cell>0.7653</cell></row><row><cell>Translate-Source</cell><cell>fastText</cell><cell>0.7778</cell><cell>0.7813</cell></row><row><cell></cell><cell>BERT</cell><cell>0.7358</cell><cell>0.7519</cell></row><row><cell></cell><cell>word2vec</cell><cell>0.6714</cell><cell>0.6822</cell></row><row><cell>Translate-Target</cell><cell>fastText</cell><cell>0.7024</cell><cell>0.7046</cell></row><row><cell></cell><cell>BERT</cell><cell>0.6802</cell><cell>0.6899</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Hazm python library was used for tokenization (https://github.com/sobhe/hazm) 2 https://github.com/dml-qom/FarsTail</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">A stoplist with 389 words was used from Hazm library.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://vectors.nlpl.eu/repository 5 https://fasttext.cc/docs/en/crawl-vectors.html 6 https://github.com/HIT-SCIR/ELMoForManyLangs 7 https://github.com/imgarylai/bert-embedding</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://github.com/facebookresearch/LASER</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on recent advances in named entity recognition from deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2145" to="2158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bibliometrics of sentiment analysis literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Keramatfar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Amirkhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A survey of deep learning techniques for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07526</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A survey on machine reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baradaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Amirkhani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01582</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maccartney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey of the usages of deep learning for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Otter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recent trends in deep learning based natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="55" to="75" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">XNLI: Evaluating cross-lingual sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2475" to="2485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SciTail: A textual entailment dataset from science question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5189" to="5197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<title level="m">Distributed representations of words and phrases and their compositionality</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Deep contextualized word representations</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond, Transactions of the Association for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="597" to="610" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Enhanced LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sentence embeddings in NLI with iterative refinement encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yli-Jyrä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="482" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">SemEval-2014 Task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lessons from natural language inference in the clinical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shivade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1586" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Anthony</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Transforming question answering datasets into natural language inference datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02922</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for SQuAD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Proceedings of EVALITA 2009 2 (6.4</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A dataset for Arabic textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alabbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Student Research Workshop associated with RANLP 2013</title>
		<meeting>the Student Research Workshop associated with RANLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="7" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An analysis of textual inference in German customer emails</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eichler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014</title>
		<meeting>the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Overview of the evaluation of semantic similarity and textual inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Borges Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Criscuolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Aluísio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguamática</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
