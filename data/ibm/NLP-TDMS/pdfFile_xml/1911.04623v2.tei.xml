<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Ohio State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot learners aim to recognize new object classes based on a small number of labeled training examples. To prevent overfitting, state-of-the-art few-shot learners use meta-learning on convolutional-network features and perform classification using a nearest-neighbor classifier. This paper studies the accuracy of nearest-neighbor baselines without meta-learning. Surprisingly, we find simple feature transformations suffice to obtain competitive fewshot learning accuracies. For example, we find that a nearest-neighbor classifier used in combination with meansubtraction and L2-normalization outperforms prior results in three out of five settings on the miniImageNet dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The human visual system has an ability to recognize new visual classes (for instance, greebles <ref type="bibr" target="#b6">[7]</ref>) based on a few examples that is, currently, unmatched by computer vision. The development of computer-vision systems that can perform such few-shot learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34]</ref> is important, e.g., for developing systems that can recognize the millions of natural or man-made classes that appear in the world <ref type="bibr" target="#b11">[12]</ref>.</p><p>Few-shot learning is generally studied in a learning setting in which the visual-recognition system is first trained to recognize a collection of base classes from a large number of training examples. Subsequently, the system receives a small number of training examples (so-called "shots") for a few novel visual classes that it needs to recognize thereafter. In order to be robust to overfitting, a successful fewshot learning model must efficiently re-use what it learned from training on the base classes for the novel classes.</p><p>Many current few-shot learners extract image features using a convolutional network, and use a combination of meta-learning and nearest-neighbor classification to perform the recognition <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36]</ref>. Prior studies suggest that using meta-learning outperforms "vanilla" nearest neighbor classification <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>This study challenges the status quo by demonstrating that nearest-neighbor classifiers can achieve state-of- using nearest neighbors. We train a DenseNet on miniImageNet and use the learned features to perform few-shot learning using a nearest-neighbor classifier with Euclidean distance. We measure the one-shot five-way accuracy on 10,000 tasks sampled from the validation classes during training. We compare un-normalized (UN), L2-normalized (L2N), and centered L2-normalized (CL2N) features. CL2N features outperform UN features, highlighting the importance of feature transformations in few-shot learning.</p><p>the-art performance on popular few-shot learning benchmarks without meta-learning. Specifically, we find that applying simple feature transformations on the features before nearest-neighbor classification leads to very competitive few-shot learning results. For example, we find that a nearest-neighbor classifier that uses DenseNet features <ref type="bibr" target="#b13">[14]</ref> to which mean subtraction and L2-normalization are applied outperforms a long list <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37]</ref> of recent, arguably more complex few-shot learning approaches on the popular miniImageNet <ref type="bibr" target="#b33">[34]</ref> and tieredImageNet <ref type="bibr" target="#b26">[27]</ref> benchmarks (see <ref type="table" target="#tab_0">Table 1</ref> and 2). These observations generalize to other convolutional network architectures <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b37">38]</ref>. We refer to our few-shot learner as SimpleShot. We hope to reestablish nearest-neighbor classification as an obvious but competitive baseline for few-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Nearest Neighbors for Few-Shot Learning</head><p>Denoting an image by I, we assume we are given a training set, D base = {(I 1 , y 1 ), . . . , (I N , y N )}, that contains N labeled images from A base classes; that is, y n ∈ {1, . . . , A}. Furthermore, we assume we are given a support set D support of labeled images from C novel classes, where each novel class has K examples. The goal of fewshot learning is to construct a model that accurately recognizes the C novel classes. This learning setting is referred to as the K-shot C-way setting.</p><p>We study a few-shot learner based on nearest-neighbor classification, called SimpleShot. The nearest-neighbor classifier operates on features x ∈ R D that were extracted from image I using a convolutional network f θ (I) with parameters θ. The feature-producing convolutional network, f θ (I), is trained to minimize the loss of a linear classifier (with W ∈ R D×A in the last network layer) on D base :</p><formula xml:id="formula_0">arg min θ,W (I,y)∈Dbase (W f θ (I), y),</formula><p>where the loss function is selected to be the cross-entropy loss. The convolutional network and the linear classifier are trained jointly using stochastic gradient descent.</p><p>Nearest Neighbor Rule. Once the feature extraction network, f θ , is trained on the base classes, we access images exclusively in feature space and consider all subsequent images as readily provided in feature space. For simplicity of notation, we denote x = f θ (I) as an image in feature space. In this space we perform nearest-neighbor classification using some distance measure, d(x, x ) ∈ R + 0 . We first consider the one-shot setting, that is, the setting in which D support contains only K = 1 labeled example for each of the C classes: D support = {(x 1 , 1), . . . , (x C , C)}, where we use the notationx to distinguish images in the novel C classes from images x in D base . The nearest-neighbor rule assigns the label of the most similar support image (in feature space) to a test imagex:</p><formula xml:id="formula_1">y(x) = arg min c∈{1,··· ,C} d(x,x c ).<label>(1)</label></formula><p>In multi-shot settings, we use a nearest-centroid approach. Specifically, we compute the averaged feature vector (centroid) for each class in D support and treat each of the centroids as a one-shot example for the corresponding class. We then apply Equation 1 on the centroids.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Feature Transformations</head><p>In this study, we use the Euclidean distance, d(x,x ) = x −x 2 , as the distance measure for nearest-neighbors classification. We only consider two feature transformations that are well-established and may be considered trivial but, empirically, we find that they can have a positive effect on the accuracy of the SimpleShot few-shot learner.</p><p>Centering. We compute the mean feature vector on the base classes,x = 1 |Dbase| x∈Dbase x, and subtract it from a feature vectorx to normalize it:x ←x −x. Centering (or mean subtraction) in itself does not alter Euclidean distances between feature vectors, but can become effective in combination with L2-normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L2-normalization (L2N).</head><p>Given a feature vectorx, we normalize it to have unit 2 norm:x ←x x 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>Following prior work, we measure the efficacy of feature transformations in nearest-neighbor classifiers for few-shot learning in a series of image-recognition experiments. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental Setup</head><p>Datasets. We experiment on three image datasets.</p><p>The miniImageNet dataset <ref type="bibr" target="#b33">[34]</ref> is a subset of Ima-geNet <ref type="bibr" target="#b27">[28]</ref> that is commonly used to study few-shot learning. The dataset contains 100 classes and has a total of 600 examples per class. Following <ref type="bibr" target="#b25">[26]</ref> and subsequent work, we split the dataset to have 64 base classes, 16 validation classes, and 20 novel classes. Following <ref type="bibr" target="#b33">[34]</ref> and subsequent studies, we resize the images to 84 × 84 pixels via rescaling and center cropping.</p><p>We also perform experiments on the tieredImageNet dataset <ref type="bibr" target="#b26">[27]</ref>, which is also constructed from ImageNet but contains 608 classes. The dataset is split into 351, 97, and 160 classes for base, validation, and novel classes, respectively. The class split is performed using WordNet <ref type="bibr" target="#b19">[20]</ref> to ensure that all the base classes are semantically unrelated to the novel classes. Again, we resize images to 84×84 pixels.</p><p>Following <ref type="bibr" target="#b23">[24]</ref>, we also perform experiments on the CIFAR-100 <ref type="bibr" target="#b15">[16]</ref> dataset, which contains 100 image classes. Each of the classes in the dataset has 600 images of size 32 × 32 pixels. We follow <ref type="bibr" target="#b23">[24]</ref> and split the classes into 60 base, 20 validation, and 20 novel classes.</p><p>Evaluation protocol. Following <ref type="bibr" target="#b28">[29]</ref>, we measure the accuracy of SimpleShot and the other few-shot learners by drawing 10,000 K-shot C-way tasks from the novel classes: each task has C novel classes and K labeled (support) images and 15 test (query) images per class. Following prior work, we focus on one-shot and five-shot, five-way tasks.</p><p>We average observed accuracies over all test images and over all the tasks, and report the resulting average accuracy and 95% confidence interval.</p><p>Model and implementation details. We evaluate our methods using five different convolutional-network architectures as the basis for the feature-generating function f θ (I). We study five different network architectures:</p><p>• Four-layer convolutional networks (Conv-4): We follow <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34]</ref> to implement this baseline model. • Wide residual networks (WRN-28-10) <ref type="bibr" target="#b37">[38]</ref>: We follow <ref type="bibr" target="#b28">[29]</ref> and use the architecture with 28 convolutional layers and a widening factor of 10. • Dense convolutional networks (DenseNet-121) <ref type="bibr" target="#b13">[14]</ref>:</p><p>We use the standard 121-layer architecture but remove the first two down-sampling layers (i.e., we set their stride to 1) and change the first convolutional layer to use a kernel of size 3 × 3 (rather than 7 × 7) pixels. • Residual networks (ResNet-10/18) <ref type="bibr" target="#b10">[11]</ref>: We use the standard 18-layer architecture but we remove the first two down-sampling layers and we change the first convolutional layer to use a kernel of size 3 × 3 (rather than 7 × 7) pixels. Our ResNet-10 contains 4 residual blocks; the ResNet-18 contains 8 blocks. • MobileNet <ref type="bibr" target="#b12">[13]</ref>: We use the standard architecture for ImageNet <ref type="bibr" target="#b27">[28]</ref> but, again, we remove the first two down-sampling layers from the network.</p><p>We train all networks for 90 epochs from scratch using stochastic gradient descent to minimize the cross-entropy loss of A-way classification (A is the number of base classes). We perform the data augmentation proposed in <ref type="bibr" target="#b10">[11]</ref>. We set the initial learning rate to 0.1 and use a batch size of 256 images. On miniImageNet, We shrink the learning rate by 10 at 45 and 66 epoch respectively.</p><p>On tieredImageNet, we divide the learning rate by 10 after every 30 epochs. We perform early stopping according to the one-shot five-way accuracy (measured using Sim-pleShot (L2N)) on the validation classes.</p><p>Feature transformations. We evaluate the effectiveness of three feature transformations in our experiments:</p><p>• UN: Unnormalized features.</p><p>• L2N: L2-normalized features.</p><p>• CL2N: Centered and then L2-normalized features.</p><p>These transforms are followed by nearest-neighbor classification using the Euclidean distance measure.</p><p>Comparison. We compare our baselines to a range of state-of-the-art few-shot learners <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>. We do not compare to approaches that were developed for semisupervised and transductive learning settings, as such approaches use the statistics of query examples or statistics across the few-shot tasks. We note that the network architectures used in prior studies may have slight variations; we have tried our best to eliminate the effect of such variations on our observations as much as possible. <ref type="bibr" target="#b1">2</ref>  <ref type="table" target="#tab_0">Table 1</ref>, 2, and 3 present our results on miniImageNet, tieredImageNet, and CIFAR-100, respectively. In line with prior work, we observe that nearest-neighbor classifiers using "vanilla" Euclidean distance (UN) do not perform very well. However, simply applying L2-normalization (L2N) consistently leads to accuracy gains of at least 3% on these datasets. Subtracting the mean before L2-normalization (CL2N) leads to another improvement of 1−3%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Results</head><p>Our SimpleShot nearest-neighbor / nearest-centroid classifiers achieve accuracies that are comparable with or better than the state-of-the-art. For example, on the miniImageNet dataset, our simple methods obtain the highest one-shot and five-shot accuracies for three of five network architectures.</p><p>We perform a simple experiment measuring the effectiveness of feature transformations at various stages of convolutional-network training. We train a DenseNet on miniImageNet for 90 epochs, and measure the one-shot fiveway accuracy on 10,000 tasks sampled from the validation classes after each epoch. The results of this experiment are shown in <ref type="figure" target="#fig_0">Figure 1</ref>: they show that nearest-neighbor classifiers using C2LN feature transformation consistently outperform their UN and L2N counterparts. This suggests that our observations on the role of feature transformations do not depend on how long the network is trained.</p><p>We also investigate the effect of feature transformations on more complex few-shot learning algorithms. Specifically, we trained a Conv-4 architecture with the Pro-toNet <ref type="bibr" target="#b29">[30]</ref> loss, which uses unnormalized Euclidean distances. After training, we apply feature transformations before computing pairwise Euclidean distances between features in a nearest-neighbor approach. <ref type="table" target="#tab_3">Table 4</ref> presents the results of this experiment, which shows that CL2N normalization can also improve the performance of ProtoNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We analyzed the effect of simple feature transformations in nearest-neighbor classifiers for few-shot learning. We observed that such transformations -in particular, a combination of centering and L2-normalization -can improve the quality of the representation to a degree that the resulting classifiers outperforms several state-of-the-art approaches to few-shot learning. We hope that the SimpleShot classifiers studied in this paper will be used as a competitive baseline in future studies on few-shot learning.  <ref type="bibr" target="#b1">[2]</ref>. : Results reported in <ref type="bibr" target="#b35">[36]</ref>. : <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b35">36]</ref> and our results are averaged over 10,000 rounds.  <ref type="bibr" target="#b28">[29]</ref>. : Results reported in <ref type="bibr" target="#b18">[19]</ref>. : <ref type="bibr" target="#b28">[29]</ref> and our results are averaged over 10,000 rounds.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Meta-iNat Results</head><p>We also investigate the role of feature transformations in SimpleShot on the long-tailed iNaturalist dataset <ref type="bibr" target="#b32">[33]</ref>. Following the meta-iNat benchmark <ref type="bibr" target="#b34">[35]</ref>, we split the dataset to have 908 base classes and 227 novel classes. We follow the evaluation setup of <ref type="bibr" target="#b34">[35]</ref> and perform 227-way multishot evaluation. (In the meta-iNat benchmark, the number of shots varies per class.) We train all networks for 90 epochs using stochastic gradient descent. We set the initial learning rate to be 0.1 and batch size to be 256. We scale the learning rate by 0.1 after every 30 epochs.</p><p>The results of our meta-iNat experiments with Sim-pleShot are presented in <ref type="table">Table 5</ref>. The table reports the averaging the accuracy on each class over all test classes (per class) and the average accuracy over all test images (mean). To the best of our knowledge, our highest accuracy of 62.13% (per class) and 65.09% (mean) is the current stateof-the-art on the meta-iNat benchmark. <ref type="figure" target="#fig_1">Figure 2</ref> shows the absolute accuracy improvement (in %) of each of the classifiers compared to the baseline nearest-neighbor classifier without feature normalization (UN). In line with prior experiments, L2-normalization (L2N) leads to accuracy improvements in few-shot learning. Different from the other experiments, centering after L2-normalization (CL2N) does not improve the accuracy of SimpleShot further.   <ref type="table">Table 5</ref>: Accuracy (in %) of SimpleShot classifiers in 227-way multi-shot classification on the meta-iNat benchmark <ref type="bibr" target="#b34">[35]</ref>. Accuracy is measured by averaging the accuracy on each class over all test classes (per class) and by averaging accuracy over all test images (mean). Higher is better.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Feature transformations matter in few-shot learning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Absolute accuracy improvement (per class; in %) on the meta-iNat dataset of SimpleShot classifiers with L2normalization (L2N) and centering and L2-normalization (CL2N) compared to a SimpleShot classifier without feature normalization (UN).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Average accuracy (in %; measured over 600/10,000 rounds ) of one-shot and five-shot classifiers for five-way classification on miniImageNet; higher is better. The best result of each network architecture of each column is in bold font. Results of our approaches are in blue. Best viewed in color.</figDesc><table><row><cell>Approach</cell><cell>Network</cell><cell>One shot</cell><cell>Five shots</cell></row><row><cell>Meta LSTM [26]</cell><cell>Conv-4</cell><cell cols="2">43.44 ± 0.77 60.60 ± 0.71</cell></row><row><cell>MatchingNet [34]</cell><cell>Conv-4</cell><cell cols="2">43.56 ± 0.84 55.31 ± 0.73</cell></row><row><cell>MAML [4]</cell><cell>Conv-4</cell><cell cols="2">48.70 ± 1.84 63.11 ± 0.92</cell></row><row><cell>LLAMA [10]</cell><cell>Conv-4</cell><cell>49.40 ± 1.83</cell><cell>-</cell></row><row><cell>ProtoNet [30]</cell><cell>Conv-4</cell><cell cols="2">49.42 ± 0.78 68.20 ± 0.66</cell></row><row><cell>Reptile [23]</cell><cell>Conv-4</cell><cell cols="2">49.97 ± 0.32 65.99 ± 0.58</cell></row><row><cell>PLATIPUS [5]</cell><cell>Conv-4</cell><cell>50.13 ± 1.86</cell><cell>-</cell></row><row><cell>mAP-SSVM [32]</cell><cell>Conv-4</cell><cell cols="2">50.32 ± 0.80 63.94 ± 0.72</cell></row><row><cell>GNN [6]</cell><cell>Conv-4</cell><cell cols="2">50.33 ± 0.36 66.41 ± 0.63</cell></row><row><cell>RelationNet [31]</cell><cell>Conv-4</cell><cell cols="2">50.44 ± 0.82 65.32 ± 0.70</cell></row><row><cell>Meta SGD [18]</cell><cell>Conv-4</cell><cell cols="2">50.47 ± 1.87 64.03 ± 0.94</cell></row><row><cell>MTNet [17]</cell><cell>Conv-4</cell><cell>51.70 ± 1.84</cell><cell>-</cell></row><row><cell>Qiao et al. [25]</cell><cell>Conv-4</cell><cell cols="2">54.53 ± 0.40 67.87 ± 0.20</cell></row><row><cell>FEAT [36]</cell><cell>Conv-4</cell><cell cols="2">55.15 ± 0.20 71.61 ± 0.16</cell></row><row><cell>SimpleShot (UN)</cell><cell>Conv-4</cell><cell cols="2">33.17 ± 0.17 63.25 ± 0.17</cell></row><row><cell>SimpleShot (L2N)</cell><cell>Conv-4</cell><cell cols="2">48.08 ± 0.18 66.49 ± 0.17</cell></row><row><cell cols="2">SimpleShot (CL2N) Conv-4</cell><cell cols="2">49.69 ± 0.19 66.92 ± 0.17</cell></row><row><cell>MAML [4]  †</cell><cell cols="3">ResNet-18 49.61 ± 0.92 65.72 ± 0.77</cell></row><row><cell>Chen et al. [2]</cell><cell cols="3">ResNet-18 51.87 ± 0.77 75.68 ± 0.63</cell></row><row><cell>RelationNet [31]  †</cell><cell cols="3">ResNet-18 52.48 ± 0.86 69.83 ± 0.68</cell></row><row><cell>MatchingNet [34]  †</cell><cell cols="3">ResNet-18 52.91 ± 0.88 68.88 ± 0.69</cell></row><row><cell>ProtoNet [30]  †</cell><cell cols="3">ResNet-18 54.16 ± 0.82 73.68 ± 0.65</cell></row><row><cell>Gidaris et al. [8]</cell><cell cols="3">ResNet-15 55.45 ± 0.89 70.13 ± 0.68</cell></row><row><cell>SNAIL [21]</cell><cell cols="3">ResNet-15 55.71 ± 0.99 68.88 ± 0.92</cell></row><row><cell>Bauer et al. [1]</cell><cell cols="3">ResNet-34 56.30 ± 0.40 73.90 ± 0.30</cell></row><row><cell>adaCNN [22]</cell><cell cols="3">ResNet-15 56.88 ± 0.62 71.94 ± 0.57</cell></row><row><cell>TADAM [24]</cell><cell cols="3">ResNet-15 58.50 ± 0.30 76.70 ± 0.30</cell></row><row><cell>CAML [15]</cell><cell cols="3">ResNet-12 59.23 ± 0.99 72.35 ± 0.71</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">ResNet-10 54.45 ± 0.21 76.98 ± 0.15</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">ResNet-10 57.85 ± 0.20 78.73 ± 0.15</cell></row><row><cell cols="4">SimpleShot (CL2N) ResNet-10 60.85 ± 0.20 78.40 ± 0.15</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">ResNet-18 56.06 ± 0.20 78.63 ± 0.15</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">ResNet-18 60.16 ± 0.20 79.94 ± 0.14</cell></row><row><cell cols="4">SimpleShot (CL2N) ResNet-18 62.85 ± 0.20 80.02 ± 0.14</cell></row><row><cell>Qiao et al. [25]</cell><cell>WRN</cell><cell cols="2">59.60 ± 0.41 73.74 ± 0.19</cell></row><row><cell>MatchingNet [34]</cell><cell>WRN</cell><cell cols="2">64.03 ± 0.20 76.32 ± 0.16</cell></row><row><cell>ProtoNet [30]</cell><cell>WRN</cell><cell cols="2">62.60 ± 0.20 79.97 ± 0.14</cell></row><row><cell>LEO [29]</cell><cell>WRN</cell><cell cols="2">61.76 ± 0.08 77.59 ± 0.12</cell></row><row><cell>FEAT [36]</cell><cell>WRN</cell><cell cols="2">65.10 ± 0.20 81.11 ± 0.14</cell></row><row><cell>SimpleShot (UN)</cell><cell>WRN</cell><cell cols="2">57.26 ± 0.21 78.99 ± 0.14</cell></row><row><cell>SimpleShot (L2N)</cell><cell>WRN</cell><cell cols="2">61.22 ± 0.21 81.00 ± 0.14</cell></row><row><cell cols="2">SimpleShot (CL2N) WRN</cell><cell cols="2">63.50 ± 0.20 80.33 ± 0.14</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">MobileNet 55.70 ± 0.20 77.46 ± 0.15</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">MobileNet 59.43 ± 0.20 78.00 ± 0.15</cell></row><row><cell cols="4">SimpleShot (CL2N) MobileNet 61.30 ± 0.20 78.37 ± 0.15</cell></row><row><cell>SimpleShot (UN)</cell><cell>DenseNet</cell><cell cols="2">57.81 ± 0.21 80.43 ± 0.15</cell></row><row><cell>SimpleShot (L2N)</cell><cell>DenseNet</cell><cell cols="2">61.49 ± 0.20 81.48 ± 0.14</cell></row><row><cell cols="2">SimpleShot (CL2N) DenseNet</cell><cell cols="2">64.29 ± 0.20 81.50 ± 0.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>† : Results reported in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Average accuracy (in %; measured over 600/10,000 rounds ) of one-shot and five-shot classifiers for five-way classification on tieredImageNet; higher is better. The best result of each network architecture of each column is in bold font. Results of our approach are in blue. Best viewed in color.</figDesc><table><row><cell>Approach</cell><cell>Network</cell><cell>One shot</cell><cell>Five shots</cell></row><row><cell>Reptile [23]</cell><cell>Conv-4</cell><cell cols="2">48.97 ± 0.21 66.47 ± 0.21</cell></row><row><cell>ProtoNet [30]</cell><cell>Conv-4</cell><cell cols="2">53.31 ± 0.89 72.69 ± 0.74</cell></row><row><cell>SimpleShot (UN)</cell><cell>Conv-4</cell><cell cols="2">33.12 ± 0.18 65.23 ± 0.18</cell></row><row><cell>SimpleShot (L2N)</cell><cell>Conv-4</cell><cell cols="2">50.21 ± 0.20 69.02 ± 0.18</cell></row><row><cell cols="2">SimpleShot (CL2N) Conv-4</cell><cell cols="2">51.02 ± 0.20 68.98 ± 0.18</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">ResNet-10 58.60 ± 0.22 79.99 ± 0.16</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">ResNet-10 64.58 ± 0.23 82.31 ± 0.16</cell></row><row><cell cols="4">SimpleShot (CL2N) ResNet-10 65.37 ± 0.22 81.84 ± 0.16</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">ResNet-18 62.69 ± 0.22 83.27 ± 0.16</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">ResNet-18 68.64 ± 0.22 84.47 ± 0.16</cell></row><row><cell cols="4">SimpleShot (CL2N) ResNet-18 69.09 ± 0.22 84.58 ± 0.16</cell></row><row><cell>Meta SGD [18]  †</cell><cell>WRN</cell><cell cols="2">62.95 ± 0.03 79.34 ± 0.06</cell></row><row><cell>LEO [29]</cell><cell>WRN</cell><cell cols="2">66.33 ± 0.05 81.44 ± 0.09</cell></row><row><cell>SimpleShot (UN)</cell><cell>WRN</cell><cell cols="2">63.85 ± 0.21 84.17 ± 0.15</cell></row><row><cell>SimpleShot (L2N)</cell><cell>WRN</cell><cell cols="2">66.86 ± 0.21 85.50 ± 0.14</cell></row><row><cell cols="2">SimpleShot (CL2N) WRN</cell><cell cols="2">69.75 ± 0.20 85.31 ± 0.15</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">MobileNet 63.65 ± 0.22 84.01 ± 0.16</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">MobileNet 68.66 ± 0.23 85.43 ± 0.15</cell></row><row><cell cols="4">SimpleShot (CL2N) MobileNet 69.47 ± 0.22 85.17 ± 0.15</cell></row><row><cell>SimpleShot (UN)</cell><cell>DenseNet</cell><cell cols="2">64.35 ± 0.23 85.69 ± 0.15</cell></row><row><cell>SimpleShot (L2N)</cell><cell>DenseNet</cell><cell cols="2">69.91 ± 0.22 86.42 ± 0.15</cell></row><row><cell cols="2">SimpleShot (CL2N) DenseNet</cell><cell cols="2">71.32 ± 0.22 86.66 ± 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>† : Results reported in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Average accuracy (in %; measured over 600/10,000 rounds ) of one-shot and five-shot classifiers for five-way classification on CIFAR-100; higher is better. The best result is in bold font. Results of our approach are in blue. Best viewed in color. ResNet-10 40.13 ± 0.18 53.63 ± 0.18 : Our results are averaged over 10,000 rounds.</figDesc><table><row><cell>Approach</cell><cell>Network</cell><cell>One shot</cell><cell>Five shots</cell></row><row><cell>TADAM [24]</cell><cell>ResNet</cell><cell cols="2">40.10 ± 0.40 56.10 ± 0.40</cell></row><row><cell>SimpleShot (UN)</cell><cell cols="3">ResNet-10 36.38 ± 0.17 52.67 ± 0.18</cell></row><row><cell>SimpleShot (L2N)</cell><cell cols="3">ResNet-10 38.47 ± 0.17 53.34 ± 0.18</cell></row><row><cell>SimpleShot (CL2N)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Feature transformations matter in 1NN classificationwith ProtoNet<ref type="bibr" target="#b29">[30]</ref>. We report average accuracy (in %; measured over 10,000 rounds) of five-way one-shot / five-shot ProtoNet classifiers on miniImageNet with and without feature transformations (applied after training).</figDesc><table><row><cell cols="3">1NN (UN) [30] 1NN (UN; ours) 1NN (L2N)</cell><cell>1NN (CL2N)</cell></row><row><cell>49.42 / 68.20</cell><cell>49.56 / 67.79</cell><cell cols="2">49.55 / 67.84 50.12 / 68.51</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code at https://github.com/mileyan/simple_shot.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For example, we report results for ResNet-10 models because it is the shallowest ResNet architecture used in prior work on few-shot learning.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments The authors thank Han-Jia Ye for helpful discussions. Y.W. and K.Q.W. are supported by grants from the NSF (III-1618134, III-1526012, IIS-1149882, IIS-1724282, and TRIPODS-1740822), the Bill and Melinda Gates Foundation, and the Cornell Center for Materials Research with funding from the NSF MRSEC program (DMR-1719875); and are also supported by Zillow, SAP America Inc., and Facebook.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Discriminative k-shot learning using probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Swiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00326</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Dissecting face recognition: The role of expertise and level of categorization in object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gauthier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Meta-learning probabilistic inference for prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The devil is in the tails: Finegrained classification in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>arXiv 1709.01450</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to learn with conditional class dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Varno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chapados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gradient-based meta-learning with learned layerwise metric and subspace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09835</idno>
		<title level="m">Meta-sgd: Learning to learn quickly for few shot learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">On first-order metalearning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno>abs/1803.02999</idno>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimization as a model for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Few-shot learning through an information retrieval lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Mac</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8769" to="8778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Few-shot learning with localization in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6558" to="6567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning embedding adaptation for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.03664</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bayesian model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">SimpleShot (UN) SimpleShot (L2N) SimpleShot (CL2N) Per class Mean Per class Mean Per class</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
