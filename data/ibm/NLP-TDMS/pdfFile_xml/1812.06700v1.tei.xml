<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hateminers : Detecting Hate speech against Women</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Punyajoy</forename><surname>Saha</surname></persName>
							<email>punyajoysaha1998@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Engineering Science and Technology</orgName>
								<address>
									<country>Shibpur</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binny</forename><surname>Mathew</surname></persName>
							<email>binnymathew@iitkgp.ac.in</email>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animesh</forename><surname>Mukherjee</surname></persName>
							<email>animeshm@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Hateminers : Detecting Hate speech against Women</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>English. With the online proliferation of hate speech, there is an urgent need for systems that can detect such harmful content. In this paper, We present the machine learning models developed for the Automatic Misogyny Identification (AMI) shared task at EVALITA 2018. We generate three types of features: Sentence Embeddings, TF-IDF Vectors, and BOW Vectors to represent each tweet. These features are then concatenated and fed into the machine learning models. Our model came First for the English Subtask A and Fifth for the English Subtask B. We release our winning model for public use 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Italiano. Con la proliferazione online di incitamento all'odio, c' un'urgente necessit di sistemi in grado di rilevare tali contenuti dannosi. In questo documento, presentiamo i modelli di apprendimento automatico sviluppati per l'attivit di identificazione automatica Misogyny Identification (AMI) a EVALITA 2018. Generiamo tre tipi di funzionalit: Embedded di frasi, Vettori TF-IDF e Vettori BOW per rappresentare ciascun tweet. Queste caratteristiche vengono quindi concatenate e inserite nei modelli di apprendimento automatico. Il nostro modello arrivato textbf Primo per la sottotabella inglese A e textbf Fifth per la sottotabella inglese B. Rilasciamo il nostro modello vincente per uso pubblico 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter defines hateful misconduct as "you may not promote violence against or directly attack or threaten other people on the basis of race, ethnicity, national origin, sexual orientation, gender, gender identity, religious affiliation, age, disability, or serious disease 2 ". With the online proliferation of hate speech, several countries like USA, Germany, and France have laws to ban such hateful content. This situation calls for online hate detection systems that are necessary to curb the rapidly increasing hate speech. In particular, there is a rise in online violence against women (Misogyny).</p><p>According to Pew research 3 , women encounter sexualized forms of abuse at much higher rates than men. Sites like Twitter are failing in acting promptly against online mysogyny and taking too much time to remove the content 4 . The research community has now started to focus on this issue and is developing methods to detect online mysogyny <ref type="bibr">(Hewitt et al., 2016b;</ref><ref type="bibr" target="#b3">Fersini et al., 2018b;</ref><ref type="bibr" target="#b12">Poland, 2016)</ref>.</p><p>In this paper, we focus on detection of misogynous posts in Twitter that are written in English and describe our submission (Hateminers) for the task of Automatic Misogyny Identification (AMI) at EVALITA2018 <ref type="bibr">(Fersini et al., 2018a)</ref>. We concatenate three types of features to represent each tweet and use machine learning models for classification.</p><p>For the English Task A, we are ranked 1 st (team "Hateminers") at the AMI shared task at EVALITA 2018 competition, with an accuracy of 70.4%. For the English Task B, we are ranked 5 th (team rank 3 rd ), with an average macro-average F1-score of 0.37.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related works</head><p>The research on hatespeech is gaining momentum with several works which focus on different aspects such as analyzing hatespeech <ref type="bibr" target="#b13">(ElSherief et al., 2018;</ref><ref type="bibr" target="#b10">Mathew et al., 2018;</ref><ref type="bibr" target="#b14">Silva et al., 2016;</ref><ref type="bibr">Chandrasekharan et al., 2017;</ref><ref type="bibr" target="#b7">Gröndahl et al., 2018)</ref>, and detection of hatespeech <ref type="bibr" target="#b4">(Fortuna and Nunes, 2018;</ref><ref type="bibr" target="#b2">Davidson et al., 2017;</ref><ref type="bibr" target="#b13">Qian et al., 2018)</ref>.</p><p>Recently, there seems to be growing interest in the identification of misogynous contents online (Ging and Siapera, 2018). Some of the initial works on identification of misogynous contents online were performed by <ref type="bibr" target="#b8">(Hewitt et al., 2016a)</ref>. In <ref type="bibr" target="#b5">(Fox et al., 2015)</ref>, the authors study the roles of anonymity and interactivity in response to sexist content posted on a social networking site. They concluded that interacting with sexist content anonymously promotes greater hostile sexism than interacting with it using an identified account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset and task description</head><p>The AMI shared task at EVALITA2018 had two balanced datasets for the English and Italian language. We participated in the English language shared task only. So, we present the systems developed for the English language AMI task only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The training dataset consisted of 4000 labelled tweets and the test dataset had 1000 unlabelled tweets. The distribution of different labels is presented in <ref type="table" target="#tab_1">Table 1</ref>. The English corpora have been manually labelled by several annotators according to three levels:</p><p>• Misogyny (Misogyny vs Not Misogyny)</p><p>• Misogynistic category (discredit, derailing, dominance, sexual harassment &amp; threats of violence, stereotype &amp; objectification)</p><p>• Target (active vs passive)</p><p>As observed from <ref type="table" target="#tab_1">Table 1</ref>, the label distribution for Task A is balanced, while in Task B the distribution is highly unbalanced for both misogyny behaviors and targets. We will explain these categories in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tasks</head><p>Task A: First, it is asked to have a binary classification of the tweets, that is as either misogynous  or not misogynous. The performance of the system is measured based on the accuracy. Task B: Next, it is asked to classify the misogynous tweets according to both the misogynistic behaviour and the target of the message. The evaluation metric is macro F1-score for this task. A tweet must be classified uniquely within one of the following categories:</p><p>1. Stereotype &amp; objectification: a widely held but fixed and oversimplified image or idea of a woman; description of women's physical appeal and/or comparisons to narrow standards.</p><p>2. Dominance: to assert the superiority of men over women to highlight gender inequality.</p><p>3. Derailing: to justify woman abuse, rejecting male responsibility; an attempt to disrupt the conversation in order to redirect women's conversations on something more comfortable for men.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Sexual harassment &amp; threats of violence:</head><p>to describe actions as sexual advances, requests for sexual favors, harassment of a sexual nature; intent to physically assert power over women through threats of violence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discredit: slurring over women with no other larger intention.</head><p>On the other hand, the target classification is again binary:</p><p>1. Active (individual): the text includes offensive messages purposely sent to a specific target.</p><p>2. Passive (generic): it refers to messages posted to many potential receivers.</p><p>In this section, we will explain the details regarding the features and machine learning models used for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature generation</head><p>Pre-processing: We pre-process the tweets before performing the feature extraction. The following steps were followed:</p><p>• We remove all the URLs.</p><p>• Convert tweet text to lowercase.</p><p>• Words such as "ain't", "i'll" were replaced by the corresponding expanded forms.</p><p>• Removed emojis, stop words, and punctuation.</p><p>• Performed tokenization and stemming.</p><p>Feature vector: The pre-processed tweets were used to generate the features for the classifiers. We generated three types of features and concatenate them for each tweet. We experimented with all the features and found that the combination of all the features worked the best. We explain each of the feature type below.</p><p>• Sentence embeddings: The sentence vector is generated using an Universal Sentence Encoder <ref type="bibr" target="#b0">(Cer et al., 2018)</ref> which outputs a 512 dimensional vector representation of the text. Recent works <ref type="bibr" target="#b1">(Conneau et al., 2017)</ref> have shown stronger performance using pretrained sentence level embeddings as compared to word level embeddings. We provide each of the preprocessed tweets as input to the sentence encoder and use the vector output for our task.</p><p>• TF-IDF vector: TF-IDF vectors were generated using Scikit's 5 TF-IDF vectorizer on the pre-processed tweets.</p><p>• Bag of words vector (BoWV): The BoWV approach uses the average of the GloVe (Pennington et al., 2014) word embeddings to represent a sentence. We set the size of the vector embeddings to 300. 5 https://goo.gl/9FrZLD </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Classifiers used</head><p>We experiment with three machine learning models for Task A &amp; B.</p><p>Logistic Regression (LR): We use the LR implementation available in scikit-learn 6 . We set C as 1.0 for all the tasks. XGBoost (XGB): XGB 7 is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. we set the objective parameter as 'binary:logistic' scale pos weight was set to 0.8 and reglamda set to 3.0.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results:</head><p>The results of our system for English Task A are presented in <ref type="figure" target="#fig_0">Figure 1</ref> and for English Task B are presented in <ref type="figure" target="#fig_2">Figure 2</ref>. Our systems captured the top three ranks for the English Subtask A of Misogyny identification. For Subtask B, our best system came at fifth position (3 rd best team). We obtained the best result for English Subtask A in run#1 (0.704 accuracy) in which we used Logistic Regression classifier and had the 1 st rank. Our other two runs, both using Catboost model, ranked 2 nd and 3 rd in the task.</p><p>For the English Subtask B, in which we needed to classify the category and target of misogyny, we kept the same set of features as we used for Task A. Our best system ranked 5 th (0.37 average F-Measure for run#3) which used Catboost classifier for both category and target classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We found that our system was able to achieve good performance for classifying the targets, but was not able to perform good in category classifica-tion. On closer inspection of Subtask B results 9 , we found that the main reason for the poor performance was the high data imbalance. We observe that several of the submitted systems perform poorly on the different categories of Task B. The under represented categories such as DE-RAILING and DOMINANCE were hard to detect due to the data imbalance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we present our approach to detect misogynous tweets in twitter. We generate sentence embeddings, TF-IDF Vectors, and BOW vectors for each tweet and then concatenate them. These vectors are then used as features for models such as CatBoost and Logistic Regression. Our model occupied the top three positions for English Subtask A and our best model for English Subtask B came at 5 th rank (3 rd best team).</p><p>We have also made the winning model public 1 for other researchers to use. 9 https://amievalita2018. files.wordpress.com/2018/11/ english-detailed-results-category-target. pdf</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>AMI results for the English Subtask A (Misogyny classification). Our System came at the top position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>CatBoost (CB): CB (Dorogush et al., 2017) is a state-of-the-art open-source gradient boosting on decision trees library developed by Yandex 8 . We set scale pos weight to 0.8 for all experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>AMI results for the English Subtask B (Category and target classification). Out best system came at 5 th position (3 rd best team).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The distribution of different labels in the English language dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/punyajoy/ Hateminers-EVALITA</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://goo.gl/RSSrrZ 3 http://www.pewinternet.org/2017/07/ 11/online-harassment-2017 4 https://goo.gl/zbYTWA arXiv:1812.06700v1 [cs.SI] 17 Dec 2018</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://scikit-learn.org/stable/ modules/generated/sklearn.linear_model. LogisticRegression.html 7 https://github.com/dmlc/xgboost 8 https://catboost.ai</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">You can&apos;t stay here: The efficacy of reddit&apos;s 2015 ban examined through hate speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.11175</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<editor>Umashanthi Pavalanathan, Anirudh Srinivasan, Adam Glynn, Jacob Eisenstein, and Eric Gilbert</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2017" />
			<publisher>CSCW</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Eshwar Chandrasekharan</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
	<note>Loïc Barrault, and Antoine Bordes</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davidson</forename></persName>
			<affiliation>
				<orgName type="collaboration">ami</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1703.04009</idno>
	</analytic>
	<monogr>
		<title level="m">ICWSM. [Fersini et al.2018a] Elisabetta Fersini, Debora Nozza, and Paolo Rosso. 2018a. Overview of the evalita 2018 task on automatic misogyny identification</title>
		<editor>ElSherief et al.2018] Mai ElSherief, Shirin Nilizadeh, Dana Nguyen, Giovanni Vigna, and Elizabeth M. Belding-Royer</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Peer to peer hate: Hate speech instigators and their targets</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Fersini</surname></persName>
		</author>
		<title level="m">Overview of the task on automatic misogyny identification at</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey on automatic detection of hate speech in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Nunes2018</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sérgio</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Perpetuating online sexism offline: Anonymity, interactivity, and the effects of sexist hashtags on social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="436" to="442" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ging and Siapera2018] Debbie Ging and Eugenia Siapera</title>
	</analytic>
	<monogr>
		<title level="m">Special issue on online misogyny</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">All you need is&quot; love&quot;: Evading hate-speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Gröndahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09115</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The problem of identifying misogynist language on twitter (and other online social spaces)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Conference on Web Science, WebSci &apos;16</title>
		<meeting>the 8th ACM Conference on Web Science, WebSci &apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="333" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The problem of identifying misogynist language on twitter (and other online social spaces)</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Conference on Web Science</title>
		<editor>Hewitt et al.2016b] Sarah Hewitt, Thanassis Tiropanis, and Christian Bokhove</editor>
		<meeting>the 8th ACM Conference on Web Science</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="333" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mathew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01693</idno>
		<title level="m">Spread of hate speech in online social media</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Haters: Harassment, abuse, and violence online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailey</forename><surname>Poland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>U of Nebraska Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical cvae for fine-grained hate speech classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3550" to="3559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Analyzing the targets of hate in online social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="687" to="690" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
