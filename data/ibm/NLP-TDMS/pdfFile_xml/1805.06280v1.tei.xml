<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Context-based Approach for Dialogue Act Recognition using Simple Recurrent Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandrakant</forename><surname>Bothe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelius</forename><surname>Weber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Magg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wermter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Knowledge Technology</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<addrLine>Vogt-Koelln-Str. 30</addrLine>
									<postCode>22527</postCode>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Context-based Approach for Dialogue Act Recognition using Simple Recurrent Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dialogue Acts Detection</term>
					<term>Recurrent Neural Networks</term>
					<term>Context-based Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dialogue act recognition is an important part of natural language understanding. We investigate the way dialogue act corpora are annotated and the learning approaches used so far. We find that the dialogue act is context-sensitive within the conversation for most of the classes. Nevertheless, previous models of dialogue act classification work on the utterance-level and only very few consider context. We propose a novel context-based learning method to classify dialogue acts using a character-level language model utterance representation, and we notice significant improvement. We evaluate this method on the Switchboard Dialogue Act corpus, and our results show that the consideration of the preceding utterances as a a context of the current utterance improves dialogue act detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In natural language processing research, the dialogue act (DA) concept plays an important role. Its recognition, in most cases, is considered a lexical-based or syntax-based classification at utterance-level. However, the discourse compositionality is context sensitive, meaning that the DA of an utterance can be elicited from the preceding utterances <ref type="bibr" target="#b5">(Grosz, 1982)</ref>. Hence, classifying only utterances is not enough because their DA class arises from their context. For example, the utterance containing only the lexical entry 'yeah' might appear in several DA classes such as Backchannel, Yes-Answer, etc. For certain DA classes, the utterances are short, and most of them share similar lexical and syntactic cues . The aim of this article has two subgoals: first, we investigate the annotation process of DA corpora and review the modelling so far used for DA classification, and second, we present a novel model and compare its results with the state of the art. We propose to use context-based learning for the identification of the DA classes. First, we show the results without context, i.e., classifying only utterances. Including context leads to 3% higher accuracy. We use a simple recurrent neural network (RNN) for context learning of the discourse compositionality. We feed the preceding and current utterances to the RNN model to predict its DA class. The main contributions of this work are as follows: -We provide detailed insight on the annotation and modelling of dialogue act corpora. We suggest to model discourse within the context of a conversation.</p><p>-We propose a context-based learning approach for DA identification. In our approach, we represent utterances by a character-level language model trained on domainindependent data.</p><p>-We evaluate the model on the Switchboard Dialogue Act (SwDA 1 ) corpus and show how using context affects the results. For the SwDA corpus, our model achieved an accu-1 Available at https://github.com/cgpotts/swda racy of 77.3% compared to 73.9% as state of the art, where the context-based learning is used for the DA classification <ref type="bibr" target="#b11">(Kalchbrenner and Blunsom, 2013)</ref>.</p><p>-Benefits of using context arise from using only a few preceding utterances making the model suitable for dialogue system in real time, in contrast to feeding the whole conversation, which can achieve high accuracy, but includes future utterances <ref type="bibr" target="#b19">(Liu et al., 2017;</ref><ref type="bibr" target="#b16">Kumar et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Annotation of Dialogue Act Corpora</head><p>Annotation Process and Standards: Research on dialogue acts became important with the commercial reality of spoken dialogue systems. There have been many taxonomies to it: speech act <ref type="bibr" target="#b1">(Austin, 1962)</ref> which was later modified into five classes (Assertive, Directive, Commissive, Expressive, Declarative) <ref type="bibr" target="#b24">(Searle, 1979)</ref>, and the Dialogue Act Markup in Several Layers (DAMSL) tag set where each DA has a forward-looking function (such as Statement, Info-request, Thanking) and a backwardlooking function (such as Accept, Reject, Answer) <ref type="bibr" target="#b0">(Allen and Core, 1997)</ref>. There are many such standard taxonomies and schemes to annotate conversational data, some of them follow the concept of discourse compositionality. These schemes are important for analysing dialogues or building a dialogue system <ref type="bibr" target="#b27">(Skantze, 2007)</ref>. However, there can never be a unique scheme that considers all aspects of dialogue. Corpus Insight: We have investigated the annotation method for two corpora: Switchboard (SWBD) <ref type="bibr" target="#b3">(Godfrey et al., 1992;</ref><ref type="bibr" target="#b7">Jurafsky et al., 1997)</ref> and ICSI Meeting Recorder Dialogue Act (MRDA) <ref type="bibr" target="#b26">(Shriberg et al., 2004)</ref>. They are annotated with the DAMSL tag set. The annotation includes not only the utterance-level but also the segmentedutterance labelling. The DAMSL tag set provides very fine-grained and detailed DA classes and follows the discourse compositionality. For example, the SWBD-DAMSL is the variant of DAMSL specific to the Switchboard cor-  <ref type="bibr">sky, 1997)</ref>. A yes-no question is more likely to get a "yes" answer than a wh-question. This also gives an intuition that the answers follow the syntactic formulation of question which provides a context. For example qy is used for a question that from a discourse perspective expects a Yes or No answer. Nature of Discourse in Conversation: The dialogue act is a context-based discourse concept that means the DA class of a current utterance can be derived from its preceding utterance. We will elaborate this argument with an example given in <ref type="table" target="#tab_0">Table 1</ref>. Speaker A utters 'Oh, yeah.' twice in the first portion, and each time it is labelled with two different DA labels. This is simply due to the context of the previously conversed utterances. If we see the last four utterances of the example, when speaker A utters the 'Yes-No Question' DA, speaker B answers with 'yeah' which is labelled as 'Yes-Answer' DA. However, after the 'Statementopinion' from the same speaker, the same utterance 'yeah' is labelled as 'Backchannel' and not 'Yes-Answer'. This gives evidence that when we process the text of a conversation, we can see the context of a current utterance in the preceding utterances. Prosodic Cues for DA Recognition: It has also been noted that prosodic knowledge plays a major role in DA identification for certain DA types <ref type="bibr" target="#b28">Stolcke et al., 2000)</ref>. The main reason is that the acoustic signal of the same utterance can be very different in a different DA class. This indicates that if one wants to classify DA classes only from the text, the context must be an important aspect to consider: simply classifying single utterances might not be enough, but considering the preceding utterances as a context is important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Modelling Approaches</head><p>Lexical, Prosodic, and Syntactic Cues: Many studies have been carried out to find out the lexical, prosodic and syntactic cues <ref type="bibr" target="#b28">(Stolcke et al., 2000;</ref><ref type="bibr" target="#b29">Surendran and Levow, 2006;</ref><ref type="bibr" target="#b22">O'Shea et al., 2012;</ref><ref type="bibr" target="#b32">Yang et al., 2014)</ref>. For the SwDA corpus, the state-of-the-art baseline result was 71% for more than a decade using a standard Hidden Markov Model (HMM) with language features such as words and n-grams <ref type="bibr" target="#b28">(Stolcke et al., 2000)</ref>. The inter-annotator agreement accuracy for the same corpus is 84%, and in this particular case, we are still far from achieving human accuracy. However, words like 'yeah' appear in many classes such as backchannel, yes-answer, agree/accept etc. Here, the prosodic cues play a very important role in identifying the DA classes, as the same utterance can acoustically differ a lot which helps to distinguish the specific DA class <ref type="bibr" target="#b25">(Shriberg et al., 1998)</ref>. There are several approaches like traditional Naive Bayes and HMM models, which use minimal information and certainly ignore the dependency of the context within the communication <ref type="bibr" target="#b4">(Grau et al., 2004;</ref><ref type="bibr" target="#b30">Tavafi et al., 2013)</ref>. They achieved 66% and 74.32% respectively on the SwDA test set.</p><p>Utterance-level Classification: Perhaps most research in modelling dialogue act identification is conducted at utterance-level <ref type="bibr" target="#b28">(Stolcke et al., 2000;</ref><ref type="bibr" target="#b4">Grau et al., 2004;</ref><ref type="bibr" target="#b30">Tavafi et al., 2013;</ref><ref type="bibr" target="#b6">Ji et al., ;</ref><ref type="bibr" target="#b12">Khanpour et al., 2016;</ref><ref type="bibr" target="#b18">Lee and Dernoncourt, 2016)</ref>. The emergence of deep learning also gave a big push to DA classification. In a natural language conversation, most utterances are very short; hence it is also referred to as short text classification. <ref type="bibr" target="#b18">Lee and Dernoncourt (2016)</ref> achieved 73.1% accuracy on the SwDA corpus by using advanced deep learning frameworks such as RNNs and convolutional neural networks (CNN) with word-level feature embeddings.</p><p>A Novel Approach: Context-based Learning: Classifying the DA classes at single utterance-level might fail when it comes to DA classes where the utterances share similar lexical and syntactic cues (words and phrases) like the backchannel, yes-answer and accept/agree classes. Some researchers proposed an utterance-dependent learning approach <ref type="bibr" target="#b11">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b6">Ji et al., ;</ref><ref type="bibr" target="#b16">Kumar et al., 2017;</ref><ref type="bibr" target="#b31">Tran et al., 2017;</ref><ref type="bibr" target="#b19">Liu et al., 2017;</ref><ref type="bibr" target="#b21">Ortega and Vu, 2017;</ref><ref type="bibr" target="#b20">Meng et al., 2017)</ref>. <ref type="bibr" target="#b11">Kalchbrenner and Blunsom (2013)</ref> and <ref type="bibr" target="#b21">Ortega and Vu (2017)</ref> have proposed contextbased learning, where they represent the utterance as a compressed vector of the word embeddings using CNNs and use these utterance representations to model discourse within a conversation using RNNs. In their architecture, I c a n i m a g i n e .  they also give importance to turn-taking by providing the speaker identity but do not analyse their model in this regard. This approach achieves about 73.9% accuracy on the SwDA corpus. In another line of research <ref type="bibr" target="#b6">(Ji et al., ;</ref><ref type="bibr" target="#b16">Kumar et al., 2017)</ref>, authors claim that their models take care of the dependency of the utterances within a conversation. <ref type="bibr">Ji et al. (2016)</ref> use discourse annotation for the word-level language modelling on the SwDA corpus and also highlight a limitation that this approach is not scalable to large data. In other approaches a hierarchical convolutional and recurrent neural encoder model are used to learn utterance representation by feeding a whole conversation <ref type="bibr" target="#b16">(Kumar et al., 2017;</ref><ref type="bibr" target="#b19">Liu et al., 2017)</ref>. The utterance representations are further used to classify DA classes using the conditional random field (CRF) as a linear classifier. The model can see the past and future utterances at the same time within a conversation, which limits usage in a dialogue system where one can only perceive the preceding utterance as a context but does not know the upcoming utterances. Hence, we use a context-based learning approach and regard the 73.9% accuracy <ref type="bibr" target="#b11">(Kalchbrenner and Blunsom, 2013</ref>) on the SwDA corpus as a current state of the art for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Approach</head><p>Our approach takes care of discourse compositionality while recognising dialogue acts. The DA class of the current utterance is predicted using the context of the preceding utterances. We represent each utterance by the hidden state of the multiplicative recurrent neural network trained on domain-independent data using a character-level language model. We use RNNs to feed the sequence of the utterances and eventually predict the DA class of the corresponding utterance. <ref type="figure">Figure 2</ref>: The RNN setup for learning the dialogue act recognition with the previous sentences as context. s t is an utterance representation derived with a character-level language model and has a dialogue act label da t . s t−1 and s t−2 are the preceding utterances of s t . The RNN is trained to learn the recurrency through previous utterances s t−1 and s t−2 derived as h t−1 and h t−2 as a context to recognize the dialogue act of current utterance s t which is represented by h t used to detect da t .</p><formula xml:id="formula_0">RNN RNN RNN s t-2 s t-1 s t h t-2 h t-1 h t h t-2 h t-1 da t softmax (128) (128)<label>(128)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Utterance Representation</head><p>Character-level encoding allows processing words and whole sentences based on their smallest units and still capturing punctuation and permutation of words. We represent a character-level utterance by encoding the whole sentence with a pre-trained character language model 2 . This model consists of a single multiplicative long-short-term memory (mLSTM) network <ref type="bibr" target="#b14">(Krause et al., 2016)</ref> layer with 4,096 hidden units. The mLSTM is composed of an LSTM and a multiplicative RNN and considers each possible input in a recurrent transition function. It is trained as a character language model on ∼80 million Amazon product reviews <ref type="bibr" target="#b23">(Radford et al., 2017)</ref>. We sequentially input the characters of an utterance to the mLSTM and take the hidden state values after the last character as shown in <ref type="figure" target="#fig_0">Figure 1 (a)</ref>. The hidden vector s t obtained after the last character is called the last feature vector, as it stores the information related to the character language model and the sentiment of the utterance. However, it was shown that the average vector over all characters in the utterance works better for emotion detection <ref type="bibr" target="#b17">(Lakomkin et al., 2017)</ref>. Hence, we extract the last feature vector and also the average feature vector representations for each utterance. We classify these representations with a multi-layer perceptron (MLP) as shown in <ref type="figure" target="#fig_0">Figure 1 (b)</ref>. The results are shown in <ref type="table" target="#tab_2">Table 2</ref>. The standard deviation (SD) is computed over ten runs. The average vector seems to carry more information related to the DA; hence we use it for future experiments. There is an advantage of using domain-independent data: it is rich regarding features being trained on big data, perhaps surpassing the limitation of scalability as mentioned in <ref type="bibr">Ji et al. (2016)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Context Learning with RNNs</head><p>We apply context learning with the help of RNNs. As shown in <ref type="figure">Figure 2</ref>, the utterances with their character-level language model representation s t are fed to the RNN with the preceding utterances (s t−1 , s t−2 ) being the context. We use the RNN, which gets the input s t , and stores the hidden vector h t at time t <ref type="bibr" target="#b2">(Elman, 1990)</ref>, which is calculated as:</p><formula xml:id="formula_1">h t = f (W h * h t−1 + I * s t + b)<label>(1)</label></formula><p>where f () is a sigmoid function, W h and I are recurrent and input weight matrices respectively and b is a bias vector learned during training. h t is computed using the previous hidden vector h t−1 which is computed in a same way for preceding utterance s t−1 . The output da t is the dialogue act label of the current utterance s t calculated using h t , as:</p><formula xml:id="formula_2">da t = g (W out * h t )<label>(2)</label></formula><p>where W out is the output weight matrix. The weight matrices are learned using back-propagation through time. The task is to classify several classes; hence we use a sof tmax function g() on the output. The input is the sequence of the current and preceding utterances, e.g., s t , s t−1 , and s t−2 . We reset the RNN when it sees the current utterance s t . We also give the information related to a speaker to let the network find the change in the speaker's turn. The speaker id 'A' is represented by <ref type="bibr">[1,</ref><ref type="bibr">0]</ref> and id 'B' by [0,1] and it is concatenated with the corresponding utterances s t . The Adam optimiser <ref type="bibr" target="#b13">(Kingma and Ba, 2014)</ref> was used with a learning rate 1e − 4, which decays to zero during training, and clipping gradients at norm 1. Early stopping was used to avoid over-fitting of the network, 20% of training samples were used for validation. In all learning cases, we minimise the categorical cross-entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results</head><p>We follow the same data split of 1115 training and 19 test conversations as in the baseline approach <ref type="bibr" target="#b28">(Stolcke et al., 2000;</ref><ref type="bibr" target="#b11">Kalchbrenner and Blunsom, 2013)</ref>. <ref type="table" target="#tab_3">Table 3</ref> shows the results of the proposed model with several setups, first without the context, then with one, two, and so on preceding utterances in the context. We examined different values for the number of the hidden units of the RNN, empirically 64 was identified as best and used throughout the experiments. We also experimented with the various representations for the speaker id that is concatenated with the respective utterances but could find no differences. As a result, our proposed model uses minimal information for the context. The performance increases from 74% to about 77% with context. We run each experiment for ten times and take the average. The model shows robustness providing minimal variance, and using a minimum number of preceding utterances as a context can produce fair results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this article, we detail the annotation and modelling of dialogue act corpora, and we find that there is a difference in the way DAs are annotated and the way they are modelled. We argue to generalise the discourse modelling for conversation within the context of communication. Hence, we propose to use the context-based learning approach for the DA identification task. We used simple RNN to model the context of preceding utterances. We used the domainindependent pre-trained character language model to represent the utterances. We evaluated the proposed model on the Switchboard Dialogue Act corpus and show the results with and without context. For this corpus, our model achieved an accuracy of 77.34% with context compared to 73.96% without context. We also compare our model with <ref type="bibr" target="#b11">Kalchbrenner and Blunsom (2013)</ref> who used the contextbased learning approach achieving 73.9%. Our model uses minimal information, such as the context of a few preceding utterances which can be adapted to an online learning tool such as a spoken dialogue system where one can naturally see the preceding utterances but not the future ones. This makes our model suitable for human-robot/computer interaction which can be easily plugged into any spoken dialogue system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgements</head><p>This project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement number 642667 (SECURE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Bibliographical References</head><p>Appendix: Analysis of the state of the RNN</p><p>We also analyze the internal state h t of the RNNs for a two-utterance setup. We plot them on a 2D graph with the t-SNE algorithm for the first 2,000 utterances of the SwDA test set. <ref type="figure">Figure 3</ref> shows the clusters of all the DA classes. The classes which do not share any information are grouped without any interference such as Non-verbal, and Abandoned. <ref type="figure">Figure 4</ref> shows some particular classes with utterances in their vector spaces, the (1) current utterance and (2) a preceding utterance in the context. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) Multiplicative LSTM (mLSTM) characterlevel language model to produce the sentence representation s t . The character-level language model is pre-trained and produces the feature (hidden unit states of mLSTM at the last character) or average (average of all hidden unit states of every character) vector representation of the given utterance. (b) Utterance-level classification using a simple MLP layer with a softmax function (our baseline model).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Example of a labeled conversation (portions) from the Switchboard Dialogue Act corpus</figDesc><table><row><cell cols="2">Speaker Dialogue Act</cell><cell>Utterance</cell></row><row><cell>A</cell><cell>Backchannel</cell><cell>Uh-huh.</cell></row><row><cell>B</cell><cell>Statement</cell><cell>About twelve foot in diameter</cell></row><row><cell>B</cell><cell>Abandoned</cell><cell>and, there is a lot of pressure to get that much weight up in the air.</cell></row><row><cell>A</cell><cell>Backchannel</cell><cell>Oh, yeah.</cell></row><row><cell>B</cell><cell>Abandoned</cell><cell>So it's interesting, though.</cell></row><row><cell></cell><cell></cell><cell>. . .</cell></row><row><cell>B</cell><cell cols="2">Statement-opinion it's a very complex, uh, situation to go into space.</cell></row><row><cell>A</cell><cell>Agree/Accept</cell><cell>Oh, yeah,</cell></row><row><cell></cell><cell></cell><cell>. . .</cell></row><row><cell>A</cell><cell>Yes-No Question</cell><cell>You never think about that do you?</cell></row><row><cell>B</cell><cell>Yes-Answer</cell><cell>Yeah.</cell></row><row><cell>A</cell><cell cols="2">Statement-opinion I would think it would be harder to get up than it would be</cell></row><row><cell>B</cell><cell>Backchannel</cell><cell>Yeah.</cell></row><row><cell cols="3">pus. It distinguishes wh-questions (qw), yes-no questions</cell></row><row><cell cols="3">(qy), open-ended (qo), and or-questions (qr) classes, not</cell></row><row><cell cols="3">just because these questions are syntactically distinct, but</cell></row><row><cell cols="3">also because they have different forward functions (Juraf</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of the dialogue act identification using the character-level language model utterance representation for 42 classes using a single MLP layer with 64 neurons.</figDesc><table><row><cell>Model input</cell><cell cols="2">Acc.(%) SD</cell></row><row><cell>Last feature vector</cell><cell>71.48</cell><cell>0.28</cell></row><row><cell>Average feature vector</cell><cell>73.96</cell><cell>0.26</cell></row><row><cell>Concatenated vector</cell><cell>73.18</cell><cell>0.31</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Accuracy of the dialogue act identification with the context-learning approach.</figDesc><table><row><cell>Model setup</cell><cell cols="2">Acc.(%) SD</cell></row><row><cell>Baseline</cell><cell></cell><cell></cell></row><row><cell>Most common class</cell><cell>31.50</cell><cell></cell></row><row><cell>Related previous work</cell><cell></cell><cell></cell></row><row><cell>Stolcke et al. (2000)</cell><cell>71.00</cell><cell></cell></row><row><cell>Kalchbrenner and Blunsom (2013)</cell><cell>73.90</cell><cell></cell></row><row><cell>Our work</cell><cell></cell><cell></cell></row><row><cell>Our baseline (without context)</cell><cell>73.96</cell><cell>0.26</cell></row><row><cell cols="2">RNN (1 utt. in context w. SpeakerID) 76.48</cell><cell>0.33</cell></row><row><cell>RNN (1 utt. in context)</cell><cell>76.57</cell><cell>0.28</cell></row><row><cell>RNN (2 utts. in context)</cell><cell>76.81</cell><cell>0.24</cell></row><row><cell>RNN (3 utts. in context)</cell><cell>77.34</cell><cell>0.21</cell></row><row><cell>RNN (4 utts. in context)</cell><cell>77.28</cell><cell>0.22</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/openai/ generating-reviews-discovering-sentiment</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Draft of DAMSL: Dialogue Act Markup in Several Layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Core</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">How to Do Things with Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Austin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SWITCHBOARD: Telephone speech corpus for research and development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>of the International Conference on Acoustics, Speech, and Signal essing</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dialogue act classification using a Bayesian approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanchis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vilar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th Conference Speech and Computer SPECOM</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Discourse Analysis. Sublanguage. Studies of Language in Restricted Semantic Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="page" from="138" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Latent Variable Recurrent Neural Network for Discourse Relation Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<biblScope unit="page" from="332" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Switchboard Dialog Act Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Biasca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>International Computer Science Inst. Berkeley CA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shribergy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Curl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Syntactic Cues for Dialog Acts</title>
	</analytic>
	<monogr>
		<title level="m">The ACL/COLING Workshop on Discourse Relations and Discourse Markers</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Switchboard SWBD-DAMSL Shallow-Discourse-Function Annotation Coders Manual, draft 13</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno>97-01</idno>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="225" to="233" />
		</imprint>
		<respStmt>
			<orgName>University of Colorado Institute of Cognitive Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recurrent Convolutional Neural Networks for Discourse Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Continuous Vector Space Models and their Compositionality, ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dialogue Act Classification in Domain-Independent Conversations Using a Deep Recurrent Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Khanpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guntakandla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2012" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multiplicative LSTM for sequence modelling</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04250v2</idno>
		<title level="m">Dialogue Act Sequence Labeling using Hierarchical encoder with CRF</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">GradAscent at EmoInt-2017: Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lakomkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis at EMNLP 2017</title>
		<meeting>of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis at EMNLP 2017</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dernoncourt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.03827</idno>
		<title level="m">Sequential Short-Text Classification with Recurrent and Convolutional Neural Networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using Context Information for Dialog Act Classification in DNN Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2017 Conference on EMNLP</title>
		<meeting>of the 2017 Conference on EMNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2160" to="2168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical RNN with Static Sentence-Level Attention for Text-Based Speaker Change Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM Conference on Information and Knowledge Management</title>
		<meeting>of ACM Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2203" to="2206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural-based Context Representation Learning for Dialog Act Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGDIAL 2017 Conference</title>
		<meeting>of the SIGDIAL 2017 Conference</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="247" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Multiclassifier Approach to Dialogue Act Classification Using Function Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>O&amp;apos;shea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions on Computational Collective Intelligence VII</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="119" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01444</idno>
		<title level="m">Learning to Generate Reviews and Discovering Sentiment</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Expression and Meaning: Studies in the Theory of Speech Acts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Searle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Can Prosody Aid the Automatic Classification of Dialog Acts in Conversational Speech?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meteer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="443" to="492" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The ICSI meeting recorder dialog act (MRDA) corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Carvey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>International Computer Science Inst. Berkeley CA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Error Handling in Spoken Dialogue Systems-Managing Uncertainty, Grounding and Miscommunication: Chapter 2, Spoken Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Skantze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>KTH Computer Science and Communication</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meteer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Dialog act tagging with support vector machines and hidden Markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Surendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-A</forename><surname>Levow</surname></persName>
		</author>
		<editor>Interspeech -ICSLP</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dialogue Act Recognition in Synchronous and Asynchronous Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tavafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL Conference</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Preserving Distributional Information in Dialogue Act Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zukerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on EMNLP</title>
		<meeting>of Conference on EMNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2141" to="2146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semisupervised Learning of Dialogue Acts Using Sentence Similarity Based on Word Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Audio, Language and Image Processing</title>
		<meeting>of International Conference on Audio, Language and Image essing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="882" to="886" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
