<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AKHCRNet: Bengali handwritten character recognition using deep learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Akash</roleName><surname>Roy</surname></persName>
							<email>royakashappleid@icloud.com</email>
							<affiliation key="aff0">
								<orgName type="department">Government College of Engineering and Ceramic Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">AKHCRNet: Bengali handwritten character recognition using deep learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Deep Learning · Image Recognition · Convolutional Net- works · Handwritten character recognition</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I propose a state of the art deep neural architectural solution for handwritten character recognition for Bengali alphabets, compound characters as well as numerical digits that achieves state-of-the-art accuracy 96.8% in just 11 epochs. Similar work has been done before by Chatterjee, Swagato, et al.</p><p>[1] but they achieved 96.12% accuracy in about 47 epochs. The deep neural architecture used in that paper was fairly large considering the inclusion of the weights of the ResNet 50 model which is a 50 layer Residual Network. This proposed model achieves higher accuracy as compared to any previous work &amp; in a little number of epochs. ResNet50 is a good model trained on the ImageNet dataset, but I propose an HCR network that is trained from the scratch on Bengali characters without the "Ensemble Learning" that can outperform previous architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation</head><p>Bengali is one of the official languages of the Republic of India and the official language of Bangladesh. About 230 million people speak and write Bengali as a native language around the world. So recognition of Bengali character is an important problem needed to be solved which could potentially help solving other noble applications like optical character recognition, handwritten character recognition and even word recognition.</p><p>But solving Bengali character recognition is much more tough than the English counterpart because -There are far more characters in Bengali alphabets, -Bengali has conjunct consonants in it's alphabets which are harder to classify because it consists of two distinct Bengali characters. Any learning algorithm could simply classify those characters as one or the other, -Many Bengali characters resembles each other closely maybe differentiated by small lines and dots, for example 1st and the 2nd vowels in Bengali alphabets are differentiated by one vertical line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2008.12995v3 [cs.CV] 20 Sep 2020</head><p>The problem of English character recognition may have been solved but the Bengali counterpart still have not achieved the human level accuracy.</p><p>Although there is a substantial amount of work that has been done on this topic as detailed in the previously done section improvements still can be achieved as the benchmark has not yet reached human-level accuracy or surpassed that. Using recent advancements both in the usage of convolution kernels in Deep Learning and also in model training procedures (like hyper-parameter tuning, data augmentation, etc.) can increase the accuracy of HCR Models. Although scientists who most recently worked on this topic used the transfer learning from the ResNet50 model achieved 96.12% accuracy, I used a sophisticated architecture and trained from scratch &amp; got a better result. The BanglaLekha-Isolated Dataset as described in datasets section was used for evaluation mainly because it has a large sample size and large variance and also because the output classes are balanced. The dataset has a total of 84 characters, which has 10 numerals, 50 basic characters, and 24 most common conjunct-consonants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Previous works</head><p>Several other people laid the foundation for Bengali handwritten character recognition. In those, work Ray and Chatterjee did the first significant work <ref type="bibr" target="#b1">[2]</ref> using nearest neighbour classifiers. After that, many more researchers did other methods, improving the performance of Bangla Handwritten Character Recognition (HCR) like Hasant et al. <ref type="bibr" target="#b2">[3]</ref> proposed an HCR capable of classifying both printed and handwritten characters by using Discrete Cosine Transform method over the input image and Hidden Markov Model (HMM) for character classification. Wen et al. <ref type="bibr" target="#b3">[4]</ref> proposed a Bangla numerals recognition method using Principal Component Analysis and Support Vector Machines, but those are using traditional machine learning methods. In Hassan and Khans work, they used the KNN algorithm where features were extracted using local binary patterns. Das et al. <ref type="bibr" target="#b4">[5]</ref> proposed a feature set representation for Bangla handwritten character recognition. It was done by hand engineering 8 distance features, 24 shadow features, 84 quad-tree based longest run features, and 16 centroid features. Their accuracy was about 85.40% on a 50 character class dataset as hand engineering was difficult for the Conjunct-Consonants in Bengali characters. Rumman Rashid Chowdhury used CNN based classifier <ref type="bibr" target="#b10">[11]</ref> and gained over 98% accuracy on 10 neumericals and 91.12% accuracy on 50 basic Bengali character. In the mentioned methods, the main concern is that they used many handcrafted features extracted for the small dataset, and also those didn't achieved the human level accuracy. So these methods are in no means achieved the human level accuracy in handwritten character recognition. As convolutional neural networks eliminated the need for feature extraction, it'll be much more economical to make the HCR network to learn the features on it's own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>The dataset Im going to be using for this problem is the BanglaLekha Isolated Dataset <ref type="bibr" target="#b11">[12]</ref>.</p><p>There are many open datasets that could be used for this classification problem but this dataset is chosen because of the followings:</p><p>- But the data has some blank images or images that are not taken properly or mislabeled data due to human error. So I have manually gone through every directory of 84 classes and removed some of the mislabeled data the dataset. This process is much important as I am using an algorithm to generate the validation dataset (data the neural network hasnt seen yet) taken at random from the directory. If any of those mislabeled or blank images get into the validation set the neural network will never know and this will generate avoidable errors in the predictions. But in the training dataset, if 1-2 images get blank or mislabeled error, it doesnt matter much. But due to sheer amount of data and unavailability of man power I only managed to remove mislabeled data from 20 categories.</p><p>Dataset preparation goes like this: Out of 166K (after cleaning mislabeled and blank images) Ive used 28% of data randomly chosen from the 84 classes, so no human bias for selection of validation data is present and the rest of the images are used for training. This is how the dataset is structured: So the validation data is selected by computer at random before the training and the neural network doesnt see the validation data during training, this way we can safely measure the accuracy of the network. The accuracy measuring algorithm used here is described below in the architecture section. In the next section it's shown how data is processed before going into the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Image data pre-processing</head><p>The very recent work that has been done by Chatterjee, Swagato, et al. <ref type="bibr" target="#b0">[1]</ref> achieved the best result yet for a training of 47 epochs at 96.12% and the 97% accuracy achieved by Saha and Saha et. al used ensemble CNN architecture run for 500 epochs. Individually, their accuracy was 95.67% and 92.43%.</p><p>Lets look deeper at what Chatterjee, Swagato, et al. did. They used ResNet50 model, which is pre-trained on the ImageNet dataset. For a hand-written classification task I think that they've used transfer learning from a model that is specifically not trained to classify handwritten characters. I think that ResNet 50 models CNN learnt to detect several features that is not quite useful for this task of classifying hand written characters. If Id to use a model, I'd use models that maybe trained previously on similar handwritten datasets like the MNIST dataset <ref type="bibr" target="#b7">[8]</ref>, I think that would converge much faster and could get better results.</p><p>Secondly they used images of size sometimes height of 200 px, width of 200 px, color depth of 3 to comply with ResNet architecture, other times 128 by 128, but in general these are huge image size. I got rid of the unnecessary color channels. I used gray-scale image as an input shape because fundamentally you wouldnt care whether your bengali handwritten character is colorful or not in order to classify them. This made less information but the 'same' useful information going into the network, so the training will converge sooner than that of K Chatterjee et.als training duration which is 47 epochs.</p><p>Next step of pre-processing is to decrease the amount of information coming in neural network. I propose instead of using 200 pixels for width and height that is 40,000 parameters we should be using 32 pixels for width and height that is 1024 parameters. Lets have a look at the data and see if those image resizing processing actually hurts the data and make them unrecognizable for the network? Each pixel value of the images is also normalized between 0-1 to converge faster, and this also makes the neural network easier to train.</p><p>I'm using the idea of bi-linear interpolation technique when resizing the input images from the original size, that goes like this:</p><p>When we are given an image suppose that we want to find the value of the unknown function f at a specific point in image (x, y). It is assumed that we know the value of function f at the four points being Q 11 = (x 1 , y 1 ),</p><formula xml:id="formula_0">Q 12 = (x 1 , y 2 ), Q 21 = (x 2 , y 1 ), Q 22 = (x 2 , y 2 ).</formula><p>We first do linear interpolation in the x-direction. This gives us the following:</p><formula xml:id="formula_1">f (x, y 1 ) ≈ x 2 − x x 2 − x 1 f (Q 11 ) + x − x 1 x 2 − x 1 f (Q 21 ) (1) f (x, y 2 ) ≈ x 2 − x x 2 − x 1 f (Q 12 ) + x − x 1 x 2 − x 1 f (Q 22 )<label>(2)</label></formula><p>Then to the y direction:</p><formula xml:id="formula_2">f (x, y) ≈ y 2 − y y 2 − y 1 f (x, y 1 ) + y − y 1 y 2 − y 1 f (x, y 2 )<label>(3)</label></formula><p>= y 2 − y y 2 − y 1</p><formula xml:id="formula_3">x 2 − x x 2 − x 1 f (Q 11 ) + x − x 1 x 2 − x 1 f (Q 21 ) + y − y 1 y 2 − y 1 x 2 − x x 2 − x 1 f (Q 12 ) + x − x 1 x 2 − x 1 f (Q 22 )</formula><p>Using this bi-linear interpolation technique for image resizing you can see the result here: So we can clearly see that our images are still recognizable and so we can get away with 1024 pixels, which will not going to hurt the deep learning model for less data in an image. Let's see more images resized to (32, 32, 1) and how those looks: The data is coming into the network as (32, 32) gray-scale image, so I have added a (32, 32, 1) layer as the input layer. For the next two layers I've used the <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b4">5)</ref> convolutions and 32 filters of those, this combination worked great against a single (3, 3) convolution. These convolution layers have "same" padding as we have very little information on the images and we don't want to lose those during convolutions. Throughout the entire deep neural architecture, the ReLU activation is used. Where</p><formula xml:id="formula_4">ReLU (z) = max(0, z)</formula><p>Next, a Batch-Normalization is used, this makes our model's weights of deeper layers more robust to changes than to the first few layers. Next, I've added a Max Pooling Layer. I've added a block of (1, 1) convolution with 128 filters followed by one (3, 3), one (5, 5) convolution with 128 filters separately and one (1, 1) convolution and one "same" padded max-pooling layer followed by a (3, 3) convolution. All convolution layers mentioned here have "same" padding. Without the inclusion of this block the architecture converged to a 96.38% accuracy in 20 epochs, which still has the better validation accuracy than that of previous state of the art architecture, but with the inclusion of this block validation accuracy peaked 96.80% in just 11 epochs.</p><p>The total of 4 outputs from the previous block has been concatenated into a (16, 16, 448) layer and a ReLU activation is applied on top of it. Following this there is another two sets of convolution-maxpooling-batch norm-maxpooling blocks. In these two blocks the convolutions has 256 and 512 filters respectively. Same padding and ReLU activation is used throughout and the data is flattened out in the next layer.</p><p>Following this I've added fully connected layer which is 4 layer deep and each layer has 1024, 512, 256, 128 number of hidden units respectively and the output layer has 84 units for the 84 classes.</p><p>The last layer has 84 hidden units with Softmax activation applied to it to comply with the 84 predictable classes in the Bengali dataset. The last few hidden layers are penalized with L2 Regularization method to decrease overfitting, Cortes, Corinna et. al <ref type="bibr" target="#b5">[6]</ref>. The regularizers used in the last few hidden layers are kernel regularizer, as weights in the network is a very high dimensional parametervector, but the bias is just a single real number. so almost all the parameters are in weights rather than in the bias. So I think adding a bias regularizer won't make that much of a difference. So it's useful to only use the kernel regularizer in this problem.</p><p>For a L layer deep network the loss function J is the following: J(w <ref type="bibr" target="#b0">[1]</ref> , b <ref type="bibr" target="#b1">[2]</ref> , ..., w <ref type="bibr">[L]</ref> , b [L] )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3: Layer by layer image data flow in AKHCRNet Model</head><p>Where W[i], b[i] is the i-th layers weight vector and bias respectively. The function J is a softmax cross-entropy loss also known as categorical cross-entropy loss shown below. Softmax function:</p><formula xml:id="formula_5">f (s) i = e si C j e sj<label>(4)</label></formula><p>Categorical cross-entropy loss:</p><formula xml:id="formula_6">CCE = − C i t i log(f (s) i )<label>(5)</label></formula><p>In this specific case of Multi-Class classification the labels are one-hot, so only the positive class Cp keeps its position in the loss. There is only one element of the target vector t which is not zero ti = tp. So discarding the elements of the summation which are zero due to target labels, we can say:</p><formula xml:id="formula_7">CCE = − log e sp C j e sj</formula><p>Here ti and si are the ground truth and the CNN prediction score for each class i in all classes C, An softmax activation is applied.</p><p>To make understanding clear from now on the categorical loss will be represented as L(ŷ, y)</p><p>where y hat is the predicted label from softmax output unit for a given ground truth y. After adding the L2 regularization the loss function J has become: J(w <ref type="bibr" target="#b0">[1]</ref> , b <ref type="bibr" target="#b1">[2]</ref> , ...,</p><formula xml:id="formula_8">w [L] , b [L] ) = 1 m n 1 L(ŷ, y) + λ 2m L 1 W [L] 2</formula><p>The extra term λ 2m</p><formula xml:id="formula_9">L 1 W [L] 2</formula><p>is the L2 weight regularizer. W is a weight vector of dimensions (n[L-1], n[L]) where n[L-1] and n[L] is the number of hidden unit in the L-1 th and Lth layer of the deep network. So the weight decay is now applied so that overfitting doesn't occur. The reason behind this deep network is to ensure not to under-fit the network. I used a 7-10 layer deep network, it was getting 90% to 92% accurate in 20 epochs. So adding more layers has made the architecture more prone to learning intricate features that it hasn't learnt before.</p><p>As this is turning out to be a very deep network I also added a dropout with the rate of 50% in the second hidden layer. Experiments are made and it is seen that between 20-80% dropout rate of 50% worked the best for this problem. The result after 11 epochs is shown in the Result Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Result</head><p>In the following figure   Below is the confusion matrix of 84 classes of Bengali character predictions. You can also see all the precision, recall, f1-score for each category in the following link. https://bit.ly/akhcrnetreport-csv</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 5: Confusion Matrix</head><p>Here Precision is the ratio of correctly predicted positive observations in Bengali characters to the total positive predictions. The question that this metric answer is of all characters that labeled as some label, how many of them is actually that label? The high precision always relates to the low false positive rate. We have got about 0.97 (avg over 84 class examples) precision which is pretty good for a hand character recognizer. The report for each class can be seen following the link https://bit.ly/akhcrnetreport-csv.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>precision =</head><p>T P (T P + F P ) Recall (Sensitivity) -Recall is the ratio of correctly predicted positive observations to the all observations in actual class -yes. The question recall answers is: Of all the characters that truly that label, how many did we label? We have got recall of 0.97 which is good for this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>recall =</head><p>T P (T P + F N ) F1 score -F1 Score is calculated by the weighted average of precision and recall. Therefore, this score takes into account both false positives and false negatives. Intuitively it is not as easy to understand as accuracy, but f1-score can be more useful than accuracy, as we have an some-what uneven class distribution. Accuracy works best when the false positives and false negatives have the similar cost. If the cost of false positives and false negatives are very different, its better to look at both Precision and Recall. In our case, F1 score is 0.97 (avg). The f1-score for each class can be seen following the link https://bit.ly/akhcrnetreport-csv. The Saha and Saha paper did the ensemble of CNN, with two CNN architecture, each of which had the accuracy 95.67% and 92.43% respectively, but AKHCRNet model was able to achieve the accuracy of 96.80%. The code and the weight file is available for download here:</p><formula xml:id="formula_10">f 1 − score = 2 * (</formula><p>https://www.github.com/theroyakash/AKHCRNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">The Conclusion and Future Scope</head><p>AKHCRNet model was able to achieve the accuracy of 96.80% on the BanglaLekha-Isolated Dataset of 166K images, Without ensembling, without transfer learning and with a minimal number of epochs our proposed solution achieves state of the art result on Bengali Handwritten character recognition.</p><p>AKHCRNet's custom very deep neural architecture trains on a hard and large dataset from scratch without transfer learning and achieves a 96.8% accuracy with just 11 epochs. The success of this architecture could make possible other indic (Indic is an adjective that refers to the Indo-Aryan languages) character classification easier.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Class 1 Image before resize and after</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Class 80 image resized before &amp; after 4 Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure- 4</head><label>4</label><figDesc>epoch by epoch validation loss and accuracy is shown. Clearly no sign of overfitting can be seen, the overall accuracy is 96.80% in 11 epochs which is a monumental jump from previous 500 epoch CNN ensemble training by Saha and Saha et al. and 47 epoch training by K Chatterjee et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( a )</head><label>a</label><figDesc>Validation loss over time (b) Validation accuracy over time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>validation accuracy and loss with each passing iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>5</head><label></label><figDesc>Training, Learning rate scheduling, Optimization</figDesc><table><row><cell cols="4">The Adam Optimizer algorithm is used for this architecture, with no change to</cell></row><row><cell cols="2">the default hyper-parameters</cell><cell></cell><cell></cell></row><row><cell></cell><cell>α = 1e − 3</cell><cell></cell><cell></cell></row><row><cell></cell><cell>β 1 = 0.9</cell><cell></cell><cell></cell></row><row><cell></cell><cell>β 2 = 0.999</cell><cell></cell><cell></cell></row><row><cell></cell><cell>= 1e − 8</cell><cell></cell><cell></cell></row><row><cell cols="4">and instead of using a automated learning rate scheduler I've manually tweaked</cell></row><row><cell cols="3">the learning rate epoch by epoch. Here is how that goes:</cell><cell></cell></row><row><cell>Epochs</cell><cell cols="3">Set Learning rate Accuracy achieved Cross Entropy Loss</cell></row><row><cell>First 5 Epochs</cell><cell>0.001</cell><cell>95.11%</cell><cell>0.30081</cell></row><row><cell>Next 3 Epochs</cell><cell>0.0001</cell><cell>96.79%</cell><cell>0.22147</cell></row><row><cell>Last 3 Epochs</cell><cell>0.00004</cell><cell>96.80%</cell><cell>0.21612</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Bengali handwritten character classification using transfer learning on deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swagato</forename><surname>Chatterjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.11133</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Design of a Nearest Neighbour Classifier System for Bengali Character Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IETE Journal of Research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">226229</biblScope>
			<date type="published" when="1984-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A high performance domain specific OCR for Bangla script</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasnat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Habib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Novel Algorithms and Techniques In Telecommunications, Automation and Industrial Electronics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page">174178</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Handwritten Bangla Numeral Recognition System and Its Application to Postal Automation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">99107</biblScope>
			<date type="published" when="2007-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An improved feature descriptor for recognition of handwritten Bangla alphabet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nibaran</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.05497</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">L2 regularization for learning kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.2653</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bengali handwritten character recognition using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Purkaystha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Islam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 20th International Conference of Computer and Information Technology (ICCIT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">MNIST handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bangla handwritten character recognition using convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Akhand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Shill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rahman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Image, Graphics and Signal Pro-cessing (IJIGSP)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4249</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Isolated Bangla handwritten character recognition with convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A R</forename><surname>Alif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">16</biblScope>
		</imprint>
		<respStmt>
			<orgName>Computer and Information Technology (ICCIT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Bangla Handwritten Character Recognition using Convolutional Neural Network with Data Augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rumman</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raihan</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sazzad</forename><surname>Hossain</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIEV.2019.8858545</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BanglaLekha-Isolated: A multi-purpose comprehensive dataset of Handwritten Bangla Isolated characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Biswas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data in Brief</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">103107</biblScope>
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Introducing the Boise State Bangla Handwriting Dataset and an Efficient Offline Recognizer of Isolated Bangla Characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H B</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">380385</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Lightning fast approach to classify Bangla Handwritten Characters and Numerals using newly structured Deep Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page">17601770</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
