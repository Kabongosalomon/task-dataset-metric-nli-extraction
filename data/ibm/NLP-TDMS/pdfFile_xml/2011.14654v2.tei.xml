<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Feature Space Singularity for Out-of-Distribution Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiwen</forename><surname>Huang</surname></persName>
							<email>haiwen.huang2@cs.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihan</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lulu</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">MEGVII Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sishuo</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
							<email>dongbin@math.pku.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Beijing International Center for Mathematical Research</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Institute for Artificial Intelligence and Center for Data Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">MEGVII Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Feature Space Singularity for Out-of-Distribution Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Out-of-Distribution (OoD) detection is important for building safe artificial intelligence systems. However, current OoD detection methods still cannot meet the performance requirements for practical deployment. In this paper, we propose a simple yet effective algorithm based on a novel observation: in a trained neural network, OoD samples with bounded norms well concentrate in the feature space. We call the center of OoD features the Feature Space Singularity (FSS), and denote the distance of a sample feature to FSS as FSSD. Then, OoD samples can be identified by taking a threshold on the FSSD. Our analysis of the phenomenon reveals why our algorithm works. We demonstrate that our algorithm achieves state-of-the-art performance on various OoD detection benchmarks. Besides, FSSD also enjoys robustness to slight corruption in test data and can be further enhanced by ensembling. These make FSSD a promising algorithm to be employed in real world. We release our code at https://github.com/megvii-research/FSSD_OoD_Detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Empirical risk minimization fits a statistical model on a training set which is independently sampled from the data distribution. As a result, the yielded model is expected to generalize to in-distribution data drawn from the same distribution. However, in real applications, it is inevitable for a model to make predictions on Out-of-Distribution (OoD) data instead of in-distribution data on which the model is trained. This can lead to fatal errors such as over-confident or ridiculous predictions <ref type="bibr" target="#b9">(Hein, Andriushchenko, and Bitterwolf 2018;</ref><ref type="bibr" target="#b34">Rabanser, Günnemann, and Lipton 2019)</ref>. Therefore, it is crucial to understand the uncertainty of models and automatically detect OoD data. In applications like autonomous driving and medical services, if the model knows what it does not know, human intervention can be sought and security can be significantly improved.</p><p>Consider one particular example of OoD detection: some high-quality human face images are given as in-distribution data (training set for OoD detector), and we are interested in filtering out non-faces and low quality faces from a large Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International <ref type="bibr">(CC BY 4.0)</ref> pool of data in the wild (test set) in order to ensure reliable prediction. One natural solution is to remove test samples far from the training data in some designated distances <ref type="bibr" target="#b22">(Lee et al. 2018b;</ref><ref type="bibr" target="#b38">van Amersfoort et al. 2020</ref>). However, calculating the distance to the whole training set needs a formidable amount of computation without some special design in feature and architecture, e.g., training a RBF network <ref type="bibr" target="#b38">(van Amersfoort et al. 2020)</ref>. In this paper, we present a simple yet effective distance-based solution, which neither computes the distance to the training data nor performs extra model training than a standard classifier.</p><p>Our approach is based on a novel observation about OoD samples:</p><p>In a trained neural network, OoD samples with bounded norms well concentrate in the feature space of the neural network. In <ref type="figure">Figure 1</ref>, we show an example where OoD features from ImageNet <ref type="bibr" target="#b35">(Russakovsky et al. 2015)</ref> concentrate in a neural network trained on the facial dataset MS-1M <ref type="bibr" target="#b6">(Guo et al. 2016)</ref>. <ref type="figure" target="#fig_1">Figure 2</ref> and 3 provide more examples of this phenomenon. In fact, we find this phenomenon to be universal in most training configurations for most datasets.</p><p>To be more precise, for a given feature extractor F θ trained on in-distribution data, the observation states that there exists a point F * in the output space of F θ such that F θ (x) − F * is small for x ∈ X OoD , where X OoD is the set of OoD samples. We call F * the Feature Space Singularity (FSS). Moreover, we discover the FSS Distance (FSSD)</p><formula xml:id="formula_0">FSSD (x) := F θ (x) − F *<label>(1)</label></formula><p>can reflect the degree of OoD, and thus can be readily used as a metric for OoD detection. Our analysis demonstrates that this phenomenon can be explained by the training dynamics. The key observation is that FSSD can be seen as an approximate movement of F θt (x) during training, where F * is the initial concentration point of the features. The difference in the moving speed dF θ t (x) dt stems from the different similarity to the training data measured by the inner product of the gradients. Moreover, this similarity measure varies according to the architecture of the feature extractor.</p><p>We demonstrate the effectiveness of our proposed method with multiple neural networks (LeNet (LeCun and Cortes  ) with varying training set sizes. We show that FSSD achieves state-of-the-art performance on almost all the considered benchmarks. Moreover, the performance margin between FSSD and other methods increases as the size of the training set increases. In particular, on large-scale benchmarks (CelebA and MS-1M), FSSD advances the AU-ROC by about 5%. We also evaluate the robustness of our algorithm when test images are corrupted. We find that our algorithm can still reliably detect OoD samples under this circumstance. Finally, we investigate the effects of ensembling FSSDs from different layers of a single neural network and multiple trained netowrks.</p><p>We summarize our contributions as follows.</p><p>• We observe that in feature spaces of trained networks OoD samples concentrate near a point (FSS), and the distance from a sample feature to FSS (FSSD) measures the degree of OoD (Section 1).</p><p>• We analyze the concentration phenomenon by analyzing the dynamics of in-distribution and OoD features during training (Section 2).</p><p>• We introduce the FSSD algorithm (Section 3) which achieves state-of-the-art performance on various OoD detection benchmarks with considerable robustness (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyzing and Understanding the Concentration Phenomenon</head><p>In this section, we analyze the concentration phenomenon.</p><p>The key observation is that during training, the features of the training data are supervised to move away from the initial point, and the moving speeds of features of other data depend on their similarity to the training data. Specifically, this similarity is measured by the inner product of the gradients. Therefore, data that are dissimilar to the training data will move little and concentrate in the feature space. This is how FSSD identifies OoD data. To see this, we derive the training dynamics of the feature vectors. We denote F θ : R a → R b as the feature extractor which maps inputs to features and G φ : R b → R c to be the map from features to outputs. The two mappings are parameterized by θ and φ respectively. The corresponding loss function can be denoted as</p><formula xml:id="formula_1">L φ (F θ (x 1 ) , · · · , F θ (x M )). A popular choice is L φ (F θ (x 1 ) , · · · , F θ (x M )) = M m=1 (G φ (F θ (x m )) , y m ) /M ,</formula><p>where is the cross entropy loss or the mean squared error. Then, the gradient descent dynamics of θ is</p><formula xml:id="formula_2">dθ t dt = − ∂ L φ ∂ θ t (F θt (x 1 ) , · · · , F θt (x M )) = − M m=1 ∂ F θt (x m ) T ∂ θ t ∂ m L φ ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">∂ m L φ = ∂ L φ ∂ F θ t (xm) ∈ R b</formula><p>is the backward propagation gradient and subscript t is the training time. The dynamics of the feature extractor F θ as a function is therefore  From Equation <ref type="formula" target="#formula_4">(3)</ref>, we can see that the relative moving speed of the feature F θt (x) depends on the inner product of the gradient on parameters between x and the training data x m . Note here ∂ m L φ is the same for all x. Since FSSD defined in Equation 1 can be seen as the integration of</p><formula xml:id="formula_4">dF θt (x) dt = ∂ F θt (x) ∂ θ t dθ t dt = − M m=1 ∂ F θt (x) ∂ θ t ∂ F θt (x m ) T ∂ θ t ∂ m L φ .<label>(3)</label></formula><formula xml:id="formula_5">dF θ t (x) dt</formula><p>when the initial value F θ0 (x) is F * for all x, FSSD(x) will also be small when the derivative, i.e., the moving speed, is small.</p><p>In <ref type="figure" target="#fig_1">Figure 2</ref>, we show both the features and their moving speeds of in-distribution and OoD data at different steps during training. We can see that although in-distribution and OoD data are indistinguishable at step 0, they are quickly separated since the moving speeds of in-distribution data are larger than those of OoD data <ref type="figure" target="#fig_1">(Figure 2(b)</ref>) and thus the accumulated movements of in-distribution data are also larger than those of OoD data <ref type="figure" target="#fig_1">(Figure 2(a)</ref>). In <ref type="figure">Figure 3</ref>, we show examples of the initial concentration of features in LeNet and ResNet-34 for MNIST vs. FashionMNIST and CIFAR10 vs. SVHN dataset pairs respectively. Empirically, we find the concentration of both in-distribution and OoD features at the initial stage to be the common case for most popular architectures using random initialization. We show more examples on our Github page.</p><p>As we've mentioned, Equation (3) demonstrates that the difference in the moving speed of F θt (x) stems from differ-</p><formula xml:id="formula_6">ence in Θ t (x, x m ) := ∂ F θ t (x) ∂ θt ∂ F θ t (xm) T ∂ θt</formula><p>. We want to further point out that Θ t (x, x m ) is effectively acting as a kernel that measures the similarity between x and x m . In fact, when the network width is infinite, Θ t (x, x m ) will converge to a time-independent term Θ(x, x m ), which is called neural tangent kernel (NTK) <ref type="bibr" target="#b15">(Jacot, Gabriel, and Hongler 2018;</ref><ref type="bibr" target="#b4">Cao and Gu 2020)</ref>. In this way, FSSD can be seen as a kernel regression result:</p><formula xml:id="formula_7">FSSD (x) F * ≈ F θ0 (x) Equation (1) F θt (x) − F θ0 (x) = M m=1 T 0 Θ t (x, x m ) ∂ m L φ dt ≈ M m=1 Θ (x, x m ) ν m ,<label>(4)</label></formula><formula xml:id="formula_8">where ν m = T 0 ∂ m L φ dt.</formula><p>This indicates that the similarity described by the inner</p><formula xml:id="formula_9">product Θ t (x, x m ) := ∂ F θ t (x) ∂ θt ∂ F θ t (xm) T ∂ θt</formula><p>might enjoy similar properties to commonly used kernels such as RBF kernel, which diminishes as the distance between x and x m increases. Moreover, since the neural tangent kernel depends on the neural architecture, this kernel interpretation also suggests that feature extractors of different architectures, including different layers, can have different properties and measure different aspects of the similarity between x and x m . We can see this more clearly later in the investigation of FSSD in different layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our Algorithm</head><p>Based on this phenomenon, we can now construct our OoD detection algorithm. Since the uniform noise input can be </p><formula xml:id="formula_10">F θ0 (x) at initialization. More- over, F * ≈ F θ0 (x) for x ∈ X OoD ∪ X in-dist .</formula><p>considered to possess the highest degree of OoD, we use the center of their features as the FSS F * . The FSSD can then be calculated using Equation <ref type="formula" target="#formula_0">(1)</ref>. Note this calculation of FSS F * is independent from the choice of in-distribution and OoD datasets. When such natural choice of uniform noise is unavailable, we can choose FSS F * to be the center of features of OoD validation data instead.</p><p>Since a single forward-pass computation through the network can give us features from each layer, it is also convenient to calculate FSSDs from different layers and ensemble them as FSSD-Ensem (x) = K k=1 α k FSSD (k) (x). The ensemble weights α k can be determined using logistic regression on some validation data as in <ref type="bibr" target="#b22">(Lee et al. 2018b</ref>) (see Evaluation section in Experiments). In later experiments, if not specified, we use the ensembled FSSD from all layers. We note that it is also possible to ensemble FSSDs from different architectures or multiple training snapshots <ref type="bibr" target="#b40">(Xie, Xu, and Zhang 2013;</ref><ref type="bibr" target="#b14">Huang et al. 2017</ref>). This may further enhance the performance of OoD detection. We investigate the effect of ensembling in the next section.</p><p>Beside, we also adopt input pre-processing as in <ref type="bibr" target="#b25">(Liang, Li, and Srikant 2018;</ref><ref type="bibr" target="#b22">Lee et al. 2018b</ref>) . The idea is to add small perturbations to the test samples in order to increase the in-distribution score. It is shown in <ref type="bibr" target="#b25">(Liang, Li, and Srikant 2018;</ref><ref type="bibr" target="#b15">Kamoi and Kobayashi 2020</ref>) that indistribution data are more sensitive to such perturbation and it can therefore enlarge the score gap between in-distribution and OoD samples. In particular, we perturb asx = x + sign (∇ x FSSD (x)) and take FSSD (x) as the final score. We present the pseudo-code of computing FSSD-Ensem (x) in Algorithm 1. for each feature extractor F (k)</p><formula xml:id="formula_11">K k=1 do 1. Estimate FSS F * (k) = S s=1 F (k) x noise s /S, where x noise s ∼ U[0, 1], s = 1, · · · , S 2. Add perturbation to test sample: x = x + sign(∇ x F (k) (x) − F * (k) ) 3. Calculate FSSD (k) (x) = F (k) (x) − F * (k) end Return FSSD-Ensem (x) = K k=1 α k FSSD (k) (x)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we investigate the performance of our FSSD algorithm on various OoD detection benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>Benchmarks To conduct a thorough test of our method, we consider a wide variety of OoD detection benchmarks. In particular, we consider different scales of datasets and different types of data. We consider different scales of datasets because large scale datasets tend to have more classes which can introduce more ambiguous data. The ambiguous data are of high classification uncertainty, but are not out-ofdistribution. We list the benchmarks in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>We first consider two common benchmarks from previ- They are known to be challenging for many methods <ref type="bibr" target="#b30">Nalisnick et al. 2019a</ref>). (C) We also construct ImageNet (dogs), a subset of ImageNet <ref type="bibr" target="#b35">(Russakovsky et al. 2015)</ref> , as in-distribution data. The OoD data are non-dog images from ImageNet.</p><p>For large-scale problems, we consider three benchmarks. (D) We train models on ImageNet and detect corrupted images from the ImageNet-C dataset . We test each method on 80 sets of corruptions (16 types and 5 levels). (E) We train models on face images without the "blurry" attribute from CelebA  and detect face images with the "blurry" attribute. (F) We train models on web images of celebrities from MS-Celeb-1M (MS-1M) <ref type="bibr" target="#b6">(Guo et al. 2016</ref>) and detect video captures from IJB-C <ref type="bibr" target="#b28">(Maze et al. 2018</ref>) which in general have lower quality due to pose, illumination, and resolution issues. We also consider (G) the bacteria genome benchmark introduced by , which consists of sequence data.</p><p>To train models on in-distribution datasets, we follow previous works <ref type="bibr" target="#b22">(Lee et al. 2018b</ref>) to train LeNet on FMNIST and ResNet with 34 layers on CIFAR10, ImageNet, and Ima-geNet (dogs). For two face recognition datasets (CelebA and MS-1M), we train ResNeXt with 50 layers. For the genome sequence dataset, we use an character embedding layer and two Bidirectional LSTM layers <ref type="bibr" target="#b37">(Schuster and Paliwal 1997)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compared methods</head><p>We compare our method with the following six common methods for OoD detection. Base: the baseline method using the maximum softmax probability p (ŷ|x) <ref type="bibr" target="#b11">(Hendrycks and Gimpel 2017)</ref>. ODIN: temperature scaling on logits and input pre-processing <ref type="bibr" target="#b25">(Liang, Li, and Srikant 2018)</ref>. Maha: Mahalanobis distance of the sample feature to the closest class-conditional Gaussian distribution which is estimated from the training data <ref type="bibr" target="#b22">(Lee et al. 2018b</ref>). In our experiments, we follow <ref type="bibr" target="#b22">(Lee et al. 2018b</ref>) to use both feature (layer) ensemble and input pre-processing. DE: Deep Ensemble which averages the softmax probability predictions from multiple independently trained classifiers <ref type="bibr" target="#b18">(Lakshminarayanan, Pritzel, and Blundell 2017)</ref>. In our experiments, we take the average of 5 classifiers by default. MCD: Monte-Carlo Dropout that uses dropout during both training and inference <ref type="bibr" target="#b5">(Gal and Ghahramani 2016)</ref>. We follow <ref type="bibr" target="#b33">(Ovadia et al. 2019)</ref> to dropout convolutional layers. For OoD detection, we calculate both the mean and the variance of 32 independent predictions and choose the better one to report. OE: Outlier exposure that explicitly enforces uniform probability prediction on an auxiliary dataset of outliers <ref type="bibr" target="#b12">(Hendrycks, Mazeika, and Dietterich 2019</ref>  <ref type="bibr" target="#b35">Ren et al. 2019;</ref><ref type="bibr" target="#b25">Liang, Li, and Srikant 2018)</ref> to use a separate validation set, which consists of 1,000 images from each in-distribution and OoD data pair. Ensemble weights α k for FSSD from different layers are extracted from a logistic regression model, which is trained using nested cross validation within the validation set as in <ref type="bibr" target="#b22">(Lee et al. 2018b;</ref><ref type="bibr" target="#b27">Ma et al. 2018)</ref>. The same procedure is performed on Maha for fair comparison. The perturbation magnitude of input pre-processing for ODIN, Maha, and FSSD is searched from 0 to 0.2 with step size 0.01. The temperature T of ODIN is chosen from 1, 10, 100, and 1000, and the dropout rate of MCD is chosen from 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, and 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main results</head><p>The main results are presented in <ref type="table" target="#tab_4">Table 2</ref> and <ref type="figure" target="#fig_4">Figure 4</ref>. In <ref type="table" target="#tab_4">Table 2</ref>, we can see that larger datasets entail greater difficulty in OoD detection. Notably, the advantage of FSSD over other methods increases as the dataset size increases. Other methods like Maha and OE perform well on some small benchmarks, but have large variance across different datasets. In comparison, FSSD maintains great performance on these benchmarks. On the genome sequence dataset, we also observe that FSSD outperforms other methods. These results show that FSSD is a promising effective method for a wide range of applications.</p><p>Inspired by <ref type="bibr" target="#b33">(Ovadia et al. 2019)</ref>, we also evaluate the methods on the ability of detecting distributional dataset shift like Gaussian noise and JPEG artifacts. <ref type="figure" target="#fig_4">Figure 4</ref> shows the means and quartiles of AUROC of the compared methods over 16 types of corruptions on 5 corruption levels. We can observe that for each method, the performance of OoD detection increases as the level of corruption increases, while FSSD enjoys the highest AUROC and much less variation over different types of corruptions. The CelebA benchmark also evaluates the methods on detecting the dataset shift of the attribute "blurry". However, all methods including FSSD do not perform very well. There are two possible reasons: (1) the attribute "blurry" of CelebA may be annotated not clearly enough; (2) the blurs in the wild may be more difficult to detect than the simulated blurs in ImageNet-C. Overall, we can see that FSSD can more reliably detect different kinds of distributional shifts.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness</head><p>In practice, it is possible that the test data are slightly corrupted or shifted due to the change of data source, e.g., from lab to real world. We evaluate the ability to distinguish in-distribution data from OoD data when test data (both in-distribution and OoD) are slightly corrupted. Note that we still use non-corrupted data during network training and hyper-parameter tuning. We apply Gaussian noise and impulse noise, two typical corruptions, with varying levels. Test results on CIFAR10 vs. SVHN and ImageNet dogs vs. non-dogs are shown in <ref type="figure" target="#fig_5">Figure 5</ref>. We can see that FSSD is robust to corruptions presented in test images, while other methods may degrade.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of ensemble</head><p>During our experiments, we find that the ensemble plays an important role in enhancing the performance of FSSD. Previous studies show that an important issue for ensemblebased algorithms is enforcing diversity <ref type="bibr" target="#b18">(Lakshminarayanan, Pritzel, and Blundell 2017)</ref>. In our case, we find that FSSD  has high diversity across different layers, and benefit from such diversity to reach higher performance. In <ref type="figure">Figure 6</ref>, we find that FSSD in different layers are working differently. This can be explained by previous works on understanding neural networks by visualizing the different representations learned by low and deep layers of a neural network <ref type="bibr" target="#b42">(Zeiler and Fergus 2014;</ref><ref type="bibr" target="#b43">Zhou et al. 2015)</ref>. Generally, FSSDs from deep layers reflect more high-level features and FSSDs from early layers reflect more low-level statistics. ImageNet (dogs) and ImageNet (non-dogs) are from the same dataset (ImageNet), and are therefore similar in terms of low-level statistics; while the differences between CIFAR10 and SVHN are in all different levels. From the perspective of kernel interpretation, this means that the neural tangent kernels of different layers diversify well and allow the ensemble of FSSD to capture different aspects of the dis-  crepancy between the test data and training data. We show more examples of FSSDs in different layers on our Github page. Furthermore, <ref type="figure" target="#fig_6">Figure 7</ref> demonstrates that the performance of FSSD can be further boosted by using network ensembles. Considering the low computational cost of ensembling FSSD, this shows FSSD can be a promising method in scenarios that require high-performance OoD detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out-of-distribution detection</head><p>According to different understandings of OoD samples, previous OoD detection methods can be summarized into four categories.</p><p>(1) Some methods regard OoD samples as those with uniform probability prediction across classes <ref type="bibr" target="#b9">(Hein, Andriushchenko, and Bitterwolf 2018;</ref><ref type="bibr" target="#b11">Hendrycks and Gimpel 2017;</ref><ref type="bibr" target="#b25">Liang, Li, and Srikant 2018;</ref><ref type="bibr" target="#b21">Lee et al. 2018a;</ref><ref type="bibr" target="#b8">Hein and Andriushchenko 2017;</ref><ref type="bibr" target="#b29">Meinke and Hein 2020)</ref> and treat the test samples with high entropy or low maximum prediction probability as OoD data. Since these methods are based on prediction, they run the risk of mis-classifying ambiguous data as OoD samples, e.g., when there are thousands of classes in a large-scale dataset.</p><p>(2) OoD samples can also be characterized as samples with high epistemic uncertainty which reflects the lack of information on these samples <ref type="bibr" target="#b18">(Lakshminarayanan, Pritzel, and Blundell 2017;</ref><ref type="bibr" target="#b5">Gal and Ghahramani 2016;</ref><ref type="bibr" target="#b2">Blundell et al. 2015)</ref>. Specifically, we can propagate the uncertainty of models to the uncertainty of predictions, which characterizes the level of OoD. MCD and DE are two popular choices of this type. However, it is reported that current epistemic uncertainty estimations may noticeably degrade under dataset distributional shift <ref type="bibr" target="#b33">(Ovadia et al. 2019)</ref>. Our experiments on detecting ImageNet-C from ImageNet <ref type="figure" target="#fig_4">(Figure 4</ref>) confirm this.</p><p>(3) When the density of data can be approximated, e.g., using generative models <ref type="bibr" target="#b16">(Kingma and Dhariwal 2018;</ref><ref type="bibr" target="#b36">Salimans et al. 2017)</ref>, OoD samples can be classified as those with low density. Recent works provide many inspiring insights on how to improve this idea <ref type="bibr" target="#b31">Nalisnick et al. 2019b;</ref><ref type="bibr" target="#b38">Serrà et al. 2020</ref>). However, these methods typically have extra training difficulty incurred by large generative models.</p><p>(4) There are also works designing non-Euclidean metrics to compare test samples to training samples, and regard those with higher distances to training samples as OoD samples <ref type="bibr" target="#b22">(Lee et al. 2018b;</ref><ref type="bibr" target="#b38">van Amersfoort et al. 2020;</ref><ref type="bibr" target="#b15">Kamoi and Kobayashi 2020;</ref><ref type="bibr" target="#b19">Lakshminarayanan et al. 2020)</ref>. Our approach resembles this type most. Instead of comparing test samples to training samples, we compare the features of the test samples to the center of OoD features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-Lipschitz property of neural networks</head><p>Many previous works have reported that the trained neural networks are not Lipschitz continuous <ref type="bibr" target="#b0">(Behrmann et al. 2019;</ref><ref type="bibr" target="#b38">van Amersfoort et al. 2020;</ref><ref type="bibr" target="#b19">Lakshminarayanan et al. 2020)</ref>. Some OoD detection methods claim that adding Lipschitz constraint may help improve OoD detection performance <ref type="bibr" target="#b38">(van Amersfoort et al. 2020;</ref><ref type="bibr" target="#b19">Lakshminarayanan et al. 2020)</ref>. <ref type="bibr" target="#b1">(Bietti and Mairal 2019)</ref> also demonstrated that the NTK kernel mappings of ReLU networks are non-Lipschitz.</p><p>Instead of adding Lipschitz constraint, this work utilizes the non-Lipschitz property of neural networks for OoD detection. In fact, the feature space singularity provides us with new understandings of the non-Lipschitz region in the input space, i.e., inputs that are dissimilar to the training data in terms of the NTK. In the future, it is interesting to further investigate the non-Lipschitz properties of neural networks, e.g., non-Lipschitz behaviours in different layers and how the inductive bias of NTK influences the OoD detection using FSSD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we propose a new OoD detection algorithm based on a novel observation that OoD samples concentrate in the feature space of a trained neural network. We provide analysis and understanding of the concentration phenomenon by analyzing the training dynamics both theoretically and empirically and further interpreted the algorithm with the neural tangent kernel. We demonstrate that our algorithm is state-of-the-art in detection performance and is robust to measurement noise. Our further investigation on the effect of ensemble reveals diversity in layer ensembles and shows promising performance of network ensembles. In summary, we hope that our work can provide new insights for understanding properties of neural networks and add an alternative simple and effective OoD detection method to the safe AI deployment toolkits.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The norm of the derivative, i.e., "moving speed", of last-layer feature vector at different time steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>We show first two principle components of the feature vector and the L2 norm of the derivatives (Equation(3)). Features and derivatives are calculated from the last fully-connected layer of a LeNet trained on MNIST (in-distribution). We feed in FashionMNIST data as OoD samples. At initialization, features of both in-distribution and OoD samples concentrate near FSS F * . After training, features of in-distribution samples are pulled away from FSS F * , while features of OoD samples remain close to FSS F * . Similar dynamics of the softmax layer on in-distribution data was observed by<ref type="bibr" target="#b23">(Li, Zhao, and Scheidegger 2020)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>CIFAR10 vs. SVHN Figure 3: Both in-distribution and OoD samples are clustered in the feature space of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>ous OoD detection literature (van Amersfoort et al. 2020; Ren et al. 2019): (A) FMNIST (Xiao, Rasul, and Vollgraf 2017) vs. MNIST (LeCun and Cortes 2010) and (B) CI-FAR10 (Krizhevsky 2009) vs. SVHN (Netzer et al. 2011).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Comparison of AUROC on ImageNet vs. ImageNet-C. FSSD enjoys the highest mean and the least variance across all corruption levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Comparison of OoD detection robustness among methods on slightly corrupted test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Comparison of network ensembles of Base, ODIN, Maha, and FSSD scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1 :</head><label>1</label><figDesc>Computation of FSSD-Ensem Input: Test samples x = {x test n } N n=1 , noise samples x noise</figDesc><table><row><cell>s</cell><cell cols="2">S s=1 , ensemble weights α k ,</cell></row><row><cell cols="2">perturbation magnitude ,</cell></row><row><cell cols="2">feature extractors F (k)</cell><cell>K k=1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>OoD detection benchmarks used in our experiments.</figDesc><table><row><cell></cell><cell cols="2">In-distribution</cell><cell></cell><cell>OoD</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Dataset</cell><cell>#Classes (Train/Test)</cell><cell>#Samples (Train/Test)</cell><cell>Dataset</cell><cell>#Samples (Test)</cell><cell>Data type</cell></row><row><cell>A</cell><cell>FMNIST</cell><cell>10/10</cell><cell>60k/10k</cell><cell>MNIST</cell><cell>10k</cell><cell>Image</cell></row><row><cell>B</cell><cell>CIFAR10</cell><cell>10/10</cell><cell>50k/10k</cell><cell>SVHN</cell><cell>26k</cell><cell>Image</cell></row><row><cell>C</cell><cell>ImageNet (dogs)</cell><cell>50/50</cell><cell>50k/10k</cell><cell>ImageNet (non-dogs)</cell><cell>10k</cell><cell>Image</cell></row><row><cell>D</cell><cell>ImageNet</cell><cell>1000/1000</cell><cell>1281.2k/50k</cell><cell>ImageNet-C</cell><cell>50k</cell><cell>Image</cell></row><row><cell>E</cell><cell>CelebA (not blurry)</cell><cell>10122/10122</cell><cell>153.8k/38.5k</cell><cell>CelebA (blurry)</cell><cell>10.3k</cell><cell>Image</cell></row><row><cell>F</cell><cell>MS-1M</cell><cell cols="2">64736/16184 2923.6k/50k</cell><cell>IJB-C</cell><cell>50k</cell><cell>Image</cell></row><row><cell cols="2">G Genome (before 2011)</cell><cell>10/10</cell><cell>1000k/1000k</cell><cell>Genome (after 2016)</cell><cell>6000k</cell><cell>Sequence</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>We do not evaluate OE on the sequence benchmark, since we can not find a reasonable auxiliary dataset. We remark here that Base, ODIN, and FSSD can be deployed directly with a trained neural network, MCD needs a trained neural network with dropout layers, while DE needs multiple trained classifiers. Besides, Maha needs to use the training data during OoD detection on test data and OE trains a neural network either from scratch or by fine-tuning to utilize the auxiliary dataset.</figDesc><table><row><cell>). For</cell></row><row><cell>the choice of auxiliary datsets, we use KMNIST (Clanuwat</cell></row><row><cell>et al. 2018) for benchmark A, CelebA (Liu et al. 2015) for</cell></row><row><cell>benchmark C, and ImageNet-1K (Russakovsky et al. 2015)</cell></row><row><cell>for benchmark B, E, F. Evaluation We follow (Ren et al. 2019; Hendrycks,</cell></row><row><cell>Mazeika, and Dietterich 2019) to use the following met-</cell></row><row><cell>rics to assess the performance of OoD detection. AUROC:</cell></row><row><cell>Area Under the Receiver Operating Characteristic curve.</cell></row></table><note>AUPRC: Area Under the Precision-Recall Curve. FPR80: False Positive Rate when the true positive rate is 80%. For hyper-parameter tuning, we follow (Lee et al. 2018b;</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Main results. All values are in %.</figDesc><table><row><cell></cell><cell>Datasets (Architecture)</cell><cell cols="3">Metrics Base ODIN Maha</cell><cell cols="2">DE MCD</cell><cell cols="2">OE FSSD</cell></row><row><cell></cell><cell>FMNIST vs. MNIST (LeNet)</cell><cell>AUROC 77.3 AUPRC 79.2 FPR80 43.5</cell><cell>96.9 93.0 2.5</cell><cell cols="2">99.6 83.9 99.7 83.3 0.0 27.5</cell><cell cols="2">81.7 99.6 85.3 99.6 36.8 0.0</cell><cell>99.6 99.7 0.0</cell></row><row><cell>Small-scale benchmarks</cell><cell>CIFAR10 vs. SVHN (ResNet34)</cell><cell>AUROC 89.9 AUPRC 85.4 FPR80 10.1</cell><cell>96.7 92.5 4.7</cell><cell cols="2">99.1 93.7 98.1 90.6 0.3 3.7</cell><cell cols="2">96.7 90.4 93.9 89.8 2.4 12.5</cell><cell>99.5 99.5 0.4</cell></row><row><cell></cell><cell>ImageNet dogs vs. non-dogs (ResNet34)</cell><cell>AUROC 88.5 AUPRC 86.1 FPR80 19.5</cell><cell>90.8 88.6 15.2</cell><cell cols="2">83.3 89.0 83.0 89.0 30.1 18.8</cell><cell cols="2">67.2 92.5 66.9 92.6 59.2 7.9</cell><cell>93.1 92.5 10.2</cell></row><row><cell>Large-scale</cell><cell>CelebA non-blurry vs. blurry (ResNeXt50)</cell><cell>AUROC 71.7 AUPRC 89.9 FPR80 52.0</cell><cell>73.3 91.4 50.3</cell><cell cols="2">73.9 74.5 90.9 91.4 46.0 47.1</cell><cell cols="2">69.8 71.5 88.7 90.7 53.2 54.2</cell><cell>78.3 92.8 39.2</cell></row><row><cell>benchmarks</cell><cell>MS-1M vs. IJB-C (ResNeXt50)</cell><cell>AUROC 60.0 AUPRC 53.3 FPR80 61.8</cell><cell>61.3 55.9 59.4</cell><cell cols="2">82.5 63.0 80.6 56.1 29.6 56.7</cell><cell cols="2">65.5 52.6 59.4 46.6 58.8 64.2</cell><cell>86.7 86.1 22.1</cell></row><row><cell>Sequence benchmark</cell><cell>Bacteria Genome (LSTM)</cell><cell>AUROC 69.6 AUPRC 69.9 FPR80 57.4</cell><cell>70.6 71.9 55.9</cell><cell cols="2">70.4 70.0 69.3 56.0 53.7 30.0</cell><cell>69.3 70.2 58.3</cell><cell>NA NA NA</cell><cell>74.8 75.8 47.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>FSSDs from different layers behave differently. Each row contains FSSD histograms extracted from different layers of a trained neural network. FSSDs of ImageNet (dogs) and ImageNet (non-dogs) are similar in early layers; while FSSDs of CIFAR10 and SVHN differ in all the layers. This can be explained by the fact that ImageNet (dogs) and ImageNet (non-dogs) are similar in low-level statistics since they are sampled from the same dataset, and that FSSDs in early layers capture more of the difference in low-level statistics.</figDesc><table><row><cell>0.002 0.004 0.006 0.008 0.010</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Layer 0</cell><cell cols="3">In-distribution OoD</cell><cell>0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Layer 1</cell><cell></cell><cell></cell><cell></cell><cell>0.005 0.010 0.015 0.020 0.025 0.030 0.035</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Layer 2</cell><cell></cell><cell></cell><cell></cell><cell>0.01 0.02 0.03 0.04 0.05 0.06</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Layer 3</cell><cell></cell><cell></cell><cell>0.005 0.010 0.015 0.020 0.025 0.030 0.035</cell><cell></cell><cell></cell><cell cols="2">Layer 4</cell></row><row><cell>0.000</cell><cell>100</cell><cell>150</cell><cell>200</cell><cell>250</cell><cell>300</cell><cell>350</cell><cell>400</cell><cell>450</cell><cell>0.000</cell><cell>400</cell><cell>450</cell><cell>500</cell><cell>550</cell><cell>600</cell><cell>650</cell><cell>700</cell><cell>750</cell><cell>0.000</cell><cell>100</cell><cell>120</cell><cell>140</cell><cell>160</cell><cell>180</cell><cell>200</cell><cell>220</cell><cell>240</cell><cell>0.00</cell><cell>40</cell><cell></cell><cell>50</cell><cell>60</cell><cell>70</cell><cell></cell><cell>80</cell><cell>0.000</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell><cell>120</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="16">(a) ImageNet (dogs) vs. ImageNet (non-dogs)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.08 0.10 0.12</cell><cell></cell><cell></cell><cell cols="2">Layer 0</cell><cell></cell><cell cols="2">In-distribution OoD</cell><cell></cell><cell>0.125 0.150 0.175 0.200</cell><cell></cell><cell></cell><cell></cell><cell>Layer 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.15 0.20 0.25</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Layer 2</cell><cell></cell><cell></cell><cell></cell><cell>0.3 0.4 0.5</cell><cell></cell><cell></cell><cell cols="2">Layer 3</cell><cell></cell><cell></cell><cell></cell><cell>0.08 0.10 0.12 0.14</cell><cell></cell><cell cols="2">Layer 4</cell><cell></cell></row><row><cell>0.02 0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.025 0.050 0.075 0.100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.05 0.10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1 0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.02 0.04 0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.00</cell><cell></cell><cell>10</cell><cell>20</cell><cell>FSSD</cell><cell>30</cell><cell cols="2">40</cell><cell></cell><cell>0.000</cell><cell>25</cell><cell></cell><cell>30</cell><cell>35 FSSD</cell><cell></cell><cell>40</cell><cell cols="2">45</cell><cell>0.00</cell><cell>16</cell><cell>18</cell><cell>20</cell><cell cols="2">22 FSSD 24</cell><cell>26</cell><cell>28</cell><cell>30</cell><cell>0.0</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12 FSSD</cell><cell>14</cell><cell>16</cell><cell>18</cell><cell>0.00</cell><cell cols="5">FSSD 10 15 20 25 30 35 40 45</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="8">(b) CIFAR10 vs. SVHN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Figure 6: 1 80 85 90 95 100 AUROC(%)</cell><cell cols="2">FSSD Maha ODIN Baseline</cell><cell cols="4">5 FMNIST vs MNIST 10 #Instances</cell><cell></cell><cell></cell><cell cols="2">20 100.0 99.7 89.4 79.9</cell><cell></cell><cell>AUROC(%)</cell><cell>88 90 92 94 96 98 100</cell><cell>1</cell><cell></cell><cell></cell><cell cols="5">5 CIFAR10 vs SVHN 10 #Instances</cell><cell cols="3">20 94.2 99.1 98.9 100.0</cell><cell></cell><cell>AUROC(%)</cell><cell>72 74 76 78 80</cell><cell>1</cell><cell></cell><cell cols="4">2 CelebA blur vs non-blur 3 4 #Instances</cell><cell></cell><cell>5 74.7 74.8 76.3 80.5</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>Bin Dong is supported in part by Beijing Natural Science Foundation (No. 180001); National Natural Science Foundation of China (NSFC) grant No. 11831002 and Beijing Academy of Artificial Intelligence (BAAI).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Invertible Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Jacobsen</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/behrmann19a.html" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2640" to="3498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bietti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12173</idno>
		<idno>ArXiv: 1905.12173</idno>
		<ptr target="http://arxiv.org/abs/1905.12173" />
	</analytic>
	<monogr>
		<title level="m">On the Inductive Bias of Neural Tangent Kernels</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Weight Uncertainty in Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cornebise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1613" to="1622" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">France</forename><surname>Lille</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v37/blundell15.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalization Error Bounds of Gradient Descent for Learning Over-Parameterized Deep ReLU Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Clanuwat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bober-Irizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kitamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/5736" />
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3349" to="3356" />
		</imprint>
	</monogr>
	<note>Deep Learning for Classical Japanese Literature</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v48/gal16.html" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1050" to="1059" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="DOI">http:/link.springer.com/10.1007/978-3-319-46487-9_6</idno>
		<ptr target="http://link.springer.com/10.1007/978-3-319-46487-9_6" />
	</analytic>
	<monogr>
		<title level="m">Series Title: Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">9907</biblScope>
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2016</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
		<ptr target="http://ieeexplore.ieee.org/document/7780459/" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6821-formal-guarantees-on-the-robustness-of-a-classifier-against-adversarial-manipulation.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2266" to="2276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Why ReLU Networks Yield High-Confidence Predictions Far Away From the Training Data and How to Mitigate the Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bitterwolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Benchmarking Neural Network Robustness to Common Corruptions and Perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep Anomaly Detection with Outlier Exposure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HyxCxhRcY7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="https://doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>abs/1704.00109</idno>
		<ptr target="http://arxiv.org/abs/1704.00109" />
		<title level="m">Snapshot Ensembles: Train 1, get M for free</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jacot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hongler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kamoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kobayashi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00402</idno>
		<idno>ArXiv: 2003.00402</idno>
		<ptr target="http://arxiv.org/abs/2003.00402" />
	</analytic>
	<monogr>
		<title level="m">Neural Tangent Kernel: Convergence and Generalization in Neural Networks</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="8571" to="8580" />
		</imprint>
	</monogr>
	<note>Why is the Mahalanobis Distance Effective for Anomaly Detection</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions.pdf" />
	</analytic>
	<monogr>
		<title level="m">Glow: Generative Flow with Invertible 1x1 Convolutions</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="10215" to="10224" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6402" to="6413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Padhy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<title level="m">MNIST handwritten digit database URL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Training Confidence-calibrated Classifiers for Detecting Outof-Distribution Samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ryiAv2xAZ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7167" to="7177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Visualizing Neural Networks with the Grand Tour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<idno>doi:10.23915/ distill.00025</idno>
		<ptr target="Https://distill.pub/2020/grand-tour" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8168" to="8177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1VGkIxRZ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep Learning Face Attributes in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schoenebeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1gJ1L2aW" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">IARPA Janus Benchmark -C: Face Dataset and Protocol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Niggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Grother</surname></persName>
		</author>
		<idno>978-1-5386-4285-6. doi:10. 1109/ICB2018.2018.00033</idno>
		<ptr target="https://ieeexplore.ieee.org/document/8411217/" />
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on Biometrics (ICB)</title>
		<meeting><address><addrLine>Gold Coast, QLD</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="158" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards neural networks that provably know when they don&apos;t know</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Meinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ByxGkySKwH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Do Deep Generative Models Know What They Don&apos;t Know?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1xwNhCcYm" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reading Digits in Natural Images with Unsupervised Feature Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf" />
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Can You Trust Your Model&apos;s Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rabanser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Alché-Buc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/8420-failing-loudly-an-empirical-study-of-methods-for-detecting-dataset-shift.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1396" to="1408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Likelihood Ratios for Out-of-Distribution Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Poplin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Depristo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Alché-Buc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-015-0816-y</idno>
		<ptr target="http://papers.nips.cc/paper/9611-likelihood-ratios-for-out-of-distribution-detection.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="211" to="252" />
		</imprint>
	</monogr>
	<note>ImageNet Large Scale Visual Recognition Challenge</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bidirectional Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Paliwal</surname></persName>
		</author>
		<idno type="DOI">10.1109/78.650093</idno>
		<ptr target="https://doi.org/10.1109/78.650093" />
	</analytic>
	<monogr>
		<title level="j">Trans. Sig. Proc</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Input Complexity and Outof-distribution Detection with Likelihood-based Generative Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serrà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Álvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Slizovskaia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Núñez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SyxIWpVYvr" />
	</analytic>
	<monogr>
		<title level="m">Simple and Scalable Epistemic Uncertainty Estimation Using a Single Deep Deterministic Neural Network</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<title level="m">Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Horizontal and Vertical Ensemble with Deep Representation for Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Aggregated Residual Transformations for Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.634</idno>
		<ptr target="http://ieeexplore.ieee.org/document/8100117/" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Honolulu, HI</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-10590-1_53</idno>
		<idno>date: 06-09-2014 Through 12-09-2014</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, ECCV 2014 -13th European Conference, Proceedings, number PART 1 in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
	<note>13th European Conference on Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Object Detectors Emerge in Deep Scene CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
