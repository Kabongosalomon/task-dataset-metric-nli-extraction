<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Negative Margin Matters: Understanding Margin in Few-shot Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Negative Margin Matters: Understanding Margin in Few-shot Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces a negative margin loss to metric learning based few-shot learning methods. The negative margin loss significantly outperforms regular softmax loss, and achieves state-of-the-art accuracy on three standard few-shot classification benchmarks with few bells and whistles. These results are contrary to the common practice in the metric learning field, that the margin is zero or positive. To understand why the negative margin loss performs well for the few-shot classification, we analyze the discriminability of learned features w.r.t different margins for training and novel classes, both empirically and theoretically. We find that although negative margin reduces the feature discriminability for training classes, it may also avoid falsely mapping samples of the same novel class to multiple peaks or clusters, and thus benefit the discrimination of novel classes. Code is available at https://github.com/bl0/negative-margin.few-shot.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent success on visual recognition tasks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b1">2]</ref> heavily relies on the massive-scale manually labeled training data, which is too expensive in many real scenarios. In contrast, humans are capable of learning new concepts with only a few examples, yet it still remains a challenge for modern machine learning systems. Hence, learning to generalize the knowledge in base classes (with sufficient annotated examples) to novel classes (with a few labeled examples), also known as few-shot learning, has attracted more and more attention <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>An important direction of few-shot classification is meta learning, which aims to learn a meta-learner on base classes and generalizes it to novel classes. Metric learning based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25]</ref>, are an important series of the meta-learning methods, and perform metric learning in the base classes and then transfer the learned metrics to the novel classes. For example, <ref type="bibr" target="#b2">[3]</ref> proved that simply using standard softmax loss or cosine softmax loss for learning metrics in base classes can achieve the state-of-the-art few-shot classification performance via learning a linear classifier on novel classes.</p><p>In the metric learning area, a common view is that the standard softmax loss is insufficient for discrimination on different training classes. Several previous † Equal contribution. * The work is done when Yutong Lin is an intern at MSRA.  <ref type="figure">Fig. 1</ref>. The one-shot and five-shot accuracy on novel classes (in red) and base classes (in blue) w.r.t different margins in cosine softmax loss on mini-ImageNet. As we expect, applying larger margin to softmax loss can achieve better accuracy on base classes. But surprisingly, applying appropriate negative margin to softmax loss can achieve state-of-the-art few-shot accuracy on novel classes.</p><p>approaches integrate the large and positive margin to the softmax loss <ref type="bibr" target="#b21">[22]</ref> or the cosine softmax loss <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b47">48]</ref> so as to enforce the score of ground truth class larger than that of other classes by at least a margin. This could help to learn highlydiscriminative deep features and result in remarkable performance improvement on visual recognition tasks, especially on face recognition <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b47">48]</ref>. Consequently, it inspires us to adopt this large-margin softmax loss to learn better metrics for few-shot classification. As we expected, shown as the blue curves in <ref type="figure">Fig. 1</ref>, the metrics learned by large-margin softmax with positive margin are more discriminative on training classes, resulting in higher few-shot accuracy on the validation set of training classes. But in the standard open-set setting of few-shot classification, shown as red curves in <ref type="figure">Fig. 1</ref>, we surprisingly find out that adding the positive margin in softmax loss would hurt the performance.</p><p>From our perspective, the positive margin would make the learned metrics more discriminative to training classes. But for novel classes, positive margin would map the samples of the same class to multiple peaks or clusters in base classes (shown in <ref type="figure">Fig. 3</ref> and <ref type="figure" target="#fig_10">Fig. 7</ref>) and hurt their discriminability. We then give a theoretical analysis that the discriminability of the samples in the novel classes is monotonic decreasing w.r.t the margin parameter under proper assumption. Instead, appropriate negative margin could achieve a better tradeoff between the discriminability and transferability for novel classes, and achieves better performance on few-shot classification.</p><p>The main contributions of this paper are summarized as follows:</p><p>1. This is the first endeavor to show that softmax loss with negative margin works surprisingly well on few-shot classification, which breaks the inherent understanding that margin can only be limited to positive values <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b47">48]</ref>. 2. We provide insightful intuitive explanation and the theoretical analysis about why negative margin works well for few-shot classification. 3. The proposed approach with negative margin achieves state-of-the-art performance on three widely-used few-shot classification benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Few-Shot Classification. The existing representative few-shot learning methods can be broadly divided into three categories: gradient-based methods, hallucination-based methods, and metric-based methods. Gradient-based methods tackle the few-shot classification by learning the task-agnostic knowledge. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b26">27]</ref> focus on learning a suitable initialization of the model parameters which can quickly adapt to new tasks with a limited number of labeled data and a small number of gradient update steps. Another line of works aims at learning an optimizer, such as LSTM-based meta learner <ref type="bibr" target="#b36">[37]</ref> and weight-update mechanism with an external memory <ref type="bibr" target="#b27">[28]</ref>, for replacing the stochastic gradient descent optimizer. However, it is challenging to solve the dual or bi-level optimization problem of these works, so their performance is not competitive on large datasets. Recently, <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b0">1]</ref> alleviate the optimization problem by closed-form model like SVM, and achieve better performance on few-shot classification benchmark of large dataset.</p><p>Hallucination-based methods attempt to address the limited data issue by learning an image generator from base classes, which is adopted to hallucinate new images in novel classes <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b48">49]</ref>. <ref type="bibr" target="#b11">[12]</ref> presents a way of hallucinating additional examples for novel classes by transferring modes of variation from base classes. <ref type="bibr" target="#b48">[49]</ref> learns to hallucinate examples that are useful for classification by the endto-end optimization of both classifier and hallucinator. As hallucination-based methods can be considered as the supplement and are always adopted with other few-shot methods, we follow <ref type="bibr" target="#b2">[3]</ref> to exclude these methods in our experimental comparison and leave it to future work.</p><p>Metric-based methods aim at learning a transferable distance metric. Match-ingNet <ref type="bibr" target="#b45">[46]</ref> computes cosine similarity between the embeddings of labeled images and unlabeled images, to classify the unlabeled images. ProtoNet <ref type="bibr" target="#b42">[43]</ref> represents each class by the mean embedding of the examples inside this class, and the classification is performed based on the distance to the mean embedding of each class. RelationNet <ref type="bibr" target="#b43">[44]</ref> replaces the non-parametric distance in ProtoNet to a parametric relation module. Recently, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25]</ref> reveal that the simple pre-training and fine-tuning pipeline (following the standard transfer learning paradigm) can achieve surprisingly competitive performance with the state-of-the-art few-shot classification methods.</p><p>Based on this simple paradigm, our work is the first endeavor towards explicitly integrating the margin parameter to the softmax loss, and mostly importantly breaks the inherent understanding that the margin can be only restricted as positive values, with both intuitive understanding and theoretical analysis. With an appropriate negative margin, our approach could achieve the state-ofthe-art performance on three standard few-shot classification benchmarks.</p><p>Margin based Metric Learning. Metric learning aims to learn a distance metric between examples, and plays a critical role in many tasks, such as classification <ref type="bibr" target="#b49">[50]</ref>, clustering <ref type="bibr" target="#b51">[52]</ref>, retrieval <ref type="bibr" target="#b19">[20]</ref> and visualization <ref type="bibr" target="#b23">[24]</ref>.</p><p>In practice, the margin between data points and the decision boundary plays a significant role in achieving strong generalization performance. <ref type="bibr" target="#b15">[16]</ref> develops a margin theory and shows that the margin loss leads to an informative generalization bound for classification task. In the past decades, the idea of marginbased metric learning has been widely explored in SVM <ref type="bibr" target="#b39">[40]</ref>, k-NN classification <ref type="bibr" target="#b49">[50]</ref>, multi-task learning <ref type="bibr" target="#b32">[33]</ref>, etc. In the deep learning era, many marginbased metric learning methods are proposed to enhance the discriminative power of the learned deep features, and show remarkable performance improvements in many tasks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30]</ref>, especially in face verification <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b5">6]</ref>. For example, SphereFace <ref type="bibr" target="#b20">[21]</ref>, CosFace <ref type="bibr" target="#b47">[48]</ref>, and ArcFace <ref type="bibr" target="#b5">[6]</ref> enforce the intra-class variance and inter-class diversity by adding the margin to cosine softmax loss.</p><p>However, as the tasks of previous works are based on close-set scenarios, they limit the margin parameter as positive values <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b5">6]</ref>, where making the deep features more discriminative could be generalized to the validation set and improve the performance. For open-set scenarios, such as few-shot learning, increasing the margin would not enforce the inter-class diversity but unfortunately enlarge the intra-class variance for novel classes, as shown in <ref type="figure" target="#fig_6">Fig. 2</ref>, which would hurt the performance. In contrast, an appropriate negative margin would better tradeoff the discriminability and transferability of deep features in novel classes, and obtain better performance for few-shot classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>In a few-shot classification task, we are given two sets of data with different classes, formulated as</p><formula xml:id="formula_0">I b = {(x i , y i )} N b i=1</formula><p>as the base training set with C b base classes for the first training stage, and I n = {(x i , y i )} N n i=1 as the novel training set with C n novel classes for the second training stage. For the novel training set, each class has K samples, where K = 1 or 5, and C n = 5 is the standard setting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b34">35]</ref>. This is called C n -way K-shot learning. Few-shot classification aims to learn both discriminative and transferable feature representations from the abundant labeled data in base classes, such that the features can be easily adapted for the novel classes with few labeled examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Negative-margin Softmax Loss</head><p>In image classification, the softmax loss is built upon the feature representation of deep networks z i = f θ (x i ) ∈ R D (f θ (·) denotes the backbone network with the parameters θ), its corresponding label y i and the linear transform matrix</p><formula xml:id="formula_1">W = [W 1 , W 2 , ..., W C b ] ∈ R D×C b .</formula><p>Recently, introducing the large and positive margin parameter to the softmax loss is widely explored in metric learning <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b5">6]</ref>. Hence, we directly integrate the margin parameter to the softmax loss to learn the transferable metrics, aiming at benefiting the few-shot classification on novel classes. The general formulation of large-margin softmax loss is defined as </p><formula xml:id="formula_2">L = − 1 N N i=1 log e β·(s(zi,Wy i )−m)</formula><p>where m is the margin parameter, β denotes the temperature parameter which could help to apply the appropriate concentrated level around the largest scores. And s(·, ·) denotes the similarity function between two input vectors. It's worth noting that all the previous works on large-margin softmax loss restrict the margin as positive values <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b5">6]</ref>. This is because that previous works focus on the close-set scenarios, the loss with larger margin leads to the smaller intra-class variance and the larger between-class variance, which will help to classify examples in the same classes. This is also validated in <ref type="figure">Figure 1</ref>, that the softmax loss with larger margin could improve the classification accuracy on the validation set of training classes.</p><p>However, the situations are different in the open-set scenarios. Learned metrics which are too discriminative to training classes may hurt their transferability to the novel classes. So applying appropriate negative margin to softmax loss aims to tradeoff the discriminability on training classes and the transferability to novel classes of the learned metrics.</p><p>Here we formulate two instantiations of Eqn. 1 with different similarity functions. By taking the inner-product similarity s (z i , W j ) = W T j z i into Eqn. 1, the negative-margin softmax loss (abbreviated as Neg-Softmax) could be obtained. By taking the cosine similarity</p><formula xml:id="formula_4">s (z i , W j ) = W T j zi</formula><p>zi Wj into Eqn. 1, we can formulate the negative-margin cosine softmax loss (abbreviated as Neg-Cosine). The detailed loss functions could be found at the Appendix. These two loss functions are adopted at the pre-training stage, as shown in <ref type="figure" target="#fig_8">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discriminability analysis of deep features w.r.t different margins</head><p>We analyze the discriminability of the deep features extracted by the deep model with different margins, to understand why negative margin works well on novel classes. For simplicity, we only analyze the cosine softmax loss, and it is direct to extend the analysis and conclusion to standard softmax loss.</p><p>We denote the pre-trained backbone network trained with margin parameter m as f θ(m) . For class j in base classes or novel classes, denote the set of examples labeled with class j as I j = {(x i , y i )|y i = j}. We compute the class center µ(I j , m) for class j as the mean of the L2-normalized feature embeddings as</p><formula xml:id="formula_5">µ(I j , m) = 1 |I j | (xi,yi)∈Ij f θ(m) (x i ) f θ(m) (x i ) 2 .<label>(2)</label></formula><p>The dataset I = I 1 ∪ I 2 ∪ · · · ∪ I C with C classes could be base dataset I b with a large number of base classes or novel dataset I n with small number of novel classes (such as 5 for 5-way few shot learning). Then we define the inter-class variance D inter (I, m), and intra-class variance D intra (I, m) as  Inter-class variance Dinter, intra-class variance Dintra, and discriminative function φ w.r.t margin m on both base and novel classes of mini-ImageNet. As the margin increases, the features of base classes is more discriminative, while that of novel classes is less discriminative.</p><formula xml:id="formula_6">Dinter(I, m) = 1 C(C − 1) C j=1 C k=1,k =j µ(Ij, m) − µ(I k , m) 2 2 , Dintra(I, m) = 1 C C j=1 ( 1 |Ij| (x i ,y i )∈I j f θ(m) (xi) f θ(m) (xi) − µ(Ij, m)</formula><p>For every two classes, the inter-class variance is the squared L2 distance between their class centers. For each class, the intra-class variance is the squared L2 distance between every sample in this class and the class center.</p><p>If inter-class variance becomes larger or intra-class variance becomes smaller, the deep features would be more discriminative. So we follow <ref type="bibr" target="#b25">[26]</ref> to define the discriminative function φ(I, m) as the inter-class variance divided by the intraclass variance:</p><formula xml:id="formula_7">φ(I, m) = D inter (I, m) D intra (I, m) .<label>(4)</label></formula><p>To measure the discriminability of the deep features with different margins, we plot the inter-class variance D inter , intra-class variance D intra , and discriminative function φ w.r.t margin m on both the base and novel classes of mini-ImageNet, respectively. As shown in <ref type="figure" target="#fig_6">Fig. 2</ref>, for base classes (red curves), as the margin increases, the inter-class variance increases a lot, meanwhile the intra-class variance does not change much, so the features of base classes become more discriminative. This is widely observed in previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b21">22]</ref>, and motivates them to introduce large and also positive margin to softmax loss for close-set scenarios. But for novel classes (blue curves), the situation is just on the contrary. As the margin increases, the inter-class variance does not change much, but the intra-class variance increases a lot, so the features of base classes become less discriminative. This indicates that larger margin may hurt the classification on the novel classes. This is also verified in the real few-shot classification task, shown as red curves in <ref type="figure">Fig. 1</ref>, larger and positive margin will achieve worse performance of few-shot classification on novel classes. Instead, the appropriate negative margin could achieve the best performance, which may lead to a better tradeoff on discriminability and transferability for novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Intuitive Explanation</head><p>To better understand how the margin works, we perform the visualization on the data distributions in the angular space trained on MNIST 1 , as shown in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base Classes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Novel Classes</head><p>Negative Positive Margin <ref type="figure">Fig. 3</ref>. The visualizations of the data distributions on angular space with different margins, on base classes (the first row) or novel classes (the second row) of MNIST. Plots from left to right denotes the margins from negative to positive. For each figure, we plot the histogram of the occurrence for each angle. Different colors denote the data points belonging to different classes. <ref type="figure">Fig. 3</ref>. We choose seven classes as the base classes for pre-training, and adopt the other three classes as the novel classes. We first train this deep model with 2-dimensional output features using cosine softmax loss with different margins on the base classes. Then we normalize the 2-D features to obtain the direction of each data point, and visualize the count of each direction (also known as the data distributions in angular space) on both base (first row) and novel classes (second row) using the models trained with different margins.</p><p>As shown in the first row in <ref type="figure">Fig. 3</ref>, with larger and even positive margin (from left to right), the clusters for each training class are getting thinner and higher, and the angle differences between different class centers are getting larger. This matches our previous observation in <ref type="figure" target="#fig_6">Fig. 2</ref>, that enlarging the margin leads to the smaller intra-class variance and larger inter-class variance on the base classes.</p><p>However, with larger margin, less data points would lie in the space far from all centers, which to some extent makes the output space much narrower. As shown on the right side of the second row in <ref type="figure">Fig. 3</ref>, as novel classes are different to base classes, model with large margin may map the data points of the same class in novel classes to multiple peaks or clusters belonging to different base classes. Then the intra-class variance for novel classes would increase accordingly, making the classification of novel classes more difficult. Instead, as shown on the left side of second row in <ref type="figure">Fig. 3</ref>, the appropriate negative margin would not enforce the data points in novel classes too close to the training center, and may alleviate the multi-peak issue, which could benefit the classification on novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Theoretical Analysis</head><p>After giving the intuitive explanation that why negative margin works well on novel classes, we then prove this claim theoretically. Denote the parameter of the classifier joint pre-trained with backbone on base classes with margin m as W(m), the probability of a sample in the novel category j classified by pre-  </p><formula xml:id="formula_8">P jk (m) = 1 |I j | (xi,yi)∈Ij exp βs(f θ(m) (x), W k (m)) C b k =1 exp βs(f θ(m) (x), W k (m)) ,<label>(5)</label></formula><p>where s(·, ·) denotes the similarity function. The probability of a pair of samples in the same novel category j classified into the same base class is P s j (m) = </p><formula xml:id="formula_9">− ψ(m 2 ) = t · (m 2 − m 1 ), t &gt; 0. ∀0 &lt; P s &lt; t t(1−φ −1 (I b ,m1))+rψ(m1) , we have φ(I n , m 2 ) &lt; φ(I n , m 1 ). Proof. Since D intra (I n , m) = P s D intra (I b , m) + (1 − P s )D inter (I b , m)</formula><p>, substituting it into the φ(I n , m 2 ) = Dinter(I n ,m2) Dintra(I n ,m2) &lt; Dinter(I n ,m1) Dintra(I n ,m1) = φ(I n , m 1 ), we have  The above proposition proves that the discriminative function on the novel classes φ(I n , m) is a monotonic decreasing function w.r.t m under proper assumption and a measurable condition about the similarity between base and novel classes using P s . The proposition indicates that an appropriate value of "negative" margin could work well for discriminating the samples in novel classes. <ref type="figure" target="#fig_4">Fig. 4</ref> shows the actual behavior of mini-ImageNet dataset. We first sort the 36 novel classes according to the probability of sample pairs in the same novel class j classified into the same base class P s j (one of every 3 categories are plotted for clarity) on mini-ImageNet. And the histograms of the samples in novel classes to be classified to 64 base classes is shown in <ref type="figure" target="#fig_4">Fig. 4(a)</ref>. <ref type="figure" target="#fig_4">Fig. 4(b)</ref> shows the accuracy curves w.r.t different margins for novel classes with different averaged P s . With smaller P s , the histograms of novel classes become more diverse (shown in <ref type="figure" target="#fig_4">Fig. 4(a)</ref>) and their accuracies become lower (shown in <ref type="figure" target="#fig_4">Fig. 4(b)</ref>). Importantly, most subsets of novel classes favor negative margins, implying the condition in the Proposition is not hard to reach.</p><formula xml:id="formula_10">φ(I n , m2) &lt; φ(I n , m1) ⇔ Dinter(I n , m2) P s Dintra(I b , m2) + (1 − P s )Dinter(I b , m2) &lt; Dinter(I n , m1) P s Dintra(I b , m1) + (1 − P s )Dinter(I b , m1) ⇔P s &lt; D inter (I n ,m 1 ) D inter (I b ,m 1 ) − D inter (I n ,m 2 ) D inter (I b ,m 2 ) D inter (I n ,m 1 ) D inter (I b ,m 1 ) · 1 − D intra (I b ,m 2 ) D inter (I b ,m 2 ) − D inter (I n ,m 2 ) D inter (I b ,m 2 ) · 1 − D intra (I b ,m 1 ) D inter (I b ,m 1 ) ⇔P s &lt; ψ(m1) − ψ(m2) ψ(m1)(1 − φ −1 (I b , m2)) − ψ(m2)(1 − φ −1 (I b , m1))) ⇔P s &lt; t t(1 − φ −1 (I b , m1)) + rψ(m1)<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Framework</head><p>Following the standard transfer learning paradigm <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b7">8]</ref>, we adopt a two-stage training pipeline for few-shot classification, as shown in <ref type="figure" target="#fig_8">Figure 5</ref>, including pretraining stage to perform metric learning on the abundant labeled data in base classes, and fine-tuning stage to learn a classifier to recognize novel classes. This pipeline is widely adopted in recent few-shot learning methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>In the pre-training stage, we aim at training the backbone network f θ (·) with abundant labeled data I b in base classes, driven by metric learning loss, such as softmax loss in <ref type="bibr" target="#b2">[3]</ref>. In our paper, we adopt the negative-margin softmax loss, which could learn more transferable representations for few-shot learning. In the fine-tuning stage, as there are only few labeled samples in I n for training (e.g. 5-way 1-shot learning only contains 5 training samples), we follow <ref type="bibr" target="#b2">[3]</ref> to fix the parameters of the backbone f θ (·), and only train a new classifier from scratch by the softmax loss. Note that, the computation of similarity (such as innerproduct similarity or cosine similarity) in softmax loss is the same as that in the pre-training stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Datasets and scenarios. Following <ref type="bibr" target="#b2">[3]</ref>, we address the few-shot classification problem under three different scenarios: (1) generic object recognition; (2) finegrained image classification; and (3) cross-domain adaptation.</p><p>For the generic scenario, the widely-used few-shot classification benchmark: mini-ImageNet, is used to evaluate the effectiveness of the proposed Negative-Margin Softmax Loss. The mini-ImageNet dataset, firstly proposed by <ref type="bibr" target="#b45">[46]</ref>, consists of a subset of 100 classes from the ILSVRC-2012 <ref type="bibr" target="#b4">[5]</ref>, and contains 600 images for each classes. Following the commonly-used evaluation protocol of <ref type="bibr" target="#b36">[37]</ref>, we split the 100 classes into 64 base, 16 validation, and 20 novel classes for pre-training, validation, and testing.</p><p>For the fine-grained image classification, we use CUB-200-2011 dataset <ref type="bibr" target="#b46">[47]</ref> (hereinafter referred as CUB), which consists of 200 classes and 11,788 images in total. Following the standard setting of <ref type="bibr" target="#b13">[14]</ref>, we split the classes in the dataset into 100 base classes, 50 validation classes, and 50 novel classes.</p><p>For the cross-domain adaptation scenario, we use mini-ImageNet → CUB <ref type="bibr" target="#b2">[3]</ref>, in which the 100 classes in mini-ImageNet, the 50 validation and 50 novel classes in CUB are adopted as base, validation and novel classes respectively, to evaluate the performance of the proposed Negative-Margin Softmax Loss in the presence of domain shift. Implementation details. For fair comparison, we evaluate our model with four commonly used backbone networks, namely Conv-4 <ref type="bibr" target="#b45">[46]</ref>, ResNet-12 <ref type="bibr" target="#b31">[32]</ref>, ResNet-18 <ref type="bibr" target="#b2">[3]</ref> and WRN-28-10 <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b53">54]</ref>. Besides the differences in network depth and architecture, the expected input size of Conv-4 and ResNet-12 is 84×84, and that of ResNet-18 is 224×224, while WRN-28-10 takes 80×80 images as input.</p><p>Our implementation is based on PyTorch <ref type="bibr" target="#b33">[34]</ref>. In the training stage, the backbone network and classifier are trained from scratch, with a batch size of 256. The models are trained for 200, 400 and 400 epochs in the CUB, mini-ImageNet and mini-ImageNet → CUB, respectively. We adopt the Adam <ref type="bibr" target="#b14">[15]</ref> optimizer with initial learning rate 3e-3 and cosine learning rate decay <ref type="bibr" target="#b22">[23]</ref>. We apply the same data argumentation as <ref type="bibr" target="#b2">[3]</ref>, including random cropping, horizontal flipping and color jittering.</p><p>In the fine-tuning stage, each episode contains 5 classes and each class contains 1 or 5 support images to train a new classifier from scratch and 16 query images to test the accuracy. The final performance is reported as the mean classification accuracy over 600 random sampled episodes with the 95% confidence interval. Note that all the hyper-parameters are determined by the performance on the validation classes.  <ref type="bibr" target="#b38">[39]</ref> 61.76 ± 0.08 77.59 ± 0.12 Fine-tuning <ref type="bibr" target="#b6">[7]</ref> 57.73 ± 0.62 78.17 ± 0.49 Cosine + rotation <ref type="bibr" target="#b10">[11]</ref> 62 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Results on mini-ImageNet. For the generic object recognition scenario, we evaluate our methods on the widely-used mini-ImageNet dataset. For fair comparison with existing methods which uses different network architecture as backbone, we evaluate our methods with all four commonly used backbone networks. The 5-way 1-shot and 5-shot classification results on the novel classes of the mini-ImageNet dataset are listed in <ref type="table" target="#tab_0">Table 1</ref>. We find that by simply adopting appropriate negative margin in standard softmax loss, our Neg-Softmax achieves competitive results with the existing state-of-the-art methods. It is worth noting that our Neg-Cosine achieves the state-of-the-art performance for both 1-shot and 5-shot settings on almost all four backbones on mini-ImageNet. Results on CUB. On the fine-grained dataset CUB, we compared the proposed method with several state-of-the-art methods with ResNet-18 as backbone. The results are showed in <ref type="table">Table 2</ref>, in which the results of the comparison methods are directly borrowed from <ref type="bibr" target="#b2">[3]</ref>. It shows that the proposed Neg-Cosine outperforms all the comparison methods on both 1-shot and 5-shot settings. Furthermore, <ref type="table">Table 2</ref>. The few-shot classification accuracy on the novel classes (also known as test classes) of the CUB dataset and cross-domain setting with ResNet-18 as the backbone Method CUB mini-ImageNet→CUB 1 shot 5 shot 5 shot MAML <ref type="bibr" target="#b8">[9]</ref> 69.96 ± 1.01 82.70 ± 0.65 51.34 ± 0.72 ProtoNet <ref type="bibr" target="#b42">[43]</ref> 71.88 ± 0.91 87.42 ± 0.48 62.02 ± 0.70 MatchingNet <ref type="bibr" target="#b45">[46]</ref> 72.36 ± 0.90 83.64 ± 0.60 53.07 ± 0.74 RelationNet <ref type="bibr" target="#b43">[44]</ref> 67.59 ± 1.02 82.75 ± 0.58 57.71 ± 0.73 Baseline <ref type="bibr" target="#b2">[3]</ref> 65.51 ± 0.87 82.85 ± 0.55 65.57 ± 0.70 Baseline++ <ref type="bibr" target="#b2">[3]</ref> 67. Neg-Softmax also achieves highly competitive performance on both 1-shot and 5-shot settings.</p><p>Results on mini-ImageNet → CUB. In the real-world applications, there may be a signification domain shift between the base and novel classes. So we evaluate our methods on a cross domain scenario: mini-ImageNet → CUB, where we pre-train the backbone on a generic object recognition dataset, and transfer it to a fine-grained dataset. We follow <ref type="bibr" target="#b2">[3]</ref> to report the 5-shot results with ResNet-18 backbone, as shown in <ref type="table">Table 2</ref>. We can observe that both Neg-Softmax and Neg-Cosine are significantly better than all the comparison methods. Specifically, Neg-Softmax outperforms Baseline <ref type="bibr" target="#b2">[3]</ref>, the state-of-the-art method on the mini-ImageNet → CUB, by a large margin of 3.73%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>This section presents a comprehensive analysis of the proposed approach. In the following experiments, we use Neg-Cosine with ResNet-18 backbone as default.</p><p>Effects of negative margin. <ref type="table" target="#tab_3">Table 3</ref> shows the 1-shot and 5-shot accuracy of the standard softmax, cosine softmax and our proposed Neg-Softmax, Neg-Cosine on the validation classes of mini-ImageNet, CUB and mini-ImageNet → CUB. By adopting appropriate negative margin, Neg-Softmax and Neg-Cosine yields significant performance gains over standard softmax loss and cosine softmax loss on all three benchmarks. Interestingly, Neg-Cosine outperforms Neg-Softmax in the in-domain setting, such as mini-ImageNet and CUB, while Neg-Softmax could achieve better performance than Neg-Cosine in the cross-domain setting. This is also observed in <ref type="bibr" target="#b2">[3]</ref>. Accuracy w.r.t different margins. <ref type="figure" target="#fig_9">Figure 6</ref> shows the 1-shot accuracy and 5-shot accuracy on validation classes of mini-ImageNet dataset w.r.t different margins in Neg-Cosine and Neg-Softmax. As we expect, as the margin gets negative and smaller, both the 1-shot accuracy and 5-shot accuracy of Neg-Cosine and Neg-Softmax first increase and then decrease, demonstrating a desirable bell-shaped curve. Hence, adopting appropriate negative margin yields signifi-   <ref type="table" target="#tab_4">Table 4</ref> shows the importance of regularizations on Neg-Cosine, which reveals that integrating various regularization techniques steadily improves the 1-shot and 5-shot test accuracy on mini-ImageNet benchmark. Firstly, by simply adopting negative margin, the test accuracy increased by 5.74% and 4.37% on the 1-shot and 5-shot settings, respectively. Based on our approach, weight decay and DropBlock could further improve the performance. After integrating all regularizations together, our method achieves state-of-the-art accuracy of 62.33% and 80.94% for the 1-shot and 5-shot settings respectively on novel classes of mini-ImageNet. T-SNE visualization. <ref type="figure" target="#fig_10">Fig. 7</ref> shows the t-SNE <ref type="bibr" target="#b23">[24]</ref> visualizations of the feature embedding and the corresponding 1-shot accuracy in the base and novel classes of mini-ImageNet dataset for negative, zero and positive margin respectively. As shown in the first row in <ref type="figure" target="#fig_10">Fig. 7</ref>, compared with negative margin, the feature embedding of zero and positive margin exhibit more discriminative structures and achieve better 1-shot accuracy on the base classes. However, the second row in <ref type="figure" target="#fig_10">Figure 7</ref> shows that enlarging the margin parameter would break the cluster structure of the novel classes and make the classification of novel classes harder. Instead, the appropriate negative margin could tradeoff the discriminability and transferability of deep features in the novel classes, and retain the better cluster structure for novel classes. Thus the few-shot classification accuracy of negative margin is better than that of zero and positive margin.  More shots. We conduct an experiment by varying the number of shots from 1 (few shot) to 300 (many shot) and report the classification accuracy of the validation classes on the mini-ImageNet dataset in <ref type="figure" target="#fig_12">Figure 8</ref>. It shows that the test accuracy of margin=−0.3 is consistently higher than that of margin=0 from 1-shot to 300-shot settings, which prove that the negative margin could benefit the open-set scenarios with more shots. But there is another trend we cannot ignore, the gap between margin=−0.3 and margin=0 is getting smaller when the number of shots increase. In other words, when sufficient data is available in the novel classes, the influence of the metrics learned from the base classes to the novel classes is weakened.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we unconventionally propose to adopt appropriate negative-margin to softmax loss for few-shot classification, which surprisingly works well for the open-set scenarios of few-shot classification. We then provide the intuitive explanation and the theoretical proof to understand why negative margin works well for few-shot classification. This claim is also demonstrated via sufficient experiments. With the negative-margin softmax loss, our approach achieves the  state-of-the-art performance on all three standard benchmarks of few-shot classification. In the future, the negative margin may be applied in more general open-set scenarios that do not restrict the number of samples in novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Instantiations of Negative-Margin Loss</head><p>Eqn. 1 provides a general formulation for the margin softmax loss. Here, we provide detailed formulation of the two instantiations: negative-margin softmax loss and negative-margin cosine softmax loss as:</p><formula xml:id="formula_11">L = − 1 N N i=1 log e β· W T y i z i −m e β· W T y i z i −m + C j=1,j =y i e β·(W T j z i) ,<label>(7)</label></formula><formula xml:id="formula_12">L = − 1 N N i=1 log e β·(cos(Wy i ,z i) −m) e β·(cos(Wy i ,z i) −m) + C j=1,j =y i e β·cos(W j ,z i) ,<label>(8)</label></formula><p>where m ≤ 0 is the margin parameter. Note that the formulations are the same as the large-margin softmax loss in <ref type="bibr" target="#b21">[22]</ref> and the large-margin cosine loss in <ref type="bibr" target="#b47">[48]</ref>, but we restrict the margin m as a non-positive value (m ≤ 0) while the original formulations restrict the margin m as a non-negative value (m ≥ 0). We follow the pre-training and fine-tuning pipeline introduced in Sec. 3.5, and the proposed negative-margin (cosine) softmax loss is applied in the pre-training stage, as illustrated in <ref type="figure" target="#fig_8">Figure 5</ref>. Note we do not apply the negative-margin loss to the pre-training stage, where we find regular (cosine) softmax loss (margin m = 0) performs well, as detailed in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B The effects of margin in the fine-tuning stage</head><p>In the main part of the paper, we show that applying the negative-margin softmax loss into the pre-training stage leads to better discrimination of novel classes. In this section, we investigate the effects of the margin parameter on the finetuning stage. As shown in <ref type="figure" target="#fig_13">Fig. 9</ref>, the 5-shot classification accuracy in the validation classes is insensitive when varying margin values, while that of 1-shot classification increases marginally when increasing margin values. Such behavior is different from the effects of the margin parameter in the pre-training stage, indicating that the negative margin mainly effects in open-set scenarios. Also note the accuracy is much more insensitive w.r.t margin parameter than that of pre-training and fine-tuning both using base classes (the blue curves in <ref type="figure">Fig 1)</ref>, probably because the feature is fixed in the fine-tuning stage and different margin values can all find good discrimination planes well. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Relationship between negative margin and label smoothing</head><p>The same as negative margin loss, the label smoothing <ref type="bibr" target="#b44">[45]</ref> technique also aims at facilitating the difficulty of equalising softmax outputs and the binary groundtruth labels. Technically, while the label smoothing technique changes the ground truth target labels from binary values to soft ones which alleviate the equalising of softmax outputs and the binary ground-truth labels, the negative margin loss modify the other side of softmax outputs. Although resulting in similarly smaller loss than regular training, they perform very differently on training classes and novel classes.</p><p>In softmax based image classification, the final prediction is the class with the largest softmax probability and the accuracy is 100% if all predictions match  <ref type="table">Table 5</ref>. Comparison with label smoothing on the 5-way 1-shot and 5-shot accuracy for the base and validation classes in the mini-ImageNet dataset with ResNet-18 as backbone. For label smoothing, is set as 0.05. For negative margin, m in pre-training stage is fixed to −0.3.</p><p>the ground truth label. The softmax output for the ground truth label is not necessarily as 1, but is correct as long as it is larger than the softmax outputs of other classes. In another word, the cross entropy loss which encourages the softmax output of the right class to be exactly 1 is stricter than the real target of doing right classification. The label smoothing technique relaxes the groundtruth labels as soft ones, which shrinks the gap between cross-entropy loss and the real classification target. As a result, it usually achieves higher accuracy on the validation images of training classes, indicating better discrimination of training classes. On the contrary, the negative margin technique enlarges the gap between loss and real classification accuracy. It usually results in lower accuracy on the validation images of training classes, indicating lower discrimination of training classes. <ref type="table">Table 5</ref> investigate the effects of two techniques by applying few-shot finetuning on either validation images (ILSVRC-2012 images of the base classes but not in mini-ImageNet) of base classes or images of val classes. For label smoothing, is set as 0.05. For negative margin, m = −0.3. It can be seen that the label smoothing technique improves the performance on the base classes by 3.48% and 0.21% for the 1-shot and 5-shot setting respectively, but has 1.47% and 3.03% accuracy drop on the validation classes for the 1-shot and 5-shot settings, respectively. On the contrary, the negative margin technique has lower performance on the validation images of training classes but benefits both the 1-shot and 5-shot classification accuracy on the validation classes.</p><p>These results are in accord with the previous analysis that the different effects of the negative margin technique and the label smoothing technique. While the label smoothing technique tends to improve the discriminability of base classes and harm the transferability to novel classes, the negative margin technique has lower discriminability of base classes but can improve the feature transferability to novel classes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2003.12060v1 [cs.CV] 26 Mar 2020</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>e</head><label></label><figDesc>β·(s(zi,Wy i )−m) + C j=1,j =yi e β·s(zi,Wj ),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4 .</head><label>4</label><figDesc>6 (P s = 0.3892) category 3-8 (P s = 0.2798) category 5-10 (P s = 0.1942) category 7-12 (P s = 0.1586) category 13-18 (P s = 0.1033) category 19-24 (P s = 0.0814) category 25-30 (P s = 0.0721) category 31-36 (P s = 0.0546) (b) Fig. We first sort the 36 novel classes according to the probability of sample pairs in the same novel class j classified into the same base class P s j (one of every 3 categories are plotted for clarity) on mini-ImageNet. For each novel class, (a) shows the histogram of samples in this class to be classified to 64 base classes. (b) shows the accuracy curves w.r.t different margins for novel classes with different averaged P s .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>trained backbone f θ(m) and classifier W (m) as a base category k is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>C b k=1 P 2 jk</head><label>2</label><figDesc>(m). And the average probability of P s j (m) is P s (m) = 1 |C n | C n j=1 P s j (m). Proposition. Assuming discriminative function for the base classes φ(I b , m) is a monotonic increasing function w.r.t margin parameter m, and then we denote φ −1 (I b , m 1 ) − φ −1 (I b , m 2 ) = r · (m 2 − m 1 ), where m 2 &gt; m 1 and r &gt; 0 is a scale variable. ψ(m) = D inter (I n , m)/D inter (I b , m) is a monotonic decreasing function and we denote ψ(m 1 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Overview of our proposed approach, which consists of two stages, pre-training (learning metrics with sufficient annotated examples on training classes) and finetuning (learning a classifier on novel classes with few labeled examples). The negativemargin softmax loss is integrated in pre-training for learning more transferable features for novel classes, with two types of similarities, inner-product and cosine similarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>The 1-shot (on red) and 5-shot (on blue) accuracy on validation classes of mini-ImageNet w.r.t different margins in Neg-Cosine and Neg-Softmax cant performance gains over both standard softmax loss and cosine softmax loss on 1-shot and 5-shot classification of mini-ImageNet. Various regularization techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>The t-SNE visualizations of the feature embeddings and the corresponding 1shot accuracy in the base and novel classes of mini-ImageNet dataset for the softmax loss with negative, zero and positive margin respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8 .</head><label>8</label><figDesc>Accuracy w.r.t # shots of validation classes on the mini-ImageNet dataset for margin = -0.3, 0 and 0.3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 .</head><label>9</label><figDesc>The one-shot (in red) and five-shot (in blue) accuracy on validation classes w.r.t different margins in cosine softmax loss applied in fine-tunning stage on mini-ImageNet. The margin parameter in the pre-training stage is fixed to −0.3 and the backbone is ResNet-18.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Few-shot classification results on the mini-ImageNet dataset. † indicates the method using the combination of base and validation classes to train the meta-learner</figDesc><table><row><cell>Backbone</cell><cell>Method</cell><cell>1 shot</cell><cell>5 shot</cell></row><row><cell></cell><cell>MAML [9]</cell><cell>48.70 ± 1.84</cell><cell>63.11 ± 0.92</cell></row><row><cell></cell><cell>ProtoNet [43]</cell><cell>49.42 ± 0.78</cell><cell>68.20 ± 0.66</cell></row><row><cell></cell><cell>MatchingNet [46]</cell><cell>48.14 ± 0.78</cell><cell>63.48 ± 0.66</cell></row><row><cell>Conv-4</cell><cell>RelationNet [44]</cell><cell>50.44 ± 0.82</cell><cell>65.32 ± 0.70</cell></row><row><cell></cell><cell>MAML+Meta-dropout [18]</cell><cell>51.93 ± 0.67</cell><cell>67.42 ± 0.52</cell></row><row><cell></cell><cell>R2D2 [1]</cell><cell>51.20 ± 0.60</cell><cell>68.80 ± 0.10</cell></row><row><cell></cell><cell>Neg-Softmax (ours)</cell><cell>47.65 ± 0.78</cell><cell>67.27 ± 0.66</cell></row><row><cell></cell><cell>Neg-Cosine (ours)</cell><cell>52.84 ± 0.76</cell><cell>70.41 ± 0.66</cell></row><row><cell></cell><cell>SNAIL [27]</cell><cell>55.71 ± 0.99</cell><cell>68.88 ± 0.92</cell></row><row><cell></cell><cell>TADAM [32]</cell><cell>58.50 ± 0.30</cell><cell>76.70 ± 0.30</cell></row><row><cell>ResNet-12</cell><cell>MetaOptNet-SVM [19]</cell><cell>62.64 ± 0.61</cell><cell>78.63 ± 0.46</cell></row><row><cell></cell><cell>Neg-Softmax (ours)</cell><cell>62.58 ± 0.82</cell><cell>80.43 ± 0.56</cell></row><row><cell></cell><cell>Neg-Cosine (ours)</cell><cell>63.85 ± 0.81</cell><cell>81.57 ± 0.56</cell></row><row><cell></cell><cell>SNCA [51]</cell><cell>57.80 ± 0.80</cell><cell>72.80 ± 0.70</cell></row><row><cell></cell><cell>Baseline [3]</cell><cell>51.75 ± 0.80</cell><cell>74.27 ± 0.63</cell></row><row><cell>ResNet-18</cell><cell>Baseline++ [3]</cell><cell>51.87 ± 0.77</cell><cell>75.68 ± 0.63</cell></row><row><cell></cell><cell>Neg-Softmax (ours)</cell><cell>59.02 ± 0.81</cell><cell>78.80 ± 0.61</cell></row><row><cell></cell><cell>Neg-Cosine (ours)</cell><cell>62.33 ± 0.82</cell><cell>80.94 ± 0.59</cell></row><row><cell></cell><cell>Activation to Parameter  † [36]</cell><cell>59.60 ± 0.41</cell><cell>73.74 ± 0.19</cell></row><row><cell></cell><cell>LEO  †</cell><cell></cell><cell></cell></row><row><cell>WRN-28-10</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>The few-shot accuracy of standard softmax, cosine softmax and our proposed Neg-Softmax, Neg-Cosine on validation classes of three standard benchmarks 98±0.79 75.25±0.61 58.32±0.87 80.21±0.59 46.87±0.78 67.68±0.71 Neg-Softmax 56.95±0.82 78.87±0.57 59.54±0.88 80.60±0.57 47.74±0.73 68.58±0.70 Cosine 59.49±0.90 79.58±0.59 66.39±0.93 82.17±0.58 42.96±0.76 61.99±0.75</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">mini-ImageNet</cell><cell></cell><cell></cell><cell></cell><cell>CUB</cell><cell></cell><cell cols="2">mini-ImageNet→CUB</cell></row><row><cell></cell><cell cols="2">Method</cell><cell></cell><cell>1 shot</cell><cell cols="2">5 shot</cell><cell cols="3">1 shot</cell><cell cols="2">5 shot</cell><cell>1 shot</cell><cell>5 shot</cell></row><row><cell cols="14">Softmax 45.Neg-Cosine 63.68±0.86 82.02±0.57 69.17±0.85 85.60±0.56 44.51±0.85 64.04±0.75</cell></row><row><cell>1-shot Accuracy (%)</cell><cell>59 60 61 62 63</cell><cell>0.3 63.68 81.2 63.3 79.48</cell><cell>63.09 82.02</cell><cell cols="2">0.2 Margin 62.25 62.08 0.1 60.91 62.55 80.6 81.62 81.78 81.85</cell><cell>0.0 59.49 79.58</cell><cell>79.5 80.0 80.5 81.0 81.5 82.0 5-shot Accuracy (%)</cell><cell>1-shot Accuracy (%)</cell><cell>46 48 50 52 54 56</cell><cell>-15 50.98</cell><cell>-10 56.56 56.95 -12 77.3 76.86</cell><cell cols="2">0 45.98 -1 46.74 75.25 78.06 -3 48.93 78.87 -5 54.26 Margin -7 56.3 78.13 76.94</cell><cell>79 75 76 77 78 5-shot Accuracy (%)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">(a) Neg-Cosine</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Neg-Softmax</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Test accuracy on 5-way mini-ImageNet of various regularization techniques</figDesc><table><row><cell>negative margin</cell><cell>weight decay</cell><cell>drop block</cell><cell>1 shot</cell><cell>5 shot</cell></row><row><cell></cell><cell></cell><cell></cell><cell>54.51 ± 0.79</cell><cell>75.70 ± 0.62</cell></row><row><cell></cell><cell></cell><cell></cell><cell>60.25 ± 0.81</cell><cell>80.07 ± 0.58</cell></row><row><cell></cell><cell></cell><cell></cell><cell>62.21 ± 0.83</cell><cell>80.81 ± 0.59</cell></row><row><cell></cell><cell></cell><cell></cell><cell>62.33 ± 0.82</cell><cell>80.94 ± 0.59</cell></row><row><cell>Base</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Novel</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>± 0.61 88.93 ± 0.62 93.93 ± 0.30 58.02 ± 0.97 75.87 ± 0.71 79.92 ± 0.81 92.34 ± 0.38 63.68 ± 0.86 81.60 ± 0.56</figDesc><table><row><cell>Label</cell><cell>Negative</cell><cell cols="2">Base</cell><cell cols="2">Val</cell></row><row><cell cols="2">Smoothing Margin</cell><cell>1 shot</cell><cell>5 shot</cell><cell>1 shot</cell><cell>5 shot</cell></row><row><cell></cell><cell></cell><cell>85.45 ± 0.67</cell><cell>93.72 ± 0.31</cell><cell>59.49 ± 0.90</cell><cell>78.90</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This technique is widely used to characterize the feature embedding under the softmax-related objectives<ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b54">55]</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HyxnZh0ct7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? a new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6299" to="6308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagenet: A largescale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4690" to="4699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02729</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04043</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05186</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Low-shot visual recognition by shrinking and hallucinating features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3018" to="3027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Few-shot learning with metric-agnostic conditional embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hilliard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Howland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yankov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">O</forename><surname>Hodas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04376</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Empirical margin distributions and bounding the generalization error of combined classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltchinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Panchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="50" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Meta dropout: Learning to perturb latent features for generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJgd81SYwr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep triplet quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia Conference on Multimedia Conference -MM 18</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Large-margin softmax loss for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02295</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<title level="m">Sgdr: Stochastic gradient descent with warm restarts</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Visualizing high-dimensional data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.12087</idno>
		<title level="m">Charting the right manifold: Manifold mixup for few-shot learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fisher discriminant analysis with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ratsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Mullers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks for signal processing IX: Proceedings of the 1999 IEEE signal processing society workshop (cat. no. 98th8468)</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1DmUzWAW" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
	<note>Meta networks</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3661" to="3670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Designing an effective metric learning pipeline for speaker diarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Thiagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Spanias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5806" to="5810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="721" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Large margin multi-task metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1867" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Autodiff Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Low-shot learning with imprinted weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5822" to="5830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJY0-Kcll" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJgklhAcK7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning with kernels: support vector machines, regularization, optimization, and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5265" to="5274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Low-shot learning from imaginary data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7278" to="7286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Improving generalization via scalable neighborhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="685" to="701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Distance metric learning with application to clustering with side-information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="521" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
		<title level="m">How transferable are features in deep neural networks? In: Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="DOI">10.5244/C.30.87</idno>
		<ptr target="http://dx.doi.org/10.5244/C.30.87" />
	</analytic>
	<monogr>
		<title level="m">Procedings of the British Machine Vision Conference</title>
		<meeting>edings of the British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Ring loss: Convex feature normalization for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5089" to="5097" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
