<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Complementing Representation Deficiency in Few-shot Image Classification: A Meta-Learning Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Zhong</surname></persName>
							<email>zhongx@whut.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Gu</surname></persName>
							<email>guchenghs@whut.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxin</forename><surname>Huang</surname></persName>
							<email>wenxin.huang@whu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuqin</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wen</forename><surname>Lin</surname></persName>
							<email>cwlin@ee.nthu.edu.tw</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Hubei Key Laboratory of Transportation Internet of Things</orgName>
								<orgName type="institution">Wuhan University of Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Wuhan University of Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Wuhan University Wuhan</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Wuhan University of Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Wuhan University of Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Electrical Engineering &amp; Institute of Communications Engineering</orgName>
								<orgName type="institution">National Tsing Hua University</orgName>
								<address>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Complementing Representation Deficiency in Few-shot Image Classification: A Meta-Learning Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Few-shot image classification</term>
					<term>Meta-learning</term>
					<term>Representation deficiency</term>
					<term>Latent space</term>
					<term>Variational inference</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot learning is a challenging problem that has attracted more and more attention recently since abundant training samples are difficult to obtain in practical applications. Meta-learning has been proposed to address this issue, which focuses on quickly adapting a predictor as a base-learner to new tasks, given limited labeled samples. However, a critical challenge for meta-learning is the representation deficiency since it is hard to discover common information from a small number of training samples or even one, as is the representation of key features from such little information. As a result, a meta-learner cannot be trained well in a high-dimensional parameter space to generalize to new tasks. Existing methods mostly resort to extracting less expressive features so as to avoid the representation deficiency. Aiming at learning better representations, we propose a metalearning approach with complemented representations network (MCRNet) for few-shot image classification. In particular, we embed a latent space, where latent codes are reconstructed with extra representation information to complement the representation deficiency. Furthermore, the latent space is established with variational inference, collaborating well with different baselearners, and can be extended to other models. Finally, our endto-end framework achieves the state-of-the-art performance in image classification on three standard few-shot learning datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Humans have extraordinary abilities to utilize the previous knowledge to quickly learn new concepts from limited information. In contrast, although deep learning methods have achieved great success in many fields, such as image classification, natural language processing, and speech modeling [1]- <ref type="figure">Fig. 2</ref>: Overview of the proposed method. The figure shows a typical 5-way 1-shot task based on our approach where the solid lines indicate the training process and the dashed lines indicate the test process during meta-training. Given an unseen sample from query set, the latent code z with additional information, reconstructed in latent space, contributes to better representations.</p><p>seek to represent features directly with less expressive feature extractors. These methods generally alleviate the tendency of over-fitting in few-shot setting and the difficulty of representing features <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b17">[18]</ref>, caused by the representation deficiency, but at the expense of greater representation or expressiveness. Furthermore, the inherent task ambiguity <ref type="bibr" target="#b15">[16]</ref> in few-shot learning also leads to difficulties when scaling to high-dimensional data. Therefore, it is desirable to develop an approach to achieve both better representation and ambiguity awareness.</p><p>In this paper, inspired by the out-performance of variational inference in generating extra information <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, we propose a novel end-to-end meta-learning approach with complemented representations network (MCRNet) for few-shot image classification. <ref type="figure">Fig. 2</ref> overviews the proposed method. Specially, our approach embeds a latent space based on lowdimensional features learned from raw samples through encoding convolution layers. Then latent codes z, reconstructed in this space, are endued extra representation information to complement the representation deficiency and will be decoded in a high-dimensional parameter space for better representation. The gradient-based optimization is performed with the new loss in both latent space and high-dimensional parameter space. Besides, the latent space is established via variational inference with stochastic initialization, enabling the method to model the inherent task ambiguity in few-shot learning <ref type="bibr" target="#b15">[16]</ref>. Our results demonstrate that MCRNet achieves state-of-the-art performance in classification tasks on three few-shot learning datasets including CIFAR-FS <ref type="bibr" target="#b20">[21]</ref>, FC100 <ref type="bibr" target="#b21">[22]</ref>, and miniIm-ageNet <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b22">[23]</ref>.</p><p>The main contributions of our work are threefold:</p><p>• We propose an end-to-end framework and interpolate a latent space to endue the reconstructed latent codes with more information, complementing the representation deficiency in a high-dimensional parameter space. • The probabilistic latent space with stochastic initialization collaborates well with different base-learners and can be extended to other architecture with high-dimensional feature extractors in few-shot learning. • We optimize the framework leveraging new loss function for the proposed latent space, which acquires better generalization across tasks and achieves the state-of-theart performance in few-shot learning classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Adaptation to new information from limited knowledge is an important aspect of human intelligence, leading to the popularity of few-shot learning <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Tackling the few-sample problems, one of the major few-shot learning methods is meta-learning, which aims to accumulate experience" and adapt the experience" to new tasks fast. Contemporary methods of meta-learning could be roughly classified into three categories. 1) Metric-based methods <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b23">[24]</ref>, which learn a similarity space through training similar metrics over the same class to enhance effectiveness. 2) Memory-based methods <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b25">[26]</ref>, which use memory architecture to store key experience from seen samples and generalize to unseen tasks according to the stored knowledge.</p><p>3) Optimization-based methods <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, which search for a suitable meta-learner that is conducive to fast gradientbased adaptation to new tasks. In this process, the meta-learner and base-leaner are continuously optimized in the outer loop and inner loop, and the optimization in our method is based on this concept.</p><p>MAML <ref type="bibr" target="#b12">[13]</ref> is an important model in meta-learning and has been extended to many variants recently. Making use of learning Gaussian posteriors over parameters to model task ambiguity, <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b16">[17]</ref> propose probabilistic extensions to MAML. Unfortunately, these methods choose a less expressive architecture as a feature extractor, like 4CONV <ref type="bibr" target="#b12">[13]</ref>, to avoid the representation deficiency in a high-dimensional parameter space. <ref type="bibr" target="#b28">[29]</ref> tries to propose better base-learners and <ref type="bibr" target="#b17">[18]</ref> interpolates self-attention relation network. These two extract features directly via more powerful architecture, ResNet-12 <ref type="bibr" target="#b21">[22]</ref> or ResNet-101, but neither of them addresses the deficiency mentioned. LEO <ref type="bibr" target="#b3">[4]</ref>, using WRN-28-10 <ref type="bibr" target="#b29">[30]</ref>, takes the deficiency into account. However, the relation network incorporated in it may lead to data-dependency issue and the potential of latent space may be neglected, since it fails to perform optimization in high-dimensional parameter space.</p><p>In contrast, we learn a probabilistic latent space over model parameters to generate latent codes with extra representation information and perform adaptation with new loss in it and the high-dimensional parameter space. This enables our method to complement the representation deficiency in few-shot learning intuitively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODOLOGY</head><p>Our main goal is embedding a latent space, established via variational inference, to complement the representation deficiency so as to learn better representations for metalearning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Primary problem definition</head><p>We evaluate the proposed approach in the K -way, N -shot problem for few-shot image classification referring to the episodic formulation of <ref type="bibr" target="#b13">[14]</ref> and <ref type="figure">Fig. 1</ref>, where K represents the number of classes for one task instance and N represents the number of training samples per class. Typically, the value of N is 1 or 5 and K is 5.</p><p>The raw dataset is divided into 3 mutually disjoint metasets: meta-training set S train , meta-validation set S val , and meta-testing set S test , considering the model's generalizability assessment. S val is used for model selection and S test is used for the final evaluation. Each task/episode is constructed during meta-training. As shown in <ref type="figure">Fig. 1</ref>, data for one task T = (D train , D test ) are sampled from S train as follows: the training/support set D train = {(x k n , y k n )|k = 1, 2...K ; n = 1, 2...N } consists of K classes selected from S train and N samples per class. The test/query set D test is composed of other different samples belonging to the same classes in D train . D test plays the role of providing an estimate of generalization and further optimizing the meta-learning objective in each task. Notably, S test should not be confused with D test .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Variational inference for latent space construction</head><p>Aiming to complement the representation deficiency, we apply a probabilistic scheme, based on <ref type="bibr" target="#b18">[19]</ref>, to establish a latent space and reconstruct latent codes with additional information in it.</p><p>To implement the parametric generative model, we first use several convolution layers as the encoder. Assuming that we acquire raw input x n , the latent code z n can be defined through a posterior distribution p(z n |x n ) which is, however, usually hard to estimate. We therefore introduce q φe (z n |x n ) with input data point x n and variational parameters φ e to approximate this posterior distribution, as defined below: where the mean and standard deviation of the approximate posterior are denoted as µ n and σ n , which are obtained through an encoding neural network:</p><formula xml:id="formula_0">q φe (z n |x n ) = N (z n |µ n , σ 2 n I),<label>(1)</label></formula><formula xml:id="formula_1">µ = W v x + b v , log σ 2 = W w x + b w ,<label>(2)</label></formula><p>where the parameter group {W v , W w , b v , b w } contains the weights and biases of the neural network. We sample random variables from the posterior distribution z l n ∼ q φe (z n |x n ) to reconstruct the latent code:</p><formula xml:id="formula_2">z l n = f φe (x n , l ) = µ n + σ n l ,<label>(3)</label></formula><p>subject to l ∼ N (0, 1),</p><p>where f φe represents the production function of z and denotes element-wise multiplication. Besides, in the method, we assume that both p(z) and q φe (z|x) follow a Multivariate Gaussian:</p><formula xml:id="formula_3">p(z) = N (z; 0, I).<label>(4)</label></formula><p>To enforce that, we compute the variation loss as follows:</p><formula xml:id="formula_4">L var =−D KL (q(z n |x n )||p(z))+E q φe (x|z) [log p(x|z)] 1 2 I i=1 (1 + log((σ (i) n ) 2 ) − (µ (i) n ) 2 − (σ (i) n ) 2 ) + 1 L L l=1 log p(x n |z l n ),<label>(5)</label></formula><p>where the first term is Kullback-Liebler divergence, the second is reconstruction error and σ</p><formula xml:id="formula_5">(i) n , µ (i)</formula><p>n respectively denote the i -th mean and standard deviation of feature samples.</p><p>In our method, as shown in <ref type="figure" target="#fig_0">Fig. 3</ref>, latent codes z are reconstructed through combining the original features µ and additional representation information σ from the encoding for number of task in batch do 5:</p><formula xml:id="formula_6">Sample task T i = (D train , D test ) from S train 6:</formula><p>for number of sample in support set D train do 7:</p><p>Encode samples in D train to z with complemented representations using f φe 8:</p><p>Decode z using f φ d 9:</p><p>Compute θ in base-learner using <ref type="formula" target="#formula_9">(6)</ref> 10:</p><p>Compute training loss L train Ti (D train ; φ, θ, ϕ) <ref type="bibr">11:</ref> Perform gradient optimization: Compute meta-training loss L meta (S train ; θ, φ)</p><formula xml:id="formula_7">θ ← θ − λ θ L train Ti (D train ; φ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17:</head><p>Perform gradient optimization:</p><formula xml:id="formula_8">φ ← φ − η φ L meta (S train ; θ, φ) 18:</formula><p>end for 19: end while neural network with variational inference. Meanwhile, extra information enables expressing the ambiguity in few-shot learning in a probabilistic manner <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Meta-learning</head><p>For each task T i , the adaptation model produces a novel classifier A, defined as the base-learner in meta-learning and optimized constantly. This process is performed on D train . The purpose of base-learner A is to estimate parameters θ of predictor for classification tasks. We obtain the parameter through minimizing the empirical loss:</p><formula xml:id="formula_9">θ = A(D train ; φ) = arg min θ L base (D train ; θ, φ) + C(θ),<label>(6)</label></formula><p>where L base is a loss function defined as negative loglikelihood of labels in our method and C(θ) is designed as a regularization term. φ is parameter of embedding module f φ , as shown in <ref type="figure">Fig. 2</ref>.</p><p>As an integral part of meta-learning, the base-learner plays an important role and we choose the base-learners suggested in <ref type="bibr" target="#b28">[29]</ref>, considering that the objective of the base-learner in our method is also convex. There are two types of base-learners used in our method including Support Vector Machine (SVM) and Ridge Regression (RR), which are both based on multiclass linear classifiers and perform well as reported in <ref type="bibr" target="#b28">[29]</ref>. Specifically, a K -class linear base-learner could be expressed as θ = {w k } K k=1 . As a result, (6) is transformed into the Crammer and Singer formulation <ref type="bibr" target="#b30">[31]</ref>:</p><formula xml:id="formula_10">θ = A(D train ; φ) = arg min {w k } min {ξi} 1 2 k w k 2 2 + C n ξ n ,<label>(7)</label></formula><p>subject to</p><formula xml:id="formula_11">w yn · f φ (x n ) − w k · f φ (x n ) ≥ 1 − δ yn,k − ξ n , ∀n, k</formula><p>where D train = {(x n , y n )}, C is designed for regularization and δ yn,k is the Kronecker delta function. Given the decoder parameters and base-learner, we then compute the inner loop" loss in each episode as follows:</p><formula xml:id="formula_12">L train Ti (D train ; φ, θ, ϕ) = (xn,yn)∈D train i [−ϕw yn ·f φ (x n ) + log K k=1 exp(ϕw k ·f φ (x n ))],<label>(8)</label></formula><formula xml:id="formula_13">where T i = (D train i , D test i )</formula><p>is the i-th sample from S train . ϕ is a proportional optimizable parameter which has shown good performance in few-shot learning <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> under conditions of SVM and RR as base-learners. Step 6 to 12 in Algorithm 1 has shown the inner loop".</p><p>After the inner loop", we obtain a preliminary optimized base-learner and then conduct the second step outer loop" on D test . In this part, encoding and decoding parameter φ e , φ d will be updated to improve generalizability to unseen samples through gradient-based optimization. The outer loop" is performed by minimizing the new loss L meta consisting of two parts:</p><formula xml:id="formula_14">L meta (S train ; θ, φ) = Ti∼S train [L test Ti (D test ; φ, θ, ϕ)+βL var ]<label>(9)</label></formula><p>where the first term is the deformation of (8) on D test and the second term uses a variation loss with optimizable weight β to regularize the latent space which is defined in <ref type="bibr" target="#b4">(5)</ref>.</p><p>Step 4 to 18 in Algorithm 1 has shown the outer loop". Once finishing the meta-training, we evaluate the generalizability of model to unseen data tuple S j = (D train j , D test j ), which is sampled from S test . Hence, we compute the loss for evaluation during meta-testing as follows:</p><formula xml:id="formula_15">L meta (S test ; θ, φ).<label>(10)</label></formula><p>We use the meta-testing set S test for evaluation, and the parameters of the model will not be updated in each episode S j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>We evaluate the proposed MCRNet for few-shot classification tasks on the unseen meta-testing set and compare it with the state-of-the-art methods.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>CIFAR-FS is a new standard benchmark for few-shot learning tasks, consisting of 100 classes from CIFAR-100 <ref type="bibr" target="#b36">[37]</ref>. These classes are randomly divided into 64, 16, and 20 classes for meta-training, meta-validation and meta-testing with 600 images of size 32 × 32 in each class.</p><p>FC100 is another dataset derived from CIFAR-100 and similar to CIFAR-FS. Differently, its 100 classes are grouped into 20 advanced classes and divided into 60 classes from 12 advanced classes for meta-training, 20 classes from 4 advanced classes for meta-validation, and 20 classes from 4 advanced classes for meta-testing. This dataset is intended to reduce the semantic similarity between classes.</p><p>MiniImageNet is a common dataset used for few-shot learning tasks with 100 classes randomly sampled from ILSVRC-2012 <ref type="bibr" target="#b37">[38]</ref> and divided into meta-training, metavalidation, and meta-testing sets with 64, 16, and 20 classes respectively. Each class contains 600 images of size 84 × 84, and we choose commonly-used class split in <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network architecture</head><p>In a nutshell, our method consists of meta-learner (including an encoder and a decoder), and base-learner. The encoder is composed of several convolution layers and sampling architecture, which is utilized to produce latent codes. The dimension of the latent space is determined by the encoder. Currently, there are two popular network models for the decoder to learn high-dimensional features in meta-learning, 4CONV and ResNet-12. Both of them consist of 4 blocks with several convolutions, Batch Normalization and pooling layers, but differ in the number of filters in each block. We choose ResNet-12 as the decoder in our method, considering the poor performance of 4CONV for few-shot learning <ref type="bibr" target="#b7">[8]</ref>. For the base-learner, we utilize two classic linear methods, multi-class SVM and RR.</p><p>In our experiment, the hyperparameters generally remain consistent with the baseline <ref type="bibr" target="#b28">[29]</ref> for fair comparisons. We apply stochastic gradient descent-based optimization and set the Nesterov momentum and weight decay to 0.9 and 0.0005, respectively. Totally, we meta-train the model for 60 epochs with 1000 episodes in each epoch. Besides, we set the learning rate to 0.1, 0.006, 0.0012, and 0.00024 at epochs 1, 20, 40, and 50 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results and analysis</head><p>1) Few-shot image classification: Our experimental results on the datasets are averaged over 1000 test episodes and summarized in <ref type="table" target="#tab_2">TABLE I and TABLE II.</ref> In general, compared to the baseline and current state-of-the-art methods, the accuracies of our model in 5-way 1-and 5-shot classification tasks both get improved.</p><p>As detailed in TABLE I, in 1-shot and 5-shot test, our method achieves 10.04% and 4.67% improvement over Finetuning <ref type="bibr" target="#b31">[32]</ref> on CIFAR-FS dataset. On FC100, compared to the baseline, our method gets improved by 2.3% in 5-shot classification tasks. TABLE II illustrates our experiment on miniImageNet dataset. Our method beats the baseline accuracy by 1.80% and 4.18% in 1-shot and 5-shot test respectively. On miniImageNet, the proposed MCRNet still achieves 4.84% and 2.75% improvement over the competitive method MTL <ref type="bibr" target="#b7">[8]</ref> and LEO <ref type="bibr" target="#b3">[4]</ref> in 5-shot classification respectively.</p><p>Our method provides a solution to break the representation limit in a high-dimensional parameter space through complementing the representation deficiency, and further fulfills the potential of ResNet-12 in representation learning. Intuitively, it outperforms those with ResNet-12, especially on CIFAR-FS and miniImageNet. Besides, collaborating well with different base-learners, MCRNet outperforms existing models on different datasets, revealing the good applicability of our method.</p><p>Although the methods in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b35">[36]</ref> use pre-trained or deeper feature extractors and TADAM <ref type="bibr" target="#b21">[22]</ref> co-trains the feature extractor on 5-and 64-way classification tasks to tackle the representation limit in few-shot learning, our method still achieves improvement generally. Besides, our model is metatrained end-to-end, allowing us to clearly observe the impact of latent space for meta-learning. Obviously, it is essential to complement the representation deficiency when using an expressive architecture in few-shot learning.</p><p>2) Ablation study: We reproduce the baseline <ref type="bibr" target="#b28">[29]</ref> and the state-of-the-art LEO <ref type="bibr" target="#b3">[4]</ref> with the provided code on miniIm-ageNet using ResNet-12 and compare with them in terms of convergence rate. As shown in <ref type="figure" target="#fig_1">Fig. 4(a)</ref>, the number of tasks required to reach convergence is almost the same as the baseline, but our method achieves higher accuracy. LEO needs a pre-trained raw embedding network. It adopts MAML as its training methods, and the relation network is embedded in it. Therefore, it is hard for LEO to train the whole model well and more iterations are needed to reach convergence. As shown in <ref type="table" target="#tab_2">Table II</ref>, compared to the LEO with ResNet-12, the accuracies of our method get improved by 3.86% and 6.69% in 5 way 1-and 5-shot classification on miniImageNet respectively. <ref type="figure" target="#fig_1">Fig. 4(b)</ref> shows some examples of representation output from baseline and our model. As we can see from the red box, our model is able to learn more details, thanks to the complemented representations. Compared to the baseline, the representation outputs generated from our model tend to perform better, such as higher brightness and sharper texture, which is beneficial to better generalization.</p><p>In regard to the influence of the latent space dimension on the model's performance, as shown in TABLE III, we found that for a particular dataset and base-learner, there is a suitable latent space dimension that contributes to the improvement of generalizability. In our experiments, this value is mostly 64, which means the huge potential of our method in the high latent dimension. Remarkably, with dimension 64, our method achieves about 4% improvement in 5-way classification accuracy on miniImageNet. However, considering the interface with ResNet-12 and fair comparison, the dimension setting in our experiment is up to 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we proposed an MCRNet for few-shot learning, which achieved state-of-the-art performance on the challenging 5-way 1-and 5-shot CIFAR and ImageNet classification problems. The MCRNet made use of a probabilistic framework to learn a latent space to complement the representation deficiency with extra representation information and broke the representation limit in a high-dimensional parameter space, resulting in better generalization across tasks. The experimental results also demonstrated the good performance of our method when applying to different base-learners.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :</head><label>3</label><figDesc>Process of data transformation. The latent code is endued extra information, when reconstructed in latent space Z, to complement the representation deficiency. It will be subsequently decoded in high-dimensional parameter space Θ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 :</head><label>4</label><figDesc>(a) Comparison of convergence on miniImageNet. Accuracies are obtained on meta-validation set after each epoch. (b) Some examples of the representation output from baseline and MCRNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1</head><label>1</label><figDesc>MCRNet Input: Meta-training set S train ; Encoding function f φe , and decoding function f φ d ; Learning rate λ, η 1: Initialize φ e , φ d randomly 2: Let φ = {φ e , φ d , λ} 3: while new batch do</figDesc><table><row><cell>4:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>Comparisons of average classification accuracy (%) with 95% confidence intervals on the CIFAR-FS and FC100. SVM" or RR" means using SVM or Ridge Regression as base-learner.</figDesc><table><row><cell>method</cell><cell>backbone</cell><cell cols="2">CIFAR-FS</cell><cell cols="2">FC100</cell></row><row><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Relation Networks [24]</cell><cell>4CONV</cell><cell>55.0 ± 1.0</cell><cell>69.3 ± 0.8</cell><cell>-</cell><cell>-</cell></row><row><cell>Prototypical Networks [15]</cell><cell>4CONV</cell><cell>55.5 ± 0.7</cell><cell>72.0 ± 0.6</cell><cell>35.3 ± 0.6</cell><cell>48.6 ± 0.6</cell></row><row><cell>MAML [13]</cell><cell>4CONV</cell><cell>58.9 ± 1.9</cell><cell>71.5 ± 1.0</cell><cell>-</cell><cell>-</cell></row><row><cell>R2D2 [21]</cell><cell>4CONV</cell><cell>65.3 ± 0.2</cell><cell>79.4 ± 0.1</cell><cell>-</cell><cell>-</cell></row><row><cell>Fine-tuning [32]</cell><cell cols="5">ResNet-12 64.66 ± 0.73 82.13 ± 0.50 37.52 ± 0.53 55.39 ± 0.57</cell></row><row><cell>TADAM [22]</cell><cell>ResNet-12</cell><cell>-</cell><cell>-</cell><cell>40.1 ± 0.4</cell><cell>56.1 ± 0.4</cell></row><row><cell>MTL [8]</cell><cell>ResNet-12  ¶</cell><cell>-</cell><cell>-</cell><cell>43.6 ± 1.8</cell><cell>55.4 ± 0.9</cell></row><row><cell>Baseline-RR [29]</cell><cell>ResNet-12</cell><cell>72.6 ± 0.7</cell><cell>84.3 ± 0.5</cell><cell>40.5 ± 0.6</cell><cell>55.3 ± 0.6</cell></row><row><cell>Baseline-SVM [29]</cell><cell>ResNet-12</cell><cell>72.0 ± 0.7</cell><cell>84.2 ± 0.5</cell><cell>41.1 ± 0.6</cell><cell>55.5 ± 0.6</cell></row><row><cell>MCRNet-RR (ours)</cell><cell>ResNet-12</cell><cell>73.8 ± 0.7</cell><cell>85.2 ± 0.5</cell><cell>40.7 ± 0.6</cell><cell>56.6 ± 0.6</cell></row><row><cell>MCRNet-SVM (ours)</cell><cell>ResNet-12</cell><cell>74.7 ± 0.7</cell><cell>86.8 ± 0.5</cell><cell>41.0 ± 0.6</cell><cell>57.8 ± 0.6</cell></row><row><cell cols="2">¶ indicates that the method is not end-to-end.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc>Comparisons of average classification accuracy (%) with 95% confidence intervals on the miniImageNet. indicates those methods are not end-to-end. * indicates those methods that are reproduced by ourselves for comparison of convergence.</figDesc><table><row><cell>method</cell><cell>backbone</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Meta-Learning LSTM [23]</cell><cell>4CONV</cell><cell>43.44 ± 0.77</cell><cell>60.60 ± 0.71</cell></row><row><cell>Matching networks [14]</cell><cell>4CONV</cell><cell>43.56 ± 0.84</cell><cell>55.31 ± 0.73</cell></row><row><cell>MAML [13]</cell><cell>4CONV</cell><cell>48.70 ± 1.84</cell><cell>63.11 ± 0.92</cell></row><row><cell>Prototypical Networks [15]</cell><cell>4CONV</cell><cell>49.42 ± 0.78</cell><cell>68.20 ± 0.66</cell></row><row><cell>Relation Networks [24]</cell><cell>4CONV</cell><cell>50.44 ± 0.82</cell><cell>65.32 ± 0.70</cell></row><row><cell>R2D2 [21]</cell><cell>4CONV</cell><cell>51.2 ± 0.6</cell><cell>68.8 ± 0.1</cell></row><row><cell>SRAN [18]</cell><cell>ResNet-101  ¶</cell><cell>51.62 ± 0.31</cell><cell>66.16 ± 0.51</cell></row><row><cell>DN4 [33]</cell><cell>ResNet-12</cell><cell>54.37 ± 0.36</cell><cell>74.44 ± 0.29</cell></row><row><cell>SNAIL [26]</cell><cell>ResNet-12</cell><cell>55.71 ± 0.99</cell><cell>68.88 ± 0.92</cell></row><row><cell>Fine-tuning [32]</cell><cell>ResNet-12</cell><cell>56.67 ± 0.62</cell><cell>74.80 ± 0.51</cell></row><row><cell>TADAM [22]</cell><cell>ResNet-12  ¶</cell><cell>58.50 ± 0.30</cell><cell>76.70 ± 0.30</cell></row><row><cell>CAML [34]</cell><cell>ResNet-12</cell><cell>59.23 ± 0.99</cell><cell>72.35 ± 0.71</cell></row><row><cell>TPN [35]</cell><cell>ResNet-12</cell><cell>59.46</cell><cell>75.65</cell></row><row><cell>wDAE-GNN [36]</cell><cell>WRN-28-10</cell><cell>61.07 ± 0.15</cell><cell>76.75 ± 0.11</cell></row><row><cell>MTL [8]</cell><cell>ResNet-12  ¶</cell><cell>61.2 ± 1.8</cell><cell>75.5 ± 0.8</cell></row><row><cell>LEO [4]</cell><cell>WRN-28-10  ¶</cell><cell>61.76 ± 0.08</cell><cell>77.59 ± 0.12</cell></row><row><cell>LEO  *  [4] Baseline-RR [29] Baseline-SVM [29]</cell><cell>ResNet-12  ¶ ResNet-12 ResNet-12</cell><cell>58.67 ± 0.07  *  60.02 ± 0.64  *  60.73 ± 0.65  *</cell><cell>73.45 ± 0.12  *  76.51 ± 0.49  *  76.16 ± 0.49  *</cell></row><row><cell>MCRNet-RR (ours)</cell><cell>ResNet-12</cell><cell>61.32 ± 0.64</cell><cell>78.16 ± 0.49</cell></row><row><cell>MCRNet-SVM (ours)</cell><cell>ResNet-12</cell><cell>62.53 ± 0.64</cell><cell>80.34 ± 0.47</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>¶</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III :</head><label>III</label><figDesc>Comparisons of average classification accuracy (%) in different dimensions on the CIFAR-FS, FC100, and miniImageNet. Dimension shot CIFAR-FS FC100 miniImageNet RR SVM RR SVM RR SVM without MCRNet 1 72.6 72.0 40.5 41.1 60.0 60.7 8 1 69.4 70.1 39.0 39.8 57.2 58.7 16 1 70.3 71.2 39.2 40.4 58.4 60.1 32 1 72.9 72.5 40.7 40.7 60.3 61.5 64 1 73.8 74.7 40.4 41.0 61.3 62.5</figDesc><table><row><cell cols="2">Latent without MCRNet 1 84.3 84.2 55.3 55.5 76.5 76.2</cell></row><row><cell>8</cell><cell>5 82.6 83.8 53.5 54.0 75.8 75.4</cell></row><row><cell>16</cell><cell>5 83.8 84.3 54.0 55.4 76.4 77.5</cell></row><row><cell>32</cell><cell>5 84.5 85.5 56.6 56.6 76.9 79.0</cell></row><row><cell>64</cell><cell>5 85.2 86.8 55.4 57.8 78.2 80.3</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Poses guide spatiotemporal model for vehicle re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MultiMedia Modeling -25th International Conference, MMM 2019</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">11296</biblScope>
			<biblScope unit="page" from="426" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Squeeze-andexcitation wide residual networks in image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="395" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Augmentation invariant and instance spreading feature for softmax embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Person reidentification via ranking aggregation of similarity pulling and dissimilarity pushing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2553" to="2566" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generalized zero-and few-shot learning via aligned variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schonfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8247" to="8255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improved fewshot visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bateni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Masrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spot and learn: A maximum-entropy patch sampler for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-H</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6251" to="6260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Graph few-shot learning via knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Prototypical networks for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic metalearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9537" to="9548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bayesian model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7343" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Self-attention relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="198" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised embedding learning via invariant and spreading instance feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6210" to="6219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="719" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Few-shot bayesian imitation learning with logic over programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Lew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gradient-based meta-learning with learned layerwise metric and subspace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2933" to="2942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the algorithmic implementation of multiclass kernel-based vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="265" to="292" />
			<date type="published" when="2002-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Revisiting local descriptor based image-to-class measure for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7260" to="7268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to learn with conditional class dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Varno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chapados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generating classification weights with GNN denoising autoencoders for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Cifar-100 (canadian institute for advanced research)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
