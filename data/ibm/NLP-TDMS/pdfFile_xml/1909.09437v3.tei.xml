<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Underwater Image Super-Resolution using Deep Residual Multipliers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Md</roleName><forename type="first">Jahidul</forename><surname>Islam</surname></persName>
							<email>islam034@umn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Minnesota Robotics Institute</orgName>
								<orgName type="laboratory">Interactive Robotics and Vision Laboratory</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>Twin Cities</addrLine>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadman</forename><surname>Sakib Enan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Minnesota Robotics Institute</orgName>
								<orgName type="laboratory">Interactive Robotics and Vision Laboratory</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>Twin Cities</addrLine>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peigen</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Minnesota Robotics Institute</orgName>
								<orgName type="laboratory">Interactive Robotics and Vision Laboratory</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>Twin Cities</addrLine>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaed</forename><surname>Sattar</surname></persName>
							<email>junaed@umn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Minnesota Robotics Institute</orgName>
								<orgName type="laboratory">Interactive Robotics and Vision Laboratory</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>Twin Cities</addrLine>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Underwater Image Super-Resolution using Deep Residual Multipliers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a deep residual network-based generative model for single image super-resolution (SISR) of underwater imagery for use by autonomous underwater robots. We also provide an adversarial training pipeline for learning SISR from paired data. In order to supervise the training, we formulate an objective function that evaluates the perceptual quality of an image based on its global content, color, and local style information. Additionally, we present USR-248, a large-scale dataset of three sets of underwater images of 'high' (640×480) and 'low' (80×60, 160×120, and 320×240) spatial resolution. USR-248 contains paired instances for supervised training of 2×, 4×, or 8× SISR models. Furthermore, we validate the effectiveness of our proposed model through qualitative and quantitative experiments and compare the results with several state-of-the-art models' performances. We also analyze its practical feasibility for applications such as scene understanding and attention modeling in noisy visual conditions. arXiv:1909.09437v3 [eess.IV]  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visually-guided autonomous underwater vehicles require image synthesis and scene understanding in many important applications such as the monitoring of marine species and coral reefs <ref type="bibr">[18]</ref>, inspection of submarine cables and wreckage <ref type="bibr">[2]</ref>, human-robot collaboration <ref type="bibr">[22]</ref>, and more. Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs) are widely used in these applications, where they harness the synthesized images for visual attention modeling to make navigation decisions such as 'where to look or go next', 'which snapshots should be recorded', etc. However, despite often using high-end cameras, underwater images are often greatly affected <ref type="bibr">[23]</ref> by poor visibility, absorption, and scattering. Consequently, the objects of interest may appear blurred as the images lack important details. This problem exacerbates when the camera (i.e., robot) cannot get close to the objects to get a closer view, e.g., while following a fast-moving target, or surveying distant coral reefs or seabed. Fast and accurate techniques for Single Image Super-Resolution (SISR) can alleviate these problems by restoring the perceptual and statistical qualities of the low-resolution image patches. The existing literature based on deep Convolutional Neural Networks (CNNs) provides good solutions for automatic SISR <ref type="bibr">[8,</ref><ref type="bibr">32]</ref>. In particular, several Generative Adversarial Network (GAN)-based models provide state-of-the-art (SOTA) performance <ref type="bibr" target="#b51">[51,</ref><ref type="bibr">31]</ref> in learning to enhance image resolution from a large collection of paired or unpaired data <ref type="bibr" target="#b58">[58]</ref>. However, there are a few challenges involved in adopting such models for underwater imagery. First, the underwater images suffer from a set of unique distortions. For instance, they tend to have a dominating green or blue hue because the red wavelengths get absorbed in deep water <ref type="bibr">[11]</ref>. Other factors such as the lighting variations in different depths, amount of particles in the water, and scattering cause irregular non-linear distortions which result in low-contrast and blurry images <ref type="bibr">[23]</ref>. Consequently, the off-the-shelf SISR models trained on arbitrary images fail to generate realistic higher resolution underwater images. Secondly, the lack of large-scale underwater dataset restricts extensive research attempts for the training and performance evaluation of SISR models on underwater images. Because of the high costs and difficulties associated with acquiring real-world underwater data, the existing datasets (that were originally proposed for training object detection and image enhancement models) often contain synthetic images <ref type="bibr">[11]</ref> and/or their resolution are typically limited to 256 × 256 <ref type="bibr">[23]</ref>. Due to these challenges, designing SISR models for underwater imagery and investigating their applicability in real-world underwater robotic applications have not been explored in-depth in the literature.</p><p>We attempt to address these challenges by designing a novel SISR model that can learn to generate 2×, 4×, or 8× higher resolution (HR) underwater images from the respective low-resolution (LR) inputs. We also present a largescale underwater dataset that provides the three sets of LR-HR pairs of images used to train the proposed model. In addition, we perform thorough experimental evaluations of the proposed model and demonstrate its effectiveness compared to several existing SOTA models. Specifically, we make the following contributions in this paper:</p><p>(a) We present a fully-convolutional deep residual network-based generative model for underwater SISR, which we refer to as SRDRM. We also formulate an adversarial training pipeline (i.e., SRDM-GAN) by designing a multi-modal objective function that evaluates the perceptual image quality based on its global content, color, and local style information. In our implementation, SRDRM and SRDM-GAN can learn to generate 640 × 480 images from respective inputs of size 320 × 240, 80 × 60, or 160 × 120. SISR has been studied <ref type="bibr">[13,</ref><ref type="bibr">4,</ref><ref type="bibr">36]</ref> for nearly two decades in the area of signal processing and computer vision. Some of the classical SISR methods include statistical methods <ref type="bibr" target="#b47">[47,</ref><ref type="bibr">28,</ref><ref type="bibr">41]</ref>, patch-based methods <ref type="bibr">[15,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr">20]</ref>, sparse representation-based methods <ref type="bibr" target="#b54">[54]</ref>, random forest-based method <ref type="bibr">[44]</ref>, etc. In recent years, with the rapid development of deep learning-based techniques, this area of research has been making incredible progress. In the pioneering work, Dong et al. <ref type="bibr">[8]</ref> proposed a three-layer CNNbased end-to-end model named SRCNN, that can learn a non-linear LR-HR mapping without requiring any handcrafted features. Soon after, Johnson et al. <ref type="bibr">[25]</ref> showed that replacing the per-pixel loss with a perceptual loss (that quantifies image quality) gives better results for CNNbased SISR models. On the other hand, Kim et al. proposed deeper networks such as VDSR <ref type="bibr">[26]</ref>, DRCN <ref type="bibr">[27]</ref> and used contemporary techniques such as gradient clipping, skip connection, and recursive-supervision in order to improve the training further. Moreover, the sparse codingbased networks <ref type="bibr">[33]</ref>, residual block-based networks (e.g., EDSR <ref type="bibr">[32]</ref>, DRRN <ref type="bibr" target="#b49">[49]</ref>), and other CNN-based models <ref type="bibr">[45]</ref>, <ref type="bibr">[9]</ref> have been proposed that outperform SRCNN for SISR. These methods, however, have rather complex training pipelines, and are often prone to poor performance for large scaling factors (i.e., 4× and higher). Thus far, researchers have been trying to address these issues by using Laplacian pyramid-based networks (LapSRN) <ref type="bibr">[30]</ref>, dense skip connections (SRDenseNet) <ref type="bibr" target="#b50">[50]</ref>, deep residual networks (RDN) <ref type="bibr" target="#b59">[59]</ref>, etc.</p><p>The CNN-based SISR models learn a sequence of nonlinear filters from a large number of training images. This end-to-end learning of LR-HR mapping provide significantly better performance <ref type="bibr" target="#b55">[55]</ref> compared to using handcrafted filters, or traditional methods based on bicubic interpolation. On the other hand, Generative Adversarial Networks (GANs) <ref type="bibr">[16]</ref> employ a two-player min-max game where the 'generator' tries to fool the 'discriminator' by generating fake images that appear to be real (i.e., sampled from the HR distribution). Simultaneously, the discriminator tries to get better at discarding fake images and eventually (in equilibrium) the generator learns the underlying LR-HR mapping. GANs are known to provide SOTA performance for style transfer <ref type="bibr">[14]</ref> and image-to-image translation <ref type="bibr">[24]</ref> problems in general. As for SISR, the GANbased models can recover finer texture details <ref type="bibr">[46,</ref><ref type="bibr">5]</ref> while super-resolving at large up-scaling factors. For instance, Ledig et al. showed that SRGAN <ref type="bibr">[31]</ref> can reconstruct highfrequency details for an up-scaling factor of 4. Moreover, ESRGAN <ref type="bibr" target="#b51">[51]</ref> incorporates a residual-in-residual dense block that improves the SISR performance. Furthermore, DeblurGAN <ref type="bibr">[29]</ref> uses conditional GANs <ref type="bibr">[37]</ref> that allow constraining the generator to learn a pixel-to-pixel mapping <ref type="bibr">[24]</ref> within the LR-HR domain. Recently, inspired by the success of CycleGAN <ref type="bibr" target="#b60">[60]</ref> and DualGAN <ref type="bibr" target="#b56">[56]</ref>, Yuan et al. <ref type="bibr" target="#b58">[58]</ref> proposed a cycle-in-cycle GAN-based model that can be trained using unpaired data. However, such unpaired training of GAN-based SISR models are prone to instability and often produce inconsistent results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">SISR for Underwater Imagery</head><p>SISR techniques for underwater imagery, on the other hand, are significantly less studied. As mentioned in the previous section, this is mostly due to the lack of large-scale datasets that capture the distribution of the unique distortions prevalent in underwater imagery. The existing datasets are only suitable for underwater object detection <ref type="bibr">[22]</ref> and image enhancement <ref type="bibr">[23]</ref> tasks, as their image resolution is typically limited to 256 × 256, and they often contain synthetic images <ref type="bibr">[11]</ref>. Consequently, the performance and applicability of existing and novel SISR models for underwater imagery have not been explored in depth.</p><p>Nevertheless, a few research attempts have been made for underwater SISR which primarily focus on reconstructing better quality underwater images from their noisy or blurred counterparts <ref type="bibr">[6,</ref><ref type="bibr">12,</ref><ref type="bibr" target="#b57">57]</ref>. Other similar approaches have used SISR models to enhance underwater image sequence <ref type="bibr">[42]</ref>, and to improve fish recognition performance <ref type="bibr" target="#b48">[48]</ref>. Although these models perform reasonably well for the respective applications, there is still significant room for improvement to match the SOTA performance. We attempt to address these aspects in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">USR-248 Dataset</head><p>The USR-248 dataset contains a large collection of HR underwater images and their respective LR pairs. As mentioned earlier, there are three sets of LR images of size 80 × 60, 160 × 120, and 320 × 240; whereas, the HR images are of size 640 × 480. Each set has 1060 RGB images for training and validation; another 248 test images are provided for benchmark evaluation. A few sample images from the dataset are provided in <ref type="figure" target="#fig_2">Fig. 2</ref>.</p><p>To prepare the dataset, we collected HR underwater images: i) during various oceanic explorations and field experiments, and ii) from publicly available Flickr TM images and YouTube TM videos. The field experiments are performed in a number of different locations over a diverse set of visibility conditions. Multiple GoPros <ref type="bibr" target="#b76">[17]</ref>, Aqua AUV's uEye cameras <ref type="bibr">[10]</ref>, low-light USB cameras <ref type="bibr">[3]</ref>, and Trident ROV's HD camera <ref type="bibr">[39]</ref> are used to collect HR images dur-ing the experiments. We also compiled HR underwater images containing natural scenes from Flickr TM , YouTube TM , and other online resources 1 . We avoided multiple instances of similar scenes and made sure they contain different objects of interest (e.g., coral reefs, fish, divers, wrecks/ruins, etc.) in a variety of backgrounds. <ref type="figure" target="#fig_3">Fig. 3</ref> shows the modality in the data in terms of object categories. Once the HR images are selected and resized to 640 × 480, three sets of LR images are generated by compressing and then gradually downsizing the images to 320 × 240, 160 × 120, and 80 × 60; a comparison of the average file sizes for these image sets are shown in <ref type="figure" target="#fig_2">Fig. 2c</ref>. Overall, USR-248 provides large-scale paired data for training 2×, 4×, and 8× underwater SISR models. It also includes the respective validation and test sets that are used to evaluate our proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SRDRM and SRDRM-GAN Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Deep Residual Multiplier (DRM)</head><p>The core element of the proposed model is a fullyconvolutional deep residual block, designed to learn 2× interpolation in the RGB image space. We denote this building block as Deep Residual Multiplier (DRM) as it scales the input features' spatial dimensions by a factor of two. As illustrated in <ref type="figure">Figure 4a</ref>, DRM consists of a convolutional (conv) layer, followed by 8 repeated residual layers, then another conv layer, and finally a de-convolutional (i.e., deconv) layer for up-scaling. Each of the repeated residual layers (consisting of two conv layers) is designed by following the principles outlined in the EDSR model <ref type="bibr">[32]</ref>. Several choices of hyper-parameters, e.g., the number of filters in each layer, the use of ReLU non-linearity <ref type="bibr">[38]</ref>, and/or Batch Normalization (BN) <ref type="bibr">[21]</ref> are annotated in <ref type="figure">Fig. 4a</ref>. As a whole, DRM is a 10 layer residual network that learns to scale up the spatial dimension of input features by a factor of two. It uses a series of 2D convolutions of size 3 × 3 (in repeated residual block) and 4 × 4 (in the rest of the network) to learn this spatial interpolation from paired training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">SRDRM Architecture</head><p>As <ref type="figure">Fig. 4b</ref> demonstrates, the SRDRM makes use of n ∈ {1, 2, 3} DRM blocks in order to learn to generate 2 n × HR outputs. An additional conv layer with tanh nonlinearity <ref type="bibr">[43]</ref> is added after the final DRM block in order to reshape the output features to the desired shape. Specifically, it generates a 2 n w × 2 n h × 3 output for an input of size w × h × 3.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">SRDRM-GAN Architecture</head><p>For adversarial training, we use the same SRDRM model as the generator and employ a Markovian PatchGAN [24]based model for the discriminator. As illustrated by <ref type="figure">Fig. 4c</ref>, nine conv layers are used to transform a 640 × 480 × 6 input (real and generated image) to a 40 × 30 × 1 output that represents the averaged validity responses of the discriminator. At each layer, 3 × 3 convolutional filters are used with a stride size of 2, followed by a Leaky-ReLU nonlinearity <ref type="bibr">[34]</ref> and BN. Although traditionally PatchGANs use 70 × 70 patches <ref type="bibr">[24,</ref><ref type="bibr" target="#b56">56]</ref>, we use a patch-size of 40 × 30 as our input/output image-shapes are of 4:3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Objective Function Formulation</head><p>At first, we define the SISR problem as learning a function or mapping G : {X} → Y , where X (Y ) represents the LR (HR) image domain. Then, we formulate an objective function that evaluates the following properties of G(X) compared to Y : 1) Global similarity and perceptual loss: existing methods have shown that adding an L 1 (L 2 ) loss to the objective function enables the generator to learn to sample from a globally similar space in an L 1 (L 2 ) sense <ref type="bibr">[24]</ref>. In our implementation, we measure the global similarity loss as: L 2 (G) = E X,Y Y − G(X) 2 . Additionally, as suggested in <ref type="bibr" target="#b6">[7]</ref>, we define a perceptual loss function based on the per-channel disparity between G(X) and Y as:</p><formula xml:id="formula_0">L P (G) = E X,Y (512 +r)r 2 + 4g 2 + (767 −r)b 2 2 .</formula><p>Here, r, g, and b denote the normalized numeric differences of the red, green, and blue channels between G(X) and Y , respectively; whereasr is the mean of their red channels.</p><p>2) Image content loss: being inspired by the success of existing SISR models <ref type="bibr" target="#b55">[55]</ref>, we also formulate the content loss as:</p><formula xml:id="formula_1">L C (G) = E X,Y Φ(Y ) − Φ(G(X)) 2 .</formula><p>Here, the function Φ(·) denotes the high-level features extracted by the block5 conv4 layer of a pre-trained VGG-19 network.</p><p>Finally, we formulate the multi-modal objective function for the generator as: (c) Discriminator: a Markovian PatchGAN <ref type="bibr">[24]</ref> with nine layers and a patch-size of 40 × 30 <ref type="figure">Figure 4</ref>: Network architecture of the proposed model.</p><formula xml:id="formula_2">L G (G) = λ c L C (G) + λ p L P (G) + + 8x w x h x f (input)</formula><formula xml:id="formula_3">λ 2 L 2 (G).</formula><p>Here, λ c , λ p , and λ 2 are scalars that are empirically tuned as hyper-parameters. Therefore, the generator G needs to solve the following minimization problem:</p><formula xml:id="formula_4">G * = arg min G L G (G).<label>(1)</label></formula><p>On the other hand, adversarial training requires a twoplayer min-max game <ref type="bibr">[16]</ref> between the generator G and discriminator D, which is expressed as:</p><formula xml:id="formula_5">L(G, D) = E X,Y log D(Y ) +E X,Y log(1−D(X, G(X))) . (2)</formula><p>Here, the generator tries to minimize L(G, D) while the discriminator tries to maximize it. Therefore, the optimization problem for adversarial training becomes:</p><formula xml:id="formula_6">G * = arg min G max D L GAN (G, D) + L G (G).</formula><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Implementation</head><p>We use TensorFlow libraries <ref type="bibr" target="#b0">[1]</ref> to implement the proposed SRDRM and SRDRM-GAN models. We trained both the models on the USR-248 dataset up to 20 epochs with a batch-size of 4, using two NVIDIA TM GeForce GTX 1080 graphics cards. We also implement a number of SOTA generative and adversarial models for performance comparison in the same setup. Specifically, we consider three generative models named SRCNN <ref type="bibr">[8]</ref>, SRResNet <ref type="bibr">[31,</ref><ref type="bibr" target="#b55">55]</ref>, and DSRCNN <ref type="bibr">[35]</ref>, and three adversarial models named SR-GAN <ref type="bibr">[31]</ref>, ESRGAN <ref type="bibr" target="#b51">[51]</ref>, and EDSRGAN <ref type="bibr">[32]</ref>. We already provided a brief discussion on the SOTA SISR models in Section 2. Next, we present the experimental results based on qualitative analysis and quantitative evaluations in terms of standard metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Qualitative Evaluations</head><p>At first, we analyze the sharpness and color consistency in the generated images of SRDRM and SRDRM-GAN. As <ref type="figure">Fig. 5</ref> suggests, both models generate images that are comparable to the ground truth for 4× SISR. We observe even better results for 2× SISR, as it is a relatively less challenging problem. We demonstrate this relative performance margins at various scales in <ref type="figure">Fig. 6</ref>. This comparison shows that the global contrast and texture is mostly recovered in the 2× and 4× HR images generated by SR-DRM and SRDRM-GAN. On the other hand, the 8× HR images miss the finer details and lack the sharpness in hightexture regions. The state-of-the-art SISR models have also reported such difficulties beyond the 4× scale <ref type="bibr" target="#b55">[55]</ref>.</p><p>Next, in <ref type="figure">Fig. 7</ref>, we provide a qualitative performance comparison with the state-of-the-art models for 4× SISR. We select multiple 160 × 120 patches on the test images containing interesting textures and objects in contrasting background. Then, we apply all the SISR models (trained on 4× USR-248 data) to generate respective HR images of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SRDRM-GAN SRDRM</head><p>G. Truth (HR) | Input (LR) <ref type="figure">Figure 5</ref>: Color consistency and sharpness of the generated 4× HR images compared to the respective ground truth. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Quantitative Evaluation</head><p>We consider two standard metrics <ref type="bibr">[19,</ref><ref type="bibr">23]</ref> named Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity (SSIM) in order to quantitatively compare the SISR models' performances. The PSNR approximates the reconstruction quality of generated images compared to their respective ground truth, whereas the SSIM <ref type="bibr" target="#b52">[52]</ref> compares the image patches based on three properties: luminance, contrast, and structure. In addition, we consider Underwater Image Quality Measure (UIQM) <ref type="bibr">[40]</ref>, which quantifies underwater image colorfulness, sharpness, and contrast. We evaluate all the SISR models on USR-248 test images, and compare their performance in <ref type="table" target="#tab_2">Table 1</ref>. The results indicate that SRDRM-GAN, SRDRM, SRGAN, and SRResNet produce comparable values for PSNR and SSIM, and perform better than other models. SRDRM and SRDRM-GAN also produce higher UIQM scores than other models in comparison. These statistics are consistent with our qualitative analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Practical Feasibility</head><p>The qualitative and quantitative results suggest that SR-DRM and SRDRM-GAN provide good quality HR visualizations for LR image patches, which is potentially useful in tracking fast-moving targets, attention modeling, and detailed understanding of underwater scenes. Therefore, AUVs and ROVs can use this to zoom in a particular region of interest (RoI) for detailed and improved visual perception. One operational consideration for using such deep learning-based models in embedded robotic platforms is the 2X 4X 8X <ref type="figure">Figure 6</ref>: Global contrast and texture recovery by SRDRM and SRDRM-GAN for 2×, 4×, and 8× SISR.  <ref type="table" target="#tab_3">Table 2</ref>, the memory requirement for the proposed model is only 3.5-12 MB and it runs at 4-7 fps on NVIDIA TM Jetson TX2. Therefore, it essentially takes about 140-246 milliseconds for a robot to take a closer look at a LR RoI. These results validate the feasibility of using the proposed model for improving real-time perception of visually-guided underwater robots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SRDRM-GAN SRDRM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we present a fully-convolutional deep residual network-based model for underwater image superresolution at 2×, 4×, and 8× scales. We also provide generative and adversarial training pipelines driven by a multimodal objective function, which is designed to evaluate image quality based on its content, color, and texture information. In addition, we present a large-scale dataset named USR-248 which contains paired underwater images of various resolutions for supervised training of SISR models. Furthermore, we perform thorough qualitative and quantitative evaluations which suggest that the proposed model can learn to restore image qualities at a higher resolution for an improved visual perception. In the future, we seek to improve its performance for 8× SISR, and plan to further investigate its applicability in other underwater robotic applications.  <ref type="figure">Figure 7</ref>: Qualitative performance comparison of SRDRM and SRDRM-GAN with SRCNN <ref type="bibr">[8]</ref>, SRResNet <ref type="bibr">[31,</ref><ref type="bibr" target="#b55">55]</ref>, DSR-CNN <ref type="bibr">[35]</ref>, SRGAN <ref type="bibr">[31]</ref>, ESRGAN <ref type="bibr" target="#b51">[51]</ref>, and EDSRGAN <ref type="bibr">[32]</ref>. (Best viewed at 400% zoom)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SRDRM-GAN SRDRM</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>SRDRM-GAN Generated: SRDRM 640 x 480 (a) Zoom-in capability: HR image generation from LR image patches Input 160 x 120 Scaled for comparison SRDRM: 4x output G. truth (640 x 480) (b) Realistic HR image generation: comparison with the ground truths Demonstration of underwater image superresolution using our proposed models: SRDRM and SRDRM-GAN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) A few instances sampled from the HR set; the HR images are of size 640 × 480.HR image (640 x 480) A particular HR ground truth image and its corresponding LR images are shown. Comparison of files sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The proposed USR-248 dataset has one HR set and three corresponding LR sets of images; hence, there are three possible combinations (i.e., 2×, 4× and 8×) for supervised training of SISR models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Modality in the USR-248 dataset based on major objects of interest in the scene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Comparison of average PSNR, SSIM, and UIQM scores for 2×/4×/8× SISR on USR-248 test set.</figDesc><table><row><cell></cell><cell>P SN R</cell><cell>SSIM</cell><cell>U IQM</cell></row><row><cell>Model</cell><cell>G(x), y</cell><cell>G(x), y</cell><cell>G(x)</cell></row><row><cell>SRResNet</cell><cell>25.98/24.15/19.26</cell><cell>0.72/0.66/0.55</cell><cell>2.68/2.23/1.95</cell></row><row><cell>SRCNN</cell><cell>26.81/23.38/19.97</cell><cell>0.76/0.67/0.57</cell><cell>2.74/2.38/2.01</cell></row><row><cell>DSRCNN</cell><cell>27.14/23.61/20.14</cell><cell>0.77/0.67/0.56</cell><cell>2.71/2.36/2.04</cell></row><row><cell>SRDRM</cell><cell>28.36/24.64/21.20</cell><cell>0.80/0.68/0.60</cell><cell>2.78/2.46/2.18</cell></row><row><cell>SRDRM-GAN</cell><cell>28.55/24.62/20.25</cell><cell>0.81/0.69/0.61</cell><cell>2.77/2.48/2.17</cell></row><row><cell>ESRGAN</cell><cell>26.66/23.79/19.75</cell><cell>0.75/0.66/0.58</cell><cell>2.70/2.38/2.05</cell></row><row><cell>EDSRGAN</cell><cell>27.12/21.65/19.87</cell><cell>0.77/0.65/0.58</cell><cell>2.67/2.40/2.12</cell></row><row><cell>SRGAN</cell><cell>28.05/24.76/20.14</cell><cell>0.78/0.69/0.60</cell><cell>2.74/2.42/2.10</cell></row><row><cell cols="4">size 640 × 480. In the evaluation, we observe that SRDRM</cell></row><row><cell cols="4">performs at least as well as and often better compared to the</cell></row><row><cell cols="4">generative models, i.e., SRResNet, SRCNN, and DSRCNN.</cell></row><row><cell cols="4">Moreover, SRResNet and SRGAN are prone to inconsis-</cell></row><row><cell cols="4">tent coloring and over-saturation in bright regions. On the</cell></row><row><cell cols="4">other hand, ESRGAN and EDSRGAN often fail to restore</cell></row><row><cell cols="4">the sharpness and global contrast. Furthermore, SRDRM-</cell></row><row><cell cols="4">GAN generates sharper images and does a better texture re-</cell></row><row><cell cols="4">covery than SRDRM (and other generative models) in gen-</cell></row><row><cell cols="4">eral. We postulate that the PatchGAN-based discriminator</cell></row><row><cell cols="4">contributes to this, as it forces the generator to learn high-</cell></row><row><cell cols="4">frequency local texture and style information [24].</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Run-time and memory requirement of SRDRM (same as SRDRM-GAN) on NVIDIA TM Jetson TX2 (optimized graph).</figDesc><table><row><cell>Model</cell><cell>2×</cell><cell>4×</cell><cell>8×</cell></row><row><cell>Inference-time (ms)</cell><cell cols="2">140.6 ms 145.7 ms</cell><cell>245.7 ms</cell></row><row><cell>Frames per second (fps)</cell><cell>7.11 fps</cell><cell>6.86 fps</cell><cell>4.07 fps</cell></row><row><cell>Model-size</cell><cell>3.5 MB</cell><cell>8 MB</cell><cell>12 MB</cell></row></table><note>computational complexity. As we demonstrate in</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Detailed information and credits for the online media resources can be found in Appendix I.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TensorFlow: A System for Large-scale Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robotic Tools for Deep Water Archaeology: Surveying an Ancient Shipwreck with an Autonomous Underwater Vehicle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Camilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Delaporta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eustice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Field Robotics (JFR)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bluerobotics</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Low-Light</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Usb Camera</surname></persName>
		</author>
		<ptr target="https://www.bluerobotics.com/" />
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Super-resolution Through Neighbor Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<editor>I-I. IEEE</editor>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient and Accurate MRI Super-resolution using a Generative Adversarial Network and 3D Multi-level Densely Connected Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Christodoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-based Super-resolution Reconstruction Techniques for Underwater Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Photonics and Optoelectronics Meetings (POEM): Optoelectronic Sensing and Imaging</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">8332</biblScope>
			<biblScope unit="page">83320</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Perceptual Color Metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Compuphase</surname></persName>
		</author>
		<idno>12-12-2019. 4</idno>
		<ptr target="https://www.compuphase.com/cmetric.htm" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image Superresolution using Deep Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="295" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Accelerating the Superresolution Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="page" from="391" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dudek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Giguere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Prahacs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saunderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-A</forename><surname>Torres-Mendez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jenkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">An Amphibious Autonomous Robot. Computer</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Enhancing Underwater Imagery using Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sattar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Application of Blind Deconvolution Approach with Image Quality Metric in Underwater Image Restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Examplebased Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Pasztor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image Style Transfer using Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Super-resolution from a Single Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Glasner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bagon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="349" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>8-15-2019. 3</idno>
		<ptr target="https://gopro.com/" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coral Reefs under Rapid Climate Change and Ocean Acidification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hoegh-Guldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Mumby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hooten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Steneck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Greenfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">5857</biblScope>
			<biblScope unit="page" from="1737" to="1742" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image Quality Metrics: PSNR vs. SSIM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ziou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2366" to="2369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Single Image Superresolution from Transformed Self-exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5197" to="5206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>abs/1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Understanding Human Motion and Gestures for Underwater Human-Robot Collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sattar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Field Robotics (JFR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sattar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.09766</idno>
		<title level="m">Fast Underwater Image Enhancement for Improved Visual Perception</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image-toimage Translation with Conditional Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Perceptual Losses for Real-time Style Transfer and Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="page" from="694" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Accurate Image Super-resolution using Very Deep Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deeply-recursive Convolutional Network for Image Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1637" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Single-image Super-resolution using Sparse Regression and Natural Image Prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1127" to="1133" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deblurgan: Blind Motion Deblurring using Conditional Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kupyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Budzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mykhailych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8183" to="8192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep Laplacian Pyramid Networks for Fast and Accurate Superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="624" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Photo-realistic Single Image Super-resolution using a Generative Adversarial Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Enhanced Deep Residual Networks for Single Image Superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) workshops</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) workshops</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust Single Image Super-resolution via Deep Networks with Sparse Prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3194" to="3207" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rectifier Nonlinearities Improve Neural Network Acoustic Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-B</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08921</idno>
		<title level="m">Image Restoration using Convolutional Auto-encoders with Symmetric Skip Connections</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Super-resolution Imaging through a Planar Silver Layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">O</forename><surname>Melville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Blaikie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Express</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2127" to="2134" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional Generative Adversarial Nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trident</surname></persName>
		</author>
		<ptr target="https://www.openrov.com" />
		<imprint>
			<date type="published" when="2017-08-15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Human-visual-systeminspired Underwater Image Quality Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Panetta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agaian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Oceanic Engineering</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generalizing the Nonlocal-means to Super-resolution Reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Protter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="51" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Underwater Video Enhancement using Multicamera Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Quevedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Delory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Callicó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tobajas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sarmiento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Communications</title>
		<imprint>
			<biblScope unit="volume">404</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="94" to="102" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep Learning Made Easier by Linear Transformations in Perceptrons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="924" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fast and Accurate Image Upscaling with Super-resolution Forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3791" to="3799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Real-time Single Image and Video Super-resolution using an Efficient Sub-pixel Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1874" to="1883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Amortised Map Inference for Image Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.04490</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image Super-resolution using Gradient Profile Prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Fish Recognition from Low-resolution Underwater Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Congress on Image and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="471" to="476" />
		</imprint>
	</monogr>
	<note>BioMedical Engineering and Informatics (CISP-BMEI)</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Image Super-resolution via Deep Recursive Residual Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3147" to="3155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Image Super-resolution using Dense Skip Connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>of the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4799" to="4807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Esrgan: Enhanced Super-resolution Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C. Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the European Conference on Computer Vision (ECCV)</title>
		<meeting>of the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Image Quality Assessment: from Error Visibility to Structural Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Coupled Dictionary Training for Image Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3467" to="3478" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Image Superresolution via Sparse Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep learning for Single Image Super-resolution: A Brief Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">DualGAN: Unsupervised Dual Learning for Image-to-image Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>of the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">System of Remote-operated-vehicle-based Underwater Blurred Image Restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">116002</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unsupervised Image Super-resolution using Cycle-in-cycle Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Residual Dense Network for Image Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2472" to="2481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Unpaired Image-to-image Translation using Cycle-consistent Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>of the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Appendix I: Credits for Media Resources 1. Wallpapercave.com. Sea-turtle</title>
		<ptr target="https://wallpapercave.com/w/wp4430950" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Potato cod (Epinephelus tukula) -Great Barrier Reef -Australia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Gingins</surname></persName>
		</author>
		<ptr target="https://www.flickr.com/photos/simongingins/15574452614/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Cat Trumpet. 2 Hours of Beautiful Coral Reef Fish, Relaxing Ocean Fish</title>
		<ptr target="https://youtu.be/cC9r0jHF-Fw" />
		<imprint>
			<biblScope unit="page" from="1080" to="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Nature Relaxation Films. 3 Hours of Stunning Underwater Footage</title>
		<ptr target="https://youtu.be/eSRj847AY8U" />
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>French Polynesia, Indonesia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Calm Cove Club -Relaxing Videos. 4K Beautiful Ocean Clown Fish Turtle Aquarium</title>
		<ptr target="https://youtu.be/DP4QDNm6f4Q" />
		<imprint>
			<biblScope unit="volume">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">4K Underwater at Stuart Cove&apos;s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scubasnap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Com</surname></persName>
		</author>
		<ptr target="https://youtu.be/kiWfG31YbXo" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">SCUBA Diving Egypt Red Sea</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><forename type="middle">Ryan</forename><surname>Diving</surname></persName>
		</author>
		<ptr target="https://youtu.be/CaLfMHl3M2o" />
		<imprint>
			<biblScope unit="volume">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Sleep Music in Underwater Paradise</title>
		<ptr target="https://youtu.be/OVct34NUk3U" />
		<imprint>
			<biblScope unit="volume">2017</biblScope>
		</imprint>
	</monogr>
	<note>Soothing Relaxation</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">4K Coral World-Tropical Reef</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thesilentwatcher</surname></persName>
		</author>
		<ptr target="https://youtu.be/uyb0wW0ln_g" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Awesome Video. 4K-The Most Beautiful Coral Reefs and Undersea Creature on Earth</title>
		<ptr target="https://youtu.be/nvq_lvC1MRY" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Celebrating World Oceans Day in 4K</title>
		<ptr target="https://youtu.be/IXxfIMNgMJA" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Earth Touch</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Deep Ocean: Relaxing Oceanscapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bbc Earth</surname></persName>
		</author>
		<ptr target="https://youtu.be/t_S_cN2re4g" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Let&apos;s Go Under the Sea I Underwater Shark Footage I Relaxing Underwater Scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alegra</forename><surname>Chetti</surname></persName>
		</author>
		<ptr target="https://youtu.be/rQB-f5BHn5M" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">The Undersea World (4K)</title>
		<ptr target="https://youtu.be/567vaK3BKbo" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Underwater 3D Channel-Barry Chall Films. Planet Earth</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">ReefScapes: Nature&apos;s Aquarium&quot; Ambient Underwater Relaxing Natural Coral Reefs and Ocean Nature</title>
		<ptr target="https://youtu.be/muYaOHfP038" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Undersea Productions</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">The Coral Reef: 10 Hours of Relaxing Oceanscapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bbc Earth</surname></persName>
		</author>
		<ptr target="https://youtu.be/nMAzchVWTis" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Scuba Diving the Great Barrier Reef Red Sea Egypt Tiran</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robby</forename><surname>Michaelle</surname></persName>
		</author>
		<ptr target="https://youtu.be/b7BEAsyPgHM" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Diving in Bali</title>
		<ptr target="https://youtu.be/uCRBxtQ55_Y" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Bubble Vision</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Vic Stefanu -Amazing World Videos. EXPLORING The GREAT BARRIER REEF, fantastic UNDERWATER VIDEOS (Australia)</title>
		<ptr target="https://youtu.be/stMzgmPlQQM" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Breathtaking Dive in Raja Ampat</title>
		<ptr target="https://youtu.be/i4ZSMDWNXTg" />
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>West Papua, Indonesia Coral Reef</pubPlace>
		</imprint>
	</monogr>
	<note>Our Coral Reef</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Awards: Great Barrier Reef with Fusion Overcapture in 4K</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gopro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gopro</surname></persName>
		</author>
		<ptr target="https://youtu.be/OAmBkfn62dY" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Freediving with Tiger Sharks in 4K</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gopro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gopro</surname></persName>
		</author>
		<ptr target="https://youtu.be/Zy3kdMFvxUU" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tfil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>With Sharks!</surname></persName>
		</author>
		<ptr target="https://youtu.be/v8eSPf4RzTU" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Stunning salt Water Fishes in a Marine Aquarium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annette</forename><surname>Vins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
		<ptr target="https://youtu.be/CWzXL6a4KGM" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Submarine Perseus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">H</forename><surname>Akouris</surname></persName>
		</author>
		<ptr target="https://youtu.be/4-oP0sX723k" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Navy Divers View An Underwater Wreck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gung</forename><forename type="middle">U S</forename><surname>Ho Vids</surname></persName>
		</author>
		<ptr target="https://youtu.be/1qfRQRUMnXY" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Truk lagoon deep wrecks, GoPro black with SRP tray and lights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martcerv</surname></persName>
		</author>
		<ptr target="https://youtu.be/0uD-nCN03s8" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Shipwreck Diving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dmireiy</surname></persName>
		</author>
		<ptr target="https://youtu.be/CIQI3isddbE" />
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Nassau Bahamas</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Frank Lame. diving WWII Wrecks around Palau</title>
		<ptr target="https://youtu.be/vcI63XQsNlI" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Wreck Dives Malta</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stevanurk</surname></persName>
		</author>
		<ptr target="https://youtu.be/IZFuOIwEBH8" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Diving Malta, Gozo and Comino 2015 Wrecks Caves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stevanurk</surname></persName>
		</author>
		<ptr target="https://youtu.be/NrDDjnij7sA" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">SHIPWRECK Scuba Diving BA-HAMAS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavio</forename><surname>Velazquez Lozano</surname></persName>
		</author>
		<ptr target="https://youtu.be/4ovFPCEw4Qk" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">SCUBA Diving The Sunken Ancient Roman City Of Baiae, the Underwater Pompeii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Drew</forename><surname>Kaplan</surname></persName>
		</author>
		<ptr target="https://youtu.be/8RmJ3jzrwH8" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">LIBERTY SHIPWRECK scuba dive destin florida</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavio</forename><surname>Velazquez Lozano</surname></persName>
		</author>
		<ptr target="https://youtu.be/DHuHZdVWONk" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">BlueROV2 Dive: Hawaiian Open Water</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blue Robotics</surname></persName>
		</author>
		<ptr target="https://youtu.be/574jPVEk7mo" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Exploring a Plane Wreck -UNDER WATER!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jerryrigeverything</surname></persName>
		</author>
		<ptr target="https://youtu.be/0-sZVJbUzqo" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Home-built Underwater Robot ROV in Action!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rovrobotsubmariner</surname></persName>
		</author>
		<ptr target="https://youtu.be/khLEyyf3Ci8" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Eca-Robotics H800 ROV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oded</forename><surname>Ezra</surname></persName>
		</author>
		<ptr target="https://youtu.be/Yafq9c7cqgE" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Titan Diving Drone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geneinno</forename><surname>Tech</surname></persName>
		</author>
		<ptr target="https://youtu.be/h7Bn4MxkFxs" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Scubo -Agile Multifunctional Underwater Robot -ETH Zurich</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scubo</surname></persName>
		</author>
		<ptr target="https://youtu.be/-g2O8e1j3fw" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Student-built Underwater Robot at Shedd ROV Club Event</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Learning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shedd</surname></persName>
		</author>
		<ptr target="https://youtu.be/y3dn8snT8os" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">SQUIDBOT sea trials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hmu-Csrl</surname></persName>
		</author>
		<ptr target="https://youtu.be/0iDBF23gI6I" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Aqua2 Underwater Robot Navigates in a Coral Reef -Barbados</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mobilerobots</surname></persName>
		</author>
		<ptr target="https://youtu.be/jC-AmPfInwU" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title/>
		<ptr target="https://youtu.be/neLu0ZGuXPM" />
	</analytic>
	<monogr>
		<title level="j">Daniela Rus. underwater robot</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Sirius -Underwater Robot, Mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnfardoulis</surname></persName>
		</author>
		<ptr target="https://youtu.be/fXxVcucOPrs" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
