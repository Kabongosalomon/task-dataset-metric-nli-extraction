<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Capsule Routing via Variational Bayes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>De</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">University of Lincoln</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sousa</forename><surname>Ribeiro</surname></persName>
							<email>fdesousaribeiro@lincoln.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">University of Lincoln</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Leontidis</surname></persName>
							<email>gleontidis@lincoln.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">University of Lincoln</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Kollias</surname></persName>
							<email>skollias@lincoln.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Machine Learning Group</orgName>
								<orgName type="institution">University of Lincoln</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Capsule Routing via Variational Bayes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Capsule networks are a recently proposed type of neural network shown to outperform alternatives in challenging shape recognition tasks. In capsule networks, scalar neurons are replaced with capsule vectors or matrices, whose entries represent different properties of objects. The relationships between objects and their parts are learned via trainable viewpointinvariant transformation matrices, and the presence of a given object is decided by the level of agreement among votes from its parts. This interaction occurs between capsule layers and is a process called routing-by-agreement. In this paper, we propose a new capsule routing algorithm derived from Variational Bayes for fitting a mixture of transforming gaussians, and show it is possible transform our capsule network into a Capsule-VAE. Our Bayesian approach addresses some of the inherent weaknesses of MLE based models such as the variance-collapse by modelling uncertainty over capsule pose parameters. We outperform the state-of-the-art on small-NORB using 50% fewer capsules than previously reported, achieve competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous works. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Capsule networks are a recently proposed method of learning part-whole relationships between observed entities in data, by using groups of neurons known as capsules. These entities could be anything that possesses a consistent underlying structure across viewpoints. Capsules attempt to encode intrinsic viewpoint-invariant properties, and learn to adjust instantiation parameters as the entity varies across its appearance manifold <ref type="bibr" target="#b7">(Hinton, Krizhevsky, and Wang 2011)</ref>. CapsNets have shown to outperform standard Convolutional Neural Networks (CNNs) in specific tasks involving shape recognition and overlapping digit segmentation. These tasks are difficult for standard CNNs, as they struggle to exploit the frame of reference humans impose on objects, and thus often fail to generalise knowledge to novel viewpoints. Although this drawback can often be mitigated by data augmentation during training, it does not address the underlying issue directly. Nonetheless, CNNs perform remarkably well 1 https://github.com/fabio-deep/Variational-Capsule-Routing  <ref type="figure">Figure 1</ref>: Depiction of Variational Bayes (VB) routing between adjacent capsule layers: with lower layer capsules i ∈ L i (orange) and higher layer capsules j ∈ L j (blue).</p><p>in practice, partly because they make structural assumptions that ring true with natural images. Capsules extend this rationale by assuming objects are composed of object parts, and if we learn part-whole relationships perfectly then we can better generalise to novel viewpoints and affine transformations. In CNNs, the convolution operator and sparse weight sharing provides the useful property of equivariance under translation, enabling efficient spatial transfer of knowledge. CapsNets retain these benefits and only do away with pooling operations in favour of learning more robust representations for disentangling factors of variation with routing-byagreement. Although promising, CapsNets remain underexplored, and few works thus far have proposed algorithmic improvements to the original formulations. In this paper, we propose a new capsule routing algorithm for fitting a mixture of transforming gaussians via Variational Bayes, which offers increased training stability, flexibility and performance. <ref type="bibr">arXiv:1905.11455v3 [cs.</ref>LG] 3 Dec 2019</p><p>Capsule Networks CapsNets are composed of at least one layer of capsules in which capsules i from a lower layer L i (children) are routed to capsules j in a higher layer L j (parents). Each layer contains multiple lower capsules, each of which has a pose matrix M i ∈ R 4×4 of instantiation parameters and activation probability a i (see <ref type="figure" target="#fig_1">Figure 2</ref>). The pose matrix may learn to encode the relationship of an entity to the viewer, and the activation probability a i represents its presence. Each lower level capsule uses its pose matrix M i to posit a vote for what the pose of a higher level capsule should be, by multiplying it with a trainable viewpointinvariant transformation weight matrix</p><formula xml:id="formula_0">V j|i = M i W ij ,<label>(1)</label></formula><p>where V j|i denotes the vote coming from capsules i to capsule j, and W ij ∈ R 4×4 is the trainable transformation matrix. To compute the pose matrix M j of any higher level capsule j we can simply take a weighted mean of the votes it received from capsules in L i as in EM routing <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref></p><formula xml:id="formula_1">: M j = 1/R j i V j|i R ij ,</formula><p>where R ij represents the posterior responsibilities of each capsule j for capsules i, and R j = i R ij . These routing coefficients can be tuned via a variant of the EM algorithm for Gaussian Mixtures, and are updated according to the agreement between V j|i and M j , which in Dynamic routing <ref type="bibr" target="#b18">(Sabour, Frosst, and Hinton 2017)</ref> for example, is simply the scalar product between capsule vectors and can be trivially extended to matrices with M j − V j|i F . Lastly, a parent capsule j is only activated if there is a measurably high agreement among the votes V j|i from child capsules i for its pose matrix M j , which forms a tight cluster in R D .</p><p>Motivation &amp; Contributions In this paper, we propose a new capsule routing algorithm derived from Variational Bayes. We show that our probabilistic approach provides advantages over previous routing algorithms, including more flexible control over capsule complexity by tuning priors to induce sparsity, and reducing the well known variancecollapse singularities inherent to MLE based mixture models such as EM. Contextually, these singularities occur in part due to the single parent assumption-whereby a parent capsule (gaussian cluster) can claim sole custody of a child capsule (datapoint), yielding infinite likelihood and zero variance. This leads to overfitting and unstable training. By modelling uncertainty over the capsule parameters as well as the routing weights, we can avoid these singularities in a principled way, without adding arbitrary constants of minimum variance to ensure numerical stability, which can affect performance in EM. Furthermore, we provide some insight into capsule network training for practitioners including weight initialisation and normalisation schemes that improve training performance. Lastly, we show it's possible to transform our capsule network into a Capsule-VAE by sampling latent code from capsule parameter approximate posteriors. We outperform the state-of-the-art on smallNORB using 50% fewer capsules than previously reported, achieve highly competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Variational Bayes Capsule Routing</head><p>Next, we briefly outline some necessary background on Variational Inference (VI), before contextualising some of these ideas with our proposed capsule routing algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Variational Inference</head><p>The Evidence Lower Bound Let x denote the observed data, z denote latent variables associated with x, and let θ represent some model parameters. Typically we'd like to infer the unknown latent variables, by evaluating the conditional p(z|x, θ) which is the posterior on z. However, this distribution cannot be computed for most complex models due to the intractability of a normalising integral. VI provides an elegant solution to posterior inference by posing it as an optimisation problem. We approximate the posterior p(z|x, θ) by choosing a variational distribution over the latent variables q φ (z) from a tractable family, with its own variational parameters φ. We can measure the quality of our approximation via the Kullback-Leibler (KL) divergence KL[q φ (z) || p(z|x, θ)] between the two distributions, which can be minimised via the variational parameters φ</p><formula xml:id="formula_2">φ = arg min φ E q φ (z) [log q φ (z) − log p(z|x, θ)]. (2)</formula><p>However, since p(z|x, θ) is unknown we cannot minimise the KL directly, so instead we maximise the variational lower bound (ELBO) on the log marginal likelihood</p><formula xml:id="formula_3">log p(x|θ) = KL[q φ (z) || p(z|x, θ)] + L ELBO (q φ (z)), (3)</formula><p>where the ELBO can be derived using Jensen's inequality log(E[X]) ≥ E[log(X)] applied to log p(x|θ) giving</p><formula xml:id="formula_4">log p(x|θ) ≥ L ELBO (q φ (z)) = = E q φ (z) [log p(x, z|θ)] − E q φ (z) [log q φ (z)].<label>(4)</label></formula><p>Here we use the joint log p(x, z|θ) which is tractable, rather than the unknown posterior log p(z|x, θ). Recall that from the product rule of probability we simply have that p(x, z|θ) = p(z|x, θ)p(x|θ). Given that the log marginal likelihood of the data log p(x|θ) is always negative and is independent of q φ (z), maximising the ELBO is therefore equivalent to minimising the KL divergence.</p><p>Mean Field A popular way of performing VI is to posit a factorised form of the approximating family of distributions q φ (z), such that each variable is assumed to be independent</p><formula xml:id="formula_5">p(z|x, θ) ≈ q φ (z) = N i=1 q φi (z i ), zi q φi (z i ) = 1. (5)</formula><p>Recall that the log marginal is given by log p(x|θ) = log z p(x, z|θ), and therefore the factorised objective to be maximised can be written in the following form arg max </p><formula xml:id="formula_6">q φ i (zi)∈q φ (z) N i=1 E q φ i (zi) [logp(x i , z i |θ)] − E q φ i (zi) [log q φi (z i )].<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Variational Bayes for a Mixture of Transforming Gaussians</head><p>Relation to Clustering Capsule routing naturally resembles clustering logic. This is reflected in the fact that any higher layer parent capsule j (cluster) is composed of, and receives votes from, many lower layer child capsules i (data points) within its receptive field (see <ref type="figure" target="#fig_1">Figure 2</ref> for intuition). However, capsule routing does differ from regular clustering substantially, as every cluster has its own learnable viewpoint-invariant transformation matrix W ij with which it transforms its data points, and predictions are made by measuring similarity among them. Therefore, each cluster sees a different view of the data, and the algorithm converges much faster since it's easier to break symmetry compared to simply initialising the gaussian clusters with different means <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>. Next we propose our capsule routing algorithm borrowing some ideas from <ref type="bibr" target="#b0">(Bishop 2006)</ref>, and begin by picking up from our general description of capsule networks in section 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed Method</head><p>Let v j|i ∈ R D denote a vectorised version of the 4x4 votes V j|i matrix, and let µ j ∈ R D denote a vectorised version of capsule j's 4x4 pose matrix M j , where D = 16. Assuming independence, consider the log likelihood function maximised in a Gaussian Mixture Model (GMM), applied to routing capsules i from a lower layer to capsules j in a higher layer</p><formula xml:id="formula_7">log p(v|π, µ, Λ) = i∈Li log j∈Lj π j N (v j|i |µ j , Λ −1 j ).</formula><p>(7) In EM routing, point estimates of the parameters µ j and diag(Λ j ) are computed in the M-step, and the routing probabilities R ij are evaluated in the E-step. The mixing coefficients π j however, are replaced with activations a j which represent the probability of cluster j being switched on, and are computed by a shifting logistic non-linearity. The a j 's play the role of the mixing proportions but j a j = 1. Recall from section 1 that the votes play the roles of the data points and are computed as V j|i = M i W ij , using different transformation matrices W ij for each capsule j.</p><p>In order to model uncertainty over the capsule parameters in our algorithm, we place conjugate priors over π, µ and Λ. Our model's generative process for any lower layer capsule i's vectorised pose µ i:Li can be derived from the following</p><formula xml:id="formula_8">v j|i | z i = j ∼ N (µ j , Λ −1 j ) z i ∼ Cat(z i |π) π | α 0 ∼ Dir(α 0 ) µ j | m 0 , κ 0 , Λ j ∼ N (m 0 , (κ 0 Λ j ) −1 ) Λ j | Ψ 0 , ν 0 ∼ Wi(Ψ 0 , ν 0 ),<label>(8)</label></formula><p>and µ i can be retrieved by simply inverting the vectorised vote transformation µ i = w −1 ij v j|i . The joint distribution of the model factorises as p(v, z, π, µ, Λ) = p(v|z, µ, Λ)p(z|π)p(π)p(µ|Λ)p(Λ), where the latent variables z are a collection of L i one-hot vectors denoting the cluster assignments of each of the lower capsules votes v j|i , to their corresponding higher capsules' gaussians. Following from the VI discussion in section 2.1, we approximate the posterior p(z, π, µ, Λ|v) ∝ p(v|z, µ, Λ)p(z|π)p(π)p(µ, Λ) with a factorised variational distribution</p><formula xml:id="formula_9">p(z, π, µ, Λ|v) ≈ q(z)q(π) j∈Lj q(µ j , Λ j ),<label>(9)</label></formula><p>and we choose conjugate priors that factor in the following standard form as in Bayesian Gaussian Mixtures</p><formula xml:id="formula_10">p(π)p(µ, Λ) = Dir(π|α 0 ) × j∈Lj N µ j |m 0 , (κ 0 Λ j ) −1 Wi(Λ j |Ψ 0 , ν 0 ). (10)</formula><p>To parameterise diagonal precisions in practice, we simply let λ j ∈ R D represent the diagonal entries of Λ j , and replace the Gaussian-Wishart prior with Gaussian-Gamma priors over each diagonal entry λ d j as follows</p><formula xml:id="formula_11">p(µ|λ)p(λ) = j∈Lj D d=1 N (µ d j |m 0 , (κ 0 λ d j ) −1 )Ga(λ d j |s 0 , ν 0 ).<label>(11)</label></formula><p>Algorithm 1 Variational Bayes Capsule Routing 1: function VB ROUTING(ai, v j|i ) Input votes and activations from preceding capsule layer Li 2:</p><p>Initialise routing weights ∀ i,j : rij ← 1/Lj 3:</p><p>Initialise capsule priors ∀ j : α0, m0, κ0, S0, ν0 4:</p><p>for n iterations do 5:</p><formula xml:id="formula_12">UPDATE SUFF. STATS 6: UPDATE q (π, µ, Λ) 7: UPDATE q (z) 8: aj ← sigmoid βa − (βu + E[ln πj] + E[ln det(Λj)]) rj Activate using approximate H[q (µ j , Λj)] 9:</formula><p>return aj, mj 10: function UPDATE SUFF. STATS(ai, v j|i , rij)</p><p>Calculate sufficient statistics of incoming votes v j|i 11:</p><p>rij ← rij ai 12:</p><p>rj ← i rij 13:</p><p>vj ← 1/rj i rijv j|i 14:</p><p>Sj</p><formula xml:id="formula_13">← i rij(v j|i − vj)(v j|i − vj) T 15: function UPDATE q (π, µ, Λ)</formula><p>Update capsule pose parameter distributions 16:</p><formula xml:id="formula_14">αj ← α0 + rj , κj ← κ0 + rj , νj ← ν0 + rj 17: mj ← (rj vj + κ0m0)κ −1 j 18: Ψ −1 j ← Ψ −1 0 + Sj + κ0rjκ −1 j ( vj − m0)( vj − m0) T 19: ln det(Ψj) ← −2trace(ln Cholesky(Ψ −1 j )) 20: function UPDATE q (z)</formula><p>Update posterior routing responsibilities 21:</p><formula xml:id="formula_15">E[ln πj] ← ψ(αj) − ψ( j αj) 22: E[ln det(Λj)] ← D ln 2 + ln det(Ψj) + D−1 i=0 ψ (νj − i)/2 23: E[D maha (v j|i , µ j )] ← Dκ −1 j + νj(v j|i − mj) T Ψj(v j|i − mj) 24: ln pj ← E[ln det(Λj)]/2 − E[D maha (v j|i , µ j )]/2 25: rij ← softmax E[ln πj] + ln pj Normalise over capsules j ∈ Lj</formula><p>In order to perform routing, we simply iterate between optimising parent capsule parameter distributions q (π, µ, Λ) using the responsibilities over child capsules fixed, and evaluating the new expected responsibilities q (z) using the current distributions over parent capsule parameters fixed. See Algorithm 1 for the standard closed-form update equations, which assume the same functional form as the priors through conjugacy, and for further details refer to <ref type="bibr" target="#b0">(Bishop 2006)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agreement &amp; Activation</head><p>We propose to measure agreement between the votes from lower capsules i using the differential entropy of a higher capsule j's Gaussian-Wishart variational posterior distribution q (µ j , Λ j ). Firstly, the differential entropy of a multivariate gaussian distributed random variable x is by definition given by</p><formula xml:id="formula_16">H[x] − +∞ −∞ f (x) ln f (x)dx = −E[ln N (x|µ, Σ)] = 1 2 ln det(Σ) + D 2 ln(2πe) ≈ ln det(Σ).<label>(12)</label></formula><p>Let f (x) be capsule j's variational posterior:</p><formula xml:id="formula_17">q (µ j , Λ j ) = N (µ j |m j , (κ j Λ j ) −1 )Wi(Λ j |Ψ j , ν j ),</formula><p>where m j , κ j , Ψ j and ν j are the updated prior parameters for a capsule j as detailed in Algorithm 1. We then approximate the entropy</p><formula xml:id="formula_18">H[q (µ j , Λ j )] ≈ E[ln det(Λ j )] = = D−1 i=0 ψ ν j − i 2 + D ln 2 + ln det(Ψ j ),<label>(13)</label></formula><p>where ψ(·) is the digamma function, and we use E[ln det(Λ j )] to indirectly measure the differential entropy of capsule j's variational posterior distribution, up to constant factors. Intuitively, the determinant of the precision matrix measures the concentration of data points across the volume defined by the matrix. The higher the concentration the higher the agreement is among votes for capsule j. To compute any capsule j's activation probability a j , we pass in both its mixing proportion and posterior entropy, as a measure of vote agreement through a logistic non-linearity</p><formula xml:id="formula_19">a j = σ β a − β u + E[ln π j ] + E[ln det(Λ j )] r j ,<label>(14)</label></formula><p>where β a and β u are learnable offset parameters as in (Hinton, <ref type="bibr" target="#b8">Sabour, and Frosst 2018)</ref>. Unlike EM or Dynamic routing, we only activate the capsules after the routing iterations. We find this to have a stabilising effect during training, and we can add in the expected mixing coefficients as a weight on the differential entropy of each capsule, encouraging a trade-off between activating the capsule with the most votes and our measure of how concentrated they are. This decision is in part motivated by context-dependent weighted information and entropy principles, wherein two separate low probability events incurring equally high surprisal can yield contextually unequal informative value <ref type="bibr" target="#b5">(Guiaşu 1971)</ref>. Note that the updated prior parameters m j , κ j , Ψ j and ν j , have a dependency on the routing weights r j = i r ij a i , which represent the amount of data assigned to capsule j, weighted by the previous capsule layer activations. From the perspective of any capsule j's cluster, previous layer activations a i simply dictate how important each data point is.  <ref type="bibr" target="#b16">(Phaye et al. 2018)</ref> 5.57% 11.8M 5.36% 11.8M 4.42% 11.8M 17.37% 11.8M MS-Caps <ref type="bibr" target="#b19">(Xiang et al. 2018)</ref> --7.3% 10.8M --24.3% 11.2M Dynamic <ref type="bibr" target="#b18">(Sabour, Frosst, and Hinton 2017)</ref> 2.7% 8.2M --4.3% 1.8M 10.6% 8.2M (7) Nair et al. <ref type="bibr" target="#b14">(Nair, Doshi, and Keselj 2018)</ref> --10.2% 8.2M 8.94% 8.2M 32.47% 8.2M FRMS <ref type="bibr" target="#b22">(Zhang, Zhou, and Wu 2018)</ref> 2.6% 1.2M 6.0% 1.2M --15.6% 1.2M MaxMin <ref type="bibr" target="#b23">(Zhao et al. 2019)</ref> --7.93% 8.2M --24.08% 8.2M KernelCaps <ref type="bibr" target="#b10">(Killian et al. 2019)</ref> ----8.6% 8.2M 22.3% 8.2M FREM <ref type="bibr" target="#b22">(Zhang, Zhou, and Wu 2018)</ref> 2.2% 1.2M 6.2% 1.2M --14.3% 1.2M EM-Routing <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref> 1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Capsule-VAE</head><p>It is possible to transform our CapsNet into a Variational Autoencoder (VAE) (Kingma and Welling 2013) by sampling from the approximate variational posterior on the capsule parameters q (µ j , Λ j ). We can do so by saving the updated prior parameters m j , κ j , Ψ j and ν j , at the end of the routing procedure of the final layer, and output the capsule means and precisions as latent code. Recall that the approximate posterior on the mean and precision of any capsule j is a Gaussian-Wishart q (µ j , Λ j ) = N (µ j |m j , (κ j Λ j ) −1 )Wi(Λ j |Ψ j , ν j ), and we can sample from this distribution in the following way</p><formula xml:id="formula_20">Λ j | Ψ j , ν j ∼ Wi(Ψ j , ν j ) µ j | Λ j , m j , κ j ∼ N (m j , (κ j Λ j ) −1 ).<label>(15)</label></formula><p>It is straight forward to condition the sample on the target class capsule during training based on the label, and make the process differentiable using the reparameterisation trick</p><formula xml:id="formula_21">z ∼ N (µ j , σ j ) = g µ j ,σj ( ) = µ j + σ j<label>(16)</label></formula><p>where ∼ N (0, I), and σ j diag(Λ j ) − 1 2 . This formulation also reduces computational time since we can avoid explicit redo of VB for each sample. Capsule-VAEs are interesting models as the output latent code is composed of capsule instantiation parameters, and we know from <ref type="bibr" target="#b18">(Sabour, Frosst, and Hinton 2017</ref>) that each capsule dimension learns to encode different variations of object properties that we can visualise/tweak. We leave further exploration of these ideas and analysis of Capsule-VAEs to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Capsules were first introduced by (Hinton, Krizhevsky, and Wang 2011), wherein the encoding of instantiation parameters was established in a transforming autoencoder. More recently, work by <ref type="bibr" target="#b18">(Sabour, Frosst, and Hinton 2017)</ref> achieved state-of-the-art performance on MNIST with a shallow CapsNet, using a Dynamic routing algorithm. Shortly after, EM routing was proposed in <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>, replacing capsule vectors with matrices to reduce the number of parameters. State-of-the-art performance was achieved on smallNORB, outperforming CNNs. More recently, Group Equivariant CapsNets were proposed in <ref type="bibr" target="#b13">(Lenssen, Fey, and Libuschewski 2018)</ref>, leveraging ideas from group theory to guarantee equivariance and invariance properties. In <ref type="bibr" target="#b22">(Zhang, Zhou, and Wu 2018)</ref> a new routing algorithm based on kernel density estimation was proposed, providing a speed up compared to EM routing. Capsules have also been extended to action recognition in videos by <ref type="bibr" target="#b3">(Duarte, Rawat, and Shah 2018)</ref>, where the propose to average the votes before routing them for speed. Work in <ref type="bibr" target="#b21">(Zhang, Edraki, and Qi 2018)</ref> proposes learning groups of capsule subspaces and project embedded features onto these subspaces. Despite these interesting works among others, CapsNets are still difficult to train and the original state-of-the-art benchmarks are yet to be beaten fairly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Capsule Network Architecture Our CapsNet follows the EM routing formulation and comprises 4 capsule layers, starting with a primary capsule (PrimaryCaps) layer followed by 3 convolutional capsule (ConvCaps) layers. The stem of the network consists of a 5 × 5 Conv layer using F filters and stride 2, and is followed by two 3 × 3 Conv layers with F filters each, all using BatchNorm and ReLU activations. The PrimaryCaps layer transforms the F filters into d 1 capsule pose 4x4 matrices and d 1 activations using 1 × 1 convolutions. This is followed by a 3 × 3 ConvCaps layer with d 2 capsules types and stride 2, and a 3×3 ConvCaps layer with d 3 capsule types and stride 1. The final ConvCaps layer shares weight matrices across spatial dimensions, yielding a capsule for each class of d 4 classes, and we perform coordinate addition as in <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>. In summary, we describe our network architectures using the notation {F, d 1 , d 2 , d 3 , d 4 }. Objective Function We experiment with both a negative likelihood loss L NLL , and the spread loss L SL in <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>, then add the VAE loss L VAE as an optional capsule reconstruction based regulariser</p><formula xml:id="formula_22">L SL = i =j max 0, m − (a t − a j ) 2 , L NLL = − j k y jk log y jk .</formula><p>(17)</p><formula xml:id="formula_23">L VAE = 1 2 d σ 2 jd +µ 2 jd − ln σ 2 jd − 1 + 1 K k x k − f (x k ) 2 F .<label>(18)</label></formula><p>The total loss is a linear combination of a classification loss and the optional VAE loss i.e. L = L NLL + ηL VAE . CapsNet regularisation by reconstruction was first proposed in <ref type="bibr" target="#b18">(Sabour, Frosst, and Hinton 2017)</ref> with a fully-connected decoder, in our VAE we use a simple 5 layer deconvnet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uninformative Priors</head><p>We set the gaussian priors on the mean parameters m 0 to be zeros with precision scaling κ 0 = 1, and the wishart priors on the precision matrix Ψ 0 to be identities I D with degrees of freedom ν 0 = D + 1. For the diagonal case, λ 0 is a vector of 1's. These priors have a regularising effect since they encourage the parent capsule clusters j to remain close to the origin, and not to be too irregular in shape. The Dirichlet prior on the mixing coefficients α is set to 1, and reducing this value favours routing solutions with less active parent capsules. In section 4.4, we provide some analysis on sensitivity to prior initialisations.</p><p>Weight Initialisation CapsNets are known to be difficult to train, in fact, the EM routing results were yet to be fairly matched before this paper. With that said, we provide some valuable suggestions for practitioners on how to initialise the various parameters of the model that worked well for us experimentally, and helped stabilise training significantly. We offer the following two ways of initialising the W ij viewpoint-invariant transformation weight matrices: (i) As identities I 4 ∈ R 4×4 with added random uniform noise ∼ Unif(0, b) on the off diagonal entries. In this way, at the start of training the capsule pose transformations don't stray too far from computing the identity function, which we find to have a stabilising effect.</p><p>(ii) To help maintain constant variance of activations across capsule layers and help avoid exploding/vanishing gradients, we propose initialising W ij with a modified (Glorot and Bengio 2010) scheme as</p><formula xml:id="formula_24">W ij ∼ Unif − r, r , r = √ 6 (c i k 2 p 2 + d j k 2 p 2 ) 1 2 ,<label>(19)</label></formula><p>where c i and d j denote the number of capsules types in layers L i and L j , k is the convolutional kernel size and p 2 is the number of neurons per capsule matrix (4 × 4). Lastly, we also normalise the argument of the logistic function for a j using BatchNorm without the learnable parameters γ and β. This restricts the range of input values from being too high/low and helps prevent vanishing gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Image Classification Results</head><p>The main comparative results are reported in <ref type="table" target="#tab_0">Table 1</ref> <ref type="bibr">, using smallNORB (LeCun et al. 2004</ref>), Fashion-MNIST <ref type="bibr" target="#b20">(Xiao, Rasul, and Vollgraf 2017)</ref>, SVHN <ref type="bibr" target="#b15">(Netzer et al. 2011</ref>) and CIFAR-10 (Krizhevsky, Hinton, and others 2009). In all cases, we use the diagonal parameterisation in Eq. (11), 3 VB routing iters and batch size 32. All hyperparameters were tuned using validation sets, then models were retrained with the full training set until convergence before testing.</p><p>smallNORB smallNORB consists of grey-level stereo 96x96 images of 5 objects. Each object is given at 18 different azimuths (0-340), 9 elevations and 6 lighting conditions, and there are 24,300 training and test set images each. Following <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>, we standardise and resize all images to 48x48 and take random 32x32 crops during training. At test time, we simply center crop the images to 32x32. Our best model {64, 16, 16, 16, 5} was trained for 350 epochs using Adam, L NLL loss, and 3e-3 initial learning rate with exponentially decay. A 20% validation split of the training set was used to tune hyperparameters. As reported in <ref type="table" target="#tab_0">Table 1</ref>, we achieve a best test error rate of 1.55% (1.6%±.06 over 5 runs) compared to the previous state-of-the-art 1.8% reported in <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>. Note that by averaging multiple crops at test time they can get 1.4% and we reach 1.29%. Our result is obtained without adding random brightness/contrast or any other augmentations/deformations during training. We also stress that our capsule network has 50% fewer capsules.  <ref type="bibr">, 16, 16, 16</ref>, 10} was trained for 200 epochs using L NLL loss, with SGDM and a weight decay of 1e-6. The initial learning rate was set to 0.1 with step decay at 80, 120, 160 epochs and a decay rate of 0.1. As reported in <ref type="table" target="#tab_0">Table 1</ref> we achieve a best test error rate of 5.15% (5.2%±.07 over 3 runs) outperforming other works with fewer parameters.</p><p>SVHN SVHN comprises challenging real-world 32x32 images of house numbers (10 digit classes). We trained on the core training set only, consisting of 73,257 examples and tested on the 26,032 in the test set. We normalise and pad to 40x40 and take random 32x32 crops during training. Our best model {64, 16, 32, 32, 10} was trained for 350 epochs using L NLL loss with SGDM. The initial learning rate was set to 0.1 with step decay at 150, 250, 300 epochs and a decay rate of 0.1. As reported in <ref type="table" target="#tab_0">Table 1</ref>, we achieved a best test error of 3.87% (3.9%±.06 over 3 runs), outperforming the Dynamic routing capsules <ref type="bibr" target="#b18">(Sabour, Frosst, and Hinton 2017)</ref> and others, with significantly fewer parameters.</p><p>CIFAR-10 CIFAR-10 consists of 60,000 32x32 colour images of 10 classes. There are 50,000 training and 10,000 test images. We normalise and pad to 40x40, and randomly crop 32x32 patches during training. We also apply random horizontal flips with probability 1 2 . Our best model {64, 16, 32, 32, 10} was trained for 350 epochs using L NLL loss with SGDM. Initial learning rate was 0.1 with step decay at 150, 250, 300 epochs and decay rate of 0.1. We achieved a best test error of 11.14% (11.2%±.09 over 3 runs), which is lower than EM routing <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref>, and using considerably fewer parameters than Dynamic <ref type="bibr" target="#b18">(Sabour et al. 2017)</ref> 99.2 79 HitNet <ref type="bibr">(Delige et al. 2019)</ref> 99.6 83.03 Baseline CNN <ref type="bibr" target="#b8">(Hinton et al. 2018)</ref> 99.2 85.9 LadderCaps <ref type="bibr" target="#b9">(Jeong et al. 2019)</ref> 99.3 87.8 GCaps <ref type="bibr" target="#b13">(Lenssen et al. 2018)</ref> 98.42 89.1 SparseCaps <ref type="bibr" target="#b17">(Rawlinson et al. 2018)</ref> 99 ‡ 90.1 Attn-Routing <ref type="bibr" target="#b1">(Choi et al. 2019)</ref> 99.46 91.6 SCAE <ref type="bibr" target="#b12">(Kosiorek et al. 2019</ref>) ‡ 98.5 92.2 EM-Routing <ref type="bibr" target="#b8">(Hinton et al. 2018)</ref> 99. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generalisation to Novel Viewpoints</head><p>In order to verify that our proposed capsule routing algorithm preserves generalisation to novel viewpoints, we trained our {64, 16, 16, 16, 5} model on the smallNORB training data containing azimuths of <ref type="bibr">(300,</ref><ref type="bibr">320,</ref><ref type="bibr">340,</ref><ref type="bibr">0,</ref><ref type="bibr">20,</ref><ref type="bibr">40)</ref>, and tested on the test data containing azimuths from 60 to 280. For elevation viewpoints, we trained on the 3 smaller and tested on the 6 larger elevations. During training, we validated using the portion of test data containing the same viewpoints as in training and measured the generalisation to novel viewpoints after matching the performance on familiar ones. As reported in <ref type="table" target="#tab_2">Table 2</ref>, we compare VB routing to the original EM routing performance in <ref type="bibr" target="#b8">(Hinton, Sabour, and Frosst 2018)</ref> as well as our implementation of EM using the same network for fairness. In our experiments, VB routing does not sacrifice the ability to generalise to novel viewpoints, and outperforms EM routing in all cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Affine Transformation Robustness</head><p>To further demonstrate our methods generalisation and invariance to affine-transformations, we train our {64, 16, 16, 16, 10} CapsNet on MNIST, and assess generalisation performance on the affNIST test set. AffNIST images are 40x40 so we train by randomly padding MNIST training set images as done in works we compare to. We achieve a significantly superior generalisation accuracy of 98.1% comparatively ( <ref type="figure">Figure 5</ref>). For fairer comparisons, we also match the 99.2% test set accuracy on MNIST reported in Dynamic/EM routing, before testing on the affNIST test set, achieving 96.9%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Sensitivity to Prior Hyperparameters</head><p>We took our {64, 16, 16, 16, 5} CapsNet, and performed sensitivity analysis on the hyperparameters of the Wishart and Dirichlet priors, with respect to test error on Fashion-MNIST ( <ref type="figure">Figure 4)</ref>. We initialise λ 0 ≡ diag(Ψ 0 ) as identities scaled by coefficients {0.01, 0.1, 1, 10}. The same coefficients were used for initialising the Dirichlet prior parameter α. In general, we find that our models are quite robust to prior initialisations in terms of final test set performance, whereas convergence speed is mildly affected. It is also possible to learn prior parameters from data via backpropagation ( la empirical Bayes), avoiding manual tuning altogether. We tested this on the Dirichlet α and observed no performance degradation (5.19% compared to 5.2%±0.07).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">VB vs. EM Routing</head><p>For direct comparisons with the leading capsule routing algorithm, we took our best performing models for each dataset and replaced VB with our implementation of EM. <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure" target="#fig_2">Figure 3</ref> report VB outperforming EM in terms of convergence rate, stability, and final test error with identical networks. VB routing is also almost 20% faster than EM. This is partly because capsule priors don't require gradient updates, and mainly because we propose to measure agreement/activate capsules after the routing iterations. As shown in <ref type="figure">Figure 4</ref>, our method compares favourably, and we find that the number of VB routing iterations has a bigger impact on training time than test error, so we can reduce the number iterations to train faster, and still perform competitively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a new capsule routing algorithm for learning a mixture of transforming gaussians via Variational Bayes. We model uncertainty over the capsule parameters in addition to the routing coefficients, which provides: (i) more flexible control over capsule complexity by tuning priors to induce sparsity, and (ii) reduces the well known variance-collapse problem inherent to MLE based mixture models, such as EM. We outperform the state-ofthe-art on smallNORB using 50% fewer capsules than previously reported, achieve highly competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous methods. For future work, we plan to extend our Bayesian framework to obtain calibrated uncertainty estimates over predictions using capsule networks.</p><p>Airplane airplane animal car human truck iter 1 iter 2 iter 3 <ref type="figure">Figure 6</ref>: Histograms of the squared distances (X axis) between votes V j|i averaged over all airplane images in the smallNORB dataset, and each of the all 5 class capsules M j throughout training (epochs on Y axis). Variational Bayes Routing iterations 1-3 are depicted per row, and each column represents a different class capsule. As can be seen above, the average votes from the airplane images learn to agree with the airplane class capsule during training, and therefore the discrepancies between the votes and the target capsule parameters increasingly gather around 0 over time, more so than the other class capsules.</p><p>Car airplane animal car human truck iter 1 iter 2 iter 3 <ref type="figure">Figure 7</ref>: Histograms of the squared distances (X axis) between votes V j|i averaged over all car images in the smallNORB dataset, and each of the all 5 class capsules M j throughout training (epochs on Y axis). Variational Bayes Routing iterations 1-3 are depicted per row, and each column represents a different class capsule. A very clear difference in the agreement between target (car) and non-target capsules as training progresses can be seen without inspecting the absolute distances on the X axis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Architectural depiction of our capsule network with Variational Bayes routing between convolutional capsule layers. Each capsule has an activation probability a and a pose matrix M ∈ R 4×4 . Parent capsules j (blue) only receive votes from child capsules i (orange) within their receptive field. c and d denote the number of child and parent capsule types respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Direct comparison between VB and EM † routing validation set error using identical networks and hyperparameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Test error rate comparisons with CapsNet literature. (·) denotes ensemble size, and ( †) denotes our EM implementation.</figDesc><table><row><cell></cell><cell cols="2">smallNORB</cell><cell cols="2">Fashion-MNIST</cell><cell>SVHN</cell><cell></cell><cell cols="2">CIFAR-10</cell></row><row><cell>Method</cell><cell cols="3">Error (%) Param Error (%)</cell><cell cols="2">Param Error (%)</cell><cell>Param</cell><cell>Error (%)</cell><cell>Param</cell></row><row><cell>HitNet (Delige et al. 2019)</cell><cell>-</cell><cell>-</cell><cell>7.7%</cell><cell>8.2M</cell><cell>5.5%</cell><cell>8.2M</cell><cell>26.7%</cell><cell>8.2M</cell></row><row><cell>DCNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparing novel viewpoint generalisation. ( †) denotes our implementation of EM with same network as VB.</figDesc><table><row><cell cols="3">Viewpoints</cell><cell cols="4">Azimuth (%)</cell><cell></cell><cell>Elevation (%)</cell></row><row><cell cols="2">(Test)</cell><cell></cell><cell>VB</cell><cell cols="2">EM  †</cell><cell cols="2">EM</cell><cell>VB</cell><cell>EM  †</cell><cell>EM</cell></row><row><cell cols="2">Novel</cell><cell></cell><cell cols="6">11.33 12.67 13.5 11.59 12.04 12.3</cell></row><row><cell cols="3">Familiar</cell><cell>3.71</cell><cell cols="2">3.72</cell><cell cols="2">3.7</cell><cell>4.32</cell><cell>4.29</cell><cell>4.3</cell></row><row><cell></cell><cell>7.0</cell><cell cols="3">Runtime (Fashion-MNIST)</cell><cell></cell><cell>6.0</cell><cell cols="2">Prior Sensitivity (Fashion-MNIST)</cell></row><row><cell>Test Error (%)</cell><cell>60 4.2 4.6 5.0 5.4 5.8 6.2 6.6</cell><cell cols="3">120 FREM/FRMS 180 240 1 iter 2 iter EM-Routing  † VB-Routing 2 iter Zhang et al. 2018 300 360 2 iter 3 iter 5.15% 1 iter</cell><cell>420 3 iter</cell><cell>5.0 5.2 5.4 5.8 5.6</cell><cell cols="2">10 −2 5.19%</cell><cell>10 −1</cell><cell>10 0 5.2 ± 0.07% α λ0 / diag(Ψ0) Backprop α Our Best Result 10 1</cell></row><row><cell></cell><cell></cell><cell cols="3">Training Time (min)</cell><cell></cell><cell></cell><cell></cell><cell>Prior Coefficients</cell></row><row><cell cols="9">Figure 4: Test error (%) sensitivity to priors (Right), and run-</cell></row><row><cell cols="9">time/error comparisons using {3,2,1} routing iters (Left).</cell></row><row><cell cols="9">Fashion-MNIST Fashion-MNIST is a more difficult ver-</cell></row><row><cell cols="9">sion of MNIST comprised of 10 clothing item classes. The</cell></row><row><cell cols="9">images are 28x28 and the training/test sets have 60,000</cell></row><row><cell cols="9">and 10,000 examples respectively. We normalise and pad</cell></row><row><cell cols="9">to 36x36, and randomly crop 32x32 image patches during</cell></row><row><cell cols="9">training. At test time we pad the images to 32x32. Our best</cell></row><row><cell cols="3">model {64</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Attention routing between capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An effective hit-or-miss layer favoring feature interpretation as learned prototypes deformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deliège</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cioppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Droogenbroeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Third AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Videocapsulenet: A simplified network for action detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7610" to="7619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weighted entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guiaşu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reports on Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="165" to="179" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Matrix capsules with em routing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Frosst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ladder capsule network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3071" to="3079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Son</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03164</idno>
		<title level="m">Kernelized capsule networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning methods for generic object recognition with invariance to pose and lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Kosiorek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06818</idno>
	</analytic>
	<monogr>
		<title level="m">Stacked capsule autoencoders</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Group equivariant capsule networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Libuschewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8844" to="8853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Pushing the limits of capsule networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keselj</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Technical note</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S R</forename><surname>Phaye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sikka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bathula</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04001</idno>
		<title level="m">Dense and diverse capsule networks: Making the capsules learn better</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rawlinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kowadlo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06094</idno>
		<title level="m">Sparse unsupervised capsules generalize better</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic routing between capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3856" to="3866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mscapsnet: A novel multi-scale capsule network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1850" to="1854" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cappronet: Deep feature learning via orthogonal projections onto capsule subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Edraki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5814" to="5823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast dynamic routing based on weighted kernel density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Artificial Intelligence and Robotics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="301" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kleinhans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sandhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Unnikrishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.09662</idno>
		<title level="m">Capsule networks with max-min normalization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
