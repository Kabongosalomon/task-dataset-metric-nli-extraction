<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiao</forename><surname>Ge</surname></persName>
							<email>yxge@link</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory The</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory The</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory The</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory The</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
							<email>hsli@ee.cuhk.edu.hkdapengchenxjtu@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory The</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain adaptive object re-ID aims to transfer the learned knowledge from the labeled source domain to the unlabeled target domain to tackle the open-class re-identification problems. Although state-of-the-art pseudo-label-based methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b13">14]</ref> have achieved great success, they did not make full use of all valuable information because of the domain gap and unsatisfying clustering performance. To solve these problems, we propose a novel self-paced contrastive learning framework with hybrid memory. The hybrid memory dynamically generates source-domain class-level, target-domain cluster-level and un-clustered instance-level supervisory signals for learning feature representations. Different from the conventional contrastive learning strategy, the proposed framework jointly distinguishes source-domain classes, and target-domain clusters and un-clustered instances. Most importantly, the proposed self-paced method gradually creates more reliable clusters to refine the hybrid memory and learning targets, and is shown to be the key to our outstanding performance. Our method outperforms state-ofthe-arts on multiple domain adaptation tasks of object re-ID and even boosts the performance on the source domain without any extra annotations. Our generalized version on unsupervised object re-ID surpasses state-of-the-art algorithms by considerable 16.7% and 7.9% on Market-1501 and MSMT17 benchmarks † .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: State-of-the-arts <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b53">54]</ref> on UDA object re-ID discarded both the source-domain data and target-domain un-clustered data for training, while our proposed self-paced contrastive learning framework fully exploits all available data with hybrid memory for joint feature learning.</p><p>designs. The accurate source-domain ground-truth labels are valuable but were ignored during target-domain training. <ref type="bibr" target="#b1">(2)</ref> Since the clustering process might result in individual outliers, to ensure the reliability of the generated pseudo labels, existing methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b13">14]</ref> simply discarded the outliers from being used for training. However, such outliers might actually be difficult but valuable samples in the target domain and there are generally many outliers especially in early epochs. Simply abandoning them might critically hurt the final performance.</p><p>To overcome the problems, we propose a hybrid memory to encode all available information from both source and target domains for feature learning. For the source-domain data, their ground-truth class labels can naturally provide valuable supervisions. For the target-domain data, clustering can be conducted to obtain relatively confident clusters as well as un-clustered outliers. All the sourcedomain class centroids, target-domain cluster centroids, and target-domain un-clustered instance features from the hybrid memory can provide supervisory signals for jointly learning discriminative feature representations across the two domains ( <ref type="figure">Figure 1 (b)</ref>). A unified framework is developed for dynamically updating and distinguishing different entries in the proposed hybrid memory.</p><p>Specifically, since all the target-domain clusters and un-clustered instances are equally treated as independent classes, the clustering reliability would significantly impact the learned representations. We thus propose a self-paced contrastive learning strategy, which initializes the learning process by using the hybrid memory with the most reliable target-domain clusters. Trained with such reliable clusters, the discriminativeness of feature representations can be gradually improved and additional reliable clusters can be formed by incorporating more un-clustered instances into the new clusters. Such a strategy can effectively mitigate the effects of noisy pseudo labels and boost the feature learning process. To properly measure the cluster reliability, a novel multi-scale clustering reliability criterion is proposed, based on which only reliable clusters are preserved and other confusing clusters are disassembled back to un-clustered instances. In this way, our self-paced learning strategy gradually creates more reliable clusters to dynamically refine the hybrid memory and learning targets.</p><p>Our contributions are summarized as three-fold. <ref type="bibr" target="#b0">(1)</ref> We propose a unified contrastive learning framework to incorporate all available information from both source and target domains for joint feature learning. It dynamically updates the hybrid memory to provide class-level, cluster-level and instance-level supervisions. <ref type="bibr" target="#b1">(2)</ref> We design a self-paced contrastive learning strategy with a novel clustering reliability criterion to prevent training error amplification caused by noisy pseudo-class labels. It gradually generates more reliable target-domain clusters for learning better features in the hybrid memory, which in turn, improves clustering. (3) Our method significantly outperforms state-of-the-arts <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b44">45]</ref> on multiple domain adaptation tasks of object re-ID with up to 5.0% mAP gains. The proposed unified framework could even boost the performance on the source domain with large margins (6.6%) by jointly training with un-annotated target-domain data, while most existing UDA methods "forget" the source domain after fine-tuning on the target domain. Our unsupervised version without labeled source-domain data on object re-ID task significantly outperforms state-of-the-arts <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b52">53]</ref> by 16.7% and 7.9% in terms of mAP on Market-1501 and MSMT17 benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Unsupervised domain adaptation (UDA) for object re-ID. Existing UDA methods for object re-ID can be divided into two main categories, including pseudo-label-based methods <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b44">45]</ref> and domain translation-based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref>. This paper follows the former one since the pseudo labels were found more effective to capture the target-domain distributions. Though driven by different motivations, previous pseudo-label-based methods generally adopted a two-stage training scheme: (1) pre-training on the source domain with ground-truth IDs, and (2) adapting the target domain with pseudo labels. The pseudo labels can be generated by either clustering instance features <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b53">54]</ref> or measuring similarities with exemplar features <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b44">45]</ref>, where the clustering-based pipeline maintains state-of-the-art performance to date. The major challenges faced by clustering-based methods is how to improve the precision of pseudo labels and how to mitigate the effects caused by noisy pseudo labels. SSG <ref type="bibr" target="#b9">[10]</ref> adopted human local features to assign multi-scale pseudo labels. PAST <ref type="bibr" target="#b54">[55]</ref> introduced to utilize multiple regularizations alternately. MMT <ref type="bibr" target="#b10">[11]</ref> proposed to generate more robust soft labels via the mutual mean-teaching. AD-Cluster <ref type="bibr" target="#b53">[54]</ref> incorporated style-translated images to improve the discriminativeness of instance features. Although various attempts along this direction have led to great performance advances, they ignored to fully exploit all valuable information across the two domains which limits their further improvements, i.e., they simply discarded both the source-domain labeled images and target-domain un-clustered outliers when fine-tuning the model on the target domain with pseudo labels.</p><p>Contrastive learning. State-of-the-art methods on unsupervised visual representation learning <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b3">4]</ref> are based on the contrastive learning. Being cast as either the dictionary look-up task <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b16">17]</ref> or the consistent learning task <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b3">4]</ref>, a contrastive loss was adopted to learn instance discriminative representations by treating each unlabeled sample as a distinct class. Although the instance-level contrastive loss could be used to train embeddings that can be generalized well to downstream tasks with fine-tuning, it does not perform well on the domain adaptive object re-ID tasks which require to correctly measure the inter-class affinities on the unsupervised target domain.</p><p>Self-paced learning. The "easy-to-hard" training scheme is at the core of self-paced learning <ref type="bibr" target="#b20">[21]</ref>, which was originally found effective in supervised learning methods, especially with noisy labels <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b12">13]</ref>. Recently, some methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b66">67]</ref> incorporated the conception of self-paced learning into unsupervised learning tasks by starting the training process with the most confident pseudo labels. However, the self-paced policies designed in these methods were all based on the close-set problems with pre-defined classes, which cannot be generalized to our open-set object re-ID task with completely unknown classes on the target domain. Moreover, they did not consider how to plausibly train with hard samples that cannot be assigned confident pseudo labels all the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>To tackle the challenges in unsupervised domain adaptation (UDA) on object re-ID, we propose a self-paced contrastive learning framework <ref type="figure" target="#fig_0">(Figure 2 (a)</ref>), which consists of a CNN <ref type="bibr" target="#b21">[22]</ref>-based encoder f θ and a novel hybrid memory. The key innovation of the proposed framework lies in jointly training the encoder with all the source-domain class-level, target-domain cluster-level and target-domain un-clustered instance-level supervisions, which are dynamically updated in the hybrid memory to gradually provide more confident learning targets. In order to avoid training error amplification caused by noisy clusters, the self-paced learning strategy initializes the training process with the most ‡ Throughout this paper, the term independence is used in its idiomatic sense rather than the statistical sense. reliable clusters and gradually incorporates more un-clustered instances to form new reliable clusters. A novel reliability criterion is introduced to measure the quality of clusters <ref type="figure" target="#fig_0">(Figure 2</ref> (b)).</p><p>Our training scheme alternates between two steps: (1) grouping the target-domain samples into clusters and un-clustered instances by clustering the target-domain instance features in the hybrid memory with the self-paced strategy (Section 3.2), and (2) optimizing the encoder f θ with a unified contrastive loss and dynamically updating the hybrid memory with encoded features (Section 3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constructing and Updating Hybrid Memory for Contrastive Learning</head><p>Given the target-domain training samples X t without any ground-truth label, we employ the selfpaced clustering strategy (Section 3.2) to group the samples into clusters and the un-clustered outliers. The whole training set of both domains can therefore be divided into three parts, including the source-domain samples X s with ground-truth identity labels, the target-domain pseudo-labeled data X t c within clusters and the target-domain instances X t o not belonging to any cluster, i.e., X t = X t c ∪X t o . State-of-the-art UDA methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55]</ref> simply abandon all source-domain data and targetdomain un-clustered instances, and utilize only the target-domain pseudo labels for adapting the network to the target domain, which, in our opinion, is a sub-optimal solution. Instead, we design a novel contrastive loss to fully exploit available data by treating all the source-domain classes, target-domain clusters and target-domain un-clustered instances as independent classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Unified Contrastive Learning</head><p>Given a general feature vector</p><formula xml:id="formula_0">f = f θ (x), x ∈ X s ∪ X t c ∪ X t o , our unified contrastive loss is L f = − log exp ( f , z + /τ ) n s k=1 exp ( f , w k /τ ) + n t c k=1 exp ( f , c k /τ ) + n t o k=1 exp ( f , v k /τ ) ,<label>(1)</label></formula><p>where z + indicates the positive class prototype corresponding to f , the temperature τ is empirically set as 0.05 and ·, · denotes the inner product between two feature vectors to measure their similarity. n s is the number of source-domain classes, n t c is the number of target-domain clusters and n t o is the number of target-domain un-clustered instances. More specifically, if f is a source-domain feature, z + = w k is the centroid of the source-domain class k that f belongs to. If f belongs to the k-th target-domain cluster, z + = c k is the k-th cluster centroid. If f is a target-domain un-clustered outlier, we would have z + = v k as the outlier instance feature corresponding to f . Intuitively, the above joint contrastive loss encourages the encoded feature vector to approach its assigned classes, clusters or instances. Note that we utilize class centroids {w} instead of learnable class weights for encoding source-domain classes to match their semantics to those of the clusters' or outliers' centroids. Our experiments (Section 4.4) show that, if the semantics of class-level, cluster-level and instance-level supervisions do not match, the performance drops significantly.</p><p>Discussion. The most significant difference between our unified contrastive loss (Eq. (1)) and previous contrastive losses <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b32">33]</ref> is that ours jointly distinguishes classes, clusters, and unclustered instances, while previous ones only focus on separating instances without considering any ground-truth classes or pseudo-class labels as our method does. They target at instance discrimination task but fail in properly modeling intra-/inter-class affinities on domain adaptive re-ID tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Hybrid Memory</head><p>As the cluster number n t c and outlier instance number n t o may change during training with the alternate clustering strategy, the class prototypes for the unified contrastive loss (Eq. (1)) are built in a nonparametric and dynamic manner. We propose a novel hybrid memory to provide the source-domain class centroids {w 1 , · · · , w n s }, target-domain cluster centroids {c 1 , · · · , c n t c } and target-domain un-clustered instance features {v 1 , · · · , v n t o }. For continuously storing and updating the above three types of entries, we propose to cache source-domain class centroids {w 1 , · · · , w n s } and all the target-domain instance features {v 1 , · · · , v n t } simultaneously in the hybrid memory, where n t is the number of all the target-domain instances and n t = n t c + n t o . Without loss of generality, we assume that un-clustered features in {v} have indices {1, · · · , n t o }, while other clustered features in {v} have indices from n t o + 1 to n t . In other words, {v n t o +1 , · · · , v n t } dynamically form the cluster centroids {c} while {v 1 , · · · , v n t o } remain un-clustered instances.</p><p>Memory initialization. The hybrid memory is initialized with the extracted features by performing forward computation of f θ : the initial source-domain class centroids {w} can be obtained as the mean feature vectors of each class, while the initial target-domain instance features {v} are directly encoded by f θ . After that, the target-domain cluster centroids {c} are initialized with the mean feature vectors of each cluster from {v}, i.e.,</p><formula xml:id="formula_1">c k = 1 |I k | vi∈I k v i ,<label>(2)</label></formula><p>where I k denotes the k-th cluster set that contains all the feature vectors within cluster k and | · | denotes the number of features in the set. Note that the source-domain class centroids {w} and the target-domain instance features {v} are only initialized once by performing the forward computation at the beginning of the learning algorithm, and then can be continuously updated during training.</p><p>Memory update. At each iteration, the encoded feature vectors in each mini-batch would be involved in hybrid memory updating. For the source-domain class centroids {w}, the k-th centroid w k is updated by the mean of the encoded features belonging to class k in the mini-batch as</p><formula xml:id="formula_2">w k ← m s w k + (1 − m s ) · 1 |B k | f s i ∈B k f s i ,<label>(3)</label></formula><p>where B k denotes the feature set belonging to source-domain class k in the current mini-batch and m s ∈ [0, 1] is a momentum coefficient for updating source-domain class centroids. m s is empirically set as 0.2.</p><p>The target-domain cluster centroids cannot be stored and updated in the same way as the sourcedomain class centroids, since the clustered set X t c and un-clustered set X t o are constantly changing. As the hybrid memory caches all the target-domain features {v}, each encoded feature vector f t i in the mini-batch is utilized to update its corresponding instance entry</p><formula xml:id="formula_3">v i by v i ← m t v i + (1 − m t )f t i ,<label>(4)</label></formula><p>where m t ∈ [0, 1] is the momentum coefficient for update target-domain instance features and is set as 0.2 in our experiments. Given the updated instance memory v i , if f t i belongs to the cluster k, the corresponding centroid c k needs to be updated with Eq. (2).</p><p>Discussion. The hybrid memory has two main differences from the memory used in <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b16">17]</ref>: (1) Our hybrid memory caches prototypes for both the centroids and instances, while the memory in <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b16">17]</ref> only provides instance-level prototypes. Other than the centroids, we for the first time treat clusters and instances as equal classes; (2) The cluster/instance learning targets provided by our hybrid memory are gradually updated and refined, while previous memory <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b16">17]</ref> only supports fixed instance-level targets. Note that our self-paced strategy (will be discussed in Section 3.2) dynamically determines confident clusters and un-clustered instances.</p><p>The momentum updating strategy is inspired by <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b42">43]</ref>, and we further introduce how to update hybrid prototypes, i.e., centroids and instances. Note that we employ different updating strategies for class centroids (Eq. (3)) and cluster centroids (Eq. (4)&amp;(2)) since source-domain classes are fixed while target-domain clusters are dynamically changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-paced Learning with Reliable Clusters</head><p>A simple way to split the target-domain data into clusters X t c and un-clustered outliers X t o is to cluster the target-domain instance features {v 1 , · · · , v n t } from the hybrid memory by a certain algorithm (e.g., DBSCAN <ref type="bibr" target="#b8">[9]</ref>). Since all the target-domain clusters and un-clustered outlier instances are treated as distinct classes in Eq. (1), the clustering reliability would significantly impact the learned representations. If the clustering is perfect, merging all the instances into their true clusters would no doubt improve the final performance (denotes as "oracle" in <ref type="table" target="#tab_4">Table 5</ref>). However, in practice, merging an instance into a wrong cluster does more harm than good. A self-paced learning strategy is therefore introduced, where in the re-clustering step before each epoch, only the most reliable clusters are preserved and the unreliable clusters are disassembled back to un-clustered instances. A reliability criterion is proposed to identify unreliable clusters by measuring the independence and compactness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Independence of clusters.</head><p>A reliable cluster should be independent from other clusters and individual samples. Intuitively, if a cluster is far away from other samples, it can be considered as highly independent. However, due to the uneven density in the latent space, we cannot naïvely use the distances between the cluster centroid and outside-cluster samples to measure the cluster independence. Generally, the clustering results can be tuned by altering certain hyper-parameters of the clustering criterion. One can loosen the clustering criterion to possibly include more samples in each cluster or tighten the clustering criterion to possibly include fewer samples in each cluster. We denote the samples within the same cluster of f t i as I(f t i ). We propose the following metric to measure the cluster independence, which is formulated as an intersection-over-union (IoU) score,</p><formula xml:id="formula_4">R indep (f t i ) = |I(f t i ) ∩ I loose (f t i )| |I(f t i ) ∪ I loose (f t i )| ∈ [0, 1],<label>(5)</label></formula><p>where I loose (f t i ) is the cluster set containing f t i when the clustering criterion becomes looser. Larger R indep (f t i ) indicates a more independent cluster for f t i , i.e., even one looses the clustering criterion, there would be no more sample to be included into the new cluster I loose (f t i ). Samples within the same cluster set (e.g., I(f t i )) generally have the same independence score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compactness of clusters.</head><p>A reliable cluster should also be compact, i.e., the samples within the same cluster should have small inter-sample distances. In an extreme case, when a cluster is most compact, all the samples in the cluster have zero inter-sample distances. Its samples would not be split into different clusters even when the clustering criterion is tightened. Based on this assumption, we can define the following metric to determine the compactness of the clustered point f t i as</p><formula xml:id="formula_5">R comp (f t i ) = |I(f t i ) ∩ I tight (f t i )| |I(f t i ) ∪ I tight (f t i )| ∈ [0, 1],<label>(6)</label></formula><p>where</p><formula xml:id="formula_6">I tight (f t i ) is the cluster set containing f t i when tightening the criterion. Larger R comp (f t i ) indicates smaller inter-sample distances around f t i within I(f t i )</formula><p>, since a cluster with larger intersample distances is more likely to include fewer points when a tightened criterion is adopted. The same cluster's data points may have different compactness scores due to the uneven density.</p><p>Given the above metrics for measuring the cluster reliability, we could compute the independence and compactness scores for each data point within clusters. We set up α, β ∈ [0, 1] as independence and compactness thresholds for determining reliable clusters. Specifically, we preserve independent clusters with compact data points whose R indep &gt; α and R comp &gt; β, while the remaining data are treated as un-clustered outlier instances. With the update of the encoder f θ and target-domain instance features {v} from the hybrid memory, more reliable clusters can be gradually created to further improve the feature learning. The overall algorithm is detailed in Alg. 1 of Appendix A. We evaluate our proposed method on both the mainstream real→real adaptation tasks and the more challenging synthetic→real adaptation tasks in person re-ID and vehicle re-ID problems. As shown in <ref type="table" target="#tab_0">Table 1</ref>, two real-world person datasets and one synthetic person dataset, as well as two real-world vehicle datasets and one synthetic vehicle dataset, are adopted in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Evaluation Protocol</head><p>Person re-ID datasets † . The Market-1501 and MSMT17 are widely used real-world person image datasets in domain adaptive tasks, among which, MSMT17 has the most images and is most challenging. The synthetic PersonX <ref type="bibr" target="#b38">[39]</ref> is generated based on Unity <ref type="bibr" target="#b35">[36]</ref> with manually designed obstacles, e.g., random occlusion, resolution and illumination differences, etc.  Vehicle re-ID datasets. Although domain adaptive person re-ID has been long studied, the same task on the vehicle has not been fully explored. We conduct experiments with the real-world VeRi-776, VehicleID and the synthetic VehicleX datasets. VehicleX <ref type="bibr" target="#b31">[32]</ref> is also generated by the Unity engine <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b41">42]</ref> and further translated to have the real-world style by SPGAN <ref type="bibr" target="#b7">[8]</ref>.</p><p>Evaluation protocol. In the experiments, only ground-truth IDs on the source-domain datasets are provided for training. Mean average precision (mAP) and cumulative matching characteristic (CMC), proposed in <ref type="bibr" target="#b57">[58]</ref>, are adopted to evaluate the methods' performances on the target-domain datasets.</p><p>No post-processing technique, e.g., re-ranking <ref type="bibr" target="#b59">[60]</ref> or multi-query fusion <ref type="bibr" target="#b57">[58]</ref>, is adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We adopt an ImageNet-pretrained <ref type="bibr" target="#b6">[7]</ref> ResNet-50 <ref type="bibr" target="#b17">[18]</ref> as the backbone for the encoder f θ . Following the clustering-based UDA methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b37">38]</ref>, we use DBSCAN <ref type="bibr" target="#b8">[9]</ref> for clustering before each epoch. The maximum distance between neighbor points, which is the most important parameter in DBSCAN, is tuned to loosen or tighten the clustering in our proposed self-paced learning strategy. We use a constant threshold α and dynamic threshold β for identifying independent clusters with the most compact points by the reliability criterion. More details can be found in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with State-of-the-arts</head><p>UDA performance on the target domain. We compare our proposed framework with state-ofthe-art UDA methods on multiple domain adaptation tasks in <ref type="table" target="#tab_1">Table 2</ref>, including three real→real and three synthetic→real tasks. The tasks in <ref type="table" target="#tab_1">Tables 2b &amp; 2c</ref> were not surveyed by previous methods, so we implement state-of-the-art MMT <ref type="bibr" target="#b10">[11]</ref> on these datasets for comparison. Our method significantly outperforms all state-of-the-arts on both person and vehicle datasets with a plain ResNet-50 backbone, achieving 2-4% improvements in terms of mAP on the common real→real tasks and up to 5.0% increases on the challenging synthetic→real tasks. An inspiring discovery is that the synthetic→real task could achieve competitive performance as the real→real task with the same target-domain dataset  (e.g., VeRi-776), which indicates that we are one more step closer towards no longer needing any manually annotated real-world images in the future.</p><p>Further improvements on the source domain. State-of-the-art UDA methods inevitably forget the source-domain knowledge after fine-tuning the pretrained networks on the target domain, as demonstrated by MMT <ref type="bibr" target="#b10">[11]</ref> in <ref type="table" target="#tab_2">Table 3</ref>. In contrast, our proposed unified framework could effectively model complex inter-sample relations across the two domains, boosting the source-domain performance by up to 6.6% mAP. Note that experiments of "Encoder train/test on the source domain" adopt the same training objective (Eq. (1)) as our proposed method, except for that only source-domain class centroids {w} are available. Our method also outperforms state-of-the-art supervised re-ID methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b39">40]</ref> on the source domain without either using multiple losses or more complex networks. Such a phenomenon indicates that our method could be applied to improve the supervised training by incorporating unlabeled data without extra human labor.</p><p>Unsupervised re-ID without any labeled training data. Another stream of research focuses on training the re-ID model without any labeled data, i.e., excluding source-domain data from the training set. Our method can be easily generalized to such a setting by discarding the source-domain class centroids {w} from both the hybrid memory and training objective (See Alg. 2 in Appendix A for details). As shown in <ref type="table" target="#tab_3">Table 4</ref>, our method considerably outperforms state-of-the-arts by up to 16.7% improvements in terms of mAP. We also implement state-of-the-art unsupervised method MoCo <ref type="bibr" target="#b16">[17]</ref>, which adopts the conventional contrastive loss, and unfortunately, it is inapplicable on unsupervised re-ID tasks. MoCo <ref type="bibr" target="#b16">[17]</ref> underperforms because it treats each instance as a single class, while the core of re-ID tasks is to encode and model intra-/inter-class variations. MoCo <ref type="bibr" target="#b16">[17]</ref> is good at unsupervised pre-training but its resulting networks need finetuning with (pseudo) class labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Studies</head><p>We analyse the effectiveness of our proposed unified contrastive loss with hybrid memory and selfpaced learning strategy in <ref type="table" target="#tab_4">Table 5</ref>. The "oracle" experiment adopts the target-domain ground-truth IDs as cluster labels for training, reflecting the maximal performance with our pipeline.</p><p>Unified contrastive learning mechanism. In order to verify the necessity of each type of classes in the unified contrastive loss (Eq. (1)), we conduct experiments when removing any one of the source-domain class-level, target-domain cluster-level or un-clustered instance-level supervisions <ref type="table" target="#tab_4">(Table 5a)</ref>. Baseline "Src. class" adopts only source-domain images with ground-truth IDs for training. "Src. class + tgt. instance" treats each target-domain sample as a distinct class. It totally fails with even worse results than the baseline "Src. class", showing that directly generalizing conventional contrastive loss to UDA tasks is inapplicable. "Src. class + tgt. cluster" follows existing UDA methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b13">14]</ref>, by simply discarding un-clustered instances from training. Noticeable performance drops are observed, especially without the self-paced policy to constrain reliable clusters. Note that the only difference between "Src. class + tgt. cluster (w/ self-paced)" and "Ours (full)" is whether using outliers for training and the large performance gaps are due to the facts that: 1) There are many un-clustered outliers (&gt; half of all samples), especially in early epochs; 2) Outliers serve as difficult samples and excluding them over-simplifies the training task; 3) "Src. class + tgt. cluster" doesn't update outliers in the memory, making them unsuitable to be clustered in the later epochs.</p><p>As illustrated in <ref type="table" target="#tab_4">Table 5b</ref>, we further verify the necessity of unified training in unsupervised object re-ID tasks. We observe the same trend as domain adaptive tasks: solving the problem via instance discrimination ("tgt. instance") would fail. What is different is that, even with our self-paced strategy, training with clusters alone ("tgt. cluster") would fail. That is due to the fact that only a few samples take part in the training if discarding the outliers, undoubtedly leading to training collapse. Note that previous unsupervised re-ID methods <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b52">53]</ref> which abandoned outliers did not fail, since they did not utilize a memory bank that requires all the entries to be continuously updated.</p><p>We adopt the non-parametric class centroids to supervise the source-domain feature learning, however, conventional methods generally adopt a learnable classifier for supervised learning. "Src. class → Src. learnable weights" in <ref type="table" target="#tab_4">Table 5a</ref> is therefore conducted to verify the necessity of using source-domain class centroids for training to match the semantics of target-domain training supervisions. We also test the effect of not extending negative classes across different types of contrasts. For instance, source-domain samples only treat non-corresponding source-domain classes as their negative classes. "Ours w/o unified contrast" shows inferior performance in both <ref type="table" target="#tab_4">Table 5a</ref> and 5b. This indicates the effectiveness of the unified contrastive learning between all types of classes in Eq. (1).</p><p>Self-paced learning strategy. We propose the self-paced learning strategy to preserve the most reliable clusters for providing stronger supervisions. The intuition is to measure the stability of clusters by hierarchical structures, i.e., a reliable cluster should be consistent in clusters at multiple levels. R indep and R comp are therefore proposed to measure the independence and compactness of clusters, respectively. To verify the effectiveness of such a strategy, we evaluate our framework when removing either R indep or R comp , or both of them. Obvious performance drops are observed under all these settings, e.g., 4.9% mAP drops are shown when removing R indep &amp;R comp in <ref type="table" target="#tab_4">Table 5b</ref>.</p><p>We illustrate the number of clusters and their corresponding Normalized Mutual Information (NMI) scores during training on MSMT17→Market-1501 in <ref type="figure" target="#fig_1">Figure 3</ref>. It can be observed that the quantity and quality of clusters are closer to the ground-truth IDs with the proposed self-paced learning strategy regardless of the un-clustered instance-level contrast, indicating higher reliability of the clusters and the effectiveness of the self-paced strategy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>Our method has shown considerable improvements over a variety of unsupervised or domain adaptive object re-ID tasks. The supervised performance can also be promoted labor-free by incorporating unlabeled data for training in our framework. The core is at exploiting all available data for jointly training with hybrid supervision. Positive as the results are, there still exists a gap from the oracle, suggesting that the pseudo-class labels may not be satisfactory enough even with the proposed self-paced strategy. Further studies are called for. Beyond the object re-ID task, our method has great potential on other unsupervised learning tasks, which needs to be explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Our method can help to identify and track different types of objects (e.g., vehicles, cyclists, pedestrians, etc. ) across different cameras (domains), thus boosting the development of smart retail, smart transportation, and smart security systems in the future metropolises. In addition, our proposed self-paced contrastive learning is quite general and not limited to the specific research field of object re-ID. It can be well extended to broader research areas, including unsupervised and semi-supervised representation learning.</p><p>However, object re-ID systems, when applied to identify pedestrians and vehicles in surveillance systems, might give rise to the infringement of people's privacy, since such re-ID systems often rely on non-consensual surveillance data for training, i.e., it is unlikely that all human subjects even knew they were being recorded. Therefore, governments and officials need to carefully establish strict regulations and laws to control the usage of re-ID technologies. Otherwise, re-ID technologies can potentially equip malicious actors with the ability to surveil pedestrians or vehicles through multiple CCTV cameras without their consent. The research committee should also avoid using the datasets with ethics issues, e.g., DukeMTMC <ref type="bibr" target="#b36">[37]</ref>, which has been taken down due to the violation of data collection terms, should no longer be used. We would not evaluate our method on DukeMTMC related benchmarks as well. Furthermore, we should be cautious of the misidentification of the re-ID systems to avoid possible disturbance. Also, note that the demographic makeup of the datasets used is not representative of the broader population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B More Discussions</head><p>Comparison with ECN <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b62">63]</ref>. There is an existing work, ECN <ref type="bibr" target="#b61">[62]</ref> with its extension version <ref type="bibr" target="#b62">[63]</ref>, which also adopts a feature memory for the domain adaptive person re-ID task. Comparison results in <ref type="table" target="#tab_1">Table 2</ref> demonstrate the superiority of our proposed method, and there are three main differences between our method and ECN. (1) Our proposed hybrid memory dynamically provides all the source-domain class-level, target-domain cluster-level and un-clustered instance-level supervisory signals, while the memory used in ECN only provides instance-level supervisions on the target domain. <ref type="bibr" target="#b1">(2)</ref> We use unified training of source classes, target clusters and target outliers, while ECN uses multi-task learning and treats source and target classes separately. <ref type="formula" target="#formula_2">(3)</ref> We propose a self-paced learning strategy to gradually refine the learning targets on both clusters and un-clustered instances, while ECN adopts noisy k-nearest neighbors as learning targets for all the samples without consideration of uneven density in the latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More Implementation Details</head><p>We implement our framework in PyTorch <ref type="bibr" target="#b34">[35]</ref> and adopt 4 GTX-1080TI GPUs for training † . The domain adaptation task with both source-domain and target-domain data takes ∼ 3 hours for training, and the unsupervised learning task with only target-domain data takes ∼ 2 hours for training on Market-1501 and PersonX datasets. When training on MSMT17, VehicleID, VeRi-776 and VehicleX datasets, time needs to be doubled due to over 2× images in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Network Optimization</head><p>We adopt an ImageNet <ref type="bibr" target="#b6">[7]</ref>-pretrained ResNet-50 <ref type="bibr" target="#b17">[18]</ref> up to the global average pooling layer, followed by a 1D BatchNorm layer and an L 2 -normalization layer, as the backbone for the encoder f θ . Domainspecific BNs <ref type="bibr" target="#b2">[3]</ref> are used in f θ for narrowing domain gaps. Adam optimizer is adopted to optimize f θ with a weight decay of 0.0005. The initial learning rate is set to 0.00035 and is decreased to 1/10 of its previous value every 20 epochs in the total 50 epochs. The temperature τ in Eq. (1) is empirically set as 0.05. The hybrid memory is initialized by extracting the whole training set with the ImageNet-pretrained encoder f θ , and is then dynamically updated with m s = m t = 0.2 in Eq.</p><p>(3)&amp;(4) at each iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Training Data Organization</head><p>During training, each mini-batch contains 64 source-domain images of 16 ground-truth classes (4 images for each class) and 64 target-domain images of at least 16 pseudo classes, where target-domain clusters and un-clustered instances are all treated as independent pseudo classes (4 images for each cluster or 1 image for each un-clustered instance). The person images are resized to 256 × 128 and the vehicle images are resized to 224 × 224. Random data augmentation is applied to each image before it is fed into the network, including randomly flipping, cropping and erasing <ref type="bibr" target="#b60">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Target-domain Clustering</head><p>Following the clustering-based UDA methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b37">38]</ref>, we use DBSCAN <ref type="bibr" target="#b8">[9]</ref> and Jaccard distance <ref type="bibr" target="#b59">[60]</ref> with k-reciprocal nearest neighbors for clustering before each epoch, where k = 30. For DBSCAN, the maximum distance between neighbors is set as d = 0.6 and the minimal number of neighbors for a dense point is set as 4. In our proposed self-paced learning strategy described in Section 3.2, we tune the value of d to loosen or tighten the clustering criterion. Specifically, we adopt d = 0.62 to form the looser criterion and d = 0.58 for the tighter criterion, denoted as ∆d = 0.02. The constant threshold α for identifying independent clusters is defined by the top-90% R indep before the first epoch and remains the same for all the training process. The dynamic threshold β for identifying compact clusters is defined by the maximum R comp in each cluster on-the-fly, i.e., we preserve the most compact points in each cluster. Instance-batch normalization (IBN) <ref type="bibr" target="#b33">[34]</ref> has been proved effective in object re-ID methods in either unsupervised <ref type="bibr" target="#b10">[11]</ref> or supervised <ref type="bibr" target="#b29">[30]</ref> learning tasks. We evaluate our framework with IBN-ResNet as the backbone of the encoder, which is formed by replacing all BN layers in ResNet-50 <ref type="bibr" target="#b17">[18]</ref> with IBN layers. As shown in <ref type="table" target="#tab_5">Table 6</ref>, the performance can be further improved with IBN-ResNet except for the vehicle datasets. In order to verify that our proposed self-paced learning strategy with cluster reliable criterion is still effective when creating pseudo labels with other clustering algorithms, we conduct experiments by replacing the original DBSCAN algorithm with Agglomerative Clustering <ref type="bibr" target="#b0">[1]</ref> algorithm. As shown in <ref type="table" target="#tab_6">Table 7</ref>, significant 4.8% mAP improvements can be observed when applying the self-paced learning strategy. What is interesting is that the final performance is even better than that on DBSCAN. The intuition of our cluster reliable criterion is to measure the stability of clusters by hierarchical structures, which shows similar motivation as HDBSCAN <ref type="bibr" target="#b1">[2]</ref>. So we test HDBSCAN to replace our reliability criterion and observe 1.4%/3.4% mAP drops on unsupervised Market-1501/MSMT17 tasks <ref type="table" target="#tab_7">(Table 8)</ref>, which indicates that DBSCAN with our cluster reliability criterion is more suitable than HDBSCAN in the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Performance with IBN-ResNet [34]</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Self-paced Learning Strategy on Other Clustering Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Cluster Reliable Criterion v.s. HDBSCAN [2]</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Parameter Analysis</head><p>We tune the hyper-parameters on the task of MSMT17→Market-1501, and the chosen hyperparameters are directly applied to all the other tasks. As demonstrated in <ref type="figure">Figure 4</ref>, our framework achieves the optimal performance when setting the temperature τ as 0.05 in Eq. (1) on the task of MSMT17→Market-1501. One may find that the performance varies with different values of τ , but note that all methods using temperature contrastive function (e.g., <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b32">33]</ref>) have similar effects on τ . We set τ = 0.05 following <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b62">63]</ref> and achieve the best performance using the same τ = 0.05 for 6 UDA tasks ( <ref type="table" target="#tab_1">Table 2</ref>) and 3 unsupervised tasks <ref type="table" target="#tab_3">(Table 4)</ref>, showing the robustness of τ = fixed 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Momentum</head><p>Coefficients m s , m t for Hybrid Memory   Our proposed hybrid memory simultaneously stores and updates the source-domain class centroids with momentum m s in Eq.</p><p>(3) and the target-domain instance features with momentum m t in Eq. (4). We adopt m s = m t = 0.2 in our experiments by tuning such hyper-parameter on the task of MSMT17→Market-1501.</p><p>We find that the value of m t is critical to the optimal performance ( <ref type="figure" target="#fig_3">Figure 5</ref>) while our framework is not sensitive to the value of m s <ref type="figure" target="#fig_4">(Figure 6</ref>), so we adopt the same momentum coefficient on two domains for convenience, i.e., m s = m t . Despite the value of m t affects the final performance, the results of our framework are robust when m t changes within a large range, i.e., [0.2, 0.6] in <ref type="figure" target="#fig_5">Figure 7</ref>. As described in Section C.3, we tune the value of the maximum neighbor distance d with a residual ∆d = 0.02 to measure the cluster reliability in our self-paced learning strategy. As shown in <ref type="figure" target="#fig_6">Figure  8</ref>, ∆d = 0.00 can be thought of as removing the self-paced strategy from training, which is the same as "Ours w/o R comp &amp;R indep " in <ref type="table" target="#tab_4">Table 5</ref>. Our method could achieve similar performance when ∆d changes within [0.02, 0.05], which indicates that our proposed reliability criterion is not sensitive to the hyper-parameter ∆d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Residual ∆d for Cluster Reliability Criterion</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>(a) The illustration of the proposed unified framework with a novel hybrid memory. (b) The proposed reliability criterion for measuring the cluster independence ‡ and compactness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Ablation study by observing the dynamically changing cluster numbers and their corresponding Normalized Mutual Information (NMI) scores during training on MSMT17→Market-1501.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>E. 1 Figure 4 :</head><label>14</label><figDesc>Temperature τ for Contrastive Loss Performance of our framework with different values of temperature τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Performance of our framework with different values of m t when m s = 0.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Performance of our framework with different values of m s when m t = 0.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Performance of our framework with different values of m s , m t when m s = m t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Performance of our framework with different values of ∆d in the cluster reliability criterion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets used for training and evaluation. (*) denotes the synthetic datasets.</figDesc><table><row><cell>Dataset</cell><cell># train IDs</cell><cell># train images</cell><cell># test IDs</cell><cell># query images</cell><cell># cameras</cell><cell># total images</cell></row><row><cell>Market-1501 [58]</cell><cell>751</cell><cell>12,936</cell><cell>750</cell><cell>3,368</cell><cell>6</cell><cell>32,217</cell></row><row><cell>MSMT17 [46]</cell><cell>1,041</cell><cell>32,621</cell><cell>3,060</cell><cell>11,659</cell><cell>15</cell><cell>126,441</cell></row><row><cell>PersonX [39]*</cell><cell>410</cell><cell>9,840</cell><cell>856</cell><cell>5,136</cell><cell>6</cell><cell>45,792</cell></row><row><cell>VeRi-776 [28]</cell><cell>575</cell><cell>37,746</cell><cell>200</cell><cell>1,678</cell><cell>20</cell><cell>51,003</cell></row><row><cell>VehicleID [27]</cell><cell>13,164</cell><cell>113,346</cell><cell>800</cell><cell>5,693</cell><cell>-</cell><cell>221,763</cell></row><row><cell>VehicleX [32]*</cell><cell>1,362</cell><cell>192,150</cell><cell>-</cell><cell>-</cell><cell>11</cell><cell>192,150</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with state-of-the-art methods on unsupervised domain adaptation for object re-ID. (*) the implementation is based on the authors' code. Real→real adaptation on person re-ID datasets. Synthetic→real adaptation on person re-ID datasets.</figDesc><table><row><cell>Methods</cell><cell></cell><cell>mAP</cell><cell cols="2">Market-1501→MSMT17 top-1 top-5</cell><cell>top-10</cell><cell>(b) Methods</cell><cell></cell><cell>mAP</cell><cell cols="2">PersonX→MSMT17 top-1 top-5</cell><cell>top-10</cell></row><row><cell>PTGAN [46]</cell><cell>CVPR'18</cell><cell>2.9</cell><cell>10.2</cell><cell>-</cell><cell>24.4</cell><cell>MMT-dbscan [11]*</cell><cell>ICLR'20</cell><cell>17.7</cell><cell>39.1</cell><cell>52.6</cell><cell>58.5</cell></row><row><cell>ECN [62]</cell><cell>CVPR'19</cell><cell>8.5</cell><cell>25.3</cell><cell>36.3</cell><cell>42.1</cell><cell>Ours</cell><cell></cell><cell>22.7</cell><cell>47.7</cell><cell>60.0</cell><cell>65.5</cell></row><row><cell>SSG [10] ECN++ [63] MMT-kmeans [11] MMCL [45] DG-Net++ [66]</cell><cell>ICCV'19 TPAMI'20 ICLR'20 CVPR'20 ECCV'20</cell><cell>13.2 15.2 22.9 15.1 22.1</cell><cell>31.6 40.4 49.2 40.8 48.4</cell><cell>-53.1 63.1 51.8 60.9</cell><cell>49.6 58.7 68.8 56.7 66.1</cell><cell>Methods MMT-dbscan [11]* Ours</cell><cell>ICLR'20</cell><cell>mAP 71.0 73.8</cell><cell cols="2">PersonX→Market-1501 top-1 top-5 86.5 94.8 88.0 95.3</cell><cell>top-10 97.0 96.9</cell></row><row><cell>D-MMD [31] JVTC [23]</cell><cell>ECCV'20 ECCV'20</cell><cell>13.5 20.3</cell><cell>29.1 45.4</cell><cell>46.3 58.4</cell><cell>54.1 64.3</cell><cell cols="6">(c) Real→real and synthetic→real adaptation on vehicle</cell></row><row><cell>GPR [29] NRMT [57]</cell><cell>ECCV'20 ECCV'20</cell><cell>20.4 19.8</cell><cell>43.7 43.7</cell><cell>56.1 56.5</cell><cell>61.9 62.2</cell><cell>re-ID datasets.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MMT-dbscan [11]* Ours</cell><cell>ICLR'20</cell><cell>24.0 26.8</cell><cell>50.1 53.7</cell><cell>63.5 65.0</cell><cell>69.3 69.8</cell><cell>Methods</cell><cell></cell><cell>mAP</cell><cell cols="2">VehicleID→VeRi-776 top-1 top-5</cell><cell>top-10</cell></row><row><cell>Methods CASCL [47] MAR [52] PAUL [50] DG-Net++ [66] D-MMD [31]</cell><cell>CVPR'19 CVPR'19 ICCV'19 ECCV'20 ECCV'20</cell><cell>mAP 40.0 40.1 35.5 64.6 50.8</cell><cell cols="2">MSMT17→Market-1501 top-1 top-5 67.7 81.9 68.5 82.4 65.4 80.6 83.1 91.5 72.8 88.1</cell><cell>top-10 -87.4 86.2 94.3 92.3</cell><cell>MMT-dbscan [11]* Ours Methods MMT-dbscan [11]* Ours</cell><cell>ICLR'20 ICLR'20</cell><cell>35.3 38.9 mAP 35.6 38.9</cell><cell cols="2">74.6 80.4 VehicleX→VeRi-776 82.6 86.8 top-1 top-5 76.0 83.1 81.3 87.3</cell><cell>87.0 89.6 top-10 87.4 90.0</cell></row><row><cell>MMT-dbscan [11]*</cell><cell>ICLR'20</cell><cell>75.6</cell><cell>89.3</cell><cell>95.8</cell><cell>97.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell>77.5</cell><cell>89.7</cell><cell>96.1</cell><cell>97.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>(a)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>Methods</cell><cell></cell><cell>mAP</cell><cell cols="2">MSMT17→Market-1501 top-1 top-5</cell><cell>top-10</cell><cell>mAP</cell><cell cols="2">Market-1501→MSMT17 top-1 top-5</cell><cell>top-10</cell></row><row><cell>MMT-dbscan [11]*</cell><cell>ICLR'20</cell><cell>3.2</cell><cell>9.8</cell><cell>16.8</cell><cell>20.7</cell><cell>30.7</cell><cell>59.9</cell><cell>75.7</cell><cell>81.3</cell></row><row><cell cols="2">Encoder train/test on the source domain</cell><cell>49.9</cell><cell>75.2</cell><cell>86.4</cell><cell>89.8</cell><cell>84.7</cell><cell>94.0</cell><cell>97.7</cell><cell>98.7</cell></row><row><cell cols="2">Ours test on the source domain</cell><cell>56.5 (+6.6)</cell><cell>79.4</cell><cell>88.7</cell><cell>91.3</cell><cell>86.8 (+2.1)</cell><cell>94.7</cell><cell>97.9</cell><cell>98.6</cell></row><row><cell cols="2">Supervised learning methods on source</cell><cell></cell><cell>MSMT17</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Market-1501</cell><cell></cell></row><row><cell>FD-GAN [12]</cell><cell>NeurIPS'18</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>77.7</cell><cell>90.5</cell><cell>-</cell><cell>-</cell></row><row><cell>DG-Net [59]</cell><cell>CVPR'19</cell><cell>52.3</cell><cell>77.2</cell><cell>87.4</cell><cell>90.5</cell><cell>86.0</cell><cell>94.8</cell><cell>-</cell><cell>-</cell></row><row><cell>OSNet [64]</cell><cell>ICCV'19</cell><cell>52.9</cell><cell>78.7</cell><cell>-</cell><cell>-</cell><cell>84.9</cell><cell>94.8</cell><cell>-</cell><cell>-</cell></row><row><cell>Circle loss [40]</cell><cell>CVPR'20</cell><cell>50.2</cell><cell>76.3</cell><cell>-</cell><cell>-</cell><cell>84.9</cell><cell>94.2</cell><cell>-</cell><cell>-</cell></row></table><note>Comparison with state-of-the-art UDA methods and supervised learning methods when evaluating on the labeled source domain. (*) the implementation is based on the authors' code.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Comparison with state-of-the-art methods on the unsupervised object re-ID task without the labeled source-domain data. (*) the implementation is based on the authors' code.</figDesc><table><row><cell cols="2">Methods</cell><cell>mAP</cell><cell cols="2">Market-1501 top-1 top-5</cell><cell>top-10</cell><cell cols="2">Methods</cell><cell>mAP</cell><cell cols="2">MSMT17 top-1 top-5</cell><cell>top-10</cell></row><row><cell>OIM [49] BUC [25]</cell><cell>CVPR'17 AAAI'19</cell><cell>14.0 38.3</cell><cell>38.0 66.2</cell><cell>58.0 79.6</cell><cell>66.3 84.5</cell><cell>MMCL [45] MoCo [17]*</cell><cell>CVPR'20 CVPR'20</cell><cell>11.2 1.6</cell><cell>35.4 4.3</cell><cell>44.8 9.7</cell><cell>49.8 13.5</cell></row><row><cell>SSL [26]</cell><cell>CVPR'20</cell><cell>37.8</cell><cell>71.7</cell><cell>83.8</cell><cell>87.4</cell><cell cols="2">Ours w/o source data</cell><cell>19.1</cell><cell>42.3</cell><cell>55.6</cell><cell>61.2</cell></row><row><cell>MMCL [45] HCT [53]</cell><cell>CVPR'20 CVPR'20</cell><cell>45.5 56.4</cell><cell>80.3 80.0</cell><cell>89.4 91.6</cell><cell>92.3 95.2</cell><cell cols="2">Methods</cell><cell>mAP</cell><cell cols="2">VeRi-776 top-1 top-5</cell><cell>top-10</cell></row><row><cell>MoCo [17]*</cell><cell>CVPR'20</cell><cell>6.1</cell><cell>12.8</cell><cell>27.1</cell><cell>35.7</cell><cell>MoCo [17]*</cell><cell>CVPR'20</cell><cell>9.5</cell><cell>24.9</cell><cell>40.6</cell><cell>51.8</cell></row><row><cell cols="2">Ours w/o source data</cell><cell>73.1</cell><cell>88.1</cell><cell>95.1</cell><cell>97.0</cell><cell cols="2">Ours w/o source data</cell><cell>36.9</cell><cell>79.9</cell><cell>86.8</cell><cell>89.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Ablation studies of our proposed self-paced contrastive learning on individual components.</figDesc><table><row><cell cols="5">(a) Experiments on domain adaptive person re-ID.</cell><cell cols="5">(b) Experiments on unsupervised person re-ID.</cell></row><row><cell>Methods</cell><cell>mAP</cell><cell cols="2">MSMT→Market-1501 top-1 top-5</cell><cell>top-10</cell><cell>Methods</cell><cell>mAP</cell><cell cols="2">Market-1501 top-1 top-5</cell><cell>top-10</cell></row><row><cell cols="3">analysis of the unified contrastive learning mechanism:</cell><cell></cell><cell></cell><cell cols="4">analysis of the unified contrastive learning mechanism:</cell><cell></cell></row><row><cell>Src. class</cell><cell>25.3</cell><cell>51.3</cell><cell>69.6</cell><cell>76.6</cell><cell>tgt. instance</cell><cell>3.5</cell><cell>9.1</cell><cell>18.7</cell><cell>25.8</cell></row><row><cell>Src. class + tgt. instance</cell><cell>4.9</cell><cell>12.6</cell><cell>24.8</cell><cell>32.7</cell><cell>tgt. cluster (w/o self-paced)</cell><cell>6.7</cell><cell>16.5</cell><cell>27.9</cell><cell>33.8</cell></row><row><cell>Src. class + tgt. cluster (w/o self-paced)</cell><cell>28.9</cell><cell>50.1</cell><cell>64.5</cell><cell>71.0</cell><cell>tgt. cluster (w/ self-paced)</cell><cell>10.1</cell><cell>23.9</cell><cell>37.3</cell><cell>43.2</cell></row><row><cell>Src. class + tgt. cluster (w/ self-paced)</cell><cell>69.2</cell><cell>84.9</cell><cell>94.0</cell><cell>96.4</cell><cell>Ours w/o unified contrast</cell><cell>57.0</cell><cell>76.2</cell><cell>89.7</cell><cell>93.0</cell></row><row><cell>Src. class → Src. learnable weights</cell><cell>70.7</cell><cell>86.9</cell><cell>94.1</cell><cell>96.3</cell><cell cols="3">analysis of the self-paced learning strategy:</cell><cell></cell><cell></cell></row><row><cell>Ours w/o unified contrast</cell><cell>68.8</cell><cell>84.6</cell><cell>94.1</cell><cell>96.2</cell><cell>Ours w/o Rcomp&amp;R indep</cell><cell>68.2</cell><cell>85.0</cell><cell>93.3</cell><cell>95.3</cell></row><row><cell>analysis of the self-paced learning strategy:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours w/o Rcomp</cell><cell>68.6</cell><cell>86.2</cell><cell>93.9</cell><cell>95.8</cell></row><row><cell>Ours w/o Rcomp&amp;R indep</cell><cell>74.5</cell><cell>89.1</cell><cell>95.3</cell><cell>96.8</cell><cell>Ours w/o R indep</cell><cell>71.8</cell><cell>87.5</cell><cell>95.0</cell><cell>96.8</cell></row><row><cell>Ours w/o Rcomp</cell><cell>75.4</cell><cell>89.3</cell><cell>95.5</cell><cell>97.1</cell><cell>Oracle</cell><cell>82.3</cell><cell>92.6</cell><cell>97.2</cell><cell>98.4</cell></row><row><cell>Ours w/o R indep</cell><cell>76.6</cell><cell>89.5</cell><cell>95.6</cell><cell>97.3</cell><cell>Ours (full) w/o source data</cell><cell>73.1</cell><cell>88.1</cell><cell>95.1</cell><cell>97.0</cell></row><row><cell>Oracle</cell><cell>83.5</cell><cell>93.1</cell><cell>97.7</cell><cell>98.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours (full)</cell><cell>77.5</cell><cell>89.7</cell><cell>96.1</cell><cell>97.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Comparison of different backbones in our framework, i.e., ResNet-50 and IBN-ResNet.</figDesc><table><row><cell>Source</cell><cell>Target</cell><cell>mAP</cell><cell cols="2">Ours w/ ResNet-50 top-1 top-5</cell><cell>top-10</cell><cell>mAP</cell><cell cols="2">Ours w/ IBN-ResNet top-1 top-5</cell><cell>top-10</cell></row><row><cell>Market-1501</cell><cell>MSMT17</cell><cell>26.8</cell><cell>53.7</cell><cell>65.0</cell><cell>69.8</cell><cell>31.0</cell><cell>58.1</cell><cell>69.6</cell><cell>74.1</cell></row><row><cell>MSMT17</cell><cell>Market-1501</cell><cell>77.5</cell><cell>89.7</cell><cell>96.1</cell><cell>97.6</cell><cell>79.9</cell><cell>92.0</cell><cell>97.1</cell><cell>98.1</cell></row><row><cell>PersonX</cell><cell>Market-1501</cell><cell>73.8</cell><cell>88.0</cell><cell>95.3</cell><cell>96.9</cell><cell>77.9</cell><cell>90.5</cell><cell>96.1</cell><cell>97.7</cell></row><row><cell>PersonX</cell><cell>MSMT17</cell><cell>22.7</cell><cell>47.7</cell><cell>60.0</cell><cell>65.5</cell><cell>25.4</cell><cell>50.6</cell><cell>63.3</cell><cell>68.3</cell></row><row><cell>VehicleID</cell><cell>VeRi-776</cell><cell>38.9</cell><cell>80.4</cell><cell>86.8</cell><cell>89.6</cell><cell>38.0</cell><cell>79.7</cell><cell>85.8</cell><cell>88.4</cell></row><row><cell>VehicleX</cell><cell>VeRi-776</cell><cell>38.9</cell><cell>81.3</cell><cell>87.3</cell><cell>90.0</cell><cell>37.8</cell><cell>80.7</cell><cell>86.1</cell><cell>89.2</cell></row><row><cell>None</cell><cell>Market-1501</cell><cell>73.1</cell><cell>88.1</cell><cell>95.1</cell><cell>97.0</cell><cell>73.8</cell><cell>88.4</cell><cell>95.3</cell><cell>97.3</cell></row><row><cell>None</cell><cell>MSMT17</cell><cell>19.1</cell><cell>42.3</cell><cell>55.6</cell><cell>61.2</cell><cell>24.0</cell><cell>48.9</cell><cell>61.8</cell><cell>67.1</cell></row><row><cell>None</cell><cell>VeRi-776</cell><cell>36.9</cell><cell>79.9</cell><cell>86.8</cell><cell>89.9</cell><cell>36.6</cell><cell>79.1</cell><cell>85.9</cell><cell>89.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Evaluate our framework over Agglomerative Clustering<ref type="bibr" target="#b0">[1]</ref> algorithm. Experiments are conducted on the tasks of unsupervised person re-ID.</figDesc><table><row><cell>Clustering</cell><cell>mAP</cell><cell cols="2">Market-1501 top-1 top-5</cell><cell>top-10</cell></row><row><cell>Agglomerative Clustering w/o self-paced strategy</cell><cell>70.4</cell><cell>87.1</cell><cell>94.7</cell><cell>96.6</cell></row><row><cell>Agglomerative Clustering w/ self-paced strategy</cell><cell>75.2</cell><cell>89.7</cell><cell>95.8</cell><cell>97.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Comparison between DBSCAN w/ our cluster reliable criterion and HDBSCAN<ref type="bibr" target="#b1">[2]</ref>. Experiments are conducted on the tasks of unsupervised person re-ID.</figDesc><table><row><cell>Clustering</cell><cell>mAP</cell><cell cols="2">Market-1501 top-1 top-5</cell><cell>top-10</cell><cell>mAP</cell><cell cols="2">MSMT17 top-1 top-5</cell><cell>top-10</cell></row><row><cell>DBSCAN w/ our cluster reliable criterion</cell><cell>73.1</cell><cell>88.1</cell><cell>95.1</cell><cell>97.0</cell><cell>19.1</cell><cell>42.3</cell><cell>55.6</cell><cell>61.2</cell></row><row><cell>HDBSCAN</cell><cell>71.7</cell><cell>87.7</cell><cell>95.0</cell><cell>96.3</cell><cell>15.7</cell><cell>39.2</cell><cell>51.3</cell><cell>56.7</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† DukeMTMC-reID<ref type="bibr" target="#b36">[37]</ref> dataset has been taken down and should no longer be used.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† https://github.com/yxgeee/SpCL</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported in part by the General Research Fund through the Research Grants Council of Hong Kong under Grants (Nos. CUHK14208417, CUHK14207319), in part by the Hong Kong Innovation and Technology Support Program (No. ITS/312/18FX), in part by CUHK Strategic Fund.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A Algorithm Details Algorithm 1 Self-paced contrastive learning algorithm on domain adaptive object re-ID Require: Source-domain labeled data X s and target-domain unlabeled data X t ; Require: Initialize the backbone encoder f θ with ImageNet-pretrained ResNet-50; Require: Initialize the hybrid memory with features extracted by f θ ; Require: Temperature τ for Eq. (1), momentum m s for Eq. (3), momentum m t for Eq. (4);</p><p>for n in <ref type="bibr">[1, num_epochs]</ref> do Group X t into X t c and X t o by clustering {v} from the hybrid memory with the independence Eq. (5) and compactness Eq. (6) criterion; Initialize the cluster centroids {c} with Eq. (2) in the hybrid memory; </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Agglomerative clustering of a search engine query log</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beeferman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the sixth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="407" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hierarchical density estimates for data clustering, visualization, and outlier detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moulavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="51" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain-specific batch normalization for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7354" to="7362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Instance-guided context rendering for cross-domain person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="232" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pseudo-labeling curriculum for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="994" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Second International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Self-similarity grouping: A simple unsupervised cross domain adaptation approach for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6112" to="6121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mutual mean-teaching: Pseudo label refinery for unsupervised domain adaptation on person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fd-gan: Pose-guided feature distilling gan for robust person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1222" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-supervising fine-grained region similarities for large-scale image localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Structured domain adaptation with online relation regularization for unsupervised person re-id</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Curriculumnet: Weakly supervised learning from large-scale web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="135" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptive self-paced deep clustering with data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-paced learning for latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Joint visual and temporal consistency for unsupervised domain adaptive person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Active self-paced learning for cost-effective and progressive face identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="7" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A bottom-up clustering approach to unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8738" to="8745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised person re-identification via softened similarity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3390" to="3399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep relative distance learning: Tell the difference between similar vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2167" to="2175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A deep learning-based approach to progressive vehicle re-identification for urban surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="869" to="884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Generalizing person re-identification by camera-aware invariance learning and cross-domain mixup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bag of tricks and a strong baseline for deep person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation in the dissimilarity space for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mekhazni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhuiyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ekladious</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naphade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anastasiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakraborty</surname></persName>
		</author>
		<title level="m">The 4th ai city challenge</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Two at once: Enhancing learning and generalization capacities via ibn-net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="464" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">John riccitiello sets out to identify the engine of growth for unity technologies (interview). VentureBeat. Interview with Dean Takahashi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riccitiello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-01" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="17" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptive re-identification: Theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">107173</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dissecting person re-identification from the viewpoint of viewpoint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="608" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Circle loss: A unified perspective of pair similarity optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6398" to="6407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Shifting weights: Adapting object detectors from image to video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="638" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pamtri: Pose-aware multi-task learning for vehicle re-identification using highly randomized synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naphade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="211" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Contrastive multiview coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unsupervised person re-identification via multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10981" to="10990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Person transfer gan to bridge domain gap for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unsupervised person re-identification by camera-aware similarity consistency learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6922" to="6931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Joint detection and identification feature learning for person search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3415" to="3424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Patch-based discriminative feature learning for unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3633" to="3642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Simulating content consistent vehicle datasets with attribute descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naphade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gedeon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.08855</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unsupervised person re-identification by soft multilabel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2148" to="2157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Hierarchical clustering with hard-batch triplet loss for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13657" to="13665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Ad-cluster: Augmented discriminative clustering for domain adaptive person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9021" to="9030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Self-training with progressive augmentation for unsupervised cross-domain person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8222" to="8231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2020" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation with noise resistible mutual-training for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1116" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Joint discriminative and generative learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Re-ranking person re-identification with k-reciprocal encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1318" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="13001" to="13008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Invariance matters: Exemplar memory for domain adaptive person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="598" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Learning to adapt invariance in memory for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Omni-scale feature learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3702" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Local aggregation for unsupervised learning of visual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6002" to="6012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Joint disentangling and adaptation for cross-domain person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="289" to="305" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
