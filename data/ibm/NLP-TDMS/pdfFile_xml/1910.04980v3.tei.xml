<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conversational Transfer Learning for Emotion Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Information Systems Technology and Design</orgName>
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Zimmermann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Conversational Transfer Learning for Emotion Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Emotion Recognition in Conversations</term>
					<term>Transfer Learning</term>
					<term>Generative Pre-training</term>
					<term>Conversation Modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recognizing emotions in conversations is a challenging task due to the presence of contextual dependencies governed by self-and inter-personal influences. Recent approaches have focused on modeling these dependencies primarily via supervised learning. However, purely supervised strategies demand large amounts of annotated data, which is lacking in most of the available corpora in this task. To tackle this challenge, we look at transfer learning approaches as a viable alternative. Given the large amount of available conversational data, we investigate whether generative conversational models can be leveraged to transfer affective knowledge for detecting emotions in context. We propose an approach, TL-ERC, where we pre-train a hierarchical dialogue model on multi-turn conversations (source) and then transfer its parameters to a conversational emotion classifier (target). In addition to the popular practice of using pre-trained sentence encoders, our approach also incorporates recurrent parameters that model inter-sentential context across the whole conversation. Based on this idea, we perform several experiments across multiple datasets and find improvement in performance and robustness against limited training data. TL-ERC also achieves better validation performances in significantly fewer epochs. Overall, we infer that knowledge acquired from dialogue generators can indeed help recognize emotions in conversations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Emotion Recognition in Conversations (ERC) is the task of detecting emotions from utterances in a conversation. It is an important task with applications ranging from dialogue understanding to affective dialogue systems <ref type="bibr" target="#b0">[1]</ref>. Apart from the traditional challenges of dialogue understanding, such as intent-detection, contextual grounding, and others <ref type="bibr" target="#b1">[2]</ref>, ERC presents additional challenges as it requires the ability to model emotional dynamics governed by self-and interspeaker influences at play <ref type="bibr" target="#b2">[3]</ref>. Further complications arise due to the limited availability of annotated data -especially in multimodal ERC -and the variability in annotations owing to the subjectivity of annotators in interpreting emotions.</p><p>In this work, we focus on these issues by investigating a framework of sequential inductive transfer learning (TL) <ref type="bibr" target="#b3">[4]</ref>. In particular, we attempt to transfer contextual affective information from a generative conversation modeling task to ERC. We name this framework TL-ERC. In the illustration, P represents the personality of the speaker; S represents speaker-state; I denotes the intent of the speaker; E refers to the speaker's emotional state, and U refers to the observed utterance. Speaker personality and the topic always condition upon the variables. At turn t, the speaker conceives several pragmatic concepts such as argumentation logic, viewpoint, and inter-personal relationship -which we collectively represent using the speaker-state S <ref type="bibr" target="#b4">[5]</ref>. Next, the intent I of the speaker gets formulated based on the current speaker-state and previous intent of the same speaker (at t − 2). These two factors influence the emotional feeling of the speaker, which finally manifests as the spoken utterance <ref type="bibr" target="#b0">[1]</ref>.</p><p>But why should generative modeling of conversations acquire knowledge on emotional dynamics? To answer this question, we first observe the role of emotions in conversations. Several works in the literature have indicated that emotional goals and influences act as latent controllers in dialogues <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. Poria et al. <ref type="bibr" target="#b0">[1]</ref> demonstrated the interplay of several factors, such as the topic of the conversation, speakers' personality, argumentation-logic, viewpoint, and intent, which modulate the emotional state of the speaker and finally lead to an utterance. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates these dependencies, which elaborate emotional factor as a critical latent state in the overall generative process of dialogues. The interactions between these latent factors lead to diverse emotional dynamics within the conversations. <ref type="figure">Fig. 2</ref> provides some examples demonstrating such patterns. In the figure, conversation (a) illustrates the presence of emotional inertia <ref type="bibr" target="#b7">[8]</ref> which occurs though self-influences in emotional states. The character Snorri maintains a frustrated emotional state by not being affected/influenced by the other speaker. Whereas, conversation (b) and (c) demonstrate the role of inter-speaker influences in emotional transitions across turns. In (b), the character John is triggered for an emotional shift due to influences based on his counterpart's responses, while (c) demonstrates the effect of mirroring <ref type="bibr" target="#b8">[9]</ref> which often arises due to topical agreement between speakers. All these examples demonstrate the presence of such emotional dynamics that are not just inherent in the conversations but also help shape them up <ref type="bibr" target="#b0">[1]</ref>.</p><p>To model such conversations, a generator would require the ability to 1) interpret latent emotions from its contextual turns and 2) model the complex dynamics governing them. In addition, it would also need to interpret other factors such as topic of the conversations, speaker personalities, intents, etc. Such a model would then be a perfect dialogue generator. We illustrate this in <ref type="figure" target="#fig_2">Fig. 3</ref>, where the model generating utterance utt t+1 would require to understand the emotions of the context arising from the utterances utt t , utt t−1 , and so on. Thereby, we hypothesize that a trained dialogue generator would possess the ability to model implicit affective patterns across a conversation <ref type="bibr" target="#b9">[10]</ref>. Consequently, we propose a framework that uses TL to transfer this affective knowledge into our target discriminative task, i.e., ERC.</p><p>In our approach, we first pre-train a hierarchical generative dialogue model on the source task of conversation modeling. Being an unsupervised (or selfsupervised) task, conversation modeling typically benefits from a large amount of data in the form of multi-turn chats. Next, we adapt our model to the target task (ERC) by transferring the inter-sentence contextual parameters 1 from the trained source model. For sentence encoding, we choose the BERT model <ref type="bibr" target="#b11">[12]</ref>, which is pre-trained on masked language modeling and next sentence prediction objectives.</p><p>Although we acknowledge that training a perfect dialogue generator is presently challenging, we demonstrate that benefits can be observed even with a popular baseline generator. In the bigger picture, our approach can enable the co-evolution of both generative and discriminative models for the tasks mentioned above. This is possible since improving an emotional classifier using a dialogue model can, in turn, be utilized to enhance dialogue models with emotional intelligence further, leading to an iterative cycle of improvements for both the applications.</p><p>Overall, our contributions are summarized as follows:</p><p>• We propose TL-ERC, which pre-trains a hierarchical generative dialogue model on multi-turn conversations (source) and subsequently transfers affective knowledge to the target task of ERC. Despite the active role of TL in providing state-of-the-art token and sentence encoders, its use in leveraging multi-turn contextual knowledge -across utterances -has been mostly unexplored. Our work stands as one of the first in this direction.</p><p>• Through our experiments, we observe the promising effects of using these pre-trained weights. Our models, initialized with the acquired knowledge, converge faster compared to randomly initialized counterparts and also demonstrate robust performance in limited training-data scenarios.</p><p>• We identify various challenges observed in using TL for ERC. These points raise essential research questions and provide a roadmap for future research in this topic.</p><p>In the remaining paper, Section 2 first discusses the works in the literature related to our task and our approach. Next, Section 3 provides information on the TL setup along with details on the design of the framework. Experimental details are mentioned in Section 4; results and extensive analyses are provided in Section 5. Section 6 provides some challenges observed in the proposed framework, casting light for future research efforts. Finally, Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>We proceed to discuss the use of transfer learning by the available literature in NLP. First, we enlist some of the famous works that have benefited from TL, and then we focus on works that attempt to frame TL in the context-level hierarchy. Next, we look at recent works on emotion/sentiment analysis, including works that have employed TL. Finally, we attempt to position our contribution amidst the latest developments in ERC. sequential information acquired from utterances of speakers in a conversation.</p><formula xml:id="formula_0">Utterance_(t+1) Utterance_(t-1) Utterance_(t)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotional Understanding</head><p>Context-level Encoder  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Transfer Learning in NLP</head><p>Transfer learning has played a critical role in the success of modern-day NLP systems. As a matter of fact, the key milestones in the recent history of NLP are provided by works using TL. NLP has particularly benefited by inductive TL, where unlabelled data is utilized to leverage knowledge for labeled downstream tasks. Early works, such as Ando and Zhang <ref type="bibr" target="#b12">[13]</ref>, introduced this concept, which was heavily adopted by the community and has shown tremendous success ever since <ref type="bibr" target="#b13">[14]</ref>.</p><p>Modern breakthroughs, such as neural word embeddings, followed similar modeling by utilizing unlabeled textual data to learn the embeddings <ref type="bibr" target="#b14">[15]</ref>. Of late, there has been a significant interest in using language models (LMs) to learn contextual embeddings <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. TL through LM pre-training has also provided state-of-the-art text classifiers with high quality sentence encoders <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19]</ref>. Consequently, several works have explored improving this framework by either modifying the LM pre-training approach or weight adaptation in the downstream tasks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>Context-level Transfer Learning. Availability for works that explore TL for inter-sentence or sequential learning is limited. Some of these include sentencelevel sequence tagging tasks <ref type="bibr" target="#b21">[22]</ref> or inter-sentence supervised tasks such as query matching in conversations <ref type="bibr" target="#b22">[23]</ref>, next sentence prediction <ref type="bibr" target="#b11">[12]</ref>, etc. Recent works that address the topic of pre-training sentence representations or multiturn conversations follow either a retrieval-based or a generative strategy. For the former, strategies include contrastive sentence selection (ToD-BERT <ref type="bibr" target="#b23">[24]</ref>, ConveRT <ref type="bibr" target="#b24">[25]</ref>), sentence ordering (ALBERT <ref type="bibr" target="#b25">[26]</ref>), and semantical sentence matching (Sentence-BERT <ref type="bibr" target="#b26">[27]</ref>) objectives. Whereas, generative models attempt to learn a probabilistic model for the conversations directly. DialoGPT <ref type="bibr" target="#b27">[28]</ref> is a recently proposed model that proposes a generative model based on the GPT architecture <ref type="bibr" target="#b28">[29]</ref>. Our pre-training model is similar in spirit to DialoGPT. However, we do not flatten the conversation and instead opt for a hierarchical conversation model. This also suits our downstream task of conversational emotion recognition. Additionally, we analyze the joint pre-training of full conversations in a self-supervised setting and attempt to observe its efficacy in transferring affective knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Affect Analysis</head><p>Affect, in particular emotions, are an integral part of human life and modulate our day-to-day behavior and activities <ref type="bibr" target="#b29">[30]</ref>. The interest in understanding emotions is multi-disciplinary and covers a long history of research. The importance of modeling emotions has multiple benefits across applications such as e-learning <ref type="bibr" target="#b30">[31]</ref>, human-computer interaction <ref type="bibr" target="#b31">[32]</ref>, user profiling <ref type="bibr" target="#b32">[33]</ref>, etc.</p><p>From a computational perspective, emotions are typically studied across various media formats, covering applications such as facial emotion recognition <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>, emotions in speech <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>, or multimodal emotion recognition <ref type="bibr" target="#b37">[38]</ref>. In text-based applications, machine learning has played a crucial role in mining emotions <ref type="bibr" target="#b38">[39]</ref>. Earlier approaches designed hand-crafted features that included emotional keyword spotting <ref type="bibr" target="#b39">[40]</ref>, affect-based lexical resources (WordNet-Affect <ref type="bibr" target="#b40">[41]</ref>, SentiWordNet <ref type="bibr" target="#b41">[42]</ref>), and distant supervision via hashtags <ref type="bibr" target="#b42">[43]</ref>. In the present deep-learning era,</p><p>In the present deep learning era, approaches have diverged from hand-crafted features and moved towards automated feature learning. Modern approaches consider advanced neural architectures, such as convolutional networks <ref type="bibr" target="#b43">[44]</ref>, recurrent networks <ref type="bibr" target="#b44">[45]</ref>, and attention mechanisms <ref type="bibr" target="#b45">[46]</ref> for emotion detection. Recent times have also seen approaches that address practical scenarios such as domain awareness <ref type="bibr" target="#b46">[47]</ref>, and utilize alternate training strategies, such as adversarial approaches <ref type="bibr" target="#b47">[48]</ref>. Complementary to these issues, we address data scarcity issues in ERC and leverage transfer learning for the same. We discuss the related works aligned to these topics next.</p><p>Transfer Learning for Affect. TL for affective analysis has gained momentum in recent years, with several works adopting TL-based approaches for their respective tasks. These works leverage diverse source tasks, such as, sentiment/emotion analysis in text <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>, large-scale image classification in vision <ref type="bibr" target="#b51">[52]</ref>, sparse auto-encoding in speech <ref type="bibr" target="#b52">[53]</ref>, etc. Felbo et al. utilize emojis present in online platforms to pre-train models and transfer knowledge for emotion recognition. Using layer-wise fine-tuning, they also transfer knowledge into related tasks of sarcasm and sentiment detection. A similar approach is taken by Daval-Frerot et al.. Similar to these works, our approach also leverages TL for knowledge transfer. However, our task is in a sequential setting at the conversational level. To the best of our knowledge, our work is one of the first that explores TL in ERC and utilizes generative conversation modeling as a pre-training objective.</p><p>Emotion Recognition in Conversations. ERC is an emerging sub-field of affective computing and is developing into an active area of research. Current works try to model contextual relationships amongst utterances in a supervised fashion to model the implicit emotional dynamics. Strategies include modeling speakerbased dependencies using recurrent neural networks <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b55">56]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>57]</head><p>, graph neural networks <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>, quantum-inspired networks <ref type="bibr" target="#b59">[60]</ref>, amongst others. Some of these works also explore challenges such as multi-speaker modeling <ref type="bibr" target="#b60">[61]</ref>, multimodal processing <ref type="bibr" target="#b56">[57]</ref>, and knowledge infusion <ref type="bibr" target="#b61">[62]</ref>. BERTbased sentence encoding has also been heavily adopted by the latest works in this area <ref type="bibr" target="#b62">[63]</ref>. Works like EmotionX-IDEA <ref type="bibr" target="#b63">[64]</ref> and PT-Code <ref type="bibr" target="#b64">[65]</ref>, developed concurrently to ours, follow a similar vein by transferring emotional knowledge from BERT pre-training. However, in these works, either the conversations are limited to utterance-reply pairs or follow a contrastive utterance retrieval objective. Our work, in contrast, pre-trains a whole conversation jointly using a hierarchical generative model. Overall, we find that there is a dearth of works that consider scarcity issues for annotated data and leverage TL. Our work strives to fill this gap by providing a systematic study for TL in ERC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Our proposed framework, TL-ERC, is summarized in <ref type="figure" target="#fig_3">Fig. 4</ref>. First, we define the source generative model trained as a dialogue generator, followed by a description of the target model, which performs hierarchical context encodingfor the task of ERC -using BERT-based sentence encoders and learned context weights from the source model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Source: Generative Conversation Modeling</head><p>To perform the generative task of conversation modeling, we use the Hierarchical Recurrent Encoder-Decoder (HRED) architecture <ref type="bibr" target="#b65">[66]</ref>. HRED is a classic framework for seq2seq conversational response generation that models conversations in a hierarchical fashion using three sequential components: encoder recurrent neural networks (RNNs) for sentence encoding, context RNNs for modeling the conversational context across sentences, and decoder RNNs for generating the response sentence.</p><p>For a given conversation context with sentences x 1 , ... x t , HRED generates the response x t+1 as follows:</p><p>1. Sentence Encoder: It encodes each sentence in the context using an encoder RNN, such that,</p><formula xml:id="formula_1">h enc t = f enc θ (x t , h enc t−1 )</formula><p>2. Context Encoder: The sentence representations are then fed into a context RNN that models the conversational context until time step t as</p><formula xml:id="formula_2">h cxt t = f cxt θ (h enc t , h cxt t−1 )</formula><p>3. Sentence Decoder: Finally, an auto-regressive decoder RNN generates sentence x t+1 conditioned on h cxt t , i.e.,</p><formula xml:id="formula_3">p θ (x t+1 x ≤t ) = f dec θ (x h cxt t ) = i f dec θ (x t+1,i h cxt t , x t+1,&lt;i )</formula><p>With the i th conversation being a sequence of utterances</p><formula xml:id="formula_4">C i = [x i,1 , ..., x i,ni ]</formula><p>, HRED trains all the conversations in the dataset together by using the maximum likelihood estimation objective arg max θ = ∑ i log p θ (C i ).</p><p>The HRED model provides the possibility to introduce multiple complexities in the form of multi-layer RNNs and other novel encoding strategies. In this work, we choose to experiment with the original version of the architecture with single-layer components so that we can analyze the hypothesis without unwanted contribution from the added complexities. In our source model, f enc θ can be any RNN function, which we model using the bi-directional Gated Recurrent Unit (GRU) variant <ref type="bibr" target="#b66">[67]</ref> to encode each sentence. We call the parameters associated with this GRU function as θ source enc . For both the context RNN (f cxt θ ) and decoder RNN, we use uni-directional GRUs -with parameters θ source cxt and θ source dec , respectively -and complement the decoder with beam-decoding for generation 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Target: Emotion Recognition in Conversations</head><p>The input for this task is also a conversation C with constituent utterances [x 1 , ..., x n ]. Each x i is associated with an emotion label y i ∈ Y. We adopt a setup similar to the three components described for the source task, as in Poria et al. <ref type="bibr" target="#b67">[68]</ref>. However, the decoder in this setup is replaced by a discriminative mapping to the label space instead of a generative network. Below, we describe the different initialization parameters that we consider for the first two stages of the network:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Sentence Encoding</head><p>To encode each utterance in the conversation, we consider the state-of-the-art universal sentence encoder BERT <ref type="bibr" target="#b11">[12]</ref>, with its parameters represented as θ BERT . We choose BERT over the HRED sentence encoder (θ source enc ) as it provides better performance (see <ref type="table" target="#tab_14">Table 8</ref>). Also, BERT includes the task of next sentence prediction as one of its training objectives which aligns with the inter-sentence level of abstraction that we consider in this work.</p><p>We choose the BERT-base uncased pre-trained model as our sentence encoder 3 . Though this model contains 12 transformer layers, to limit the total number of parameters in our model, we restrict to the first 4 transformer layers. To get a sentential representation, we use the hidden vectors of the first token [CLS] across the considered transformer layers (see Devlin et al. <ref type="bibr" target="#b11">[12]</ref>) and mean-pool them to get the final sentence representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Context Encoding</head><p>We use a similar context encoder RNN as the source HRED model with the option to transfer the learned parameters θ source cxt . For input sentence representation h enc t provided by the encoder RNN, the context RNN transforms it as follows:</p><formula xml:id="formula_5">z t = σ(V z h enc t + W z h cxt t−1 + b z ) r t = σ(V r h enc t + W r h cxt t−1 + b r ) v t = tanh(V h h enc t + W h (h cxt t−1 ⊗ r t ) + b h ) h cxt t = (1 − z t ) ⊗ v t + z t ⊗ h cxt t−1 h cxt t = tanh(W p h cxt t + b p )</formula><p>Here, {V z,r,h , W z,r,h , b z,r,h are parameters for the GRU function and {W p , b p } are additional parameters of a dense layer. For our setup, adhering to size considerations, we consider our transfer parameters to be θ source cxt = {W z,r,h,p , b z,r,h,p }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Classification</head><p>For each turn in the conversation, the output from the context RNN is projected to the label-space, which provides the predicted emotion for the associated utterance. Similar to HRED, we train for all the utterances in the conversation together using the standard Cross Entropy loss. For regression targets, we utilize the Mean Square Error (MSE) loss, instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup</head><p>In this section, we define the experimental setup followed in this work. First, we detail the datasets that we utilize and mention their properties. Further, we provide information on the metrics used for evaluation, the training setup, and the model variants considered to test our hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets 4.1.1. Source Task</head><p>For pre-training with the source task of conversation modeling, we consider two large-scale benchmark datasets:</p><p>• Cornell Movie Dialog Corpus <ref type="bibr" target="#b10">[11]</ref> is a popular collection of fictional conversations extracted from movie scripts. In this dataset, conversations are sampled from a diverse set of 617 movies leading to over 83k dialogues.</p><p>• Ubuntu Dialog Corpus <ref type="bibr" target="#b68">[69]</ref> is a larger corpus with around 1 million dialogues, which, like the Cornell corpus, comprises of unstructured multi-turn dialogues based on Ubuntu chat logs (Internet Relay Chat).</p><p>Both datasets contain dyadic, i.e. two-party conversations. For brevity, throughout the paper, we mention these datasets as Cornell and Ubuntu, respectively. The data splits for training are created as per Park et al. <ref type="bibr" target="#b69">[70]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Target Task</head><p>For the target task of ERC, we experiment with three datasets popular in this area of research:</p><p>• Primarily, we consider the textual modality of a small-sized multimodal dataset IEMOCAP <ref type="bibr" target="#b70">[71]</ref> consisting of dyadic conversations between 10 speakers. Each pair is assigned one of many diverse conversational scenarios, with a total of five sessions across the dataset. Each conversational video is segmented into utterances and annotated with the following emotion labels: anger, happiness, sadness, neutral, excitement, and frustration. Split creating scheme is based on Hazarika et al. <ref type="bibr" target="#b56">[57]</ref>.</p><p>• We also analyze results on a moderately-sized emotional dialogue dataset DailyDialog <ref type="bibr" target="#b71">[72]</ref> with labeled emotions: anger, happiness, sadness, surprise, fear disgust and no emotion. Unlike spoken utterances in IEMOCAP, the conversations are chat-based based on daily life topics. For creating the splits, we follow the original split details provided by Li et al. <ref type="bibr" target="#b71">[72]</ref>.</p><p>• Finally, we choose a regression-based dataset SEMAINE, which is a videobased corpus of human-agent emotional interactions. We use the split configuration detailed in AVEC 2012's fully continuous sub-challenge <ref type="bibr" target="#b72">[73]</ref> for the prediction of affective dimensions: valence, arousal, power, and expectancy. Annotation configuration is based on Hazarika et al. <ref type="bibr" target="#b56">[57]</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">Metrics</head><p>We choose the pre-training weights from the source task based on the best validation perplexity score <ref type="bibr" target="#b69">[70]</ref>. For ERC, we use weighted-F-score metric for the classification tasks on IEMOCAP and DailyDialog. For DailyDialog, we remove no emotion class from the F-score calculations due to its high majority (82.6%/81.3% occupancy in training/testing set) which hinders evaluation of other classes 4 . For the regression task on SEMAINE, we take the Pearson correlation coefficient (r) as its metric.</p><p>We also provide the average best epoch (BE) on which the least validation losses -across the multiple runs -are observed, and the testing evaluations are performed. A lower BE represents the model's ability to reach optimum performance in lesser training epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model Size</head><p>We consider two versions of the source generative model: HRED-small and HRED-large with 256 and 1000-dimensional hidden state sizes, respectively. While testing the performance of both the models on the IEMOCAP dataset, we find the context weights from HRED-small (Cornell dataset) to provide better performance on average (58.5% F-score ) over HRED-large (55.3% F-score). Following this observation, and also to avoid over-fitting on the small target datasets due to increased parameters, we choose the HRED-small model as the source task model for our TL procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Model Variants and Baselines</head><p>The primary goal of this paper is to analyze the effect of TL at the conversation level for ERC. For this, we experiment on different variants of our model based on the parameter initialization procedure. We provide a summary of these variants in Context encoders -randomly initialized.</p><p>(2) θ BERT -Sentence encoders -BERT parameters.</p><p>Context encoders -randomly initialized.</p><p>(3) θ BERT θ ubuntu cornell cxt</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TL-ERC</head><p>Sentence encoders -BERT parameters.</p><p>Context encoders -initialized from generative models pre-trained on Ubuntu/Cornell corpus. parameters. In Variant 2, we replace the sentence encoders with the BERT model including its original pre-trained parameters. Finally, in Variant 3, in addition to BERT sentence encoders, we also initialize the context-RNN parameters learned from the source task. Different results and analyses amongst these variants are provided in Section 5. Next, to compare our model with the existing literature, we select some prior state-of-the-art models evaluated on the target datasets:</p><p>• CNN <ref type="bibr" target="#b73">[74]</ref> extracts textual features based on Convolutional Neural Networks (CNN). This is a non-contextual model, which evaluates each utterance in a conversation independently.</p><p>• Memnet <ref type="bibr" target="#b74">[75]</ref> assigns dedicated memory for each historical utterance and performs multi-hop inference on them to get final representations for emotion classification.</p><p>• c-LSTM [68] is a popular model which is similar to our target model. It employs a bi-directional LSTM <ref type="bibr" target="#b75">[76]</ref> to capture inter-utterance dependencies.</p><p>• c-LSTM+Att <ref type="bibr" target="#b76">[77]</ref> enhances the c-LSTM model with inter-modality and interutterance attention mechanisms.</p><p>• CMN <ref type="bibr" target="#b2">[3]</ref>, the Conversational Memory Network, is an extension to the Memnet model which allots separate memories to both speakers in a dyadic conversational exchange.    <ref type="bibr" target="#b11">[12]</ref>). For a particular dataset-model pair, the final hyper-parameter configuration is chosen based on the best performance on the respective validation set. In the case of negligent difference between the combinations, we use the Adam optimizer <ref type="bibr" target="#b78">[79]</ref> as the default variant with β = [0.9, 0.999] and learning rate 1e − 4.</p><p>Inference. We train our models on each target dataset for multiple runs (10:IEMO-CAP, 5:DailyDialog, 5:SEMAINE). In each run, the training proceeds with an early stopping criterion of patience 10. During this training loop, the parameters with the least validation loss are finally chosen for the testing-set inference and evaluation.  and statistically significant improvements of the models that use pre-trained weights over the randomly initialized variant. We see further improvements when context-modeling parameters from the source task (θ source cxt ) are transferred, indicating the benefit of using TL in this context-level hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Analyses</head><p>Similar trends are observed in the regression task based on the SEMAINE corpus (see <ref type="table" target="#tab_11">Table 6</ref>). For valence, arousal, and power dimensions, the improvement is significant. For expectation, the performance is marginally better but at a much lesser BE, indicating faster generalization.</p><p>In the following sections, we take a closer look at various aspects of our approach that include checking robustness towards limited-data scenarios, generalization time, and questioning design choices. We also provide additional analyses that probe the existence of data-split bias, domain influence, and effect of fine-tuning strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Target Data Size</head><p>Present approaches in ERC primarily adopt supervised learning strategies that demand a high amount of annotated data. However, the publicly available datasets in this field belong to the small-to-medium range in the spectrum of dataset sizes. For example, other applications of NLP have datasets of much larger sizes -over 130k instances in SQuAD for Question Answering <ref type="bibr" target="#b80">[81]</ref>, over 393k instances in MNLI for language inference <ref type="bibr" target="#b81">[82]</ref>, and so on. This constraint inhibits the true potential of systems trained on these datasets. As a result, approaches that provide higher performance in a limited training-data scenario tend to be highly desirable, particularly for ERC.</p><p>We design experiments to check the robustness of our models against such limited settings. To limit the amount of available training data, we create random subsets of the training dialogues while maintaining the original label-distribution. In both <ref type="table" target="#tab_8">Table 4</ref> and 5, we observe that the pre-trained models are significantly more robust against limited training resources compared to models trained from scratch.</p><p>Effect of bias in random splits. We investigate the possibility of bias in the random splits, which aid in supporting our hypothesis. To eliminate this possibility, we further check if the improvement in our TL-based approach -for the limited-data scenarios -are triggered by such data-split bias. In other words, we pose the following question, if another training split is sampled from the original dataset, would our model provide similar improvements? We provide evidence that this is indeed true. <ref type="table" target="#tab_13">Table 7</ref> presents the results where for 10% and 50% training-data setup, we sample 4 independent splits from the IEMOCAP dataset. As seen from the table, different splits provide different results, which is expected owing to the variances in the samples and their corresponding labels. However, the relative performance within each split follows similar trends of improvement for TL-based models. This observation nullifies the potential existence of bias in the reported results. In all the configurations in <ref type="table" target="#tab_8">Table 4</ref> and 5, we observe that the presence of weight initialization leads to faster convergence in terms of the best validation loss. <ref type="figure" target="#fig_4">Fig. 5</ref> demonstrates the trace of the validation loss on training data configurations of the IEMOCAP dataset. As observed, the pre-trained models achieve their best epoch in a significantly shorter time which indicates that the transferred weights are helping the model better guide to its optimal performance. <ref type="table" target="#tab_14">Table 8</ref> provides a comparative study between the performance of models initialized with HRED-based sentence encoders (θ source enc ) versus the BERT encoders (θ BERT ) that we use in our final networks. Results demonstrate that BERT provides better representations, which leads to better performance. Moreover, the positive effects of the context parameters are observed when coupled with the BERT encoders. This behavior indicates that the performance boosts provided by the context-encoders is contingent on the quality of sentence encoders. Observing this empirical evidence, we choose BERT-based sentence encoders in our final network.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Target Task's Training Time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Encoder Initialization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Impact of Source Domain.</head><p>We investigate if the choice of source datasets incur any significant change in the results. First, we define an emotional profile for the source datasets and observe whether any correlation is found between their emotive content versus the performance boost achieved by pre-training on them.</p><p>To set up an emotional profile, we look at the respective vocabularies of both corpora. For each token, we check its association with any emotion by using the emotion-lexicon provided by Mohammad and Turney <ref type="bibr" target="#b82">[83]</ref>. The NRC Emotion Lexicon contains 6423 words belonging to emotion categories: fear, trust, anger, sadness, anticipation, joy, surprise, and disgust. It also assigns two broad categories: positive and negative to describe the type of connotation evoked by the words. We enumerate the frequency of each emotion category amongst the tokens of the source dataset's vocabulary. To compose the vocabulary of both the source datasets, we set a minimum frequency threshold of 5, which provides 13518 and 18473 unique tokens for Cornell and Ubuntu, respectively. Each of the unique tokens is then lemmatized 5 and cross-referenced with the lexicon, which provides 3099 <ref type="bibr">(Cornell)</ref>     emotions. <ref type="figure" target="#fig_5">Fig. 6</ref> presents the emotional profiles, which indicate that the Cornell dataset has a higher number of emotive tokens in its vocabulary. However, the results illustrated in <ref type="table" target="#tab_8">Table 4</ref>, 5, and 6 do not present any significant difference between the two sources. A possible reason for this behavior attributes to the fact that such emotional profile relies on surface emotions derived from the vocabularies. However, as per our hypothesis, response generation includes emotional understanding as a latent process. This reasoning leads us to believe that surface emotions need not necessarily correlate to performance increments. Rather, the quality of generation would include such properties intrinsically. <ref type="table" target="#tab_2">Table 10</ref> provides the results for various baselines detailed in Section 4.3. As seen, our proposed TL-ERC comfortably outperforms both non-contextual and contextual baselines. It achieves this without the aid of attention mechanisms that is used in c-LSTM + Att, multi-hop memory networks used in Memnet, and CMN. It also achieves competitive performance against DialogueRNN, which has three layers of inter-utterance recurrent layers, while TL-ERC has one. These trends indicate TL to be effective in our setup and provided promising directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Comparison with previous work.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Challenges</head><p>In this section, we enlist the different challenges that we observed while experimenting with the proposed idea. These challenges provide roadmaps for further research on this topic to build better and robust systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Adaptation Strategies</head><p>We try two primary adaptation techniques used in inductive TL, freezed or fine-tuned. In the former setting, the borrowed weights are used for feature extraction, while in the latter, we train the weights along with the other new parameters of the target task's model. Fine-tuning can also be performed using other techniques such as gradual unfreezing <ref type="bibr" target="#b83">[84]</ref>. In <ref type="table" target="#tab_16">Table 9</ref>, we experiment with freezing different amounts of transferred weights in our ERC model. We notice a degradation in performance with more frozen parameters. The datasets in ERC contain multi-class annotations with varying label distributions. With frozen parameters, our transferred model is unable to account for the label distribution and results in low recall for infrequent classes. We thus find the fine-tuning approach to be more effective in this setup.</p><p>However, fine-tuning all parameters also present higher susceptibility to over-fitting <ref type="bibr" target="#b19">[20]</ref>. We observe this trait in <ref type="figure" target="#fig_4">Fig. 5</ref>, where the validation loss shoots up at a faster rate than the random counterpart. Finding a fine-balance in this trade-off remains an open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Stability Issues</head><p>In the results, we observe that the variability of the models across multiple runs (in terms of the standard error) is relatively higher for the proposed models as compared to randomly initialized weights. Though, on average, our models perform significantly better, there remains a scope for improvement to achieve more stable training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Variational Models</head><p>Many works utilize variational networks to model the uncertainties and variability in latent factors. For dialogue modeling, networks such as VHRED <ref type="bibr" target="#b84">[85]</ref> incorporate such variational properties to model its latent processes. Emotional perception, in particular, has been argued to contain shades of multiple affective classes instead of a hard label assignment <ref type="bibr" target="#b85">[86]</ref>. We, thus, posit that variational dialogue models such as VHRED also hold the potential for improving affective knowledge transfer.</p><p>We experiment on this concept by using VHRED as the source model. VHRED uses additional paramteres to model its prior latent state z t , which is then concatenated with h cxt t as follows:   p θ (z t x ≤t ) = N (z µ t , σ t I)</p><formula xml:id="formula_6">where µ t = MLP θ (h cxt t ) σ t = Softplus( MLP θ (h cxt t ) ) h cxt t = [h cxt t ; z t ]</formula><p>As a result, our set of transferred parameters contain the additional parameters of MLP θ , included in θ source cxt . <ref type="table" target="#tab_2">Table 11</ref> presents the result of using VHRED parameters. Unfortunately, we do not find significant difference between the parameters from VHRED as opposed to HRED. However, the lack of degradation in the results promise possible future improvements in such designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">In-domain Generative Fine-Tuning</head><p>We try in-domain tuning of the generative HRED model by performing conversation modeling on the ERC resources. Finally, we transfer these re-tuned weights for the discriminative ERC task. However, we do not find this procedure to be helpful <ref type="table" target="#tab_2">( Table 12</ref> ). TL between generative tasks, especially with smallscale target resources, is a challenging task. As a result, we find sub-optimal generation in ERC datasets whose further transfer for the classification does not provide any improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Quality of Generative Models</head><p>Despite their recent developments, generative dialogue models still suffer from numerous shortcomings. Challenges include lack of diversity in the responses, which results in the generation of universal sentences, such as I don't know <ref type="bibr" target="#b86">[87,</ref><ref type="bibr" target="#b87">88]</ref>. Coherence in topic and emotions are also difficult to maintain while generating responses <ref type="bibr" target="#b88">[89]</ref>. Similar traits are observed in our pre-training experiments.</p><p>Although TL-ERC obtains significant improvement in the results, we obtain it with a simple dialogue model. We, thus, believe that further improvements are possible and is contingent on the quality of the dialogue generator. As research in dialogue systems inch towards the perfect dialogue generator, it would also benefit ERC via our proposed TL-ERC framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we presented a novel framework of transfer learning (TL-ERC) for ERC that uses pre-trained affective information from dialogue generators. We presented various experiments with different scenarios to investigate the effect of this procedure. We found that using such pre-trained weights help the overall task and also provide added benefits in terms of lesser training epochs for good generalization. We primarily experimented on dyadic conversations both in the source and the target tasks. In the future, we aim to investigate the more general setting of multi-party conversations. This setting will increase the complexity of the task, as pre-training would require multi-party data and special training schemes to capture complex influence dynamics.</p><p>Code used for this work is publicly available at https://github.com/ SenticNet/conv-emotion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Dyadic conversation -between person X and Y -are governed by interactions between several latent factors. Emotions are a crucial component in this generative process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The figure illustrates how a perfect dialogue generator requires emotional understanding from its context -a transferrable knowledge into ERC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Proposed framework for ERC using TL parameters. The model on the left is a conversational response generator which is used as a pre-trained model. The parameters are transferred to the target model as shown on the right side.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Validation loss across epochs in training for different weight-initialization settings on the IEMOCAP dataset. Part a) represents results when trained on 100% training data b) 10% training data split. For fair comparison, optimizer learning rates are fixed at 1e-4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>a) Frequency of emotive words from source datasets: Cornell and Ubuntu. b) randomly sampled words from Cornell associated to mentioned emotions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, memory networks[3,   </figDesc><table><row><cell cols="2">x 2x 3</cell><cell></cell><cell></cell><cell cols="2">y 1ŷ 2</cell></row><row><cell>Decoder</cell><cell>Decoder</cell><cell></cell><cell></cell><cell>Classifier</cell><cell>Classifier</cell></row><row><cell></cell><cell></cell><cell cols="2">Transfer</cell><cell></cell><cell></cell></row><row><cell>Context</cell><cell>Context</cell><cell></cell><cell></cell><cell>Context</cell><cell>Context</cell></row><row><cell>RNN</cell><cell>RNN</cell><cell cols="2">θ sou rce cxt</cell><cell>RNN</cell><cell>RNN</cell></row><row><cell>Sentence</cell><cell>Sentence</cell><cell></cell><cell></cell><cell>Sentence</cell><cell>Sentence</cell></row><row><cell>Encoder x 1</cell><cell>Encoder x 2</cell><cell>{θ sou rce enc</cell><cell>, θ BERT }</cell><cell>Encoder x 1</cell><cell>Encoder x 2</cell></row><row><cell>source task:</cell><cell></cell><cell></cell><cell></cell><cell cols="2">target task: Emotion Recognition in</cell></row><row><cell cols="2">Conversation Modeling</cell><cell></cell><cell></cell><cell></cell><cell>Conversations</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>provides the sizes along with split distributions for the abovementioned datasets. For both IEMOCAP and SEMAINE, we generate the validation sets by random-sampling of 20% dialogue videos from the training sets. The class distribution for the categorical emotions in IEMOCAP and DailyDialog are presented inTable 2. From the table, IEMOCAP is observed a fairly balanced dataset whereas DailyDialog is highly skewed towards sentences with no emotion. As such, we decide upon different metrics for each dataset as discussed next.</figDesc><table><row><cell></cell><cell>Dataset</cell><cell></cell><cell>train</cell><cell cols="3">Dataset splits validation</cell><cell>test</cell></row><row><cell>Source</cell><cell>Cornell Ubuntu</cell><cell cols="3">#D #U #D #U 6,893,060 66,477 244,030 898,142</cell><cell cols="2">8,310 30,436 18,920 135,747</cell><cell>8,310 30,247 19,560 139,775</cell></row><row><cell>Target Target</cell><cell>IEMOCAP SEMAINE Dailydialog</cell><cell>#D #U #D #U #D #U</cell><cell>11,118 87,170</cell><cell cols="2">120 5810 58 4386</cell><cell>1,000 7,740</cell><cell>31 1,623 22 1,430 1,000 8,069</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Table illustrates the sizes of the datasets used in this work. #D represents the number of dialogues whereas #U represents the total number of constituting utterances.</figDesc><table><row><cell></cell><cell cols="2">Iemocap</cell><cell cols="3">Dailydialog</cell></row><row><cell></cell><cell cols="2">train/val test</cell><cell>train</cell><cell>val</cell><cell>test</cell></row><row><cell>hap</cell><cell>504</cell><cell cols="4">144 11182 684 1019</cell></row><row><cell>sad</cell><cell>839</cell><cell>245</cell><cell>969</cell><cell>79</cell><cell>102</cell></row><row><cell>neu</cell><cell>1324</cell><cell cols="4">384 72143 7108 6321</cell></row><row><cell>ang</cell><cell>933</cell><cell>170</cell><cell>827</cell><cell>77</cell><cell>118</cell></row><row><cell>exc</cell><cell>742</cell><cell>299</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>frus</cell><cell>1468</cell><cell>381</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>surp</cell><cell>-</cell><cell>-</cell><cell>1600</cell><cell>107</cell><cell>116</cell></row><row><cell>fear</cell><cell>-</cell><cell>-</cell><cell>146</cell><cell>11</cell><cell>17</cell></row><row><cell>disg</cell><cell>-</cell><cell>-</cell><cell>303</cell><cell>3</cell><cell>47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Category-wise distribution of utter-</figDesc><table /><note>ances. hap: happiness; neu: neutral or no emotion; ang: anger; exc: excitement; frus: frustration; surp: surprise; disg: disgust.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>In the table, Variant 1 is the model with randomly initialized</figDesc><table><row><cell>Variant</cell><cell cols="2">Initial Weight sent enc cxt enc</cell><cell>Model Description</cell></row><row><cell>(1)</cell><cell>-</cell><cell>-</cell><cell>Sentence encoders -randomly initialized.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Variants of the model used in the experiments. Variant (3) is the proposed TL-ERC model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>•</head><label></label><figDesc>DialogueRNN [61] is a strong state-of-the-art baseline which employs three stages of recurrent units comprising global, speaker-state, and emotional units. The global RNN models the conversational context, speaker-state RNN models the individual speaker-states, and emotion RNN models the final emotional representations used for classification. For a fair comparison with our model, we chose the basic version of DialogueRNN without bi-directional RNNs and inter-utterance attention mechanisms.</figDesc><table><row><cell>Variant</cell><cell cols="2">Initial Weights sent enc cxt enc</cell><cell cols="2">10% F-Score</cell><cell>BE</cell><cell cols="3">Dataset: IEMOCAP 25% 50% F-Score BE F-Score</cell><cell>BE</cell><cell cols="2">100% F-Score</cell><cell>BE</cell></row><row><cell>(1)</cell><cell>-</cell><cell>-</cell><cell>23.2 ±0.4</cell><cell></cell><cell>48.4</cell><cell>41.6 ±0.8</cell><cell>72.5</cell><cell>48.4 ±0.3</cell><cell>75.1</cell><cell>53.8 ±0.3</cell><cell>13.8</cell></row><row><cell cols="2">(2) θ BERT</cell><cell>-</cell><cell>32.4 ±1.1</cell><cell></cell><cell>11.0</cell><cell>41.9 ±0.5</cell><cell>8.0</cell><cell>49.2 ±1.0</cell><cell>6.3</cell><cell>55.1 ±0.6</cell><cell>5.0</cell></row><row><cell cols="3">cxt (3) θ BERT θ ubuntu θ cornell cxt</cell><cell>35.7 ±1.1 36.3 ±1.1</cell><cell>†</cell><cell cols="2">14.2 17.0 46.0 ±0.5 45.9 ±2.0  †</cell><cell cols="2">11.2 53.1 ±0.7 11.2 50.9 ±1.5  †</cell><cell cols="2">7.8 58.8 ±0.5 8.2 58.5 ±0.8</cell><cell>†</cell><cell>5.4 5.0</cell></row></table><note>Results on these baselines are provided in Section 5.5.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>IEMOCAP results. Metric: Weighted-Fscore averaged over 10 random runs. BE = Best Epoch. Results span across different amount of available training data. Validation and testing splits are fixed across configurations. † represents significant difference with p &lt; 0.05 over randomly initialized model as per two-tailed Wilcoxon rank sum hypothesis test<ref type="bibr" target="#b79">[80]</ref>.</figDesc><table><row><cell>Variant</cell><cell cols="2">Initial Weights sent enc cxt enc</cell><cell cols="3">Dataset: DailyDialog 10% 100% F-score BE F-score</cell><cell>BE</cell></row><row><cell>(1)</cell><cell>-</cell><cell>-</cell><cell>33.5 ±2.2</cell><cell>12.3</cell><cell>45.3 ±1.9</cell><cell>7.9</cell></row><row><cell cols="2">(2) θ BERT</cell><cell>-</cell><cell>37.5 ±1.8</cell><cell>2.6</cell><cell>47.4 ±1.2</cell><cell>2.4</cell></row><row><cell cols="3">cxt (3) θ BERT θ ubuntu θ cornell cxt</cell><cell>37.7 ±3.1 38.5 ±1.5  †</cell><cell>3.1 3.2</cell><cell>47.1 ±.76 48.0 ±1.8  †</cell><cell>2.4 2.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>DailyDialog</figDesc><table><row><cell>4.4. Training Criteria</cell></row><row><cell>Hyper-parameter search. For each target dataset-model combination, we perform</cell></row><row><cell>grid-search to select the appropriate hyper-parameters. In the search procedure,</cell></row><row><cell>we keep the model architecture constant but vary learning rate (1e-3, 1e-4, and 1e-</cell></row><row><cell>5), optimizer (Adam, RMSprop [78]), batch size (2-40 videos/batch), and dropout</cell></row><row><cell>({0.0, 0.</cell></row></table><note>results. Metric: Weighted-Fscore averaged over 5 random runs. BE = Best Epoch.† represents significant difference with p &lt; 0.05 over random initialized model as per two-tailed Wilcoxon rank sum hypothesis test [80].5}. BERT-parameters contain dropout of 0.1 as in Devlin et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4</head><label>4</label><figDesc>and 5 provide the performance results of ERC on classification datasets IEMOCAP and DailyDialog, respectively. In both the tables, we observe clearVariant    </figDesc><table><row><cell></cell><cell cols="2">Initial Weights</cell><cell></cell><cell></cell><cell cols="4">Dataset: SEMAINE</cell></row><row><cell></cell><cell></cell><cell></cell><cell>DV</cell><cell></cell><cell>DA</cell><cell></cell><cell>DP</cell><cell></cell><cell>DE</cell></row><row><cell></cell><cell cols="2">sent enc cxt enc</cell><cell>r</cell><cell>BE</cell><cell>r</cell><cell>BE</cell><cell>r</cell><cell>BE</cell><cell>r</cell><cell>BE</cell></row><row><cell>(1)</cell><cell>-</cell><cell>-</cell><cell>0.14</cell><cell>4</cell><cell cols="5">0.27 6.2 0.18 12.8 -0.03 287.4</cell></row><row><cell cols="2">(2) θ BERT</cell><cell>-</cell><cell cols="5">0.64 13.8 0.36 7.8 0.33</cell><cell>4.8</cell><cell>-0.03</cell><cell>23</cell></row><row><cell cols="3">cxt (3) θ BERT θ ubuntu θ cornell cxt</cell><cell cols="7">0.66 10.2 0.41 0.65 10.2 0.42 8.8 0.35 3.4 -0.029 22.7 6 0.34 3.8 -0.03 23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>SEMAINE</figDesc><table><row><cell>results. Metric (r): Pearson correlation coefficients averaged over 5 random</cell></row><row><cell>runs. DV = Valence, DA = Activation/Arousal, DP = Power, DE =Anticipation/Expectation.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>±1.1 39.0 ±0.2 24.90 ±3.0 53.1 ±0.7 53.2 ±1.3 ±1.1 34.2 ±0.8 35.7 ±0.5 24.70 ±1.2 50.9 ±1.5 54.3 ±0.8 53.5 ±0.6 55.4 ±1.0</figDesc><table><row><cell>Variant</cell><cell cols="2">Initial Weight sentenc cxtenc</cell><cell>split  *  1</cell><cell>split2</cell><cell>10%</cell><cell>split3</cell><cell cols="2">Dataset: IEMOCAP split4 split  *  1</cell><cell>split2</cell><cell>50%</cell><cell>split3</cell><cell>split4</cell></row><row><cell>(1)</cell><cell>-</cell><cell>-</cell><cell>23.2 ±0.4</cell><cell>31.5 ±0.6</cell><cell cols="2">25.0 ±1.7</cell><cell>8.8 ±1.1</cell><cell>48.4 ±0.3</cell><cell>48.5 ±1.3</cell><cell cols="2">49.1 ±0.9</cell><cell>51.3 ±0.5</cell></row><row><cell cols="2">(2) θ BERT</cell><cell>-</cell><cell>32.4 ±1.1</cell><cell>31.6 ±1.2</cell><cell cols="2">30.5 ±0.8</cell><cell>23.65 ±1.3</cell><cell>49.2 ±1.0</cell><cell>49.0 ±0.7</cell><cell cols="2">48.8 ±0.9</cell><cell>51.4 ±0.6</cell></row><row><cell cols="3">cxt (3) θ BERT θ ubuntu θ cornell cxt</cell><cell>35.7 ±1.1 36.3</cell><cell cols="8">32.0 52.9 ±1.9</cell><cell>54.2 ±0.8</cell></row></table><note>* primary split</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 :</head><label>7</label><figDesc>Table to investigate if split randomness incurs bias in results. Comparisons are</figDesc><table><row><cell cols="4">held between two limited training data scenarios comprising 10% and 50% available training</cell></row><row><cell cols="4">data. For both the cases, 4 independent splits are sampled and compared against. Metric:</cell></row><row><cell cols="3">Weighted-Fscore averaged over 10 random runs.</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Dataset: IEMOCAP</cell></row><row><cell cols="2">Initial Weight</cell><cell>10%</cell><cell>100%</cell></row><row><cell>sent enc</cell><cell>cxt enc</cell><cell>F-score</cell><cell>F-score</cell></row><row><cell>-</cell><cell>-</cell><cell>23.2 ±0.4</cell><cell>53.8 ±0.3</cell></row><row><cell>θ cornell enc</cell><cell>-θ cornell cxt</cell><cell>26.3 ±0.9 27.5 ±1.3</cell><cell>54.9 ±0.3 55.1 ±0.9</cell></row><row><cell>θ ubuntu enc</cell><cell>-θ ubuntu cxt</cell><cell>24.6 ±0.9 23.3 ±0.8</cell><cell>53.2 ±0.5 53.7 ±0.9</cell></row><row><cell></cell><cell>-</cell><cell>32.4 ±1.1</cell><cell>55.1 ±0.6</cell></row><row><cell>θ BERT</cell><cell>θ ubuntu cxt θ cornell cxt</cell><cell>35.7 ±1.1 36.3 ±1.1</cell><cell>58.8 ±0.5 58.5 ±0.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>Table to analyze HRED encoder vs BERT. Metric: Weighted-Fscore averaged over 10 random runs. BE = Best Epoch (average).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 9 :</head><label>9</label><figDesc>Average performance on ERC with pre-trained weights: {θ BERT + θ cornell cxt }. Note: DD here means DailyDialog.</figDesc><table><row><cell></cell><cell>Iemocap</cell><cell></cell><cell cols="2">SEMAINE</cell><cell></cell></row><row><cell></cell><cell></cell><cell>DV</cell><cell>DA</cell><cell>DP</cell><cell>DE</cell></row><row><cell>Models</cell><cell>F-Score</cell><cell>r</cell><cell>r</cell><cell>r</cell><cell>r</cell></row><row><cell>CNN</cell><cell>48.1</cell><cell cols="4">-0.01 0.01 -0.01 0.19</cell></row><row><cell>Memnet</cell><cell>55.1</cell><cell>0.16</cell><cell>0.24</cell><cell>0.23</cell><cell>0.05</cell></row><row><cell>c-LSTM</cell><cell>54.9</cell><cell>0.14</cell><cell>0.23</cell><cell cols="2">0.25 -0.04</cell></row><row><cell>c-LSTM + Att</cell><cell>56.1</cell><cell>0.16</cell><cell>0.25</cell><cell>0.24</cell><cell>0.10</cell></row><row><cell>CMN</cell><cell>56.1</cell><cell>0.23</cell><cell>0.29</cell><cell cols="2">0.26 -0.02</cell></row><row><cell>DialogueRNN</cell><cell>59.8</cell><cell>0.28</cell><cell>0.36</cell><cell cols="2">0.32 0.31</cell></row><row><cell>TL-ERC</cell><cell>58.8</cell><cell cols="4">0.66 0.42 0.35 -0.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Average performance of TL-ERC compared to previous state-of-the-art models.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 11 :</head><label>11</label><figDesc>Average performance on ERC with pre-trained weights: {θ BERT + θ cornell cxt } for VHRED, θ cornell cxt contain additional parameters modeling the latent prior state.</figDesc><table><row><cell>Generative</cell><cell cols="2">IEMOCAP Dailydialog</cell></row><row><cell>Training</cell><cell>F-Score</cell><cell>F-Score</cell></row><row><cell>Source</cell><cell>58.5</cell><cell>48.0</cell></row><row><cell>Source + Target</cell><cell>58.0</cell><cell>47.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 12 :</head><label>12</label><figDesc>Average performance on ERC with pre-trained weights: {θ BERT + θ cornell</figDesc><table /><note>cxt }.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In this paper, context refers to the inter-sentential context in conversations, i.e. the</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Model implementations are adapted from https://github.com/ctr4si/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/huggingface/pytorch-pretrained-BERT</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Evaluation strategy adapted from Semeval 2019 ERC task: www.humanizing-ai.com/ emocontext.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://www.nltk.org/_modules/nltk/stem/wordnet.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research is supported by Singapore Ministry of Education Academic Research Fund Tier 1 under MOE's official grant number T1 251RES1820. We also gratefully acknowledge the support of NVIDIA Corporation with the donation of a Titan Xp GPU used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Emotion recognition in conversation: Research challenges, datasets, and recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2019.2929050</idno>
		<idno>doi:10.1109/ACCESS.2019.2929050</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2019.2929050" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="100943" to="100953" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on dialogue systems: Recent advances and new frontiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3166054.3166058</idno>
		<idno>doi:10.1145/ 3166054.3166058</idno>
		<ptr target="https://doi.org/10.1145/3166054.3166058" />
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Conversational memory network for emotion recognition in dyadic dialogue videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N18-1193/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2009.191</idno>
		<idno>doi:10.1109/TKDE.2009.191</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2009.191" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating natural language under pragmatic constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pragmatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="689" to="719" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Emotions in dialogue, Dialoganalyse VI/1: Referate der 6. Arbeitstagung, Prag</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Weigand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The handbook of conversation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sidnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stivers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">121</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Changing emotion dynamics: individual differences in the effect of anticipatory social stress on emotional inertia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuppens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">256</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mirroring facial expressions and emotions in dyadic conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Navarretta</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2016/summaries/258.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC 2016</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation LREC 2016<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pretraining sentiment classifiers with unlabeled dialog data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kobayashi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2121</idno>
		<ptr target="https://www.aclweb.org/anthology/P18-2121/.doi:10.18653/v1/P18-2121" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>I. Gurevych, Y. Miyao</editor>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="764" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics</title>
		<meeting>the 2nd Workshop on Cognitive Modeling and Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="76" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1423/" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A framework for learning predictive structures from multiple tasks and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v6/ando05a.html" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1817" to="1853" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transfer learning in natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-5004/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-02" />
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors" />
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>R. Garnett</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-09" />
			<biblScope unit="page" from="6294" to="6305" />
		</imprint>
	</monogr>
	<note>Learned in translation: Contextualized word vectors</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N18-1202/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<editor>M. A. Walker, H. Ji, A. Stent</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12-07" />
			<biblScope unit="page" from="3079" to="3087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<ptr target="http://arxiv.org/abs/1906.08237" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1031</idno>
		<ptr target="https://www.aclweb.org/anthology/P18-1031/.doi:10.18653/v1/P18-1031" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>I. Gurevych, Y. Miyao</editor>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A robustly optimized BERT pretraining approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberta</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<ptr target="http://arxiv.org/abs/1907.11692" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.05309</idno>
		<title level="m">Transfer learning for sequence labeling using source model and target data</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Transfer learning for context-aware question matching in information-seeking conversations in e-commerce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="208" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Pre-trained natural language understanding for task-oriented dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tod-Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06871</idno>
		<ptr target="https://arxiv.org/abs/2004.06871" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Convert: Efficient and accurate conversational representations from transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vulic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03688</idno>
		<ptr target="http://arxiv.org/abs/1911.03688" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ALBERT: A lite BERT for self-supervised learning of language representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1eA7AEtvS" />
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sentence-Bert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1410.doi:10.18653/v1/D19-1410" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<editor>K. Inui, J. Jiang, V. Ng, X. Wan</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="3980" to="3990" />
		</imprint>
	</monogr>
	<note>Sentence embeddings using siamese bert-networks</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dialogpt: Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00536</idno>
		<ptr target="http://arxiv.org/abs/1911.00536" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Computational intelligence for affective computing and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCI.2019.2901082</idno>
		<idno>doi:10.1109/MCI.2019.2901082</idno>
		<ptr target="https://doi.org/10.1109/MCI.2019.2901082" />
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="16" to="17" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>guest editorial</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A survey of emotion recognition methods with emphasis on e-learning environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Imani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Montazer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jnca.2019.102423</idno>
		<idno>doi:10.1016/j. jnca.2019.102423</idno>
		<ptr target="https://doi.org/10.1016/j.jnca.2019.102423" />
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Using context to improve emotion detection in spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liscombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<ptr target="http://www.isca-speech.org/archive/interspeech_2005/i05_1845.html" />
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2005 -Eurospeech, 9th European Conference on Speech Communication and Technology</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1845" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Artificial Intelligence: An International Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Schiaffino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Amandi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-03226-4_11</idno>
		<idno>doi:10.1007/ 978-3-642-03226-4\_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-03226-4_11" />
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>M. Bramer</editor>
		<imprint>
			<biblScope unit="volume">5640</biblScope>
			<biblScope unit="page" from="193" to="216" />
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Intelligent user profiling</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Deep facial expression recognition: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.08348</idno>
		<ptr target="http://arxiv.org/abs/1804.08348" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Intelligent facial emotion recognition based on stationary wavelet entropy and jaya algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2017.08.015</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2017.08.015.doi:10.1016/j.neucom.2017.08.015" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">272</biblScope>
			<biblScope unit="page" from="668" to="676" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Emotion recognition from speech: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Drakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pikramenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Spyrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Perantonis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Web Information Systems and Technologies, WEBIST 2019</title>
		<editor>A. Bozzon, F. J. D. Mayo, J. Filipe</editor>
		<meeting>the 15th International Conference on Web Information Systems and Technologies, WEBIST 2019<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>ScitePress</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="432" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Features and classifiers for emotion recognition from speech: a survey from</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Anagnostopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Iliou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Giannoukos</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10462-012-9368-5</idno>
		<idno>doi:10.1007/s10462-012-9368-5</idno>
		<ptr target="https://doi.org/10.1007/s10462-012-9368-5" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Rev</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="155" to="177" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">High-Performance Modelling and Simulation for Big Data Applications -Selected Results of the COST Action IC1406 cHiPSet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Maréchal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mikolajewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tyburek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prokopowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bougueroua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ancourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wegrzyn-Wolska</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-16272-6_11</idno>
		<idno>doi:10.1007/ 978-3-030-16272-6\_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-16272-6_11" />
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>J. Kolodziej, H. González-Vélez</editor>
		<imprint>
			<biblScope unit="volume">11400</biblScope>
			<biblScope unit="page" from="307" to="324" />
			<date type="published" when="2019" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Survey on ai-based multimodal methods for emotion detection</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Emotions from text: Machine learning for text-based emotion prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">O</forename><surname>Alm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sproat</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/H05-1073/" />
	</analytic>
	<monogr>
		<title level="m">HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference</title>
		<meeting><address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10-08" />
			<biblScope unit="page" from="579" to="586" />
		</imprint>
	</monogr>
	<note>The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to identify emotions in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="DOI">10.1145/1363686.1364052</idno>
		<idno>doi:10.1145/1363686.1364052</idno>
		<ptr target="https://doi.org/10.1145/1363686.1364052" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM Symposium on Applied Computing (SAC)</title>
		<editor>R. L. Wainwright, H. Haddad</editor>
		<meeting>the 2008 ACM Symposium on Applied Computing (SAC)<address><addrLine>Fortaleza, Ceara, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1556" to="1560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Wordnet affect: an affective extension of wordnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Valitutti</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2004/summaries/369.htm" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2004-05-26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; N</forename><surname>Calzolari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gangemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mariani</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2006/summaries/384.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation</title>
		<editor>J. Odijk, D. Tapias</editor>
		<meeting>the Fifth International Conference on Language Resources and Evaluation<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05-22" />
			<biblScope unit="page" from="417" to="422" />
		</imprint>
	</monogr>
	<note>SENTIWORDNET: A publicly available lexical resource for opinion mining</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Harnessing twitter &quot;big data&quot; for automatic emotion identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thirunarayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Sheth</surname></persName>
		</author>
		<idno type="DOI">10.1109/SocialCom-PASSAT.2012.119</idno>
		<ptr target="https://doi.org/10.1109/SocialCom-PASSAT.2012.119.doi:10.1109/SocialCom-PASSAT.2012.119" />
	</analytic>
	<monogr>
		<title level="m">2012 International Conference on Privacy, Security, Risk and Trust, PASSAT 2012, and 2012 International Confernece on Social Computing</title>
		<meeting><address><addrLine>SocialCom; Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012-09-03" />
			<biblScope unit="page" from="587" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Convolutional attention networks for multimodal emotion recognition from speech and text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-3304</idno>
		<ptr target="https://www.aclweb.org/anthology/W18-3304.doi:10.18653/v1/W18-3304" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML)</title>
		<meeting>Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML)<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Emotion recognition from speech with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chernykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prihodko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08071</idno>
		<ptr target="http://arxiv.org/abs/1701.08071" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic speech emotion recognition using recurrent neural networks with local attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mirsamadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Barsoum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2017.7952552</idno>
		<idno>doi:10.1109/ICASSP.2017.7952552</idno>
		<ptr target="https://doi.org/10.1109/ICASSP.2017.7952552" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017-03-05" />
			<biblScope unit="page" from="2227" to="2231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An evolutionary strategy for concept-based multi-domain sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dragoni</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCI.2019.2901083</idno>
		<idno>doi:10.1109/MCI.2019.2901083</idno>
		<ptr target="https://doi.org/10.1109/MCI.2019.2901083" />
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="18" to="27" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adversarial training in affective computing and sentiment analysis: Recent advances and perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCI.2019.2901088</idno>
		<idno>doi:10.1109/MCI.2019.2901088</idno>
		<ptr target="https://doi.org/10.1109/MCI.2019.2901088" />
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="68" to="81" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>review article</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Improving multilabel emotion classification via sentiment classification with dual attention transfer network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Karuturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1137/" />
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1097" to="1102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Epita at semeval-2018 task 1: Sentiment analysis using transfer learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Daval-Frerot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bouchekif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moreau</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/S18-1021/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th International Workshop on Semantic Evaluation</title>
		<meeting>The 12th International Workshop on Semantic Evaluation<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-05" />
			<biblScope unit="page" from="151" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Epita-adapt at semeval-2019 task 3: Detecting emotions in textual conversations using deep learning models combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bouchekif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bouchekif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Afli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="215" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Deep learning for emotion recognition on small datasets using transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vonikakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
		<idno type="DOI">10.1145/2818346.2830593</idno>
		<ptr target="http://doi.acm.org/10.1145/2818346.2830593.doi:10.1145/2818346.2830593" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM on International Conference on Multimodal Interaction</title>
		<editor>Z. Zhang, P. Cohen, D. Bohus, R. Horaud, H. Meng</editor>
		<meeting>the 2015 ACM on International Conference on Multimodal Interaction<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="443" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Sparse autoencoder-based feature transfer learning for speech emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACII.2013.90</idno>
		<ptr target="https://doi.org/10.1109/ACII.2013.90.doi:10.1109/ACII.2013.90" />
	</analytic>
	<monogr>
		<title level="m">Humaine Association Conference on Affective Computing and Intelligent Interaction, ACII 2013</title>
		<meeting><address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2013-09-02" />
			<biblScope unit="page" from="511" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Felbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lehmann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d17-1169</idno>
		<ptr target="https://doi.org/10.18653/v1/d17-1169.doi:10.18653/v1/d17-1169" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>M. Palmer, R. Hwa, S. Riedel</editor>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="1615" to="1625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Coastal at semeval-2019 task 3: Affect classification in dialogue using attentive bilstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>González-Garduño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P B</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Søgaard</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/S19-2026/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019, Minneapolis</title>
		<meeting>the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019, Minneapolis<address><addrLine>MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Higru: Hierarchical gated recurrent units for utterance-level emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1037/" />
		<imprint>
			<biblScope unit="page" from="397" to="406" />
		</imprint>
	</monogr>
	<note>in: [90], 2019</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">ICON: interactive conversational memory network for multimodal emotion detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1280/" />
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2594" to="2604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.11540</idno>
		<ptr target="http://arxiv.org/abs/1908.11540" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Modeling both contextand speaker-sensitive dependence for emotion detection in multi-speaker conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/752</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/752.doi:10.24963/ijcai.2019/752" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5415" to="5421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Quantum-inspired interactive networks for conversational sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/755</idno>
		<idno>doi:10.24963/ ijcai.2019/755</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/755" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5436" to="5442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Dialoguernn: An attentive RNN for emotion detection in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/4657" />
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019-02-01" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="6818" to="6825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Knowledge-enriched transformer for emotion detection in textual conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.10681</idno>
		<ptr target="http://arxiv.org/abs/1909.10681" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 3: Emocontext contextual emotion detection in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Narahari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/s19-2005</idno>
		<ptr target="https://doi.org/10.18653/v1/s19-2005.doi:10.18653/v1/s19-2005" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019</title>
		<editor>J. May, E. Shutova, A. Herbelot, X. Zhu, M. Apidianaki, S. M. Mohammad</editor>
		<meeting>the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Emotionx-idea: Emotion BERT -an affectional model for conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.06264</idno>
		<ptr target="http://arxiv.org/abs/1908.06264" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Pt-code: Pre-trained context-dependent encoder for utterance-level emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.08916</idno>
		<ptr target="http://arxiv.org/abs/1910.08916" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<ptr target="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11957" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<editor>D. Schuurmans, M. P. Wellman</editor>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoderdecoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Context-dependent sentiment analysis in user-generated videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morency</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1081</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-1081.doi:10.18653/v1/P17-1081" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="873" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A hierarchical latent structure for variational conversation modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1792" to="1801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Iemocap: Interactive emotional dyadic motion capture database, Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">335</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Dailydialog: A manually labelled multi-turn dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">AVEC 2012: the continuous audio/visual emotion challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Valstar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<idno type="DOI">10.1145/2388676.2388776</idno>
		<ptr target="https://doi.org/10.1145/2388676.2388776.doi:10.1145/2388676.2388776" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimodal Interaction, ICMI &apos;12</title>
		<editor>L. Morency, D. Bohus, H. K. Aghajan, J. Cassell, A. Nijholt, J. Epps</editor>
		<meeting><address><addrLine>Santa Monica, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="449" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/d14-1181</idno>
		<ptr target="https://doi.org/10.3115/v1/d14-1181.doi:10.3115/v1/d14-1181" />
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>A. Moschitti, B. Pang, W. Daelemans</editor>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL, ACL</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5846-end-to-end-memory-networks" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems</title>
		<editor>C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, R. Garnett</editor>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12-07" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="https://doi.org/10.1162/neco.1997.9.8.1735.doi:10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Multi-level multiple attentions for contextual multimodal sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morency</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2017.134</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2017.134.doi:10.1109/ICDM.2017.134" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Data Mining</title>
		<editor>V. Raghavan, S. Aluru, G. Karypis, L. Miele, X. Wu</editor>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-11-18" />
			<biblScope unit="page" from="1033" to="1038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Lecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COURSERA: Neural Networks for Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<editor>Y. Bengio, Y. LeCun</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The mann-whitney u: A test for assessing whether two independent samples come from the same distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nachar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tutorials in quantitative Methods for Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="13" to="20" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2124</idno>
		<ptr target="https://www.aclweb.org/anthology/P18-2124/.doi:10.18653/v1/P18-2124" />
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>I. Gurevych, Y. Miyao</editor>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
	<note>Know what you don&apos;t know: Unanswerable questions for squad</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N18-1101" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Crowdsourcing a word-emotion association lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8640.2012.00460.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-8640.2012.00460.x.doi:10.1111/j.1467-8640.2012.00460.x" />
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">To tune or not to tune? adapting pretrained representations to diverse tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith ; I. Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Can</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W19-4302/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Representation Learning for NLP</title>
		<editor>Ren, M. Rei</editor>
		<meeting>the 4th Workshop on Representation Learning for NLP<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-02" />
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14567" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3295" to="3301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A framework for automatic human emotion classification using emotion profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mataric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TASL.2010.2076804</idno>
		<idno>doi:10.1109/TASL.2010.2076804</idno>
		<ptr target="https://doi.org/10.1109/TASL.2010.2076804" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio, Speech &amp; Language Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1057" to="1070" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1014</idno>
		<ptr target="https://www.aclweb.org/anthology/N16-1014.doi:10.18653/v1/N16-1014" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">An ensemble of retrieval-based and generation-based human-computer conversation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2018/609</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2018/609.doi:10.24963/ijcai.2018/609" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018<address><addrLine>Stockholm, Sweden.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4382" to="4388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16455" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="730" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
				<ptr target="https://www.aclweb.org/anthology/volumes/N19-1/" />
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>J. Burstein, C. Doran, T. Solorio</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/volumes/D18-1/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Hockenmaier, J. Tsujii</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019.doi:10.24963/ijcai.2019" />
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
