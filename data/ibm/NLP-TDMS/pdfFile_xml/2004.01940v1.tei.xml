<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pre-Trained and Attention-Based Neural Networks for Building Noetic Task-Oriented Dialogue Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Chen</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianda</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">ECE &amp; Ingenuity Labs</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
							<email>quanliu@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
							<email>xiaodan.zhu@queensu.ca</email>
							<affiliation key="aff1">
								<orgName type="laboratory">ECE &amp; Ingenuity Labs</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
							<email>zhling@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ping</forename><surname>Ruan</surname></persName>
							<email>ypruan@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pre-Trained and Attention-Based Neural Networks for Building Noetic Task-Oriented Dialogue Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The NOESIS II challenge, as the Track 2 of the 8th Dialogue System Technology Challenges (DSTC 8), is the extension of DSTC 7. This track incorporates new elements that are vital for the creation of a deployed task-oriented dialogue system. This paper describes our systems that are evaluated on all subtasks under this challenge. We study the problem of employing pre-trained attention-based network for multi-turn dialogue systems. Meanwhile, several adaptation methods are proposed to adapt the pre-trained language models for multiturn dialogue systems, in order to keep the intrinsic property of dialogue systems. In the released evaluation results of Track 2 of DSTC 8, our proposed models ranked fourth in subtask 1, third in subtask 2, and first in subtask 3 and subtask 4 respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Building on the success of Track 1 of the 7th Dialogue System Technology Challenges (DSTC 7) (NOESIS: Noetic End-to-End Response Selection Challenge) <ref type="bibr" target="#b9">(Gunasekara et al. 2019)</ref>, an extension as Track 2 of DSTC 8 (NOESIS II: Predicting Responses, Identifying Success, and Managing Complexity in Task-Oriented Dialogue) is proposed <ref type="bibr" target="#b9">(Kim et al. 2019)</ref>, which incorporates new elements that are vital for the creation of a deployed task-oriented dialogue system. Specifically, three new dimensions are added to the challenge: (1) conversations with more than 2 participants, (2) predicting whether a dialogue has solved the problem yet, and (3) handling multiple simultaneous conversations. Each of these adds an exciting new dimension and brings the task closer to the creation of systems able to handle the complexity of real-world conversation.</p><p>Enabling dialogue systems to converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. Recently, human-computer conversation has attracted increasing attention due to its promising potentials and alluring commercial values. Dialogue systems aim to engage users in human-computer conversations in the open domain. The existing approaches to dialogue systems includes generation-based methods <ref type="bibr" target="#b18">(Shang, Lu, and Li 2015;</ref><ref type="bibr" target="#b17">Serban et al. 2016</ref>) and retrieval-based methods <ref type="bibr" target="#b9">(Lowe et al. 2015;</ref><ref type="bibr" target="#b9">Lowe et al. 2017;</ref><ref type="bibr" target="#b23">Wu et al. 2017;</ref><ref type="bibr" target="#b25">Zhang et al. 2018)</ref>. Generation-based models maximize the probability of generating a response given the previous dialogue. This approach enables the incorporation of rich context when mapping between consecutive dialogue turns. Retrievalbased methods select a proper response for the current conversation from a repository with response selection algorithms, and have the advantage of producing informative and fluent responses.</p><p>Pre-trained language models are also a very popular topic in the domain of natural language processing <ref type="bibr" target="#b14">(Peters et al. 2018;</ref><ref type="bibr" target="#b1">Devlin et al. 2019;</ref><ref type="bibr" target="#b24">Yang et al. 2019)</ref>. It captures rich language information from texts and shows great performance on many downstream tasks, such as natural language inference (NLI) <ref type="bibr" target="#b0">(Bowman et al. 2015)</ref> and question answering (QA) <ref type="bibr" target="#b15">(Rajpurkar et al. 2016)</ref>. Typically, the premise in NLI or question in QA is considered as the sentence A, and the hypothesis in NLI or answer in QA is considered as the sentence B. A long sequence is formed by concatenating the two sentences with a segmentation token, and then is sent into the model for classification.</p><p>In this paper, we describe our systems that are evaluated on all subtasks of Track 2 of DSTC 8. Pre-trained language models are employed to establish pre-trained attentionbased models for multi-turn dialogue systems. Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" target="#b1">(Devlin et al. 2019)</ref>, as one of the most recently developed models, is adopted as the basic of our work. Furthermore, to make pre-trained language models more suitable for dialogue systems, several adaptation methods are proposed to keep its intrinsic property.</p><p>As shown in the released evaluation results, our proposed models ranked fourth in subtask 1, third in subtask 2, and first in subtask 3 and subtask 4 respectively. In the following sections, we first introduce the related work on dialogues, task descriptions of Track 2 in DSTC 8, and present the details of our proposed model. Then the experimental settings and evaluation results are shown. Furthermore, experimental results are analyzed by ablation tests. Finally we draw arXiv:2004.01940v1 [cs.CL] 4 Apr 2020 conclusions and give an overview of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>The existing methods used to build an open domain dialogue system can be generally categorized into generation-based methods and retrieval-based methods. The generation-based models synthesize a response with a natural language generation model by maximizing its generation probability given the previous conversation context. This approach enables the incorporation of rich context when mapping between consecutive dialogue turns <ref type="bibr" target="#b18">(Shang, Lu, and Li 2015;</ref><ref type="bibr" target="#b17">Serban et al. 2016</ref>).</p><p>The first two subtasks of Track 2 belong to the retrievalbased task, which learn a matching model for a pair of a conversational context and a response candidate. This approach has the advantage of providing informative and fluent responses because they select a proper response for the current conversation from a repository by means of response selection algorithms <ref type="bibr" target="#b9">(Lowe et al. 2015;</ref><ref type="bibr" target="#b9">Lowe et al. 2017;</ref><ref type="bibr" target="#b23">Wu et al. 2017;</ref><ref type="bibr" target="#b25">Zhang et al. 2018;</ref><ref type="bibr" target="#b4">Gu, Ling, and Liu 2019b)</ref>. Previous work on retrieval-based chatbots focused on single-turn response selection <ref type="bibr" target="#b23">(Wang et al. 2013;</ref><ref type="bibr" target="#b6">Ji, Lu, and Li 2014)</ref>. Recently, researchers have extended the focus to the multi-turn conversation, which is more practical for real applications. Some earlier work on multi-turn response selection matched a response with concatenating the context utterances literally into a single long sequence, and calculating its matching score with a response candidate <ref type="bibr" target="#b9">(Lowe et al. 2015;</ref><ref type="bibr" target="#b9">Lowe et al. 2017)</ref>. Recent work has kept utterances separate and performed matching within a representation-interaction-aggregation framework, which improved the performance on this task. For example, <ref type="bibr" target="#b23">(Wu et al. 2017)</ref> proposed the sequential matching network (SMN) which first matched the response with each utterance and then accumulated the matching information by recurrent neural network (RNN). <ref type="bibr" target="#b25">(Zhang et al. 2018)</ref> proposed the deep utterance aggregation network (DUA) which refined utterances and employed self-matching attention to route the vital information in each utterance. <ref type="bibr" target="#b26">(Zhou et al. 2018</ref>) proposed the deep attention matching network (DAM) which constructed representations at different granularities with stacked self-attention and cross-attention. <ref type="bibr" target="#b20">(Tao et al. 2019a)</ref> proposed the multi-representation fusion network (MRFN) with multiple types of representations. <ref type="bibr" target="#b3">(Gu, Ling, and Liu 2019a)</ref> proposed the interactive matching network (IMN) which performed the global and bidirectional interactions between the context and response. <ref type="bibr" target="#b21">(Tao et al. 2019b</ref>) proposed the interaction over interaction (IOI) model which performed matching by stacking multiple interaction blocks.  proposed the dually interactive matching network (DIM), which adopted a dual matching architecture by performing the interactive matching between responses and contexts and between responses and personas respectively for ranking response candidates.</p><p>The fourth subtasks of Track 2 can be categorized as disentangle problem. Simultaneous conversation occurs not only in informal social interactions but also in multi-party involved chat in our daily life. Aiming to separate intermingled messages to detached conversations, disentanglement is of vital importance for understanding conversation. The research for conversation disentanglement could date back to <ref type="bibr" target="#b0">(Aoki et al. 2006)</ref> which conducted a study of voice conversations among 8-10 people with an average of 1.76 conversations active at a time. Then followed by more research not only propose datasets <ref type="bibr" target="#b10">(Mehri and Carenini 2017;</ref><ref type="bibr" target="#b16">Riou, Salim, and Hernandez 2015;</ref>) but also models <ref type="bibr" target="#b10">(Mehri and Carenini 2017;</ref><ref type="bibr" target="#b7">Jiang et al. 2018)</ref>.</p><p>However, these models mentioned above were all RNNbased, CNN-based or Transformer-based models without employing any pre-trained language models. This paper makes the attempt to employ the pre-trained language model for multi-turn dialogues, and propose new approach for it to keep the intrinsic property of multi-turn dialogue systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Description</head><p>The Track 2 of DSTC 8 focuses on task-oriented multiturn dialogues. It is divided into four different subtasks and explores three dialogue challenges: next utterance selection, task success, and conversation disentanglement. Two datasets are provided, i.e., Ubuntu and Advising, which will be introduced in detail in the experiment section. The series of subtasks has similar structures, but varies in the output space and available context. Detailed descriptions of each subtask are shown in <ref type="table" target="#tab_0">Table 1</ref>. "indicates that the task is evaluated on the marked dataset, and %indicates not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>We present here our proposed methods and the detailed implementation. Due to limit space, we omit an exhaustive background description of the model architecture of BERT and its basic block Transformer. Readers can refer to <ref type="bibr" target="#b1">(Devlin et al. 2019)</ref> and <ref type="bibr" target="#b22">(Vaswani et al. 2017</ref>) for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtask 1</head><p>Input Representation To represent a pair of sentence A and sentence B, the original BERT concatenates this pair of sentence with a [SEP] token. For a given token, its input representation of the original BERT is constructed by summing the corresponding token, segment and position embeddings.</p><p>When constructing the sentence A for multi-turn response selection, in order to distinguish the utterances in a context and to model the speaker exchange in turn as the conversation progresses, we use two methods as follows.</p><p>• Segmentation tokens. Empirical results in <ref type="bibr" target="#b2">(Dong and Huang 2018)</ref> show that segmentation tokens play an important role for multi-turn response selection. Motivated by it, a [EOU] token is added at the end of an utterance and a [EOT] token is added at the end of a turn. These tokens can help to model the interactions between utterances in the context implicitly, without using extra complicated networks. • Switch embeddings. In order to model the speaker exchange during the conversation directly, we add additional</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtask Description</head><p>Ubuntu Advising 1 A conversational context and 100 utterances that could be the next message (either 99 or 100 will be incorrect).</p><p>" " 2 A conversational context contains multiple entangled conversations (either 99 or 100 will be incorrect).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>" %</head><p>3 Participants predict where in a dialogue the problem is solved (if at all).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>% "</head><p>4 Given a section of the chat logs, one needs to identify a set of conversations contained within that coherent section. " %  switch embeddings to the corresponding token. These embeddings function as a switch to change the speaker in turn as the conversation progresses. Furthermore, we propose an assumption that conversations are conducted between two speakers, i.e., only two switch embedding vectors are required to be estimated during the training process. In this assumption, the first vector is added to the utterances of the first conversation turn. When the speaker changes, the second vector is added to the utterances of the second conversation turn. Then, the first one is employed again when it comes to the third conversation turn, and so on. An illustration of how switch embeddings work is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The switch embeddings are expected to model the speaker exchange during the conversation directly to keep the intrinsic property of dialogue systems.</p><p>Finally, a visual architecture of our input representation is illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>Output Representation Similar to the original BERT, the first token of each sequence which is the concatenation of a context-response pair is the [CLS] token, whose embedding is used as the aggregated representation for classifying a context-response pair. This embedding captures the matching information between a context-response pair, denoted as c ∈ R H . Then, this embedding is sent into a classifier with a sigmoid output layer as follows:</p><formula xml:id="formula_0">s = sigmoid(c · W + b),<label>(1)</label></formula><p>where W ∈ R 1×H and b ∈ R need to be estimated during the fine-tuning process.</p><p>Finally, the classifier returns a score s to denote the matching degree of a context-response pair.</p><p>Dynamic Negative Sampling When constructing the training set, the positive and negative responses are sampled in a ratio of 1:1. For those examples without positive response, the positive one is neglected. When sampling the negative responses, we select different negative samples at different epochs. Thus, given a context, we fix the positive response and select different negative responses at different epochs so that the model could have a strong ability to distinguish the positive from the negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training Tasks</head><p>The original BERT is trained on a large text corpus to learn general language representations. To incorporate some specific in-domain knowledge into language representation models, some pre-training tasks are designed. Here, the masked language model (MLM) and the next sentence prediction (NSP) <ref type="bibr" target="#b1">(Devlin et al. 2019</ref>) are employed. In addition to the provided dataset for the specific subtask, DSTC 8 provides external files, which contain the source data of both Ubuntu and Advising domains. We use the provided external data to pre-train our BERT model, in order to further improve the performance of our model.</p><p>• MLM. We follow the experimental settings in the original BERT by masking some percentage of the input tokens at random and then predicting only those masked tokens to train a deep bidirectional representation. In more detail, we replace the word with the [MASK] token at 80% of the time, with a random word at 10% of the time, and with the original word at 10% of the time.</p><p>• NSP. If there is no pre-training process, the switch embeddings have to be initialized at random at the beginning of the fine-tuning process. To achieve a better performance, the switch embeddings can be pre-trained with the help of NSP. Here, the sentence A and sentence B are constructed with the same method as we mentioned above.  <ref type="table" target="#tab_0">EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EB  EB  EB  EB  EB   E0  E1  E2  E3  E4  E5  E18  E19  E6  E7  E8  E9  E10  E11  E17  E12  E13  E14  E15  E16  E20  E21  E22  E23  E24  E25</ref> [  </p><formula xml:id="formula_1">+ + + + + E0 E0 E0 E0 E0 E0 E0 E0 E1 E1 E1 E1 E1 E1 E0 E1 E1 E1 E1 E1 E0 E1 E1<label>E1</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtask 2</head><p>Subtask 2 is similar to subtask 1 but need additional disentangle strategy. When a group of people communicate in a common channel there are often multiple conversation topics occurring concurrently. In terms of a specific conversation topic, utterances relevant to it are useful and other utterances could be considered as noise for them. Meanwhile, BERT is not good at dealing with sequences which are composed of thousands of tokens as the maximum length of position embeddings is set to 512. In order to select a small number of most important utterances, a disentanglement strategy is necessary.</p><p>In this paper, we propose a heuristic speaker-aware strategy to select utterances according to the utterance speakers as follows:</p><p>• First, we define the speaker who is uttering an utterance as the spoken-from speaker, and define the speaker who is receiving an utterance as the spoken-to speaker. Each utterance usually has both the spoken-from and spoken-to speakers. But some utterances may have only the spokenfrom speaker and the spoken-to speaker is unknown and considered as None.</p><p>• Second, given the speaker of the response, we select the utterances which have the same spoken-from or spoken-to speaker as that of the response.</p><p>• Third, these selected utterances are then organized in their original chronological order and used to form the context.</p><p>• Finally, utterances with the spoken-from or spoken-to speaker correspond to the two types of switch embedding respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtask 3</head><p>Subtask 3 is different from the first 2 subtasks, which aims to predict whether and where a dialogue has solved the problem. In more detail, the dialogue is conducted between a advisor and a student, in order to help the student select appropriate courses. One of Accept, Reject or No Decision Yet, should be made for each utterance. We formalize this problem as a combination of sequence labeling and natural language inference. Each utterance is considered as a unit when performing sequence labeling.</p><p>Furthermore, a three-class classification of Accept (Entailment), Reject (Contradiction) and No Decision Yet (Neutral) is performed for each unit. A hierarchical RNN-based model is adopted rather than the pre-trained language model because the former shows a better performance on this task.</p><p>First, each utterance is encoded by a BiLSTM (Hochreiter and Schmidhuber 1997) separately at the utterance-level. A pooling operation with a combination of max pooling and last-hidden-state pooling is performed to obtain a sequence of utterance embeddings. Then, to incorporate the context information, another context-level BiLSTM is employed by considering each utterance as a unit and organizing them in their original chronological order. Finally, the outputs of the context-level BiLSTM at each time step are used as the inputs of a multi-layer perceptron (MLP) classifier for classification.</p><p>There are several challenges to this task. One is the sparsity of labels because most of utterances belong to the class of No Decision Yet. To address this problem, we design a weighted loss function that pay larger weights to the Accept or Reject, which enforces the model to pay more attention to utterances with Accept or Reject labels. Another challenge is the lack of training examples because the training set is small which is composed of only 500 examples. We augment the training set by generating some paraphrase examples with the set provided by the track organizer, so that the model could see more different contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtask 4</head><p>Subtask 4 is another disentanglement task that we need to identify several sets of conversations occurring in the same section of IRC channel. Specifically, every section contains more than 1000 messages including directed messages posted by users and information messages. It contains more than 500 links, and each link indicates that the two linked messages are in the same conversation in time order.</p><p>In this paper, we propose a model based on BERT whose overview is shown in <ref type="figure">Figure 3</ref>. To detect whether every two messages belong to the same conversation, we should make each message aware of its context. We name a message target message, and name its previous messages context messages. Here, we heuristically consider only the nearest K context messages of each target message, resulting in a balance between the performance and computation.</p><p>First, each input sequence is constructed by concatenating the target message with its context messages and itself as well. It is noticeable that concatenating the target message with itself is designed in case that the target message is not in a conversation with any context messages 1 . These input sequences are first encoded by the pre-trained BERT model to obtain the sequence embeddings represented by the [CLS] token. Then, a single-layer BiLSTM is employed on top of the output of BERT in order to capture the semantics across different messages. We denote the outputs of the BiLSTM as m t ∈ R H for concatenation of the target message with itself, and M c ∈ R K×H for concatenation of the target message with its context messages, where K denotes the nearest K context messages of each target message, and H denotes the dimension of outputs of BERT.</p><p>Furthermore, in order to model the high-order interactions between the target message and its context messages, we compute the differences and element-wise products between them. We duplicate the target message to obtain M t ∈ R K×H and concatenate them as follows:</p><formula xml:id="formula_2">M = [M t , M c , M t M c , M t − M c ],<label>(2)</label></formula><formula xml:id="formula_3">prediction = Tanh(M · W + b),<label>(3)</label></formula><p>where W ∈ R H and b ∈ R are parameters estimated during the training process. prediction ∈ R K denotes the similarity scores calculated between the target message and its context messages. Here, we select the one obtaining the highest score with the target message, indicating which context message or none of them is in the same conversation with the target massage. Finally, three ensemble strategies are employed to further improve the performance as follows.</p><p>• Model-AVG. The final ensemble model is initialized by averaging the weights of several single models with identical architectures and different random initializations.</p><p>• Probability-AVG. Similarly, prediction probabilities for each sample are averaged across different models.</p><p>• Vote-AVG. We employ several models to make vote predictions. The context message which is voted most is considered as our final prediction in the same conversation with the target message.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Datasets</head><p>We tested our model on all subtasks of Track 2. Two datasets were provided under this challenge, one on the Ubuntu IRC help channel, and the other on the course recommendation between the advisor and student. Some statistics of these datasets were shown in <ref type="table" target="#tab_4">Table 2</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>For subtask 1 and subtask 2, each model was tasked with selecting the k best-matched responses from n available candidates for the given conversation context, and we calculated the recall of the true positive replies among the k selected responses, denoted as Recall@k, as the main evaluation metric. In addition to Recall@k, we considered the mean reciprocal rank (MRR). Finally, the average of Recall@10 and MRR was considered as the final metric. For subtask 3, the accuracy of whole dialogue prediction was considered as the main metric. In addition, precision, recall and F-1 value were also evaluated for reference.</p><p>For subtask 4, five clustering metrics were adopted for evaluation: Scaled Variation of information (VI), adjusted rand index (ARI), F 1 score (F1), recall and precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Details</head><p>For subtask 1, the large version of BERT was employed. The Adam method (Kingma and Ba 2014) was employed for optimization. The initial learning rate was set to 1e-5 and was linearly decayed by L2 weight decay. gelu activation (Hendrycks and Gimpel 2016) was employed. The maximum sequence length of the concatenation of a context-response pair was set to 320. The training batch size was set to 32. The maximum number of training epochs was set to 30. The dropout <ref type="bibr" target="#b19">(Srivastava et al. 2014</ref>) probability of 0.1 is applied on all layers. The candidate pool may not contain the correct response, so we need to choose a threshold. When the probability of positive labels was smaller than the threshold, we predicted that candidate pool did not contain the correct response. The threshold was selected from the range [0.6, 0.65, .., 0.95] based on the validation set and was set to 0.95 finally. We used the validation set to set the stop condition to select the best model for testing.</p><p>For subtask 2, the base version of BERT was employed because the large version could not provide further improvement. The initial learning rate was set to 2e-5. The maximum sequence length of the concatenation of a context-response pair was set to 512. The training batch size was set to 25. The maximum number of training epochs was set to 8. The threshold to decide whether the candidate pool contains the correct response was set to 0.95.</p><p>For subtask 3, the word representations were 300dimensional GloVe embeddings <ref type="bibr" target="#b13">(Pennington, Socher, and Manning 2014)</ref>, the 100-dimensional embeddings estimated on the training set using the Word2Vec algorithm <ref type="bibr" target="#b11">(Mikolov et al. 2013</ref>) and the 150-dimensional character-level embeddings with window sizes of {3, 4, 5}, each consisting of 50 filters. The word embeddings were not updated during training. All hidden states of the LSTM had 200 dimensions. The MLP at the prediction had 256 hidden units with ReLU <ref type="bibr" target="#b12">(Nair and Hinton 2010)</ref> activation. Dropout with a rate of 0.2 was applied to the word embeddings and all hidden layers. The maximum utterance length, maximum number of utterances in a context were set to 30 and 26 respectively. Zeros were padded if the number of utterances in a context was less than 26. Otherwise, we kept the last 26 utterances in the context. The Adam method was employed for optimization with a batch size of 200. The learning rate was initialized as 0.001 and was exponentially decayed by 0.96 every 5000 steps. The weight of loss for Accept or Reject is enlarged to twice the original, and that for No Decision Yet keeps the original.</p><p>For subtask 4, we used the base version of BERT, because no further improvement could be achieved by its large version. The initial learning rate was set to 2e-5. The maximum sequence length were set to 100. The batch size was set to 4 . The max number of messages which were considered as the context of the target message was set to 50. Messages after the target message were also taken into consideration, but no further improvement was achieved. The hidden size of the BiLSTM module were set to 384 to make the concatenated output equal to 768 which was the same size as the output of BERT. The heuristic classifier had 3072 hidden units. For ensemble strategies, different strategies require different numbers of models to achieve the best result. For Model-AVG, the number was set to 2. For both Probability-AVG and Vote-AVG, the number was set to 8. <ref type="table" target="#tab_6">Table 3</ref> presents the evaluation results of our methods on the four subtasks. We tuned our single models on the validation set and submitted the final results using ensemble models. The ensemble models were built by averaging the outputs of five single models with identical architectures and different random initializations. Finally, our results ranked fourth in subtask 1, third in subtask 2, and first in subtask 3 and   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>To demonstrate the importance of each component in our proposed model, various parts of the architecture were ablated, and the results were reported on the validation set on each subtask, as shown in <ref type="table" target="#tab_7">Table 4</ref>, <ref type="table" target="#tab_9">Table 5</ref>, <ref type="table" target="#tab_10">Table 6</ref>, <ref type="table" target="#tab_11">Table 7</ref> and <ref type="table" target="#tab_12">Table 8</ref>. From    model further when we use pre-training. Furthermore, the performance continues to drop 0.6% in terms of Recall@1 by ablating the switch embeddings, which shows the effectiveness of utilizing the information of speaker turns. Similarly, the pre-training process and switch embeddings also benefit subtask 2 as shown in <ref type="table" target="#tab_9">Table 5</ref>. In addition, we ablated the disentanglement strategy and truncated the sequence to the max sequence length of BERT by selecting the head or tail part. The performance drops sharply which shows the effectiveness of the disentanglement strategy. <ref type="table" target="#tab_10">Table 6</ref> shows that enriching the training data with the help of the paraphrase and the weighted loss function are both effective.</p><p>From the result shown in <ref type="table" target="#tab_11">Table 7</ref>, we can see that our model has outperform the baseline given by DSTC 8 contest in all the five evaluation metrics. After we combine feature such as user and time etc., our model could achieve the further improvement, which indicates that manual feature still could capture some information that BERT could not capture. Even though we use the state-of-art model BERT with pre-training method, our model could only reach 46.3% F1 score, which indicates that the disentangling problem is still a hard problem to solve. <ref type="table" target="#tab_12">Table 8</ref> shows that, the Probability-AVG and Vote-AVG strategies could reach better performance compared with Model-AVG. Probability-AVG performs better on 1-Scaled VI, ARI and F1 metrics, and Votes performs better on recall and precision metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-Scaled VI ARI F1 recall precision</head><p>Model-AVG 0.939 0.811 0.472 0.520 0.495 Probability-AVG 0.947 0.831 0.521 0.547 0.534 Vote-AVG 0.941 0.783 0.519 0.552 0.535 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This paper describes our systems that are evaluated on all subtasks of Track 2 of DSTC 8. Pre-trained attention-based network for multi-turn dialogue systems are designed for each subtask according to different evaluation dimensions. In the released evaluation results of Track 2 of DSTC 8, our proposed models ranked fourth in subtask 1, third in subtask 2, and first in subtask 3 and subtask 4 respectively. Investigating other strategies for better employing pre-trained language models for multi-turn dialogue will be a part of our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The switch embeddings function as a switch to change the speaker in turn as the conversation progresses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>+ + + + + + + + + + + + + + + + + + + + + + + Input representation. The input embeddings is the sum of the token embeddings, the segmentation embeddings, the position embeddings and the switch embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Task description of each subtask in Track 2.</figDesc><table><row><cell>Switch</cell><cell></cell><cell></cell><cell></cell></row><row><cell>embedding</cell><cell></cell><cell></cell><cell></cell></row><row><cell>index</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Utterances of the 1 st turn</cell><cell>Utterances of the 2 nd turn</cell><cell>Utterances of the 3 rd turn</cell><cell>…...</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The positive responses are true responses that follow the context, and the negative responses are randomly sampled. For the Ubuntu dataset, we used title and question as sentence A, and answer as sentence B. For the Advising dataset, we use the name of courses as sentence</figDesc><table><row><cell cols="2">E[CLS] EHow</cell><cell>Eare</cell><cell>Eyou E[EOU] E[EOT]</cell><cell>EGo</cell><cell>Eto</cell><cell>Ehold</cell><cell>Ea</cell><cell>Edrum Eclass</cell><cell>E[EOU] EAnyone</cell><cell>Ejoins E[EOU] E[EOT]</cell><cell>ESure</cell><cell>E[EOU] E[EOT]</cell><cell>E[SEP] EHave</cell><cell>Efun</cell><cell>Ein</cell><cell>Eclass E[SEP]</cell></row><row><cell>EA</cell><cell>EA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>A, and its description as sentence B. For every sentence A, we randomly pick another answer as negative sample. The embedding of the [CLS] token is used as the aggregated representation for classification.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the datasets that our models were tested on.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>The submission results on the hidden test sets for the Track 2 of DSTC 8 challenge. NA -not applicable.</figDesc><table><row><cell></cell><cell cols="4">Recall@1 Recall@5 Recall@10 MRR</cell></row><row><cell>Ours</cell><cell>0.638</cell><cell>0.895</cell><cell>0.938</cell><cell>0.749</cell></row><row><cell>-Pre-train</cell><cell>0.622</cell><cell>0.881</cell><cell>0.909</cell><cell>0.733</cell></row><row><cell>-Switch</cell><cell>0.616</cell><cell>0.877</cell><cell>0.902</cell><cell>0.728</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Ablation results for a single model on the validation set of Ubuntu dataset in subtask 1.</figDesc><table /><note>subtask 4 respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc>, we can see that both the pre-training process and switch embeddings contribute to our final model. Without the pre-training process, the metric of Recall@1 drops a large margin 1.6%, which shows that the external data given by the DSTC 8 package does improve our</figDesc><table><row><cell></cell><cell cols="4">Recall@1 Recall@5 Recall@10 MRR</cell></row><row><cell>Ours</cell><cell>0.477</cell><cell>0.728</cell><cell>0.810</cell><cell>0.594</cell></row><row><cell>-Switch</cell><cell>0.452</cell><cell>0.713</cell><cell>0.799</cell><cell>0.573</cell></row><row><cell>-Pre-train</cell><cell>0.436</cell><cell>0.701</cell><cell>0.790</cell><cell>0.559</cell></row><row><cell>-Disentangle</cell><cell>0.258</cell><cell>0.393</cell><cell>0.458</cell><cell>0.335</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Ablation results for a single model on the validation set of Ubuntu dataset in subtask 2.</figDesc><table><row><cell></cell><cell>Accuracy</cell></row><row><cell>Ours</cell><cell>0.868</cell></row><row><cell>-Paraphrase</cell><cell>0.852</cell></row><row><cell>-Weight loss</cell><cell>0.846</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Ablation results for a single model on the validation set of Advising dataset in subtask 3.</figDesc><table><row><cell></cell><cell cols="2">1-Scaled VI ARI</cell><cell>F1 recall precision</cell></row><row><cell>Ours</cell><cell>0.947</cell><cell cols="2">0.841 0.463 0.502 0.482</cell></row><row><cell>-features</cell><cell>0.937</cell><cell cols="2">0.813 0.482 0.497 0.490</cell></row><row><cell>baseline</cell><cell>0.921</cell><cell cols="2">0.742 0.405 0.412 0.409</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Ablation results for a single model on the validation set of subtask 4.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Results for a ensemble model on the validation set of subtask 4.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In the following part of this paper, the context messages includes the target message itself.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Where&apos;s the &quot;party&quot; in &quot;multi-party&quot;? analyzing the structure of small-group sociable talk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aoki</surname></persName>
		</author>
		<idno>abs/cs/0608083</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
	<note>A large annotated corpus for learning natural language inference</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the NAACL-HLT 2019</title>
		<meeting>the 2019 Conference of the NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-02" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dually interactive matching network for personalized response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1845" to="1854" />
		</imprint>
	</monogr>
	<note>Enhance word representation for out-of-vocabulary on ubuntu dialogue corpus</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Interactive matching network for multiturn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM &apos;19</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management, CIKM &apos;19</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2321" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Utterance-to-utterance interactive matching network for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Polymenakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lasecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on NLP for Conversational AI</title>
		<meeting>the First Workshop on NLP for Conversational AI</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="60" to="67" />
		</imprint>
	</monogr>
	<note>Dstc7 task 1: Noetic end-to-end response selection</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bridging nonlinearities and stochastic regularizers with gaussian error linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>abs/1606.08415</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>Long short-term memory</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An information retrieval approach to short text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li ;</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<idno>abs/1408.6988</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to disentangle interleaved conversational threads with a siamese hierarchical network and similarity ranking</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Conference of the NAACL-HLT</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1812" to="1822" />
			<publisher>Long Papers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.06394</idno>
		<idno>Lowe et al. 2015</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2015 Conference, The 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the SIGDIAL 2015 Conference, The 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Ba; Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09-04" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="31" to="65" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Training endto-end dialogue systems with the ubuntu dialogue corpus. D&amp;D</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Chat disentanglement: Identifying semantic reply relationships with random forests and recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="615" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06-21" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
	<note>and Hinton</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Socher</forename><surname>Manning ; Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the NAACL-HLT 2018</title>
		<meeting>the 2018 Conference of the NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-01" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
	<note>Rajpurkar et al. 2016</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using discursive information to disentangle French language chat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Riou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hernandez ; Riou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hernandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Natural Language Processing for Computer-Mediated Communication (NLP4CMC 2015) / Social Media at GSCL Conference</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="23" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Building end-toend dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02-12" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li ;</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07-26" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-representation fusion network for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019<address><addrLine>Melbourne, VIC, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-02-11" />
			<biblScope unit="page" from="267" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">One time of interaction may not be enough: Go deep with an interaction-over-interaction network for response selection in dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-09" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequential matching network: A new architecture for multi-turn response selection in retrievalbased chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="496" to="505" />
		</imprint>
	</monogr>
	<note>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>CoRR abs/1906.08237</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling multi-turn conversation with deep utterance aggregation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3740" to="3752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-turn response selection for chatbots with deep attention matching network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1118" to="1127" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
