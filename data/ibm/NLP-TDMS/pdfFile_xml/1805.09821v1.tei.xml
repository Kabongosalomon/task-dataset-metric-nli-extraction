<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Corpus for Multilingual Document Classification in Eight Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-05-24">24 May 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
							<email>schwenk@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<country>Facebook AML</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
							<email>xianl@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<country>Facebook AML</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Corpus for Multilingual Document Classification in Eight Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-05-24">24 May 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cross-lingual document classification</term>
					<term>multilinguality</term>
					<term>Reuters Corpus Volume 2 (RCV2)</term>
					<term>evaluation framework</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cross-lingual document classification aims at training a document classifier on resources in one language and transferring it to a different language without any additional resources. Several approaches have been proposed in the literature and the current best practice is to evaluate them on a subset of the Reuters Corpus Volume 2. However, this subset covers only few languages (English, German, French and Spanish) and almost all published works focus on the the transfer between English and German. In addition, we have observed that the class prior distributions differ significantly between the languages. We argue that this complicates the evaluation of the multilinguality. In this paper, we propose a new subset of the Reuters corpus with balanced class priors for eight languages. By adding Italian, Russian, Japanese and Chinese, we cover languages which are very different with respect to syntax, morphology, etc. We provide strong baselines for all language transfer directions using multilingual word and sentence embeddings respectively. Our goal is to offer a freely available framework to evaluate cross-lingual document classification, and we hope to foster by these means, research in this important area.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There are many tasks in natural language processing which require the classification of sentences or longer paragraphs into a set of predefined categories. Typical applications are for instance topic identification (e.g. sports, news, . . .) or product reviews (positive or negative). There is a large body of research on approaches for document classification. An important aspect to compare these different approaches is the availability of high quality corpora to train and evaluate them. Unfortunately, most of these evaluation tasks focus on the English language only, while there is an ever increasing need to perform document classification in many other languages. One could of course collect and label training data for other languages, but this would be costly and time consuming. An interesting alternative is "crosslingual document classification". The underlying idea is to use a representation of the words or whole documents which is independent of the language. By these means, a classifier trained on one language can be transferred to a different one, without the need of resources in that transfer language. Ideally, the performance obtained by crosslingual transfer should be as close as possible to training the entire system on language specific resources. Such a task was first proposed by <ref type="bibr" target="#b2">(Klementiev et al., 2012)</ref> using the Reuters Corpus Volume 2. The aim was to first train a classifier on English and then to transfer it to German, and vice versa. An extension to the transfer between English and French and Spanish respectively was proposed by <ref type="bibr" target="#b5">(Mogadala and Rettinger, 2016)</ref>. However, only few comparative results are available for these transfer directions. The contributions of this work are as follows. We extend previous works and use the data in the Reuters Corpus Volume 2 to define new cross-lingual document classification tasks for eight very different languages, namely English, French, Spanish, Italian, German, Russian, Chinese and Japanese. For each language, we define a train, development and test corpus. We also provide strong reference results for all transfer directions between the eight languages, e.g. not limited to the transfer between a foreign language and English. We compare two approaches, based either on multilingual word or sentence embeddings respectively. By these means, we hope to define a clear evaluation environment for highly multilingual document classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Corpus description</head><p>The Reuters Corpus Volume 2 <ref type="bibr" target="#b4">(Lewis et al., 2004)</ref>, in short RCV2 1 , is a multilingual corpus with a collection of 487,000 news stories. Each news story was manually classified into four hierarchical groups: CCAT (Corporate/Industrial), ECAT (Economics), GCAT (Government/Social) and MCAT (Markets). Topic codes were assigned to capture the major subject of the news story. The entire corpus covers thirteen languages, i.e. Dutch, French, German, Chinese, Japanese, Russian, Portuguese, Spanish, Latin American Spanish, Italian, Danish, Norwegian, and Swedish, written by local reporters in each language. The news stories are not parallel. Single-label stories, i.e. those labeled with only one topic out of the four top categories, are often used for evaluations. However, the class distributions vary significantly across all the thirteen languages (see <ref type="table">Table 1</ref>). Therefore, using random samples to extract evaluation corpora may lead to very imbalanced test sets, i.e. undesired and misleading variability among the languages when the main focus is to evaluate cross-lingual transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Cross-lingual document classification</head><p>A subset of the English and German sections of RCV2 was defined by <ref type="bibr" target="#b2">(Klementiev et al., 2012)</ref> to evaluate crosslingual document classification. This subset was used in several follow-up works and many comparative results are available for the transfer between German and English. <ref type="bibr" target="#b5">(Mogadala and Rettinger, 2016)</ref> extended the use of RCV2 for cross-lingual document classification to the French and Spanish language (transfer from and to English). An analysis of these evaluation corpora has shown that the class prior distributions vary significantly between the classes (see <ref type="table" target="#tab_2">Table 2</ref>). For German and English, more than 80% of the ex- amples in the test set belong to the classes GCAT and MCAT and at most 2% to the class CCAT. These class prior distributions are very different for French and Spanish: the class CCAT is quite frequent with 21% and 15% of the French and Spanish test set respectively. One may of course argue that variability in the class prior distribution is typical for real-world problems, but this shifts the focus from a high quality cross-lingual transfer to "tricks" for how to best handle the class imbalance. Indeed, in previous research the transfer between English and German achieves accuracies higher than 90%, while the performance is below 80% for EN/FR or even 70% EN/ES. We have seen experimental evidence that these important differences are likely to be caused by the discrepancy in the class priors of the test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Multilingual document classification</head><p>In this work, we propose a new evaluation framework for highly multilingual document classification which significantly extends the current state. We continue to use Reuters Corpus Volume 2, but based on the above mentioned limitations of the current subset of RCV2, we propose new tasks for cross-lingual document classification. The design choices are as follow:</p><p>• Uniform class coverage: we sample from RCV2 the same number of examples for each class and language;</p><p>• Split the data into train, development and test corpus: for each languages, we provide training data of different sizes (1k, 2k, 5k and 10k stories), a development (1k) and a test corpus (4k);</p><p>• Support more languages:  uniform class distributions. An important aspect of this work is to provide a framework to study and evaluate cross-lingual document classification for many language pairs. In that spirit, we will name this corpus "Multilingual Document Classification Corpus", abbreviated as MLDoc. The full Reuters Corpus Volume 2 has a special license and we can not distribute it ourselves. Instead, we provide tools to extract all the subsets of MLDoc at https://github.com/facebookresearch/MLDoc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Baseline results</head><p>In this section, we provide comparative results on our new Multilingual Document Classification Corpus. Since the initial work by <ref type="bibr" target="#b2">(Klementiev et al., 2012)</ref> many alternative approaches to cross-lingual document classification have been developed. We will encourage the respective authors to evaluate their systems on MLDoc. We believe that a large variety of transfer language pairs will give valuable insights on the performance of the various approaches.</p><p>In this paper, we propose initial strong baselines which represent two complementary directions of research: one based on the aggregation of multilingual word embeddings, and another one, which directly learns multilingual sentence representations. Details on each approach are given in section 3.1. and 3.2. respectively. In contrast to previous works on cross-lingual document classification with RVC2, we explore training the classifier on all languages and transfer it to all others, ie. we do not limit our study to the transfer between English and a foreign language. One can envision several ways to define cross-lingual document classification, in function of the resources which are used in the source and transfer language (see <ref type="table" target="#tab_4">Table 3</ref>). The first scheme assumes that we have no resources in the transfer language at all, neither labeled nor unlabeled. We will name this case "zero-shot cross-lingual document classification". To simplify the presentation, we will assume that we transfer from English to German.   Once the best performing model is selected, it is applied to the transfer language, eg. the German test set. Since no resources of the transfer language are used, the same system can be applied to many different transfer languages. This type of cross-lingual document classification needs a very strong multilingual representation since no knowledge on the target language was used during the development of the classifier. In a second class of cross-lingual document classification, we may aim in improving the transfer performance by using a limited amount of resources in the target language.</p><p>In the framework of the proposed MLDoc we will use the development corpus of target language for model selection. We will name this method "targeted cross-lingual document classification" since the system is tailored to one particular transfer language. It is unlikely that this system will perform well on other languages than the ones used for training or model selection.</p><p>If the goal is to build one document classification system for many languages, it may be interesting to use already several languages during training and model selection. To allow a fair comparison, we will assume that these multilingual resources have the same size than the ones used for zero-shot or targeted cross-language document classification, e.g. a training set composed of five languages with 200 examples each. This type of training is not a cross-lingual approach any more. Consequently, we will refer to this method as "joint multilingual document classification".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multilingual word representations</head><p>Several works have been proposed to learn multilingual word embeddings, which are then combined to perform cross-lingual document classifications. These word embeddings are trained on either word alignments or sentencealigned parallel corpora. To provide reproducible benchmark results, we use MultiCCA word embeddings published by <ref type="bibr" target="#b0">(Ammar et al., 2016)</ref>. There are multiple ways to combine these word embeddings for classification. We train a simple one-layer convolutional neural network (CNN) on top of the word embeddings, which has shown to perform well on text classification tasks regardless of training data size <ref type="bibr" target="#b1">(Kim, 2014)</ref>. Specifically, convolutional filters are applied to windows of word embeddings, with a max-over-time pooling on top of them. We freeze the multilingual word embeddings while only training the classifier. Hyper-parameters such as convolutional output dimension, window sizes are done by grid search over the Dev set of the same language as the train set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multilingual sentence representations</head><p>A second direction of research is to directly learn multilingual sentence representations. In this paper, we evaluate a recently proposed technique to learn joint multilingual sentence representations <ref type="bibr" target="#b6">(Schwenk and Douze, 2017)</ref>. The underlying idea is to use multiple sequence encoders and decoders and to train them with aligned corpora from the machine translation community.  Each entry corresponds to a specifically optimized system. this approach can be found in <ref type="bibr" target="#b6">(Schwenk and Douze, 2017)</ref>.</p><p>We have developed two versions of the system: one trained on the Europarl corpus <ref type="bibr" target="#b3">(Koehn, 2005)</ref> to cover the languages English, German, French, Spanish and Italian, and another one trained on the United Nations corpus <ref type="bibr" target="#b7">(Ziemski et al., 2016)</ref> which allows to learn a joint sentence embedding for English, French, Spanish, Russian and Chinese. We use a one hidden-layer MLP as classifier. For comparison, we have evaluated its performance on the original subset of RCV2 as used in previous publications on cross-lingual document classification: we are able to outperform the current state-of-the-art in three out of six transfer directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Zero-shot cross-lingual document classification</head><p>The classification accuracy for zero-shot transfer on the test set of our Multilingual Document Classification Corpus are summarized in <ref type="table" target="#tab_5">Table 4</ref>. The classifiers based on the MultiCCA embeddings perform very well on the development corpus (accuracies close or exceeding 90%). The system trained on English also achieves excellent results when transfered to a different languages, it scores best for three out of seven languages (DE, IT and ZH). 3 However, the transfer accuracies are quite low when training the classifiers on other languages than English, in particular for Russian, Chinese and Japanese. The systems using multilingual sentence embeddings seem to be overall more robust and less language specific. They score best for four out of seven languages (EN, ES, FR and RU). Training on German or French actually leads to better transfer performance than training on English. Crosslingual transfer between very different languages like Chinese and Russian also achieves remarkable results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Targeted cross-lingual document classification</head><p>The classification accuracy for targeted transfer are summarized in <ref type="table" target="#tab_7">Table 5</ref>. Due to space constraints, we provide only the results for multilingual sentence embeddings and five target languages. Not surprisingly, targeting the classi- <ref type="bibr">3</ref> We exclude Japanese from the comparison since we do not have joint sentence embeddings for that language yet.  fier to the transfer language can lead to important improvements, in particular when training on Italian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Joint multilingual document classification</head><p>The classification accuracies for joint multilingual training are given in <ref type="table" target="#tab_9">Table 6</ref>. We use a multilingual train and Dev corpus composed of 200 examples of each of the five languages. One could argue that the data collection and annotation cost for such a corpus would be the same than producing a corpus of the same size in one language only. This leads to important improvement for all languages, in comparison to zero-shot or targeted transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We have defined a new evaluation framework for crosslingual document classification in eight languages. This corpus largely extends previous corpora which were also based on the Reuters Corpus Volume 2, but mainly considered the transfer between English and German. We also provide detailed baseline results using two competitive approaches (multilingual word and sentence embeddings, respectively), for cross-lingual document classification between all eight languages. This new evaluation framework is freely available at https://github.com/facebookresearch/MLDoc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>http://trec.nist.gov/data/reuters/reuters.html</figDesc><table><row><cell></cell><cell cols="2">Category</cell></row><row><cell cols="3">Language ECAT CCAT GCAT MCAT</cell></row><row><cell>English</cell><cell cols="2">6.2% 39.8% 29.5% 24.5%</cell></row><row><cell>German</cell><cell cols="2">6.4% 30.1% 40.9% 22.6%</cell></row><row><cell>French</cell><cell cols="2">6.3% 21.6% 60.2% 11.8%</cell></row><row><cell>Spanish</cell><cell>8.6% 15.0%</cell><cell>9.0% 67.3%</cell></row><row><cell>Chinese</cell><cell>19.7% 18.2%</cell><cell>2.8% 59.4%</cell></row><row><cell>Italian</cell><cell>18.0% 35.7%</cell><cell>9.5% 36.8%</cell></row><row><cell>Japanese</cell><cell>14.8% 42.1%</cell><cell>7.0% 36.1%</cell></row><row><cell>Russian</cell><cell cols="2">26.9% 27.6% 13.4% 32.2%</cell></row><row><cell>Danish</cell><cell>7.5% 56.6%</cell><cell>5.3% 30.6%</cell></row><row><cell cols="3">Table 1: Class distribution of all single-label stories per</cell></row><row><cell cols="3">language of the entire Reuters Corpus Volume 2.</cell></row></table><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Class distribution of the test set of the RCV2 subsets as used in previous publications on cross-lingual document classification.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The training and evaluation protocol is as follows. First, train a classifier using resources in the source language only, eg. the training</figDesc><table><row><cell>Transfer type</cell><cell cols="2">Model training selection Model</cell><cell>Evaluation</cell></row><row><cell cols="2">Zero shot Train L 1</cell><cell>Dev L 1</cell><cell>Test L i</cell></row><row><cell>Targeted</cell><cell>Train L 1</cell><cell>Dev L 2</cell><cell>Test L 2</cell></row><row><cell>Joint</cell><cell>Train L i</cell><cell>Dev L i</cell><cell>Test L i</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>Training</cell><cell>Develop</cell><cell></cell><cell></cell><cell cols="3">Accuracy on test languages</cell><cell></cell><cell></cell><cell>Average</cell></row><row><cell cols="2">Language Accuracy</cell><cell>DE 1</cell><cell cols="2">EN 1,2 ES 1,2 FR 1,2</cell><cell>IT 1</cell><cell>RU 2</cell><cell>ZH 2</cell><cell>JA</cell><cell>lang 1 lang 2</cell></row><row><cell cols="7">MultiCCA word embeddings, aggregation by convolutional network</cell><cell></cell><cell></cell></row><row><cell>German</cell><cell>92.2</cell><cell cols="7">(93.7) 55.95 73.23 71.55 63.98 44.83 55.45 60.18</cell><cell>71.68 60.20</cell></row><row><cell>English</cell><cell>93.9</cell><cell>81.2</cell><cell cols="6">(92.2) 72.50 72.38 69.38 60.80 74.73 67.63</cell><cell>77.52 73.44</cell></row><row><cell>Spanish</cell><cell>95.3</cell><cell>55.8</cell><cell cols="6">74.0 (94.45) 65.63 58.35 45.53 41.63 43.40</cell><cell>69.63 67.58</cell></row><row><cell>French</cell><cell>91.5</cell><cell>53.7</cell><cell>64.8</cell><cell cols="5">65.40 (92.05) 61.15 40.75 38.35 37.75</cell><cell>67.43 64.83</cell></row><row><cell>Italian</cell><cell>85.6</cell><cell>49.2</cell><cell>53.7</cell><cell cols="5">58.68 62.25 (85.55) 35.58 32.13 45.30</cell><cell>61.87 64.83</cell></row><row><cell>Russian</cell><cell>86.8</cell><cell>40.3</cell><cell>72.5</cell><cell cols="5">41.03 44.60 42.70 (85.65) 42.38 39.68</cell><cell>48.22 57.30</cell></row><row><cell>Chinese</cell><cell>90.8</cell><cell>48.7</cell><cell>56.0</cell><cell cols="5">35.53 53.58 47.18 40.45 (87.30) 50.63</cell><cell>48.19 46.55</cell></row><row><cell>Japanese</cell><cell>87.3</cell><cell>52.7</cell><cell>54.9</cell><cell cols="6">54.28 48.30 44.33 40.85 44.78 (85.35) 50.89 48.52</cell></row><row><cell cols="7">Joint sentence embeddings BiLSTM + max pooling, trained on Europarl</cell><cell></cell><cell></cell></row><row><cell>German</cell><cell>94.3</cell><cell cols="4">(92.03) 71.52 75.50 75.45 56.45</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>74.15</cell><cell>-</cell></row><row><cell>English</cell><cell>90.7</cell><cell cols="4">71.83 (88.40) 66.65 72.83 60.73</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>72.09</cell><cell>-</cell></row><row><cell>Spanish</cell><cell>88.2</cell><cell cols="4">71.05 62.70 (88.28) 62.67 57.93</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>68.53</cell><cell>-</cell></row><row><cell>French</cell><cell>90.6</cell><cell cols="4">78.42 76.00 70.70 (89.75) 63.70</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>75.71</cell><cell>-</cell></row><row><cell>Italian</cell><cell>83.1</cell><cell cols="4">66.22 67.15 67.07 65.07 (82.88)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>69.68</cell><cell>-</cell></row><row><cell cols="8">Joint sentence embeddings BiLSTM + max pooling, trained on United Nations</cell><cell></cell></row><row><cell>English</cell><cell>91.3</cell><cell>-</cell><cell cols="2">(88.83) 69.50 74.52</cell><cell>-</cell><cell cols="2">61.42 71.97</cell><cell>-</cell><cell>-</cell><cell>73.25</cell></row><row><cell>Spanish</cell><cell>86.8</cell><cell>-</cell><cell cols="2">61.65 (87.67) 61.62</cell><cell>-</cell><cell cols="2">45.10 59.88</cell><cell>-</cell><cell>-</cell><cell>63.18</cell></row><row><cell>French</cell><cell>90.5</cell><cell>-</cell><cell cols="2">75.35 71.80 (89.55)</cell><cell>-</cell><cell cols="2">59.55 69.08</cell><cell>-</cell><cell>-</cell><cell>73.07</cell></row><row><cell>Russian</cell><cell>83.8</cell><cell>-</cell><cell cols="2">68.53 65.18 65.90</cell><cell>-</cell><cell cols="2">(81.60) 59.65</cell><cell>-</cell><cell>-</cell><cell>68.17</cell></row><row><cell>Chinese</cell><cell>90.4</cell><cell>-</cell><cell cols="2">66.30 64.78 63.82</cell><cell>-</cell><cell cols="2">54.57 87.10</cell><cell>-</cell><cell>-</cell><cell>67.31</cell></row></table><note>Different schemes of cross-and multilingual doc- ument classification.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Baseline classification accuracies for zero-shot transfer on the test set of the proposed Multilingual Document Classification Corpus. All classifiers were trained on 1 000 news stories and model selection is performed on the Dev corpus of the training language. The same system is then applied to all test languages. Underlined scores indicate the best result on each transfer language for each group, bold scores the overall best accuracy, and italic ones the second best results. and development corpus are in English. All meta parameters and model choices are performed using the English development corpus.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>DE (92.03) 76.48 76.95 76.72 66.27 77.69 EN 81.17 (88.40) 70.75 77.80 62.35 76.09 ES 77.38 67.58 (88.28) 67.92 64.07 73.</figDesc><table><row><cell>Train</cell><cell>DE</cell><cell>Accuracy on test languages EN ES FR</cell><cell>IT</cell><cell>Avg</cell></row><row><cell cols="3">Joint sentence embeddings (Europarl)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>05</cell></row><row><cell>FR</cell><cell cols="4">82.78 76.72 76.97 (89.75) 64.07 78.06</cell></row><row><cell>IT</cell><cell cols="4">77.10 72.70 72.60 76.97 (82.88) 76.45</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>The goal is that all encoders</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>share the same sentence representation, i.e. we map all lan-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>guages into one common space. A detailed description of</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Baseline classification accuracies for targeted transfer on the test set of the proposed MLDoc. All classifiers were trained on 1 000 news stories and model selection is performed on the Dev corpus of the target language.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>79.08 86.95 81.70 77.58 83.31 Joint sentence embeddings (Europarl) 1k 88.02 82.42 80.12 84.55 75.08 82.04</figDesc><table><row><cell>Train Size</cell><cell>Accuracy on test languages DE EN ES FR IT</cell><cell>Average</cell></row><row><cell cols="2">MultiCCA word embeddings</cell><cell></cell></row><row><cell>1k</cell><cell>91.23</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Baseline classification accuracies on the test set of the proposed MLDoc for joint multilingual training. Train and test sets are composed of 200 examples form each of the five languages.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01925</idno>
		<title level="m">Massively multilingual word embeddings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<title level="m">Convolutional neural networks for sentence classification</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Inducing crosslingual distributed representations of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bhattarai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>In Coling</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>In MT Summit</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Rcv1: A new benchmark collection for text categorization research. JMLR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bilingual word embeddings from parallel and non-parallel corpora for cross-language classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mogadala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="692" to="702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning joint multilingual sentence representations with neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL workshop on Representation Learning for NLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The United Nations parallel corpus v1.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ziemski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Juncys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pouliquen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<meeting><address><addrLine>Portorož</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
