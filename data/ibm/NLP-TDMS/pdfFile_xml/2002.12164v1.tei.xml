<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Performance Analysis of Semi-supervised Learning in the Small-data Regime using VAEs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkata</forename><forename type="middle">Varunbabu</forename><surname>Mannam</surname></persName>
							<email>vmannam@nd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Notre Dame Notre Dame</orgName>
								<address>
									<region>Indiana</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Kazemi</surname></persName>
							<email>akazemi@nd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Notre Dame Notre Dame</orgName>
								<address>
									<region>Indiana</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Performance Analysis of Semi-supervised Learning in the Small-data Regime using VAEs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>University of Notre Dame Notre Dame, Indiana</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Extracting large amounts of data from biological samples is not feasible due to radiation issues and image processing in the smalldata regime is one of the critical challenges when working with limited amount of data. In this work, we applied an existing algorithm named Variational Auto Encoder (VAE) that pre-trains a latent space representation of the data that captures the features in a lower-dimension for the small-data regime input. The latent space representation will be fine-tuned and its weights will be fixed. The latent space will be used as a segment of the neural network that can be used for classification. Here we will present the performance analysis of the VAE algorithm with various latent space sizes in the semi-supervised learning using the CIFAR-10 dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Artificial neural networks (ANNs), specifically Convolutional Neural Networks (CNNS), have become popular due to their success in image classification, feature extraction and object recognition and detection <ref type="bibr" target="#b3">[4]</ref> in the recent years. CNNs leverage the huge amount of labeled data available to train networks that outperform humans in image recognition tasks. However, in the small-data regime, the accuracy of trained networks using a limited number of labeled samples is low <ref type="bibr" target="#b2">[3]</ref>. This is a typical case when working with biological samples where exposure to radiation (in order to capture an image) is detrimental to the well-being of the sample. More images can be derived from the initial data by some augmentation methods, but it is unhelpful due to lack of labeled images.</p><p>To address this problem, there exists a framework called Auto Encoder (AE <ref type="bibr" target="#b0">[1]</ref>) that uses all the input data, labeled and unlabeled, to train a low-dimensional embedding. AE is a neural network that takes unlabeled images as the input and regards the input itself as the label. As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, AE is comprised of two parts: the encoder and the decoder. The encoder part tries to embed the features in a latent space that can extract the features of the original image and the decoder tries to restore the image to the original image. The process called pre-training trains the weights for both encoder and decoder parts. Once trained, the encoder part of the AE will be a representation of all the labeled and unlabeled data. This increases the amount of usable information from all of the images.</p><p>Traditional semi-supervised models consists of pretraining using Restricted Boltzmann machine (RBM) <ref type="bibr" target="#b5">[6]</ref> or Gaussian-Restricted Boltzmann machine (G-RBM) <ref type="bibr" target="#b5">[6]</ref>. RBM is an energy based model that is represented using an undirected graph containing a layer of observable variables and a single layer of latent variables (similar to hidden units in a multi-layer perceptron) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>. This energy based model was first introduced in 1980's <ref type="bibr" target="#b10">[11]</ref> and have been implemented using diverse datasets including image <ref type="bibr" target="#b5">[6]</ref> and medical data <ref type="bibr" target="#b9">[10]</ref>. Hinton and Salakhutdinov <ref type="bibr" target="#b4">[5]</ref> showed that RBMs can be stacked and trained in a greedy manner. This deep learning model, Deep belief networks (DBN), that utilizes RBM as the learning model has been implemented on various unsupervised and supervised learning problems. Later, Bengio et. al. <ref type="bibr" target="#b1">[2]</ref> showed that the pre-trained undirected graphical model in semi-supervised setting performs well with deep architectures. However, the challenge working with RBM is that it is constructed using sigmoid functions as the activation function between the input and the hidden layer. As we are aware that the major drawback of using sigmoid activation function is the vanishing gradient problem. Hence, in this work, we pre-train the model using Variational Auto Encoder (VAE <ref type="bibr" target="#b0">[1]</ref>).</p><p>After pre-training the encoder is able to observe similar images to the training images and extract the valuable features from it in a lower dimension than the initial image. Now it is possible to couple the encoder with a small neural network and train that network for classification tasks. The present work is similar to reinforcement learning where the model is trained with one dataset and uses the feature extraction part of that model to train another model for a different dataset. It is important to mention that the encoder weights are fixed and can't be changed. It is only the small neural network that will be trained. The input to this network is the small set of labeled data. This is called fine-tuning.</p><p>In this project we will implement VAE that tries to capture not only the compressed representation of the images, but also the parameters of a probability distribution representing the data. We will examine the effect of different size of the latent spaces and how it affects the accuracy of the model. Later, we will analyze the performance of the semi-supervised model with the optimum latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2002.12164v1 [cs.</head><p>LG] 26 Feb 2020</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section we enumerate the basic details about AE and VAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Auto Encoder</head><p>An autoencoder is a type of ANN used to learn efficient data encoding in an unsupervised manner. The aim of an autoencoder is to learn a representation of a set of data, typically for dimensionality reduction, by training the network to ignore signal noise. Along with the reduction side, a reconstructing side is learned, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input. An autoencoder always consists of two parts, the encoder and the decoder, which can be defined as transitions ϕ and ψ such that <ref type="bibr" target="#b0">[1]</ref>:</p><formula xml:id="formula_0">ϕ : X → (1) ψ : F → Y (2) ϕ,ψ = arдmin ϕ,ψ ||X − (ψoϕ)(X ) 2 ||<label>(3)</label></formula><p>where the given input is X and the predicted output is Y . If the feature space F has lower dimensionality than the input space X , then the feature vector ϕ(x) can be regarded as a compressed representation of the input X . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">VAE</head><p>To extend the idea used in the AE, there is a variation called VAE which uses the "KL-divergence" between the predicted probability distribution function and actual posterior distribution in the latent space whereas traditional AEs try to find the accurate mapping functions in the encoder (between input and latent space) as well as in the decoder (between the latent space and output). Using VAE, we generate a large dataset by adding the noise in the latent space which is similar to input data augmentation (adding noise to images to increase the number of examples in the input dataset). VAE uses a variational approach for latent representation learning, which results in an additional loss component. It assumes that the data is generated by a directed graphical model p(X|Z) and that the encoder is learning an approximation q ϕ (Z|X) of the posterior distribution p θ (X|Z) where ϕ and θ denote the parameters of the encoder (recognition model) and decoder (generative model) respectively. We can write the conditional or posterior distribution</p><formula xml:id="formula_1">p(z|x) = p(z, x) p(x) = p(x |z)p(z) p(x)<label>(4)</label></formula><p>The denominator of above equation is the marginal distribution of the observations and is calculated by marginalizing out the latent </p><p>In many cases of interest this integral is not available in closed form or is intractable (requires exponential time to compute). Hence, we consider variational approximation as follows: consider a tractable distribution q(z). The goal is to find the best approximation, e.g., the one that satisfies the following optimization problem:</p><formula xml:id="formula_3">Minimize : D K L [q ϕ (z|x)||p θ (z|x)]<label>(6)</label></formula><p>Therefore, the objective of the variational autoencoder in this case has the following form:</p><formula xml:id="formula_4">L(ϕ, θ, x) = D KL q ϕ (z|x)∥p θ (z) − E q ϕ (z|x) (log p θ (x|z)) (7)</formula><p>where D K L stands for the KL-divergence. In the VAE, the principle is to minimize the loss between input and the restored image along with the loss generated by the latent space to represent the features in the input images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>Consider a surrogate model y = f (x, θ ) which is trained using</p><formula xml:id="formula_5">limited simulation data D = {x i , y i } N i=1 , {x j } D j=N +1 . Where the input data, x i ∈ R d x ×H ×W is the input from CIFAR-10 dataset.</formula><p>Here H and W are the height and width respectively and d x is the number of dimensions for the input x at one location. x j is the additional data utilized for pretraining the model. y i ∈ R 1 is the classified result. θ is the model parameter and N is the total number of training data utilized during fine-tuning and D is the total number of data utilized for pre-training. In semi-supervised model, we pretrain the model with the input data R d x ×H ×W and then perform image classification problem R d x ×H ×W → R 1 . For both the pretraining and fine tuning, we used stochastic gradient descent with Adam optimizer to update the network weights and biases. The simulation was performed using Pytorch machine learning package in Python.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">VAE pre-training</head><p>We implemented dense-net <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b12">[13]</ref> version of VAE for the pretraining part. Dense-net contains the encoder and decoder blocks along with the dense-layer that has the simple and complex features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">VAE fine-tuning</head><p>We implemented a simple fully connected layer to classify the input images on the CIFAR-10 <ref type="bibr" target="#b7">[8]</ref> data. This is due to the expectation that the latent space is smaller (either 4 × 4 or 8 × 8) (image size is 32 × 32). If the number of channels are large at the latent space, we will add more fully connected layers for classification of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DATA</head><p>We perform the simulations on the CIFAR-10 dataset with ten image classes with three input channels (C = 3) of size 32 × 32 (W × H). CIFAR-10 dataset has 50000 training images and 10000 test images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>In this section we enumerate the results obtained using CIFAR-10 data. We consider the following latent dimensions: 6400, 10,000 and 14,400. In order to evaluate the performance of the model for above three latent space, we consider the distribution estimated for the values at various pixel location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Pre-training</head><p>For the results presented in this section, we have a dataset with 50,000 {x k } 50000 k=1 examples for pre-training and the test set consist of 10000, {x k } 10000 k=1 examples. Adam optimizer was used for training 100 epochs, with learning rate of 1e-4 and a plateau scheduler on the test RMSE. Batch size is always smaller than the number of training data. In this work, a batch size of 16 for pre-training was used. Weight decay was set to 1e-3 for pre-training.</p><p>We consider Equation: 7 loss function to evaluate the trained model on test data and also to monitor the convergence.</p><p>From <ref type="figure" target="#fig_0">figure 1</ref>, we observe that the solution is converged after 50 epochs and most importantly the loss for the three latent spaces is similar.</p><p>From figure 4, we observe that even when the latent size is small (Batch × 100 (channels) × 8 × 8) and (Batch × 100 (channels) × 10 × 10) the reconstructed density estimate is close to actual input data. The PDF with the latent size 10000 is closer to the actual input and also 6400 &amp; 14400 latent space. Since, all the latent spaces yield the similar outputs,we fine-tune and compare the classification accuracy in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fine-tuning</head><p>In this section we freeze the parameters (weights and bias) used in the pre-training stage and fine tune the parameters (weights and bias) in the classification network. For this problem, we consider small data from the given CIFAR-10 dataset and use fully connected layers to perform classification. Cross entropy loss function is commonly used for all classification problems, we implemented cross entropy to measures the performance of a classification mode. From <ref type="figure" target="#fig_4">figure 5</ref>, we observe the latent space 10000 yields better accuracy than other two latent spaces (6400 and 14400). The smaller the latent space the lower the test accuracy, this is due to insufficient features to classify the data. Also, for the large latent space, the test accuracy is low, this is due to model complexity <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE WORK</head><p>The present document outlines the development of surrogate model for semi-supervised problem. In this work, we have implemented VAE as a pre-training model and a feed forward deep learning For future work, a Bayesian approach can be explored. Due to a limited amount of data, it is necessary to model appropriate surrogate, since it is important to quantify the epistemic uncertainty induced by limited data <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref> and hence, a Bayesian probabilistic approach is a natural way of addressing this challenge. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Autoencoder block diagram</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Network architecture: pre-training with VAE(first row) In the second row, parameter θ is underlined and bold to indicate that these parameters are freezed when the finetuning the network variables from the joint distribution, i.e.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Error v/s epoch for 6400 latent space (top), Error v/s epoch for 10000 latent space (middle) and Error v/s epoch for 14400 latent space (bottom)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Distribution estimate for the values at various location of the square domain for 6400, 10000 and 14400 latent space model for the classification. The results obtained for differently sized latent spaces are presented. It was observed that there is a slight improvement in the test accuracy when the latent space is 10000 in comparison with latent space of 6400 and 14400.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Fine tuning results with three different latent space models</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Autoencoder -Wikipedia, the free encyclopedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoencoder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning from labeled and unlabeled data: An empirical study across techniques and domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="331" to="366" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An efficient learning procedure for deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1967" to="2006" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Reducing the dimensionality of data with neural networks. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan R</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Latent patient profile modelling and applications with mixed-variate restricted boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Truyen</forename><surname>Tu Dinh Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetha</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia conference on knowledge discovery and data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="123" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Information processing in dynamical systems: Foundations of harmony theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Smolensky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
		<respStmt>
			<orgName>Colorado Univ at Boulder Dept of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep uq: Learning deep neural network surrogate models for high dimensional uncertainty quantification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilias</forename><surname>Tripathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bilionis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">375</biblScope>
			<biblScope unit="page" from="565" to="588" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yide</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cody</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Howard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.10366</idno>
		<title level="m">A poisson-gaussian denoising dataset with real fluorescence microscopy images</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Zabaras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="page" from="415" to="447" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
