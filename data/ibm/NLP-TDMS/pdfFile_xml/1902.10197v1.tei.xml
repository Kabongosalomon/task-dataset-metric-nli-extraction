<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ROTATE: KNOWLEDGE GRAPH EMBEDDING BY RELA- TIONAL ROTATION IN COMPLEX SPACE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
							<email>zhdeng@pku.edu.cnnie@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Université de Montréal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
							<email>jian.tang@hec.ca</email>
							<affiliation key="aff1">
								<orgName type="institution">Mila-Quebec Institute for Learning Algorithms</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">HEC Montréal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">CIFAR AI Research Chair</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ROTATE: KNOWLEDGE GRAPH EMBEDDING BY RELA- TIONAL ROTATION IN COMPLEX SPACE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.</p><p>Published as a conference paper at ICLR 2019 Model Score Function SE (Bordes et al., 2011) − Wr,1h − Wr,2t h, t ∈ R k , Wr,· ∈ R k×k TransE (Bordes et al., 2013) − h + r − t h, r, t ∈ R k TransX − gr,1(h) + r − gr,2(t) h, r, t ∈ R k DistMult (Yang et al., 2014) r, h, t h, r, t ∈ R k ComplEx (Trouillon et al., 2016) Re( r, h, t ) h, r, t ∈ C k HolE (Nickel et al., 2016) r, h ⊗ t h, r, t ∈ R k ConvE (Dettmers et al., 2017) σ(vec(σ([r, h] * Ω))W ), t h, r, t ∈ R k RotatE − h • r − t 2 h, r, t ∈ C k , |ri| = 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Knowledge graphs are collections of factual triplets, where each triplet (h, r, t) represents a relation r between a head entity h and a tail entity t. Examples of real-world knowledge graphs include Freebase <ref type="bibr" target="#b0">(Bollacker et al., 2008)</ref>, <ref type="bibr">Yago (Suchanek et al., 2007)</ref>, and <ref type="bibr">WordNet (Miller, 1995)</ref>. Knowledge graphs are potentially useful to a variety of applications such as question-answering <ref type="bibr" target="#b10">(Hao et al., 2017)</ref>, information retrieval <ref type="bibr" target="#b30">(Xiong et al., 2017)</ref>, recommender systems <ref type="bibr" target="#b34">(Zhang et al., 2016)</ref>, and natural language processing <ref type="bibr" target="#b31">(Yang &amp; Mitchell, 2017)</ref>. Research on knowledge graphs is attracting growing interests in both academia and industry communities.</p><p>Since knowledge graphs are usually incomplete, a fundamental problem for knowledge graph is predicting the missing links. Recently, extensive studies have been done on learning low-dimensional representations of entities and relations for missing link prediction (a.k.a., knowledge graph embedding) <ref type="bibr" target="#b3">(Bordes et al., 2013;</ref><ref type="bibr" target="#b28">Trouillon et al., 2016;</ref><ref type="bibr" target="#b7">Dettmers et al., 2017)</ref>. These methods have been shown to be scalable and effective. The general intuition of these methods is to model and infer the connectivity patterns in knowledge graphs according to the observed knowledge facts. For example, some relations are symmetric (e.g., marriage) while others are antisymmetric (e.g., filiation); some relations are the inverse of other relations (e.g., hypernym and hyponym); and some relations may be composed by others (e.g., my mother's husband is my father). It is critical to find ways to model and infer these patterns, i.e., symmetry/antisymmetry, inversion, and composition, from the observed facts in order to predict missing links.</p><p>Indeed, many existing approaches have been trying to either implicitly or explicitly model one or a few of the above relation patterns <ref type="bibr" target="#b3">(Bordes et al., 2013;</ref><ref type="bibr" target="#b29">Wang et al., 2014;</ref><ref type="bibr" target="#b17">Lin et al., 2015b</ref>; <ref type="table" target="#tab_1">Table 1</ref>: The score functions f r (h, t) of several knowledge graph embedding models, where · denotes the generalized dot product, • denotes the Hadamard product, ⊗ denotes circular correlation, σ denotes activation function and * denotes 2D convolution. · denotes conjugate for complex vectors, and 2D reshaping for real vectors in ConvE model. TransX represents a wide range of TransE's variants, such as TransH <ref type="bibr" target="#b29">(Wang et al., 2014)</ref>, TransR <ref type="bibr" target="#b17">(Lin et al., 2015b)</ref>, and STransE <ref type="bibr" target="#b23">(Nguyen et al., 2016)</ref>, where g r,i (·) denotes a matrix multiplication with respect to relation r. <ref type="bibr" target="#b32">Yang et al., 2014;</ref><ref type="bibr" target="#b28">Trouillon et al., 2016)</ref>. For example, the TransE model <ref type="bibr" target="#b2">(Bordes et al., 2011)</ref>, which represents relations as translations, aims to model the inversion and composition patterns; the DisMult model <ref type="bibr" target="#b32">(Yang et al., 2014)</ref>, which models the three-way interactions between head entities, relations, and tail entities, aims to model the symmetry pattern. However, none of existing models is capable of modeling and inferring all the above patterns. Therefore, we are looking for an approach that is able to model and infer all the three types of relation patterns.</p><p>In this paper, we propose such an approach called RotatE for knowledge graph embedding. Our motivation is from Euler's identity e iθ = cos θ + i sin θ, which indicates that a unitary complex number can be regarded as a rotation in the complex plane. Specifically, the RotatE model maps the entities and relations to the complex vector space and defines each relation as a rotation from the source entity to the target entity. Given a triplet (h, r, t), we expect that t = h • r, where h, r, t ∈ C k are the embeddings, the modulus |r i | = 1 and • denotes the Hadamard (element-wise) product. Specifically, for each dimension in the complex space, we expect that:</p><formula xml:id="formula_0">t i = h i r i , where h i , r i , t i ∈ C and |r i | = 1.<label>(1)</label></formula><p>It turns out that such a simple operation can effectively model all the three relation patterns: symmetric/antisymmetric, inversion, and composition. For example, a relation r is symmetric if and only if each element of its embedding r, i.e. r i , satisfies r i = e 0/iπ = ±1; two relations r 1 and r 2 are inverse if and only if their embeddings are conjugates: r 2 =r 1 ; a relation r 3 = e iθ3 is a combination of other two relations r 1 = e iθ1 and r 2 = e iθ2 if and only if r 3 = r 1 • r 2 (i.e. θ 3 = θ 1 + θ 2 ). Moreover, the RotatE model is scalable to large knowledge graphs as it remains linear in both time and memory.</p><p>To effectively optimizing the RotatE, we further propose a novel self-adversarial negative sampling technique, which generates negative samples according to the current entity and relation embeddings. The proposed technique is very general and can be applied to many existing knowledge graph embedding models. We evaluate the RotatE on four large knowledge graph benchmark datasets including FB15k <ref type="bibr" target="#b3">(Bordes et al., 2013)</ref>, WN18 <ref type="bibr" target="#b3">(Bordes et al., 2013)</ref>, FB15k-237 <ref type="bibr" target="#b27">(Toutanova &amp; Chen, 2015)</ref> and WN18RR <ref type="bibr" target="#b7">(Dettmers et al., 2017)</ref>. Experimental results show that the RotatE model significantly outperforms existing state-of-the-art approaches. In addition, RotatE also outperforms state-of-the-art models on Countries <ref type="bibr" target="#b4">(Bouchard et al., 2015)</ref>, a benchmark explicitly designed for composition pattern inference and modeling. To the best of our knowledge, RotatE is the first model that achieves state-of-the-art performance on all the benchmarks. 1 2 RELATED WORK 1 The codes of our paper are available online: https://github.com/DeepGraphLearning/ KnowledgeGraphEmbedding. <ref type="bibr">2</ref> The p-norm of a complex vector v is defined as v p = p |vi| p . We use L1-norm for all distancebased models in this paper and drop the subscript of · 1 for brevity. Predicting missing links with knowledge graph embedding (KGE) methods has been extensively investigated in recent years. The general methodology is to define a score function for the triplets. Formally, let E denote the set of entities and R denote the set of relations, then a knowledge graph is a collection of factual triplets (h, r, t), where h, t ∈ E and r ∈ R. Since entity embeddings are usually represented as vectors, the score function usually takes the form f r (h, t), where h and t are head and tail entity embeddings. The score function f r (h, t) measures the salience of a candidate triplet (h, r, t). The goal of the optimization is usually to score true triplet (h, r, t) higher than the corrupted false triplets (h , r, t) or (h, r, t ). There are also a large body of relational approaches for modeling the relational patterns on knowledge graphs <ref type="bibr" target="#b15">(Lao et al., 2011;</ref><ref type="bibr" target="#b21">Neelakantan et al., 2015;</ref><ref type="bibr" target="#b6">Das et al., 2016;</ref><ref type="bibr" target="#b25">Rocktäschel &amp; Riedel, 2017;</ref>. However, these approaches mainly focus on explicitly modeling the relational paths while our proposed RotatE model implicitly learns the relation patterns, which is not only much more scalable but also provides meaningful embeddings for both entities and relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score Function Symmetry Antisymmetry Inversion Composition</head><formula xml:id="formula_1">SE − Wr,1h − Wr,2t TransE − h + r − t TransX − gr,1(h) + r − gr,2(t) DistMult h, r, t ComplEx Re( h, r, t ) RotatE − h • r − t</formula><p>Another related problem is how to effectively draw negative samples for training knowledge graph embeddings. This problem has been explicitly studied by <ref type="bibr" target="#b5">Cai &amp; Wang (2017)</ref>, which proposed a generative adversarial learning framework to draw negative samples. However, such a framework requires simultaneously training the embedding model and a discrete negative sample generator, which are difficult to optimize and also computationally expensive. We propose a self-adversarial sampling scheme which only relies on the current model. It does require any additional optimization component, which make it much more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ROTATE: RELATIONAL ROTATION IN COMPLEX VECTOR SPACE</head><p>In this section, we introduce our proposed RotatE model. We first introduce three important relation patterns that are widely studied in the literature of link prediction on knowledge graphs. Afterwards, we introduce our proposed RotatE model, which defines relations as rotations in complex vector space. We also show that the RotatE model is able to model and infer all three relation patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MODELING AND INFERRING RELATION PATTERNS</head><p>The key of link prediction in knowledge graph is to infer the connection patterns, e.g., relation patterns, with observed facts. According to the existing literature <ref type="bibr" target="#b28">(Trouillon et al., 2016;</ref><ref type="bibr" target="#b27">Toutanova &amp; Chen, 2015;</ref><ref type="bibr" target="#b9">Guu et al., 2015;</ref><ref type="bibr" target="#b16">Lin et al., 2015a)</ref>, three types of relation patterns are very important and widely spread in knowledge graphs: symmetry, inversion and composition. We give their formal definition here:</p><formula xml:id="formula_2">Definition 1. A relation r is symmetric (antisymmetric) if ∀x, y r(x, y) ⇒ r(y, x) ( r(x, y) ⇒ ¬r(y, x) ) A clause with such form is a symmetry (antisymmetry) pattern. Definition 2. Relation r 1 is inverse to relation r 2 if ∀x, y r 2 (x, y) ⇒ r 1 (y, x) A clause with such form is a inversion pattern. Definition 3. Relation r 1 is composed of relation r 2 and relation r 3 if ∀x, y, z r 2 (x, y) ∧ r 3 (y, z) ⇒ r 1 (x, z) A clause with such form is a composition pattern.</formula><p>According to the definition of the above three types of relation patterns, we provide an analysis of existing models on their abilities in inferring and modeling these patterns. Specifically, we provide an analysis on TransE, TransX, DistMult, and ComplEx. <ref type="bibr">3</ref> We did not include the analysis on HolE and ConvE since HolE is equivalent to ComplEx <ref type="bibr" target="#b11">(Hayashi &amp; Shimbo, 2017)</ref>, and ConvE is a black box that involves two-layer neural networks and convolution operations, which are hard to analyze. The results are summarized into <ref type="table" target="#tab_0">Table 2</ref>. We can see that no existing approaches are capable of modeling all the three relation patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MODELING RELATIONS AS ROTATIONS IN COMPLEX VECTOR SPACE</head><p>In this part, we introduce our proposed model that is able to model and infer all the three types of relation patterns. Inspired by Euler's identity, we map the head and tail entities h, t to the complex embeddings, i.e., h, t ∈ C k ; then we define the functional mapping induced by each relation r as an element-wise rotation from the head entity h to the tail entity t. In other words, given a triple (h, r, t), we expect that:</p><formula xml:id="formula_3">t = h • r, where |r i | = 1,<label>(2)</label></formula><p>and • is the Hadmard (or element-wise) product. Specifically, for each element in the embeddings, we have t i = h i r i . Here, we constrain the modulus of each element of r ∈ C k , i.e., r i ∈ C, to be |r i | = 1. By doing this, r i is of the form e iθr,i , which corresponds to a counterclockwise rotation by θ r,i radians about the origin of the complex plane, and only affects the phases of the entity embeddings in the complex vector space. We refer to the proposed model as RotatE due to its rotational nature. According to the above definition, for each triple (h, r, t), we define the distance function of RotatE as:</p><formula xml:id="formula_4">d r (h, t) = h • r − t<label>(3)</label></formula><p>By defining each relation as a rotation in the complex vector spaces, RotatE can model and infer all the three types of relation patterns introduced above. Formally, we have following results 4 :</p><p>3 See discussion at Appendix A <ref type="bibr">4</ref> We relegate all proofs to the appendix. <ref type="table" target="#tab_0">FB15k  14,951  1,345  483,142  50,000  59,071  WN18  40,943  18  141,442  5,000  5,000  FB15k-237 14,541  237  272,115  17,535  20,466  WN18RR  40,943  11  86,835  3,034  3,</ref> <ref type="bibr">134</ref>  These results are also summarized into <ref type="table" target="#tab_0">Table 2</ref>. We can see that the RotatE model is the only model that can model and infer all the three types of relation patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset #entity #relation #training #validation #test</head><p>Connection to TransE. From <ref type="table" target="#tab_0">Table 2</ref>, we can see that TransE is able to infer and model all the other relation patterns except the symmetry pattern. The reason is that in TransE, any symmetric relation will be represented by a 0 translation vector. As a result, this will push the entities with symmetric relations to be close to each other in the embedding space. RotatE solves this problem and is a able to model and infer the symmetry pattern. An arbitrary vector r that satisfies r i = ±1 can be used for representing a symmetric relation in RotatE, and thus the entities having symmetric relations can be distinguished. Different symmetric relations can be also represented with different embedding vectors. <ref type="figure">Figure 1</ref> provides illustrations of TransE and RotatE with only 1-dimensional embedding and shows how RotatE models a symmetric relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">OPTIMIZATION</head><p>Negative sampling has been proved quite effective for both learning knowledge graph embedding <ref type="bibr" target="#b28">(Trouillon et al., 2016)</ref> and word embedding <ref type="bibr" target="#b19">(Mikolov et al., 2013)</ref>. Here we use a loss function similar to the negative sampling loss <ref type="bibr" target="#b19">(Mikolov et al., 2013)</ref> for effectively optimizing distance-based models:</p><formula xml:id="formula_5">L = − log σ(γ − d r (h, t)) − n i=1 1 k log σ(d r (h i , t i ) − γ),<label>(4)</label></formula><p>where γ is a fixed margin, σ is the sigmoid function, and (h i , r, t i ) is the i-th negative triplet.</p><p>We also propose a new approach for drawing negative samples. The negative sampling loss samples the negative triplets in a uniform way. Such a uniform negative sampling suffers the problem of inefficiency since many samples are obviously false as training goes on, which does not provide any meaningful information. Therefore, we propose an approach called self-adversarial negative sampling, which samples negative triples according to the current embedding model. Specifically, we sample negative triples from the following distribution:</p><formula xml:id="formula_6">p(h j , r, t j |{(h i , r i , t i )}) = exp αf r (h j , t j ) i exp αf r (h i , t i )<label>(5)</label></formula><p>where α is the temperature of sampling. Moreover, since the sampling procedure may be costly, we treat the above probability as the weight of the negative sample. Therefore, the final negative sampling loss with self-adversarial training takes the following form:</p><formula xml:id="formula_7">L = − log σ(γ − d r (h, t)) − n i=1 p(h i , r, t i ) log σ(d r (h i , t i ) − γ)<label>(6)</label></formula><p>In the experiments, we will compare different approaches for negative sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">EXPERIMENTAL SETTING</head><p>We evaluate our proposed model on four widely used knowledge graphs. The statistics of these knowledge graphs are summarized into <ref type="table" target="#tab_2">Table 3</ref>.</p><p>• FB15k <ref type="bibr" target="#b3">(Bordes et al., 2013</ref>) is a subset of Freebase <ref type="bibr" target="#b0">(Bollacker et al., 2008)</ref>, a large-scale knowledge graph containing general knowledge facts. <ref type="bibr" target="#b27">Toutanova &amp; Chen (2015)</ref> showed that almost 81% of the test triplets (x, r, y) can be inferred via a directly linked triplet (x, r , y) or (y, r , x). Therefore, the key of link prediction on FB15k is to model and infer the symmetry/antisymmetry and inversion patterns.</p><p>• WN18 <ref type="bibr" target="#b3">(Bordes et al., 2013</ref>) is a subset of WordNet <ref type="bibr" target="#b20">(Miller, 1995)</ref>, a database featuring lexical relations between words. This dataset also has many inverse relations. So the main relation patterns in WN18 are also symmetry/antisymmetry and inversion.</p><p>• FB15k-237 <ref type="bibr" target="#b27">(Toutanova &amp; Chen, 2015)</ref> is a subset of FB15k, where inverse relations are deleted. Therefore, the key of link prediction on FB15k-237 boils down to model and infer the symmetry/antisymmetry and composition patterns.</p><p>• WN18RR <ref type="bibr" target="#b7">(Dettmers et al., 2017</ref>) is a subset of WN18. The inverse relations are deleted, and the main relation patterns are symmetry/antisymmetry and composition.</p><p>Hyperparameter Settings. We use Adam (Kingma &amp; Ba, 2014) as the optimizer and fine-tune the hyperparameters on the validation dataset. The ranges of the hyperparameters for the grid search are set as follows: embedding dimension 5 k ∈ {125, 250, 500, 1000}, batch size b ∈ {512, 1024, 2048}, self-adversarial sampling temperature α ∈ {0.5, 1.0}, and fixed margin γ ∈ {3, 6, 9, 12, 18, 24, 30}.</p><p>Both the real and imaginary parts of the entity embeddings are uniformly initialized, and the phases of the relation embeddings are uniformly initialized between 0 and 2π. No regularization is used since we find that the fixed margin γ could prevent our model from over-fitting.</p><p>Evaluation Settings. We evaluate the performance of link prediction in the filtered setting: we rank test triples against all other candidate triples not appearing in the training, validation, or test set, where candidates are generated by corrupting subjects or objects: (h , r, t) or (h, r, t ). Mean Rank (MR), Mean Reciprocal Rank (MRR) and Hits at N (H@N) are standard evaluation measures for these datasets and are evaluated in our experiments.</p><p>Baseline. Apart from RotatE, we propose a variant of RotatE as baseline, where the modulus of the entity embeddings are also constrained: |h i | = |t i | = C, and the distance function is thus 2C sin θ h +θr−θt 2 (See Equation 17 at Appendix F for a detailed derivation). In this way, we can investigate how RotatE works without modulus information and with only phase information. We refer to the baseline as pRotatE. It is obvious to see that pRotatE can also model and infer all the three relation patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MAIN RESULTS</head><p>We compare RotatE to several state-of-the-art models, including TransE <ref type="bibr" target="#b3">(Bordes et al., 2013)</ref>, Dist-Mult <ref type="bibr" target="#b32">(Yang et al., 2014)</ref>, ComplEx <ref type="bibr" target="#b28">(Trouillon et al., 2016)</ref>, HolE <ref type="bibr" target="#b24">(Nickel et al., 2016)</ref>, and ConvE <ref type="bibr" target="#b7">(Dettmers et al., 2017)</ref>, as well as our baseline model pRotatE, to empirically show the importance of modeling and inferring the relation patterns for the task of predicting missing links. <ref type="table" target="#tab_4">Table 4</ref> summarizes our results on FB15k and WN18. We can see that RotatE outperforms all the state-of-the-art models. The performance of pRotatE and RotatE are similar on these two datasets. <ref type="table" target="#tab_5">Table 5</ref> summarizes our results on FB15k-237 and WN18RR, where the improvement is much more significant. The difference between RotatE and pRotatE is much larger on FB15k-237 and   Moreover, the performance of these models on different datasets is consistent with our analysis on the three relation patterns <ref type="table" target="#tab_0">(Table 2)</ref>:</p><p>• On FB15K, the main relation patterns are symmetry/antisymmetry and inversion. We can see that ComplEx performs well while TransE does not perform well since Com-plEx can infer both symmetry/antisymmetry and inversion patterns while TransE cannot infer symmetry pattern. Surprisingly, DistMult achieves good performance on this dataset although it cannot model the antisymmetry and inversion patterns. The reason is that for most of the relations in FB15K, the types of head entities and tail entities are different. Although DistMult gives the same score to a true triplet (h, r, t) and its opposition triplet (t, r, h), (t, r, h) is usually impossible to be valid since the entity type of t does not match the head entity type of h. For example, DistMult assigns the same score to (Obama, nationality, USA) and (USA, nationality, Obama). But (USA, nationality, Obama) can be simply predicted as false since USA cannot be the head entity of the relation nationality.</p><p>• On WN18, the main relation patterns are also symmetry/antisymmetry and inversion. As expected, ComplEx still performs very well on this dataset. However, different from the results on FB15K, the performance of DistMult significantly decreases on WN18. The reason is that DistMult cannot model antisymmetry and inversion patterns, and almost all the entities in WN18 are words and belong to the same entity type, which do not have the same problem as FB15K.</p><p>• On FB15k-237, the main relation pattern is composition. We can see that TransE performs really well while ComplEx does not perform well. The reason is that, as discussed before, TransE is able to infer the composition pattern while ComplEx cannot infer the composition pattern.</p><p>• On WN18RR, one of the main relation patterns is the symmetry pattern since almost each word has a symmetric relation in WN18RR, e.g., also see and similar to. TransE does not well on this dataset since it is not able to model the symmetric relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Countries (AUC-PR) DistMult</head><p>ComplEx ConvE RotatE S1 1.00 ± 0.00 0.97 ± 0.02 1.00 ± 0.00 1.00 ± 0.00 S2 0.72 ± 0.12 0.57 ± 0.10 0.99 ± 0.01 1.00 ± 0.00 S3</p><p>0.52 ± 0.07 0.43 ± 0.07 0.86 ± 0.05 0.95 ± 0.00 <ref type="table">Table 6</ref>: Results on the Countries datasets. Other results are taken from <ref type="bibr" target="#b7">(Dettmers et al., 2017)</ref>. The symmetry, inversion and composition pattern is represented in <ref type="figure" target="#fig_1">Figure 2a</ref>, 2c and 2g, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">INFERRING RELATION PATTERNS ON COUNTRIES DATASET</head><p>We also evaluate our model on the Countries dataset <ref type="bibr" target="#b4">(Bouchard et al., 2015;</ref><ref type="bibr" target="#b24">Nickel et al., 2016)</ref>, which is carefully designed to explicitly test the capabilities of the link prediction models for composition pattern modeling and inferring. It contains 2 relations and 272 entities (244 countries, 5 regions and 23 subregions). Unlike link prediction on general knowledge graphs, the queries in Countries are of the form locatedIn <ref type="bibr">(c, ?)</ref>, and the answer is one of the five regions. The Countries dataset has 3 tasks, each requiring inferring a composition pattern with increasing length and difficulty. For example, task S2 requires inferring a relatively simpler composition pattern: neighborOf(c 1 , c 2 ) ∧ locatedIn(c 2 , r) ⇒ locatedIn(c 1 , r), while task S3 requires inferring the most complex composition pattern:</p><formula xml:id="formula_8">neighborOf(c 1 , c 2 ) ∧ locatedIn(c 2 , s) ∧ locatedIn(s, r) ⇒ locatedIn(c 1 , r).</formula><p>In <ref type="table">Table 6</ref>, we report the results with respect to the AUC-PR metric, which is commonly used in the literature. We can see that RotatE outperforms all the previous models. The performance of RotatE is significantly better than other methods on S3, which is the most difficult task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">IMPLICIT RELATION PATTERN INFERENCE</head><p>In this section, we verify whether the relation patterns are implicitly represented by RotatE relation embeddings. We ignore the specific positions in the relation embedding θ r and plot the histogram of the phase of each element in the relation embedding, i.e., {θ r,i }.</p><p>Symmetry pattern requires the symmetric relations to have property r • r = 1, and the solution is r i = ±1. We investigate the relation embeddings from a 500-dimensional RotatE trained on WN18. <ref type="figure" target="#fig_1">Figure 2a</ref> gives the histogram of the embedding phases of a symmetric relation similar to. We can find that the embedding phases are either π (r i = −1) or 0, 2π (r i = 1). It indicates that the RotatE  1.00 ± 0.00 1.00 ± 0.00 0.95 ± 0.00 model does infer and model the symmetry pattern. <ref type="figure" target="#fig_1">Figure 2b</ref> is the histogram of relation hypernym, which shows that the embedding of a general relation does not have such a ±1 pattern.</p><p>Inversion pattern requires the embeddings of a pair of inverse relations to be conjugate. We use the same RotatE model trained on WN18 for an analysis. <ref type="figure" target="#fig_1">Figure 2c</ref> illustrates the element-wise addition of the embedding phases from relation r 1 = hypernym and its inversed relation r 2 = hyponym. All the additive embedding phases are 0 or 2π, which represents that r 1 = r −1 2 . This case shows that the inversion pattern is also inferred and modeled in the RotatE model.</p><p>Composition pattern requires the embedding phases of the composed relation to be the addition of the other two relations. Since there is no significant composition pattern in WN18, we study the inference of the composition patterns on FB15k-237, where a 1000-dimensional RotatE is trained. <ref type="figure" target="#fig_1">Figure 2d</ref> -2g illustrate such a r 1 = r 2 • r 3 case, where θ 2,i + θ 3,i = θ 1,i or θ 2,i + θ 3,i = θ 1,i + 2π.</p><p>More results of implicitly inferring basic patterns are presented in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">COMPARING DIFFERENT NEGATIVE SAMPLING TECHNIQUES</head><p>In this part, we compare different negative sampling techniques including uniform sampling, our proposed self-adversarial technique, and the KBGAN model <ref type="bibr" target="#b5">(Cai &amp; Wang, 2017)</ref>, which aims to optimize a generative adversarial network to generate the negative samples. We re-implement a 50dimension TransE model with the margin-based ranking criterion that was used in <ref type="bibr" target="#b5">(Cai &amp; Wang, 2017)</ref>, and evaluate its performance on FB15k-237, WN18RR and WN18 with self-adversarial negative sampling. <ref type="table" target="#tab_7">Table 7</ref> summarizes our results. We can see that self-adversarial sampling is the most effective negative sampling technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">FURTHER EXPERIMENTS ON TRANSE AND COMPLEX</head><p>One may argue that the contribution of RotatE comes from the self-adversarial negative sampling technique. In this part, we conduct further experiments on TransE and ComplEx in the same setting as RotatE to make a fair comparison among the three models. <ref type="table" target="#tab_8">Table 8</ref> shows the results of TransE and ComplEx trained with the self-adversarial negative sampling technique on FB15k and FB15k-237 datasets, where a large number of relations are available. In addition, we evaluate these three models on the Countries dataset, which explicitly requires inferring the composition pattern. We also provide a detailed ablation study on TransE and RotatE in the appendix.</p><p>From <ref type="table" target="#tab_8">Table 8</ref>, we can see that similar results are observed as <ref type="table" target="#tab_4">Table 4</ref> and 5. The RotatE model achieves the best performance on both FB15k and FB15k-237, as it is able to model all the three relation patterns. The TransE model does not work well on the FB15k datasets, which requires modeling the symmetric pattern; the ComplEx model does not work well on FB15k-237, which requires modeling the composition pattern. The results on the Countries dataset are a little bit different, where the TransE model slightly outperforms RoateE on the S3 task. The reason is that Relation Category 1-to-1 1-to-N N-to-1 N-to-N 1-to-1 1-to-N N-to-1 N-to-N Tasks Prediction Head <ref type="formula" target="#formula_0">(Hits@10</ref>  <ref type="table">Table 9</ref>: Experimental results on FB15k by relation category. The first three rows are taken from <ref type="bibr" target="#b12">(He et al., 2015)</ref>. The rest of the results are from RotatE trained with the self-adversarial negative sampling technique.</p><p>the Countries datasets do not have the symmetric relation between different regions, and all the three tasks in the Countries datasets only require inferring the region for a given city. Therefore, the TransE model does not suffer from its inability of modeling symmetric relations. For ComplEx, we can see that it does not perform well on Countries since it cannot infer the composition pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">EXPERIMENTAL RESULTS ON FB15K BY RELATION CATEGORY</head><p>We also did some further investigation on the performance of RotatE on different relation categories: one-to-many, many-to-one, and many-to-many relations 6 . The results of RotatE on different relation categories on the data set FB15k are summarized into <ref type="table">Table 9</ref>. We also compare an additional approach KG2E KL <ref type="bibr" target="#b12">(He et al., 2015)</ref>, which is a probabilistic framework for knowledge graph embedding methods and aims to model the uncertainties of the entities and relations in knowledge graphs with the TransE model. We also summarize the statistics of different relation categories into <ref type="table" target="#tab_1">Table 10</ref> in the appendix.</p><p>We can see that besides the one-to-one relation, the RotatE model also performs quite well on the non-injective relations, especially on many-to-many relations. We also notice that the probabilistic framework KG2E KL(bern) <ref type="bibr" target="#b12">(He et al., 2015)</ref> is quite powerful, which consistently outperforms its corresponding knowledge graph embedding model, showing the importance of modeling the uncertainties in knowledge graphs. We leave the work of modeling the uncertainties in knowledge graphs with RotatE as our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We TransX can infer and model the symmetry/antisymmetry pattern when g r,1 = g r,2 , e.g. in TransH <ref type="bibr" target="#b29">(Wang et al., 2014)</ref>, but cannot infer inversion and composition as g r,1 and g r,2 are invertible matrix multiplications; due to its symmetric nature, DistMult is difficult to model the asymmetric and inversion pattern; ComplEx addresses the problem of DisMult and is able to infer both the symmetry and asymmetric patterns with complex embeddings. Moreover, it can infer inversion rules because the complex conjugate of the solution to arg max r Re( x, r, y ) is exactly the solution to arg max r Re( y, r, x ). However, ComplEx cannot infer composition rules, since it does not model a bijection mapping from h to t via relation r. These concerns are summarized in </p><formula xml:id="formula_9">= r • x ∧ x = r • y ⇒ r • r = 1 C PROOF OF LEMMA 2</formula><p>Proof. if r 1 (x, y) and r 2 (y, x) hold, we have</p><formula xml:id="formula_10">y = r 1 • x ∧ x = r 2 • y ⇒ r 1 = r −1 2 D PROOF OF LEMMA 3</formula><p>Proof. if r 1 (x, z), r 2 (x, y) and r 3 (y, z) hold, we have z = r 1 • x ∧ y = r 2 • x ∧ z = r 3 • y ⇒ r 1 = r 2 • r 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E PROPERTIES OF ROTATE</head><p>A useful property for RotatE is that the inverse of a relation can be easily acquired by complex conjugate. In this way, the RotatE model treats head and tail entities in a uniform way, which is potentially useful for efficient 1-N scoring <ref type="bibr" target="#b7">(Dettmers et al., 2017)</ref>:</p><formula xml:id="formula_11">h • r − t = (h • r − t) • r = t • r − h<label>(7)</label></formula><p>Moreover, considering the embeddings in the polar form, i.e., h i = m h,i e iθ h,i , r i = e iθr,i , t i = m t,i e iθt,i , we can rewrite the RotatE distance function as:</p><formula xml:id="formula_12">h • r − t = k i=1 (m h,i − m t,i ) 2 + 4m h,i m t,i sin 2 θ h,i + θ r,i − θ t,i 2<label>(8)</label></formula><p>This equation provides two interesting views of the model:</p><p>(1) When we constrain the modulus m h,i = m t,i = C, the distance function is reduced to 2C sin θ h +θr−θt 2 . We can see that this is very similar to the distance function of TransE: h + r − t . Based on this intuition, we can show that: (2) The modulus provides the lower bound of the distance function, which is m h − m t .   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F PROOF OF THEOREM 4</head><p>Proof. By further restricting |h i | = |t i | = C, we can rewrite h, r, t by</p><formula xml:id="formula_13">h = Ce iθ h = C cos θ h + iC sin θ h<label>(9)</label></formula><p>r = e iθr = cos θ r + i sin θ r (10)</p><formula xml:id="formula_14">t = Ce iθt = C cos θ t + iC sin θ t (11) (12) Therefore, we have h • r − t = C e i(θ h +θr) − e iθt = C e i(θ h +θr−θt) − 1 (13) = C cos(θ h + θ r − θ t ) − 1 + i sin(θ h + θ r − θ t ) (14) = C (cos(θ h + θ r − θ t ) − 1) 2 + sin 2 (θ h + θ r − θ t ) (15) = C 2 − 2 cos(θ h + θ r − θ t ) (16) = 2C sin θ h + θ r − θ t 2<label>(17)</label></formula><p>If the embedding of (h, r, t) in TransE is h , r , t , let θ h = ch , θ r = cr , θ t = ct and C = 1/c , we have</p><formula xml:id="formula_15">lim c→0 h • r − t = h + r − t G LINK PREDICTION ON YAGO3-10</formula><p>YAGO3-10 is a subset of YAGO3 <ref type="bibr" target="#b18">(Mahdisoltani et al., 2013)</ref>, which consists of entities that have a minimum of 10 relations each. It has 123,182 entities and 37 relations. Most of the triples deal with descriptive attributes of people, such as citizenship, gender, profession and marital status.  <ref type="table" target="#tab_1">Table 13</ref>: Results of ablation study on FB15k-237, where "adv" represents "self-adversarial".</p><p>I ABLATION STUDY <ref type="table" target="#tab_1">Table 13</ref> shows our ablation study of self-adversarial sampling and negative sampling loss on FB15k-237. We also re-implement a 1000-dimension TransE and do ablation study on it. From the table, We can find that self-adversarial sampling boosts the performance for both models, while negative sampling loss is only effective on RotatE; in addition, our re-implementation of TransE also outperforms all the state-of-the-art models on FB15k-237.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J VARIANCE OF THE RESULTS</head><p>In <ref type="table" target="#tab_1">Table 14</ref>, We provide the average and variance of the MRR results on FB15k, WN18, FB15k-237 and WN18RR. Both the average and the variance is calculated by three runs of RotatE with difference random seeds. We can find that the performance of RotatE is quite stable for different random initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K MORE RESULTS OF IMPLICIT BASIC PATTERN INFERENCE</head><p>We provide more histograms of embedding phases in <ref type="figure">Figure 3</ref> -5.</p><p>FB15k WN18 FB15k-237 WN18RR MRR .797 ± .001 .949 ± .000 .337 ± .001 .477 ± .001   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( a )Figure 1 :</head><label>a1</label><figDesc>TransE models r as translation in real line. (b) RotatE models r as rotation in complex plane. (c) RotatE: an example of modeling symmetric relations r with ri = −1 Illustrations of TransE and RotatE with only 1 dimension of embedding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Histograms of relation embedding phases {θ r,i } (r i = e iθr,i ), where for 1 represents relation award nominee/award nominations./award/award nomination/nominated for, winner represents relation award category/winners./award/award honor/award winner and for 2 represents award category/nominees./award/award nomination/nominated for.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Theorem 4. RotatE can degenerate into TransE. (See proof at Appendix F) which indicates that RotatE is able to simulate TransE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Histograms of embedding phases from two general relations and four symmetric relations on WN18. ( k = 500 ) /award/award winner-/awards won./award/award honor-/location/statistical region-/places exported to./location-/imports and exports/exported to Histograms of embedding phases from six symmetric relations on FB15k-237. (k = 1000) instance hypernym • instance hyponym</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Histograms of element-wise additions of inversed relation embedding phases on WN18. (k = 500)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>The pattern modeling and inference abilities of several models.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>each relation</cell></row></table><note>summarizes different score functions f r (h, t) in previous state-of-the-art methods as well as the model proposed in this paper. These models gen- erally capture only a portion of the relation patterns. For example, TransE represents</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Number of entities, relations, and observed triples in each split for four benchmarks.</figDesc><table /><note>Lemma 1. RotatE can infer the symmetry/antisymmetry pattern. (See proof in Appendix B) Lemma 2. RotatE can infer the inversion pattern. (See proof in Appendix C) Lemma 3. RotatE can infer the composition pattern. (See proof in Appendix D)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Results of several models evaluated on the FB15K and WN18 datasets. Results of [♥] are taken from<ref type="bibr" target="#b24">(Nickel et al., 2016)</ref> and results of [♦] are taken from<ref type="bibr" target="#b13">(Kadlec et al., 2017)</ref>. Other results are taken from the corresponding original papers.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">FB15k-237</cell><cell></cell><cell></cell><cell></cell><cell>WN18RR</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">MR MRR H@1 H@3 H@10</cell><cell>MR</cell><cell cols="4">MRR H@1 H@3 H@10</cell></row><row><cell cols="2">TransE [♥] 357</cell><cell>.294</cell><cell>-</cell><cell>-</cell><cell>.465</cell><cell>3384</cell><cell>.226</cell><cell>-</cell><cell>-</cell><cell>.501</cell></row><row><cell>DistMult</cell><cell>254</cell><cell>.241</cell><cell>.155</cell><cell>.263</cell><cell>.419</cell><cell>5110</cell><cell>.43</cell><cell>.39</cell><cell>.44</cell><cell>.49</cell></row><row><cell>ComplEx</cell><cell>339</cell><cell>.247</cell><cell>.158</cell><cell>.275</cell><cell>.428</cell><cell>5261</cell><cell>.44</cell><cell>.41</cell><cell>.46</cell><cell>.51</cell></row><row><cell>ConvE</cell><cell>244</cell><cell>.325</cell><cell>.237</cell><cell>.356</cell><cell>.501</cell><cell>4187</cell><cell>.43</cell><cell>.40</cell><cell>.44</cell><cell>.52</cell></row><row><cell>pRotatE</cell><cell>178</cell><cell>.328</cell><cell>.230</cell><cell>.365</cell><cell>.524</cell><cell>2923</cell><cell>.462</cell><cell>.417</cell><cell>.479</cell><cell>.552</cell></row><row><cell>RotatE</cell><cell>177</cell><cell>.338</cell><cell>.241</cell><cell>.375</cell><cell>.533</cell><cell>3340</cell><cell>.476</cell><cell>.428</cell><cell>.492</cell><cell>.571</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Results of several models evaluated on the FB15k-237 and WN18RR datasets. Results of [♥] are taken from (Nguyen et al., 2017). Other results are taken from (Dettmers et al., 2017).WN18RR, where there are a lot of composition patterns. This indicates that modulus is very impor- tant for modeling and inferring the composition pattern.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>TransE with different negative sampling techniques. The results in first 2 rows are taken from<ref type="bibr" target="#b5">(Cai &amp; Wang, 2017)</ref>, where KBGAN uses a ComplEx negative sample generator.</figDesc><table><row><cell></cell><cell cols="2">FB15k</cell><cell cols="2">FB15k-237</cell><cell></cell><cell>Countries (AUC-ROC)</cell></row><row><cell></cell><cell cols="4">MRR H@10 MRR H@10</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell></row><row><cell>TransE</cell><cell>.735</cell><cell>.871</cell><cell>.332</cell><cell>.531</cell><cell cols="2">1.00 ± 0.00 1.00 ± 0.00 0.96 ± 0.00</cell></row><row><cell cols="2">ComplEx .780</cell><cell>.890</cell><cell>.319</cell><cell>.509</cell><cell cols="2">1.00 ± 0.00 0.98 ± 0.00</cell><cell>0.88 ± 0.01</cell></row><row><cell>RotatE</cell><cell>.797</cell><cell>.884</cell><cell>.338</cell><cell>.533</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Results of TransE and ComplEx with self-adversarial sampling and negative sampling loss on FB15k, FB15k-237 and Countries datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>have proposed a new knowledge graph embedding method called RotatE, which represents entities as complex vectors and relations as rotations in complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Our experimental results show that the RotatE model outperforms all existing state-of-theart models on four large-scale benchmarks. Moreover, RotatE also achieves state-of-the-art results on a benchmark that is explicitly designed for composition pattern inference and modeling. A deep investigation into RotatE relation embeddings shows that the three relation patterns are implicitly represented in the relation embeddings. In the future, we plan to evaluate the RotatE model on more datasets and leverage a probabilistic framework to model the uncertainties of entities and relations.APPENDIX A DISCUSSION ON THE ABILITY OF PATTERN MODELING AND INFERENCE No existing models are capable of modeling all the three relation patterns. For example, TransE cannot model the symmetry pattern because it would yield r = 0 for symmetric relations;</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Statistics of FB15k by mapping properties of relations.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">YAGO3-10</cell><cell></cell></row><row><cell></cell><cell cols="5">MR MRR H@1 H@3 H@10</cell></row><row><cell cols="2">DistMult 5926</cell><cell>.34</cell><cell>.24</cell><cell>.38</cell><cell>.54</cell></row><row><cell cols="2">ComplEx 6351</cell><cell>.36</cell><cell>.26</cell><cell>.40</cell><cell>.55</cell></row><row><cell>ConvE</cell><cell>1671</cell><cell>.44</cell><cell>.35</cell><cell>.49</cell><cell>.62</cell></row><row><cell>RotatE</cell><cell cols="2">1767 .495</cell><cell>.402</cell><cell>.550</cell><cell>.670</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>Results of several models evaluated on the YAGO3-10 datasets. Other results are taken from<ref type="bibr" target="#b7">(Dettmers et al., 2017)</ref>.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 Table 12 :</head><label>1112</label><figDesc>shows that the RotatE model also outperforms state-of-the-art models on YAGO3-10. The best hyperparameter setting of RotatE on several benchmarks.</figDesc><table><row><cell>H HYPERPARAMETERS</cell></row><row><cell>We list the best hyperparameter setting of RotatE w.r.t the validation dataset on several benchmarks</cell></row><row><cell>in Table 12.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>The average and variance of the MRR results of RotatE on FB15k, WN18, FB15k-237 and WN18RR.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5"> Following Trouillon et al. (2016), we treat complex number as the same as real number with regard to the embedding dimension. If the same number of dimension is used for both the real and imaginary parts of the complex number as the real number, the number of parameters for the complex embedding would be twice the number of parameters for the embeddings in the real space.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6"> Following Wang et al. (2014), for each relation r, we compute the average number of tails per head (tphr) and the average number of head per tail (hptr). If tphr &lt; 1.5 and hptr &lt; 1.5, r is treated as one-to-one; if tphr ≥ 1.5 and hptr ≥ 1.5, r is treated as a many-to-many; if tphr &lt; 1.5 and hptr ≥ 1.5, r is treated as one-to-many.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">ACM SIGMOD international conference on Management of data</title>
		<imprint>
			<publisher>AcM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning structured embeddings of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On approximate reasoning capabilities of low-rank vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Trouillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Syposium on Knowledge Representation and Reasoning (KRR): Integrating Symbolic and Neural Approaches</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kbgan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04071</idno>
		<title level="m">Adversarial learning for knowledge graph embeddings</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Chains of reasoning over entities, relations, and text using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01426</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01476</idno>
		<title level="m">Convolutional 2d knowledge graph embeddings</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Toruse: Knowledge graph embedding on a lie group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuma</forename><surname>Ebisu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryutaro</forename><surname>Ichise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1819" to="1826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Traversing knowledge graphs in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.01094</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An endto-end model for question answering over knowledge base with cross-attention combining global knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="221" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">On the equivalence of holographic and complex embeddings for link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhiko</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Shimbo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05563</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to represent knowledge graphs with gaussian embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Knowledge base completion: Baselines strike back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bajgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kleindienst</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10744</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Random walk inference and learning in a large scale knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="529" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Modeling relation paths for representation learning of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.00379</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Yago3: A knowledge base from multilingual wikipedias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farzaneh</forename><surname>Mahdisoltani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Compositional vector space models for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.06662</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02121</idno>
		<title level="m">Dat Quoc Nguyen, and Dinh Phung. A novel embedding model for knowledge base completion based on convolutional neural network</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Stranse: a novel embedding model of entities and relationships in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kairit</forename><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Sirts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08140</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tomaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">End-to-end differentiable proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3788" to="3800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Explicit semantic ranking for academic search via knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web</title>
		<meeting>the 26th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1271" to="1279" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Leveraging knowledge bases in lstms for improving machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1436" to="1446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Differentiable learning of logical rules for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno>abs/1702.08367</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">Jing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
