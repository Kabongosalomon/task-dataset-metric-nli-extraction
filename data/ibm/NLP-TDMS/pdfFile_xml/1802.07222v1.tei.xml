<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">007: Democratically Finding The Cause of Packet Drops (Extended Version)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnaz</forename><surname>Arzani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Selim</forename><surname>Ciraci</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luiz</forename><surname>Chamon</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongqiang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitu</forename><surname>Padhye</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boon</forename><forename type="middle">Thau</forename><surname>Loo</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Outhred</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">007: Democratically Finding The Cause of Packet Drops (Extended Version)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Network failures continue to plague datacenter operators as their symptoms may not have direct correlation with where or why they occur. We introduce 007, a lightweight, always-on diagnosis application that can find problematic links and also pinpoint problems for each TCP connection. 007 is completely contained within the end host. During its two month deployment in a tier-1 datacenter, it detected every problem found by previously deployed monitoring tools while also finding the sources of other problems previously undetected.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Introduction 007 has an ambitious goal: for every packet drop on a TCP flow in a datacenter, find the link that dropped the packet and do so with negligible overhead and no changes to the network infrastructure.</p><p>This goal may sound like an overkill-after all, TCP is supposed to be able to deal with a few packet losses. Moreover, packet losses might occur due to congestion instead of network equipment failures. Even network failures might be transient. Above all, there is a danger of drowning in a sea of data without generating any actionable intelligence.</p><p>These objections are valid, but so is the need to diagnose "failures" that can result in severe problems for applications. For example, in our datacenters, VM images are stored in a storage service. When a VM boots, the image is mounted over the network. Even a small network outage or a few lossy links can cause the VM to "panic" and reboot. In fact, 17% of our VM reboots are due to network issues and in over 70% of these none of our monitoring tools were able to find the links that caused the problem.</p><p>VM reboots affect customers and we need to understand their root cause. Any persistent pattern in such transient failures is a cause for concern and is potentially actionable. One example is silent packet drops <ref type="bibr" target="#b0">[1]</ref>. These types of problems are nearly impossible to detect with traditional monitoring tools (e.g., SNMP). If a switch is experiencing these problems, we may want to reboot or replace it. These interventions are "costly" as they affect a large number of flows/VMs. Therefore, careful blame assignment is necessary. Naturally, this is only one example that would benefit from such a detection system.</p><p>There is a lot of prior work on network failure diagnosis, though one of the existing systems meet our ambitious goal. Pingmesh <ref type="bibr" target="#b0">[1]</ref> sends periodic probes to detect failures and can leave "gaps" in coverage, as it must manage the overhead of probing. Also, since it uses out-of-band probes, it cannot detect failures that affect only in-band data. Roy et al. <ref type="bibr" target="#b1">[2]</ref> monitor all paths to detect failures but require modifications to routers and special features in the switch ( §10). Everflow <ref type="bibr" target="#b2">[3]</ref> can be used to find the location of packet drops but it would require capturing all traffic and is not scalable. We asked our operators what would be the most useful solution for them. Responses included: "In a network of ≥ 10 6 links its a reasonable assumption that there is a non-zero chance that a number (&gt; 10) of these links are bad (due to device, port, or cable, etc.) and we cannot fix them simultaneously. Therefore, fixes need to be prioritized based on customer impact. However, currently we do not have a direct way to correlate customer impact with bad links". This shows that current systems do not satisfy operator needs as they do not provide application and connection level context.</p><p>To address these limitations, we propose 007, a simple, lightweight, always-on monitoring tool. 007 records the path of TCP connections (flows) suffering from one or more retransmissions and assigns proportional "blame" to each link on the path. It then provides a ranking of links that represents their relative drop rates. Using this ranking, it can find the most likely cause of drops in each TCP flow. 007 has several noteworthy properties. First, it does not require any changes to the existing networking infrastructure. Second, it does not require changes to the client software-the monitoring agent is an independent entity that sits on the side. Third, it detects in-band failures. Fourth, it continues to perform well in the presence of noise (e.g. lone packet drops). Finally, it's overhead is negligible.</p><p>While the high-level design of 007 appear simple, the practical challenges of making 007 work and the theoretical challenge of proving it works are non-trivial. For example, its path discovery is based on a traceroute-like approach. Due to the use of ECMP, traceroute packets have to be carefully crafted to ensure that they follow the same path as the TCP flow. Also, we must ensure that we do not overwhelm routers by sending too many traceroutes (traceroute responses are handled by control-plane CPUs of routers, which are quite puny). Thus, we 1 arXiv:1802.07222v1 [cs.NI] 20 Feb 2018 need to ensure that our sampling strikes the right balance between accuracy and the overhead on the switches. On the theoretical side, we are able to show that 007's simple blame assignment scheme is highly accurate even in the presence of noise.</p><p>We make the following contributions: (i) we design 007, a simple, lightweight, and yet accurate fault localization system for datacenter networks; (ii) we prove that 007 is accurate without imposing excessive burden on the switches; (iii) we prove that its blame assignment scheme correctly finds the failed links with high probability; and (iv) we show how to tackle numerous practical challenges involved in deploying 007 in a real datacenter.</p><p>Our results from a two month deployment of 007 in a datacenter show that it finds all problems found by other previously deployed monitoring tools while also finding the sources of problems for which information is not provided by these monitoring tools.</p><p>2 Motivation 007 aims to identify the cause of retransmissions with high probability. It is is driven by two practical requirements: (i) it should scale to datacenter size networks and (ii) it should be deployable in a running datacenter with as little change to the infrastructure as possible. Our current focus is mainly on analyzing infrastructure traffic, especially connections to services such as storage as these can have severe consequences (see §1, <ref type="bibr" target="#b3">[4]</ref>). Nevertheless, the same mechanisms can be used in other contexts as well (see §9). We deliberately include congestioninduced retransmissions. If episodes of congestion, however short-lived, are common on a link, we want to be able to flag them. Of course, in practice, any such system needs to deal with a certain amount of noise, a concept we formalize later.</p><p>There are a number of ways to find the cause of packet drops. One can monitor switch counters. These are inherently unreliable <ref type="bibr" target="#b4">[5]</ref> and monitoring thousands of switches at a fine time granularity is not scalable. One can use new hardware capabilities to gather more useful information <ref type="bibr" target="#b5">[6]</ref>. Correlating this data with each retransmission reliably is difficult. Furthermore, time is needed until such hardware is production-ready and switches are upgraded. Complicating matters, operators may be unwilling to incur the expense and overhead of such changes <ref type="bibr" target="#b3">[4]</ref>. One can use PingMesh <ref type="bibr" target="#b0">[1]</ref> to send probe packets and monitor link status. Such systems suffer from a rate of probing trade-off: sending too many probes creates unacceptable overhead whereas reducing the probing rate leaves temporal and spatial gaps in coverage. More importantly, the probe traffic does not capture what the end user and TCP flows see. Instead, we choose to use data traffic itself as probe traffic. Using data traffic has the advantage that the system introduces little to no monitoring overhead.</p><p>As one might expect, almost all traffic in our datacenters is TCP traffic. One way to monitor TCP traffic is to use a system like Everflow. Everflow inserts a special tag in every packet and has the switches mirror tagged packets to special collection servers. Thus, if a tagged packet is dropped, we can determine the link on which it happened. Unfortunately, there is no way to know in advance which packet is going to be dropped, so we would have to tag and mirror every TCP packet. This is clearly infeasible. We could tag only a fraction of packets, but doing so would result in another sampling rate trade-off. Hence, we choose to rely on some form of network tomography <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. We can take advantage of the fact that TCP is a connection-oriented, reliable delivery protocol so that any packet loss results in retransmissions that are easy to detect.</p><p>If we knew the path of all flows, we could set up an optimization to find which link dropped the packet. Such an optimization would minimize the number of "blamed" links while simultaneously explaining the cause of all drops. Indeed past approaches such as MAX COVERAGE and Tomo <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> aim to approximate the solution of such an optimization (see §12 for an example). There are problems with this approach: (i) the optimization is NP-hard <ref type="bibr" target="#b11">[12]</ref>. Solving it on a datacenter scale is infeasible. (ii) tracking the path of every flow in the datacenter is not scalable in our setting. We can use alternative solutions such as Everflow or the approach of <ref type="bibr" target="#b1">[2]</ref> to track the path of SYN packets. However, both rely on making changes to the switches. The only way to find the path of a flow without any special infrastructure support is to employ something like a traceroute. Traceroute relies on getting ICMP TTL exceeded messages back from the switches. These messages are generated by the control-plane, i.e., the switch CPU. To avoid overloading the CPU, our administrators have capped the rate of ICMP responses to 100 per second. This severely limits the number of flows we can track.</p><p>Given these limitations, what can we do? We analyzed the drop patterns in two of our datacenters and found: typically when there are packet drops, multiple flows experience drops. We show this in <ref type="figure" target="#fig_1">Figure 1a</ref> for TCP flows in production datacenters. The figure shows the number of flows experiencing drops in the datacenter conditioned on the total number of packets dropped in that datacenter in 30 second intervals. The data spans one day. We see that the more packets are dropped in the datacenter,   the more flows experience drops and 95% of the time, at least 3 flows see drops when we condition on ≥ 10 total drops. We focus on the ≥ 10 case because lower values mostly capture noisy drops due to one-off packet drops by healthy links. In most cases drops are distributed across flows and no single flow sees more than 40% of the total packet drops. This is shown in <ref type="figure" target="#fig_1">Figure 1b</ref> (we have discarded all flows with 0 drops and cases where the total number of drops was less than 10). We see that in ≥ 80% of cases, no single flow captures more than 34% of all drops.</p><p>Based on these observations and the high path diversity in datacenter networks <ref type="bibr" target="#b12">[13]</ref>, we show that if: (a) we only track the path of those flows that have retransmissions, (b) assign each link on the path of such a flow a vote of 1/h, where h is the path length, and (c) sum up the votes during a given period, then the top-voted links are almost always the ones dropping packets (see §5)! Unlike the optimization, our scheme is able to provide a ranking of the links in terms of their drop rates, i.e. if link A has a higher vote than B, it is also dropping more packets (with high probability). This gives us a heat-map of our network which highlights the links with the most impact to a given application/customer (because we know which links impact a particular flows).</p><p>3 Design Overview <ref type="figure" target="#fig_2">Figure 2</ref> shows the overall architecture of 007. It is deployed alongside other applications on each endhost as a user-level process running in the host OS. 007 consists of three agents responsible for TCP monitoring, path discovery, and analysis.</p><p>The TCP monitoring agent detects retransmissions at each end-host. The Event Tracing For Windows (ETW) <ref type="bibr" target="#b13">[14]</ref> framework 1 notifies the agent as soon as an active flow suffers a retransmission.</p><p>Upon a retransmission, the monitoring agent triggers the path discovery agent ( §4) which identifies the flow's path to the destination IP (DIP).</p><p>At the end-hosts, a voting scheme ( §5) is used based on the paths of flows that had retransmissions. At regular intervals of 30s the votes are tallied by a centralized analysis agent to find the top-voted links. Although we use an aggregation interval of 30s, failures do not have to last for 30s. 007's implementation consists of 6000 lines of C++ code. Its memory usage never goes beyond 600 KB on any of our production hosts, its CPU utilization is minimal (1-3%), and its bandwidth utilization due to traceroute is minimal (maximum of 200 KBps per host). 007 is proven to be accurate ( §5) in typical datacenter conditions (a full description of the assumed conditions can be found in §9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Path Discovery Agent</head><p>The path discovery agent uses traceroute packets to find the path of flows that suffer retransmissions. These packets are used solely to identify the path of a flow. They do not need to be dropped for 007 to operate. We first ensure that the number of traceroutes sent by the agent does not overload our switches ( §4.1). Then, we briefly describe the key engineering issues and how we solve them ( §4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ICMP Rate Limiting</head><p>Generating ICMP packets in response to traceroute consumes switch CPU, which is a valuable resource. In our network, there is a cap of T max = 100 on the number of ICMP messages a switch can send per second. To ensure that the traceroute load does not exceed T max , we start by noticing that a small fraction of flows go through tier-3 switches (T 3 ). Indeed, after monitoring all TCP flows in our network for one hour, only 2.1% went through a T 3 switch. Thus we can ignore T 3 switches in our analysis. Given that our network is a Clos topology and assuming that hosts under a top of the rack switch (ToR) communicate with hosts under a different ToR uniformly at random (see §6 for when this is not the case): Theorem 1. The rate of ICMP packets sent by any switch due to a traceroute is below T max if the rate C t at which hosts send traceroutes is upper bounded as</p><formula xml:id="formula_0">C t ≤ T max n 0 H min n 1 , n 2 (n 0 n pod − 1) n 0 (n pod − 1) ,<label>(1)</label></formula><p>where n 0 , n 1 , and n 2 , are the numbers of ToR, T 1 , and T 2 switches respectively, n pod is the number of pods, and H is the number of hosts under each ToR.</p><p>See §12 for proof. The upper bound of C t in our datacenters is 10. As long as hosts do not have more than 10 flows with retransmissions per second, we can guarantee that the number of traceroutes sent by 007 will not go above T max . We use C t as a threshold to limit the traceroute rate of each host. Note that there are two independent rate limits, one set at the host by 007 and the other set by the network operators on the switch (T max ). Additionally, the agent triggers path discovery for a given connection no more than once every epoch to further limit the number of traceroutes. We will show in §5 that this number is sufficient to ensure high accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Engineering Challenges</head><p>Using the correct five-tuple. As in most datacenters, our network also uses ECMP. All packets of a given flow, defined by the five-tuple, follow the same path <ref type="bibr" target="#b14">[15]</ref>. Thus, traceroute packets must have the same five-tuple as the flow we want to trace. To ensure this, we must account for load balancers.</p><p>TCP connections are initiated in our datacenter in a way similar to that described in <ref type="bibr" target="#b15">[16]</ref>. The connection is first established to a virtual IP (VIP) and the SYN packet (containing the VIP as destination) goes to a software load balancer (SLB) which assigns that flow to a physical destination IP (DIP) and a service port associated with that VIP. The SLB then sends a configuration message to the virtual switch (vSwitch) in the hypervisor of the source machine that registers that DIP with that vSwitch. The destination of all subsequent packets in that flow have the DIP as their destination and do not go through the SLB. For the path of the traceroute packets to match that of the data packets, its header should contain the DIP and not the VIP. Thus, before tracing the path of a flow, the path discovery agent first queries the SLB for the VIP-to-DIP mapping for that flow. An alternative is to query the vSwitch. In the instances where the failure also results in connection termination the mapping may be removed from the vSwitch table. It is therefore more reliable to query the SLB. Note that there are cases where the TCP connection establishment itself may fail due to packet loss. Path discovery is not triggered for such connections. It is also not triggered when the query to the SLB fails to avoid tracerouting the internet. Re-routing and packet drops. Traceroute itself may fail. This may happen if the link drop rate is high or due to a blackhole. This actually helps us, as it directly pinpoints the faulty link and our analysis engine ( §5) is able to use such partial traceroutes.</p><p>A more insidious possibility is that routing may change by the time traceroute starts. We use BGP in our datacenter and a lossy link may cause one or more BGP sessions to fail, triggering rerouting. Then, the traceroute packets may take a different path than the original connection. However, RTTs in a datacenter are typically less than 1 or 2 ms, so TCP retransmits a dropped packet quickly. The ETW framework notifies the monitoring agent immediately, which invokes the path discovery agent. The only additional delay is the time required to query the SLB to obtain the VIP-to-DIP mapping, which is typically less than a millisecond. Thus, as long as paths are stable for a few milliseconds after a packet drop, the traceroute packets will follow the same path as the flow and the probability of error is low. Past work has shown this to be usually the case <ref type="bibr" target="#b16">[17]</ref>.</p><p>Our network also makes use of link aggregation (LAG) <ref type="bibr" target="#b17">[18]</ref>. However, unless all the links in the aggregation group fail, the L3 path is not affected. Router aliasing <ref type="bibr" target="#b18">[19]</ref>. This problem is easily solved in a datacenter, as we know the topology, names, and IPs of all routers and interfaces. We can simply map the IPs from the traceroutes to the switch names.</p><p>To summarize, 007's path discovery implementation is as follows: Once the TCP monitoring agent notifies the path discovery agent that a flow has suffered a retransmission, the path discovery agent checks its cache of discovered path for that epoch and if need be, queries the SLB for the DIP. It then sends 15 appropriately crafted TCP packets with TTL values ranging from 0-15. In order to disambiguate the responses, the TTL value is also encoded in the IP ID field <ref type="bibr" target="#b19">[20]</ref>. This allows for concurrent traceroutes to multiple destinations. The TCP packets deliberately carry a bad checksum so that they do not interfere with the ongoing connection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The Analysis Agent</head><p>Here, we describe 007's analysis agent focusing on its voting-based scheme. We also present alternative NP-hard optimization solutions for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.1</head><p>Voting-Based Scheme 007's analysis agent uses a simple voting scheme. If a flow sees a retransmission, 007 votes its links as bad. Each vote has a value that is tallied at the end of every epoch, providing a natural ranking of the links.</p><p>We set the value of good votes to 0 (if a flow has no retransmission, no traceroute is needed). Bad votes are assigned a value of 1 h , where h is the number of hops on the path, since each link on the path is equally likely to be responsible for the drop.</p><p>The ranking obtained after compiling the votes allows us to identify the most likely cause of drops on each flow: links ranked higher have higher drop rates (Theorem 2). To further guard against high levels of noise, we can use our knowledge of the topology to adjust the links votes. Namely, we iteratively pick the most voted link l max and estimate the portion of votes obtained by all other links due to failures on l max . This estimate is obtained for each link k by (i) assuming all flows having retransmissions and going through l max had drops due to l max and (ii) finding what fraction of these flows go through k by assuming ECMP distributes flows uniformly at random. Our evaluations showed that this results in a 5% reduction in false positives.</p><p>Algorithm 1 Finding the most problematic links in the network.</p><formula xml:id="formula_1">1: L ← Set of all links 2: P ← Set of all possible paths 3: v(li) ← Number of votes for li ∈ L 4: B ← Set of most problematic links 5: lmax ← Link with maximum votes in ∀li ∈ L ∩ B c 6: while v(lmax) ≥ 0.01( l i ∈L v(li)) do 7: lmax ← argmax l i ∈L∩B c v(li) 8: B ← B ∪ {lmax} 9: for li ∈ L ∩ B c do 10: if ∃ pi ∈ P s.t. li ∈ pi &amp; lmax ∈ pi then</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Adjust the score of li 12: 007 can also be used to detect failed links using Algorithm 1. The algorithm sorts the links based on their votes and uses a threshold to determine if there are problematic links. If so, it adjusts the votes of all other links and repeats until no link has votes above the threshold. In Algorithm 1, we use a threshold of 1% of the total votes cast based on a parameter sweep where we found that it provides a reasonable trade-off between precision and recall. Higher values reduce false positives but increase false negatives.</p><p>Here we have focused on detecting link failures. 007 can also be used to detect switch failures in a similar fashion by applying votes to switches instead of links. This is beyond the scope of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Voting Scheme Analysis</head><p>Can 007 deliver on its promise of finding the most probable cause of packet drops on each flow? This is not trivial. In its voting scheme, failed connections contribute to increase the tally of both good and bad links. Moreover, in a large datacenter such as ours, occasional, lone, and sporadic drops can and will happen due to good links. These failures are akin to noise and can cause severe inaccuracies in any detection system <ref type="bibr" target="#b20">[21]</ref>, 007 included. We show that the likelihood of 007 making these errors is small. Given our topology (Clos):</p><formula xml:id="formula_2">Theorem 2. For n pod ≥ n 0 n 1 + 1, 007 will find with probability 1 − 2e −O(N ) the k &lt; n 2 (n 0 n pod −1) n 0 (n pod −1)</formula><p>bad links that drop packets with probability p b among good links that drop packets with probability p g if</p><formula xml:id="formula_3">p g ≤ (n u α) −1 [1 − (1 − p b ) n l ] ,</formula><p>where N is the total number of flows between hosts, n l and n u are lower and upper bounds, respectively, on the number of packets per connection, and</p><formula xml:id="formula_4">α = n 0 (4n 0 − k)(n pod − 1) n 2 (n 0 n pod − 1) − n 0 (n pod − 1)k .<label>(2)</label></formula><p>The proof is deferred to the appendices due to space constraints. Theorem 2 states that under mild conditions, links with higher drop rates are ranked higher by 007. Since a single flow is unlikely to go through more than one failed link in a network with thousands of links, it allows 007 to find the most likely cause of packet drops on each flow.</p><p>A corollary of Theorem 2 is that in the absence of noise (p g = 0), 007 can find all bad links with high probability. In the presence of noise, 007 can still identify the bad links as long as the probability of dropping packets on non-failed links is low enough (the signal-to-noise ratio is large enough). This number is compatible with typical values found in practice. As an example, let n l and n u be the 10 th and 90 th percentiles respectively of the number of packets sent by TCP flows across all hosts in a 3 hour period. If p b ≥ 0.05%, the drop rate on good links can be as high as 1.8 × 10 −6 . Drop rates in a production datacenter are typically below 10 −8 <ref type="bibr" target="#b21">[22]</ref>.</p><p>Another important consequence of Theorem 2 is that it establishes that the probability of errors in 007's results diminishes exponentially with N , so that even with the limits imposed by Theorem 1 we can accurately identify the failed links. The conditions in Theorem 2 are sufficient but not necessary. In fact, §6 shows how well 007 performs even when the conditions in Theorem 2 do not hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Optimization-Based Solutions</head><p>One of the advantages of 007's voting scheme is its simplicity. Given additional time and resources we may consider searching for the optimal sets of failed links by finding the most likely cause of drops given the available evidence. For instance, we can find the least number of links that explain all failures as we know the flows that had packet drops and their path. This can be written as an optimization problem we call the binary program. Explicitly,</p><formula xml:id="formula_5">minimize p 0 subject to Ap ≥ s p ∈ {0, 1} L (3)</formula><p>where A is a C × L routing matrix; s is a C × 1 vector that collects the status of each flow during an epoch (each element of s is 1 if the connection experienced at least one retransmission and 0 otherwise); L is the number of links; C is the number of connections in an epoch; and p 0 denotes the number of nonzero entries of the vector p. Indeed, if the solution of (3) is p , then the i-th element of p indicates whether the binary program estimates that link i failed.</p><p>Problem <ref type="formula">(3)</ref> is the NP-hard minimum set covering problem <ref type="bibr" target="#b22">[23]</ref> and is intractable. Its solutions can be approximated greedily as in MAX COVERAGE or Tomo <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> (see appendix). For benchmarking, we compare 007 to the true solution of (3) obtained by a mixed-integer linear program (MILP) solver <ref type="bibr" target="#b23">[24]</ref>. Our evaluations showed that 007 (Algorithm 1) significantly outperforms this binary optimization (by more than 50% in the presence of noise). We illustrate this point in Figures 4 and 10, but otherwise omit results for this optimization in §6 for clarity.</p><p>The binary program (3) does not provide a ranking of links. We also consider a solution in which we determine the number of packets dropped by each link, thus creating a natural ranking. The integer program can be written as</p><formula xml:id="formula_6">minimize p 0 subject to Ap ≥ c p 1 = c 1 p i ∈ N ∪ {0} (4)</formula><p>where N is the set of natural numbers and c is a C × 1 vector that collects the number of retransmissions suffered by each flow during an epoch. The solution p of (4) represents the number of packets dropped by each link, which provides a ranking. The constraint p 1 = c 1 ensures each failure is explained only once. As with (3), this problem is NP-hard <ref type="bibr" target="#b11">[12]</ref> and is only used as a benchmark. As it uses more information than the binary program (the number of failures), (4) performs better (see §6).</p><p>In the next three sections, we present our evaluation of 007 in simulations ( §6), in a test cluster ( §7), and in one of our production datacenters ( §8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluations: Simulations</head><p>We start by evaluating in simulations where we know the ground truth. 007 first finds flows whose drops were due to noise and marks them as "noise drops". It then finds the link most likely responsible for drops on the remaining set of flows ("failure drops"). A noisy drop is defined as one where the corresponding link only dropped a single packet. 007 never marked a connection into the noisy category incorrectly. We therefore focus on the accuracy for connections that 007 puts into the failure drop class. Performance metrics. Our measure for the performance of 007 is accuracy, which is the proportion of correctly identified drop causes. For evaluating Algorithm 1, we use recall and precision. Recall is a measure of reliability and shows how many of the failures 007 can detect (false negatives). For example, if there are 100 failed links and 007 detects 90 of them, its recall is 90%. Precision is a measure of accuracy and shows to what extent 007's results can be trusted (false positives). For example, if 007 flags 100 links as bad, but only 90 of those links actually failed, its precision is 90%. Simulation setup. We use a flow level simulator <ref type="bibr" target="#b24">[25]</ref> implemented in MATLAB. Our topology consists of 4160 links, 2 pods, and 20 ToRs per pod. Each host establishes 2 connections per second to a random ToR outside of its rack. The simulator has two types of links. For good links, packets are dropped at a very low rate chosen uniformly from (0, 10 −6 ) to simulate noise. On the other hand, failed links have a higher drop rate to simulate failures. By default, drop rates on failed links are set to vary uniformly from 0.01% to 1%, though to study the impact of drop rates we do allow this rate to vary as an input parameter. The number of good and failed links is also tunable. Every 30 seconds of simulation time, we send up to 100 packets per flow and drop them based on the rates above as they traverse links along the path. The simulator records all flows with at least one drop and for each such flow, the link with the most drops.</p><p>We compare 007 against the solutions described in §5.3. We only show results for the binary program (3) in Figures 4 and 10 since its performance is typically inferior to 007 and the integer program (4) due to noise. This also applies to MAX COVERAGE or Tomo <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b25">26]</ref> as they are approximations of the binary program (see <ref type="bibr" target="#b26">[27]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">In The Optimal Case</head><p>The bounds of Theorem 2 are sufficient (not necessary) conditions for accuracy. We first validate that 007 can achieve high levels of accuracy as expected when these bounds hold. We set the drop rates on the failed links to be between (0.05%, 1%). We refer the reader to <ref type="bibr" target="#b1">[2]</ref> for why these drop rates are reasonable. Accuracy. <ref type="figure">Figure 3</ref> shows that 007 has an average accuracy that is higher than 96% in almost all cases. Due to its robustness to noise, it also outperforms the optimization algorithm ( § 5.3) in most cases.</p><p>Recall &amp; precision. <ref type="figure">Figure 4</ref> shows that even when failed links have low packet drop rates, 007 detects them with high recall/precision. We proceed to evaluate 007's accuracy when the bounds in Theorem 2 do not hold. This shows these conditions are not necessary for good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Varying Drop Rates</head><p>Our next experiment aims to push the boundaries of Theorem 2 by varying the "failed" links drop rates below the conservative bounds of Theorem 2.</p><p>Single Failure. <ref type="figure">Figure 5a</ref> shows results for different drop rates on a single failed link. It shows that 007 can find the cause of drops on each flow with high accuracy. Even as the drop rate decreases below the bounds of Theorem 2, we see that 007 can maintain accuracy on par with the optimization.</p><p>Multiple Failures. <ref type="figure">Figure 5b</ref> shows that 007 is successful at finding the link responsible for a drop even when links have very different drop rates. Prior work have reported the difficulty of detecting such cases <ref type="bibr" target="#b1">[2]</ref>. However, 007's accuracy remains high. 6.3 Impact of Noise Single Failure. We vary noise levels by changing the drop rate of good links. We see that higher noise levels have little impact on 007's ability to find the cause of drops on individual flows <ref type="figure">(Figure 6a</ref>). Multiple Failures. We repeat this experiment for the case of 5 failed links. <ref type="figure">Figure 6b</ref> shows the results. 007 shows little sensitivity to the increase in noise when finding the cause of per-flow drops. Note that the large confidence intervals of the optimization is a result of its high sensitivity to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Varying Number of Connections</head><p>In previous experiments, hosts opened 60 connections per epoch. Here, we allow hosts to choose the number of connections they create per epoch uniformly at random between <ref type="bibr" target="#b9">(10,</ref><ref type="bibr" target="#b59">60)</ref>. Recall, from Theorem 2, that a larger number of connections from each host helps 007 improve its accuracy.</p><p>Single Failure. <ref type="figure">Figure 7a</ref> shows the results. 007 accurately finds the cause of packet drops on each connection. It also outperforms the optimization when the failed link has a low drop rate. This is because the optimization has multiple optimal points and is not sufficiently constrained.</p><p>Multiple Failures. <ref type="figure">Figure 7b</ref> shows the results for multiple failures. The optimization suffers from the lack of information to constrain the set of results. It therefore has a large variance (confidence intervals). 007 on the other hand maintains high probability of detection no matter the number of failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Impact of Traffic Skews</head><p>Single Failure. We next demonstrate 007's ability to detect the cause of drops even under heavily skewed traffic. We pick 10 ToRs at random (25% of the ToRs). To skew the traffic, 80% of the flows have destinations set to hosts under these 10 ToRs. The remaining flows are routed to randomly chosen hosts. <ref type="figure">Figure 8a</ref> shows that the optimization is much more heavily impacted by the skew than 007. 007 continues to detect the cause of drops with high probability (≥ 85%) for drop rates higher than 0.1%. Multiple Failures. We repeated the above for multiple failures. <ref type="figure">Figure 8b</ref> shows that the optimization's accuracy suffers. It consistently shows a low detection rate as its constraints are not sufficient in guiding the optimizer to the right solution. 007 maintains a detection rate of ≥ 98% at all times. Hot ToR. A special instance of traffic skew occurs in the presence of a single hot ToR which acts as a sink for a large number of flows. <ref type="figure" target="#fig_7">Figure 9</ref> shows how 007 performs in these situations. 007 can tolerate up to 50% skew, i.e., 50% of all flows go to the hot ToR, with negligible accuracy degradation. However, skews above 50% negatively impact its accuracy in the presence of a large number of failures (≥ 10). Such scenarios are unlikely as datacenter load balancing mitigates such extreme situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Detecting Bad Links</head><p>In our previous experiments, we focused on 007's accuracy on a per connection basis. In our next experiment, we evaluate its ability to detect bad links.</p><p>Single Failure. <ref type="figure" target="#fig_1">Figure 10</ref> shows the results. 007  </p><p>ToR-T1 failure T1-T2 failure T2-T1 failure T1-ToR failure <ref type="figure" target="#fig_1">Figure 11</ref>: Impact of link location on Algorithm 1.</p><p>outperforms the optimization as it does not require a fully specified set of equations to provide a best guess as to which links failed. We also evaluate the impact of failure location on our results ( <ref type="figure" target="#fig_1">Figure 11</ref>). Multiple Failures. We heavily skew the drop rates on the failed links. Specifically, at least one failed link has a drop rate between 10 and 100%, while all others have a drop rate in (0.01%, 0.1%). This scenario is one that past approaches have reported as hard to detect <ref type="bibr" target="#b1">[2]</ref>. <ref type="figure" target="#fig_1">Figure 12</ref> shows that 007 can detect up to 7 failures with accuracy above 90%. Its recall drops as the number of failed links increase. This is because the increase in the number of failures drives up the votes of all other links increasing the cutoff threshold and thus increasing the likelihood of false negatives. In fact if the top k links had been selected 007's recall would have been close to 100%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Effects of Network Size</head><p>Finally, we evaluate 007 in larger networks. Its accuracy when finding a single failure was 98%, 92%, 91%, and 90% on average in a network with 1, 2, 3, and 4 pods respectively. In contrast, the optimization had an average accuracy of 94%, 72%, 79%, and 77%  respectively. Algorithm 1 continues to have Recall ≥ 98% for up to 6 pods (it drops to 85% for 7 pods). Precision remains 100% for all pod sizes. We also evaluate both 007 and the optimization's ability to find the cause of per flow drops when the number of failed links is ≥ 30. We observe that both approach's performance remained unchanged for the most part, e.g., the accuracy of 007 in an example with 30 failed links is 98.01%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluations: Test Cluster</head><p>We next evaluate 007 on the more realistic environment of a test cluster with 10 ToRs and a total of 80 links. We control 50 hosts in the cluster, while others are production machines. Therefore, the T 1 switches see real production traffic. We recorded 6 hours of traffic from a host in production and replayed it from our hosts in the cluster (with different starting times). Using Everflow-like functionality <ref type="bibr" target="#b2">[3]</ref> on the ToR switches, we induced different rates of drops on T 1 to ToR links. Our goal is to find the cause of packet drops on each flow §7.2 and to validate whether Algorithm 1 works in practice §7.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Clean Testbed Validation</head><p>We first validate a clean testbed environment. We repave the cluster by setting all devices to a clean state. We then run 007 without injecting any failures. We see that in the newly-repaved cluster, links arriving at a particular ToR switch had abnormally high votes, namely 22.5 ± 3.65 in average. We thus suspected that this ToR is experiencing problems. After rebooting it, the total votes of the links went down to 0, validating our suspicions. This exercise also provides one example of when 007 is extremely effective at identifying links with low drop rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Per-connection Failure Analysis</head><p>Can 007 identify the cause of drops when links have very different drop rates? To find out, we induce a drop rate of 0.2% and 0.05% on two different links for an hour. We only know the ground truth when the flow goes through at least one of the two failed links. Thus, we only consider such flows. For 90.47% of these, 007 was able to attribute the packet drop to the correct link (the one with higher drop rate).  <ref type="figure" target="#fig_1">Figure 13</ref>: Distribution of the difference between votes on bad links and the maximum vote on good links for different bad link drop rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Identifying Failed Links</head><p>We next validate Algorithm 1 and its ability to detect failed links. We inject different drop rates on a chosen link and determine whether there is a correlation between total votes and drop rates. Specifically, we look at the difference between the vote tally on the bad link and that of the most voted good link. We induced a packet drop rate of 1%, 0.1%, and 0.05% on a T 1 to ToR link in the test cluster. <ref type="figure" target="#fig_1">Figure 13</ref> shows the distribution for the various drop rates. The failed link has the highest vote out of all links when the drop rate is 1% and 0.1%. When the drop rate is lowered to 0.05%, the failed link becomes harder to detect due to the smaller gap between the drop rate of the bad link and that of the normal links. Indeed, the bad link only has the maximum score in 88.89% of the instances (mostly due to occasional lone drops on healthy links). However, it is always one of the 2 links with the highest votes. <ref type="figure" target="#fig_1">Figure 13</ref> also shows the high correlation between the probability of packet drop on a links and its vote tally. This trivially shows that 007 is 100% accurate in finding the cause of packet drops on each flow given a single link failure: the failed link has the highest votes among all links. We compare 007 with the optimization problem in <ref type="bibr" target="#b3">(4)</ref>. We find that the latter also returns the correct result every time, albeit at the cost of a large number of false positives. To illustrate this point: the number of links marked as bad by (4) on average is 1.5, 1.18, and 1.47 times higher than the number given by 007 for the drop rates of 1%, 0.1%, and 0.05% respectively.</p><p>What about multiple failures? This is a harder experiment to configure due to the smaller number of links in this test cluster and its lower path diversity. We induce different drop rates (p 1 = 0.2% and p 2 = 0.1%) on two links in the cluster. The link with higher drop rate is the most voted 100% of the time. The second link is the second highest ranked 47% of the time and the third 32% of the time. It always remained among the 5 most voted links. This shows that by allowing a single false positive (identifying three instead of two links), 007 can detect all failed links 80% of the time even in a setup where the traffic distribution is highly skewed. This is something past approaches <ref type="bibr" target="#b1">[2]</ref> could not achieve. In this example, 007 identifies the true cause of packet drops on each connection 98% of the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluations: Production</head><p>We have deployed 007 in one of our datacenters 2 . Notable examples of problems 007 found include: power</p><formula xml:id="formula_8">T = 0 T &gt; 0 &amp; T ≤ 3 T &gt; 3 max(T ) 69%</formula><p>30.98% 0.02% 11 supply undervoltages <ref type="bibr" target="#b27">[28]</ref>, FCS errors <ref type="bibr" target="#b28">[29]</ref>, switch reconfigurations, continuous BGP state changes, link flaps, and software bugs <ref type="bibr" target="#b29">[30]</ref>. Also, 007 found every problem that was caught by our previously deployed diagnosis tools. <ref type="table" target="#tab_0">Table 1</ref> shows the distribution of the number of ICMP messages sent by each switch in each epoch over a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Validating Theorem 1</head><p>week. The number of ICMP messages generated by 007 never exceed T max (Theorem 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">TCP Connection Diagnosis</head><p>In addition to finding problematic links, 007 identifies the most likely cause of drops on each flow. Knowing when each individual packet is dropped in production is hard. We perform a semi-controlled experiment to test the accuracy of 007. Our environment consists of thousands of hosts/links. To find the "ground truth", we compare its results to that obtained by EverFlow. EverFlow captures all packets going through each switch on which it was enabled. It is expensive to run for extended periods of time. We thus only run EverFlow for 5 hours and configure it to capture all outgoing IP traffic from 9 random hosts. The captures for each host were conducted on different days. We filter all flows that were detected to have at least one retransmission during this time and using EverFlow find where their packets were dropped. We then check whether the detected link matches that found by 007. We found that 007 was accurate in every single case. In this test we also verified that each path recorded by 007 matches exactly the path taken by that flow's packets as captured by EverFlow. This confirms that it is unlikely for paths to change fast enough to cause errors in 007's path discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">VM Reboot Diagnosis</head><p>During our deployment, there were 281 VM reboots in the datacenter for which there was no explanation. 007 found a link as the cause of problems in each case. Upon further investigation on the SNMP system logs, we observe that in 262 cases, there were transient drops on the host to ToR link a number of which were correlated with high CPU usage on the host. Two were due to high drop rates on the ToR. In another 15, the endpoints of the links found were undergoing configuration updates. In the remaining 2 instances, the link was flapping. Finally, we looked at our data for one cluster for one day. 007 identifies an average of 0.45 ± 0.12 links as dropping packets per epoch. The average across all epochs of the maximum vote tally was 2.51 ± 0.33. Out of the links dropping packets 48% are server to ToR links (38% were due to a single ToR switch that was eventually taken out for repair), 24% are T 1 -ToR links and 6% were due to T 2 -T 1 link failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>007 is highly effective in finding the cause of packet drops on individual flows. By doing so, it provides flow-level context which is useful in finding the cause of problems for specific applications. In this section we discuss a number of other factors we considered in its design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">007's Main Assumptions</head><p>The proofs of Theorems 1 and 2 and the design of the path discovery agent ( §4) are based on a number of assumptions: ACK loss on reverse path. It is possible that packet loss on the reverse path is so severe that loss of ACK packets triggers timeout at the sender. If this happens, the traceroute would not be going over any link that triggered the packet drop. Since TCP ACKs are cumulative, this is typically not a problem and 007 assumes retransmissions in such cases are unlikely. This is true unless loss rates are very high, in which case the severity of the problem is such that the cause is apparent. Spurious retransmissions triggered by timeouts may also occur if there is sudden increased delay on forward or reverse paths. This can happen due to rerouting, or large queue buildups. 007 treats these retransmissions like any other. Source NATs. Source network address translators (SNATs) change the source IP of a packet before it is sent out to a VIP. Our current implementation of 007 assumes connections are SNAT bypassed. However, if flows are SNATed, the ICMP messages will not have the right source address for 007 to get the response to its traceroutes. This can be fixed by a query to the SLB. Details are omitted. L2 networks. Traceroute is not a viable option to find paths when datacenters operate using L2 routing. In such cases we recommend one of the following: (a) If access to the destination is not a problem and switches can be upgraded one can use the path discovery methods of <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">31]</ref>. 007 is still useful as it allows for finding the cause of failures when multiple failures are present and for individual flows. (b) Alternatively, EverFlow can be used to find path. 007's sampling is necessary here as EverFlow doesn't scale to capture the path of all flows. Network topology. The calculations in §5 assume a known topology (Clos). The same calculations can be carried out for any known topology by updating the values used for ECMP. The accuracy of 007 is tied to the degree of path diversity and that multiple paths are available at each hop: the higher the degree of path diversity, the better 007 performs. This is also a desired property in any datacenter topology, most of which follow the Clos topology <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. ICMP rate limit. In rare instances, the severity of a failure or the number of flows impacted by it may be such that it triggers 007's ICMP rate limit which stops sending more traceroute messages in that epoch. This does not impact the accuracy of Algorithm 1. By the time 007 reaches its rate limit, it has enough data to localize the problematic links. However, this limits 007's ability to find the cause of drops on flows for which it did not identify the path. We accept this trade-off in accuracy for the simplicity and lower overhead of 007. Unpredictability of ECMP. If the topology and the ECMP functions on all the routers are known, the path of a packet can be found by inspecting its header. However, ECMP functions are typically proprietary and have initialization "seeds" that change with every reboot of the switch. Furthermore, ECMP functions change after link failures and recoveries. Tracking all link failures/recoveries in real time is not feasible at a datacenter scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Other Factors To Consider</head><p>007 has been designed for a specific use case, namely finding the cause of packet drops on individual connections in order to provide application context. This resulted in a number of design choices: Detecting congestion. 007 should not avoid detecting major congestion events as they signal severe traffic imbalance and/or incast and are actionable. However, the more prevalent (≥ 92%) forms of congestion have low drop rates 10 −8 -10 −5 <ref type="bibr" target="#b28">[29]</ref>. 007 treats these as noise and does not detect them. Standard congestion control protocols can effectively react to them. 007's ranking. 007's ranking approach will naturally bias towards the detection of failed links that are frequently used. This is an intentional design choice as the goal of 007 is to identity high impact failures that affect many connections. Finding the cause of other problems. 007's goal is to identify the cause of every packet drop, but other problems may also be of interest. 007 can be extended to identify the cause of many such problems. For example, for latency, ETW provides TCP's smooth RTT estimates upon each received ACK. Thresholding on these values allows for identifying "failed" flows and 007's voting scheme can be used to provides a ranked list of suspects. Proving the accuracy of 007 for such problems requires an extension of the analysis presented in this paper. VM traffic problems. 007's goal is to find the cause of drops on infrastructure connections and through those, find the failed links in the network. In principle, we can build a 007-like system to diagnose TCP failures for connections established by customer VMs as well. For example, we can update the monitoring agent to capture VM TCP statistics through a VFP-like system <ref type="bibr" target="#b33">[34]</ref>. However, such a system raises a number of new issues, chief among them being security. This is part of our future work.</p><p>In conclusion, we stress that the purpose of 007 is to explain the cause of drops when they occur. Many of these are not actionable and do not require operator intervention. The tally of votes on a given link provide a starting point for deciding when such intervention is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Related Work</head><p>Finding the source of failures in distributed systems, specifically networks, is a mature topic. We outline some of the key differences of 007 with these works.</p><p>The most closely related work to ours is perhaps <ref type="bibr" target="#b1">[2]</ref>, which requires modifications to routers and both endpoints a limitation that 007 does not have. Often services (e.g. storage) are unwilling to incur the additional overhead of new monitoring software on their machines and in many instances the two endpoints are in seperate organizations <ref type="bibr" target="#b3">[4]</ref>. Moreover, in order to apply their approach to our datacenter, a number of engineering problems need to be overcome, including finding a substitute for their use of the DSCP bit, which is used for other purposes in our datacenter. Lastly, while the statistical testing method used in <ref type="bibr" target="#b1">[2]</ref> (as well as others) are useful when paths of both failed and non-failed flows are available they cannot be used in our setting as the limited number of traceroutes 007 can send prevent it from tracking the path of all flows. In addition 007 allows for diagnosis of individual connections and it works well in the presence of multiple simultaneous failures, features that <ref type="bibr" target="#b1">[2]</ref> does not provide. Indeed, finding paths only when they are needed is one of the most attractive features of 007 as it minimizes its overhead on the system. Maximum cover algorithms <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35]</ref> suffer from many of the same limitations described earlier for the binary optimization, since MAX COV-ERAGE and Tomo are approximations of (3). Other related work can be loosely categorized as follows: Inference and Trace-Based Algorithms <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref> use anomaly detection and trace-based algorithms to find sources of failures. They require knowledge/inference of the location of logical devices, e.g. load balancers in the connection path. While this information is available to the network operators, it is not clear which instance of these entities a flow will go over. This reduces the accuracy of the results.</p><p>Everflow <ref type="bibr" target="#b2">[3]</ref> aims to accurately identify the path of packets of interest. However, it does not scale to be used as an always on diagnosis system. Furthermore, it requires additional features to be enabled in the switch. Similarly, <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b30">31]</ref> provides another means of path discovery, however, such approaches require deploying new applications to the remote end points which we want to avoid (due to reasons described in <ref type="bibr" target="#b3">[4]</ref>). Also, they depend on SDN enabled networks and are not applicable to our setting where routing is based on BGP enabled switches.</p><p>Some inference approaches aim at covering the full topology, e.g. <ref type="bibr" target="#b0">[1]</ref>. While this is useful, they typically only provides a sampled view of connection livelihood and do not achieve the type of always on monitoring that 007 provides. The time between probes for <ref type="bibr" target="#b0">[1]</ref> for example is currently 5 minutes. It is likely that failures that happen at finer time scales slip through the cracks of its monitoring probes.</p><p>Other such work, e.g. <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref> require access to both endpoints and/or switches. Such access may not always be possible. Finally, NetPoirot <ref type="bibr" target="#b3">[4]</ref> can only identify the general type of a problem (network, client, server) rather than the responsible device. Network tomography <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref> typically consist of two aspects: (i) the gathering and filtering of network traffic data to be used for identifying the points of failure <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b44">45]</ref> and (ii) using the information found in the previous step to identify where/why failures occurred <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">51]</ref>. 007 utilizes ongoing traffic to detect problems, unlike these approaches which require a much heavier-weight operation of gathering large volumes of data. Tomography-based approaches are also better suited for non-transient failures, while 007 can handle both transient and persistent errors. 007 also has coverage that extends to the entire network infrastructure, and does not limit coverage to only paths between designated monitors as some such approaches do. Work on analyzing failures <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b44">45]</ref> are complementary and can be applied to 007 to improve our accuracy. Anomaly detection <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref> find when a failure has occurred using machine learning <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54]</ref> and Fourier transforms <ref type="bibr" target="#b55">[56]</ref>. 007 goes a step further by finding the device responsible. Fault Localization by Consensus <ref type="bibr" target="#b58">[59]</ref> assumes that a failure on a node common to the path used by a subset of clients will result in failures on a significant number of them. NetPoirot <ref type="bibr" target="#b3">[4]</ref> illustrates why this approach fails in the face of a subset of problems that are common to datacenters. While our work builds on this idea, it provides a confidence measure that identifies how reliable a diagnosis report is.</p><p>Fault Localization using TCP statistics <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref> use TCP metrics for diagnosis. <ref type="bibr" target="#b59">[60]</ref> requires heavyweight active probing. <ref type="bibr" target="#b60">[61]</ref> uses learning techniques. Both <ref type="bibr" target="#b60">[61]</ref>, and T-Rat <ref type="bibr" target="#b61">[62]</ref> rely on continuous packet captures which doesn't scale. SNAP <ref type="bibr" target="#b62">[63]</ref> identifies performance problems/causes for connections by acquiring TCP information which are gathered by querying socket options. It also gathers routing data combined with topology data to compare the TCP statistics for flows that share the same host, link, ToR, or aggregator switch. Given their lack of continuous monitoring, all of these approaches fail in detecting the type of problems 007 is designed to detect. Furthermore, the goal of 007 is more ambitious, namely to find the link that causes packet drops for each TCP connection.</p><p>Learning Based Approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66]</ref> do failure detection in home and mobile networks. Our application domain is different.</p><p>Application diagnosis <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b67">68]</ref> aim at identifying the cause of problems in a distributed application's execution path. The limitations of diagnosing network level paths and the complexities associated with this task are different. Obtaining all execution paths seen by an application, is plausible in such systems but is not an option in ours.</p><p>Failure resilience in datacenters <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref> target resilience to failures in datacenters. 007 can be helpful to a number of these algorithms as it can find problematic areas which these tools can then help avoid.</p><p>Understanding datacenter failures <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b77">78]</ref> aims to find the various types of failures in datacenters. They are useful in understanding the types of problems that arise in practice and to ensure that our diagnosis engines are well equipped to find them. 007's analysis agent uses the findings of <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Conclusion</head><p>We introduced 007, an always on and scalable monitoring/diagnosis system for datacenters. 007 can accurately identify drop rates as low as 0.05% in datacenters with thousands of links through monitoring the status of ongoing TCP flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Application example: VM reboots</head><p>In the introduction ( § 1), we describe an instance in which the failure detection capacities of 007 can be useful: pinpointing the cause of VM reboots. Indeed, in our datacenters, VM images are stored in a storage service. When a customer boots a VM, the image is mounted over the network. Thus, even a small network outage can cause the host kernel to "panic" and reboot the guest VM. We mentioned that over 70% of VM reboots caused by network issues in our datacenters cannot be explained using currently deployed monitoring systems. To further illustrate how important this issue can be, <ref type="figure" target="#fig_1">Figure 14</ref> shows the number of unexplained VM reboots due to network problems in one day of operations: there were on average 10 VM reboots per hour due to unexplained network problems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Network tomography example</head><p>Knowing the path of all flows, it is possible to find with confidence which link dropped a packet. To do so, consider the example network in <ref type="figure" target="#fig_1">Figure 15</ref>. Suppose that the link between nodes 2 and 4 drops packets. Flows 1-2 and 3-2 suffer from drops, but 1-3 does not. A set cover optimization, such as the one used by MAX COVERAGE and Tomo <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, that minimizes the number of "blamed" links will correctly find the cause of drops. This problem is however equivalent to a set covering optimization problem that is known to be NP-complete <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Proofs</head><p>Definition 1 (Clos topology). A Clos topology has n pod pods each with n 0 top of the rack (ToR) switches under which lie H hosts. The ToR switches are connected to n 1 tier-1 switches by a complete network (n 0 n 1 links). Links between tier-0 and tier-1 switches are referred to as level 1 links. The tier-1 switches within each pod are connected to n 2 tier-2 switches by another complete network (n 1 n 2 links). Links between these switches are called level 2 links. This notation is illustrated in <ref type="figure" target="#fig_1">Figure 16</ref>. Remark 1 (Communication and failure model). Assume that connection occur uniformly at random between hosts under different ToR switches. Since the number of hosts under each ToR switch is the same, this is equivalent to saying that connections occur uniformly at random directly between ToR switches. Also, assume that link failure and connection routing are independent and that links drop packets independently across links and across packets.</p><p>Remark 2 (Notation). We use calligraphic letter (A) to denote sets and boldface font (A) to denote random variables. Also, we write [M ] to mean the set of integers between 1 and M , i.e., [M ] = 1, . . . , M .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Proof of Theorem 1</head><p>Proof. Start by noticing that the number of hosts below each ToR switch is the same, so that we can consider that traceroute are sent on flows uniformly at random between ToR switches at a rate C t H. Moreover, note that routing probabilities are the same for links on the same level, so that the traceroute rate depends only on whether the link is on level 1 or level 2.</p><p>Since the probability of a switch routing a connection through any link is uniform, the traceroute rate of a level 1 link is given by</p><formula xml:id="formula_9">R 1 = 1 n 1 C t H,<label>(5)</label></formula><p>Similarly for a level 2 link:</p><formula xml:id="formula_10">R 2 = n 0 n 1 n 2 n 0 (n pod − 1) (n 0 n pod − 1) C t H,<label>(6)</label></formula><p>where the second fraction represents the probability of a host connecting to another host outside its own pod, i.e., of going through a level 2 link. Since n 0 links are connected to a tier-1 switch and n 1 links are connected to a tier-2, the rate of ICMP packets at any links is bounded by T ≤ max [n 0 R 1 , n 1 R 2 ].</p><p>Taking max [n 0 R 1 , n 1 R 2 ] ≤ T max yields (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Proof of Theorem 2</head><p>We prove the following more precise statement of Theorem 2.</p><p>where r b and r g are the probabilities of a retransmission occurring due to a bad and a good link, respectively.</p><p>Before proving these lemmata, let us see how they imply Theorem 3. From the (10) in Lemma 2, it holds that</p><formula xml:id="formula_11">r b ≥ n 0 (4n 0 − k)(n pod − 1) n 2 (n 0 n pod − 1) − n 0 (n pod − 1)k α r g ⇒ v b ≥ v g ,<label>(11)</label></formula><p>for k &lt; n 2 (n 0 n pod −1) n 0 (n pod −1) &lt; n 0 . Thus, in a Clos topology, if the probability of retransmission due to a bad link is large enough compare to a good link, i.e., r b ≥ αr g for α as in <ref type="formula">(8)</ref>, then we have that the probability of a bad link receiving a vote is larger than that of a good link (v b ≥ v g ).</p><p>Still, <ref type="bibr" target="#b10">(11)</ref> gives a relation in terms of the probabilities of retransmission (r g , r b ) instead of the packet drop rates (p g , p b ) as in <ref type="bibr" target="#b6">(7)</ref>. To obtain <ref type="formula">(7)</ref>, note that the probability r of retransmission during a connection with c packets due to a link that drops packets with probability p is r</p><formula xml:id="formula_12">= 1 − (1 − p) c . Since r is monotonically increasing in c, we have that r b ≥ 1 − (1 − p b ) c l . Similarly, r g ≤ 1 − (1 − p g ) c u .</formula><p>Using the fact (1 − x) n ≥ 1 − nx yields <ref type="bibr" target="#b6">(7)</ref>.</p><p>We now proceed with the proofs of Lemmata 1 and 2.</p><p>Proof of Lemma 1. We start by noting that in a datacenter-sized Clos network, almost every connection has a hop count of 5. In our datacenter, this happens to 97.5% of connections. Therefore, we can approximate links votes by assuming all bad votes have the same value. Thus, suffices to determine how many votes each link has.</p><p>Since links cause retransmissions independently across connections (see Remark 1), the number of votes received by a bad link is a binomial random variable B with parameters N , the total number of connections, and v b , the probability of a bad link receiving a vote. Similarly, let G be the number of votes on a good link, a binomial random variable with parameters N and v g . 007 will correctly rank the bad links if B ≥ G, i.e., when bad links receive more votes than good links. This event contains the event <ref type="bibr" target="#b79">[80]</ref>, the probability of 007 identifying the </p><formula xml:id="formula_13">D = {G ≤ (1 + δ)N v g ∩ B ≥ (1 − δ)N v b } for δ ≤ v b −v g v b +v g . Using the union bound P [ i E i ] ≤ i P [E i ]</formula><formula xml:id="formula_14">P(B ≥ G) ≥ P [G ≤ (1 + δ)N v g ∩ B ≥ (1 − δ)N v b ] ≥ 1 − P [G ≥ (1 + δ)N v g ] − P [B ≤ (1 − δ)N v b ]<label>(12)</label></formula><p>To proceed, note that the probabilities in (12) can be bounded using the large deviation principle <ref type="bibr" target="#b78">[79]</ref>. Indeed, let S be a binomial random variable with parameters M and q. For δ &gt; 0 it holds that</p><formula xml:id="formula_15">P [S ≥ (1 + δ)qM ] ≤ e −M D KL ((1+δ)q q) (13a) P [S ≤ (1 − δ)qM ] ≤ e −M D KL ((1−δ)q q)<label>(13b)</label></formula><p>where D KL (q r) is the Kullback-Leibler divergence between two Bernoulli distributions with probabilities of success q and r <ref type="bibr" target="#b80">[81]</ref>. Explicitly, D KL (q r) = q log q r + (1 − q) log 1 − q 1 − r .</p><p>Substituting the inequalities (13) into (12) yields <ref type="bibr" target="#b8">(9)</ref>.</p><p>Proof of Lemma 2. Before proceeding, let T 0 , T 1 , and T 2 denote the set of ToR, tier-1, and tier-2 switches respectively ( <ref type="figure" target="#fig_1">Figure 16</ref>). Also let T s 0 and T s 1 , s = [n pod ], denote the tier-0 and tier-1 switches in pod s respectively. Note that T 0 = T 1 0 ∪ · · · ∪ T n pod 0 and T 1 = T 1 1 ∪ · · · ∪ T n pod 1</p><p>. Note that we use subscripts to denote the switch tier and superscripts to denote its pod. To clarify the derivations, we maintain this notation for indices. For instance, i s 0 is the i-th tier-0 switch from pod s, i.e., i s 0 ∈ T s 0 , and 2 is the -th tier-2 switch. Note that tier-2 switches do not belong to specific pods. We write (i s 0 , j s 1 ) to denote the level 1 link that connects i s 0 to j s 1 (as in <ref type="figure" target="#fig_1">Figure 16</ref>) and use r(i s 0 , j s 1 ) = r(j s 1 , i s 0 ) to refer to the probability of link (i s 0 , j s 1 ) causing a retransmission. Note that r is also a function of the number of packets in a connection, but we omit this dependence for clarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>18</head><p>The bounds in <ref type="bibr" target="#b9">(10)</ref> are obtained by decomposing the events that 007 votes for a level 1 or level 2 link into a union of simpler events. Before proceeding, note that each connection only goes through one link in each level and in each direction, so that events such as "going through a ToR to tier-1 link" are disjoint.</p><p>Starting with level 1, let A 0 be the event that a connection goes through link (i s 0 , j s 1 ), i.e., a link that connects a ToR to a tier-1 switch in any pod. This event happens with probability P [A 0 ] = 1 n 0 n 1 n pod ,</p><p>given that there are n 0 n 1 n pod level 1 links and that connections occur uniformly at random. The link (i s 0 , j s 1 ) will get a vote if one of five things occur: (i) it causes a retransmission; (ii) the connection stays within the pod and some other link causes a retransmission; (iii) the connection leaves the pod and a link between a tier-1 and tier-2 switch causes the retransmission; (iv) the connection leaves the pod and a link between a tier-2 and tier-1 switch causes the retransmission; or (v) the connection leaves the pod and a link between a tier-1 and ToR switch in the other pod causes the retransmission. Formally, the link (i s 0 , j s 1 ) receives a vote if a connection goes through it (event A 0 ) and either of the following occurs:</p><p>• event A 1 : (i s 0 , j s 1 ) causes a retransmission, i.e., P [A 1 ] = r(i s 0 , j s 1 ) (14b)</p><p>• event A 2 : the connection also goes through some (j s 1 , k s 0 ), k s 0 = i s 0 , and (j s 1 , k s 0 ) causes a retransmission. Therefore,</p><formula xml:id="formula_17">P [A 2 ] = 1 n 0 n pod − 1 connect to k s 0 k s 0 ∈T s 0 \{i s 0 } r(j s 1 , k s 0 ) (14c)</formula><p>• event A <ref type="bibr" target="#b2">3</ref> : the connection also goes through some (j s 1 , 2 ) and (j s 1 , 2 ) causes a retransmission, which occurs with probability D Greedy solution of the binary program When discussing optimization-based alternatives to 007's voting scheme, we presented the following problem which we dubbed the binary program minimize p 0 subject to Ap ≥ s p ∈ {0, 1} L <ref type="bibr" target="#b18">(19)</ref> where A is a C × L routing matrix; s is a C × 1 vector that collects the status of each flow during an epoch (each element of s is 1 if the connection experienced at least one retransmission and 0 otherwise); L is the number of links; C is the number of connections in an epoch; and p 0 denotes the number of nonzero entries of the vector p.</p><p>Problem <ref type="bibr" target="#b18">(19)</ref> can be described as one of looking for the smallest number of links that explains all failures. To see this is the case, start by noting that p is an L× 1 whose i-th entry describe whether link i is believed to have failed or not. Thus, since A is the routing matrix, the C × 1 vector Ap describes whether p explains a possible failure in that connection or not: if [Ap] i = 0, then p does not explain a possible failure in the i-th connection; if [Ap] i &gt; 0, then p explains a possible failure in the i-th connection. Hence, the 20 constraint Ap ≥ s can be read as "explain each failure at least once". Note that in an attempt to explain all failure, p may explain failures that did not occur. This is the reason we used the term "possible failure" earlier. Recalling that the objective of <ref type="bibr" target="#b18">(19)</ref> is to minimize the number of ones in p, i.e., the number of links marked as "failed", gives the interpretation from the beginning of the paragraph.</p><p>As we noted before, the binary program is NPhard in general. Its solution is therefore typically approximated using a greedy procedure. Given the interpretation from the last paragraph, we can describe the greedy solution of <ref type="bibr" target="#b18">(19)</ref> as in Algorithm 2 <ref type="bibr" target="#b22">[23]</ref>. The algorithm proceeds as follows. Start with an empty set of failed links F and a set of unexplained failures C. At each step, find the single link l that explains the largest number of unexplained failures, add it to F, and remove from C all the failures it explains. We then iterate until C is empty. Note that this is the procedure followed by MAX COVERAGE and Tomo <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. They both therefore approximate the solution of <ref type="bibr" target="#b18">(19)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Observations from a production network: (a) CDF of the number of flows with at least one retransmission; (b) CDF of the fraction of drops belonging to each flow in each 30 second interval.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Overview of 007 architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>When Theorem 2 holds. Algorithm 1 when Theorem 2 holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>007's accuracy for varying drop rates. 007's accuracy for varying noise levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1 Figure 7 :Figure 8 :</head><label>178</label><figDesc>Varying the number of connections. 007's accuracy under skewed traffic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Impact of a hot ToR on 007's accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Algorithm 1 with single failure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 :</head><label>12</label><figDesc>Algorithm 1 with multiple failures. The drop rates on the links are heavily skewed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>[</head><label></label><figDesc>Bad link votes] − [Maximum good link votes]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 14 :</head><label>14</label><figDesc>Number of network related reboots in a day.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 15 :</head><label>15</label><figDesc>Simple tomography example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 16 :</head><label>16</label><figDesc>Illustration of notation for Clos topology used in the proof of Lemma 2 correct links is therefore bounded by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Number of ICMPs per second per switch (T ).We see max(T ) ≤ T max .</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Similar functionality exists in Linux.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The monitoring agent has been deployed across all our data centers for over 2 years.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12">Acknowledgements</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Set of all ToR switches (T 0 = T 1 0 ∪ · · · ∪ T n pod 0 ) T <ref type="bibr" target="#b0">1</ref> Set of all tier-1 switches (T 1 = T 1 1 ∪ · · · ∪ T n pod 1 )</p><p>Set of all tier-2 switches k Number of failed links in the network c u</p><p>Upper bound on the number of packets per connection c l Lower bound on the number of packets per connection p g Probability that a good link drops a packet p b</p><p>Probability that a failed link drops a packet v g Probability that a good link receives a vote v b</p><p>Probability that a bad link receives a vote r g Probability that a good link causes a retransmission (drops at least one packet) r b</p><p>Probability that a bad link causes a retransmission (drops at least one packet)</p><p>Theorem 3. In a Clos topology with n 0 ≥ n 2 and n pod ≥ 1 + max n 0 n 1 , n 2 (n 0 −1) n 0 (n 0 −n 2 ) , 1 , 007 will rank with probability (1 − ) the k &lt; n 2 (n 0 n pod −1) n 0 (n pod −1) bad links that drop packets with probability p b above all good links that drop packets with probability p g as long as</p><p>where c l and c u are lower and upper bounds, respectively, on the number of packets per connection,</p><p>and</p><p>with v g and v b being the probabilities of a good and bad link receiving a vote, respectively, N being the total number of connections between hosts, and D KL (q r) denoting the Kullback-Leibler divergence between two Bernoulli distributions with probabilities of success q and r.</p><p>Before proceeding, note that the typical scenario in which n 0 ≥ 2n 2 and n 2 (n 0 −1) n 0 (n 0 −n 2 ) ≤ 1, as in our data center, the condition on the number of pods from Theorem 3 reduces to n pod ≥ 1 + n 0 n 1 .</p><p>Proof. The proof proceeds as follows. First, we show that if a link has higher probability of receiving a vote, then it receives more votes if a large enough number of connections (N ) are established. We do so using large deviation theory <ref type="bibr" target="#b78">[79]</ref>, so that we can show that this does not happen actually decreases exponentially in N .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1.</head><p>If v b ≥ v g , 007 will rank bad links above good links with probability (1 − ) for as in <ref type="bibr" target="#b8">(9)</ref>.</p><p>With Lemma 1 in hands, we then need to relate the probabilities of a link receiving a vote (v b , v g ) to the link drop rates (p b , p g ). This will allow us to derive the signal-to-noise ratio condition in <ref type="bibr" target="#b6">(7)</ref>. Note that the probability of a link receiving a vote is the probability of a flow going through the link and that a retransmission occurs (i.e., some link in the flow's path drops at least one packet). Hence, we relate these probabilities by exploiting the combinatorial structure of ECMP in the Clos topology.</p><p>Lemma 2. In a Clos topology with n 0 ≥ n 2 and n pod ≥ 1 + max n 0 n 1 , n 2 (n 0 −1) n 0 (n 0 −n 2 ) , 1 , it holds that for k ≤ n 0 bad links</p><p>• event A <ref type="bibr" target="#b3">4</ref> : the connection also goes through some ( 2 , m t 1 ), t = s, and ( 2 , m t 1 ) causes a retransmis-sion, so that</p><p>• event A <ref type="bibr" target="#b4">5</ref> : the connection also goes through some (m t 1 , u t 0 ), t = s, and (m t 1 , u t 0 ) causes a retransmission. Thus,</p><p>Similarly for level 2, let B 0 be the event that a connection goes through link (j s 1 , 2 ), so that its probability is</p><p>For this link to receive a vote either (i) it causes a retransmission; (ii) a level 1 link from the origin pod causes a retransmission; (iii) a link between a tier-2 and tier-1 switch causes the retransmission; or (iv) a level 1 link in the destination pod causes the retransmission. Thus, link (j s 1 , 2 ) gets a vote if a connection goes through (j s 1 , 2 ) (event B 0 ) and either of the following occurs:</p><p>• event B 1 : (j s 1 , 2 ) causes a retransmission, i.e.,</p><p>• event B 2 : the connection also goes through some (i s 0 , j s 1 ) and (i s 0 , j s 1 ) causes a retransmission. Then,</p><p>• event B <ref type="bibr" target="#b2">3</ref> : the connection also goes through some ( 2 , m t 1 ), t = s, and ( 2 , m t 1 ) causes a retransmission, which yields</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19</head><p>• event B <ref type="bibr" target="#b3">4</ref> : the connection also goes through some (m t 1 , u t 0 ), t = s, and (m t 1 , u t 0 ) causes a retransmission. Therefore,</p><p>To obtain the lower bound in (10a), note that a bad link receives at least as many votes as retransmissions it causes. Therefore, the probability of 007 voting for a bad link is larger than the probability of that link causing a retransmission. Explicitly, using the fact that failure and routing are independent and r = r b , <ref type="bibr" target="#b13">(14)</ref> and <ref type="formula">(15)</ref> give</p><p>The assumption that n pod ≥ 1+ n 2 (n 0 −1) n 0 (n 0 −n 2 ) makes the first term smaller than the second and yields (10a).</p><p>In contrast, the upper bound in (10b) is obtained by applying the union bound <ref type="bibr" target="#b79">[80]</ref> to <ref type="bibr" target="#b13">(14)</ref> and <ref type="bibr" target="#b14">(15)</ref>. Indeed, this leads to the following inequalities for the probability of 007 voting for a good level 1 and level 2 link:</p><p>where v g,1 and v g,2 denote the probability of a good level 1 and level 2 link being voted bad, respectively. Note that once again used the independence between failures and routing. From <ref type="bibr" target="#b15">(16)</ref>, it is straightforward</p><p>. To obtain (10b), we first bound <ref type="bibr" target="#b15">(16)</ref> by assuming that all k bad links belong to the event A i and B i , i ≥ 2, that maximize v g,1 and v g,2 . For a good level 1 link, it is straightforward to see from <ref type="bibr" target="#b13">(14)</ref> that since n 0 ≥ n 2 , event A 3 has the largest coefficient. Thus, taking all links to be good except for k bad links satisfying A 3 one has v g,1 ≤ 1 n 0 n 1 n pod n 0 (n pod − 1) n 0 n pod − 1 × 4 − k n 2 + 2(n 0 − 1) n 0 (n pod − 1)</p><p>Algorithm 2 Finding the most problematic links in the network. 1: F: set of failed links 2: C: set of failed connections 3: F ← ∅ 4: while C = ∅ do <ref type="bibr">5:</ref> l ← link that explains the most number of additional failures <ref type="bibr">6:</ref> L ← failures explained by l 7:</p><p>F ← F ∪ {l} <ref type="bibr">8:</ref> C ← C − L 9: end while 10: return F which holds for k ≤ n 2 . Similarly for a good level 2 link, since n pod ≥ n 0 n 1 + 1 it holds from (15) that event B 2 has the largest coefficient. Therefore, v g,2 ≤ 1 n 1 n 2 n pod n 0 (n pod − 1) n 0 n pod − 1 × 4 − k n 0 r g + k n 0 r b , <ref type="bibr" target="#b17">(18)</ref> which holds for k ≤ n 0 . Straightforward algebra shows that for n pod ≥ 2, v g,2 ≥ v g,1 , from which (10a) follows.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pingmesh: A large-scale system for data center network latency measurement and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="139" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Passive realtime datacenter fault detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sneoren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM NSDI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Packet-level telemetry in large datacenter networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="479" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Taking the blame game out of data centers operations with NetPoirot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Arzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ciraci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Loo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Outhred</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="440" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automating datacenter network failure mitigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Netpilot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="419" to="430" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language-directed hardware design for network performance monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jeyakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the ACM Special Interest Group on Data Communication</title>
		<meeting>the Conference of the ACM Special Interest Group on Data Communication</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="85" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spatio-temporal compressive sensing and internet traffic matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Willinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="267" to="278" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Node failure localization via network tomography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM IMC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="195" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Measurement design framework for network tomography using fisher information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ITA AFM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Troubleshooting network unreachabilities using end-to-end probes and routing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dhamdhere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dovrolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Netdiagnoser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CoNEXT</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">IP fault localization via risk modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Kompella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Snoeren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="57" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Introduction to linear optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bertsimas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Designing distributed systems using approximate synchrony in data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R K</forename><surname>Ports</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="43" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Microsoft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Windows</surname></persName>
		</author>
		<ptr target="https://msdn.microsoft.com/en-us/library/windows/desktop/bb968803(v=vs.85).aspx" />
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Analysis of an Equal-Cost Multi-Path algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Hopps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rfc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cloud scale load balancing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zikos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Traffic engineering with forward fault correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gelernter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="527" to="538" />
			<date type="published" when="2014" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Link aggregation path selection method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Leo</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">504</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Resolving IP aliases in building traceroute-based internet maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Gunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sarac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1738" to="1751" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DARPA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Institute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rfc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Protocol</title>
		<imprint>
			<biblScope unit="volume">791</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gestalt: Fast, unified fault localization for networked systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Mysore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="255" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">RAIL: A case for Redundant Arrays of Inexpensive Links in data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghobadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Phanishayee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">K</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Combinatorial optimization: Theory and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vygen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Third Edition</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The mosek optimization software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mosek</surname></persName>
		</author>
		<ptr target="http://www.mosek.com54" />
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Simulation source codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Arzani</surname></persName>
		</author>
		<ptr target="https://github.com/behnazak/Vigil-007SourceCode.git" />
	</analytic>
	<monogr>
		<title level="j">Tech. rep., Microsoft Research</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cherrypick: Tracing packet trajectory in software-defined datacenter networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tammana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM SIGCOMM Symposium on Software Defined Networking Research</title>
		<meeting>the 1st ACM SIGCOMM Symposium on Software Defined Networking Research</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">007: Democratically finding the cause of packet drops</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Arzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ciraci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thau Loo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Outhred</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Arista eos system message guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arista</surname></persName>
		</author>
		<ptr target="http://simatinc.com/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
	<note>Arista Networks. simatftp/ 4.14/EOS-4.14.6M/EOS-4.14.6M-SysMsgGuide.pdf</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding and mitigating packet corruption in data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghobadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-T</forename><surname>Förster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the ACM Special Interest Group on Data Communication</title>
		<meeting>the Conference of the ACM Special Interest Group on Data Communication</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="362" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Cisco bug: Cscut86141 -sfp-h10gb-cu2.255m, hardware type changed to no-transceiver on n3k</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cisco</surname></persName>
		</author>
		<ptr target="https://quickview.cloudapps.cisco.com/quickview/bug/CSCut86141" />
		<imprint/>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simplifying datacenter network debugging with pathdump</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tammana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="233" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Al-Fares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Loukissas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scalable</surname></persName>
		</author>
		<title level="m">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Vl2: a scalable and flexible data center network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGCOMM computer communication review</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2009" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Vfp: A virtual switch platform for host sdn in the public cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Firestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="315" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Detection and localization of network black holes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Kompella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Snoeren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM 2007. 26th IEEE International Conference on Computer Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2180" to="2188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards highly reliable enterprise network services via inference of multi-level dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="13" to="24" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Expert network development environment for automating machine fault diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Adair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Hruska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Applications and Science of Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="506" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">RINC: Real-time Inference-based Network diagnosis in the Cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghasemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rexford</surname></persName>
		</author>
		<ptr target="https://www.cs.princeton.edu/research/techreps/TR-975-14" />
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Princeton University</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">User-level internet path diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Spring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wetherall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="106" to="119" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">LossRadar: Fast detection of lost packets in data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liú</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuú</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CoNEXT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="481" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">FlowRadar: A better NetFlow for data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="311" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Leveraging SDN layering to systematically troubleshoot networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wundsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Whitlock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jeyakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Handigol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mccauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM HotSDN</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Network tomography of binary network performance characteristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duffield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="5373" to="5388" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Shrink: A tool for failure diagnosis in IP networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Vasseur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM MineNet</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="173" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Decentralized boolean network tomography based on network partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ogino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kitahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arakawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/IFIP NOMS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="162" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An algebraic approach to practical and scalable overlay network monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bindel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Towards unbiased end-to-end network diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bindel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="219" to="230" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Practical issues with using network tomography for fault diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Feamster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Teixeira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="53" to="58" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Network tomography from aggregate loss reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">G</forename><surname>Duffield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bellino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Turletti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Performance Evaluation</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="147" to="163" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scalable near real-time failure localization of data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herodotou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Outhred</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1689" to="1698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A framework for distributed monitoring and root cause analysis for large IP networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Madduri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Srivatsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE SRDS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="246" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Execution anomaly detection in distributed systems through unstructured log analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICDM</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">In-network PCA and anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garofalakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="617" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Latent fault detection with unbalanced workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schuster</surname></persName>
		</author>
		<editor>EPForDM</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Performance anomaly detection and bottleneck identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ibidunmoye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hernández-Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elmroth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Network</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anomography</surname></persName>
		</author>
		<title level="m">ACM SIGCOMM IMC</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Method and apparatus for whole-network anomaly diagnosis and method to detect and classify network anomalies using traffic feature distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">276</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Histogram-based traffic anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Stoecklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dimitropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Network and Service Management</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Profiling wide-area networks using peer cooperation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Netprofiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPTPS. 2005</title>
		<imprint>
			<biblScope unit="page" from="80" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Automated TCP diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heffner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O&amp;apos;neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Siemsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pathdiag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAM</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="152" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Intelligent automated diagnosis of client device bottlenecks in private clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Widanapathirana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Sekercioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ivanovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fitzpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE UCC</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="261" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">On the characteristics and origins of internet flow rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breslau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paxson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="309" to="322" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Profiling network performance for multi-tier data center applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rexford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Failure diagnosis using decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICAC</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Identifying the root cause of video streaming issues on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dimopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Leontiadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barlet-Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papagiannaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Steenkiste</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">NetPrints: Diagnosing home network misconfigurations using shared knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhagwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Voelker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="349" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Path-based failure and evolution management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Accardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kiciman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Performance debugging for distributed systems of black boxes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Aguilera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Mogul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Wiener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Muthitacharoen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="74" to="89" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Ensuring connectivity via data plane mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schapira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX NSDI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="113" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">CONGA: Distributed congestion-aware load balancing for datacenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Edsall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dharmapurikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fingerhut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Matus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="503" to="514" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bonaventure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tcp</forename><surname>Multipath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="51" to="57" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Fast and cautious: Leveraging multi-path diversity for transport loss recovery in data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Ground control to major faults: Towards a fault tolerant and adaptive SDN control network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schiff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Canini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/IFIP DSN</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="90" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Fattire: Declarative fault tolerance for software-defined networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reitblatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Canini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM HotSDN</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="109" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Automatic failure recovery for softwaredefined networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuźniar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perešíni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Canini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kostić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM HotSDN</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="159" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Surviving failures in bandwidth-constrained datacenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bodík</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Menache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="431" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Network troubleshooting with mirror VNets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wundsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Maennel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE GLOBECOM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="283" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Understanding network failures in data centers: Measurement, analysis, and implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nagappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="350" to="361" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Tutorial on large deviations for the binomial distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arratia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of Mathematical Biology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="125" to="131" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">An Introduction to Probability Theory and Its Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<publisher>Wiley</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Wiley-Interscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
