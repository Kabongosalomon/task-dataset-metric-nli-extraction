<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Experimental Study of the Transferability of Spectral Graph Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-12-18">18 Dec 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><surname>Nilsson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University (NTU)</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
							<email>xbresson@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University (NTU)</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Experimental Study of the Transferability of Spectral Graph Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-12-18">18 Dec 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph networks</term>
					<term>spectral convolution</term>
					<term>transfer- ability</term>
					<term>benchmarking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spectral graph convolutional networks are generalizations of standard convolutional networks for graph-structured data using the Laplacian operator. A common misconception is the unstability of spectral filters, i.e. the impossibility to transfer spectral filters between graphs of variable size and topology. This misbelief has limited the development of spectral networks for multi-graph tasks in favor of spatial graph networks. However, recent works have proved the stability of spectral filters under graph perturbation. Our work complements and emphasizes further the high quality of spectral transferability by benchmarking spectral graph networks on tasks involving graphs of different size and connectivity. Numerical experiments exhibit favorable performance on graph regression, graph classification and node classification problems on two graph benchmarks. The implementation of our experiments are available on GitHub for reproducibility.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Graph neural networks <ref type="bibr">(Scarselli et al. 2009</ref>) is the class of networks that process data on graphs. Convolutional neural networks <ref type="bibr" target="#b17">(LeCun et al. 1998)</ref>, which have shown great performances on a variety of tasks defined on Euclidean domains such as computer vision, have been extended to graphs with spectral theory <ref type="bibr" target="#b2">(Bruna et al. 2014;</ref><ref type="bibr" target="#b5">Defferrard, Bresson, and Vandergheynst 2016)</ref> and spatial template matching . Graph convolutional networks (GCNs) have showed significant performances in myriads of domains, among others the representation of social networks to describe communities , fake news detection <ref type="bibr" target="#b22">(Monti et al. 2019)</ref>, chemistry <ref type="bibr" target="#b8">(Gilmer et al. 2017)</ref>, knowledge graphs <ref type="bibr" target="#b25">(Schlichtkrull et al. 2017;</ref><ref type="bibr" target="#b9">Hamilton, Ying, and Leskovec 2017)</ref>, physics <ref type="bibr" target="#b4">(Cranmer et al. 2019)</ref>, and recommendation systems <ref type="bibr" target="#b21">(Monti, Bronstein, and Bresson 2017;</ref><ref type="bibr" target="#b30">Ying et al. 2018)</ref>.</p><p>In this paper, we focus on the transferability of spectral GCNs. Spectral GCNs define learnable filters as parametric functions of the graph Laplacian operator. Transferability is an essential property of learning systems, related to Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. their generalization capability. It demonstrates the ability of the system to learn consistent and discriminative features that can be used to make prediction for graphs unseen by the model during training. <ref type="bibr" target="#b19">(Levie, Isufi, and Kutyniok 2019;</ref><ref type="bibr" target="#b18">Levie, Bronstein, and Kutyniok 2019)</ref> disproved the idea that spectral filters cannot be transfered to different graphs. Precisely, the authors in <ref type="bibr" target="#b19">(Levie, Isufi, and Kutyniok 2019)</ref> showed that given a graph filter g and a small perturbation E with E ≤ 1 on the graph Laplacian ∆ then the filter on the perturbed graph is a small perturbation of the original filter:</p><formula xml:id="formula_0">g(∆) − g(∆ + E) = O( E ).</formula><p>In other words, the perturbation of the filter is only bounded by the perturbation of the graph, and filters are thus stable. Combining stability with equivariance, graph spectral filters are proven to be transferable. Besides, in <ref type="bibr" target="#b18">(Levie, Bronstein, and Kutyniok 2019)</ref>, they showed the robustness of spectral filters w.r.t. small graph perturbations by assuming the graphs are discretized from the same "continuous" space. They established the transferability error of a given filter g:</p><formula xml:id="formula_1">Err(g) ≤ Err(∆) + Err(Consistency).</formula><p>The transferability error is thus bounded by the perturbation of the Laplacian ∆ and the consistency error that vanishes for large graphs. Spectral GCNs are thus robust if graphs are discretized from the same underlying space. Because of the misconception of failure of spectral filter transfer, the use of spectral GCNs in a multi-graph setting has been scarce in the literature. <ref type="bibr" target="#b13">(Knyazev et al. 2018</ref>) applied spectral GCNs to a set of multiple molecular graphs and <ref type="bibr" target="#b16">(Ktena et al. 2018)</ref> to brain connectivity networks.</p><p>The goal of this work is to validate the theoretical results on the transferability of spectral filters with a corpus of experimental evidence. Specifically, we will show that Cheb-Nets <ref type="bibr" target="#b5">(Defferrard, Bresson, and Vandergheynst 2016)</ref> performs favorably for the fundamental tasks of graph classification, graph regression and node classification using two graph benchmarks. Another class of spectral networks is CayleyNets <ref type="bibr" target="#b20">(Levie et al. 2018)</ref>, which may also be investigated in a future work.</p><p>ChebNets <ref type="bibr" target="#b5">(Defferrard, Bresson, and Vandergheynst 2016)</ref> These graph networks define smooth spectral filters g θ parametrized with Chebyshev polynomials T i applied to the normalised Laplacian operator ∆:</p><formula xml:id="formula_2">∆ = I − D − 1 2 AD − 1 2 ,<label>(1)</label></formula><p>where A is the adjacency matrix and D is the degree matrix. The spectral filters g θ are defined as</p><formula xml:id="formula_3">g θ (∆)h = k i=0 θ i T i (∆)h,<label>(2)</label></formula><p>where k is the number of Chebyshev polynomials, θ are the learnable parameters, h is a signal defined on the graph, and ∆ = 2λ −1 max ∆ − I n is the Laplacian re-normalized such that its eigenvalues are in the interval [−1, 1], where the Chebyshev polynomials are orthogonal. A great computational advantage of these parametric filters is to define them with a recursive equation:</p><formula xml:id="formula_4">   T 0 = h T 1 =∆T 0 T k≥2 = 2∆T k−1 − T k−2 (3)</formula><p>which reduces the computational complexity to O(n) for sparse graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Benchmarks</head><p>Recent projects <ref type="bibr" target="#b10">(Hu et al. 2020;</ref><ref type="bibr" target="#b6">Dwivedi et al. 2020a</ref>) have proposed benchmarks with collections of datasets to evaluate and compare GNNs. They not only provide openly accessible and peer-reviewed datasets but also leaderboards, helping to track the performance of different GNN models. In this work, we will use datasets from the Open Graph Benchmark (OGB version 1.2.3) <ref type="bibr" target="#b10">(Hu et al. 2020</ref>) and Benchmarking-GNNs <ref type="bibr" target="#b7">(Dwivedi et al. 2020b</ref>). The selected datasets are composed of multiple graphs and cover a variety of tasks such as graph regression (ZINC , ogbg-Molpcba), graph classification (ogbg-Molhiv) and node classification (CLUSTER, PATTERN). A summary of these datasets and some of their proprieties can be found in <ref type="table" target="#tab_0">Table 1</ref>. We notice that three of the five selected datasets are made of molecular graphs. This is simply because there exist only a few real-world datasets of multiple graphs with varying sizes. Nonetheless, they exhibit significant differences, in respect of task and size, making them complementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PATTERN &amp; CLUSTER</head><p>PATTERN and CLUSTER are node classification datasets for graphs generated synthetically with stochastic block models (SBMs) <ref type="bibr" target="#b0">(Abbe 2017)</ref>, commonly used to model communities in social networks. Each node has an intra-probability of being connected to a node in the same communitie and an extra-probability of being connected to a node in other communities. For CLUSTER, the task is to identify communities in a semi-supervised setting. Each graph has six SBM communities of 5 to 35 nodes, and one node in each community is labeled at random. For PATTERN, the task is pattern matching, that is recognizing pre-defined subgraphs embedded in larger graphs. There are 100 randomly generated patterns of 20 nodes with random features. The train/test/val splitting is 10K/2K/2K respectively for PAT-TERN and 10K/1K/1K for CLUSTER. More details on the construction of these datasets can be found in the paper <ref type="bibr" target="#b7">(Dwivedi et al. 2020b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ZINC</head><p>ZINC is a graph regression dataset composed of molecular graphs. The task is to predict the constrained solubility of each molecule (Jin, Barzilay, and Jaakkola 2018), a continuous variable. The accuracy is determined by the mean average error of the L1 loss over the test set. Node and edge features are categorical and correspond to the type of atoms and bonds. The number of graphs in the training/validation/test sets are respectively 10K/1K/1K graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OGBG-MOL</head><p>ogbg-Molhiv and ogbg-Molpcba are two molecular datasets from the OGB benchmark, used for regression tasks. ogbg-Molhiv is the smallest of the two datasets with 41,127 graphs. The task is to predict if a given molecule would inhibit the replication of the HIV, cast as a binary label. It is evaluated by a ROC-AUC performance metric. ogbg-Molpcba represents a more difficult task as the set is larger with 437,929 graphs, and there are 128 properties to regress for each graph. Besides, the class distribution is skewed with only 1.4% of positive data. The performance is evaluated with average precision (AP). Both datasets are split by scaffolding to split the graphs based on their structure. This contrasts with ZINC which is randomly split, making easier to generalize <ref type="bibr" target="#b10">(Hu et al. 2020</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChebNet Architectures</head><p>Although it is essential to compare the performance of GCNs to contextualize a new model, there is no perfect approach to compare two GCNs. Therefore, each benchmark has defined a set of rules to enable the comparison of models. In this work, we will follow the strategy of each benchmark to compare ChebNets with the following popular models; GCN , GraphSage <ref type="bibr" target="#b9">(Hamilton, Ying, and Leskovec 2017)</ref>, GAT <ref type="bibr" target="#b26">(Velickovic et al. 2018</ref>) and GIN .</p><p>All experiments are run on a single GeForce RTX 2070 8GB GPU. The source code is available at: https://github.com/Axeln78/ Transferability-of-spectral-gnns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmarking-GNNs</head><p>In Benchmarking-GNNs <ref type="bibr" target="#b7">(Dwivedi et al. 2020b</ref>), a budget of 100,000 learnable parameters with four convolutional layers are fixed to compare the performance with the same learning capacity. We will follow this constraint when designing ChebNets for CLUSTER, PATTERN and ZINC. The learning hyperparameters are the same as in <ref type="bibr" target="#b7">(Dwivedi et al. 2020b</ref> to prevent improving the performance by tweaking. That is, the batch size is 128 graphs, Adam optimizer has an initial learning rate of 10 −3 , reduced by a factor of 0.5 if the validation accuracy does not decrease every 5 epochs, batch normalisation and no dropout. Finally, the score is averaged over four runs with pre-selected seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OGBG-MOL</head><p>For the selected OGB datasets, ogbg-Molhiv and ogbg-Molpcba, we will adhere to the default architectures described in <ref type="bibr" target="#b10">(Hu et al. 2020)</ref> i.e. those used for GIN and GCN. They are composed of an Atom-and Edge-Embedding layer, five convolutional layers, a mean-pooling layer with a hidden dimensionality of 300 followed by three linear layers with a tuned dropout ratio ∈ {0.0, 0.5}. The learning hyperparameters are the default OGB values, with a learning rate of 10 −3 for the Adam optimizer and a batch size of 128. The result is the average over ten runs with random seeds. A summary of the ChebNet architectures for all datasets is available in <ref type="table">Table.</ref> 2. Finally, observe that the OGB leaderboard has no strict rules about model architecture, parameter budget, and hyperparameter selection. Therefore we will only provide the two models GIN and GCN, which have similar architectures as a basis of comparison, and discuss more informally models that are on the leaderboard as of this writing.</p><p>We also notice that both benchmarks do not have any spectral GCNs to compare to in their leaderboard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Values of k and λ max</head><p>We select the number of Chebyshev polynomials to be k = 5 for PATTERN and CLUSTER. This value is related to the size of the communities (5-35 nodes). For ZINC, the chosen Chebyshev order is k = 2 as the graphs are small (9 to 35 nodes). For ogbg-Molhiv and ogbg-Molpcba, the order of polynomial is selected to be k = 3.</p><p>For all ChebNets, the spectral parameter λ max = 2 is fixed, as the largest eigenvalues can sometimes be numerical unstable to compute on certain graphs. Besides, fixing λ max = 2 is mathematically justified as the spectrum of the normalized Laplacian is bounded by this value <ref type="bibr" target="#b3">(Chung and Graham 1997)</ref>. Another advantage is to reduce the computational cost and allow to compare with papers using this approximation <ref type="bibr">(Knyazev et al. 2019</ref><ref type="bibr" target="#b13">(Knyazev et al. , 2018</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Numerical Results</head><p>Overall, numerical experiments show that ChebNets perform favorably well compared to other popular GCN models with comparable architectures. <ref type="table" target="#tab_2">Table 3</ref> reports the performance of ChebNets for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLUSTER</head><p>ChebNets outperform all models for the CLUSTER dataset and perform at the level of deeper models found in the leaderboard of the benchmark. In fact, the strong performance implies that ChebNets hold a good inductive bias for identifying community clusters in a semi-supervised node classification setting. This was expected as Laplacian-based clustering techniques have showed significant performance for community detection <ref type="bibr" target="#b27">(Von Luxburg 2007)</ref>. This is in contrast to the current literature as the a commonly used model for this task has been GCNs , which perform worse (25 percentage points). Furthermore, if we consider that this dataset is a set of discretizations of a continuous manifold, then this result is a salient confirmation of the theory of <ref type="bibr" target="#b18">(Levie, Bronstein, and Kutyniok 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PATTERN</head><p>ChebNets perform better than the other models for PATTERN and performs closely to GIN. Both models are have significantly higher accuracy than the rest. Although is expected that GIN performs well on tasks of pattern and graph matching, it is striking that the ChebNet performs equally well. Additionally, we observe no significant improvement in accuracy with deeper models in the benchmark leaderboard for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ZINC</head><p>The ZINC experiment allows to compare ChebNets with a range of models with a similar budget of learnable parameters. Comparing to the leaderboard in <ref type="bibr" target="#b7">(Dwivedi et al. 2020b)</ref>, ChebNets not only performs significantly better than spatial GCN models, they exhibit superior performances over models with the same depth although some are using edge features like GAT or Gated GCN <ref type="bibr" target="#b1">(Bresson and Laurent 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OGBG-MOL</head><p>For the two OGB tasks, ChebNets achieve better performance than the two models of comparison, GIN and GCN. Unexpectedly, ChebNets outperform GIN, a model designed Dataset Model Architecture Hyperparam.   <ref type="bibr" target="#b28">(Weisfeiler and Lehman 1968)</ref>, while using 25% less parameters. Finally, comparing our results with the OGB leaderboard also reveals that ChebNets provide the best performance over the other reported GCNs that do not consider additional data augmentation techniques.</p><formula xml:id="formula_5">CLUSTER 7 -E70 -ChN70 -ChN70 -ChN70 -ChN70 -MP70 -L35 -L17 -L6 k = 5 PATTERN 3 -E70 -ChN70 -ChN70 -ChN70 -ChN70 -MP70 -L35 -L17 -L2 k = 5 ZINC 28 -E106 -ChN106 -ChN106 -ChN106 -ChN106 -MP106 -L53 -L26 -L1 (No-RC) k = 2 ogbg-Molhiv -AE300 -ChN300 -ChN300 -ChN300 -ChN300 -ChN300 -MP300 -L150 -L75 -L1 k = 3 ogbg-Molpcba -AE300 -ChN300 -ChN300 -ChN300 -ChN300 -ChN300 -MP300 -L150 -L75 -L128 k = 3</formula><p>Overall the results show that ChebNets provide an efficient architecture for molecule tasks with ZINC, ogbg-Molhiv and ogbg-Molpcba. The presented results can be further improved by modifying the architecture to consider the edge bond features, which are important information about molecular structure.</p><p>To summarize, it is clear that the performance of ChebNets is consistently high compared to the most used GCN architectures. This delivers a significant experimental proof that ChebNets work well on datasets of multiple graphs with variable sizes and for different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This experimental work investigates the transferability capacity of spectral GCNs on two graph benchmarks. Numerical experiments demonstrate that ChebNets perform better than most popular spatial GCNs with comparable parameter budgets. These numerical experiments strongly support recent analytical results <ref type="bibr" target="#b19">(Levie, Isufi, and Kutyniok 2019;</ref><ref type="bibr" target="#b18">Levie, Bronstein, and Kutyniok 2019)</ref> that spectral GCNs can compete at least as well as other spatial GCNs in the multi-graph setting. Such results are promising to encourage the development of new spectral networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of the different tasks with the number of graphs, problem type and type of metric. *is the average node number instead of the range.</figDesc><table><row><cell>)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Summary of all model architectures used. E stands for Embedding, AE for AtomEmbedding, MP for Mean Pooling, L for Linear, ChN for ChebNets layer, and No-RC for no residual connections used. Each layer type is followed by a number indicating the output dimension.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell># parameters</cell><cell>Accuracy</cell><cell>Metric</cell></row><row><cell></cell><cell>ChebNet</cell><cell>102,535</cell><cell>73.13 ± 0.64</cell><cell></cell></row><row><cell>CLUSTER</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Numerical study of ChebNets on several datasets. The models are ranked w.r.t. performance. The proposed ChebNets are in bold. The performances of the models identified with * are taken from the leaderboards of different benchmarks as of Nov. 9th, 2020. The results are the average and standard deviation over four runs for tasks from Benchmarking-GNNs and ten for OGB. ChebNets show favorable performance compared to other models by achieving the best performance in all five tasks.with maximal representation power w.r.t. the Weisfeiler-Lehman graph isomorphism test</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>XB is supported by NRF Fellowship NRFF2017-10.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Community detection and stochastic block models: recent developments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Abbe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10146</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, math, stat</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07553</idno>
		<title level="m">Residual Gated Graph ConvNets</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral Networks and Locally Connected Networks on Graphs</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Spectral graph theory. 92</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Graham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>American Mathematical Soc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05862</idno>
		<title level="m">Learning Symbolic Physics with Graph Networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>astro-ph, physics:physics, stat</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.09375[cs.LG]9</idno>
		<title level="m">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<title level="m">Benchmarking Graph Neural Networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<title level="m">Benchmarking Graph Neural Networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01212</idno>
		<title level="m">Neural Message Passing for Quantum Chemistry</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02216</idno>
		<title level="m">Inductive Representation Learning on Large Graphs</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00687</idno>
		<title level="m">Open Graph Benchmark: Datasets for Machine Learning on Graphs</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Junction tree variational autoencoder for molecular graph generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04364</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Knyazev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.09595</idno>
		<title level="m">Spectral Multigraph Networks for Discovering and Fusing Relationships in Molecules</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Knyazev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<idno type="arXiv">arXiv:1907.09000</idno>
	</analytic>
	<monogr>
		<title level="j">Image Classification with Hierarchical Multigraph Networks</title>
		<imprint/>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Metric learning with spectral graph convolutions on brain connectivity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Ktena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parisot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajchl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="431" to="442" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kutyniok</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.12972</idno>
		<title level="m">Transferability of Spectral Graph Convolutional Neural Networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">On the Transferability of Spectral Graph Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Isufi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kutyniok</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10524</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cayleynets: Graph convolutional neural networks with complex rational spectral filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06803[cs.LG]11</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mannion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06673</idno>
	</analytic>
	<monogr>
		<title level="j">Fake News Detection on Social Media using Geometric Deep Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<imprint>
			<publisher>Ah Chung Tsoi</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Graph Neural Network Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNN.2008</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06103</idno>
		<title level="m">Modeling Relational Data with Graph Convolutional Networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903[stat.ML]12</idno>
		<title level="m">Graph Attention Networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A reduction of a graph to a canonical form and an algebra arising during this reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weisfeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Lehman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nauchno-Technicheskaya Informatsia</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="12" to="16" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.1145/3219819.3219890</idno>
		<title level="m">Graph Convolutional Neural Networks for Web-Scale Recommender Systems. Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining 974-983</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
