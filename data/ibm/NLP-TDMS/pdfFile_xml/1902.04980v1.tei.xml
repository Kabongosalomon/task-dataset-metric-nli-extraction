<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RECURRENT NEURAL NETWORKS WITH STOCHASTIC LAYERS FOR ACOUSTIC NOVELTY DETECTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duong</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">) IMT Atlantique, Lab-STICC</orgName>
								<orgName type="institution">UBL</orgName>
								<address>
									<settlement>Brest</settlement>
									<country>France (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><forename type="middle">S</forename><surname>Kirsebom</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Big Data Analytics</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country>Canada (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fábio</forename><surname>Frazão</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Big Data Analytics</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country>Canada (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Fablet</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">) IMT Atlantique, Lab-STICC</orgName>
								<orgName type="institution">UBL</orgName>
								<address>
									<settlement>Brest</settlement>
									<country>France (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Matwin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Big Data Analytics</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<country>Canada (</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">Polish Academy of Sciences</orgName>
								<address>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RECURRENT NEURAL NETWORKS WITH STOCHASTIC LAYERS FOR ACOUSTIC NOVELTY DETECTION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we adapt Recurrent Neural Networks with Stochastic Layers, which are the state-of-the-art for generating text, music and speech, to the problem of acoustic novelty detection. By integrating uncertainty into the hidden states, this type of network is able to learn the distribution of complex sequences. Because the learned distribution can be calculated explicitly in terms of probability, we can evaluate how likely an observation is then detect low-probability events as novel. The model is robust, highly unsupervised, end-toend and requires minimum preprocessing, feature engineering or hyperparameter tuning. An experiment on a benchmark dataset shows that our model outperforms the state-of-the-art acoustic novelty detectors.</p><p>Index Termsacoustic modeling, novelty detection, variational recurrent neural network, stochastic recurrent neural network.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Audio processing in general, and acoustic novelty detection in particular has attracted significant attention recently. A number of studies have used acoustic data to detect abnormal events, mostly for surveillance purposes, such as human fall detection <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, abnormal jet engine vibration detection <ref type="bibr" target="#b2">[3]</ref>, hazardous events detection <ref type="bibr" target="#b3">[4]</ref>.</p><p>The main challenge of novelty detection is we do not have a large amount of novel events to learn their characteristics, while the normal set is usually very big and contains a large amount of uncertainty. The common approach is to use unsupervised methods to learn the normality model, then consider events that do not fit this model as abnormal (novel). Most of these systems use Gaussian Mixture Model (GMM) or Hidden Markov Model (HMM) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Bayesian Networks have also been explored <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. Recently, advances in deep learning <ref type="bibr" target="#b8">[9]</ref>, especially in Recurrent Neural Networks (RNNs) and their extensions (Long Short-Term Memory -LSTM <ref type="bibr" target="#b9">[10]</ref>, Gated Recurrent Unit -GRU <ref type="bibr" target="#b10">[11]</ref>) have opened new venues for acoustic modeling. In <ref type="bibr" target="#b11">[12]</ref>, the authors employed LSTMs to create an AutoEncoder (AE) to model normal sounds and detect abnormal sounds using the reconstruction errors. This idea has been extended in <ref type="bibr" target="#b12">[13]</ref> by applying an adversarial training protocol.</p><p>However, acoustic signals are stochastic. RNN-based networks, whose hidden states are deterministic, can hardly capture all the variations in the data. Recent efforts to improve the modeling capacity of RNNs by including stochastic factors in their hidden states have shown impressive results, especially for generating text, music and speech <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>.</p><p>In this paper, we adapt these models to create an unsupervised acoustic novelty detector. Our approach performs an end-to-end learning of a probabilistic representation of acoustic signals. Given this representation, we can evaluate how likely an observation and state the detection of novel events as the detection of observations with a low probability. We argue that this model is robust, highly unsupervised, end-to-end and requires minimum preprocessing, feature engineering or hyperparameter tuning. Our empirical evaluation on a dataset for novel event detection in audio data shows that the proposed model outperforms the state-of-the-art.</p><p>The paper is organized as follows: in Section 2, we present the details of the proposed approach; we compare the model with state-of-the-art methods to point out its advantages in Section 3; the experiment and results are shown in Section 4; finally in Section 5 we give conclusions and some perspectives for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE PROPOSED APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Recurrent Neural Networks with Stochastic Layers (RNNSLs)</head><p>For time series modeling, the two most common approaches are State Space Models (SSMs) and Recurrent Neural Networks (RNNs). SSMs such as Kalman filters <ref type="bibr" target="#b17">[18]</ref> and particle filters <ref type="bibr" target="#b18">[19]</ref> have been explored for a long time and are the state-of-the-art model-driven schemes thanks to their ability to model stochasticity. However, these models are limited by their mathematical assumptions (for example, Kalman filters assume the data generating process is Gaussian). RNNs, on the other hand, have attracted a lot of attentions recently by their capacity to represent long-term dependencies in time series <ref type="bibr" target="#b8">[9]</ref>. The main drawback of RNNs is that their hidden states are deterministic, making them unable to capture all the stochastic components of the data. A number of efforts have been made to bring together the power of SSMs and RNNs <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b19">[20]</ref>: Recurrent Neural Networks with Stochastic Layers (RNNSLs).</p><p>RNNSLs aim to learn the distribution p, which can be factored through time, over a sequence of T observed random variables {x t } ,t=1..T :</p><formula xml:id="formula_0">p(x 1:T ) = T t=1 p t (x t |x &lt;t ),<label>(1)</label></formula><p>where x &lt;t denotes x 1:t−1 . Following a SSM formulation, we assume that the data generation process of x 1:T relies on a sequence of T latent random variables {z t } ,t=1..T . At each time step t, the joint distribution p t (x t , z t |x &lt;t z &lt;t ) can be factored into:</p><formula xml:id="formula_1">p t (x t , z t |x &lt;t z &lt;t ) = p t (x t |x &lt;t , z ≤t )p t (z t |x &lt;t , z &lt;t ), (2)</formula><p>where z ≤t denotes z 1:t . In other words, each time step of the network is an autoencoder, conditionally to the historical information.</p><p>Depending on the stochastic nature of the considered data, the emission distribution p t (x t |x &lt;t , z ≤t ) may be highly nonlinear. However, this nonlinearity usually leads to the intractability of the inference distribution p t (z t |x ≤t , z &lt;t ). The most common solution to overcome this obstacle is the variational approach <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, which introduces an approximation q t (z t |x ≤t , z &lt;t ) of the posterior distribution p t (z t |x ≤t , z &lt;t ) then estimates p t (x t |x &lt;t ) by the Evidence Lower BOund (ELBO) L(x, p t , q t ):</p><formula xml:id="formula_2">log p t (x t |x &lt;t ) ≥ L(x, p t , q t ) = E zt∼qt log p t (x t |x &lt;t , z ≤t ) − KL q t (z t |x ≤t , z &lt;t )||p t (z t |x &lt;t , z &lt;t ) (3)</formula><p>where KL q t ||p t is the Kullback-Leibler divergence between two distributions q t and p t .</p><p>There are several types of RNNSLs, differing in the way that they model the structure of the latent space. The most common types are Variational Recurrent Neural Networks (VRNNs) <ref type="bibr" target="#b15">[16]</ref>, Stochastic Recurrent Neural Networks (SRNNs) <ref type="bibr" target="#b16">[17]</ref> and Deep Kalman Filters (DKFs) <ref type="bibr" target="#b19">[20]</ref>. We experimented most of these types, however, in this paper, for simplicity purposes, we only report the VRNNs, introduced by Chung et al. <ref type="bibr" target="#b15">[16]</ref>. In VRNNs, the historical information (x &lt;t , z &lt;t ) is encoded by the dynamics of the hidden states of their RNN</p><formula xml:id="formula_3">(LSTM) h t = h(x t−1 , z t−1 , h t−1 )</formula><p>. More precisely, it involves the parameterization of the following distributions, namely the emission distribution p t (x t |x &lt;t , z ≤t ) = p(x t |z t , h t ), the prior distribution p t (z t |x &lt;t , z &lt;t ) = p(z t |h t ) and the variational posterior distribution q t (z t |x ≤t , z &lt;t ) = p(z t |x t , h t ) as neural networks. Here, we consider fully connected networks with Gaussian formulation of these three distributions. For more details of VRNNs, please refer to <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">RNNSLs for Acoustic Novelty Detection</head><p>RNNSLs were initially designed for generating text, music, speech. They are currently the state-of-the-art in these domains <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>. The interesting point of this type of models in comparison to other state-of-the-art methods like Wavenet <ref type="bibr" target="#b21">[22]</ref> is that these models calculate the distribution p(x 1:T ) explicitly, so that after learning this distribution from the training set, we can evaluate the probability for each new sequence. The idea of using RNNSLs for novelty detection was first introduced in <ref type="bibr" target="#b22">[23]</ref> for the detection of abnormal behaviors of vessels, we adapt this model to novelty detection in acoustic data.</p><p>Here, an acoustic signal is modeled as a time series {x t } ,t=1..T where x t can be a chunk of n samples of the waveform, or n frequency bins in a spectrogram at a given time t. A RNNSL first learns the distribution over x 1:T in the training set, which may or may not contain some abnormal sequences. Then, for any new acoustic signal, we can evaluate its log-probability. If this log-probability is smaller than a threshold, the sequence will be considered as abnormal (or novel), as illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>To choose the threshold, we create a validation set, which again may or may not contain some abnormal sequences and compute the mean µ valid and the standard deviation σ valid of the log-probability of the sequences in this set. The value of the threshold is then chosen as: θ = µ valid − α * σ valid . α is usually chosen as 3.</p><p>The training set and the validation set may contain some abnormal sequences. However, since RNNSLs are probabilistic models, they will eventually ignore these "outliers" (this conjecture is confirmed experimentally). This property helps to reduce data cleaning efforts. x t is the original signal at the given time step t, h t is the hidden state of the RNN (LTSM), z t is the latent stochastic state, x t is the reconstructed output of the AE. The solid arrows denote the calculation processes, while the dashed arrows show how the cost function is calculated. We use the same notation as <ref type="bibr" target="#b16">[17]</ref>, circles for stochastic factors, diamonds for deterministic factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELATED WORK</head><p>A number of researches have explored deep neural networks to detect novelty in acoustic surveillance. We point out here the advantages of our model over those used in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>, which are currently the state-of-the-art methods.</p><p>Both <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref> used RNNs (LSTMs in particular) as an AutoEncoder (AE) which can reconstruct the original signal from a compressed representation (Compression AutoEncoders -CAEs) or from a corrupted version of it (Denoising AutoEncoders -DAEs). However, as discussed in <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b19">[20]</ref>, the fact that the hidden states of RNNs are deterministic reduces their capacity to capture all data variabilities, especially for data that contain high levels of randomness.</p><p>Moreover, the detection criterion used in <ref type="bibr" target="#b11">[12]</ref> is the Euclidean distance between the original input and the reconstructed output of the autoencoder. This criterion is very sensitive to noise. <ref type="bibr" target="#b12">[13]</ref> addressed this drawback by using an adversarial strategy, however, the ultimate idea is also to compare the original input and the reconstructed output from the autoencoder. By contrast, our method detects novel events by directly evaluating the probability of the received signal. Besides the improved detection criterion, the architecture of our model is also more robust to noise <ref type="bibr" target="#b22">[23]</ref>.</p><p>These differences are sketched in <ref type="figure" target="#fig_1">Fig. 2</ref>. The hidden space of our model has stochastic factors, which help to increase modeling capacity. The decision rule of our model is a function of the distribution learned by the network, making the model more robust to noise.</p><p>The selection of the thresholding value for novelty detection is another important difference compared to previous works. The approach in <ref type="bibr" target="#b11">[12]</ref> is not fully unsupervised, because it needs some information about the proportion of abnormal events in the data. Our method, in contrast, only uses the information from the training set and the validation set to chose the threshold, without any prior knowledge of the annotations, based on a statistically-sound criterion, i.e. the false alarm rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENT AND RESULT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>We tested our model 1 on the same dataset used in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>, which is part of the PASCAL CHiME speech separation and recognition challenge dataset <ref type="bibr" target="#b23">[24]</ref>. The original dataset contains 7 hours of in-home environment recordings with two children and two adults performing common activities, such as talking, eating, playing and watching television. The author of <ref type="bibr" target="#b11">[12]</ref> took a part of those recordings and created a dataset for acoustic novelty detection (100 minutes for the training set and 70 minutes for the test set). In the new dataset, the sounds of the PASCAL CHiME are considered as background, the test set was generated by digitally adding abnormal sounds like alarms, falls, fractures (breakages of objects), screams. The details of the dataset were presented in <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Setup</head><p>In order to use the models in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref> as baselines, we set up our model to have the same evaluation metric that was used in those papers. However, instead of transforming the data to mel spectrograms like in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>, we worked directly with the waveform (end-to-end model). The dataset was recorded by a binaural microphone at a sample rate of 16kHz. We converted each audio to 1 channel and then split it into sequences of 160-dimensional frames, each frame corresponds to 0.01s, as in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>. <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref> evaluated the detection at each frame instead of at the whole sequence, so we also applied the thresholding step to each log p(x t |x &lt;t ), instead of log p(x 1:T ).</p><p>We tested different topologies of VRNN, with the latent size of 64, 80, 160 and 200. The models were trained using Adam optimizer <ref type="bibr" target="#b24">[25]</ref>, with a learning rate of 3e − 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>Different configurations gave different log-likelihoods on the dataset, however the final detection results were quite similar. We report here only one of the topologies, which gave the best result: VRNN with 160 latent units (the models with 80 hidden units also gave similar results). We compare the performance of our model with the result of GMM, HMM, those in <ref type="bibr" target="#b11">[12]</ref> (LSTM-based CAE, LSTM-based DAE) and in <ref type="bibr" target="#b12">[13]</ref> (Adversarial AE). The result is shown in <ref type="table">Table 1</ref> 2 . Besides choosing the threshold automatically as discussed in Section 2, we also used the same technique as in <ref type="bibr" target="#b11">[12]</ref> to chose the optimal threshold value, denoted as VRNN* . Our method not only outperformed the state-of-the-art methods, but also has the ability to work online, which is highly beneficial for real-time surveillance. Models that use bidirectional LSTM (BLSTM-CAEs, BLSTM-DAEs) can not reach online processing the because a look-ahead buffer is required. The online processing ability of Adversarial AEs depends on the structure that they use (LSTM or BLSTM).</p><p>When investigating the cases where the proposed model misdetected the novelty, we found that actually the model could detect all the novel events, however, the way the detection was evaluated reduced the accuracy. As in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>, the detection was evaluated at each time step of 0.01s. Our model has a memory effect (the memory of its LSTM cells), so it tends to merge the abnormal events that are very close to each other, as shown in <ref type="figure">Fig. 3</ref>. In other cases, the model missed a part of the sound, especially for the tail of the fractures, as shown in <ref type="figure" target="#fig_2">Fig. 4</ref>. These sounds have a long tail which is gradually submerged in the background. These misdetections are not detrimental in real life applications, because we are more interested in whether or not there is a novel event than on how long the event is.</p><p>We also conducted a robustness test where we added Gaussian noise to the test set. The additive noise is unknown by the model. This is a common scenario in audio surveillance, when the background environment changes (e.g. because of winds) or when noise appears in the electronic system. <ref type="table">Table 2</ref>  <ref type="bibr" target="#b2">3</ref> shows the performance of the proposed <ref type="figure">Fig. 3</ref>. An example where the novelty events were merged. This figure shows the waveform of two alarms, each alarm consists of there "beeps", our model considered this "beep beep beep" as one event, while the annotation made by the authors of <ref type="bibr" target="#b11">[12]</ref> separates these "beeps". approach (with optimal threshold) on the corrupted test sets with different level of Signal to Noise Ratio (SNR). Thanks to the nature of VRNNs and the improved detection criterion, our model is robust to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS AND PERSPECTIVES</head><p>We have presented a novel unsupervised end-to-end approach for acoustic novelty detection. This approach exploits RNNs with stochastic layers, which are the state-of-the-art frameworks for time series modeling. Given the learned probabilistic representations, novelty detection can be stated as a classic statistical test, which fully accounts for the stochasticity of the considered acoustic datasets. Reported experiments on a benchmarked dataset showed that the model outperforms the state-of-the-art detectors <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>.</p><p>The dataset used in this paper is quite simple, the novel events in it are quite easy to be detected. Future work could involve applying this model to more complex signals, e.g. underwater acoustic signals which depict even greater variabilities. The impact of the threshold is also being studied to obtain better threshold selection rule.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Architecture of the proposed RNNSL-based novelty detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Architecture and decision rule of the proposed model (VRNN) in compared to previously proposed AE-based models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>An example where the model missed a part of the novelty event. This figure shows the waveform of the sound of a fracture of a dish. The tail of the sound is very mall and gradually becomes submerged in the background.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Detection result, in comparison with state-of-the-art methods. Robustness test.</figDesc><table><row><cell>Method</cell><cell>Online Processing</cell><cell>Precision</cell><cell>Recall</cell><cell>F1 score</cell></row><row><cell>GMM</cell><cell>Yes</cell><cell>99.1</cell><cell>87.8</cell><cell>89.4</cell></row><row><cell>HMM</cell><cell>Yes</cell><cell>94.1</cell><cell>88.9</cell><cell>91.1</cell></row><row><cell>LSTM-CAE</cell><cell>Yes</cell><cell>91.7</cell><cell>86.6</cell><cell>89.1</cell></row><row><cell>BLSTM-CAE</cell><cell>No</cell><cell>93.6</cell><cell>89.2</cell><cell>91.3</cell></row><row><cell>LSTM-DAE</cell><cell>Yes</cell><cell>94.2</cell><cell>90.6</cell><cell>92.4</cell></row><row><cell>BLSTM-DAE</cell><cell>No</cell><cell>94.7</cell><cell>92.0</cell><cell>93.4</cell></row><row><cell>Adversarial AE</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>93.3</cell></row><row><cell>VRNN</cell><cell>Yes</cell><cell>95.4</cell><cell>91.8</cell><cell>93.6</cell></row><row><cell>VRNN*</cell><cell>Yes</cell><cell>95.4</cell><cell>92.8</cell><cell>94.1</cell></row><row><cell>SNR</cell><cell>Precision</cell><cell>Recall</cell><cell>F1 score</cell><cell></cell></row><row><cell>5dB</cell><cell>96.0</cell><cell>91.2</cell><cell>93.6</cell><cell></cell></row><row><cell>10dB</cell><cell>96.1</cell><cell>91.9</cell><cell>94.0</cell><cell></cell></row><row><cell>15dB</cell><cell>96.1</cell><cell>92.1</cell><cell>94.0</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code is available at https://github.com/dnguyengithub/AudioNovelty 2 The values inTable 1are from<ref type="bibr" target="#b11">[12]</ref> and<ref type="bibr" target="#b12">[13]</ref>,<ref type="bibr" target="#b12">[13]</ref> did not show the precision and recall of their model</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3"><ref type="bibr" target="#b11">[12]</ref> and<ref type="bibr" target="#b12">[13]</ref> did not provide sufficient detail to replicate their codes for this test.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Acoustic fall detection using Gaussian mixture models and GMM supervectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Potamianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009-04" />
			<biblScope unit="page" from="69" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An unsupervised acoustic fall detection system using source separation for sound interference suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="199" to="210" />
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Novelty detection in jet engine vibration spectra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tarassenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Condition Monitoring</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2" to="7" />
			<date type="published" when="2015-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Probabilistic Novelty Detection for Acoustic Surveillance Under Real-World Conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ntalampiras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Potamitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fakotakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="713" to="719" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Multimodal Audio Visible and Infrared Surveillance System (MAVISS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 3rd International Conference on Intelligent Sensing and Information Processing</title>
		<imprint>
			<date type="published" when="2005-12" />
			<biblScope unit="page" from="151" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Audio Based Event Detection for Multimedia Surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Atrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Maddage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE International Conference on Acoustics Speed and Signal Processing Proceedings</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="813" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CAS-SANDRA: audio-video sensor fusion for aggression detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zajdel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krijnders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Andringa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Conference on Advanced Video and Signal Based Surveillance</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007-09" />
			<biblScope unit="page" from="200" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Audio-Visual Fusion for Detecting Violent Scenes in Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Giannakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kosmopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Perantonis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Theodoridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence: Theories, Models and Applications</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">6040</biblScope>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth annual conference of the international speech communication association</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gated Feedback Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vesperini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Squartini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2015-04" />
			<biblScope unit="page" from="1996" to="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Acoustic novelty detection with adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Principi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vesperini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Squartini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Piazza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2017-05" />
			<biblScope unit="page" from="3324" to="3330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning Stochastic Recurrent Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7610</idno>
		<idno>arXiv: 1411.7610</idno>
		<imprint>
			<date type="published" when="2014-11" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boulanger-Lewandowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6392</idno>
	</analytic>
	<monogr>
		<title level="m">29th International Conference on Machine Learning (ICML 2012)</title>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Recurrent Latent Variable Model for Sequential Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sequential Neural Models with Stochastic Layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2199" to="2207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Introduction to Random Signals and Applied Kalman Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y C</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A Tutorial on Particle Filtering and Smoothing: Fifteen years later</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Johansen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep Kalman Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Filtering Variational Objectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017-05" />
			<biblScope unit="page" from="6576" to="6586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<idno>arXiv: 1609.03499</idno>
		<title level="m">WaveNet: A Generative Model for Raw Audio</title>
		<imprint>
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Multi-task Deep Learning Architecture for Maritime Surveillance using AIS Data Streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vadaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hajduch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fablet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE DSAA</title>
		<imprint>
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The PASCAL CHiME speech separation and recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="621" to="633" />
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
